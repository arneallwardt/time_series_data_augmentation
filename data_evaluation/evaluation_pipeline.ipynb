{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "from utilities import split_data_into_sequences, load_sequential_time_series, reconstruct_sequential_data, Scaler, extract_features_and_targets_reg\n",
    "from visual_evaluation import visualize\n",
    "from predictive_evaluation import predictive_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../data\")\n",
    "REAL_DATA_FOLDER = DATA_FOLDER / \"real\"\n",
    "SYNTHETIC_DATA_FOLDER = DATA_FOLDER / \"synthetic\"\n",
    "BENCHMARK = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load and Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways of loading data\n",
    "- Laden der Originaldaten: als pd dataframe \n",
    "- Laden der synthetischen, sequentiellen Daten: als np array (GAN, (V)AE)\n",
    "- Laden der synthetischen, sequentiellen Daten: als pd dataframe (brownian, algorithmit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible types: 'timegan_lstm', 'timegan_gru', 'jitter', 'timewarp', 'autoencoder'\n",
    "syn_data_type = 'jitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real time series\n",
    "data_real_df = pd.read_csv(REAL_DATA_FOLDER/'metro_interstate_traffic_volume_label_encoded_no_categorical.csv')\n",
    "data_real_numpy = dc(data_real_df).to_numpy()\n",
    "\n",
    "if syn_data_type == 'timegan_lstm':\n",
    "    # load sequential data (which should already be scaled)\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28499_12_5_lstm_unscaled.csv', shape=(28499, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'timegan_gru':\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28499_12_5_gru_unscaled.csv', shape=(28499, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'autoencoder':\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28478_12_5_autoencoder_unscaled.csv', shape=(28478, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'jitter':\n",
    "    jitter_factor = 0.1\n",
    "    data_syn_df = pd.read_csv(SYNTHETIC_DATA_FOLDER/f'mitv_jittered_{str(jitter_factor).replace(\".\", \"\")}.csv')\n",
    "    data_syn_numpy = dc(data_syn_df).to_numpy()\n",
    "\n",
    "elif syn_data_type == 'timewarp':\n",
    "    data_syn_df = pd.read_csv(SYNTHETIC_DATA_FOLDER/f'mitv_time_warped.csv')\n",
    "    data_syn_numpy = dc(data_syn_df).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>341736.000000</td>\n",
       "      <td>341736.000000</td>\n",
       "      <td>3.417360e+05</td>\n",
       "      <td>3.417360e+05</td>\n",
       "      <td>3.417360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3297.084510</td>\n",
       "      <td>284.493392</td>\n",
       "      <td>1.616547e-08</td>\n",
       "      <td>1.729086e-10</td>\n",
       "      <td>4.172296e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1787.420224</td>\n",
       "      <td>12.444296</td>\n",
       "      <td>3.040603e-06</td>\n",
       "      <td>3.160590e-08</td>\n",
       "      <td>3.824214e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>80.215370</td>\n",
       "      <td>249.496434</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.585317e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1488.666795</td>\n",
       "      <td>274.942441</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.442180e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3605.163780</td>\n",
       "      <td>287.485713</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.064934e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4902.021024</td>\n",
       "      <td>295.257689</td>\n",
       "      <td>9.039629e-36</td>\n",
       "      <td>2.611568e-37</td>\n",
       "      <td>8.628855e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6862.129388</td>\n",
       "      <td>304.725510</td>\n",
       "      <td>1.481370e-03</td>\n",
       "      <td>1.521341e-05</td>\n",
       "      <td>9.474959e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       traffic_volume           temp       rain_1h       snow_1h    clouds_all\n",
       "count   341736.000000  341736.000000  3.417360e+05  3.417360e+05  3.417360e+05\n",
       "mean      3297.084510     284.493392  1.616547e-08  1.729086e-10  4.172296e+01\n",
       "std       1787.420224      12.444296  3.040603e-06  3.160590e-08  3.824214e+01\n",
       "min         80.215370     249.496434  0.000000e+00  0.000000e+00  1.585317e-14\n",
       "25%       1488.666795     274.942441  0.000000e+00  0.000000e+00  2.442180e+00\n",
       "50%       3605.163780     287.485713  0.000000e+00  0.000000e+00  3.064934e+01\n",
       "75%       4902.021024     295.257689  9.039629e-36  2.611568e-37  8.628855e+01\n",
       "max       6862.129388     304.725510  1.481370e-03  1.521341e-05  9.474959e+01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_syn_numpy.reshape(-1, data_syn_numpy.shape[-1]), columns=data_real_df.columns)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28511.00000</td>\n",
       "      <td>28511.000000</td>\n",
       "      <td>28511.000000</td>\n",
       "      <td>28511.000000</td>\n",
       "      <td>28511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3313.74238</td>\n",
       "      <td>282.688768</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>42.122795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1971.53206</td>\n",
       "      <td>12.367361</td>\n",
       "      <td>0.678185</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>39.316195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>243.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1289.00000</td>\n",
       "      <td>273.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3507.00000</td>\n",
       "      <td>284.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4948.00000</td>\n",
       "      <td>292.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7280.00000</td>\n",
       "      <td>310.070000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       traffic_volume          temp       rain_1h       snow_1h    clouds_all\n",
       "count     28511.00000  28511.000000  28511.000000  28511.000000  28511.000000\n",
       "mean       3313.74238    282.688768      0.061611      0.000250     42.122795\n",
       "std        1971.53206     12.367361      0.678185      0.008298     39.316195\n",
       "min           0.00000    243.390000      0.000000      0.000000      0.000000\n",
       "25%        1289.00000    273.480000      0.000000      0.000000      1.000000\n",
       "50%        3507.00000    284.550000      0.000000      0.000000     40.000000\n",
       "75%        4948.00000    292.790000      0.000000      0.000000     90.000000\n",
       "max        7280.00000    310.070000     42.000000      0.510000    100.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_real_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train and Test Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"seq_len\": 12,\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 32,\n",
    "    \"hidden_size\": 4,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_evaluation_runs\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"device\": 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETERS:\n",
      "seq_len :  12\n",
      "lr :  0.0001\n",
      "batch_size :  32\n",
      "hidden_size :  4\n",
      "num_layers :  1\n",
      "num_evaluation_runs :  10\n",
      "num_epochs :  200\n",
      "device :  cpu\n",
      "Synthetic Data is sequential: True\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2841, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.3724797283113003\n",
      "Training Loss: 0.2587138967216015\n",
      "Training Loss: 0.15787248089909553\n",
      "Validation Loss: 0.08384611980801218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.08787313522771001\n",
      "Training Loss: 0.07890509041026235\n",
      "Training Loss: 0.07299171866849065\n",
      "Validation Loss: 0.06069226650876945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06708046006038786\n",
      "Training Loss: 0.06447082148864865\n",
      "Training Loss: 0.061691562850028275\n",
      "Validation Loss: 0.05300344673267911\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.057565800212323666\n",
      "Training Loss: 0.055322766341269015\n",
      "Training Loss: 0.0531382723711431\n",
      "Validation Loss: 0.04571915677424227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.0489798968937248\n",
      "Training Loss: 0.04631241998635233\n",
      "Training Loss: 0.04405591446906328\n",
      "Validation Loss: 0.03734053363709637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.03944067477248609\n",
      "Training Loss: 0.03652845189906657\n",
      "Training Loss: 0.03472332281060517\n",
      "Validation Loss: 0.02955017299548294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03081687823869288\n",
      "Training Loss: 0.028499896260909735\n",
      "Training Loss: 0.027671791398897767\n",
      "Validation Loss: 0.02401012775561448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.02490526542067528\n",
      "Training Loss: 0.023233385137282313\n",
      "Training Loss: 0.02303924727719277\n",
      "Validation Loss: 0.020191470851724066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.02106031115166843\n",
      "Training Loss: 0.019806012799963354\n",
      "Training Loss: 0.019889956447295843\n",
      "Validation Loss: 0.017430773758318988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.018413056696299463\n",
      "Training Loss: 0.017418234846554696\n",
      "Training Loss: 0.017602346369531004\n",
      "Validation Loss: 0.015344636096210961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.016485020960681142\n",
      "Training Loss: 0.01566642164485529\n",
      "Training Loss: 0.01588379722321406\n",
      "Validation Loss: 0.01373393415065294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.015048423495609314\n",
      "Training Loss: 0.014351526219397783\n",
      "Training Loss: 0.014579565937165171\n",
      "Validation Loss: 0.012464886897484238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013958857639227062\n",
      "Training Loss: 0.01333660053787753\n",
      "Training Loss: 0.013570173801854253\n",
      "Validation Loss: 0.01142862621234374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.013102677785791456\n",
      "Training Loss: 0.012519593932665884\n",
      "Training Loss: 0.012764474286232144\n",
      "Validation Loss: 0.010550880236969738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.012403994586784393\n",
      "Training Loss: 0.011839380785822869\n",
      "Training Loss: 0.012106085446430371\n",
      "Validation Loss: 0.009791672656187014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.011821666951291263\n",
      "Training Loss: 0.01126560620032251\n",
      "Training Loss: 0.011563623427646235\n",
      "Validation Loss: 0.009131572871165497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.01133445614716038\n",
      "Training Loss: 0.010782804045593366\n",
      "Training Loss: 0.011118044999893755\n",
      "Validation Loss: 0.00855986150295547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.010929231832269579\n",
      "Training Loss: 0.010380465596681461\n",
      "Training Loss: 0.010755065884441138\n",
      "Validation Loss: 0.008068441902548911\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.010595236613880843\n",
      "Training Loss: 0.010048878075322136\n",
      "Training Loss: 0.010461918872315436\n",
      "Validation Loss: 0.007649506159712759\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.010322055012220516\n",
      "Training Loss: 0.00977796184946783\n",
      "Training Loss: 0.01022637145128101\n",
      "Validation Loss: 0.007294875561793366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.010099262425210326\n",
      "Training Loss: 0.00955738251330331\n",
      "Training Loss: 0.010036747835110873\n",
      "Validation Loss: 0.006996086665188496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009916716705774889\n",
      "Training Loss: 0.009377046845620497\n",
      "Training Loss: 0.00988229414448142\n",
      "Validation Loss: 0.006744702820132455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009765021953498945\n",
      "Training Loss: 0.009227645087521523\n",
      "Training Loss: 0.0097535650676582\n",
      "Validation Loss: 0.006532623840684301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.009635930916992948\n",
      "Training Loss: 0.00910107434145175\n",
      "Training Loss: 0.009642732089851051\n",
      "Validation Loss: 0.006352400127275104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.009522615702589974\n",
      "Training Loss: 0.008990684013115242\n",
      "Training Loss: 0.009543678514892235\n",
      "Validation Loss: 0.006197440597553099\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.009419776297872886\n",
      "Training Loss: 0.008891334331128747\n",
      "Training Loss: 0.009451952759409323\n",
      "Validation Loss: 0.006062107835634706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.009323569989064709\n",
      "Training Loss: 0.008799314569914713\n",
      "Training Loss: 0.009364567381562666\n",
      "Validation Loss: 0.00594175415207747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.009231450645020232\n",
      "Training Loss: 0.008712157576810568\n",
      "Training Loss: 0.00927975435857661\n",
      "Validation Loss: 0.0058327037998046095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.009141921754926443\n",
      "Training Loss: 0.008628382845781744\n",
      "Training Loss: 0.009196624666219576\n",
      "Validation Loss: 0.005732114319532608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00905424849013798\n",
      "Training Loss: 0.00854722241172567\n",
      "Training Loss: 0.009114871517522261\n",
      "Validation Loss: 0.005637879905897831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008968189033912494\n",
      "Training Loss: 0.008468368111643941\n",
      "Training Loss: 0.009034503850853071\n",
      "Validation Loss: 0.005548508437559678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.008883766328217461\n",
      "Training Loss: 0.008391764933476225\n",
      "Training Loss: 0.008955661955988035\n",
      "Validation Loss: 0.005463002445804102\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.008801110577769578\n",
      "Training Loss: 0.008317465448053554\n",
      "Training Loss: 0.008878495671087876\n",
      "Validation Loss: 0.005380740726701497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.008720355000114068\n",
      "Training Loss: 0.0082455336174462\n",
      "Training Loss: 0.008803106428822503\n",
      "Validation Loss: 0.005301393568515778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.008641601729905232\n",
      "Training Loss: 0.0081760355446022\n",
      "Training Loss: 0.008729570684954524\n",
      "Validation Loss: 0.0052248620430761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.008564928537234664\n",
      "Training Loss: 0.008109009473118932\n",
      "Training Loss: 0.008657920059049503\n",
      "Validation Loss: 0.00515116970290252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.008490384644828737\n",
      "Training Loss: 0.008044484637212008\n",
      "Training Loss: 0.008588187422137707\n",
      "Validation Loss: 0.005080417355815514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.008418009056476876\n",
      "Training Loss: 0.00798248546780087\n",
      "Training Loss: 0.008520409852499142\n",
      "Validation Loss: 0.005012752120697013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.008347854171879589\n",
      "Training Loss: 0.007923046194482595\n",
      "Training Loss: 0.008454650755738839\n",
      "Validation Loss: 0.004948346068548938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.008279990738956258\n",
      "Training Loss: 0.007866214266978205\n",
      "Training Loss: 0.00839099766802974\n",
      "Validation Loss: 0.004887358628192477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.008214512488339097\n",
      "Training Loss: 0.007812046207254753\n",
      "Training Loss: 0.008329571367939935\n",
      "Validation Loss: 0.00482993161965036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.008151542651467026\n",
      "Training Loss: 0.007760621848283336\n",
      "Training Loss: 0.008270524119725451\n",
      "Validation Loss: 0.004776199867561711\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.008091225582174956\n",
      "Training Loss: 0.007712015575962141\n",
      "Training Loss: 0.0082140184531454\n",
      "Validation Loss: 0.004726255601638237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.008033707601716742\n",
      "Training Loss: 0.007666291318600998\n",
      "Training Loss: 0.008160212696529924\n",
      "Validation Loss: 0.00468015735393411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007979120895033703\n",
      "Training Loss: 0.0076234768284484744\n",
      "Training Loss: 0.008109238034812734\n",
      "Validation Loss: 0.0046378996346166795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007927553385961801\n",
      "Training Loss: 0.007583539710612968\n",
      "Training Loss: 0.008061159608187153\n",
      "Validation Loss: 0.004599403740388205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007879009203752502\n",
      "Training Loss: 0.007546344532165676\n",
      "Training Loss: 0.008015936703886837\n",
      "Validation Loss: 0.004564472447997064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007833358566276729\n",
      "Training Loss: 0.007511605864856392\n",
      "Training Loss: 0.007973372394917532\n",
      "Validation Loss: 0.004532765446680734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007790274769067764\n",
      "Training Loss: 0.007478811192559078\n",
      "Training Loss: 0.007933040573261678\n",
      "Validation Loss: 0.004503669556010556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007749120931839571\n",
      "Training Loss: 0.00744709704304114\n",
      "Training Loss: 0.007894195129629224\n",
      "Validation Loss: 0.0044760325363722075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007708832190837711\n",
      "Training Loss: 0.007415173776680603\n",
      "Training Loss: 0.00785576058900915\n",
      "Validation Loss: 0.004447725746686455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007667960320832208\n",
      "Training Loss: 0.007381605269620195\n",
      "Training Loss: 0.00781656641396694\n",
      "Validation Loss: 0.004415504799193043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007625198414316401\n",
      "Training Loss: 0.007345472811721265\n",
      "Training Loss: 0.007775684262160212\n",
      "Validation Loss: 0.004376424959170099\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0075801203947048635\n",
      "Training Loss: 0.007306394445477054\n",
      "Training Loss: 0.007732885734876618\n",
      "Validation Loss: 0.004330443100627052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007533892369829118\n",
      "Training Loss: 0.007264920604648069\n",
      "Training Loss: 0.007689843614352867\n",
      "Validation Loss: 0.004281860767089332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007489452322479337\n",
      "Training Loss: 0.007223487090086565\n",
      "Training Loss: 0.007649693633429706\n",
      "Validation Loss: 0.0042357817109088215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00744936553761363\n",
      "Training Loss: 0.007185052720597013\n",
      "Training Loss: 0.007614413510309532\n",
      "Validation Loss: 0.004194809941397038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00741441486752592\n",
      "Training Loss: 0.007151130046695471\n",
      "Training Loss: 0.007584076164057478\n",
      "Validation Loss: 0.00415956424653865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007384138039778918\n",
      "Training Loss: 0.007121718450216577\n",
      "Training Loss: 0.007557769386330619\n",
      "Validation Loss: 0.0041296174867455375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007357591214822605\n",
      "Training Loss: 0.007096088352845982\n",
      "Training Loss: 0.007534400190925225\n",
      "Validation Loss: 0.004104106721018305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007333810272393748\n",
      "Training Loss: 0.007073360848007724\n",
      "Training Loss: 0.007513040681369603\n",
      "Validation Loss: 0.00408211195961771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007312006901483983\n",
      "Training Loss: 0.007052763485116884\n",
      "Training Loss: 0.0074930156872142105\n",
      "Validation Loss: 0.00406282055165535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007291599288582802\n",
      "Training Loss: 0.007033702303888276\n",
      "Training Loss: 0.007473879497265443\n",
      "Validation Loss: 0.0040455726289263605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007272187551716342\n",
      "Training Loss: 0.007015750358114019\n",
      "Training Loss: 0.007455349181545898\n",
      "Validation Loss: 0.0040298663864561015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007253500352380798\n",
      "Training Loss: 0.006998603491811081\n",
      "Training Loss: 0.0074372552405111494\n",
      "Validation Loss: 0.004015329436482757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0072353612026199695\n",
      "Training Loss: 0.006982053748797626\n",
      "Training Loss: 0.0074194983660709115\n",
      "Validation Loss: 0.004001675080769601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007217652689432725\n",
      "Training Loss: 0.006965959229273721\n",
      "Training Loss: 0.007402020482113585\n",
      "Validation Loss: 0.003988702025452859\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0072002973244525495\n",
      "Training Loss: 0.00695021822466515\n",
      "Training Loss: 0.0073847850156016645\n",
      "Validation Loss: 0.003976259306020868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007183240097947419\n",
      "Training Loss: 0.006934760755393654\n",
      "Training Loss: 0.007367772865109146\n",
      "Validation Loss: 0.003964234611772922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007166446703486144\n",
      "Training Loss: 0.006919539090013131\n",
      "Training Loss: 0.007350970491534099\n",
      "Validation Loss: 0.003952552667777106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007149891224689782\n",
      "Training Loss: 0.006904519154923037\n",
      "Training Loss: 0.007334370221942663\n",
      "Validation Loss: 0.0039411481820423614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007133553915191442\n",
      "Training Loss: 0.006889674947597086\n",
      "Training Loss: 0.007317964378744364\n",
      "Validation Loss: 0.003929983999768502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007117422961164266\n",
      "Training Loss: 0.006874990771757438\n",
      "Training Loss: 0.007301749733742326\n",
      "Validation Loss: 0.003919028902028719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00710148906102404\n",
      "Training Loss: 0.006860455656424165\n",
      "Training Loss: 0.007285722328815609\n",
      "Validation Loss: 0.0039082581682256265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007085745638469234\n",
      "Training Loss: 0.006846061929827556\n",
      "Training Loss: 0.00726988032925874\n",
      "Validation Loss: 0.00389766086709131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00707018745248206\n",
      "Training Loss: 0.006831804387038573\n",
      "Training Loss: 0.007254221879411489\n",
      "Validation Loss: 0.003887224259650272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007054811487905681\n",
      "Training Loss: 0.006817681665997952\n",
      "Training Loss: 0.007238744780188426\n",
      "Validation Loss: 0.003876935766507568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007039612747030332\n",
      "Training Loss: 0.00680369118694216\n",
      "Training Loss: 0.007223448191070929\n",
      "Validation Loss: 0.003866798560961746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0070245945337228475\n",
      "Training Loss: 0.006789835414383561\n",
      "Training Loss: 0.0072083307255525145\n",
      "Validation Loss: 0.003856804678373541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.0070097502938006075\n",
      "Training Loss: 0.00677611256018281\n",
      "Training Loss: 0.007193390651373192\n",
      "Validation Loss: 0.0038469533339205585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006995081298518926\n",
      "Training Loss: 0.006762524303048849\n",
      "Training Loss: 0.007178626210661605\n",
      "Validation Loss: 0.003837242479216349\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006980583727126941\n",
      "Training Loss: 0.006749071612721309\n",
      "Training Loss: 0.007164035639725626\n",
      "Validation Loss: 0.003827670203218383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0069662581756711\n",
      "Training Loss: 0.006735757131827995\n",
      "Training Loss: 0.007149618739495054\n",
      "Validation Loss: 0.003818239821801276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006952104462543502\n",
      "Training Loss: 0.006722581612411887\n",
      "Training Loss: 0.007135371816111728\n",
      "Validation Loss: 0.00380894654885646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0069381169474218045\n",
      "Training Loss: 0.006709544326877221\n",
      "Training Loss: 0.0071212934772484\n",
      "Validation Loss: 0.003799792121457501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006924297191435471\n",
      "Training Loss: 0.00669664820889011\n",
      "Training Loss: 0.007107380740344524\n",
      "Validation Loss: 0.003790776699184953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0069106412981636825\n",
      "Training Loss: 0.0066838940279558305\n",
      "Training Loss: 0.007093632715987041\n",
      "Validation Loss: 0.003781899171515127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00689714930136688\n",
      "Training Loss: 0.006671280808513984\n",
      "Training Loss: 0.007080047006020322\n",
      "Validation Loss: 0.0037731565194978806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00688381741871126\n",
      "Training Loss: 0.006658810829976574\n",
      "Training Loss: 0.007066620821133256\n",
      "Validation Loss: 0.003764549687536161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00687064670259133\n",
      "Training Loss: 0.006646484648808837\n",
      "Training Loss: 0.0070533549960237\n",
      "Validation Loss: 0.0037560795912560956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006857636098284274\n",
      "Training Loss: 0.006634303373284638\n",
      "Training Loss: 0.0070402483909856525\n",
      "Validation Loss: 0.003747740171828799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0068447848851792515\n",
      "Training Loss: 0.006622269074432552\n",
      "Training Loss: 0.007027301879134029\n",
      "Validation Loss: 0.003739533379537922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006832092833938077\n",
      "Training Loss: 0.00661038079764694\n",
      "Training Loss: 0.007014512676978484\n",
      "Validation Loss: 0.0037314598278529692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006819562941091135\n",
      "Training Loss: 0.00659864219953306\n",
      "Training Loss: 0.0070018854876980185\n",
      "Validation Loss: 0.0037235153415188025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006807195942383259\n",
      "Training Loss: 0.00658705310896039\n",
      "Training Loss: 0.006989420567406341\n",
      "Validation Loss: 0.0037157003312591422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00679499443853274\n",
      "Training Loss: 0.0065756177017465235\n",
      "Training Loss: 0.006977120594820007\n",
      "Validation Loss: 0.003708013377853491\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006782960704294965\n",
      "Training Loss: 0.006564337075687945\n",
      "Training Loss: 0.006964988563559018\n",
      "Validation Loss: 0.0037004546984360457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.00677109956392087\n",
      "Training Loss: 0.006553213255247101\n",
      "Training Loss: 0.006953028864809312\n",
      "Validation Loss: 0.0036930214454095516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006759415154810995\n",
      "Training Loss: 0.006542249814374373\n",
      "Training Loss: 0.006941244440386071\n",
      "Validation Loss: 0.0036857135193631724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006747911379206926\n",
      "Training Loss: 0.0065314504422713075\n",
      "Training Loss: 0.0069296404795022686\n",
      "Validation Loss: 0.0036785249360261505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006736592521192506\n",
      "Training Loss: 0.006520816031843424\n",
      "Training Loss: 0.006918219771469012\n",
      "Validation Loss: 0.003671458875237221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006725463959155604\n",
      "Training Loss: 0.006510350479511544\n",
      "Training Loss: 0.0069069882552139465\n",
      "Validation Loss: 0.003664513758195334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006714528433512897\n",
      "Training Loss: 0.006500055176438764\n",
      "Training Loss: 0.006895948646124452\n",
      "Validation Loss: 0.0036576822611995123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0067037907685153185\n",
      "Training Loss: 0.006489933017874137\n",
      "Training Loss: 0.006885103777167387\n",
      "Validation Loss: 0.0036509678950219344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0066932542470749465\n",
      "Training Loss: 0.006479985961923376\n",
      "Training Loss: 0.0068744564498774705\n",
      "Validation Loss: 0.003644364009600844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.00668291948386468\n",
      "Training Loss: 0.006470213471911848\n",
      "Training Loss: 0.0068640089593827724\n",
      "Validation Loss: 0.0036378733858235934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00667279033572413\n",
      "Training Loss: 0.006460617799311876\n",
      "Training Loss: 0.006853763346443884\n",
      "Validation Loss: 0.003631488650283787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006662867836421355\n",
      "Training Loss: 0.006451200421433895\n",
      "Training Loss: 0.00684372030198574\n",
      "Validation Loss: 0.003625208166626732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006653152462095022\n",
      "Training Loss: 0.006441958389477804\n",
      "Training Loss: 0.006833877785247751\n",
      "Validation Loss: 0.003619026905448919\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006643641496775671\n",
      "Training Loss: 0.006432892469456419\n",
      "Training Loss: 0.006824238268891349\n",
      "Validation Loss: 0.0036129463801495313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006634336616843939\n",
      "Training Loss: 0.006424002384301275\n",
      "Training Loss: 0.006814798515988514\n",
      "Validation Loss: 0.0036069591139872253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006625234371749684\n",
      "Training Loss: 0.00641528403502889\n",
      "Training Loss: 0.006805557268671691\n",
      "Validation Loss: 0.0036010660422086884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006616333598503843\n",
      "Training Loss: 0.006406737682409585\n",
      "Training Loss: 0.0067965113575337455\n",
      "Validation Loss: 0.0035952612001637226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006607630263315514\n",
      "Training Loss: 0.006398357294965535\n",
      "Training Loss: 0.006787657356471755\n",
      "Validation Loss: 0.0035895411254775324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0065991196176037195\n",
      "Training Loss: 0.006390143883181736\n",
      "Training Loss: 0.006778992773033679\n",
      "Validation Loss: 0.003583903663812645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.00659079898847267\n",
      "Training Loss: 0.006382090944098309\n",
      "Training Loss: 0.006770512196817435\n",
      "Validation Loss: 0.003578345361950525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006582662203582004\n",
      "Training Loss: 0.00637419703300111\n",
      "Training Loss: 0.006762212018948048\n",
      "Validation Loss: 0.0035728623637971417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006574706280371174\n",
      "Training Loss: 0.006366456556133926\n",
      "Training Loss: 0.006754086951841601\n",
      "Validation Loss: 0.0035674491180420925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006566923313075676\n",
      "Training Loss: 0.006358865210786462\n",
      "Training Loss: 0.006746131078107283\n",
      "Validation Loss: 0.0035621083127020787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006559310108423233\n",
      "Training Loss: 0.006351419606944546\n",
      "Training Loss: 0.006738340176525526\n",
      "Validation Loss: 0.0035568330975856337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006551858676830307\n",
      "Training Loss: 0.006344114951789379\n",
      "Training Loss: 0.006730709025869146\n",
      "Validation Loss: 0.003551622609388125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006544564494397491\n",
      "Training Loss: 0.006336946819210425\n",
      "Training Loss: 0.006723229899071157\n",
      "Validation Loss: 0.0035464719246570647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006537420932436362\n",
      "Training Loss: 0.0063299102289602165\n",
      "Training Loss: 0.006715900144772604\n",
      "Validation Loss: 0.003541378288665849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006530422841897234\n",
      "Training Loss: 0.006323001217097044\n",
      "Training Loss: 0.006708711737301201\n",
      "Validation Loss: 0.003536341362632811\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006523563717491925\n",
      "Training Loss: 0.006316214167745784\n",
      "Training Loss: 0.006701659683021717\n",
      "Validation Loss: 0.0035313610654596366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006516837006201968\n",
      "Training Loss: 0.006309544635005295\n",
      "Training Loss: 0.006694737881189212\n",
      "Validation Loss: 0.0035264303756019706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006510237830225378\n",
      "Training Loss: 0.006302989341784269\n",
      "Training Loss: 0.0066879418556345625\n",
      "Validation Loss: 0.0035215483185720075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.00650375968660228\n",
      "Training Loss: 0.006296542753698304\n",
      "Training Loss: 0.006681265306542628\n",
      "Validation Loss: 0.0035167155274598116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006497396603226662\n",
      "Training Loss: 0.006290199669310823\n",
      "Training Loss: 0.006674701569718309\n",
      "Validation Loss: 0.003511928042836404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006491143166786059\n",
      "Training Loss: 0.006283956326078624\n",
      "Training Loss: 0.006668245661421679\n",
      "Validation Loss: 0.0035071856109425426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0064849943574517965\n",
      "Training Loss: 0.006277809551684186\n",
      "Training Loss: 0.0066618941206252206\n",
      "Validation Loss: 0.0035024887693815687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006478944846894592\n",
      "Training Loss: 0.006271753984037787\n",
      "Training Loss: 0.00665563996473793\n",
      "Validation Loss: 0.0034978324207320306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.00647298990515992\n",
      "Training Loss: 0.006265786554431543\n",
      "Training Loss: 0.006649479618063197\n",
      "Validation Loss: 0.003493212931266243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0064671225601341574\n",
      "Training Loss: 0.006259902489837259\n",
      "Training Loss: 0.006643407315714285\n",
      "Validation Loss: 0.0034886321649373916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006461340540554374\n",
      "Training Loss: 0.006254098088247701\n",
      "Training Loss: 0.006637419059406966\n",
      "Validation Loss: 0.003484087955635669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006455637945327908\n",
      "Training Loss: 0.006248370493995026\n",
      "Training Loss: 0.006631509546423331\n",
      "Validation Loss: 0.003479579719976428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006450010902481154\n",
      "Training Loss: 0.006242716012056917\n",
      "Training Loss: 0.006625675317482091\n",
      "Validation Loss: 0.0034751077208751706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0064444549090694634\n",
      "Training Loss: 0.00623713081353344\n",
      "Training Loss: 0.006619911959860474\n",
      "Validation Loss: 0.0034706690492568894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006438966421410441\n",
      "Training Loss: 0.006231611733091995\n",
      "Training Loss: 0.00661421476805117\n",
      "Validation Loss: 0.0034662596672103644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006433540309080854\n",
      "Training Loss: 0.006226155490148813\n",
      "Training Loss: 0.006608580576139503\n",
      "Validation Loss: 0.0034618853000149634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006428174620959908\n",
      "Training Loss: 0.006220759893767536\n",
      "Training Loss: 0.006603005737415515\n",
      "Validation Loss: 0.0034575372335260337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.00642286504036747\n",
      "Training Loss: 0.0062154213921166955\n",
      "Training Loss: 0.006597486214595847\n",
      "Validation Loss: 0.003453219726713102\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006417608020128683\n",
      "Training Loss: 0.006210136750014499\n",
      "Training Loss: 0.0065920185658615085\n",
      "Validation Loss: 0.0034489297514697643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006412400063127279\n",
      "Training Loss: 0.0062049043877050285\n",
      "Training Loss: 0.006586600298760459\n",
      "Validation Loss: 0.003444665698910111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006407239217078313\n",
      "Training Loss: 0.00619972130167298\n",
      "Training Loss: 0.00658122812747024\n",
      "Validation Loss: 0.003440426899319033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.0064021209499333055\n",
      "Training Loss: 0.006194585100747645\n",
      "Training Loss: 0.0065758978272788225\n",
      "Validation Loss: 0.003436214133594813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0063970437843818215\n",
      "Training Loss: 0.00618949317606166\n",
      "Training Loss: 0.006570608650799841\n",
      "Validation Loss: 0.00343202309567858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006392006115056574\n",
      "Training Loss: 0.006184443786041811\n",
      "Training Loss: 0.006565356035716832\n",
      "Validation Loss: 0.0034278592296216764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.00638700294890441\n",
      "Training Loss: 0.006179433837532997\n",
      "Training Loss: 0.00656013767584227\n",
      "Validation Loss: 0.0034237120776656974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006382032715482638\n",
      "Training Loss: 0.006174461182672531\n",
      "Training Loss: 0.006554950370918959\n",
      "Validation Loss: 0.0034195924598953865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.0063770932774059475\n",
      "Training Loss: 0.0061695241217967125\n",
      "Training Loss: 0.006549792168079875\n",
      "Validation Loss: 0.0034154882442645647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006372182277264073\n",
      "Training Loss: 0.0061646218132227655\n",
      "Training Loss: 0.006544661913649179\n",
      "Validation Loss: 0.0034114006629443906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006367297787801362\n",
      "Training Loss: 0.0061597501661162825\n",
      "Training Loss: 0.006539555789786391\n",
      "Validation Loss: 0.0034073320494734504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006362436873605475\n",
      "Training Loss: 0.006154908195603639\n",
      "Training Loss: 0.0065344723261659965\n",
      "Validation Loss: 0.0034032799617460603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006357599157490767\n",
      "Training Loss: 0.0061500950751360505\n",
      "Training Loss: 0.006529408833594061\n",
      "Validation Loss: 0.003399245178044428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006352781411842443\n",
      "Training Loss: 0.006145308058476076\n",
      "Training Loss: 0.006524363394128159\n",
      "Validation Loss: 0.003395224051560495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006347982694860548\n",
      "Training Loss: 0.006140544672962278\n",
      "Training Loss: 0.006519334480399266\n",
      "Validation Loss: 0.003391216070851667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006343201260315254\n",
      "Training Loss: 0.006135805762605742\n",
      "Training Loss: 0.0065143199026351795\n",
      "Validation Loss: 0.003387218010297903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006338434343924746\n",
      "Training Loss: 0.006131086823297664\n",
      "Training Loss: 0.0065093175449874256\n",
      "Validation Loss: 0.003383237207988591\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006333681388641707\n",
      "Training Loss: 0.006126387700205669\n",
      "Training Loss: 0.006504325193236582\n",
      "Validation Loss: 0.0033792667941117053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.00632893965463154\n",
      "Training Loss: 0.006121705643599853\n",
      "Training Loss: 0.006499340471345931\n",
      "Validation Loss: 0.003375304286012405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006324207488214597\n",
      "Training Loss: 0.0061170405056327586\n",
      "Training Loss: 0.006494362339144573\n",
      "Validation Loss: 0.003371349305667904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006319484401028603\n",
      "Training Loss: 0.006112389046465978\n",
      "Training Loss: 0.006489389066118747\n",
      "Validation Loss: 0.0033674044508403274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006314768142183311\n",
      "Training Loss: 0.006107751248637214\n",
      "Training Loss: 0.00648441853467375\n",
      "Validation Loss: 0.003363465087153436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.0063100571394898\n",
      "Training Loss: 0.006103124832734465\n",
      "Training Loss: 0.006479449268663302\n",
      "Validation Loss: 0.0033595312577724625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006305350388865918\n",
      "Training Loss: 0.006098508642753586\n",
      "Training Loss: 0.006474479630123824\n",
      "Validation Loss: 0.0033556019136514723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.0063006457849405706\n",
      "Training Loss: 0.006093899849802255\n",
      "Training Loss: 0.006469507511355914\n",
      "Validation Loss: 0.0033516757807621127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006295942902215757\n",
      "Training Loss: 0.006089298679726198\n",
      "Training Loss: 0.006464531907113269\n",
      "Validation Loss: 0.0033477516334734104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0062912402517395095\n",
      "Training Loss: 0.006084702985826879\n",
      "Training Loss: 0.0064595504169119525\n",
      "Validation Loss: 0.0033438323219986948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006286535441759043\n",
      "Training Loss: 0.006080110769253224\n",
      "Training Loss: 0.006454561310238205\n",
      "Validation Loss: 0.0033399099431764543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006281826409976929\n",
      "Training Loss: 0.00607552143628709\n",
      "Training Loss: 0.006449563854839652\n",
      "Validation Loss: 0.0033359910698942423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006277114314725623\n",
      "Training Loss: 0.006070932066068053\n",
      "Training Loss: 0.00644455537199974\n",
      "Validation Loss: 0.003332067936334466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0062723959016148\n",
      "Training Loss: 0.0060663421044591815\n",
      "Training Loss: 0.006439534185919911\n",
      "Validation Loss: 0.0033281388472807543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006267668886575848\n",
      "Training Loss: 0.006061749276705086\n",
      "Training Loss: 0.00643449840368703\n",
      "Validation Loss: 0.00332420849335495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006262933312682435\n",
      "Training Loss: 0.006057152861030772\n",
      "Training Loss: 0.006429447002592497\n",
      "Validation Loss: 0.00332026910481535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006258187411003746\n",
      "Training Loss: 0.006052550395252183\n",
      "Training Loss: 0.006424377402872779\n",
      "Validation Loss: 0.003316326149257967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006253429140197113\n",
      "Training Loss: 0.006047940674470738\n",
      "Training Loss: 0.006419288162142038\n",
      "Validation Loss: 0.003312373881782876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006248658017138951\n",
      "Training Loss: 0.006043321973411366\n",
      "Training Loss: 0.00641417785664089\n",
      "Validation Loss: 0.0033084153148000327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006243871169863269\n",
      "Training Loss: 0.006038692673901096\n",
      "Training Loss: 0.006409043989260681\n",
      "Validation Loss: 0.003304446007522723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006239068923168816\n",
      "Training Loss: 0.006034050919115543\n",
      "Training Loss: 0.006403885168256238\n",
      "Validation Loss: 0.0033004617022894573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006234247706597671\n",
      "Training Loss: 0.0060293943679425865\n",
      "Training Loss: 0.006398698987322859\n",
      "Validation Loss: 0.003296464884371151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.0062294057937106115\n",
      "Training Loss: 0.006024721724679693\n",
      "Training Loss: 0.006393483172287233\n",
      "Validation Loss: 0.0032924528958359627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006224543543066829\n",
      "Training Loss: 0.006020032326923683\n",
      "Training Loss: 0.0063882378773996605\n",
      "Validation Loss: 0.00328842608462182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006219658193876967\n",
      "Training Loss: 0.00601532225497067\n",
      "Training Loss: 0.006382957844762132\n",
      "Validation Loss: 0.0032843818058772537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006214747802587226\n",
      "Training Loss: 0.006010591189842671\n",
      "Training Loss: 0.006377643937012181\n",
      "Validation Loss: 0.003280316360472712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006209811046719551\n",
      "Training Loss: 0.0060058371000923216\n",
      "Training Loss: 0.006372293054591864\n",
      "Validation Loss: 0.003276233420068963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00620484706829302\n",
      "Training Loss: 0.006001056584063917\n",
      "Training Loss: 0.006366901759756729\n",
      "Validation Loss: 0.003272126420934716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006199852128047496\n",
      "Training Loss: 0.005996249065501616\n",
      "Training Loss: 0.006361469639814459\n",
      "Validation Loss: 0.0032679976822201457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.00619482557696756\n",
      "Training Loss: 0.0059914114279672505\n",
      "Training Loss: 0.006355993124307133\n",
      "Validation Loss: 0.0032638417978069923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006189765536109917\n",
      "Training Loss: 0.005986542694736272\n",
      "Training Loss: 0.006350471001933328\n",
      "Validation Loss: 0.0032596585584092844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006184669716749341\n",
      "Training Loss: 0.005981640476966277\n",
      "Training Loss: 0.006344899891410023\n",
      "Validation Loss: 0.003255448578804564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006179536406998523\n",
      "Training Loss: 0.005976701353210956\n",
      "Training Loss: 0.00633927826595027\n",
      "Validation Loss: 0.003251207471835647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006174364167964086\n",
      "Training Loss: 0.005971724410774187\n",
      "Training Loss: 0.006333603612729348\n",
      "Validation Loss: 0.0032469342447022037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006169149887282402\n",
      "Training Loss: 0.005966706919716671\n",
      "Training Loss: 0.006327872481197119\n",
      "Validation Loss: 0.0032426260341105336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006163891848409549\n",
      "Training Loss: 0.00596164619200863\n",
      "Training Loss: 0.006322082924889401\n",
      "Validation Loss: 0.003238285165750997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006158588629332371\n",
      "Training Loss: 0.005956541078630835\n",
      "Training Loss: 0.006316231900127605\n",
      "Validation Loss: 0.003233904988253803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006153237492544577\n",
      "Training Loss: 0.005951386766973883\n",
      "Training Loss: 0.006310317071620375\n",
      "Validation Loss: 0.0032294868528215067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006147836041636765\n",
      "Training Loss: 0.005946182368788868\n",
      "Training Loss: 0.006304335195454769\n",
      "Validation Loss: 0.0032250266718374713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006142382343532518\n",
      "Training Loss: 0.0059409243357367815\n",
      "Training Loss: 0.006298283113283105\n",
      "Validation Loss: 0.003220525804352476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.00613687326782383\n",
      "Training Loss: 0.005935610501328483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fanny\\Documents\\ArnesShit\\time_series_data_augmentation\\data_evaluation\\predictive_evaluation.py:255: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([{'Model': evaluation_method, 'Metric': 'MAE', 'Error': mae}])], ignore_index=True)\n",
      " 10%|█         | 1/10 [02:26<21:59, 146.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00629215789551381\n",
      "Validation Loss: 0.00321597727067936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.23386890914291145\n",
      "Training Loss: 0.18426533553749322\n",
      "Training Loss: 0.13528615292161703\n",
      "Validation Loss: 0.07312273376443412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0760305593162775\n",
      "Training Loss: 0.06582265708595514\n",
      "Training Loss: 0.06297634176909923\n",
      "Validation Loss: 0.05633356267314279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.059089006055146456\n",
      "Training Loss: 0.05724076692014932\n",
      "Training Loss: 0.05556911915540695\n",
      "Validation Loss: 0.04898688316428929\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05178409429267049\n",
      "Training Loss: 0.04966281745582819\n",
      "Training Loss: 0.04805785190314055\n",
      "Validation Loss: 0.04120179240623217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.043973775701597335\n",
      "Training Loss: 0.04154839913360774\n",
      "Training Loss: 0.0400125337485224\n",
      "Validation Loss: 0.03308713040576222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.035589991444721816\n",
      "Training Loss: 0.03314700456336141\n",
      "Training Loss: 0.031946512162685396\n",
      "Validation Loss: 0.02587457277466742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.027894835597835482\n",
      "Training Loss: 0.026368075544014574\n",
      "Training Loss: 0.025950603717938066\n",
      "Validation Loss: 0.021398560740472226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.02292700617108494\n",
      "Training Loss: 0.022286149314604698\n",
      "Training Loss: 0.02207390731200576\n",
      "Validation Loss: 0.01813383825290739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.019559849686920643\n",
      "Training Loss: 0.019204755802638827\n",
      "Training Loss: 0.0189562786789611\n",
      "Validation Loss: 0.015348271560970317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.016913475026376544\n",
      "Training Loss: 0.01676466562785208\n",
      "Training Loss: 0.016567025263793767\n",
      "Validation Loss: 0.013387490042977119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.015076259803026914\n",
      "Training Loss: 0.015103423304390162\n",
      "Training Loss: 0.014992030365392565\n",
      "Validation Loss: 0.012135915955256545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.013923002788797021\n",
      "Training Loss: 0.014032193762250244\n",
      "Training Loss: 0.013982701755594462\n",
      "Validation Loss: 0.0112793458301281\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013160548692103475\n",
      "Training Loss: 0.013293651149142533\n",
      "Training Loss: 0.013283540401607752\n",
      "Validation Loss: 0.01063633273784699\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.012592526271473616\n",
      "Training Loss: 0.012721410482190549\n",
      "Training Loss: 0.012734938326757402\n",
      "Validation Loss: 0.010101009845691785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.012109097819775342\n",
      "Training Loss: 0.012219304551836103\n",
      "Training Loss: 0.012247031214646995\n",
      "Validation Loss: 0.009608773791932323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.011652553635649383\n",
      "Training Loss: 0.01173733122413978\n",
      "Training Loss: 0.01177518702344969\n",
      "Validation Loss: 0.009127059794460119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.011198620127979666\n",
      "Training Loss: 0.011256762142293155\n",
      "Training Loss: 0.011304928348399699\n",
      "Validation Loss: 0.008646817522102527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.010743852260056884\n",
      "Training Loss: 0.010776890777051448\n",
      "Training Loss: 0.010837734220549464\n",
      "Validation Loss: 0.008169123332612636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.010293479319661855\n",
      "Training Loss: 0.010303393993526698\n",
      "Training Loss: 0.010380099050235004\n",
      "Validation Loss: 0.00769870184372399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009855658640153706\n",
      "Training Loss: 0.009844400238944218\n",
      "Training Loss: 0.00994059395743534\n",
      "Validation Loss: 0.007243557220973661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.009440517253242433\n",
      "Training Loss: 0.009409804296446965\n",
      "Training Loss: 0.009529098677448928\n",
      "Validation Loss: 0.006813827936087599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009058547789463774\n",
      "Training Loss: 0.009009456156054512\n",
      "Training Loss: 0.009154786528088153\n",
      "Validation Loss: 0.00641914638638329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008717964419629425\n",
      "Training Loss: 0.008650671184295789\n",
      "Training Loss: 0.008823730861768126\n",
      "Validation Loss: 0.006065993543630571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008422607982065528\n",
      "Training Loss: 0.00833661800599657\n",
      "Training Loss: 0.00853771082824096\n",
      "Validation Loss: 0.005756483138591218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008171734473435208\n",
      "Training Loss: 0.008066526895854622\n",
      "Training Loss: 0.008294840600574388\n",
      "Validation Loss: 0.005489000972109229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00796146688866429\n",
      "Training Loss: 0.007837131889536976\n",
      "Training Loss: 0.008091111143585294\n",
      "Validation Loss: 0.005259739687624439\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007786623805295676\n",
      "Training Loss: 0.007644145453814417\n",
      "Training Loss: 0.007921763051999733\n",
      "Validation Loss: 0.005064109434488784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00764199088444002\n",
      "Training Loss: 0.007483148734318093\n",
      "Training Loss: 0.007782061027828604\n",
      "Validation Loss: 0.004897583979757481\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0075228536943905055\n",
      "Training Loss: 0.007349914602236822\n",
      "Training Loss: 0.007667571713682264\n",
      "Validation Loss: 0.004756064687886935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007425092516932637\n",
      "Training Loss: 0.007240462749032304\n",
      "Training Loss: 0.007574225234566257\n",
      "Validation Loss: 0.004635957619070672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0073450989555567505\n",
      "Training Loss: 0.007151058755116537\n",
      "Training Loss: 0.007498326569329947\n",
      "Validation Loss: 0.004534149325316709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0072797034098766745\n",
      "Training Loss: 0.00707824552548118\n",
      "Training Loss: 0.007436559537891299\n",
      "Validation Loss: 0.0044479367396469864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0072261188505217434\n",
      "Training Loss: 0.007018888622988015\n",
      "Training Loss: 0.007386021458078176\n",
      "Validation Loss: 0.004374947856714049\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007181926605990156\n",
      "Training Loss: 0.00697023204760626\n",
      "Training Loss: 0.00734423704794608\n",
      "Validation Loss: 0.004313109712047356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007145080210175365\n",
      "Training Loss: 0.006929929316975177\n",
      "Training Loss: 0.007309160224394873\n",
      "Validation Loss: 0.004260607409092148\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007113896226510406\n",
      "Training Loss: 0.006896056735422462\n",
      "Training Loss: 0.007279158746823669\n",
      "Validation Loss: 0.004215885374925277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007087035008007661\n",
      "Training Loss: 0.006867086231941357\n",
      "Training Loss: 0.007252968861721456\n",
      "Validation Loss: 0.004177603436361873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007063458787743002\n",
      "Training Loss: 0.006841834378428757\n",
      "Training Loss: 0.007229634647956118\n",
      "Validation Loss: 0.004144640356888262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00704238319885917\n",
      "Training Loss: 0.006819407981820405\n",
      "Training Loss: 0.0072084504796657714\n",
      "Validation Loss: 0.0041160538944342495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007023225807351992\n",
      "Training Loss: 0.0067991403955966236\n",
      "Training Loss: 0.00718890379415825\n",
      "Validation Loss: 0.004091067731464177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0070055606868118046\n",
      "Training Loss: 0.006780544128268957\n",
      "Training Loss: 0.007170627862215042\n",
      "Validation Loss: 0.00406904329200474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00698908087797463\n",
      "Training Loss: 0.006763261888409033\n",
      "Training Loss: 0.007153358459472656\n",
      "Validation Loss: 0.004049456973947333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006973560932092369\n",
      "Training Loss: 0.006747031972045079\n",
      "Training Loss: 0.007136907974490896\n",
      "Validation Loss: 0.004031883769804675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006958838405553252\n",
      "Training Loss: 0.006731662638485431\n",
      "Training Loss: 0.0071211426437366755\n",
      "Validation Loss: 0.004015971909099248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006944793380680494\n",
      "Training Loss: 0.00671701462357305\n",
      "Training Loss: 0.007105964402435347\n",
      "Validation Loss: 0.004001449759568224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006931337555288337\n",
      "Training Loss: 0.0067029826948419215\n",
      "Training Loss: 0.0070913026353809985\n",
      "Validation Loss: 0.003988088501010383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006918402718147263\n",
      "Training Loss: 0.006689486838877201\n",
      "Training Loss: 0.007077102743787691\n",
      "Validation Loss: 0.003975699766894824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006905936892144382\n",
      "Training Loss: 0.006676467707147821\n",
      "Training Loss: 0.00706332414643839\n",
      "Validation Loss: 0.003964132569165209\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006893898067064583\n",
      "Training Loss: 0.006663877285318449\n",
      "Training Loss: 0.007049935322720557\n",
      "Validation Loss: 0.003953262219163641\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006882253580843098\n",
      "Training Loss: 0.006651678183116019\n",
      "Training Loss: 0.007036911727627739\n",
      "Validation Loss: 0.003942994186340758\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006870975035126321\n",
      "Training Loss: 0.006639840235002339\n",
      "Training Loss: 0.007024230955867097\n",
      "Validation Loss: 0.00393324193094721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006860040103201754\n",
      "Training Loss: 0.006628338656155392\n",
      "Training Loss: 0.007011875075986609\n",
      "Validation Loss: 0.0039239412257343195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006849426925182343\n",
      "Training Loss: 0.006617152773542329\n",
      "Training Loss: 0.006999828895786777\n",
      "Validation Loss: 0.003915039075569909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006839119289070368\n",
      "Training Loss: 0.006606265074806288\n",
      "Training Loss: 0.006988079549046233\n",
      "Validation Loss: 0.003906483958171827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006829100143513642\n",
      "Training Loss: 0.00659566012211144\n",
      "Training Loss: 0.006976614829618484\n",
      "Validation Loss: 0.0038982381929088842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006819356237538159\n",
      "Training Loss: 0.006585324233165011\n",
      "Training Loss: 0.0069654231157619505\n",
      "Validation Loss: 0.0038902757132132904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006809874016325921\n",
      "Training Loss: 0.006575244863051921\n",
      "Training Loss: 0.006954493805533275\n",
      "Validation Loss: 0.0038825689469662943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006800641713780351\n",
      "Training Loss: 0.006565412459895015\n",
      "Training Loss: 0.006943817690480501\n",
      "Validation Loss: 0.0038750906752192237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006791647914797068\n",
      "Training Loss: 0.006555814724415541\n",
      "Training Loss: 0.006933385625015945\n",
      "Validation Loss: 0.0038678274565805376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006782882135012187\n",
      "Training Loss: 0.006546443623956293\n",
      "Training Loss: 0.006923189626540989\n",
      "Validation Loss: 0.003860760779706029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006774334908695892\n",
      "Training Loss: 0.006537290341220796\n",
      "Training Loss: 0.006913219495909288\n",
      "Validation Loss: 0.003853871947510189\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0067659964202903215\n",
      "Training Loss: 0.006528346294071525\n",
      "Training Loss: 0.006903469490353018\n",
      "Validation Loss: 0.0038471514427134497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006757857988122851\n",
      "Training Loss: 0.0065196030994411555\n",
      "Training Loss: 0.006893929865909741\n",
      "Validation Loss: 0.0038405919586193193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006749910496291704\n",
      "Training Loss: 0.006511053831782192\n",
      "Training Loss: 0.006884594473522156\n",
      "Validation Loss: 0.0038341766359347306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006742147502372973\n",
      "Training Loss: 0.006502690539346077\n",
      "Training Loss: 0.006875455192057416\n",
      "Validation Loss: 0.0038279011829892235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0067345592589117586\n",
      "Training Loss: 0.006494506024755538\n",
      "Training Loss: 0.006866505792131648\n",
      "Validation Loss: 0.0038217558876056682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006727139150025323\n",
      "Training Loss: 0.00648649325594306\n",
      "Training Loss: 0.006857738691614941\n",
      "Validation Loss: 0.0038157313868529006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006719881022581831\n",
      "Training Loss: 0.006478646470350213\n",
      "Training Loss: 0.006849148863693699\n",
      "Validation Loss: 0.003809824041771085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006712775838095695\n",
      "Training Loss: 0.006470958237187006\n",
      "Training Loss: 0.006840727909002453\n",
      "Validation Loss: 0.003804020693504743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006705819111084565\n",
      "Training Loss: 0.006463423119857908\n",
      "Training Loss: 0.006832470177905634\n",
      "Validation Loss: 0.0037983207403567065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006699003310059197\n",
      "Training Loss: 0.006456034139264375\n",
      "Training Loss: 0.006824369188398123\n",
      "Validation Loss: 0.003792720404715183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0066923219547607\n",
      "Training Loss: 0.006448786834371276\n",
      "Training Loss: 0.006816419644746929\n",
      "Validation Loss: 0.0037872069462966383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006685770198819227\n",
      "Training Loss: 0.006441674110828899\n",
      "Training Loss: 0.006808615558547899\n",
      "Validation Loss: 0.0037817811289948696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006679341246490366\n",
      "Training Loss: 0.0064346915110945705\n",
      "Training Loss: 0.006800951682962477\n",
      "Validation Loss: 0.0037764366663824976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006673031129175797\n",
      "Training Loss: 0.006427833004854619\n",
      "Training Loss: 0.006793422370683402\n",
      "Validation Loss: 0.0037711667658217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006666833045892417\n",
      "Training Loss: 0.006421093605458736\n",
      "Training Loss: 0.006786021383013576\n",
      "Validation Loss: 0.00376596907938548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006660741758532822\n",
      "Training Loss: 0.006414468397852033\n",
      "Training Loss: 0.006778744927141815\n",
      "Validation Loss: 0.003760839940645219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006654754058690742\n",
      "Training Loss: 0.006407953031593933\n",
      "Training Loss: 0.006771587925031781\n",
      "Validation Loss: 0.003755773998420225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006648864188464359\n",
      "Training Loss: 0.006401542690582573\n",
      "Training Loss: 0.006764544805046171\n",
      "Validation Loss: 0.003750765596757109\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.0066430684021906924\n",
      "Training Loss: 0.006395232448121533\n",
      "Training Loss: 0.006757611990906298\n",
      "Validation Loss: 0.00374581337268098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006637361797038466\n",
      "Training Loss: 0.0063890186976641415\n",
      "Training Loss: 0.006750784592004493\n",
      "Validation Loss: 0.0037409143399426276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006631740077864379\n",
      "Training Loss: 0.00638289675640408\n",
      "Training Loss: 0.006744058431359008\n",
      "Validation Loss: 0.0037360655306053633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006626200485625304\n",
      "Training Loss: 0.0063768631650600585\n",
      "Training Loss: 0.006737429859349504\n",
      "Validation Loss: 0.0037312617739976455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006620738741476089\n",
      "Training Loss: 0.00637091436132323\n",
      "Training Loss: 0.006730893622152507\n",
      "Validation Loss: 0.003726502548212583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006615350557258353\n",
      "Training Loss: 0.006365046394639648\n",
      "Training Loss: 0.006724447089945898\n",
      "Validation Loss: 0.003721787418981784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.0066100334067596125\n",
      "Training Loss: 0.006359256262076087\n",
      "Training Loss: 0.006718086275504902\n",
      "Validation Loss: 0.003717109008974741\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006604783595539629\n",
      "Training Loss: 0.006353539794217795\n",
      "Training Loss: 0.0067118069529533385\n",
      "Validation Loss: 0.0037124649427956744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006599598170723766\n",
      "Training Loss: 0.006347893625497818\n",
      "Training Loss: 0.006705606665927916\n",
      "Validation Loss: 0.00370785525183748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006594473705044948\n",
      "Training Loss: 0.006342315235524438\n",
      "Training Loss: 0.006699481193209067\n",
      "Validation Loss: 0.00370327895245609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006589407433057204\n",
      "Training Loss: 0.006336802169680595\n",
      "Training Loss: 0.006693427893333137\n",
      "Validation Loss: 0.003698732178093175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006584397759870626\n",
      "Training Loss: 0.006331351143307984\n",
      "Training Loss: 0.006687443625414744\n",
      "Validation Loss: 0.003694213160282273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006579439486959018\n",
      "Training Loss: 0.0063259586389176545\n",
      "Training Loss: 0.006681524885352701\n",
      "Validation Loss: 0.003689722927140721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0065745326358592135\n",
      "Training Loss: 0.006320622733328491\n",
      "Training Loss: 0.006675668727839365\n",
      "Validation Loss: 0.003685254831222838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006569673684425652\n",
      "Training Loss: 0.00631534141371958\n",
      "Training Loss: 0.006669873736100272\n",
      "Validation Loss: 0.0036808115513890646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00656486042891629\n",
      "Training Loss: 0.006310111273778602\n",
      "Training Loss: 0.006664134622551501\n",
      "Validation Loss: 0.0036763875284807736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006560088716214523\n",
      "Training Loss: 0.006304929829784669\n",
      "Training Loss: 0.006658450085669756\n",
      "Validation Loss: 0.0036719857618275485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006555358587647788\n",
      "Training Loss: 0.0062997946416726335\n",
      "Training Loss: 0.006652817794820294\n",
      "Validation Loss: 0.0036676014561645605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006550666717812419\n",
      "Training Loss: 0.006294703077874147\n",
      "Training Loss: 0.006647233595140278\n",
      "Validation Loss: 0.0036632372275664567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006546011309255846\n",
      "Training Loss: 0.00628965373034589\n",
      "Training Loss: 0.00664169572526589\n",
      "Validation Loss: 0.0036588901486457066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006541390205384232\n",
      "Training Loss: 0.006284643498365767\n",
      "Training Loss: 0.006636201712535694\n",
      "Validation Loss: 0.0036545560114462387\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.0065368005837081\n",
      "Training Loss: 0.006279669968644157\n",
      "Training Loss: 0.006630748428869992\n",
      "Validation Loss: 0.003650234498114984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006532241422100924\n",
      "Training Loss: 0.006274730751174502\n",
      "Training Loss: 0.006625332933617755\n",
      "Validation Loss: 0.003645925337888217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006527709403308109\n",
      "Training Loss: 0.006269823653856293\n",
      "Training Loss: 0.006619953471235931\n",
      "Validation Loss: 0.003641628253462023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0065232025436125695\n",
      "Training Loss: 0.0062649465474532914\n",
      "Training Loss: 0.006614606160437689\n",
      "Validation Loss: 0.0036373428001037138\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006518719324376434\n",
      "Training Loss: 0.0062600965291494505\n",
      "Training Loss: 0.006609288367908448\n",
      "Validation Loss: 0.003633066249247431\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006514255331712775\n",
      "Training Loss: 0.006255271070403978\n",
      "Training Loss: 0.006603997258935124\n",
      "Validation Loss: 0.0036287954746839707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0065098109049722555\n",
      "Training Loss: 0.006250467684585601\n",
      "Training Loss: 0.006598730691475794\n",
      "Validation Loss: 0.0036245296353453332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006505382118630223\n",
      "Training Loss: 0.006245683610322885\n",
      "Training Loss: 0.00659348379354924\n",
      "Validation Loss: 0.003620271861364835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006500966233434155\n",
      "Training Loss: 0.00624091561359819\n",
      "Training Loss: 0.0065882544126361605\n",
      "Validation Loss: 0.0036160139735850892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006496561976382509\n",
      "Training Loss: 0.0062361618649447335\n",
      "Training Loss: 0.006583040030673146\n",
      "Validation Loss: 0.003611757677686767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006492165265954099\n",
      "Training Loss: 0.0062314182100817565\n",
      "Training Loss: 0.006577836134238168\n",
      "Validation Loss: 0.003607499914170567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006487774286651984\n",
      "Training Loss: 0.006226681307307445\n",
      "Training Loss: 0.006572638917714357\n",
      "Validation Loss: 0.0036032367785450783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006483384290477261\n",
      "Training Loss: 0.006221948420861736\n",
      "Training Loss: 0.006567445418331772\n",
      "Validation Loss: 0.003598971485966042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.0064789938158355655\n",
      "Training Loss: 0.006217215207288973\n",
      "Training Loss: 0.006562250463757664\n",
      "Validation Loss: 0.003594696532223332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006474600541405379\n",
      "Training Loss: 0.0062124788301298394\n",
      "Training Loss: 0.006557051062118262\n",
      "Validation Loss: 0.003590413735488827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006470198009046726\n",
      "Training Loss: 0.006207735110656358\n",
      "Training Loss: 0.006551842162152753\n",
      "Validation Loss: 0.0035861178282962252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.00646578345564194\n",
      "Training Loss: 0.006202979757799767\n",
      "Training Loss: 0.0065466183354146775\n",
      "Validation Loss: 0.0035818083332119026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006461354307248257\n",
      "Training Loss: 0.006198207557899877\n",
      "Training Loss: 0.00654137602658011\n",
      "Validation Loss: 0.003577481374521269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006456905156373978\n",
      "Training Loss: 0.006193415513262152\n",
      "Training Loss: 0.006536109317094088\n",
      "Validation Loss: 0.0035731297148538107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006452432794612832\n",
      "Training Loss: 0.0061885963845998045\n",
      "Training Loss: 0.006530812351265922\n",
      "Validation Loss: 0.0035687538381833374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006447929971618578\n",
      "Training Loss: 0.006183745455928147\n",
      "Training Loss: 0.006525479108095169\n",
      "Validation Loss: 0.003564347029046229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0064433941303286705\n",
      "Training Loss: 0.006178857783088461\n",
      "Training Loss: 0.006520104147493839\n",
      "Validation Loss: 0.0035599053371697664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006438818140304647\n",
      "Training Loss: 0.0061739265656797215\n",
      "Training Loss: 0.006514679999090731\n",
      "Validation Loss: 0.0035554267364041356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006434197889175266\n",
      "Training Loss: 0.006168945565004833\n",
      "Training Loss: 0.006509200915461406\n",
      "Validation Loss: 0.003550903934441256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006429526361171156\n",
      "Training Loss: 0.0061639085045317185\n",
      "Training Loss: 0.006503657993162051\n",
      "Validation Loss: 0.003546334829265147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006424798258231021\n",
      "Training Loss: 0.006158807938336394\n",
      "Training Loss: 0.0064980441448278725\n",
      "Validation Loss: 0.0035417082750897728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006420006559928879\n",
      "Training Loss: 0.006153637127717957\n",
      "Training Loss: 0.006492353349458426\n",
      "Validation Loss: 0.0035370225780067986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006415145585197024\n",
      "Training Loss: 0.006148388048168272\n",
      "Training Loss: 0.006486575126182288\n",
      "Validation Loss: 0.0035322683986297315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006410208356683143\n",
      "Training Loss: 0.006143055111751891\n",
      "Training Loss: 0.00648070242954418\n",
      "Validation Loss: 0.003527443611397921\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006405187374330126\n",
      "Training Loss: 0.006137626795680262\n",
      "Training Loss: 0.006474727410823107\n",
      "Validation Loss: 0.0035225367997616026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006400076079298742\n",
      "Training Loss: 0.006132097003865055\n",
      "Training Loss: 0.006468640709063039\n",
      "Validation Loss: 0.003517543687746766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0063948678586166355\n",
      "Training Loss: 0.006126458359649405\n",
      "Training Loss: 0.0064624331053346395\n",
      "Validation Loss: 0.0035124564951474076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006389556672656909\n",
      "Training Loss: 0.006120701935142279\n",
      "Training Loss: 0.006456098458729684\n",
      "Validation Loss: 0.0035072693711125785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0063841356604825705\n",
      "Training Loss: 0.00611482112610247\n",
      "Training Loss: 0.006449626960093155\n",
      "Validation Loss: 0.0035019743549271247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006378598511801102\n",
      "Training Loss: 0.006108808653079905\n",
      "Training Loss: 0.006443012517411262\n",
      "Validation Loss: 0.003496564066644465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006372940827277489\n",
      "Training Loss: 0.0061026578891323876\n",
      "Training Loss: 0.006436248596291989\n",
      "Validation Loss: 0.0034910324552839393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006367158484645188\n",
      "Training Loss: 0.006096363315591589\n",
      "Training Loss: 0.006429329233942554\n",
      "Validation Loss: 0.0034853746235538065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0063612466270569715\n",
      "Training Loss: 0.006089920232188888\n",
      "Training Loss: 0.006422249383758754\n",
      "Validation Loss: 0.003479586690507327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006355204809806309\n",
      "Training Loss: 0.006083326099906116\n",
      "Training Loss: 0.006415006256429478\n",
      "Validation Loss: 0.0034736642938400252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006349030639976263\n",
      "Training Loss: 0.006076579001965001\n",
      "Training Loss: 0.0064075988228432836\n",
      "Validation Loss: 0.0034676070372165924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006342726183938794\n",
      "Training Loss: 0.006069679495994933\n",
      "Training Loss: 0.006400025734910742\n",
      "Validation Loss: 0.0034614133719208366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006336293551139533\n",
      "Training Loss: 0.0060626293742097916\n",
      "Training Loss: 0.00639229140826501\n",
      "Validation Loss: 0.0034550877348153613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006329736778279766\n",
      "Training Loss: 0.006055432633147575\n",
      "Training Loss: 0.006384398424997926\n",
      "Validation Loss: 0.003448630569324818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006323061879375019\n",
      "Training Loss: 0.006048095883452334\n",
      "Training Loss: 0.006376354800304398\n",
      "Validation Loss: 0.003442051378340366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0063162781624123455\n",
      "Training Loss: 0.006040628177579492\n",
      "Training Loss: 0.006368167843902484\n",
      "Validation Loss: 0.0034353546575862873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006309393539559096\n",
      "Training Loss: 0.0060330408264417205\n",
      "Training Loss: 0.006359849512809887\n",
      "Validation Loss: 0.0034285539269363614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006302420372958295\n",
      "Training Loss: 0.006025346701499075\n",
      "Training Loss: 0.006351411301875487\n",
      "Validation Loss: 0.0034216632647963052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006295370729640126\n",
      "Training Loss: 0.0060175605269614605\n",
      "Training Loss: 0.006342868315987289\n",
      "Validation Loss: 0.0034146964147142816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006288257832638919\n",
      "Training Loss: 0.0060096990008605645\n",
      "Training Loss: 0.006334235889371484\n",
      "Validation Loss: 0.0034076695348753522\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006281096320599318\n",
      "Training Loss: 0.00600178042484913\n",
      "Training Loss: 0.006325531579786912\n",
      "Validation Loss: 0.0034005995486664138\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006273899766383693\n",
      "Training Loss: 0.005993822099408135\n",
      "Training Loss: 0.006316771758720279\n",
      "Validation Loss: 0.0033935066286390754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0062666818755678835\n",
      "Training Loss: 0.005985843882663175\n",
      "Training Loss: 0.006307973861112259\n",
      "Validation Loss: 0.003386408366587306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.00625945588981267\n",
      "Training Loss: 0.005977863700827583\n",
      "Training Loss: 0.0062991539738141\n",
      "Validation Loss: 0.0033793258506888417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006252233803388662\n",
      "Training Loss: 0.005969899992924184\n",
      "Training Loss: 0.006290328920586035\n",
      "Validation Loss: 0.0033722745027037317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006245027059921995\n",
      "Training Loss: 0.00596196923055686\n",
      "Training Loss: 0.006281513952417299\n",
      "Validation Loss: 0.0033652749765413197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006237844690331258\n",
      "Training Loss: 0.005954086139681749\n",
      "Training Loss: 0.006272722104913555\n",
      "Validation Loss: 0.0033583377992859884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006230694912374019\n",
      "Training Loss: 0.005946264934027568\n",
      "Training Loss: 0.006263966669794172\n",
      "Validation Loss: 0.0033514743116213365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006223582981619984\n",
      "Training Loss: 0.00593851747456938\n",
      "Training Loss: 0.0062552572635468096\n",
      "Validation Loss: 0.0033447053021845525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006216514258994721\n",
      "Training Loss: 0.005930853788158857\n",
      "Training Loss: 0.006246603198233061\n",
      "Validation Loss: 0.003338029101920011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006209491937188432\n",
      "Training Loss: 0.0059232813096605245\n",
      "Training Loss: 0.0062380119488807395\n",
      "Validation Loss: 0.0033314588840716005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006202517879428342\n",
      "Training Loss: 0.005915805739350617\n",
      "Training Loss: 0.006229488320532255\n",
      "Validation Loss: 0.003324995267340976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006195592965232208\n",
      "Training Loss: 0.005908431934076361\n",
      "Training Loss: 0.0062210385187063365\n",
      "Validation Loss: 0.0033186399063953524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006188717558397911\n",
      "Training Loss: 0.0059011617681244384\n",
      "Training Loss: 0.00621266319474671\n",
      "Validation Loss: 0.0033123971203739724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006181891692685895\n",
      "Training Loss: 0.005893998093088157\n",
      "Training Loss: 0.006204367193276994\n",
      "Validation Loss: 0.003306262380851621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.0061751137720420955\n",
      "Training Loss: 0.005886939007323236\n",
      "Training Loss: 0.006196150236646645\n",
      "Validation Loss: 0.003300237878790816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006168383485055528\n",
      "Training Loss: 0.005879985359497368\n",
      "Training Loss: 0.0061880136717809365\n",
      "Validation Loss: 0.003294314264340766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006161699066287838\n",
      "Training Loss: 0.005873134769499302\n",
      "Training Loss: 0.006179957778076641\n",
      "Validation Loss: 0.0032884967709588034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006155059217126109\n",
      "Training Loss: 0.005866385172121227\n",
      "Training Loss: 0.006171980813378468\n",
      "Validation Loss: 0.003282772774776716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0061484632978681475\n",
      "Training Loss: 0.0058597331721102815\n",
      "Training Loss: 0.006164082546602004\n",
      "Validation Loss: 0.0032771383059012255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006141910324804485\n",
      "Training Loss: 0.005853175179800019\n",
      "Training Loss: 0.006156263275188394\n",
      "Validation Loss: 0.0032715865664623596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006135398808983155\n",
      "Training Loss: 0.0058467104285955425\n",
      "Training Loss: 0.006148520507849753\n",
      "Validation Loss: 0.003266119229439855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.0061289286991814155\n",
      "Training Loss: 0.0058403344126418235\n",
      "Training Loss: 0.006140854380792007\n",
      "Validation Loss: 0.003260725984883526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006122500808560289\n",
      "Training Loss: 0.0058340439951280135\n",
      "Training Loss: 0.006133264006348327\n",
      "Validation Loss: 0.003255402936150184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006116113811731339\n",
      "Training Loss: 0.0058278357493691145\n",
      "Training Loss: 0.006125747631886043\n",
      "Validation Loss: 0.003250145921065064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006109767469461076\n",
      "Training Loss: 0.005821706485585309\n",
      "Training Loss: 0.006118304599658586\n",
      "Validation Loss: 0.0032449517977225146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006103462667088024\n",
      "Training Loss: 0.005815654143807478\n",
      "Training Loss: 0.006110933725722134\n",
      "Validation Loss: 0.003239813760404339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006097200090880506\n",
      "Training Loss: 0.005809675476630218\n",
      "Training Loss: 0.006103635232429952\n",
      "Validation Loss: 0.00323472752136419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0060909809306031095\n",
      "Training Loss: 0.005803767402539961\n",
      "Training Loss: 0.006096407695440576\n",
      "Validation Loss: 0.0032296926528738623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006084804005804472\n",
      "Training Loss: 0.005797929117106832\n",
      "Training Loss: 0.0060892505606170745\n",
      "Validation Loss: 0.0032247052308213846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006078671867144294\n",
      "Training Loss: 0.005792157827527262\n",
      "Training Loss: 0.006082163848332129\n",
      "Validation Loss: 0.0032197607084690186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006072585135116242\n",
      "Training Loss: 0.005786450132727623\n",
      "Training Loss: 0.006075147121446207\n",
      "Validation Loss: 0.003214855618209819\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006066543668275699\n",
      "Training Loss: 0.005780805149115622\n",
      "Training Loss: 0.006068198956781999\n",
      "Validation Loss: 0.00320999089136636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006060549421235919\n",
      "Training Loss: 0.005775221205549314\n",
      "Training Loss: 0.0060613195889163765\n",
      "Validation Loss: 0.0032051606169179753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006054602125659585\n",
      "Training Loss: 0.0057696971966652195\n",
      "Training Loss: 0.006054509161040187\n",
      "Validation Loss: 0.0032003657144149033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006048703911947086\n",
      "Training Loss: 0.005764229982742108\n",
      "Training Loss: 0.006047765645198524\n",
      "Validation Loss: 0.003195604038675933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006042854785919189\n",
      "Training Loss: 0.005758819834445603\n",
      "Training Loss: 0.006041090450598858\n",
      "Validation Loss: 0.0031908725942955928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006037055758642964\n",
      "Training Loss: 0.00575346433906816\n",
      "Training Loss: 0.0060344817576697095\n",
      "Validation Loss: 0.0031861712295415527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006031306902877986\n",
      "Training Loss: 0.005748162977979519\n",
      "Training Loss: 0.006027940104249865\n",
      "Validation Loss: 0.0031814954879306506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006025610117358155\n",
      "Training Loss: 0.005742914051515982\n",
      "Training Loss: 0.0060214650834677745\n",
      "Validation Loss: 0.0031768469861970187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006019964754814282\n",
      "Training Loss: 0.0057377161917975174\n",
      "Training Loss: 0.006015055053867399\n",
      "Validation Loss: 0.0031722222279568905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006014371922356076\n",
      "Training Loss: 0.005732569374958985\n",
      "Training Loss: 0.006008710465393961\n",
      "Validation Loss: 0.003167623901226966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0060088314698077735\n",
      "Training Loss: 0.005727471774443984\n",
      "Training Loss: 0.006002431198721752\n",
      "Validation Loss: 0.0031630457378923893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006003344255732373\n",
      "Training Loss: 0.005722422315739095\n",
      "Training Loss: 0.005996215059421956\n",
      "Validation Loss: 0.0031584885005389203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005997909747529775\n",
      "Training Loss: 0.005717419440043159\n",
      "Training Loss: 0.005990062148193829\n",
      "Validation Loss: 0.0031539537640434974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00599252823216375\n",
      "Training Loss: 0.005712463130475953\n",
      "Training Loss: 0.005983970217639581\n",
      "Validation Loss: 0.003149438768447366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005987199483788572\n",
      "Training Loss: 0.005707552211242728\n",
      "Training Loss: 0.005977940474404022\n",
      "Validation Loss: 0.0031449421965569426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0059819240274373445\n",
      "Training Loss: 0.00570268501935061\n",
      "Training Loss: 0.005971971703693271\n",
      "Validation Loss: 0.003140464478716505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.0059767005546018485\n",
      "Training Loss: 0.005697861468652263\n",
      "Training Loss: 0.005966061684302986\n",
      "Validation Loss: 0.003136002780409174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005971529253874905\n",
      "Training Loss: 0.005693080414785072\n",
      "Training Loss: 0.005960210300399922\n",
      "Validation Loss: 0.0031315592899813912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.0059664090827573095\n",
      "Training Loss: 0.005688340285560116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [04:50<19:21, 145.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005954416222521104\n",
      "Validation Loss: 0.0031271292160924397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.1045730141364038\n",
      "Training Loss: 0.08326114177703857\n",
      "Training Loss: 0.07165061248466373\n",
      "Validation Loss: 0.06454173806175757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06529859201982617\n",
      "Training Loss: 0.06433481255546213\n",
      "Training Loss: 0.06321752754971385\n",
      "Validation Loss: 0.059780003398321985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.060691477283835414\n",
      "Training Loss: 0.059148370698094366\n",
      "Training Loss: 0.05748381156474352\n",
      "Validation Loss: 0.053322789395290816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.053601124584674836\n",
      "Training Loss: 0.05106382979080081\n",
      "Training Loss: 0.048894291911274194\n",
      "Validation Loss: 0.04409712435824148\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04398475334979594\n",
      "Training Loss: 0.04093062322586775\n",
      "Training Loss: 0.03901053779758513\n",
      "Validation Loss: 0.03423309041542953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.03412061168812215\n",
      "Training Loss: 0.031160910353064536\n",
      "Training Loss: 0.029692719085142018\n",
      "Validation Loss: 0.02513081164967813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.02524959824513644\n",
      "Training Loss: 0.022839170768857\n",
      "Training Loss: 0.02190432399045676\n",
      "Validation Loss: 0.017899691817884363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.018705451218411325\n",
      "Training Loss: 0.017519685460720212\n",
      "Training Loss: 0.0172746179997921\n",
      "Validation Loss: 0.014061319819662008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.015516631589271128\n",
      "Training Loss: 0.015124301158357412\n",
      "Training Loss: 0.015077424999326468\n",
      "Validation Loss: 0.012213313025997931\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013902573890518397\n",
      "Training Loss: 0.01370557613670826\n",
      "Training Loss: 0.013696089782752097\n",
      "Validation Loss: 0.011010632353175558\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012795615922659636\n",
      "Training Loss: 0.012654613344930113\n",
      "Training Loss: 0.0126750917872414\n",
      "Validation Loss: 0.010104905625575044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011945524106267839\n",
      "Training Loss: 0.011822694439906627\n",
      "Training Loss: 0.011869040748570115\n",
      "Validation Loss: 0.009376705090483923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.011258032005280257\n",
      "Training Loss: 0.011139604207128286\n",
      "Training Loss: 0.011208553549367934\n",
      "Validation Loss: 0.008768179124283992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0106854003877379\n",
      "Training Loss: 0.010565501183737069\n",
      "Training Loss: 0.010654937294311821\n",
      "Validation Loss: 0.00824704544168761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010199856825638563\n",
      "Training Loss: 0.010075603751465679\n",
      "Training Loss: 0.010184105911757797\n",
      "Validation Loss: 0.007793470474190257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009783318871632219\n",
      "Training Loss: 0.00965320158051327\n",
      "Training Loss: 0.009779660741332918\n",
      "Validation Loss: 0.007394233723746591\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009423033131752164\n",
      "Training Loss: 0.009286356043303386\n",
      "Training Loss: 0.009429808682762086\n",
      "Validation Loss: 0.007040000073297807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009109654023777693\n",
      "Training Loss: 0.008966298181330785\n",
      "Training Loss: 0.009125858652405441\n",
      "Validation Loss: 0.006723966745115565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008836205040570349\n",
      "Training Loss: 0.00868643967085518\n",
      "Training Loss: 0.008861276872921734\n",
      "Validation Loss: 0.006441049884711759\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008597372471122071\n",
      "Training Loss: 0.008441692837513982\n",
      "Training Loss: 0.008631033706478775\n",
      "Validation Loss: 0.006187363022812799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008389004446798935\n",
      "Training Loss: 0.008227994152111933\n",
      "Training Loss: 0.008431103405309842\n",
      "Validation Loss: 0.005959832473145275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008207695963792503\n",
      "Training Loss: 0.00804192541865632\n",
      "Training Loss: 0.008258079077349975\n",
      "Validation Loss: 0.005755905224156849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008050499780802056\n",
      "Training Loss: 0.0078804639284499\n",
      "Training Loss: 0.008108931670431047\n",
      "Validation Loss: 0.005573367838632692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007914745304733515\n",
      "Training Loss: 0.00774084834381938\n",
      "Training Loss: 0.007980862994445488\n",
      "Validation Loss: 0.005410216178410174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007797932493267581\n",
      "Training Loss: 0.007620486153755337\n",
      "Training Loss: 0.007871234819758684\n",
      "Validation Loss: 0.005264587747456318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007697697225958109\n",
      "Training Loss: 0.007516937429318205\n",
      "Training Loss: 0.007777569054160267\n",
      "Validation Loss: 0.005134743206684341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007611821681493893\n",
      "Training Loss: 0.007427937308093533\n",
      "Training Loss: 0.007697569921147078\n",
      "Validation Loss: 0.005019056600298774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007538252647500485\n",
      "Training Loss: 0.007351397828897461\n",
      "Training Loss: 0.007629144509555772\n",
      "Validation Loss: 0.0049160036331649575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007475119812879711\n",
      "Training Loss: 0.0072854327817913145\n",
      "Training Loss: 0.00757041760487482\n",
      "Validation Loss: 0.004824183290049936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007420753072947264\n",
      "Training Loss: 0.00722836319473572\n",
      "Training Loss: 0.007519746819743886\n",
      "Validation Loss: 0.004742308467459143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0073736898263450715\n",
      "Training Loss: 0.007178724956465885\n",
      "Training Loss: 0.007475721918744967\n",
      "Validation Loss: 0.004669206664280108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007332669220631942\n",
      "Training Loss: 0.007135259066708386\n",
      "Training Loss: 0.00743714528507553\n",
      "Validation Loss: 0.004603816287885054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007296619140543043\n",
      "Training Loss: 0.0070968917384743695\n",
      "Training Loss: 0.0074030157481320205\n",
      "Validation Loss: 0.004545182323219318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007264639124041423\n",
      "Training Loss: 0.007062725668074563\n",
      "Training Loss: 0.0073725059418939054\n",
      "Validation Loss: 0.004492455646081754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007235986163141206\n",
      "Training Loss: 0.007032016459852457\n",
      "Training Loss: 0.00734494365635328\n",
      "Validation Loss: 0.004444881776619828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007210051231086254\n",
      "Training Loss: 0.007004153621383011\n",
      "Training Loss: 0.007319785549771041\n",
      "Validation Loss: 0.0044017978499151685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007186340320622549\n",
      "Training Loss: 0.006978640396846458\n",
      "Training Loss: 0.007296595295192674\n",
      "Validation Loss: 0.004362616218427678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007164456892060116\n",
      "Training Loss: 0.006955075963633135\n",
      "Training Loss: 0.007275026565184817\n",
      "Validation Loss: 0.00432683155987035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007144082890590653\n",
      "Training Loss: 0.006933137990999967\n",
      "Training Loss: 0.007254806048003957\n",
      "Validation Loss: 0.004293996831559147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007124967235140503\n",
      "Training Loss: 0.006912570742424577\n",
      "Training Loss: 0.007235720218159258\n",
      "Validation Loss: 0.004263732986514237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007106912647141144\n",
      "Training Loss: 0.006893168730894104\n",
      "Training Loss: 0.007217599940486252\n",
      "Validation Loss: 0.004235711362045468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0070897618716116995\n",
      "Training Loss: 0.006874770086724311\n",
      "Training Loss: 0.007200314201181755\n",
      "Validation Loss: 0.004209642480336799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007073391845915466\n",
      "Training Loss: 0.006857243427075446\n",
      "Training Loss: 0.007183758746832609\n",
      "Validation Loss: 0.004185280930041597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007057706135092303\n",
      "Training Loss: 0.006840487365843728\n",
      "Training Loss: 0.00716785377706401\n",
      "Validation Loss: 0.004162419446105702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007042628752533347\n",
      "Training Loss: 0.006824418798787519\n",
      "Training Loss: 0.007152535134227946\n",
      "Validation Loss: 0.004140873826789052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0070280986302532255\n",
      "Training Loss: 0.0068089703074656425\n",
      "Training Loss: 0.007137752212584019\n",
      "Validation Loss: 0.0041204996333781925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007014068369753659\n",
      "Training Loss: 0.006794089812319726\n",
      "Training Loss: 0.0071234648337122055\n",
      "Validation Loss: 0.004101161491858323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007000499814748764\n",
      "Training Loss: 0.006779732382274233\n",
      "Training Loss: 0.007109638948459178\n",
      "Validation Loss: 0.0040827528233482934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006987360129714943\n",
      "Training Loss: 0.006765860235900618\n",
      "Training Loss: 0.007096245330758393\n",
      "Validation Loss: 0.004065172872349118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00697462297976017\n",
      "Training Loss: 0.006752443338627927\n",
      "Training Loss: 0.007083263514796272\n",
      "Validation Loss: 0.004048347041492214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006962267842609436\n",
      "Training Loss: 0.006739455594797618\n",
      "Training Loss: 0.007070669915992767\n",
      "Validation Loss: 0.0040322085868650945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006950273335096426\n",
      "Training Loss: 0.006726871759165079\n",
      "Training Loss: 0.007058447370072826\n",
      "Validation Loss: 0.004016697116384513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006938623246387578\n",
      "Training Loss: 0.006714673422975465\n",
      "Training Loss: 0.007046579770976677\n",
      "Validation Loss: 0.004001768190790428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006927302867406979\n",
      "Training Loss: 0.00670284119900316\n",
      "Training Loss: 0.0070350506028626116\n",
      "Validation Loss: 0.003987374998043093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00691629691165872\n",
      "Training Loss: 0.00669135797128547\n",
      "Training Loss: 0.0070238455082289875\n",
      "Validation Loss: 0.003973481784250294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006905591054819524\n",
      "Training Loss: 0.0066802077577449385\n",
      "Training Loss: 0.007012950524222105\n",
      "Validation Loss: 0.003960062697362364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006895174185629003\n",
      "Training Loss: 0.006669375436613337\n",
      "Training Loss: 0.007002351626288146\n",
      "Validation Loss: 0.003947090430792128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006885034394217655\n",
      "Training Loss: 0.006658847586950287\n",
      "Training Loss: 0.0069920356431975965\n",
      "Validation Loss: 0.003934534080849772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006875157598406076\n",
      "Training Loss: 0.006648608893156052\n",
      "Training Loss: 0.006981990946223959\n",
      "Validation Loss: 0.003922375303619866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006865533468662761\n",
      "Training Loss: 0.006638648486114107\n",
      "Training Loss: 0.006972204629564657\n",
      "Validation Loss: 0.003910598252230229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006856150821549818\n",
      "Training Loss: 0.006628951956517994\n",
      "Training Loss: 0.006962665130849928\n",
      "Validation Loss: 0.003899183605661553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006846999075496569\n",
      "Training Loss: 0.006619508560397662\n",
      "Training Loss: 0.0069533598388079555\n",
      "Validation Loss: 0.003888119613814555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00683806678163819\n",
      "Training Loss: 0.006610306439106353\n",
      "Training Loss: 0.0069442785216961055\n",
      "Validation Loss: 0.0038773877771173634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006829343906720169\n",
      "Training Loss: 0.006601334359729662\n",
      "Training Loss: 0.006935410398291424\n",
      "Validation Loss: 0.0038669793866574764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006820821155561135\n",
      "Training Loss: 0.0065925816458184275\n",
      "Training Loss: 0.006926743373041972\n",
      "Validation Loss: 0.0038568777793474246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006812489154981449\n",
      "Training Loss: 0.006584038304863498\n",
      "Training Loss: 0.0069182695809286085\n",
      "Validation Loss: 0.00384707387740818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0068043382227187975\n",
      "Training Loss: 0.00657569310395047\n",
      "Training Loss: 0.006909977204632014\n",
      "Validation Loss: 0.0038375501426753033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00679635691572912\n",
      "Training Loss: 0.006567537450464443\n",
      "Training Loss: 0.006901857670163736\n",
      "Validation Loss: 0.0038283022063041335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006788540032575838\n",
      "Training Loss: 0.006559561757603661\n",
      "Training Loss: 0.006893902405863628\n",
      "Validation Loss: 0.0038193142331948275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0067808758880710225\n",
      "Training Loss: 0.006551755804684945\n",
      "Training Loss: 0.006886102295247838\n",
      "Validation Loss: 0.003810580808072864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0067733592295553535\n",
      "Training Loss: 0.006544112242991105\n",
      "Training Loss: 0.0068784499273169784\n",
      "Validation Loss: 0.0038020920003188794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006765981731005013\n",
      "Training Loss: 0.006536623767460697\n",
      "Training Loss: 0.0068709366442635655\n",
      "Validation Loss: 0.003793836783178234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.0067587344470666725\n",
      "Training Loss: 0.006529280244722031\n",
      "Training Loss: 0.0068635551631450655\n",
      "Validation Loss: 0.003785809333268762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006751612412044778\n",
      "Training Loss: 0.006522075985558331\n",
      "Training Loss: 0.0068562990555074066\n",
      "Validation Loss: 0.0037779945623799324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006744606934953481\n",
      "Training Loss: 0.006515003478853032\n",
      "Training Loss: 0.006849161598365754\n",
      "Validation Loss: 0.003770388852480506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006737713047768921\n",
      "Training Loss: 0.006508055060403421\n",
      "Training Loss: 0.0068421354237943885\n",
      "Validation Loss: 0.0037629834475686377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006730923838913441\n",
      "Training Loss: 0.006501224398380146\n",
      "Training Loss: 0.00683521484141238\n",
      "Validation Loss: 0.003755768691712802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006724234213470482\n",
      "Training Loss: 0.006494505552109331\n",
      "Training Loss: 0.006828394677722826\n",
      "Validation Loss: 0.0037487353527855673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006717637016554363\n",
      "Training Loss: 0.006487891755532473\n",
      "Training Loss: 0.006821669578785077\n",
      "Validation Loss: 0.0037418790148529275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006711128964088858\n",
      "Training Loss: 0.006481378169846721\n",
      "Training Loss: 0.0068150339100975545\n",
      "Validation Loss: 0.003735192314972787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0067047032783739266\n",
      "Training Loss: 0.006474958977778442\n",
      "Training Loss: 0.006808483051136136\n",
      "Validation Loss: 0.0037286700641610817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006698355069383979\n",
      "Training Loss: 0.0064686291886027905\n",
      "Training Loss: 0.006802012342959642\n",
      "Validation Loss: 0.00372230228209303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0066920820355881\n",
      "Training Loss: 0.006462383925681933\n",
      "Training Loss: 0.006795618034666404\n",
      "Validation Loss: 0.0037160839092802633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006685877105919644\n",
      "Training Loss: 0.0064562177861807865\n",
      "Training Loss: 0.006789294152986259\n",
      "Validation Loss: 0.003710005915033097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006679737038211897\n",
      "Training Loss: 0.006450127047719434\n",
      "Training Loss: 0.006783038419671357\n",
      "Validation Loss: 0.003704064644695249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00667365912348032\n",
      "Training Loss: 0.00644410761015024\n",
      "Training Loss: 0.006776847497094423\n",
      "Validation Loss: 0.0036982559243196184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.00666763823479414\n",
      "Training Loss: 0.006438155121868476\n",
      "Training Loss: 0.006770717186154798\n",
      "Validation Loss: 0.003692572778143156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006661671369802207\n",
      "Training Loss: 0.006432265540934168\n",
      "Training Loss: 0.0067646429385058585\n",
      "Validation Loss: 0.0036870078419157294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006655754806706682\n",
      "Training Loss: 0.006426436274196022\n",
      "Training Loss: 0.006758624659851193\n",
      "Validation Loss: 0.003681558349138398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006649886511731893\n",
      "Training Loss: 0.006420662928721867\n",
      "Training Loss: 0.006752656953176483\n",
      "Validation Loss: 0.003676216144198447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.0066440616815816615\n",
      "Training Loss: 0.006414942055707798\n",
      "Training Loss: 0.006746737222420052\n",
      "Validation Loss: 0.003670979865429023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006638278118334711\n",
      "Training Loss: 0.006409270614967682\n",
      "Training Loss: 0.006740863641607575\n",
      "Validation Loss: 0.0036658422623792393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00663253354257904\n",
      "Training Loss: 0.0064036459306953475\n",
      "Training Loss: 0.0067350327235180885\n",
      "Validation Loss: 0.003660801087840973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006626825222047046\n",
      "Training Loss: 0.006398065792163834\n",
      "Training Loss: 0.006729243011213839\n",
      "Validation Loss: 0.0036558534641321122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006621150843566284\n",
      "Training Loss: 0.006392526606796309\n",
      "Training Loss: 0.006723491599550471\n",
      "Validation Loss: 0.0036509888589361245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006615507348906249\n",
      "Training Loss: 0.006387026177253574\n",
      "Training Loss: 0.006717776033328846\n",
      "Validation Loss: 0.0036462090773445167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006609893785207532\n",
      "Training Loss: 0.006381562560563907\n",
      "Training Loss: 0.006712096087867394\n",
      "Validation Loss: 0.0036415085798192225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006604306114604696\n",
      "Training Loss: 0.006376132775330916\n",
      "Training Loss: 0.006706447176402435\n",
      "Validation Loss: 0.003636882334340657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006598743874346838\n",
      "Training Loss: 0.006370734376250766\n",
      "Training Loss: 0.006700829179026186\n",
      "Validation Loss: 0.0036323258177157532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006593205345561728\n",
      "Training Loss: 0.006365366991376504\n",
      "Training Loss: 0.006695239874534309\n",
      "Validation Loss: 0.003627839574088039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006587687458377332\n",
      "Training Loss: 0.006360027074115351\n",
      "Training Loss: 0.006689676798414439\n",
      "Validation Loss: 0.0036234167231811902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006582189582986757\n",
      "Training Loss: 0.006354713347391226\n",
      "Training Loss: 0.006684139675926417\n",
      "Validation Loss: 0.0036190541897994583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006576709196669981\n",
      "Training Loss: 0.0063494233845267445\n",
      "Training Loss: 0.006678625456406735\n",
      "Validation Loss: 0.003614750664597482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0065712448861449954\n",
      "Training Loss: 0.0063441566721303385\n",
      "Training Loss: 0.00667313388781622\n",
      "Validation Loss: 0.0036104992803793106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006565796245704405\n",
      "Training Loss: 0.0063389109284617004\n",
      "Training Loss: 0.00666766257782001\n",
      "Validation Loss: 0.003606302392920165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006560359994182363\n",
      "Training Loss: 0.0063336843810975554\n",
      "Training Loss: 0.006662209705682471\n",
      "Validation Loss: 0.0036021520755138625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00655493535916321\n",
      "Training Loss: 0.0063284764852141965\n",
      "Training Loss: 0.006656775359879248\n",
      "Validation Loss: 0.003598049368050075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006549522103159689\n",
      "Training Loss: 0.006323284415993839\n",
      "Training Loss: 0.006651357225491665\n",
      "Validation Loss: 0.0035939897381794756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006544117644662038\n",
      "Training Loss: 0.006318107959814369\n",
      "Training Loss: 0.006645952856633813\n",
      "Validation Loss: 0.0035899705201219976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.00653872171533294\n",
      "Training Loss: 0.006312945912359282\n",
      "Training Loss: 0.006640563477412797\n",
      "Validation Loss: 0.0035859856916738027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006533332085236907\n",
      "Training Loss: 0.006307796495966613\n",
      "Training Loss: 0.006635186817147769\n",
      "Validation Loss: 0.0035820347623208935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006527948268922046\n",
      "Training Loss: 0.006302658703061752\n",
      "Training Loss: 0.00662982085486874\n",
      "Validation Loss: 0.0035781179531215786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006522568833315745\n",
      "Training Loss: 0.006297532122698612\n",
      "Training Loss: 0.006624465592904016\n",
      "Validation Loss: 0.0035742276421423707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00651719324872829\n",
      "Training Loss: 0.006292414380586706\n",
      "Training Loss: 0.006619118606904522\n",
      "Validation Loss: 0.0035703653179297453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006511819707229733\n",
      "Training Loss: 0.006287305525620468\n",
      "Training Loss: 0.006613779485924169\n",
      "Validation Loss: 0.0035665248667172502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006506448109284975\n",
      "Training Loss: 0.0062822043459163975\n",
      "Training Loss: 0.006608447200851515\n",
      "Validation Loss: 0.0035627074330375434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.0065010766452178355\n",
      "Training Loss: 0.006277109261718579\n",
      "Training Loss: 0.006603120731888339\n",
      "Validation Loss: 0.003558906170623272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006495703723048791\n",
      "Training Loss: 0.006272019853931852\n",
      "Training Loss: 0.006597797280992381\n",
      "Validation Loss: 0.003555122922499026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006490330265951343\n",
      "Training Loss: 0.006266935323365033\n",
      "Training Loss: 0.00659247757634148\n",
      "Validation Loss: 0.003551350189686826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0064849546767072755\n",
      "Training Loss: 0.0062618558673420924\n",
      "Training Loss: 0.006587161258794367\n",
      "Validation Loss: 0.003547589344317826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0064795756054809315\n",
      "Training Loss: 0.006256779552204534\n",
      "Training Loss: 0.006581845298060216\n",
      "Validation Loss: 0.003543836192824365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006474192967871204\n",
      "Training Loss: 0.006251705694012344\n",
      "Training Loss: 0.006576529474114068\n",
      "Validation Loss: 0.0035400881779934753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006468805269687437\n",
      "Training Loss: 0.006246634233393706\n",
      "Training Loss: 0.00657121240044944\n",
      "Validation Loss: 0.0035363418152137252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006463412853772752\n",
      "Training Loss: 0.006241564648225903\n",
      "Training Loss: 0.006565894538653083\n",
      "Validation Loss: 0.0035325968873509196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0064580138010205705\n",
      "Training Loss: 0.0062364956055535005\n",
      "Training Loss: 0.006560573558090255\n",
      "Validation Loss: 0.003528850978460121\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006452608981635422\n",
      "Training Loss: 0.0062314272276125845\n",
      "Training Loss: 0.006555248320801184\n",
      "Validation Loss: 0.003525101210859217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006447196659282781\n",
      "Training Loss: 0.006226358634303324\n",
      "Training Loss: 0.0065499181940685955\n",
      "Validation Loss: 0.0035213427945155274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006441777601721697\n",
      "Training Loss: 0.006221289970562793\n",
      "Training Loss: 0.00654458379780408\n",
      "Validation Loss: 0.0035175743860747207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006436350364238024\n",
      "Training Loss: 0.00621622110134922\n",
      "Training Loss: 0.00653924225945957\n",
      "Validation Loss: 0.0035137955983577484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006430914776865393\n",
      "Training Loss: 0.006211151644238271\n",
      "Training Loss: 0.00653389475075528\n",
      "Validation Loss: 0.003510004011495562\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006425471739494242\n",
      "Training Loss: 0.006206080944393761\n",
      "Training Loss: 0.006528540673898533\n",
      "Validation Loss: 0.003506195533947412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006420020154910162\n",
      "Training Loss: 0.006201008915086277\n",
      "Training Loss: 0.006523177181370556\n",
      "Validation Loss: 0.003502368420791509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0064145611715503035\n",
      "Training Loss: 0.006195936550502665\n",
      "Training Loss: 0.0065178064780775456\n",
      "Validation Loss: 0.0034985240310786312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006409094849950634\n",
      "Training Loss: 0.0061908637720625844\n",
      "Training Loss: 0.006512426850385964\n",
      "Validation Loss: 0.003494655063344438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006403620733763092\n",
      "Training Loss: 0.006185789881856181\n",
      "Training Loss: 0.006507038454874419\n",
      "Validation Loss: 0.0034907648583162535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0063981398072792215\n",
      "Training Loss: 0.006180715718655847\n",
      "Training Loss: 0.00650164173450321\n",
      "Validation Loss: 0.0034868527815959762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006392654473311268\n",
      "Training Loss: 0.006175643270253204\n",
      "Training Loss: 0.006496237291721627\n",
      "Validation Loss: 0.003482912524519593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006387163302861154\n",
      "Training Loss: 0.006170570575050078\n",
      "Training Loss: 0.006490823699859902\n",
      "Validation Loss: 0.0034789474068858315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006381668793037534\n",
      "Training Loss: 0.006165499751223252\n",
      "Training Loss: 0.006485402807593346\n",
      "Validation Loss: 0.0034749542226952114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006376172201707959\n",
      "Training Loss: 0.006160430879681371\n",
      "Training Loss: 0.006479975181864574\n",
      "Validation Loss: 0.0034709350975083834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006370675205253065\n",
      "Training Loss: 0.006155365564045496\n",
      "Training Loss: 0.006474541558418423\n",
      "Validation Loss: 0.003466888907721287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.00636517972452566\n",
      "Training Loss: 0.006150304140755907\n",
      "Training Loss: 0.006469103078125045\n",
      "Validation Loss: 0.003462813041183386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006359687347430736\n",
      "Training Loss: 0.006145248165703379\n",
      "Training Loss: 0.006463661282323301\n",
      "Validation Loss: 0.0034587124422757647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006354200632777065\n",
      "Training Loss: 0.006140197995118796\n",
      "Training Loss: 0.00645821682352107\n",
      "Validation Loss: 0.003454591215619545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0063487216376233845\n",
      "Training Loss: 0.0061351551290135834\n",
      "Training Loss: 0.006452771183103323\n",
      "Validation Loss: 0.003450443286689396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006343252229271457\n",
      "Training Loss: 0.006130120668676682\n",
      "Training Loss: 0.006447327143396251\n",
      "Validation Loss: 0.003446272944539702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006337795511353761\n",
      "Training Loss: 0.006125095552997664\n",
      "Training Loss: 0.0064418866881169375\n",
      "Validation Loss: 0.0034420839327732834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006332355231279507\n",
      "Training Loss: 0.006120081105036661\n",
      "Training Loss: 0.006436450065812096\n",
      "Validation Loss: 0.0034378747118302107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006326931369840167\n",
      "Training Loss: 0.006115078160655684\n",
      "Training Loss: 0.006431019845767878\n",
      "Validation Loss: 0.003433651811432805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006321528478874825\n",
      "Training Loss: 0.006110088220448233\n",
      "Training Loss: 0.006425598727655597\n",
      "Validation Loss: 0.0034294193048092923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.0063161490589845925\n",
      "Training Loss: 0.006105111552169546\n",
      "Training Loss: 0.006420188012998551\n",
      "Validation Loss: 0.0034251747498539892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.00631079550134018\n",
      "Training Loss: 0.006100149251287803\n",
      "Training Loss: 0.006414791662828065\n",
      "Validation Loss: 0.003420924468311282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006305469666840508\n",
      "Training Loss: 0.006095202552969568\n",
      "Training Loss: 0.006409408620093018\n",
      "Validation Loss: 0.003416675013448164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006300174912903458\n",
      "Training Loss: 0.006090271950233728\n",
      "Training Loss: 0.00640404301462695\n",
      "Validation Loss: 0.0034124234291002826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006294911713339389\n",
      "Training Loss: 0.0060853580140974375\n",
      "Training Loss: 0.006398695933166891\n",
      "Validation Loss: 0.0034081759022841795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006289682706701569\n",
      "Training Loss: 0.006080461429082789\n",
      "Training Loss: 0.006393368427525275\n",
      "Validation Loss: 0.0034039403322372545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006284489399986342\n",
      "Training Loss: 0.00607558274816256\n",
      "Training Loss: 0.006388061286997981\n",
      "Validation Loss: 0.0033997182310506534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0062793322937795895\n",
      "Training Loss: 0.006070721402647905\n",
      "Training Loss: 0.0063827781827421855\n",
      "Validation Loss: 0.0033955109512349697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006274214684963226\n",
      "Training Loss: 0.006065880089299753\n",
      "Training Loss: 0.006377519245725125\n",
      "Validation Loss: 0.0033913188995898106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0062691336445277555\n",
      "Training Loss: 0.006061057331971824\n",
      "Training Loss: 0.00637228486710228\n",
      "Validation Loss: 0.0033871503311387273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006264092432102189\n",
      "Training Loss: 0.0060562541906256226\n",
      "Training Loss: 0.006367075946182013\n",
      "Validation Loss: 0.0033830080738584145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006259089024388232\n",
      "Training Loss: 0.006051470618112944\n",
      "Training Loss: 0.006361894002184272\n",
      "Validation Loss: 0.003378900386696535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006254125928971916\n",
      "Training Loss: 0.0060467074433108794\n",
      "Training Loss: 0.006356738719623536\n",
      "Validation Loss: 0.00337482150120849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006249201136524789\n",
      "Training Loss: 0.006041966288466938\n",
      "Training Loss: 0.0063516115659149365\n",
      "Validation Loss: 0.00337077858805489\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006244315500953235\n",
      "Training Loss: 0.0060372458241181445\n",
      "Training Loss: 0.006346511644078418\n",
      "Validation Loss: 0.0033667714091729414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0062394659843994305\n",
      "Training Loss: 0.0060325468669179825\n",
      "Training Loss: 0.0063414384867064655\n",
      "Validation Loss: 0.0033628074321477267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.00623465351993218\n",
      "Training Loss: 0.006027870418620296\n",
      "Training Loss: 0.006336393805686385\n",
      "Validation Loss: 0.0033588857282727453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006229877481237054\n",
      "Training Loss: 0.006023217421607115\n",
      "Training Loss: 0.006331377143505961\n",
      "Validation Loss: 0.003355007553263829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0062251355079934005\n",
      "Training Loss: 0.006018588388687931\n",
      "Training Loss: 0.006326387687586248\n",
      "Validation Loss: 0.00335117693325986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0062204269884387035\n",
      "Training Loss: 0.0060139824287034575\n",
      "Training Loss: 0.006321425954811275\n",
      "Validation Loss: 0.0033473929290900404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006215751636191271\n",
      "Training Loss: 0.006009401665651239\n",
      "Training Loss: 0.006316490746103227\n",
      "Validation Loss: 0.0033436623281600437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006211106935516\n",
      "Training Loss: 0.0060048474196810276\n",
      "Training Loss: 0.006311582850757986\n",
      "Validation Loss: 0.0033399799257893574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.00620649254124146\n",
      "Training Loss: 0.006000318169826642\n",
      "Training Loss: 0.006306700884597376\n",
      "Validation Loss: 0.0033363491712724057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006201906555215828\n",
      "Training Loss: 0.005995815872447565\n",
      "Training Loss: 0.006301844835397787\n",
      "Validation Loss: 0.003332771321633056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006197347849956713\n",
      "Training Loss: 0.005991340830223635\n",
      "Training Loss: 0.006297014699666761\n",
      "Validation Loss: 0.003329245665299005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006192815373069606\n",
      "Training Loss: 0.0059868933242978525\n",
      "Training Loss: 0.006292208656668663\n",
      "Validation Loss: 0.003325777133570963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00618830808729399\n",
      "Training Loss: 0.005982474426855333\n",
      "Training Loss: 0.006287427767529152\n",
      "Validation Loss: 0.0033223566604422385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006183823968167417\n",
      "Training Loss: 0.005978083629161119\n",
      "Training Loss: 0.0062826708692591635\n",
      "Validation Loss: 0.0033189895722408142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.00617936352500692\n",
      "Training Loss: 0.005973720940528437\n",
      "Training Loss: 0.006277937886188738\n",
      "Validation Loss: 0.003315670991295509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006174924069200643\n",
      "Training Loss: 0.005969387444783933\n",
      "Training Loss: 0.00627322805521544\n",
      "Validation Loss: 0.003312407846280028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006170506187481805\n",
      "Training Loss: 0.0059650831844192\n",
      "Training Loss: 0.006268540470045991\n",
      "Validation Loss: 0.0033091952699874894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006166106621967629\n",
      "Training Loss: 0.0059608077973825856\n",
      "Training Loss: 0.006263875312870368\n",
      "Validation Loss: 0.0033060327182743657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006161727511789649\n",
      "Training Loss: 0.005956560739432462\n",
      "Training Loss: 0.006259231659350916\n",
      "Validation Loss: 0.0033029193330681725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006157364618266001\n",
      "Training Loss: 0.005952343147946522\n",
      "Training Loss: 0.006254609421594068\n",
      "Validation Loss: 0.0032998506735821957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006153019669000059\n",
      "Training Loss: 0.005948153402423486\n",
      "Training Loss: 0.0062500073155388235\n",
      "Validation Loss: 0.0032968244841060697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006148689499823377\n",
      "Training Loss: 0.00594399263500236\n",
      "Training Loss: 0.0062454259977675975\n",
      "Validation Loss: 0.003293844859450637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006144376252777874\n",
      "Training Loss: 0.005939860455109738\n",
      "Training Loss: 0.006240865137660876\n",
      "Validation Loss: 0.0032909114850329215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006140077804448083\n",
      "Training Loss: 0.005935756393009797\n",
      "Training Loss: 0.006236323398770765\n",
      "Validation Loss: 0.003288020528303564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006135794463334605\n",
      "Training Loss: 0.005931680526118726\n",
      "Training Loss: 0.006231801935937256\n",
      "Validation Loss: 0.0032851663954409486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006131524412776344\n",
      "Training Loss: 0.005927632011589594\n",
      "Training Loss: 0.006227299461024813\n",
      "Validation Loss: 0.003282351839863643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.0061272685037693005\n",
      "Training Loss: 0.005923611001926474\n",
      "Training Loss: 0.006222815868095494\n",
      "Validation Loss: 0.003279575718347025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006123026238637977\n",
      "Training Loss: 0.005919616827159188\n",
      "Training Loss: 0.0062183509231545035\n",
      "Validation Loss: 0.003276835559354572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006118796899681911\n",
      "Training Loss: 0.005915650430833921\n",
      "Training Loss: 0.00621390575717669\n",
      "Validation Loss: 0.003274127035244797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006114580598077737\n",
      "Training Loss: 0.005911710861837492\n",
      "Training Loss: 0.006209479249082506\n",
      "Validation Loss: 0.0032714498896423854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00611037825292442\n",
      "Training Loss: 0.005907796628889628\n",
      "Training Loss: 0.0062050717195961625\n",
      "Validation Loss: 0.0032688070649772964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006106189286801964\n",
      "Training Loss: 0.005903909988701344\n",
      "Training Loss: 0.006200683595379814\n",
      "Validation Loss: 0.0032661903919024246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006102013846393675\n",
      "Training Loss: 0.005900050351046957\n",
      "Training Loss: 0.006196317049907521\n",
      "Validation Loss: 0.003263605615317696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006097852161619812\n",
      "Training Loss: 0.0058962167968275025\n",
      "Training Loss: 0.006191968555795029\n",
      "Validation Loss: 0.003261043975951171\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006093705237144604\n",
      "Training Loss: 0.005892410352826119\n",
      "Training Loss: 0.006187641437863931\n",
      "Validation Loss: 0.003258506717746345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006089572114869952\n",
      "Training Loss: 0.005888631105772219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [07:15<16:54, 144.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006183336318936199\n",
      "Validation Loss: 0.003255990078787874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.8081794127821922\n",
      "Training Loss: 0.6841780990362167\n",
      "Training Loss: 0.5582806667685509\n",
      "Validation Loss: 0.43424925141120224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.3725827119499445\n",
      "Training Loss: 0.2783579232543707\n",
      "Training Loss: 0.1969282991439104\n",
      "Validation Loss: 0.12728390449218535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.11337296852841973\n",
      "Training Loss: 0.08829233273863793\n",
      "Training Loss: 0.0737121613137424\n",
      "Validation Loss: 0.060765917130400623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.0660475017875433\n",
      "Training Loss: 0.06518174398690463\n",
      "Training Loss: 0.0644169488362968\n",
      "Validation Loss: 0.05786361260695404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.0630440277978778\n",
      "Training Loss: 0.06233875136822462\n",
      "Training Loss: 0.061672212593257426\n",
      "Validation Loss: 0.05543975904583931\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.0600674613751471\n",
      "Training Loss: 0.05906422521919012\n",
      "Training Loss: 0.058211370408535\n",
      "Validation Loss: 0.05217645934709672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.05610645670443773\n",
      "Training Loss: 0.05461383022367954\n",
      "Training Loss: 0.05338192578405142\n",
      "Validation Loss: 0.047569189534595845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.05020147139206529\n",
      "Training Loss: 0.047632568329572675\n",
      "Training Loss: 0.04547090996056795\n",
      "Validation Loss: 0.04005805562051495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.04058306664228439\n",
      "Training Loss: 0.037483538454398516\n",
      "Training Loss: 0.03603043258190155\n",
      "Validation Loss: 0.03214288423402926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.032476507229730486\n",
      "Training Loss: 0.030256007988937197\n",
      "Training Loss: 0.029833709867671133\n",
      "Validation Loss: 0.026683122118453632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.02731830092146993\n",
      "Training Loss: 0.025566480313427745\n",
      "Training Loss: 0.02558247813023627\n",
      "Validation Loss: 0.022768681230588575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.023642220166511834\n",
      "Training Loss: 0.02217434886842966\n",
      "Training Loss: 0.0223849913245067\n",
      "Validation Loss: 0.019778087217193305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.020837474949657916\n",
      "Training Loss: 0.01957517069764435\n",
      "Training Loss: 0.01986540897283703\n",
      "Validation Loss: 0.017391074543002615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.018622441925108434\n",
      "Training Loss: 0.017520178693812342\n",
      "Training Loss: 0.01783471376169473\n",
      "Validation Loss: 0.015436743490732787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.016845377702265976\n",
      "Training Loss: 0.01587103679543361\n",
      "Training Loss: 0.016188687758985906\n",
      "Validation Loss: 0.013818311206787155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.015413944912143051\n",
      "Training Loss: 0.01454087076941505\n",
      "Training Loss: 0.014858467960730195\n",
      "Validation Loss: 0.012470274975293138\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.014260753423441202\n",
      "Training Loss: 0.013465411928482354\n",
      "Training Loss: 0.013788312589749694\n",
      "Validation Loss: 0.011341528221441622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.013331799109000713\n",
      "Training Loss: 0.012594473399221897\n",
      "Training Loss: 0.012931290450505912\n",
      "Validation Loss: 0.01039211044684471\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.01258430008776486\n",
      "Training Loss: 0.011889491353649646\n",
      "Training Loss: 0.012248404915444553\n",
      "Validation Loss: 0.009591094887909594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.011983890389092266\n",
      "Training Loss: 0.011319895246997476\n",
      "Training Loss: 0.011706187676172703\n",
      "Validation Loss: 0.008913382477116552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.011501178781036287\n",
      "Training Loss: 0.010859411843121052\n",
      "Training Loss: 0.011274406922748312\n",
      "Validation Loss: 0.008337046511554987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.011109415584942326\n",
      "Training Loss: 0.010483760525239631\n",
      "Training Loss: 0.010924927494488656\n",
      "Validation Loss: 0.007841910392548262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.01078378479462117\n",
      "Training Loss: 0.010170333354035393\n",
      "Training Loss: 0.010632435959996656\n",
      "Validation Loss: 0.007409760422397698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.010502460012212396\n",
      "Training Loss: 0.00989961420884356\n",
      "Training Loss: 0.010376199984457345\n",
      "Validation Loss: 0.007025632612260707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.010248353675706312\n",
      "Training Loss: 0.009656950215576216\n",
      "Training Loss: 0.01014176145195961\n",
      "Validation Loss: 0.006679493779567688\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.010010354705154895\n",
      "Training Loss: 0.009433230574941262\n",
      "Training Loss: 0.009920900262659415\n",
      "Validation Loss: 0.006366500981528772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.009782644613878802\n",
      "Training Loss: 0.009223726973868907\n",
      "Training Loss: 0.009709915436105802\n",
      "Validation Loss: 0.006085465575850914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.009563157144002616\n",
      "Training Loss: 0.00902653387747705\n",
      "Training Loss: 0.009507999067427591\n",
      "Validation Loss: 0.005836800261390176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00935238900128752\n",
      "Training Loss: 0.00884153216611594\n",
      "Training Loss: 0.009316171725513413\n",
      "Validation Loss: 0.005620919167995453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.009152350393123924\n",
      "Training Loss: 0.008669565529562533\n",
      "Training Loss: 0.009136303040431813\n",
      "Validation Loss: 0.005437204185245412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008965458784950897\n",
      "Training Loss: 0.008511680805822834\n",
      "Training Loss: 0.008970215390436352\n",
      "Validation Loss: 0.005283700227685106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.008793698807712644\n",
      "Training Loss: 0.008368599900277331\n",
      "Training Loss: 0.008819128598552196\n",
      "Validation Loss: 0.005157337575010286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0086382238403894\n",
      "Training Loss: 0.008240484844427555\n",
      "Training Loss: 0.008683451494434849\n",
      "Validation Loss: 0.005054369422324588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.008499280425021426\n",
      "Training Loss: 0.008126900495262816\n",
      "Training Loss: 0.008562823452521115\n",
      "Validation Loss: 0.0049708455309188096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.008376333464402705\n",
      "Training Loss: 0.008026905331062152\n",
      "Training Loss: 0.008456290839239955\n",
      "Validation Loss: 0.004902967276689963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00826827053388115\n",
      "Training Loss: 0.007939212368801235\n",
      "Training Loss: 0.00836252600303851\n",
      "Validation Loss: 0.004847330187729905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.008173634310951456\n",
      "Training Loss: 0.007862366512417793\n",
      "Training Loss: 0.00828004274284467\n",
      "Validation Loss: 0.004801060086158052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00809083568805363\n",
      "Training Loss: 0.007794906852068379\n",
      "Training Loss: 0.008207368068397045\n",
      "Validation Loss: 0.004761847468574395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.008018314467626624\n",
      "Training Loss: 0.007735475449590012\n",
      "Training Loss: 0.008143144871573894\n",
      "Validation Loss: 0.0047279147096396835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007954638776136563\n",
      "Training Loss: 0.007682881061919033\n",
      "Training Loss: 0.008086189681198447\n",
      "Validation Loss: 0.0046979465830568855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007898555838037282\n",
      "Training Loss: 0.007636117205256596\n",
      "Training Loss: 0.008035502976272256\n",
      "Validation Loss: 0.004670990344524132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007848999198758975\n",
      "Training Loss: 0.007594353840686381\n",
      "Training Loss: 0.007990252561867237\n",
      "Validation Loss: 0.004646378501287002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007805073342751712\n",
      "Training Loss: 0.007556907157413662\n",
      "Training Loss: 0.007949747112579644\n",
      "Validation Loss: 0.004623643677221255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007766026449389756\n",
      "Training Loss: 0.007523218236747198\n",
      "Training Loss: 0.007913410119945183\n",
      "Validation Loss: 0.004602468560784637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007731230586068704\n",
      "Training Loss: 0.007492822483181953\n",
      "Training Loss: 0.007880754249636085\n",
      "Validation Loss: 0.004582625149299254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0077001513593131675\n",
      "Training Loss: 0.007465329493861646\n",
      "Training Loss: 0.007851361099164933\n",
      "Validation Loss: 0.004563943336435249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0076723323669284586\n",
      "Training Loss: 0.007440405762754381\n",
      "Training Loss: 0.007824865481816233\n",
      "Validation Loss: 0.004546310077682974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00764737854944542\n",
      "Training Loss: 0.0074177595088258386\n",
      "Training Loss: 0.007800944815389812\n",
      "Validation Loss: 0.004529623892890771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0076249446300789715\n",
      "Training Loss: 0.0073971363750752065\n",
      "Training Loss: 0.007779311194317415\n",
      "Validation Loss: 0.004513810681744238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007604729093145579\n",
      "Training Loss: 0.007378311164793558\n",
      "Training Loss: 0.007759708700468763\n",
      "Validation Loss: 0.004498805118243346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007586465175263584\n",
      "Training Loss: 0.007361083452124149\n",
      "Training Loss: 0.007741906604496762\n",
      "Validation Loss: 0.0044845515584803364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00756991736125201\n",
      "Training Loss: 0.007345271564554423\n",
      "Training Loss: 0.007725697011919692\n",
      "Validation Loss: 0.004471001660011792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007554877031361684\n",
      "Training Loss: 0.007330718254088424\n",
      "Training Loss: 0.007710895681520924\n",
      "Validation Loss: 0.00445811007056762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007541162935085595\n",
      "Training Loss: 0.007317279546405189\n",
      "Training Loss: 0.007697337585268542\n",
      "Validation Loss: 0.004445837054589993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0075286105053965005\n",
      "Training Loss: 0.007304828236228787\n",
      "Training Loss: 0.0076848752016667275\n",
      "Validation Loss: 0.004434146969369874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007517079858807847\n",
      "Training Loss: 0.007293251443188637\n",
      "Training Loss: 0.007673376849852503\n",
      "Validation Loss: 0.004423005130989582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007506444827886299\n",
      "Training Loss: 0.0072824499750277025\n",
      "Training Loss: 0.007662726804846897\n",
      "Validation Loss: 0.004412379994821013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007496595464181155\n",
      "Training Loss: 0.007272333563305438\n",
      "Training Loss: 0.007652821750380099\n",
      "Validation Loss: 0.004402244602214922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007487434410722926\n",
      "Training Loss: 0.0072628234047442675\n",
      "Training Loss: 0.007643572547240182\n",
      "Validation Loss: 0.004392566891868462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007478878251858987\n",
      "Training Loss: 0.007253851191489957\n",
      "Training Loss: 0.00763489670236595\n",
      "Validation Loss: 0.004383323167377476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007470851567341015\n",
      "Training Loss: 0.0072453538584522905\n",
      "Training Loss: 0.007626725235022605\n",
      "Validation Loss: 0.004374491610679399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007463289441075176\n",
      "Training Loss: 0.007237277096137405\n",
      "Training Loss: 0.007618995090015232\n",
      "Validation Loss: 0.004366041974719154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007456134181120433\n",
      "Training Loss: 0.007229572833166458\n",
      "Training Loss: 0.007611652030609548\n",
      "Validation Loss: 0.004357956300144282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0074493359046755355\n",
      "Training Loss: 0.007222197938826867\n",
      "Training Loss: 0.007604647669941187\n",
      "Validation Loss: 0.004350212177659353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00744284977321513\n",
      "Training Loss: 0.007215113715501502\n",
      "Training Loss: 0.007597938213730231\n",
      "Validation Loss: 0.004342788835631662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007436637537903152\n",
      "Training Loss: 0.007208287832327187\n",
      "Training Loss: 0.007591486778110266\n",
      "Validation Loss: 0.004335666342188468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00743066371534951\n",
      "Training Loss: 0.0072016889578662814\n",
      "Training Loss: 0.007585260049672797\n",
      "Validation Loss: 0.004328825074153837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007424898816389032\n",
      "Training Loss: 0.007195290738600306\n",
      "Training Loss: 0.007579227791866288\n",
      "Validation Loss: 0.004322247795519952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007419315677834675\n",
      "Training Loss: 0.007189068857696839\n",
      "Training Loss: 0.007573363716946915\n",
      "Validation Loss: 0.004315918010628123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0074138894811039795\n",
      "Training Loss: 0.007183002296369523\n",
      "Training Loss: 0.007567644375376404\n",
      "Validation Loss: 0.00430981787784925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007408600336057134\n",
      "Training Loss: 0.007177071329206228\n",
      "Training Loss: 0.007562050118576735\n",
      "Validation Loss: 0.004303932578428492\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007403428354300559\n",
      "Training Loss: 0.007171257971785963\n",
      "Training Loss: 0.007556560426019132\n",
      "Validation Loss: 0.004298249577444172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007398356859339401\n",
      "Training Loss: 0.007165546807809733\n",
      "Training Loss: 0.0075511589716188605\n",
      "Validation Loss: 0.004292751194155785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007393370714853517\n",
      "Training Loss: 0.0071599229454295706\n",
      "Training Loss: 0.0075458301359321925\n",
      "Validation Loss: 0.0042874275921226555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007388455132604577\n",
      "Training Loss: 0.007154373449739068\n",
      "Training Loss: 0.007540559086482972\n",
      "Validation Loss: 0.004282263973518536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.0073835973005043345\n",
      "Training Loss: 0.007148884435300715\n",
      "Training Loss: 0.007535332625266165\n",
      "Validation Loss: 0.004277249876660913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007378786037443206\n",
      "Training Loss: 0.007143444544053637\n",
      "Training Loss: 0.007530138500733301\n",
      "Validation Loss: 0.004272370049834586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007374009852064774\n",
      "Training Loss: 0.007138043250888586\n",
      "Training Loss: 0.007524966315831989\n",
      "Validation Loss: 0.004267618337415912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007369258083635941\n",
      "Training Loss: 0.007132669207639992\n",
      "Training Loss: 0.0075198033533524725\n",
      "Validation Loss: 0.0042629852443619555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007364522516145371\n",
      "Training Loss: 0.00712731194216758\n",
      "Training Loss: 0.007514638898428529\n",
      "Validation Loss: 0.004258457639286023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007359791823546402\n",
      "Training Loss: 0.007121961998054757\n",
      "Training Loss: 0.0075094625481870025\n",
      "Validation Loss: 0.004254027544468474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007355056917876936\n",
      "Training Loss: 0.0071166074171196666\n",
      "Training Loss: 0.007504263393348083\n",
      "Validation Loss: 0.004249682908961445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007350308618042618\n",
      "Training Loss: 0.007111238349461928\n",
      "Training Loss: 0.0074990301055368035\n",
      "Validation Loss: 0.004245418713825723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007345536922221072\n",
      "Training Loss: 0.007105844135512598\n",
      "Training Loss: 0.007493752043228596\n",
      "Validation Loss: 0.004241224621642339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007340733647579327\n",
      "Training Loss: 0.007100412575528026\n",
      "Training Loss: 0.007488416839623824\n",
      "Validation Loss: 0.004237092584057638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007335886055370793\n",
      "Training Loss: 0.007094933146727271\n",
      "Training Loss: 0.007483012838056311\n",
      "Validation Loss: 0.00423301383722155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007330985904554836\n",
      "Training Loss: 0.007089393603964708\n",
      "Training Loss: 0.007477527712471783\n",
      "Validation Loss: 0.004228980978950858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0073260212258901445\n",
      "Training Loss: 0.0070837802661117165\n",
      "Training Loss: 0.0074719465640373526\n",
      "Validation Loss: 0.004224984422640017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007320980952354148\n",
      "Training Loss: 0.007078080361243338\n",
      "Training Loss: 0.0074662562843877825\n",
      "Validation Loss: 0.004221017388731576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007315851878374815\n",
      "Training Loss: 0.007072279171552509\n",
      "Training Loss: 0.007460441346047446\n",
      "Validation Loss: 0.004217070838687628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007310621744254604\n",
      "Training Loss: 0.00706636197748594\n",
      "Training Loss: 0.00745448682224378\n",
      "Validation Loss: 0.004213136041359034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007305275571416132\n",
      "Training Loss: 0.007060312567045912\n",
      "Training Loss: 0.007448376319371164\n",
      "Validation Loss: 0.004209207302859325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0072997996176127344\n",
      "Training Loss: 0.007054117259685882\n",
      "Training Loss: 0.0074420938070397825\n",
      "Validation Loss: 0.004205272445361015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007294180153403431\n",
      "Training Loss: 0.0070477590884547685\n",
      "Training Loss: 0.007435621953336522\n",
      "Validation Loss: 0.004201322329607321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007288400568068027\n",
      "Training Loss: 0.007041222802945413\n",
      "Training Loss: 0.007428946573054418\n",
      "Validation Loss: 0.004197347954993419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007282448121695779\n",
      "Training Loss: 0.007034495942643843\n",
      "Training Loss: 0.007422054276103154\n",
      "Validation Loss: 0.004193341775451985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007276309499284253\n",
      "Training Loss: 0.007027566711767577\n",
      "Training Loss: 0.007414932367391884\n",
      "Validation Loss: 0.0041892930363001445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007269971843925305\n",
      "Training Loss: 0.007020426212111488\n",
      "Training Loss: 0.0074075726652517914\n",
      "Validation Loss: 0.004185191591092375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007263427153229713\n",
      "Training Loss: 0.007013067398802377\n",
      "Training Loss: 0.007399969212710858\n",
      "Validation Loss: 0.004181029641310151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007256667430046946\n",
      "Training Loss: 0.007005489890580066\n",
      "Training Loss: 0.00739212162210606\n",
      "Validation Loss: 0.004176796751431702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007249692137120292\n",
      "Training Loss: 0.0069976963894441725\n",
      "Training Loss: 0.007384034056449309\n",
      "Validation Loss: 0.004172485342688775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007242500475840643\n",
      "Training Loss: 0.006989692815695889\n",
      "Training Loss: 0.007375715019879863\n",
      "Validation Loss: 0.004168082394877847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007235097874654457\n",
      "Training Loss: 0.006981489045429044\n",
      "Training Loss: 0.007367177442647517\n",
      "Validation Loss: 0.004163579379595565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.007227492691017687\n",
      "Training Loss: 0.006973098089802079\n",
      "Training Loss: 0.00735843792790547\n",
      "Validation Loss: 0.004158967687340265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.007219697225955315\n",
      "Training Loss: 0.00696453332551755\n",
      "Training Loss: 0.007349512618966401\n",
      "Validation Loss: 0.00415423280936195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007211722015053965\n",
      "Training Loss: 0.006955809276551008\n",
      "Training Loss: 0.0073404206847772005\n",
      "Validation Loss: 0.004149364325835296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.007203582151560113\n",
      "Training Loss: 0.0069469373190077024\n",
      "Training Loss: 0.00733117678319104\n",
      "Validation Loss: 0.004144344928810436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.0071952859940938654\n",
      "Training Loss: 0.0069379256269894544\n",
      "Training Loss: 0.0073217923194169995\n",
      "Validation Loss: 0.004139161649097302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.007186843996169046\n",
      "Training Loss: 0.006928777748835273\n",
      "Training Loss: 0.007312272872077301\n",
      "Validation Loss: 0.004133800341580273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0071782588167116045\n",
      "Training Loss: 0.006919494436006062\n",
      "Training Loss: 0.007302617684472352\n",
      "Validation Loss: 0.004128244001774139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.007169528939994052\n",
      "Training Loss: 0.006910069739678875\n",
      "Training Loss: 0.0072928185225464405\n",
      "Validation Loss: 0.004122479723274624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.007160651149461046\n",
      "Training Loss: 0.006900493160355836\n",
      "Training Loss: 0.007282864211592823\n",
      "Validation Loss: 0.004116493468225169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.007151612899033353\n",
      "Training Loss: 0.00689075103146024\n",
      "Training Loss: 0.007272734881844371\n",
      "Validation Loss: 0.004110272518578875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.007142402043100447\n",
      "Training Loss: 0.006880827543791383\n",
      "Training Loss: 0.007262409046525135\n",
      "Validation Loss: 0.0041038070575156235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.007132999819004908\n",
      "Training Loss: 0.006870704442262649\n",
      "Training Loss: 0.007251861824188382\n",
      "Validation Loss: 0.0040970882322388085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.007123388388426974\n",
      "Training Loss: 0.006860362265142612\n",
      "Training Loss: 0.007241069051669911\n",
      "Validation Loss: 0.004090106263861395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.00711354533676058\n",
      "Training Loss: 0.006849783587967977\n",
      "Training Loss: 0.007230003996519372\n",
      "Validation Loss: 0.0040828500471465036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.007103453268064186\n",
      "Training Loss: 0.006838950965320691\n",
      "Training Loss: 0.0072186453780159355\n",
      "Validation Loss: 0.004075314538302214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0070930902822874484\n",
      "Training Loss: 0.006827849947148934\n",
      "Training Loss: 0.007206971829291433\n",
      "Validation Loss: 0.004067492548355393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0070824405690655115\n",
      "Training Loss: 0.006816471280762926\n",
      "Training Loss: 0.007194969488773495\n",
      "Validation Loss: 0.004059384871284697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.007071492093382403\n",
      "Training Loss: 0.006804812086629681\n",
      "Training Loss: 0.007182629503076896\n",
      "Validation Loss: 0.004050981033635274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.007060237653786316\n",
      "Training Loss: 0.006792875484097749\n",
      "Training Loss: 0.007169952197000384\n",
      "Validation Loss: 0.0040422957168180455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.007048678054707125\n",
      "Training Loss: 0.006780676385969855\n",
      "Training Loss: 0.007156948428601027\n",
      "Validation Loss: 0.004033338867148824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.007036823969101534\n",
      "Training Loss: 0.006768240488599986\n",
      "Training Loss: 0.007143642366863787\n",
      "Validation Loss: 0.004024132680712959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.007024698234163225\n",
      "Training Loss: 0.006755609721876681\n",
      "Training Loss: 0.0071300761471502485\n",
      "Validation Loss: 0.004014713106300222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.007012339479988441\n",
      "Training Loss: 0.0067428398039191964\n",
      "Training Loss: 0.007116305575473234\n",
      "Validation Loss: 0.004005126048172458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006999799715122208\n",
      "Training Loss: 0.0067300040024565536\n",
      "Training Loss: 0.007102407813072205\n",
      "Validation Loss: 0.0039954383535771056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006987150732893497\n",
      "Training Loss: 0.00671718904923182\n",
      "Training Loss: 0.0070884765253867955\n",
      "Validation Loss: 0.003985730109715395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006974475799361244\n",
      "Training Loss: 0.0067044948163675145\n",
      "Training Loss: 0.007074618643382564\n",
      "Validation Loss: 0.003976092522105809\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006961875081760809\n",
      "Training Loss: 0.006692029879195616\n",
      "Training Loss: 0.0070609524834435436\n",
      "Validation Loss: 0.0039666205215571305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006949451870750636\n",
      "Training Loss: 0.006679899676819332\n",
      "Training Loss: 0.0070475965086370706\n",
      "Validation Loss: 0.00395741895641713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006937313537346199\n",
      "Training Loss: 0.006668205366004258\n",
      "Training Loss: 0.007034662184305489\n",
      "Validation Loss: 0.003948572604508882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0069255553145194425\n",
      "Training Loss: 0.006657029817579314\n",
      "Training Loss: 0.0070222467533312734\n",
      "Validation Loss: 0.003940156447763942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0069142609398113565\n",
      "Training Loss: 0.006646435190341435\n",
      "Training Loss: 0.007010421685408801\n",
      "Validation Loss: 0.003932221198789357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006903489615651779\n",
      "Training Loss: 0.006636457531712949\n",
      "Training Loss: 0.006999233906390146\n",
      "Validation Loss: 0.003924798067355675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006893277309136465\n",
      "Training Loss: 0.006627104831277392\n",
      "Training Loss: 0.006988699855282903\n",
      "Validation Loss: 0.0039178873843963395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006883634655969218\n",
      "Training Loss: 0.0066183630598243325\n",
      "Training Loss: 0.006978812047746033\n",
      "Validation Loss: 0.003911470234383609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006874550879001617\n",
      "Training Loss: 0.006610199274728074\n",
      "Training Loss: 0.00696954186540097\n",
      "Validation Loss: 0.003905512450074547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006865998067078181\n",
      "Training Loss: 0.00660256611474324\n",
      "Training Loss: 0.006960844800341874\n",
      "Validation Loss: 0.0038999772887007237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006857934989384375\n",
      "Training Loss: 0.006595408788416535\n",
      "Training Loss: 0.006952669073361903\n",
      "Validation Loss: 0.003894812647211418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006850314361508935\n",
      "Training Loss: 0.006588670723722316\n",
      "Training Loss: 0.006944955856306478\n",
      "Validation Loss: 0.003889968559888893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006843087361194194\n",
      "Training Loss: 0.006582296525011771\n",
      "Training Loss: 0.006937649786705151\n",
      "Validation Loss: 0.003885396384749185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006836203275597654\n",
      "Training Loss: 0.006576233003288507\n",
      "Training Loss: 0.0069306968653108925\n",
      "Validation Loss: 0.0038810545798349245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006829616181203164\n",
      "Training Loss: 0.006570433165761642\n",
      "Training Loss: 0.006924047629581764\n",
      "Validation Loss: 0.003876906278114138\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006823282084660605\n",
      "Training Loss: 0.006564856609329582\n",
      "Training Loss: 0.006917656667064875\n",
      "Validation Loss: 0.0038729155556497612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006817164652748033\n",
      "Training Loss: 0.006559465879108757\n",
      "Training Loss: 0.006911487503675744\n",
      "Validation Loss: 0.0038690540620408367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0068112274678424\n",
      "Training Loss: 0.006554231913760304\n",
      "Training Loss: 0.006905505325412378\n",
      "Validation Loss: 0.003865301376208663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.00680544508213643\n",
      "Training Loss: 0.006549128981423564\n",
      "Training Loss: 0.006899682518560439\n",
      "Validation Loss: 0.003861636701667828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006799790462246165\n",
      "Training Loss: 0.006544135272270069\n",
      "Training Loss: 0.0068939945357851685\n",
      "Validation Loss: 0.003858038084319887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006794242928735912\n",
      "Training Loss: 0.00653923342411872\n",
      "Training Loss: 0.006888421736657619\n",
      "Validation Loss: 0.0038544991173980274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.00678878476144746\n",
      "Training Loss: 0.0065344088099664075\n",
      "Training Loss: 0.006882945430697873\n",
      "Validation Loss: 0.003851004685222935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006783400573767722\n",
      "Training Loss: 0.0065296502964338286\n",
      "Training Loss: 0.006877552267396823\n",
      "Validation Loss: 0.0038475462502349962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006778077080380172\n",
      "Training Loss: 0.006524946582503617\n",
      "Training Loss: 0.006872229859000072\n",
      "Validation Loss: 0.0038441166705504228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006772802932537161\n",
      "Training Loss: 0.006520290283951909\n",
      "Training Loss: 0.006866967248497531\n",
      "Validation Loss: 0.0038407086185441256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0067675689642783254\n",
      "Training Loss: 0.006515673275571316\n",
      "Training Loss: 0.006861755122663453\n",
      "Validation Loss: 0.0038373171903841783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006762366263428703\n",
      "Training Loss: 0.006511090005515144\n",
      "Training Loss: 0.006856586239300668\n",
      "Validation Loss: 0.0038339355711961226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.00675718902843073\n",
      "Training Loss: 0.006506535764201544\n",
      "Training Loss: 0.0068514543026685715\n",
      "Validation Loss: 0.003830561195918767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006752030585194007\n",
      "Training Loss: 0.006502006287337281\n",
      "Training Loss: 0.006846352376742288\n",
      "Validation Loss: 0.0038271912104146702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006746884398162365\n",
      "Training Loss: 0.006497496876399964\n",
      "Training Loss: 0.0068412759981583806\n",
      "Validation Loss: 0.003823821587236912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006741746895713731\n",
      "Training Loss: 0.0064930053369607775\n",
      "Training Loss: 0.00683621912728995\n",
      "Validation Loss: 0.003820450878388175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.0067366132413735616\n",
      "Training Loss: 0.006488528114859946\n",
      "Training Loss: 0.006831179079599678\n",
      "Validation Loss: 0.0038170744364118474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006731480478774757\n",
      "Training Loss: 0.006484063506941311\n",
      "Training Loss: 0.006826151969144121\n",
      "Validation Loss: 0.0038136928826256584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006726344430935569\n",
      "Training Loss: 0.006479608188383282\n",
      "Training Loss: 0.006821133340708912\n",
      "Validation Loss: 0.0038103017252294367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.0067212023597676305\n",
      "Training Loss: 0.006475160185364075\n",
      "Training Loss: 0.00681612117215991\n",
      "Validation Loss: 0.0038069005051020828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006716051631374284\n",
      "Training Loss: 0.006470718142809346\n",
      "Training Loss: 0.00681111087440513\n",
      "Validation Loss: 0.0038034896329673155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006710890363901854\n",
      "Training Loss: 0.0064662803884129975\n",
      "Training Loss: 0.006806101439287886\n",
      "Validation Loss: 0.0038000638151980855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006705714719137177\n",
      "Training Loss: 0.00646184483775869\n",
      "Training Loss: 0.006801089803921059\n",
      "Validation Loss: 0.0037966245717337625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006700524149928242\n",
      "Training Loss: 0.006457409850554541\n",
      "Training Loss: 0.0067960728413891044\n",
      "Validation Loss: 0.003793170058241721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006695316028781235\n",
      "Training Loss: 0.006452974476269446\n",
      "Training Loss: 0.006791050265310333\n",
      "Validation Loss: 0.003789697775062634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00669008910190314\n",
      "Training Loss: 0.006448536631069146\n",
      "Training Loss: 0.006786017896374687\n",
      "Validation Loss: 0.003786208517483195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006684841114329174\n",
      "Training Loss: 0.006444096004706808\n",
      "Training Loss: 0.006780975314322859\n",
      "Validation Loss: 0.003782700451635075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006679571068380028\n",
      "Training Loss: 0.0064396503026364375\n",
      "Training Loss: 0.006775919937063009\n",
      "Validation Loss: 0.003779171895382277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.00667427756707184\n",
      "Training Loss: 0.006435199350817129\n",
      "Training Loss: 0.006770850382745266\n",
      "Validation Loss: 0.0037756242273961392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0066689597198273986\n",
      "Training Loss: 0.0064307413157075645\n",
      "Training Loss: 0.006765764584997669\n",
      "Validation Loss: 0.0037720549990307916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.00666361614712514\n",
      "Training Loss: 0.006426276662386954\n",
      "Training Loss: 0.006760662198066711\n",
      "Validation Loss: 0.0037684600638079172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006658245155122131\n",
      "Training Loss: 0.006421802650438621\n",
      "Training Loss: 0.0067555410298518834\n",
      "Validation Loss: 0.0037648457578603137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.0066528472397476435\n",
      "Training Loss: 0.006417319579049945\n",
      "Training Loss: 0.006750400048913434\n",
      "Validation Loss: 0.003761204197647029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0066474201530218125\n",
      "Training Loss: 0.006412826055893674\n",
      "Training Loss: 0.006745237834984437\n",
      "Validation Loss: 0.003757539629057217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006641964102163911\n",
      "Training Loss: 0.006408321546041406\n",
      "Training Loss: 0.0067400529375299814\n",
      "Validation Loss: 0.003753849161328392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006636478696600534\n",
      "Training Loss: 0.006403805789304897\n",
      "Training Loss: 0.006734844809398055\n",
      "Validation Loss: 0.003750133453711365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006630961195915006\n",
      "Training Loss: 0.006399277276941575\n",
      "Training Loss: 0.006729612173512578\n",
      "Validation Loss: 0.0037463885546253806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006625413538422435\n",
      "Training Loss: 0.00639473540999461\n",
      "Training Loss: 0.006724354168400168\n",
      "Validation Loss: 0.0037426206537030555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006619834416778758\n",
      "Training Loss: 0.006390180115122348\n",
      "Training Loss: 0.006719070869730785\n",
      "Validation Loss: 0.0037388210538042226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006614223513170145\n",
      "Training Loss: 0.0063856109487824145\n",
      "Training Loss: 0.006713760488200933\n",
      "Validation Loss: 0.00373499558746731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006608581584296189\n",
      "Training Loss: 0.006381027084426023\n",
      "Training Loss: 0.006708422624506057\n",
      "Validation Loss: 0.0037311399093923276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006602905567851849\n",
      "Training Loss: 0.006376428243238479\n",
      "Training Loss: 0.006703056574333459\n",
      "Validation Loss: 0.0037272543256600082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006597198792151176\n",
      "Training Loss: 0.006371813828591258\n",
      "Training Loss: 0.006697662775404751\n",
      "Validation Loss: 0.003723337515152656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006591458071488887\n",
      "Training Loss: 0.006367183640250005\n",
      "Training Loss: 0.006692239888943732\n",
      "Validation Loss: 0.0037193919304402525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006585686199832708\n",
      "Training Loss: 0.0063625380466692145\n",
      "Training Loss: 0.0066867872199509295\n",
      "Validation Loss: 0.003715413036557396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006579881330253556\n",
      "Training Loss: 0.0063578752765897665\n",
      "Training Loss: 0.006681305686943233\n",
      "Validation Loss: 0.003711402561421391\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006574044495937415\n",
      "Training Loss: 0.006353196821874007\n",
      "Training Loss: 0.006675794809125364\n",
      "Validation Loss: 0.003707359244084258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006568175854627043\n",
      "Training Loss: 0.006348501779139042\n",
      "Training Loss: 0.006670253883348778\n",
      "Validation Loss: 0.0037032867627469507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006562275459291413\n",
      "Training Loss: 0.0063437894929666075\n",
      "Training Loss: 0.00666468228911981\n",
      "Validation Loss: 0.003699179194616468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006556343557313085\n",
      "Training Loss: 0.006339061225298792\n",
      "Training Loss: 0.00665908228023909\n",
      "Validation Loss: 0.0036950394958571602\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0065503808320499955\n",
      "Training Loss: 0.006334315807325765\n",
      "Training Loss: 0.0066534522420261056\n",
      "Validation Loss: 0.0036908639045536854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006544388168840669\n",
      "Training Loss: 0.006329554778640159\n",
      "Training Loss: 0.006647793342126534\n",
      "Validation Loss: 0.0036866537130469186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006538365897140466\n",
      "Training Loss: 0.0063247771275928245\n",
      "Training Loss: 0.006642104937345721\n",
      "Validation Loss: 0.003682414373236426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006532314388896339\n",
      "Training Loss: 0.006319982890272513\n",
      "Training Loss: 0.006636387971229851\n",
      "Validation Loss: 0.0036781368805932696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006526234701741487\n",
      "Training Loss: 0.00631517272151541\n",
      "Training Loss: 0.006630643067182973\n",
      "Validation Loss: 0.0036738248426843893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.00652012747945264\n",
      "Training Loss: 0.006310346879763529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [09:39<14:28, 144.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006624870589002967\n",
      "Validation Loss: 0.003669477714058221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.22969355762004853\n",
      "Training Loss: 0.1614959966018796\n",
      "Training Loss: 0.11264144640415907\n",
      "Validation Loss: 0.07839036456654581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06979629997164011\n",
      "Training Loss: 0.061130773797631266\n",
      "Training Loss: 0.057895087003707886\n",
      "Validation Loss: 0.05383797061074985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.054797751847654584\n",
      "Training Loss: 0.05333465356379748\n",
      "Training Loss: 0.05235098673030734\n",
      "Validation Loss: 0.048651394800523697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.049230403648689386\n",
      "Training Loss: 0.047310291128233074\n",
      "Training Loss: 0.046270131589844825\n",
      "Validation Loss: 0.042780282268865724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04277998331002891\n",
      "Training Loss: 0.04060104005038738\n",
      "Training Loss: 0.03968895030207932\n",
      "Validation Loss: 0.036540834044807416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.03622815609909594\n",
      "Training Loss: 0.034095621453598145\n",
      "Training Loss: 0.03343925702385604\n",
      "Validation Loss: 0.030675354047437733\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03038855823688209\n",
      "Training Loss: 0.028507734038867055\n",
      "Training Loss: 0.028099619513377548\n",
      "Validation Loss: 0.02568918981411484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.025620068632997574\n",
      "Training Loss: 0.02403504541143775\n",
      "Training Loss: 0.023787961089983583\n",
      "Validation Loss: 0.02163607682614179\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.021847950113005936\n",
      "Training Loss: 0.020516487220302224\n",
      "Training Loss: 0.020348596796393396\n",
      "Validation Loss: 0.018333753581378568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.018855670662596823\n",
      "Training Loss: 0.01772643965901807\n",
      "Training Loss: 0.01760403138352558\n",
      "Validation Loss: 0.015617050978700432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01647241544444114\n",
      "Training Loss: 0.015505640655755997\n",
      "Training Loss: 0.015429869033396245\n",
      "Validation Loss: 0.013388431992046954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.014586239329073578\n",
      "Training Loss: 0.01374925410374999\n",
      "Training Loss: 0.013733340753242373\n",
      "Validation Loss: 0.01158185652718785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013112910601776093\n",
      "Training Loss: 0.012376401878427715\n",
      "Training Loss: 0.012431983496062457\n",
      "Validation Loss: 0.010135974494342724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.01197459123795852\n",
      "Training Loss: 0.011311804074794055\n",
      "Training Loss: 0.011442787740379571\n",
      "Validation Loss: 0.008985272158732575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.011093630436807871\n",
      "Training Loss: 0.01048274627304636\n",
      "Training Loss: 0.010685281931655482\n",
      "Validation Loss: 0.008065877885170531\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.01039949013153091\n",
      "Training Loss: 0.009825967511860654\n",
      "Training Loss: 0.01009129931917414\n",
      "Validation Loss: 0.007324193549352918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009837082080775873\n",
      "Training Loss: 0.009294029829325154\n",
      "Training Loss: 0.009612247751792893\n",
      "Validation Loss: 0.0067216840080833165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00937160564819351\n",
      "Training Loss: 0.008858290147036313\n",
      "Training Loss: 0.009221257076133043\n",
      "Validation Loss: 0.006235449030744225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008987883680965751\n",
      "Training Loss: 0.008506243794690817\n",
      "Training Loss: 0.008907632713671773\n",
      "Validation Loss: 0.005852744796867954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008681679689325393\n",
      "Training Loss: 0.008232011091895402\n",
      "Training Loss: 0.008665148777654395\n",
      "Validation Loss: 0.005560986184923167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008447766120079905\n",
      "Training Loss: 0.00802670679986477\n",
      "Training Loss: 0.008483757156645878\n",
      "Validation Loss: 0.005342920140750455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00827473718789406\n",
      "Training Loss: 0.007876499011181294\n",
      "Training Loss: 0.008349763413425535\n",
      "Validation Loss: 0.005179602053707068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008147776530822739\n",
      "Training Loss: 0.007766303432872519\n",
      "Training Loss: 0.008249568333849312\n",
      "Validation Loss: 0.005054607325536984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008052993917372077\n",
      "Training Loss: 0.007683311876608059\n",
      "Training Loss: 0.008172180918045342\n",
      "Validation Loss: 0.004955750661169629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007979634638177231\n",
      "Training Loss: 0.0076182066241744905\n",
      "Training Loss: 0.00810977241373621\n",
      "Validation Loss: 0.004874800845949251\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007920244456036016\n",
      "Training Loss: 0.007564787825103849\n",
      "Training Loss: 0.008057154775597155\n",
      "Validation Loss: 0.004806417333527228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007869953342014924\n",
      "Training Loss: 0.00751911930157803\n",
      "Training Loss: 0.008011019588448107\n",
      "Validation Loss: 0.004747178129527425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007825677884975448\n",
      "Training Loss: 0.007478746514534578\n",
      "Training Loss: 0.007969293354544788\n",
      "Validation Loss: 0.00469484108269968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007785482201725245\n",
      "Training Loss: 0.0074421399924904106\n",
      "Training Loss: 0.007930679330602288\n",
      "Validation Loss: 0.004647896264083265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007748158182948828\n",
      "Training Loss: 0.007408341089030728\n",
      "Training Loss: 0.007894373491872102\n",
      "Validation Loss: 0.004605289747457156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007712954903254286\n",
      "Training Loss: 0.007376742125488818\n",
      "Training Loss: 0.00785987651674077\n",
      "Validation Loss: 0.0045662621700654875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007679411106510088\n",
      "Training Loss: 0.007346959131537005\n",
      "Training Loss: 0.007826888767303898\n",
      "Validation Loss: 0.004530254971194133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007647250096779317\n",
      "Training Loss: 0.007318740680348128\n",
      "Training Loss: 0.007795224969740957\n",
      "Validation Loss: 0.004496840833361899\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007616306914715096\n",
      "Training Loss: 0.0072919233446009455\n",
      "Training Loss: 0.007764779271092266\n",
      "Validation Loss: 0.004465697691618894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007586487433873117\n",
      "Training Loss: 0.007266391174634918\n",
      "Training Loss: 0.007735482841962948\n",
      "Validation Loss: 0.004436564533657321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007557734098518267\n",
      "Training Loss: 0.0072420586412772535\n",
      "Training Loss: 0.0077072872780263426\n",
      "Validation Loss: 0.004409241152592422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007530006396118552\n",
      "Training Loss: 0.0072188508044928315\n",
      "Training Loss: 0.0076801536313723774\n",
      "Validation Loss: 0.004383556429673446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0075032705161720515\n",
      "Training Loss: 0.0071967018215218555\n",
      "Training Loss: 0.007654037594329565\n",
      "Validation Loss: 0.004359366741094194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007477490466553718\n",
      "Training Loss: 0.007175543543417007\n",
      "Training Loss: 0.007628895347006619\n",
      "Validation Loss: 0.004336543369441806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00745262294774875\n",
      "Training Loss: 0.007155308337532915\n",
      "Training Loss: 0.007604677579365671\n",
      "Validation Loss: 0.004314974155747907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0074286233598832045\n",
      "Training Loss: 0.007135928414063528\n",
      "Training Loss: 0.0075813278357964005\n",
      "Validation Loss: 0.004294549536190174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00740544079686515\n",
      "Training Loss: 0.0071173350582830605\n",
      "Training Loss: 0.007558789991308003\n",
      "Validation Loss: 0.0042751722451132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.0073830194177571685\n",
      "Training Loss: 0.00709945954149589\n",
      "Training Loss: 0.007537002685712651\n",
      "Validation Loss: 0.004256749287603444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007361303989309818\n",
      "Training Loss: 0.007082233874243684\n",
      "Training Loss: 0.007515905612381175\n",
      "Validation Loss: 0.004239191948645487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007340234585572034\n",
      "Training Loss: 0.007065592213766649\n",
      "Training Loss: 0.007495433657895774\n",
      "Validation Loss: 0.00422242074142723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007319750537863001\n",
      "Training Loss: 0.007049470848287455\n",
      "Training Loss: 0.00747552816872485\n",
      "Validation Loss: 0.004206359046354388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007299795775907114\n",
      "Training Loss: 0.007033809379208833\n",
      "Training Loss: 0.0074561284121591595\n",
      "Validation Loss: 0.004190933751988779\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00728031071019359\n",
      "Training Loss: 0.007018548870109953\n",
      "Training Loss: 0.007437177270185202\n",
      "Validation Loss: 0.004176081643502615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007261241562664509\n",
      "Training Loss: 0.007003636006847955\n",
      "Training Loss: 0.007418620879761874\n",
      "Validation Loss: 0.0041617424661565695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007242535138502717\n",
      "Training Loss: 0.006989019695902243\n",
      "Training Loss: 0.007400407225359232\n",
      "Validation Loss: 0.004147855601576942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007224145155632868\n",
      "Training Loss: 0.0069746527180541305\n",
      "Training Loss: 0.0073824898130260405\n",
      "Validation Loss: 0.004134374626211069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.0072060250758659095\n",
      "Training Loss: 0.006960492853540928\n",
      "Training Loss: 0.007364823295501992\n",
      "Validation Loss: 0.004121249631894857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007188131808070466\n",
      "Training Loss: 0.006946499806363135\n",
      "Training Loss: 0.007347367635229602\n",
      "Validation Loss: 0.004108441268941492\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007170428510289639\n",
      "Training Loss: 0.006932636913843453\n",
      "Training Loss: 0.007330086693400517\n",
      "Validation Loss: 0.004095911476080924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007152880872599781\n",
      "Training Loss: 0.006918872101232409\n",
      "Training Loss: 0.007312946454621851\n",
      "Validation Loss: 0.0040836279918805935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007135458546690643\n",
      "Training Loss: 0.006905177677981556\n",
      "Training Loss: 0.00729591753333807\n",
      "Validation Loss: 0.00407155438880907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007118134230840951\n",
      "Training Loss: 0.006891526257968508\n",
      "Training Loss: 0.007278974464861676\n",
      "Validation Loss: 0.004059670278488585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007100889065768569\n",
      "Training Loss: 0.006877897517406382\n",
      "Training Loss: 0.007262097195489332\n",
      "Validation Loss: 0.004047947404696868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007083702594973147\n",
      "Training Loss: 0.006864274268154986\n",
      "Training Loss: 0.007245266473619267\n",
      "Validation Loss: 0.004036372578493581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007066563455155119\n",
      "Training Loss: 0.006850641652708873\n",
      "Training Loss: 0.007228470765985548\n",
      "Validation Loss: 0.004024925652179825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007049461997230538\n",
      "Training Loss: 0.006836991418967955\n",
      "Training Loss: 0.007211700937477872\n",
      "Validation Loss: 0.004013592120929716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0070323949004523455\n",
      "Training Loss: 0.006823316367808729\n",
      "Training Loss: 0.007194953123107552\n",
      "Validation Loss: 0.004002365249659071\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007015361210214906\n",
      "Training Loss: 0.006809614569065161\n",
      "Training Loss: 0.0071782276616431774\n",
      "Validation Loss: 0.003991231560351306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0069983684917679055\n",
      "Training Loss: 0.006795889165950939\n",
      "Training Loss: 0.007161529496079311\n",
      "Validation Loss: 0.003980185818241051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006981423972174525\n",
      "Training Loss: 0.0067821455054217945\n",
      "Training Loss: 0.0071448674891144036\n",
      "Validation Loss: 0.003969225704178131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006964541804045439\n",
      "Training Loss: 0.006768394179525785\n",
      "Training Loss: 0.00712825539521873\n",
      "Validation Loss: 0.003958346320870804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006947741161566228\n",
      "Training Loss: 0.006754649392096326\n",
      "Training Loss: 0.0071117098990362134\n",
      "Validation Loss: 0.003947544897896018\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00693104141682852\n",
      "Training Loss: 0.0067409274290548635\n",
      "Training Loss: 0.007095251744613051\n",
      "Validation Loss: 0.003936827235091268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006914467929163948\n",
      "Training Loss: 0.0067272486875299365\n",
      "Training Loss: 0.007078903297660873\n",
      "Validation Loss: 0.0039261803632664885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006898042308166623\n",
      "Training Loss: 0.006713633187464438\n",
      "Training Loss: 0.00706268995651044\n",
      "Validation Loss: 0.0039156148199703585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0068817946861963715\n",
      "Training Loss: 0.006700105961062946\n",
      "Training Loss: 0.007046636596787721\n",
      "Validation Loss: 0.0039051243606326954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006865748534910381\n",
      "Training Loss: 0.006686689518392086\n",
      "Training Loss: 0.007030768451513723\n",
      "Validation Loss: 0.003894709835477759\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006849930939497426\n",
      "Training Loss: 0.006673407155321911\n",
      "Training Loss: 0.007015109866624698\n",
      "Validation Loss: 0.0038843727095073527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00683436281979084\n",
      "Training Loss: 0.006660280891810544\n",
      "Training Loss: 0.006999683059984818\n",
      "Validation Loss: 0.0038741124425020613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006819065851159394\n",
      "Training Loss: 0.006647331331623718\n",
      "Training Loss: 0.006984505424043164\n",
      "Validation Loss: 0.0038639218258681926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006804056100663729\n",
      "Training Loss: 0.006634575854986906\n",
      "Training Loss: 0.006969594596885145\n",
      "Validation Loss: 0.003853804332444842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006789348259335384\n",
      "Training Loss: 0.0066220298473490405\n",
      "Training Loss: 0.006954964123433455\n",
      "Validation Loss: 0.0038437555266774438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006774952632258646\n",
      "Training Loss: 0.006609704366419464\n",
      "Training Loss: 0.006940621165558696\n",
      "Validation Loss: 0.0038337752686060044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006760872516315431\n",
      "Training Loss: 0.006597607323201373\n",
      "Training Loss: 0.006926570680225268\n",
      "Validation Loss: 0.0038238609683166227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006747112383018248\n",
      "Training Loss: 0.0065857434459030625\n",
      "Training Loss: 0.0069128135277424\n",
      "Validation Loss: 0.003814012166688198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.00673367028706707\n",
      "Training Loss: 0.0065741170180263\n",
      "Training Loss: 0.006899349438026547\n",
      "Validation Loss: 0.0038042355137824844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006720543751725927\n",
      "Training Loss: 0.006562726476113312\n",
      "Training Loss: 0.0068861729640048\n",
      "Validation Loss: 0.0037945212254803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006707724234438502\n",
      "Training Loss: 0.006551566431298852\n",
      "Training Loss: 0.006873277175473049\n",
      "Validation Loss: 0.0037848716327041555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006695203472627326\n",
      "Training Loss: 0.006540632812539115\n",
      "Training Loss: 0.0068606512236874554\n",
      "Validation Loss: 0.0037752898982883003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006682972273556516\n",
      "Training Loss: 0.006529918382875621\n",
      "Training Loss: 0.006848286888562143\n",
      "Validation Loss: 0.003765778359695432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006671018297784031\n",
      "Training Loss: 0.006519414542126469\n",
      "Training Loss: 0.006836171579780057\n",
      "Validation Loss: 0.0037563329580857347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0066593304486013945\n",
      "Training Loss: 0.006509112430503592\n",
      "Training Loss: 0.006824293218087405\n",
      "Validation Loss: 0.003746956758190658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006647895889473148\n",
      "Training Loss: 0.006499000498442911\n",
      "Training Loss: 0.006812639238778502\n",
      "Validation Loss: 0.003737647825423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00663670040317811\n",
      "Training Loss: 0.006489068204537034\n",
      "Training Loss: 0.006801195839652791\n",
      "Validation Loss: 0.003728406376916957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006625732170650735\n",
      "Training Loss: 0.006479304536478594\n",
      "Training Loss: 0.00678995099151507\n",
      "Validation Loss: 0.0037192322203910416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006614977944409474\n",
      "Training Loss: 0.0064696977939456704\n",
      "Training Loss: 0.006778889819979667\n",
      "Validation Loss: 0.0037101214304252456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006604424681281671\n",
      "Training Loss: 0.006460236178245395\n",
      "Training Loss: 0.006768000189913437\n",
      "Validation Loss: 0.003701073441947444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006594059283379465\n",
      "Training Loss: 0.006450909377308562\n",
      "Training Loss: 0.006757270413218066\n",
      "Validation Loss: 0.003692087586550565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006583870329195634\n",
      "Training Loss: 0.006441707223420963\n",
      "Training Loss: 0.0067466879182029515\n",
      "Validation Loss: 0.0036831537740346925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006573846213286743\n",
      "Training Loss: 0.006432618870167062\n",
      "Training Loss: 0.0067362410330679265\n",
      "Validation Loss: 0.0036742769409326857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006563975705066696\n",
      "Training Loss: 0.006423634056118317\n",
      "Training Loss: 0.006725919434102252\n",
      "Validation Loss: 0.0036654485823858656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006554249034379609\n",
      "Training Loss: 0.006414745584479533\n",
      "Training Loss: 0.00671571365557611\n",
      "Validation Loss: 0.003656669423046909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006544656387995928\n",
      "Training Loss: 0.006405945898732171\n",
      "Training Loss: 0.006705615964019671\n",
      "Validation Loss: 0.0036479335558192616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006535189354326576\n",
      "Training Loss: 0.006397229865542613\n",
      "Training Loss: 0.006695619124220684\n",
      "Validation Loss: 0.0036392416530341078\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006525843041599728\n",
      "Training Loss: 0.006388591510476545\n",
      "Training Loss: 0.006685717976070009\n",
      "Validation Loss: 0.0036305917277827523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006516609464306385\n",
      "Training Loss: 0.0063800272025400775\n",
      "Training Loss: 0.00667590567143634\n",
      "Validation Loss: 0.0036219857225006217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006507484112516977\n",
      "Training Loss: 0.006371536068036221\n",
      "Training Loss: 0.0066661823773756625\n",
      "Validation Loss: 0.003613427376866424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006498463251627982\n",
      "Training Loss: 0.006363116865395568\n",
      "Training Loss: 0.006656544834841043\n",
      "Validation Loss: 0.0036049167196569817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006489546726224944\n",
      "Training Loss: 0.0063547710957936945\n",
      "Training Loss: 0.006646993369795382\n",
      "Validation Loss: 0.0035964562125985373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.00648073140589986\n",
      "Training Loss: 0.006346500010695308\n",
      "Training Loss: 0.006637528900755569\n",
      "Validation Loss: 0.0035880540139198807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006472018749918789\n",
      "Training Loss: 0.006338306542602368\n",
      "Training Loss: 0.006628155073849484\n",
      "Validation Loss: 0.003579721472152833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006463407819392159\n",
      "Training Loss: 0.0063301957852672786\n",
      "Training Loss: 0.006618873929255642\n",
      "Validation Loss: 0.0035714622105607824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006454900703974999\n",
      "Training Loss: 0.006322171686333604\n",
      "Training Loss: 0.006609689519973472\n",
      "Validation Loss: 0.003563285146034166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006446499167941511\n",
      "Training Loss: 0.006314237102633342\n",
      "Training Loss: 0.006600606592837721\n",
      "Validation Loss: 0.003555198701025311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006438204744481482\n",
      "Training Loss: 0.006306398173910566\n",
      "Training Loss: 0.006591627878369763\n",
      "Validation Loss: 0.0035472189369245193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.0064300173352239655\n",
      "Training Loss: 0.006298656950821169\n",
      "Training Loss: 0.006582756407442503\n",
      "Validation Loss: 0.003539350297134579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006421939950669185\n",
      "Training Loss: 0.006291016989271156\n",
      "Training Loss: 0.006573996781371534\n",
      "Validation Loss: 0.0035315971505001523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00641397089115344\n",
      "Training Loss: 0.006283479990670458\n",
      "Training Loss: 0.006565350265009329\n",
      "Validation Loss: 0.0035239724976042015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006406111036194488\n",
      "Training Loss: 0.006276047668652609\n",
      "Training Loss: 0.006556817694799975\n",
      "Validation Loss: 0.0035164821343601086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006398359123268165\n",
      "Training Loss: 0.006268718909122981\n",
      "Training Loss: 0.0065484009240753946\n",
      "Validation Loss: 0.003509125699749572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006390712438151241\n",
      "Training Loss: 0.00626149216957856\n",
      "Training Loss: 0.006540097405668348\n",
      "Validation Loss: 0.003501909625392114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006383167652529664\n",
      "Training Loss: 0.006254365831846371\n",
      "Training Loss: 0.0065319060481851925\n",
      "Validation Loss: 0.0034948340721763253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.00637572092236951\n",
      "Training Loss: 0.006247335285879671\n",
      "Training Loss: 0.006523822381859645\n",
      "Validation Loss: 0.003487897936118704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006368367535760627\n",
      "Training Loss: 0.006240395171917043\n",
      "Training Loss: 0.006515844383975491\n",
      "Validation Loss: 0.0034810977116792223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0063611033215420325\n",
      "Training Loss: 0.006233541434048675\n",
      "Training Loss: 0.00650796604109928\n",
      "Validation Loss: 0.0034744316630923515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0063539218751247975\n",
      "Training Loss: 0.006226768134511076\n",
      "Training Loss: 0.006500183843309059\n",
      "Validation Loss: 0.003467893687055938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0063468175602611155\n",
      "Training Loss: 0.0062200687901349735\n",
      "Training Loss: 0.006492490828968585\n",
      "Validation Loss: 0.0034614843551822928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006339783653384074\n",
      "Training Loss: 0.0062134373368462545\n",
      "Training Loss: 0.0064848806394729765\n",
      "Validation Loss: 0.0034551903817363165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006332814933266491\n",
      "Training Loss: 0.006206866424181498\n",
      "Training Loss: 0.006477349242777564\n",
      "Validation Loss: 0.003449010236314341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0063259049295447765\n",
      "Training Loss: 0.00620035148691386\n",
      "Training Loss: 0.006469889399595558\n",
      "Validation Loss: 0.0034429346174629553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006319048840086907\n",
      "Training Loss: 0.006193885231623426\n",
      "Training Loss: 0.006462494485313073\n",
      "Validation Loss: 0.0034369537698397978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0063122387469047685\n",
      "Training Loss: 0.006187460902146995\n",
      "Training Loss: 0.006455159779288806\n",
      "Validation Loss: 0.003431065464549269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006305471315863542\n",
      "Training Loss: 0.006181073870975524\n",
      "Training Loss: 0.006447879199404269\n",
      "Validation Loss: 0.0034252583491354346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006298740209313109\n",
      "Training Loss: 0.006174718266702257\n",
      "Training Loss: 0.006440647082054056\n",
      "Validation Loss: 0.0034195291456567607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006292041566921398\n",
      "Training Loss: 0.006168390375678428\n",
      "Training Loss: 0.0064334592345403506\n",
      "Validation Loss: 0.0034138681249316323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006285370595869608\n",
      "Training Loss: 0.006162084395182319\n",
      "Training Loss: 0.006426309478119947\n",
      "Validation Loss: 0.003408269955399917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0062787235772702845\n",
      "Training Loss: 0.006155796400271356\n",
      "Training Loss: 0.006419193719048053\n",
      "Validation Loss: 0.0034027270674496218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006272096614702604\n",
      "Training Loss: 0.006149522768100724\n",
      "Training Loss: 0.006412108360091224\n",
      "Validation Loss: 0.003397235767183344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00626548684143927\n",
      "Training Loss: 0.00614326091716066\n",
      "Training Loss: 0.006405049001914449\n",
      "Validation Loss: 0.003391790080794625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006258890755125321\n",
      "Training Loss: 0.006137005725759081\n",
      "Training Loss: 0.006398013519938104\n",
      "Validation Loss: 0.003386386846757253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006252307690447196\n",
      "Training Loss: 0.006130757220089436\n",
      "Training Loss: 0.006390997357084416\n",
      "Validation Loss: 0.003381021617744327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006245733227697201\n",
      "Training Loss: 0.0061245124321430925\n",
      "Training Loss: 0.00638399863790255\n",
      "Validation Loss: 0.0033756924866374287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006239167972235009\n",
      "Training Loss: 0.0061182681255741046\n",
      "Training Loss: 0.006377014326862991\n",
      "Validation Loss: 0.0033703902226171634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.0062326093978481364\n",
      "Training Loss: 0.006112024916219525\n",
      "Training Loss: 0.00637004295247607\n",
      "Validation Loss: 0.0033651176915933073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.0062260566331679\n",
      "Training Loss: 0.006105780267971568\n",
      "Training Loss: 0.006363082047901116\n",
      "Validation Loss: 0.0033598712977712577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006219507739879191\n",
      "Training Loss: 0.006099533357773908\n",
      "Training Loss: 0.006356131129432469\n",
      "Validation Loss: 0.0033546447481834487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006212965290760621\n",
      "Training Loss: 0.006093283194350079\n",
      "Training Loss: 0.006349188195890747\n",
      "Validation Loss: 0.0033494382704283747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00620642707683146\n",
      "Training Loss: 0.006087030930793844\n",
      "Training Loss: 0.006342253697803244\n",
      "Validation Loss: 0.003344252133961725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006199894006131217\n",
      "Training Loss: 0.006080775870941579\n",
      "Training Loss: 0.006335326739354059\n",
      "Validation Loss: 0.003339085162857945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006193368425010703\n",
      "Training Loss: 0.006074518849491142\n",
      "Training Loss: 0.006328407478285954\n",
      "Validation Loss: 0.003333936712254634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006186850221129134\n",
      "Training Loss: 0.0060682598821586\n",
      "Training Loss: 0.0063214958825847135\n",
      "Validation Loss: 0.00332880795153716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006180340782739222\n",
      "Training Loss: 0.006062001286773011\n",
      "Training Loss: 0.006314594583818689\n",
      "Validation Loss: 0.003323697827735476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006173842949210666\n",
      "Training Loss: 0.006055744652403518\n",
      "Training Loss: 0.006307702740305104\n",
      "Validation Loss: 0.0033186074173643014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006167359031387605\n",
      "Training Loss: 0.006049490393488668\n",
      "Training Loss: 0.006300822554039769\n",
      "Validation Loss: 0.003313533696241342\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006160890031605959\n",
      "Training Loss: 0.006043242039741017\n",
      "Training Loss: 0.006293956090812572\n",
      "Validation Loss: 0.0033084837330002964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006154440600657836\n",
      "Training Loss: 0.00603700132924132\n",
      "Training Loss: 0.006287106911186129\n",
      "Validation Loss: 0.003303453593064895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0061480135400779545\n",
      "Training Loss: 0.0060307706316234545\n",
      "Training Loss: 0.00628027677827049\n",
      "Validation Loss: 0.0032984472581007508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0061416117637418215\n",
      "Training Loss: 0.006024553314782679\n",
      "Training Loss: 0.0062734677799744535\n",
      "Validation Loss: 0.0032934670838830845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006135240259463898\n",
      "Training Loss: 0.0060183523921296\n",
      "Training Loss: 0.006266684574075043\n",
      "Validation Loss: 0.003288513738818969\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0061289016564842315\n",
      "Training Loss: 0.0060121711378451435\n",
      "Training Loss: 0.006259928975487128\n",
      "Validation Loss: 0.003283589407984753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006122601099777966\n",
      "Training Loss: 0.006006012712023221\n",
      "Training Loss: 0.0062532063730759545\n",
      "Validation Loss: 0.0032786977597711125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006116341585293412\n",
      "Training Loss: 0.005999882037867792\n",
      "Training Loss: 0.00624652023485396\n",
      "Validation Loss: 0.00327384109959383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006110128390137106\n",
      "Training Loss: 0.005993780550197698\n",
      "Training Loss: 0.006239872024743818\n",
      "Validation Loss: 0.003269020365969686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006103965403744951\n",
      "Training Loss: 0.005987713964423165\n",
      "Training Loss: 0.006233269619406201\n",
      "Validation Loss: 0.0032642405869941532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00609785724314861\n",
      "Training Loss: 0.005981684903381392\n",
      "Training Loss: 0.006226714216172696\n",
      "Validation Loss: 0.0032595031871198773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006091808323399164\n",
      "Training Loss: 0.005975696460227482\n",
      "Training Loss: 0.006220210820902139\n",
      "Validation Loss: 0.003254807265109142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006085822533350438\n",
      "Training Loss: 0.0059697541751666\n",
      "Training Loss: 0.006213764260755852\n",
      "Validation Loss: 0.003250157208119132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.0060799044877057895\n",
      "Training Loss: 0.005963860120973549\n",
      "Training Loss: 0.0062073773529846225\n",
      "Validation Loss: 0.0032455597433858037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006074056685902178\n",
      "Training Loss: 0.005958017786615528\n",
      "Training Loss: 0.006201053434051573\n",
      "Validation Loss: 0.003241013860450325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.0060682841262314465\n",
      "Training Loss: 0.0059522305330028755\n",
      "Training Loss: 0.006194796625059098\n",
      "Validation Loss: 0.0032365206116287226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006062588670756668\n",
      "Training Loss: 0.005946500139543787\n",
      "Training Loss: 0.006188609454547986\n",
      "Validation Loss: 0.0032320835253516777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006056974781677127\n",
      "Training Loss: 0.005940832032938488\n",
      "Training Loss: 0.006182495353277773\n",
      "Validation Loss: 0.00322770176120521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006051444014301524\n",
      "Training Loss: 0.005935224672430195\n",
      "Training Loss: 0.006176456943503581\n",
      "Validation Loss: 0.0032233799339449975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006045998951303772\n",
      "Training Loss: 0.0059296830673702065\n",
      "Training Loss: 0.0061704950744751845\n",
      "Validation Loss: 0.0032191177401063816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006040642933221534\n",
      "Training Loss: 0.005924208400538191\n",
      "Training Loss: 0.0061646152497269215\n",
      "Validation Loss: 0.0032149159383510102\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.00603537566435989\n",
      "Training Loss: 0.005918801741790958\n",
      "Training Loss: 0.00615881560894195\n",
      "Validation Loss: 0.0032107762539801137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006030199506203644\n",
      "Training Loss: 0.005913465010235086\n",
      "Training Loss: 0.006153098166687414\n",
      "Validation Loss: 0.0032066980212026937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006025114795193076\n",
      "Training Loss: 0.00590819776058197\n",
      "Training Loss: 0.0061474646598799155\n",
      "Validation Loss: 0.0032026852648495956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006020122797344811\n",
      "Training Loss: 0.0059030014195013795\n",
      "Training Loss: 0.0061419148597633465\n",
      "Validation Loss: 0.0031987345388964908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006015223393333145\n",
      "Training Loss: 0.005897876872331835\n",
      "Training Loss: 0.006136449322802946\n",
      "Validation Loss: 0.003194850525462979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006010416160570457\n",
      "Training Loss: 0.005892823227331974\n",
      "Training Loss: 0.006131067236419767\n",
      "Validation Loss: 0.0031910276209171653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006005700231180526\n",
      "Training Loss: 0.00588784029299859\n",
      "Training Loss: 0.006125768714118749\n",
      "Validation Loss: 0.0031872659142055874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006001075591193512\n",
      "Training Loss: 0.00588292763393838\n",
      "Training Loss: 0.006120553072541952\n",
      "Validation Loss: 0.0031835728251699653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005996541184140369\n",
      "Training Loss: 0.005878084547002799\n",
      "Training Loss: 0.006115418566041626\n",
      "Validation Loss: 0.003179935636417417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005992094967514277\n",
      "Training Loss: 0.005873309958260507\n",
      "Training Loss: 0.006110365787753836\n",
      "Validation Loss: 0.003176362533645516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005987736184033565\n",
      "Training Loss: 0.005868603377602994\n",
      "Training Loss: 0.006105390361044556\n",
      "Validation Loss: 0.003172846465225049\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005983462217845954\n",
      "Training Loss: 0.005863961854483932\n",
      "Training Loss: 0.006100493214325979\n",
      "Validation Loss: 0.00316939071367568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005979272504337132\n",
      "Training Loss: 0.005859385450603441\n",
      "Training Loss: 0.006095671391813084\n",
      "Validation Loss: 0.0031659912476263772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005975163549301214\n",
      "Training Loss: 0.0058548722957493735\n",
      "Training Loss: 0.006090922667062841\n",
      "Validation Loss: 0.003162645362709973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005971133228158578\n",
      "Training Loss: 0.0058504197816364465\n",
      "Training Loss: 0.0060862448962870986\n",
      "Validation Loss: 0.0031593544487161247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.0059671807562699545\n",
      "Training Loss: 0.0058460270869545635\n",
      "Training Loss: 0.006081637873430737\n",
      "Validation Loss: 0.0031561156645877643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.0059633023751666766\n",
      "Training Loss: 0.005841690663364716\n",
      "Training Loss: 0.006077096224762499\n",
      "Validation Loss: 0.0031529297212431772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005959496270515956\n",
      "Training Loss: 0.005837410775129683\n",
      "Training Loss: 0.0060726195259485395\n",
      "Validation Loss: 0.0031497890909275646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005955759493517689\n",
      "Training Loss: 0.0058331836690194904\n",
      "Training Loss: 0.006068205835181289\n",
      "Validation Loss: 0.0031466988076225676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.00595208995800931\n",
      "Training Loss: 0.005829008347354829\n",
      "Training Loss: 0.006063851625658572\n",
      "Validation Loss: 0.0031436520191746647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005948484084219672\n",
      "Training Loss: 0.0058248819835716855\n",
      "Training Loss: 0.006059554725652561\n",
      "Validation Loss: 0.0031406451212870105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005944940391927957\n",
      "Training Loss: 0.005820802298258059\n",
      "Training Loss: 0.006055311944219283\n",
      "Validation Loss: 0.0031376826325745393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0059414564853068445\n",
      "Training Loss: 0.005816766897914931\n",
      "Training Loss: 0.006051122528151609\n",
      "Validation Loss: 0.0031347618545562532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005938029105891474\n",
      "Training Loss: 0.005812774169608019\n",
      "Training Loss: 0.006046982819680124\n",
      "Validation Loss: 0.003131875344499778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005934655832243152\n",
      "Training Loss: 0.005808821753016673\n",
      "Training Loss: 0.006042891459073872\n",
      "Validation Loss: 0.0031290213012377197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005931334214983508\n",
      "Training Loss: 0.0058049068873515354\n",
      "Training Loss: 0.006038844512077048\n",
      "Validation Loss: 0.0031262031786426316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005928062637103722\n",
      "Training Loss: 0.005801028779824264\n",
      "Training Loss: 0.006034840909997001\n",
      "Validation Loss: 0.0031234176013241995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005924837772035971\n",
      "Training Loss: 0.005797184911789373\n",
      "Training Loss: 0.006030878353049047\n",
      "Validation Loss: 0.0031206645195770047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005921658120350912\n",
      "Training Loss: 0.005793372642947361\n",
      "Training Loss: 0.0060269538994180034\n",
      "Validation Loss: 0.0031179385181265267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005918519888655283\n",
      "Training Loss: 0.005789589064661414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [12:04<12:03, 144.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006023065958870575\n",
      "Validation Loss: 0.0031152359240039598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.653823484480381\n",
      "Training Loss: 0.5398627331852913\n",
      "Training Loss: 0.4403177371621132\n",
      "Validation Loss: 0.3450091631894701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.3097145490348339\n",
      "Training Loss: 0.25108740612864494\n",
      "Training Loss: 0.20116406843066215\n",
      "Validation Loss: 0.1538651345318623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.14236612778156996\n",
      "Training Loss: 0.12029015507549047\n",
      "Training Loss: 0.1008504942432046\n",
      "Validation Loss: 0.08048582935098851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.07747407872229814\n",
      "Training Loss: 0.0701410749182105\n",
      "Training Loss: 0.0645571319758892\n",
      "Validation Loss: 0.05764615544107523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.06008668694645167\n",
      "Training Loss: 0.05877524983137846\n",
      "Training Loss: 0.05707315197214484\n",
      "Validation Loss: 0.05236235436763656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.05361748001538217\n",
      "Training Loss: 0.05099747968837619\n",
      "Training Loss: 0.04826681008562446\n",
      "Validation Loss: 0.04299560438297438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.042620396139100195\n",
      "Training Loss: 0.03888865516521037\n",
      "Training Loss: 0.03656194232404232\n",
      "Validation Loss: 0.031529389572947215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.031448442968539894\n",
      "Training Loss: 0.028534697727300228\n",
      "Training Loss: 0.027466744580306113\n",
      "Validation Loss: 0.023331517604797073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.02383957263547927\n",
      "Training Loss: 0.02199866939801723\n",
      "Training Loss: 0.021697589280083775\n",
      "Validation Loss: 0.01843880173446757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.019207195551134645\n",
      "Training Loss: 0.01816133646061644\n",
      "Training Loss: 0.01817016157321632\n",
      "Validation Loss: 0.015489551217787051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.016424197878222913\n",
      "Training Loss: 0.015848825110588223\n",
      "Training Loss: 0.015901012897957117\n",
      "Validation Loss: 0.013470368313320567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.014582454750780016\n",
      "Training Loss: 0.014215980437584222\n",
      "Training Loss: 0.01422934118192643\n",
      "Validation Loss: 0.011870919575056668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013184983211103826\n",
      "Training Loss: 0.012909176303073764\n",
      "Training Loss: 0.012899213323835283\n",
      "Validation Loss: 0.01054654424758942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.012063247626647353\n",
      "Training Loss: 0.011832722992403432\n",
      "Training Loss: 0.011826898148283362\n",
      "Validation Loss: 0.00945181110507568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.01115554419811815\n",
      "Training Loss: 0.010949333977187052\n",
      "Training Loss: 0.010966470260173082\n",
      "Validation Loss: 0.008552790054360802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010422927939798684\n",
      "Training Loss: 0.010228935015620664\n",
      "Training Loss: 0.010279371313517914\n",
      "Validation Loss: 0.007816679916982905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009832559500355274\n",
      "Training Loss: 0.009643248507054523\n",
      "Training Loss: 0.009731405535712839\n",
      "Validation Loss: 0.00721370502050673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009356233596336097\n",
      "Training Loss: 0.009167170051950961\n",
      "Training Loss: 0.009293632721528411\n",
      "Validation Loss: 0.0067185707562969306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008970661705825477\n",
      "Training Loss: 0.00877960471319966\n",
      "Training Loss: 0.00894257695763372\n",
      "Validation Loss: 0.006310576293094272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008657204482005909\n",
      "Training Loss: 0.008463364755734802\n",
      "Training Loss: 0.008659700632560998\n",
      "Validation Loss: 0.005973055689292175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008401218346552924\n",
      "Training Loss: 0.008204673805739731\n",
      "Training Loss: 0.008430593042867258\n",
      "Validation Loss: 0.00569266297990519\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008191284260246902\n",
      "Training Loss: 0.007992525103036314\n",
      "Training Loss: 0.008244108764920384\n",
      "Validation Loss: 0.005458699515759108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008018495860742405\n",
      "Training Loss: 0.007818138558650389\n",
      "Training Loss: 0.00809164077276364\n",
      "Validation Loss: 0.005262565168583494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007875859469641\n",
      "Training Loss: 0.007674468193436042\n",
      "Training Loss: 0.00796648689894937\n",
      "Validation Loss: 0.005097331578602616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007757811570772901\n",
      "Training Loss: 0.007555812305072323\n",
      "Training Loss: 0.00786336068995297\n",
      "Validation Loss: 0.00495738543967685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007659851622302085\n",
      "Training Loss: 0.007457515811547637\n",
      "Training Loss: 0.007778018548851833\n",
      "Validation Loss: 0.0048381855339858304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007578287017531693\n",
      "Training Loss: 0.007375743985176086\n",
      "Training Loss: 0.007707014172337949\n",
      "Validation Loss: 0.004736054761942183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007510059344349429\n",
      "Training Loss: 0.007307336729136296\n",
      "Training Loss: 0.007647529735695571\n",
      "Validation Loss: 0.004648028124709812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00745264082099311\n",
      "Training Loss: 0.007249696923536248\n",
      "Training Loss: 0.007597262925701216\n",
      "Validation Loss: 0.004571708677901646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007403944494435564\n",
      "Training Loss: 0.007200705912546255\n",
      "Training Loss: 0.007554350384743884\n",
      "Validation Loss: 0.00450517592972584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007362268958240747\n",
      "Training Loss: 0.007158649383345619\n",
      "Training Loss: 0.0075172914285212755\n",
      "Validation Loss: 0.0044468719606402885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007326239622198045\n",
      "Training Loss: 0.0071221504861023275\n",
      "Training Loss: 0.0074848932516761125\n",
      "Validation Loss: 0.004395528850825817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00729475237429142\n",
      "Training Loss: 0.007090111856232397\n",
      "Training Loss: 0.00745621022535488\n",
      "Validation Loss: 0.004350112696188722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007266929249744862\n",
      "Training Loss: 0.0070616648677969355\n",
      "Training Loss: 0.00743050079792738\n",
      "Validation Loss: 0.004309765727709184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007242074868408963\n",
      "Training Loss: 0.0070361193391727285\n",
      "Training Loss: 0.007407183377072215\n",
      "Validation Loss: 0.004273777406432488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007219638637034223\n",
      "Training Loss: 0.007012930720229633\n",
      "Training Loss: 0.007385802507633344\n",
      "Validation Loss: 0.004241552237902632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00719918695744127\n",
      "Training Loss: 0.0069916707667289305\n",
      "Training Loss: 0.007366002617636695\n",
      "Validation Loss: 0.004212591378541475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007180376600008458\n",
      "Training Loss: 0.006971999865490943\n",
      "Training Loss: 0.00734750721254386\n",
      "Validation Loss: 0.004186470720791415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0071629373030737045\n",
      "Training Loss: 0.006953649898059666\n",
      "Training Loss: 0.007330099637620151\n",
      "Validation Loss: 0.004162830615866134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00714665467850864\n",
      "Training Loss: 0.006936408237670548\n",
      "Training Loss: 0.007313609385164455\n",
      "Validation Loss: 0.00414136244151532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007131357990438118\n",
      "Training Loss: 0.006920107252080925\n",
      "Training Loss: 0.0072979067417327315\n",
      "Validation Loss: 0.0041218040971441215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007116912219207734\n",
      "Training Loss: 0.006904614075901918\n",
      "Training Loss: 0.007282885716995225\n",
      "Validation Loss: 0.00410392644469825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007103206119500101\n",
      "Training Loss: 0.006889820521464572\n",
      "Training Loss: 0.0072684639529325065\n",
      "Validation Loss: 0.004087535232786884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007090151067823172\n",
      "Training Loss: 0.006875642085215077\n",
      "Training Loss: 0.007254578284919262\n",
      "Validation Loss: 0.004072453886835596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.0070776759670116\n",
      "Training Loss: 0.006862010132172145\n",
      "Training Loss: 0.0072411734575871375\n",
      "Validation Loss: 0.004058532228463151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007065719289239496\n",
      "Training Loss: 0.006848866859218106\n",
      "Training Loss: 0.007228209931636229\n",
      "Validation Loss: 0.004045633999421523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007054230022476986\n",
      "Training Loss: 0.006836166085558943\n",
      "Training Loss: 0.007215649944264442\n",
      "Validation Loss: 0.004033644267703208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007043164647184312\n",
      "Training Loss: 0.006823867418570444\n",
      "Training Loss: 0.00720346522051841\n",
      "Validation Loss: 0.004022451780809696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007032485096715391\n",
      "Training Loss: 0.006811938909813762\n",
      "Training Loss: 0.007191628942964598\n",
      "Validation Loss: 0.004011967764863891\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00702215910074301\n",
      "Training Loss: 0.0068003497988684105\n",
      "Training Loss: 0.00718011942692101\n",
      "Validation Loss: 0.004002101073208987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007012154732365161\n",
      "Training Loss: 0.006789075180422515\n",
      "Training Loss: 0.0071689160808455195\n",
      "Validation Loss: 0.00399277776511114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007002446711994708\n",
      "Training Loss: 0.006778091915766709\n",
      "Training Loss: 0.007157999738119543\n",
      "Validation Loss: 0.003983931281091122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006993008485296741\n",
      "Training Loss: 0.0067673783045029265\n",
      "Training Loss: 0.0071473536000121385\n",
      "Validation Loss: 0.003975501412190915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006983817437430844\n",
      "Training Loss: 0.0067569140082923695\n",
      "Training Loss: 0.0071369595522992315\n",
      "Validation Loss: 0.003967428343171735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006974849960533902\n",
      "Training Loss: 0.006746681068907492\n",
      "Training Loss: 0.007126801258418709\n",
      "Validation Loss: 0.0039596702730848215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006966087055625394\n",
      "Training Loss: 0.006736662546754815\n",
      "Training Loss: 0.007116863848641515\n",
      "Validation Loss: 0.00395218022638576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006957508490886539\n",
      "Training Loss: 0.006726841507479549\n",
      "Training Loss: 0.007107131516095251\n",
      "Validation Loss: 0.003944919772937977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0069490973267238585\n",
      "Training Loss: 0.006717203345615417\n",
      "Training Loss: 0.007097591365454719\n",
      "Validation Loss: 0.003937855950200909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006940835736459121\n",
      "Training Loss: 0.006707732394570485\n",
      "Training Loss: 0.0070882272347807885\n",
      "Validation Loss: 0.0039309586916286285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006932706707157194\n",
      "Training Loss: 0.0066984153166413304\n",
      "Training Loss: 0.007079025375423953\n",
      "Validation Loss: 0.003924202783493681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006924695874331519\n",
      "Training Loss: 0.006689239771803841\n",
      "Training Loss: 0.007069973816396668\n",
      "Validation Loss: 0.003917565690929049\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006916788913076744\n",
      "Training Loss: 0.006680191487539559\n",
      "Training Loss: 0.007061058024410158\n",
      "Validation Loss: 0.003911025368273677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006908972702221945\n",
      "Training Loss: 0.006671260424191132\n",
      "Training Loss: 0.007052267479011789\n",
      "Validation Loss: 0.0039045657240524053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006901233271928504\n",
      "Training Loss: 0.006662434902973473\n",
      "Training Loss: 0.00704358855378814\n",
      "Validation Loss: 0.003898171743304793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006893559893360362\n",
      "Training Loss: 0.006653703451156616\n",
      "Training Loss: 0.007035011016996578\n",
      "Validation Loss: 0.0038918310703102794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00688594079692848\n",
      "Training Loss: 0.006645057910354808\n",
      "Training Loss: 0.007026523555396125\n",
      "Validation Loss: 0.003885532444175542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006878366015153006\n",
      "Training Loss: 0.006636487945215776\n",
      "Training Loss: 0.00701811532722786\n",
      "Validation Loss: 0.0038792614437890855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00687082635005936\n",
      "Training Loss: 0.0066279862797819075\n",
      "Training Loss: 0.00700977720785886\n",
      "Validation Loss: 0.0038730141123380054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006863311122870073\n",
      "Training Loss: 0.006619542954722419\n",
      "Training Loss: 0.007001499796751886\n",
      "Validation Loss: 0.0038667776284404516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006855812323046848\n",
      "Training Loss: 0.0066111519490368665\n",
      "Training Loss: 0.006993274147389456\n",
      "Validation Loss: 0.003860551731796998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006848323561716825\n",
      "Training Loss: 0.006602805242873728\n",
      "Training Loss: 0.006985091584501788\n",
      "Validation Loss: 0.003854326525797251\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006840834018075839\n",
      "Training Loss: 0.006594496216857806\n",
      "Training Loss: 0.0069769430917222056\n",
      "Validation Loss: 0.003848092676286868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006833336770068854\n",
      "Training Loss: 0.006586218030424789\n",
      "Training Loss: 0.006968823700444773\n",
      "Validation Loss: 0.003841855046548619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00682582859066315\n",
      "Training Loss: 0.0065779664053116\n",
      "Training Loss: 0.006960723486263305\n",
      "Validation Loss: 0.0038355997779270573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006818299090955406\n",
      "Training Loss: 0.006569733308861032\n",
      "Training Loss: 0.006952635777415708\n",
      "Validation Loss: 0.0038293249881564736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006810742552625015\n",
      "Training Loss: 0.006561514216009527\n",
      "Training Loss: 0.00694455397198908\n",
      "Validation Loss: 0.003823025326056176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0068031539581716064\n",
      "Training Loss: 0.00655330310575664\n",
      "Training Loss: 0.006936472340021283\n",
      "Validation Loss: 0.0038167002644871224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006795527982758358\n",
      "Training Loss: 0.006545096355257556\n",
      "Training Loss: 0.0069283846137113865\n",
      "Validation Loss: 0.0038103436504417425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006787856500595808\n",
      "Training Loss: 0.0065368868852965535\n",
      "Training Loss: 0.006920282858191058\n",
      "Validation Loss: 0.0038039517717101097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00678013657219708\n",
      "Training Loss: 0.006528671985724941\n",
      "Training Loss: 0.006912162757944315\n",
      "Validation Loss: 0.003797520786586605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006772361429175362\n",
      "Training Loss: 0.006520445159403607\n",
      "Training Loss: 0.00690401830826886\n",
      "Validation Loss: 0.0037910485237292696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006764528217026964\n",
      "Training Loss: 0.006512203351594508\n",
      "Training Loss: 0.006895844648825005\n",
      "Validation Loss: 0.003784528373625506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00675662919296883\n",
      "Training Loss: 0.006503941795090213\n",
      "Training Loss: 0.006887635313905776\n",
      "Validation Loss: 0.003777958421308673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006748660563025624\n",
      "Training Loss: 0.00649565601022914\n",
      "Training Loss: 0.0068793851626105604\n",
      "Validation Loss: 0.0037713345817782067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006740617562318221\n",
      "Training Loss: 0.006487340981839225\n",
      "Training Loss: 0.006871089109918103\n",
      "Validation Loss: 0.003764653044721384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006732495474861935\n",
      "Training Loss: 0.006478992932243272\n",
      "Training Loss: 0.006862742360681295\n",
      "Validation Loss: 0.0037579080312293064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006724288432160393\n",
      "Training Loss: 0.006470606833463535\n",
      "Training Loss: 0.006854338150005788\n",
      "Validation Loss: 0.0037511017793538364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006715993253747002\n",
      "Training Loss: 0.006462179805384949\n",
      "Training Loss: 0.006845872433623299\n",
      "Validation Loss: 0.0037442234023003264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00670760637614876\n",
      "Training Loss: 0.0064537064614705745\n",
      "Training Loss: 0.006837340556085109\n",
      "Validation Loss: 0.0037372721898045096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.0066991200624033805\n",
      "Training Loss: 0.006445183347677812\n",
      "Training Loss: 0.006828737219329924\n",
      "Validation Loss: 0.0037302412890588468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.0066905324789695445\n",
      "Training Loss: 0.006436605184571818\n",
      "Training Loss: 0.00682005699723959\n",
      "Validation Loss: 0.003723129703338896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0066818386677186935\n",
      "Training Loss: 0.006427968868520111\n",
      "Training Loss: 0.006811295001534745\n",
      "Validation Loss: 0.0037159304438012367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006673033735714853\n",
      "Training Loss: 0.006419269375037402\n",
      "Training Loss: 0.006802446519723162\n",
      "Validation Loss: 0.0037086422259532165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006664113744627684\n",
      "Training Loss: 0.00641050239559263\n",
      "Training Loss: 0.006793506549438461\n",
      "Validation Loss: 0.003701258364416073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006655076001770795\n",
      "Training Loss: 0.006401665216544643\n",
      "Training Loss: 0.006784469936974347\n",
      "Validation Loss: 0.0036937754007391214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006645914115943015\n",
      "Training Loss: 0.00639275273308158\n",
      "Training Loss: 0.006775331967510283\n",
      "Validation Loss: 0.0036861865161237923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006636625374667347\n",
      "Training Loss: 0.006383760559838265\n",
      "Training Loss: 0.006766086549032479\n",
      "Validation Loss: 0.003678490913975356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006627205413533375\n",
      "Training Loss: 0.006374683275353164\n",
      "Training Loss: 0.006756730491761118\n",
      "Validation Loss: 0.003670680303953253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0066176508273929355\n",
      "Training Loss: 0.006365517729427665\n",
      "Training Loss: 0.006747257248498499\n",
      "Validation Loss: 0.0036627514290445474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006607957881642506\n",
      "Training Loss: 0.00635625913972035\n",
      "Training Loss: 0.006737662942614406\n",
      "Validation Loss: 0.0036546958327879396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006598122481955215\n",
      "Training Loss: 0.006346904783276841\n",
      "Training Loss: 0.006727943394798786\n",
      "Validation Loss: 0.0036465156499003427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006588142820401117\n",
      "Training Loss: 0.0063374506693799045\n",
      "Training Loss: 0.006718093233648688\n",
      "Validation Loss: 0.0036382042904897186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.0065780155919492244\n",
      "Training Loss: 0.006327891158871352\n",
      "Training Loss: 0.006708108311286196\n",
      "Validation Loss: 0.003629754051524267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006567737479927018\n",
      "Training Loss: 0.0063182240864261986\n",
      "Training Loss: 0.00669798360671848\n",
      "Validation Loss: 0.003621163660283671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0065573065727949145\n",
      "Training Loss: 0.006308445465983823\n",
      "Training Loss: 0.006687716539017856\n",
      "Validation Loss: 0.0036124311952611034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006546721913618967\n",
      "Training Loss: 0.006298551572253928\n",
      "Training Loss: 0.006677301863674074\n",
      "Validation Loss: 0.0036035427415555114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006535978876054287\n",
      "Training Loss: 0.006288539018714801\n",
      "Training Loss: 0.006666736332699656\n",
      "Validation Loss: 0.0035945025084310033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00652507980237715\n",
      "Training Loss: 0.006278405416524037\n",
      "Training Loss: 0.0066560177470091735\n",
      "Validation Loss: 0.0035853084409609437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006514023189083673\n",
      "Training Loss: 0.006268149252864532\n",
      "Training Loss: 0.006645142111228779\n",
      "Validation Loss: 0.0035759535489938736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006502809016965329\n",
      "Training Loss: 0.006257767560891807\n",
      "Training Loss: 0.006634108424186706\n",
      "Validation Loss: 0.003566434848896657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006491438440280035\n",
      "Training Loss: 0.0062472576776053754\n",
      "Training Loss: 0.006622914120089263\n",
      "Validation Loss: 0.0035567524165354587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006479912307113409\n",
      "Training Loss: 0.0062366195255890485\n",
      "Training Loss: 0.006611558442236856\n",
      "Validation Loss: 0.003546900950435005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.0064682333660312\n",
      "Training Loss: 0.0062258523242780936\n",
      "Training Loss: 0.0066000414453446865\n",
      "Validation Loss: 0.003536879189647316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.0064564042020356285\n",
      "Training Loss: 0.006214956118492409\n",
      "Training Loss: 0.006588362624170258\n",
      "Validation Loss: 0.0035266905847748512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0064444299385650085\n",
      "Training Loss: 0.006203931117779575\n",
      "Training Loss: 0.006576523219700902\n",
      "Validation Loss: 0.003516333031185557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006432315105921588\n",
      "Training Loss: 0.0061927794868825\n",
      "Training Loss: 0.006564526720903813\n",
      "Validation Loss: 0.0035058062581157083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006420067302533425\n",
      "Training Loss: 0.006181503236293792\n",
      "Training Loss: 0.006552376670297236\n",
      "Validation Loss: 0.0034951128528631303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006407691523199901\n",
      "Training Loss: 0.006170105586061254\n",
      "Training Loss: 0.006540077208774165\n",
      "Validation Loss: 0.003484253710125353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006395197515957989\n",
      "Training Loss: 0.006158590241102502\n",
      "Training Loss: 0.006527633626246825\n",
      "Validation Loss: 0.0034732353622407724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006382597286137753\n",
      "Training Loss: 0.006146963980863802\n",
      "Training Loss: 0.006515054508927278\n",
      "Validation Loss: 0.0034620644828158146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006369899184792302\n",
      "Training Loss: 0.006135232842643746\n",
      "Training Loss: 0.0065023464686237275\n",
      "Validation Loss: 0.003450744221604356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006357116771978326\n",
      "Training Loss: 0.0061234033218352125\n",
      "Training Loss: 0.006489520651521161\n",
      "Validation Loss: 0.003439284706739395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006344261644408107\n",
      "Training Loss: 0.006111485019791871\n",
      "Training Loss: 0.00647658821195364\n",
      "Validation Loss: 0.0034276968773370715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006331351432600059\n",
      "Training Loss: 0.006099486903985962\n",
      "Training Loss: 0.006463561351411045\n",
      "Validation Loss: 0.0034159828576499993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006318397696013563\n",
      "Training Loss: 0.006087418135721236\n",
      "Training Loss: 0.006450451833079569\n",
      "Validation Loss: 0.003404160832013056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006305418601259589\n",
      "Training Loss: 0.006075291341985576\n",
      "Training Loss: 0.006437276441720314\n",
      "Validation Loss: 0.0033922402941611376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006292429611785337\n",
      "Training Loss: 0.006063118645688519\n",
      "Training Loss: 0.00642404819605872\n",
      "Validation Loss: 0.0033802369575466167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.0062794473516987635\n",
      "Training Loss: 0.006050911927013658\n",
      "Training Loss: 0.006410785255720839\n",
      "Validation Loss: 0.003368164856101941\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006266490702982992\n",
      "Training Loss: 0.0060386860527796675\n",
      "Training Loss: 0.006397503393818624\n",
      "Validation Loss: 0.0033560346634116736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006253575422451831\n",
      "Training Loss: 0.006026452841470018\n",
      "Training Loss: 0.006384220289764926\n",
      "Validation Loss: 0.0033438641334664117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0062407186109339815\n",
      "Training Loss: 0.0060142280248692255\n",
      "Training Loss: 0.006370950317941606\n",
      "Validation Loss: 0.003331672773026767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0062279358418891205\n",
      "Training Loss: 0.006002024614717811\n",
      "Training Loss: 0.006357712809694931\n",
      "Validation Loss: 0.003319472438143043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006215244191116654\n",
      "Training Loss: 0.005989857497625053\n",
      "Training Loss: 0.006344523613806814\n",
      "Validation Loss: 0.003307283258201617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006202657883986831\n",
      "Training Loss: 0.00597773909335956\n",
      "Training Loss: 0.006331397425965406\n",
      "Validation Loss: 0.0032951194803450216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006190191256464459\n",
      "Training Loss: 0.005965684617403894\n",
      "Training Loss: 0.006318350558285601\n",
      "Validation Loss: 0.003282996798405068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006177856739377603\n",
      "Training Loss: 0.005953705122228712\n",
      "Training Loss: 0.006305396181414835\n",
      "Validation Loss: 0.003270930774101799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006165664703585208\n",
      "Training Loss: 0.005941812546225265\n",
      "Training Loss: 0.006292546815238893\n",
      "Validation Loss: 0.0032589388357245185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006153627217863686\n",
      "Training Loss: 0.005930019926163368\n",
      "Training Loss: 0.006279814128065482\n",
      "Validation Loss: 0.0032470315927639604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006141751066315919\n",
      "Training Loss: 0.005918334401794709\n",
      "Training Loss: 0.006267208610079251\n",
      "Validation Loss: 0.003235222277325693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006130043071461842\n",
      "Training Loss: 0.005906766247353517\n",
      "Training Loss: 0.006254737793351523\n",
      "Validation Loss: 0.00322352579580306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006118510040105321\n",
      "Training Loss: 0.005895323433796875\n",
      "Training Loss: 0.006242409292026423\n",
      "Validation Loss: 0.003211949224677983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.00610715605202131\n",
      "Training Loss: 0.005884012035094202\n",
      "Training Loss: 0.006230230321525596\n",
      "Validation Loss: 0.003200508217233118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.0060959837754489855\n",
      "Training Loss: 0.005872839729418047\n",
      "Training Loss: 0.0062182058818871155\n",
      "Validation Loss: 0.003189206589013338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006084997287252918\n",
      "Training Loss: 0.005861810381757096\n",
      "Training Loss: 0.006206339538330212\n",
      "Validation Loss: 0.003178052487783134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006074194947723299\n",
      "Training Loss: 0.005850927200517617\n",
      "Training Loss: 0.006194632971310057\n",
      "Validation Loss: 0.003167055905639623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006063579206238501\n",
      "Training Loss: 0.005840194320189767\n",
      "Training Loss: 0.006183090071426704\n",
      "Validation Loss: 0.0031562247640568386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006053148692590184\n",
      "Training Loss: 0.005829615200636909\n",
      "Training Loss: 0.006171711593051441\n",
      "Validation Loss: 0.003145560763483302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006042903586057946\n",
      "Training Loss: 0.00581919017364271\n",
      "Training Loss: 0.006160499471006915\n",
      "Validation Loss: 0.0031350700085292036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006032842824351974\n",
      "Training Loss: 0.005808922765427269\n",
      "Training Loss: 0.006149454533006065\n",
      "Validation Loss: 0.003124757524673942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0060229647217784075\n",
      "Training Loss: 0.005798811615677551\n",
      "Training Loss: 0.00613857788965106\n",
      "Validation Loss: 0.0031146248593256712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006013268614769913\n",
      "Training Loss: 0.005788860387401656\n",
      "Training Loss: 0.006127869260380976\n",
      "Validation Loss: 0.003104678568367459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006003753351978958\n",
      "Training Loss: 0.005779069463023916\n",
      "Training Loss: 0.006117330198176205\n",
      "Validation Loss: 0.003094920064479615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005994417310575955\n",
      "Training Loss: 0.005769437681301497\n",
      "Training Loss: 0.006106959788012318\n",
      "Validation Loss: 0.0030853501403327573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005985258856089786\n",
      "Training Loss: 0.005759966975892894\n",
      "Training Loss: 0.006096760931541212\n",
      "Validation Loss: 0.0030759742216657053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005976277725421824\n",
      "Training Loss: 0.005750658821198158\n",
      "Training Loss: 0.006086733369738795\n",
      "Validation Loss: 0.0030667897970467974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00596747255534865\n",
      "Training Loss: 0.005741512103704736\n",
      "Training Loss: 0.0060768766066757966\n",
      "Validation Loss: 0.0030578051345799577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.0059588425053516405\n",
      "Training Loss: 0.005732527505606413\n",
      "Training Loss: 0.00606719326460734\n",
      "Validation Loss: 0.0030490147653611356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005950385621399618\n",
      "Training Loss: 0.005723705947166309\n",
      "Training Loss: 0.006057682486134581\n",
      "Validation Loss: 0.0030404222904170833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005942100401734933\n",
      "Training Loss: 0.005715047500561923\n",
      "Training Loss: 0.0060483456880319865\n",
      "Validation Loss: 0.003032027221849879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00593398779979907\n",
      "Training Loss: 0.00570655225252267\n",
      "Training Loss: 0.0060391817521303895\n",
      "Validation Loss: 0.003023830959259459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005926045224769041\n",
      "Training Loss: 0.0056982194335432725\n",
      "Training Loss: 0.006030192026519217\n",
      "Validation Loss: 0.0030158317341793623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005918268783134408\n",
      "Training Loss: 0.005690048306132667\n",
      "Training Loss: 0.006021376747521572\n",
      "Validation Loss: 0.003008032705519725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005910659269429744\n",
      "Training Loss: 0.0056820401013828814\n",
      "Training Loss: 0.0060127307672519234\n",
      "Validation Loss: 0.0030004318144298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005903212181292475\n",
      "Training Loss: 0.005674191018333659\n",
      "Training Loss: 0.00600425559503492\n",
      "Validation Loss: 0.002993021754213096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005895924424403347\n",
      "Training Loss: 0.00566650127293542\n",
      "Training Loss: 0.00599594995030202\n",
      "Validation Loss: 0.0029858089460248357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005888794690836221\n",
      "Training Loss: 0.0056589685077779\n",
      "Training Loss: 0.005987810678198003\n",
      "Validation Loss: 0.0029787856044268674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005881817532354034\n",
      "Training Loss: 0.0056515897338977085\n",
      "Training Loss: 0.005979833697201684\n",
      "Validation Loss: 0.0029719519151604912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005874988551368005\n",
      "Training Loss: 0.005644363735918887\n",
      "Training Loss: 0.005972014594590291\n",
      "Validation Loss: 0.0029652993406660937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005868303023162298\n",
      "Training Loss: 0.005637285016709939\n",
      "Training Loss: 0.005964352752198465\n",
      "Validation Loss: 0.0029588301778572163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005861755994847045\n",
      "Training Loss: 0.005630351559375413\n",
      "Training Loss: 0.00595684094063472\n",
      "Validation Loss: 0.0029525377779801407\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005855342319700867\n",
      "Training Loss: 0.005623558638617397\n",
      "Training Loss: 0.005949472434585914\n",
      "Validation Loss: 0.002946419089383791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005849056654842571\n",
      "Training Loss: 0.005616901717730798\n",
      "Training Loss: 0.005942245876067318\n",
      "Validation Loss: 0.0029404648433156897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005842892199289054\n",
      "Training Loss: 0.005610375914839097\n",
      "Training Loss: 0.0059351532283471896\n",
      "Validation Loss: 0.002934673510680205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005836841850541532\n",
      "Training Loss: 0.005603976604761556\n",
      "Training Loss: 0.005928187382523902\n",
      "Validation Loss: 0.0029290381837322305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005830899983411655\n",
      "Training Loss: 0.005597699072095566\n",
      "Training Loss: 0.005921344097005204\n",
      "Validation Loss: 0.002923553179049592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0058250598580343645\n",
      "Training Loss: 0.005591537114232778\n",
      "Training Loss: 0.005914615466608666\n",
      "Validation Loss: 0.0029182142598993994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005819314433028922\n",
      "Training Loss: 0.005585484101320617\n",
      "Training Loss: 0.0059079949505394325\n",
      "Validation Loss: 0.002913015554502104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005813657173421234\n",
      "Training Loss: 0.005579535933211446\n",
      "Training Loss: 0.005901476050494239\n",
      "Validation Loss: 0.0029079496475941176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005808080801507458\n",
      "Training Loss: 0.005573685111594387\n",
      "Training Loss: 0.0058950516377808525\n",
      "Validation Loss: 0.0029030125849786098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0058025787182850765\n",
      "Training Loss: 0.005567926629446447\n",
      "Training Loss: 0.0058887128147762265\n",
      "Validation Loss: 0.002898198140397919\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005797144557000138\n",
      "Training Loss: 0.005562253691023216\n",
      "Training Loss: 0.005882455258397385\n",
      "Validation Loss: 0.0028934995238302967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005791770823998376\n",
      "Training Loss: 0.00555666078638751\n",
      "Training Loss: 0.0058762708387803285\n",
      "Validation Loss: 0.0028889091368869283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005786451492458582\n",
      "Training Loss: 0.00555114187009167\n",
      "Training Loss: 0.005870154718868434\n",
      "Validation Loss: 0.0028844236453806752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005781179725308902\n",
      "Training Loss: 0.0055456916452385485\n",
      "Training Loss: 0.005864097901503555\n",
      "Validation Loss: 0.0028800361428744673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005775950702955015\n",
      "Training Loss: 0.0055403032916365195\n",
      "Training Loss: 0.005858094447758049\n",
      "Validation Loss: 0.00287574295116735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005770756385754794\n",
      "Training Loss: 0.0055349712143652145\n",
      "Training Loss: 0.005852138654445298\n",
      "Validation Loss: 0.0028715354071281265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00576559294888284\n",
      "Training Loss: 0.005529690664261579\n",
      "Training Loss: 0.005846223958069458\n",
      "Validation Loss: 0.002867411154981577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.0057604544109199195\n",
      "Training Loss: 0.005524457186111249\n",
      "Training Loss: 0.005840345475589857\n",
      "Validation Loss: 0.002863363081620734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005755335261346773\n",
      "Training Loss: 0.005519263917231001\n",
      "Training Loss: 0.005834497289033607\n",
      "Validation Loss: 0.0028593854669983804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005750230704434216\n",
      "Training Loss: 0.005514106880873441\n",
      "Training Loss: 0.005828674071817658\n",
      "Validation Loss: 0.0028554790292270064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005745137297781184\n",
      "Training Loss: 0.005508982883766294\n",
      "Training Loss: 0.005822872088174336\n",
      "Validation Loss: 0.002851633251686528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005740050202002749\n",
      "Training Loss: 0.005503886623773724\n",
      "Training Loss: 0.0058170864271232855\n",
      "Validation Loss: 0.0028478483763638507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005734966113232076\n",
      "Training Loss: 0.005498812735895626\n",
      "Training Loss: 0.005811312202131376\n",
      "Validation Loss: 0.0028441189330468855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005729880303842947\n",
      "Training Loss: 0.005493758519878611\n",
      "Training Loss: 0.0058055460808100175\n",
      "Validation Loss: 0.002840439392661864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005724789993255399\n",
      "Training Loss: 0.005488721511210315\n",
      "Training Loss: 0.005799785434501246\n",
      "Validation Loss: 0.0028368085818993075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005719692594138906\n",
      "Training Loss: 0.0054836965695722025\n",
      "Training Loss: 0.005794025463983416\n",
      "Validation Loss: 0.002833221900391947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005714585767127574\n",
      "Training Loss: 0.005478682934190147\n",
      "Training Loss: 0.005788264764123596\n",
      "Validation Loss: 0.00282967455941514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.00570946742722299\n",
      "Training Loss: 0.005473676483379677\n",
      "Training Loss: 0.005782501075882465\n",
      "Validation Loss: 0.002826164200577592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005704335864284076\n",
      "Training Loss: 0.005468675445299596\n",
      "Training Loss: 0.0057767323177540675\n",
      "Validation Loss: 0.002822691933094953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005699188453145325\n",
      "Training Loss: 0.005463678251253441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [14:29<09:38, 144.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005770956035703421\n",
      "Validation Loss: 0.0028192479702319655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.6733226613700389\n",
      "Training Loss: 0.6012000688910484\n",
      "Training Loss: 0.5130564597249031\n",
      "Validation Loss: 0.37748258502295845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.33157105088233946\n",
      "Training Loss: 0.214425982683897\n",
      "Training Loss: 0.12853469662368297\n",
      "Validation Loss: 0.07420673137635328\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.078574357368052\n",
      "Training Loss: 0.07193578900769353\n",
      "Training Loss: 0.06898421406745911\n",
      "Validation Loss: 0.060100454272011695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06646568184718489\n",
      "Training Loss: 0.06524996273219585\n",
      "Training Loss: 0.06412996714934707\n",
      "Validation Loss: 0.05655135381757544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.061797192078083756\n",
      "Training Loss: 0.06035296633839607\n",
      "Training Loss: 0.05922424141317606\n",
      "Validation Loss: 0.052260693351037044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.056708587193861605\n",
      "Training Loss: 0.05511819686740637\n",
      "Training Loss: 0.05403666438534856\n",
      "Validation Loss: 0.04765692510213075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.05144742893986404\n",
      "Training Loss: 0.04976081363856792\n",
      "Training Loss: 0.04874865602701903\n",
      "Validation Loss: 0.042918212879239845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.046067339358851316\n",
      "Training Loss: 0.044244985776022074\n",
      "Training Loss: 0.04325093792751431\n",
      "Validation Loss: 0.03795289989100414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.04038832415826619\n",
      "Training Loss: 0.03839598120190203\n",
      "Training Loss: 0.03742597102187574\n",
      "Validation Loss: 0.03274974168351527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.034419085439294575\n",
      "Training Loss: 0.03233815454877913\n",
      "Training Loss: 0.03150688093155622\n",
      "Validation Loss: 0.027490358098587964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.02853606247343123\n",
      "Training Loss: 0.02654203593265265\n",
      "Training Loss: 0.02598308753222227\n",
      "Validation Loss: 0.02234280789584926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.02323809499386698\n",
      "Training Loss: 0.021500315689481794\n",
      "Training Loss: 0.021195618640631436\n",
      "Validation Loss: 0.01763052140686954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.018771038029808552\n",
      "Training Loss: 0.017525662621483206\n",
      "Training Loss: 0.017457448984496294\n",
      "Validation Loss: 0.014436420838066032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0157700043451041\n",
      "Training Loss: 0.015164988227188586\n",
      "Training Loss: 0.015286243038717657\n",
      "Validation Loss: 0.012706414524340228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.014121274489443749\n",
      "Training Loss: 0.013791174381040036\n",
      "Training Loss: 0.013930790941230953\n",
      "Validation Loss: 0.011493401717017876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.012997765995096415\n",
      "Training Loss: 0.012768806011881679\n",
      "Training Loss: 0.01289346611360088\n",
      "Validation Loss: 0.010500004541212589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.012107368765864521\n",
      "Training Loss: 0.011922378707677126\n",
      "Training Loss: 0.012034113304689526\n",
      "Validation Loss: 0.009648993362808663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.011362591627985238\n",
      "Training Loss: 0.01119754440500401\n",
      "Training Loss: 0.011303089854773135\n",
      "Validation Loss: 0.00891007079606813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.010727123781107366\n",
      "Training Loss: 0.010574235722888261\n",
      "Training Loss: 0.010679988553747535\n",
      "Validation Loss: 0.008270974276231581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.01018511771224439\n",
      "Training Loss: 0.010043856267584488\n",
      "Training Loss: 0.010155373369343579\n",
      "Validation Loss: 0.007725829172230671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00972853591432795\n",
      "Training Loss: 0.009599441495956852\n",
      "Training Loss: 0.009720981117570773\n",
      "Validation Loss: 0.007268002507894227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00934959516627714\n",
      "Training Loss: 0.009232288344064728\n",
      "Training Loss: 0.009366182216908783\n",
      "Validation Loss: 0.006887815835142738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009038589529227465\n",
      "Training Loss: 0.008931753430515528\n",
      "Training Loss: 0.00907845787703991\n",
      "Validation Loss: 0.006573463756109724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008784655454801395\n",
      "Training Loss: 0.00868640913045965\n",
      "Training Loss: 0.008845135206356644\n",
      "Validation Loss: 0.006312855469648925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008577109387842938\n",
      "Training Loss: 0.00848539732163772\n",
      "Training Loss: 0.008654772421577946\n",
      "Validation Loss: 0.006095026800241531\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008406430333852768\n",
      "Training Loss: 0.008319324970943853\n",
      "Training Loss: 0.008497867465484888\n",
      "Validation Loss: 0.005910832055561831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008264716458506882\n",
      "Training Loss: 0.008180596439633519\n",
      "Training Loss: 0.00836695360369049\n",
      "Validation Loss: 0.005753034443249193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008145718516316265\n",
      "Training Loss: 0.008063299303175881\n",
      "Training Loss: 0.008256344049004837\n",
      "Validation Loss: 0.005616089928204592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008044626564951614\n",
      "Training Loss: 0.007962931249057874\n",
      "Training Loss: 0.008161758616333828\n",
      "Validation Loss: 0.0054958269020982005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007957788783824072\n",
      "Training Loss: 0.007876094562234356\n",
      "Training Loss: 0.008080002412898466\n",
      "Validation Loss: 0.005389118648207422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007882431480102241\n",
      "Training Loss: 0.007800209001870826\n",
      "Training Loss: 0.008008651313139126\n",
      "Validation Loss: 0.005293603363875928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007816434124251828\n",
      "Training Loss: 0.0077332941070199016\n",
      "Training Loss: 0.007945840660249814\n",
      "Validation Loss: 0.005207474866693609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007758150000590831\n",
      "Training Loss: 0.007673810980049893\n",
      "Training Loss: 0.007890120714437216\n",
      "Validation Loss: 0.005129334775814682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007706286552129313\n",
      "Training Loss: 0.007620542527874931\n",
      "Training Loss: 0.007840332967462019\n",
      "Validation Loss: 0.005058076852681429\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007659806477604434\n",
      "Training Loss: 0.007572508001467213\n",
      "Training Loss: 0.007795543543761596\n",
      "Validation Loss: 0.0049928113650739864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007617873080307618\n",
      "Training Loss: 0.007528913221322\n",
      "Training Loss: 0.007754985591163859\n",
      "Validation Loss: 0.004932802442586824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007579791394528001\n",
      "Training Loss: 0.007489092224277556\n",
      "Training Loss: 0.007718015088466927\n",
      "Validation Loss: 0.004877435460718077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007544986354187131\n",
      "Training Loss: 0.007452492800075561\n",
      "Training Loss: 0.007684093478601426\n",
      "Validation Loss: 0.004826184945557727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0075129710196051745\n",
      "Training Loss: 0.0074186460161581634\n",
      "Training Loss: 0.007652764668455348\n",
      "Validation Loss: 0.004778609765442402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00748333616182208\n",
      "Training Loss: 0.007387152943992987\n",
      "Training Loss: 0.007623637240612879\n",
      "Validation Loss: 0.004734313394089512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007455730035435409\n",
      "Training Loss: 0.007357672454090789\n",
      "Training Loss: 0.00759637315175496\n",
      "Validation Loss: 0.004692954202234912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007429849510081112\n",
      "Training Loss: 0.00732990714139305\n",
      "Training Loss: 0.007570681623183191\n",
      "Validation Loss: 0.004654219294270354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007405432239174843\n",
      "Training Loss: 0.007303602391621098\n",
      "Training Loss: 0.007546311533078551\n",
      "Validation Loss: 0.004617850997307328\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007382254817057401\n",
      "Training Loss: 0.007278539428953081\n",
      "Training Loss: 0.007523044595727697\n",
      "Validation Loss: 0.004583587535144238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.0073601172026246785\n",
      "Training Loss: 0.0072545228875242175\n",
      "Training Loss: 0.007500686093699187\n",
      "Validation Loss: 0.00455121899264331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007338843400357291\n",
      "Training Loss: 0.007231384438928217\n",
      "Training Loss: 0.00747907291748561\n",
      "Validation Loss: 0.0045205449104685795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007318280164618045\n",
      "Training Loss: 0.0072089799924287944\n",
      "Training Loss: 0.007458057685289532\n",
      "Validation Loss: 0.004491379128748111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007298292482737452\n",
      "Training Loss: 0.007187182537745684\n",
      "Training Loss: 0.007437516206409782\n",
      "Validation Loss: 0.0044635594403894426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007278758585453033\n",
      "Training Loss: 0.007165887460578233\n",
      "Training Loss: 0.0074173459410667416\n",
      "Validation Loss: 0.004436943016873066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.0072595780051779\n",
      "Training Loss: 0.007145008296938613\n",
      "Training Loss: 0.0073974640795495365\n",
      "Validation Loss: 0.0044114030348241665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007240671599283814\n",
      "Training Loss: 0.007124479664489627\n",
      "Training Loss: 0.007377812892664224\n",
      "Validation Loss: 0.004386834703448615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007221982382470742\n",
      "Training Loss: 0.007104256638558582\n",
      "Training Loss: 0.007358356047188863\n",
      "Validation Loss: 0.004363154860349435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.0072034827660536396\n",
      "Training Loss: 0.007084312241058797\n",
      "Training Loss: 0.007339080382371322\n",
      "Validation Loss: 0.004340302374402291\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007185169686563313\n",
      "Training Loss: 0.007064635786809959\n",
      "Training Loss: 0.007319990958785638\n",
      "Validation Loss: 0.00431823700645499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007167069374118\n",
      "Training Loss: 0.007045228800852783\n",
      "Training Loss: 0.0073011091188527645\n",
      "Validation Loss: 0.004296932985556176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00714922122482676\n",
      "Training Loss: 0.0070260986563516785\n",
      "Training Loss: 0.007282462124712765\n",
      "Validation Loss: 0.004276372698983282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0071316738106543195\n",
      "Training Loss: 0.007007256530923769\n",
      "Training Loss: 0.007264081011526286\n",
      "Validation Loss: 0.004256537896999566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007114473290857859\n",
      "Training Loss: 0.006988715225015767\n",
      "Training Loss: 0.0072459974675439295\n",
      "Validation Loss: 0.0042374135450240265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007097661864827387\n",
      "Training Loss: 0.006970487832440995\n",
      "Training Loss: 0.007228235781658441\n",
      "Validation Loss: 0.004218975487531403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007081265992019326\n",
      "Training Loss: 0.0069525837147375565\n",
      "Training Loss: 0.007210818923776969\n",
      "Validation Loss: 0.004201206964639465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007065304081188515\n",
      "Training Loss: 0.0069350130890961734\n",
      "Training Loss: 0.007193761283997446\n",
      "Validation Loss: 0.004184076007916017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00704978542518802\n",
      "Training Loss: 0.006917783701210283\n",
      "Training Loss: 0.007177076262887567\n",
      "Validation Loss: 0.004167550641080636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007034709478029981\n",
      "Training Loss: 0.0069009014259791\n",
      "Training Loss: 0.007160770552000031\n",
      "Validation Loss: 0.004151600716489084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007020070848520845\n",
      "Training Loss: 0.006884368943865411\n",
      "Training Loss: 0.00714484627940692\n",
      "Validation Loss: 0.004136197862811805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007005860868375748\n",
      "Training Loss: 0.006868188030202873\n",
      "Training Loss: 0.007129306703573093\n",
      "Validation Loss: 0.004121307490309805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0069920655724126845\n",
      "Training Loss: 0.006852358397445642\n",
      "Training Loss: 0.007114148378605023\n",
      "Validation Loss: 0.004106897570381171\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006978670755634084\n",
      "Training Loss: 0.006836877001915127\n",
      "Training Loss: 0.0070993693999480455\n",
      "Validation Loss: 0.00409294220911904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0069656601303722705\n",
      "Training Loss: 0.0068217404966708275\n",
      "Training Loss: 0.0070849635475315155\n",
      "Validation Loss: 0.004079412383791269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006953016717452556\n",
      "Training Loss: 0.006806944851414301\n",
      "Training Loss: 0.007070924580330029\n",
      "Validation Loss: 0.004066282439861823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006940725579624996\n",
      "Training Loss: 0.006792484186589718\n",
      "Training Loss: 0.007057244397001341\n",
      "Validation Loss: 0.004053526956933352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006928768032230437\n",
      "Training Loss: 0.006778351897373795\n",
      "Training Loss: 0.007043914222158491\n",
      "Validation Loss: 0.004041122419110844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0069171289174119015\n",
      "Training Loss: 0.0067645415180595594\n",
      "Training Loss: 0.007030925755389035\n",
      "Validation Loss: 0.004029048096618793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006905792435863986\n",
      "Training Loss: 0.006751047278521582\n",
      "Training Loss: 0.007018270646221935\n",
      "Validation Loss: 0.004017289628515418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006894745976896956\n",
      "Training Loss: 0.006737859635613859\n",
      "Training Loss: 0.00700593730667606\n",
      "Validation Loss: 0.0040058248985056465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00688397329649888\n",
      "Training Loss: 0.006724972667871043\n",
      "Training Loss: 0.006993916912470013\n",
      "Validation Loss: 0.003994639408303781\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006873462961520999\n",
      "Training Loss: 0.006712376901996322\n",
      "Training Loss: 0.006982198518235236\n",
      "Validation Loss: 0.003983719899643506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0068632008403074\n",
      "Training Loss: 0.006700065808836371\n",
      "Training Loss: 0.0069707717711571604\n",
      "Validation Loss: 0.003973048999173085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006853175085270777\n",
      "Training Loss: 0.006688029770739377\n",
      "Training Loss: 0.006959626405732706\n",
      "Validation Loss: 0.003962620444009813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00684337496815715\n",
      "Training Loss: 0.0066762605792609975\n",
      "Training Loss: 0.006948751260060817\n",
      "Validation Loss: 0.003952419198264651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006833789931843057\n",
      "Training Loss: 0.006664751672069542\n",
      "Training Loss: 0.006938138215336949\n",
      "Validation Loss: 0.003942437290758146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006824408583343029\n",
      "Training Loss: 0.006653492188779637\n",
      "Training Loss: 0.006927774075884372\n",
      "Validation Loss: 0.003932665936711631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006815221426077187\n",
      "Training Loss: 0.006642474916297943\n",
      "Training Loss: 0.006917650505201891\n",
      "Validation Loss: 0.003923097002749028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006806218736455776\n",
      "Training Loss: 0.006631691829534247\n",
      "Training Loss: 0.0069077577989082786\n",
      "Validation Loss: 0.0039137200768932364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006797392951557413\n",
      "Training Loss: 0.006621134887100197\n",
      "Training Loss: 0.006898085399297997\n",
      "Validation Loss: 0.0039045288622525805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006788734650472179\n",
      "Training Loss: 0.006610796340974048\n",
      "Training Loss: 0.006888626131694764\n",
      "Validation Loss: 0.0038955171613462188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006780236940830946\n",
      "Training Loss: 0.006600669055478648\n",
      "Training Loss: 0.006879370493115857\n",
      "Validation Loss: 0.0038866804745257572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0067718917684396725\n",
      "Training Loss: 0.006590744620189071\n",
      "Training Loss: 0.006870307283243164\n",
      "Validation Loss: 0.003878007090933035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006763690721709281\n",
      "Training Loss: 0.006581015263218432\n",
      "Training Loss: 0.006861430283170194\n",
      "Validation Loss: 0.003869495701222691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006755627898965031\n",
      "Training Loss: 0.0065714752598432825\n",
      "Training Loss: 0.006852730261161923\n",
      "Validation Loss: 0.0038611376893528727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006747696297243238\n",
      "Training Loss: 0.006562116070417687\n",
      "Training Loss: 0.0068442007584962996\n",
      "Validation Loss: 0.003852929110283011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.0067398892814526335\n",
      "Training Loss: 0.006552930970210582\n",
      "Training Loss: 0.006835832855431363\n",
      "Validation Loss: 0.0038448638907958117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006732201316626742\n",
      "Training Loss: 0.0065439143194817\n",
      "Training Loss: 0.006827619827818126\n",
      "Validation Loss: 0.0038369353690571833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006724626639625058\n",
      "Training Loss: 0.006535059742163867\n",
      "Training Loss: 0.006819556088885292\n",
      "Validation Loss: 0.0038291404162418474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006717161128181033\n",
      "Training Loss: 0.006526361235883087\n",
      "Training Loss: 0.006811633604811505\n",
      "Validation Loss: 0.003821476163823953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006709798311349004\n",
      "Training Loss: 0.006517812459496781\n",
      "Training Loss: 0.006803846535040066\n",
      "Validation Loss: 0.003813932161893319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.0067025329935131595\n",
      "Training Loss: 0.00650940750783775\n",
      "Training Loss: 0.006796189213637263\n",
      "Validation Loss: 0.003806507620395402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006695361427264288\n",
      "Training Loss: 0.006501140729524195\n",
      "Training Loss: 0.00678865454159677\n",
      "Validation Loss: 0.0037991961090187176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006688279110821895\n",
      "Training Loss: 0.00649300756980665\n",
      "Training Loss: 0.006781237756367773\n",
      "Validation Loss: 0.0037919949580590877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006681281354394742\n",
      "Training Loss: 0.006485002911649645\n",
      "Training Loss: 0.006773934423690662\n",
      "Validation Loss: 0.0037849030661490863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006674365277867764\n",
      "Training Loss: 0.006477121512871236\n",
      "Training Loss: 0.00676673881476745\n",
      "Validation Loss: 0.00377791411939255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006667527776444331\n",
      "Training Loss: 0.006469359949696809\n",
      "Training Loss: 0.006759646453429013\n",
      "Validation Loss: 0.0037710191027962425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006660763320396655\n",
      "Training Loss: 0.006461711698793806\n",
      "Training Loss: 0.006752652757568285\n",
      "Validation Loss: 0.003764221253752541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006654069948708639\n",
      "Training Loss: 0.006454173047095537\n",
      "Training Loss: 0.006745753358118236\n",
      "Validation Loss: 0.0037575128587653463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006647444276604801\n",
      "Training Loss: 0.006446741319377907\n",
      "Training Loss: 0.006738943890668452\n",
      "Validation Loss: 0.003750894155897451\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006640883657964878\n",
      "Training Loss: 0.006439409867161885\n",
      "Training Loss: 0.006732220117701217\n",
      "Validation Loss: 0.0037443605696342967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006634384977514856\n",
      "Training Loss: 0.006432176928501576\n",
      "Training Loss: 0.006725578595651313\n",
      "Validation Loss: 0.003737905224931709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006627945895306766\n",
      "Training Loss: 0.006425038786255754\n",
      "Training Loss: 0.006719016941497102\n",
      "Validation Loss: 0.003731529135518613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006621563563239761\n",
      "Training Loss: 0.00641798984608613\n",
      "Training Loss: 0.006712529170326889\n",
      "Validation Loss: 0.0037252254276588727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006615235350327566\n",
      "Training Loss: 0.00641102857538499\n",
      "Training Loss: 0.006706113799009472\n",
      "Validation Loss: 0.003718995686693724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006608960625017062\n",
      "Training Loss: 0.006404152007307857\n",
      "Training Loss: 0.006699767879908904\n",
      "Validation Loss: 0.003712835652345603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.0066027368861250576\n",
      "Training Loss: 0.006397355879307724\n",
      "Training Loss: 0.0066934890160337095\n",
      "Validation Loss: 0.003706742641829959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006596561593469232\n",
      "Training Loss: 0.006390637982985936\n",
      "Training Loss: 0.006687271140981466\n",
      "Validation Loss: 0.0037007151352074206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006590433361125179\n",
      "Training Loss: 0.006383994330535643\n",
      "Training Loss: 0.006681114281527698\n",
      "Validation Loss: 0.003694748651142117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006584349823533557\n",
      "Training Loss: 0.006377423073863611\n",
      "Training Loss: 0.006675015088403597\n",
      "Validation Loss: 0.0036888431556250773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006578310625627637\n",
      "Training Loss: 0.006370922208297998\n",
      "Training Loss: 0.006668971081962809\n",
      "Validation Loss: 0.0036829922091885566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006572311669588089\n",
      "Training Loss: 0.006364486222155392\n",
      "Training Loss: 0.006662979734828696\n",
      "Validation Loss: 0.0036771984305232763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006566354028764181\n",
      "Training Loss: 0.006358115893090144\n",
      "Training Loss: 0.006657038397388532\n",
      "Validation Loss: 0.0036714546698972247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006560435352148488\n",
      "Training Loss: 0.006351806145394221\n",
      "Training Loss: 0.006651145953219384\n",
      "Validation Loss: 0.003665761787998961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006554553310852498\n",
      "Training Loss: 0.006345555576262996\n",
      "Training Loss: 0.006645298172952607\n",
      "Validation Loss: 0.0036601177364420355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.00654870767495595\n",
      "Training Loss: 0.006339361519785598\n",
      "Training Loss: 0.006639494333649054\n",
      "Validation Loss: 0.0036545174544300426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006542896087048575\n",
      "Training Loss: 0.006333222228568048\n",
      "Training Loss: 0.006633731879992411\n",
      "Validation Loss: 0.0036489625809337485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006537117948755622\n",
      "Training Loss: 0.006327134512830525\n",
      "Training Loss: 0.00662800807855092\n",
      "Validation Loss: 0.003643452234335997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006531371119199321\n",
      "Training Loss: 0.006321096555329859\n",
      "Training Loss: 0.006622321887407452\n",
      "Validation Loss: 0.003637980281249777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006525655365549028\n",
      "Training Loss: 0.00631510692415759\n",
      "Training Loss: 0.006616671490482986\n",
      "Validation Loss: 0.0036325493285934746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006519970078952611\n",
      "Training Loss: 0.006309162537218071\n",
      "Training Loss: 0.006611054608365521\n",
      "Validation Loss: 0.003627154844017762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006514312923536636\n",
      "Training Loss: 0.006303261778084561\n",
      "Training Loss: 0.006605469237547368\n",
      "Validation Loss: 0.0036217957954811915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006508681361447088\n",
      "Training Loss: 0.006297401978517882\n",
      "Training Loss: 0.0065999126248061655\n",
      "Validation Loss: 0.0036164682798003884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.00650307564123068\n",
      "Training Loss: 0.006291581924888306\n",
      "Training Loss: 0.00659438440692611\n",
      "Validation Loss: 0.0036111712060722238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.0064974944345885886\n",
      "Training Loss: 0.006285798241151497\n",
      "Training Loss: 0.006588882158976048\n",
      "Validation Loss: 0.00360590946635629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006491936764214188\n",
      "Training Loss: 0.0062800495827104895\n",
      "Training Loss: 0.006583404138218611\n",
      "Validation Loss: 0.0036006745989591387\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006486400553840212\n",
      "Training Loss: 0.006274333722540177\n",
      "Training Loss: 0.006577948093181476\n",
      "Validation Loss: 0.003595465178120086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006480885663768277\n",
      "Training Loss: 0.006268649574485608\n",
      "Training Loss: 0.00657251181663014\n",
      "Validation Loss: 0.0035902816969692036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006475388624239713\n",
      "Training Loss: 0.006262993810232729\n",
      "Training Loss: 0.006567094831261784\n",
      "Validation Loss: 0.003585119593072306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006469909458537586\n",
      "Training Loss: 0.006257364373304881\n",
      "Training Loss: 0.006561694230185822\n",
      "Validation Loss: 0.0035799804243018454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006464447538601235\n",
      "Training Loss: 0.006251760219456628\n",
      "Training Loss: 0.006556307906284928\n",
      "Validation Loss: 0.0035748570199972125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0064589998970041055\n",
      "Training Loss: 0.0062461783789331095\n",
      "Training Loss: 0.006550934695405885\n",
      "Validation Loss: 0.0035697534573107454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006453566282289103\n",
      "Training Loss: 0.006240616881405004\n",
      "Training Loss: 0.006545572800096124\n",
      "Validation Loss: 0.003564667571440674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006448144263122231\n",
      "Training Loss: 0.0062350737990345805\n",
      "Training Loss: 0.00654021878959611\n",
      "Validation Loss: 0.003559594578894504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.00644273268757388\n",
      "Training Loss: 0.0062295466859359295\n",
      "Training Loss: 0.006534872847842052\n",
      "Validation Loss: 0.0035545334947201307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006437330326298252\n",
      "Training Loss: 0.006224034068873152\n",
      "Training Loss: 0.0065295312996022405\n",
      "Validation Loss: 0.0035494820455486856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006431934374850243\n",
      "Training Loss: 0.0062185318145202475\n",
      "Training Loss: 0.006524193006334826\n",
      "Validation Loss: 0.003544440182982787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.00642654400318861\n",
      "Training Loss: 0.006213039509602823\n",
      "Training Loss: 0.006518854334717617\n",
      "Validation Loss: 0.003539401836421215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006421157178701833\n",
      "Training Loss: 0.006207554044085555\n",
      "Training Loss: 0.006513515256810934\n",
      "Validation Loss: 0.003534367442748436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006415771764004603\n",
      "Training Loss: 0.0062020732765086\n",
      "Training Loss: 0.0065081725479103625\n",
      "Validation Loss: 0.0035293382354436463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00641038637375459\n",
      "Training Loss: 0.0061965945945121345\n",
      "Training Loss: 0.006502823246410117\n",
      "Validation Loss: 0.00352430855724542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006404998814105056\n",
      "Training Loss: 0.006191116074332968\n",
      "Training Loss: 0.006497466412838548\n",
      "Validation Loss: 0.003519274438260479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0063996070058783515\n",
      "Training Loss: 0.006185634608264081\n",
      "Training Loss: 0.006492099885363132\n",
      "Validation Loss: 0.003514234718259717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006394208985730074\n",
      "Training Loss: 0.006180148637504317\n",
      "Training Loss: 0.006486720109824091\n",
      "Validation Loss: 0.0035091887039833524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.0063888018432771785\n",
      "Training Loss: 0.006174655001377687\n",
      "Training Loss: 0.006481325775384903\n",
      "Validation Loss: 0.003504134662281931\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006383385867229663\n",
      "Training Loss: 0.006169151062495075\n",
      "Training Loss: 0.006475913845933974\n",
      "Validation Loss: 0.0034990650680167285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006377955195493996\n",
      "Training Loss: 0.006163635171251371\n",
      "Training Loss: 0.00647048260550946\n",
      "Validation Loss: 0.00349398278317341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006372511041117832\n",
      "Training Loss: 0.00615810280374717\n",
      "Training Loss: 0.006465028674574569\n",
      "Validation Loss: 0.003488881453306655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0063670490286313\n",
      "Training Loss: 0.006152554166037589\n",
      "Training Loss: 0.006459550466388464\n",
      "Validation Loss: 0.003483762103917726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006361567988060415\n",
      "Training Loss: 0.006146984138176777\n",
      "Training Loss: 0.006454044769052416\n",
      "Validation Loss: 0.003478616965264919\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006356064806459472\n",
      "Training Loss: 0.006141392649733461\n",
      "Training Loss: 0.006448510114569217\n",
      "Validation Loss: 0.0034734454565796625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006350536880781874\n",
      "Training Loss: 0.006135774090653285\n",
      "Training Loss: 0.006442943438887596\n",
      "Validation Loss: 0.003468245250863557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006344982971204445\n",
      "Training Loss: 0.006130128190852702\n",
      "Training Loss: 0.006437342688441277\n",
      "Validation Loss: 0.0034630135436845796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0063394005905138325\n",
      "Training Loss: 0.006124452808289788\n",
      "Training Loss: 0.006431705019203946\n",
      "Validation Loss: 0.0034577486607549565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.00633378709142562\n",
      "Training Loss: 0.0061187450226861985\n",
      "Training Loss: 0.006426029661670327\n",
      "Validation Loss: 0.0034524440631961053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006328142238198779\n",
      "Training Loss: 0.006113002836355008\n",
      "Training Loss: 0.006420314165297896\n",
      "Validation Loss: 0.0034471004560401434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006322460960363969\n",
      "Training Loss: 0.00610722450481262\n",
      "Training Loss: 0.006414555480005219\n",
      "Validation Loss: 0.0034417129249908448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006316743375500664\n",
      "Training Loss: 0.006101406919187866\n",
      "Training Loss: 0.0064087518199812624\n",
      "Validation Loss: 0.0034362790606434594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006310987432370894\n",
      "Training Loss: 0.006095550460158848\n",
      "Training Loss: 0.006402902514673769\n",
      "Validation Loss: 0.0034307972017905853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006305191845749505\n",
      "Training Loss: 0.006089651978109032\n",
      "Training Loss: 0.006397006281185895\n",
      "Validation Loss: 0.003425266241832647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006299354584771208\n",
      "Training Loss: 0.006083711063256487\n",
      "Training Loss: 0.0063910616876091805\n",
      "Validation Loss: 0.0034196787001041884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006293475156417117\n",
      "Training Loss: 0.006077727344818413\n",
      "Training Loss: 0.006385068439412862\n",
      "Validation Loss: 0.0034140407243806324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.00628755416313652\n",
      "Training Loss: 0.0060717003780882805\n",
      "Training Loss: 0.006379024895140901\n",
      "Validation Loss: 0.0034083430119005317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006281588597339578\n",
      "Training Loss: 0.006065629178192466\n",
      "Training Loss: 0.006372932954691351\n",
      "Validation Loss: 0.003402587140156898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0062755811895476655\n",
      "Training Loss: 0.006059514638036489\n",
      "Training Loss: 0.006366791145410389\n",
      "Validation Loss: 0.0033967714649468157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00626953027327545\n",
      "Training Loss: 0.006053356048068963\n",
      "Training Loss: 0.006360600311309099\n",
      "Validation Loss: 0.0033908970915618236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006263437099987641\n",
      "Training Loss: 0.006047155868727714\n",
      "Training Loss: 0.006354361217236146\n",
      "Validation Loss: 0.0033849581717670467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006257302168523893\n",
      "Training Loss: 0.0060409143089782446\n",
      "Training Loss: 0.006348076331196353\n",
      "Validation Loss: 0.00337896068067698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006251128015574068\n",
      "Training Loss: 0.0060346337017836045\n",
      "Training Loss: 0.006341746796388179\n",
      "Validation Loss: 0.0033729037903039976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006244915939169005\n",
      "Training Loss: 0.0060283172619529065\n",
      "Training Loss: 0.006335374427726493\n",
      "Validation Loss: 0.0033667852076586713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006238668292644434\n",
      "Training Loss: 0.006021966377156787\n",
      "Training Loss: 0.006328962786355987\n",
      "Validation Loss: 0.0033606088751654945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0062323890894185755\n",
      "Training Loss: 0.006015584695269353\n",
      "Training Loss: 0.006322514991043135\n",
      "Validation Loss: 0.0033543732166394927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006226078826002777\n",
      "Training Loss: 0.006009175354265608\n",
      "Training Loss: 0.006316034293267876\n",
      "Validation Loss: 0.0033480846218429923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006219743767869659\n",
      "Training Loss: 0.006002741627744399\n",
      "Training Loss: 0.006309524272801355\n",
      "Validation Loss: 0.0033417454740199983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006213386317249388\n",
      "Training Loss: 0.0059962895250646395\n",
      "Training Loss: 0.00630298864794895\n",
      "Validation Loss: 0.00333535623752376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006207011633669026\n",
      "Training Loss: 0.00598982265451923\n",
      "Training Loss: 0.006296434864634648\n",
      "Validation Loss: 0.0033289225879282263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006200624724733643\n",
      "Training Loss: 0.0059833453252213075\n",
      "Training Loss: 0.006289865287253633\n",
      "Validation Loss: 0.003322448039929686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006194229720276781\n",
      "Training Loss: 0.005976864260737784\n",
      "Training Loss: 0.006283286636462435\n",
      "Validation Loss: 0.003315937454194835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.0061878318758681414\n",
      "Training Loss: 0.005970383111271076\n",
      "Training Loss: 0.006276704039191827\n",
      "Validation Loss: 0.0033093944893040684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006181436430197209\n",
      "Training Loss: 0.005963909195852466\n",
      "Training Loss: 0.006270121050765738\n",
      "Validation Loss: 0.00330282596667203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006175048486329615\n",
      "Training Loss: 0.00595744562218897\n",
      "Training Loss: 0.006263546084519476\n",
      "Validation Loss: 0.003296235680260978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006168675379594788\n",
      "Training Loss: 0.005950998413609341\n",
      "Training Loss: 0.006256982277845964\n",
      "Validation Loss: 0.003289631327216545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.0061623209703247995\n",
      "Training Loss: 0.005944575252942741\n",
      "Training Loss: 0.006250437734415755\n",
      "Validation Loss: 0.0032830163980363293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006155990430852398\n",
      "Training Loss: 0.005938179820077494\n",
      "Training Loss: 0.006243915917584672\n",
      "Validation Loss: 0.003276395234750228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006149690601159818\n",
      "Training Loss: 0.005931817825767211\n",
      "Training Loss: 0.006237422885606065\n",
      "Validation Loss: 0.003269777251302861\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006143425234477036\n",
      "Training Loss: 0.0059254949516616764\n",
      "Training Loss: 0.00623096514493227\n",
      "Validation Loss: 0.0032631663090204087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006137200609082356\n",
      "Training Loss: 0.005919214530149475\n",
      "Training Loss: 0.006224546037847176\n",
      "Validation Loss: 0.003256570562207548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006131020446773618\n",
      "Training Loss: 0.005912983391899615\n",
      "Training Loss: 0.006218169841449708\n",
      "Validation Loss: 0.003249993841451582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006124890708597377\n",
      "Training Loss: 0.005906804284313694\n",
      "Training Loss: 0.006211843185592442\n",
      "Validation Loss: 0.0032434412186672346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006118814849760384\n",
      "Training Loss: 0.005900682097999379\n",
      "Training Loss: 0.006205567829310894\n",
      "Validation Loss: 0.0032369190214850594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006112796530360356\n",
      "Training Loss: 0.005894621032639407\n",
      "Training Loss: 0.006199349056696519\n",
      "Validation Loss: 0.0032304313676065526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006106839892454446\n",
      "Training Loss: 0.005888623463106341\n",
      "Training Loss: 0.006193191048223526\n",
      "Validation Loss: 0.0032239817449132378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.00610094829578884\n",
      "Training Loss: 0.00588269300351385\n",
      "Training Loss: 0.006187093418557197\n",
      "Validation Loss: 0.0032175748276764924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006095122984261252\n",
      "Training Loss: 0.005876831879722886\n",
      "Training Loss: 0.006181061118841171\n",
      "Validation Loss: 0.003211216957915281\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006089368312386796\n",
      "Training Loss: 0.005871042107464745\n",
      "Training Loss: 0.006175095872022212\n",
      "Validation Loss: 0.00320490994137513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006083686057827435\n",
      "Training Loss: 0.005865326279890723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [16:53<07:14, 144.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006169200544245541\n",
      "Validation Loss: 0.0031986577309448313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.182696676813066\n",
      "Training Loss: 0.14015614684671163\n",
      "Training Loss: 0.0992707716114819\n",
      "Validation Loss: 0.06719352187735311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06765807552263141\n",
      "Training Loss: 0.06434168759733438\n",
      "Training Loss: 0.0626331977546215\n",
      "Validation Loss: 0.06031063613429498\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.058931391425430774\n",
      "Training Loss: 0.057036374490708114\n",
      "Training Loss: 0.05517872439697385\n",
      "Validation Loss: 0.052603770089283415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05050677918829024\n",
      "Training Loss: 0.04777972253970802\n",
      "Training Loss: 0.045267654955387114\n",
      "Validation Loss: 0.04177781175612734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03935717835091054\n",
      "Training Loss: 0.03587447816506028\n",
      "Training Loss: 0.03274729670956731\n",
      "Validation Loss: 0.0282103144929985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02664753945544362\n",
      "Training Loss: 0.024152914956212045\n",
      "Training Loss: 0.022401756094768643\n",
      "Validation Loss: 0.01907340498913205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.019751311121508477\n",
      "Training Loss: 0.01930307281203568\n",
      "Training Loss: 0.018688760716468095\n",
      "Validation Loss: 0.015880943485274072\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.017093702398706227\n",
      "Training Loss: 0.01684325932059437\n",
      "Training Loss: 0.016352129359729586\n",
      "Validation Loss: 0.013517752383950721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01502030809642747\n",
      "Training Loss: 0.014829015608411282\n",
      "Training Loss: 0.014479106257203967\n",
      "Validation Loss: 0.011712021921667155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013502464103512466\n",
      "Training Loss: 0.013420454005245119\n",
      "Training Loss: 0.013237798777408898\n",
      "Validation Loss: 0.010635147509531359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012581444343086333\n",
      "Training Loss: 0.012570511878002434\n",
      "Training Loss: 0.012493551701772958\n",
      "Validation Loss: 0.010019369852425677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.012012396415229887\n",
      "Training Loss: 0.012025732656475156\n",
      "Training Loss: 0.012002129547763616\n",
      "Validation Loss: 0.009605061995346895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.011602656748145819\n",
      "Training Loss: 0.011622035342734307\n",
      "Training Loss: 0.011628062024246901\n",
      "Validation Loss: 0.009276275805542978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.011266935702878981\n",
      "Training Loss: 0.011286762177478522\n",
      "Training Loss: 0.011312664593569935\n",
      "Validation Loss: 0.008987053315772603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010969968386925757\n",
      "Training Loss: 0.010988259622827172\n",
      "Training Loss: 0.011029853192158044\n",
      "Validation Loss: 0.008717970064516817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010696126932743936\n",
      "Training Loss: 0.010711802155710756\n",
      "Training Loss: 0.010767168805468828\n",
      "Validation Loss: 0.008460299802546421\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.010438073333352805\n",
      "Training Loss: 0.010450244066305459\n",
      "Training Loss: 0.010518470474053174\n",
      "Validation Loss: 0.008210247408682377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.01019240171648562\n",
      "Training Loss: 0.010200211964547633\n",
      "Training Loss: 0.010280856920871884\n",
      "Validation Loss: 0.007966504696484529\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009957740486133843\n",
      "Training Loss: 0.009960354185895994\n",
      "Training Loss: 0.010053206842858344\n",
      "Validation Loss: 0.0077290813742059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009733788464218377\n",
      "Training Loss: 0.009730425954330713\n",
      "Training Loss: 0.009835383170284331\n",
      "Validation Loss: 0.007498660833794582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.009520773194963113\n",
      "Training Loss: 0.009510730538750067\n",
      "Training Loss: 0.009627722925506533\n",
      "Validation Loss: 0.007276180828136675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009319109354401008\n",
      "Training Loss: 0.009301782429683953\n",
      "Training Loss: 0.009430726149585098\n",
      "Validation Loss: 0.007062584972741564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009129184592748061\n",
      "Training Loss: 0.009104076091898606\n",
      "Training Loss: 0.009244847551453859\n",
      "Validation Loss: 0.0068586547361958895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008951237248256803\n",
      "Training Loss: 0.008917964465217665\n",
      "Training Loss: 0.009070383312646299\n",
      "Validation Loss: 0.0066649331240339225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008785307833459228\n",
      "Training Loss: 0.008743595755659044\n",
      "Training Loss: 0.008907424039207398\n",
      "Validation Loss: 0.006481712095418505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008631223466945812\n",
      "Training Loss: 0.008580893479520455\n",
      "Training Loss: 0.008755829588044434\n",
      "Validation Loss: 0.006309011511588364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00848860829253681\n",
      "Training Loss: 0.00842957420856692\n",
      "Training Loss: 0.008615271076560021\n",
      "Validation Loss: 0.006146643182597636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008356933140894397\n",
      "Training Loss: 0.00828918067854829\n",
      "Training Loss: 0.008485253631370142\n",
      "Validation Loss: 0.005994239638904842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008235547792864964\n",
      "Training Loss: 0.008159132418222725\n",
      "Training Loss: 0.008365176895167678\n",
      "Validation Loss: 0.0058513005536175175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008123731036903337\n",
      "Training Loss: 0.008038760690251365\n",
      "Training Loss: 0.008254368698690086\n",
      "Validation Loss: 0.005717249492999543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008020737159531563\n",
      "Training Loss: 0.007927363000344485\n",
      "Training Loss: 0.008152136403368785\n",
      "Validation Loss: 0.005591476221014274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00792582222027704\n",
      "Training Loss: 0.007824227469973266\n",
      "Training Loss: 0.008057785208802671\n",
      "Validation Loss: 0.005473349481465274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007838264647871256\n",
      "Training Loss: 0.007728664074093104\n",
      "Training Loss: 0.00797066182247363\n",
      "Validation Loss: 0.005362275009451622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.0077574105537496505\n",
      "Training Loss: 0.007640037824166938\n",
      "Training Loss: 0.007890167162986472\n",
      "Validation Loss: 0.005257699997007345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0076826621068175885\n",
      "Training Loss: 0.0075577683409210296\n",
      "Training Loss: 0.007815761541714893\n",
      "Validation Loss: 0.0051591239471951225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0076134975394234064\n",
      "Training Loss: 0.0074813531746622175\n",
      "Training Loss: 0.007746984288096428\n",
      "Validation Loss: 0.005066127872115441\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0075494698458351195\n",
      "Training Loss: 0.0074103598517831415\n",
      "Training Loss: 0.0076834372128359975\n",
      "Validation Loss: 0.004978345809085818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0074902046041097495\n",
      "Training Loss: 0.007344427263597027\n",
      "Training Loss: 0.007624791203998029\n",
      "Validation Loss: 0.0048954915883166064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007435387398581952\n",
      "Training Loss: 0.007283259275136515\n",
      "Training Loss: 0.0075707686087116595\n",
      "Validation Loss: 0.004817334192103884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007384762394940481\n",
      "Training Loss: 0.007226610938087106\n",
      "Training Loss: 0.007521135362330824\n",
      "Validation Loss: 0.004743697226382374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007338108670664951\n",
      "Training Loss: 0.007174276732839644\n",
      "Training Loss: 0.007475682073272765\n",
      "Validation Loss: 0.004674438449941324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007295234194025398\n",
      "Training Loss: 0.007126072045648471\n",
      "Training Loss: 0.007434212043881417\n",
      "Validation Loss: 0.004609441523325075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007255958977621049\n",
      "Training Loss: 0.007081823861226439\n",
      "Training Loss: 0.007396529957186431\n",
      "Validation Loss: 0.004548600995180647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007220103703439236\n",
      "Training Loss: 0.007041353913955391\n",
      "Training Loss: 0.007362425804603845\n",
      "Validation Loss: 0.004491810637180892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007187480569118634\n",
      "Training Loss: 0.007004471626132726\n",
      "Training Loss: 0.007331678736954927\n",
      "Validation Loss: 0.004438959721350268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007157892932882532\n",
      "Training Loss: 0.006970970658585429\n",
      "Training Loss: 0.007304047598736361\n",
      "Validation Loss: 0.004389912334762597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007131127113243565\n",
      "Training Loss: 0.006940626719151624\n",
      "Training Loss: 0.007279277816414833\n",
      "Validation Loss: 0.0043445260282291955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007106959791854024\n",
      "Training Loss: 0.006913199506816454\n",
      "Training Loss: 0.007257102088769898\n",
      "Validation Loss: 0.004302634019143043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00708515883772634\n",
      "Training Loss: 0.006888437237939797\n",
      "Training Loss: 0.007237250370671973\n",
      "Validation Loss: 0.004264054291494442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007065486951032654\n",
      "Training Loss: 0.006866081369807943\n",
      "Training Loss: 0.0072194519767072056\n",
      "Validation Loss: 0.004228587644279338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0070477108482737095\n",
      "Training Loss: 0.006845874938881025\n",
      "Training Loss: 0.0072034456534311175\n",
      "Validation Loss: 0.004196030804573485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007031602151691914\n",
      "Training Loss: 0.006827569455490448\n",
      "Training Loss: 0.007188984253443778\n",
      "Validation Loss: 0.0041661702993775855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007016945853829384\n",
      "Training Loss: 0.006810926033067517\n",
      "Training Loss: 0.007175839836709202\n",
      "Validation Loss: 0.004138794486944595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007003543219761923\n",
      "Training Loss: 0.006795724958064966\n",
      "Training Loss: 0.00716380501165986\n",
      "Validation Loss: 0.0041136997333319665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006991212066495791\n",
      "Training Loss: 0.006781764499028214\n",
      "Training Loss: 0.007152693128446117\n",
      "Validation Loss: 0.0040906725746966644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006979788587195799\n",
      "Training Loss: 0.006768861991004087\n",
      "Training Loss: 0.0071423441718798135\n",
      "Validation Loss: 0.0040695258505181985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006969130528159439\n",
      "Training Loss: 0.006756859176675789\n",
      "Training Loss: 0.007132618263131008\n",
      "Validation Loss: 0.004050075134074085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006959113567136228\n",
      "Training Loss: 0.006745614668470807\n",
      "Training Loss: 0.007123398334952072\n",
      "Validation Loss: 0.004032148950827423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006949629795271904\n",
      "Training Loss: 0.006735009009717032\n",
      "Training Loss: 0.007114584980299697\n",
      "Validation Loss: 0.004015591225764724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0069405904226005075\n",
      "Training Loss: 0.006724940031417646\n",
      "Training Loss: 0.0071060976374428715\n",
      "Validation Loss: 0.004000251513665144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006931918982882052\n",
      "Training Loss: 0.006715321545489133\n",
      "Training Loss: 0.0070978692744392904\n",
      "Validation Loss: 0.003986001438513565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006923553239321336\n",
      "Training Loss: 0.006706080926232971\n",
      "Training Loss: 0.007089847972383723\n",
      "Validation Loss: 0.003972720930331878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006915442256722599\n",
      "Training Loss: 0.006697159301838837\n",
      "Training Loss: 0.007081990123260766\n",
      "Validation Loss: 0.003960303619524904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006907543241977692\n",
      "Training Loss: 0.006688506843056529\n",
      "Training Loss: 0.007074263817630708\n",
      "Validation Loss: 0.003948649851961083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006899823350831866\n",
      "Training Loss: 0.006680082851671614\n",
      "Training Loss: 0.007066642445279285\n",
      "Validation Loss: 0.003937678126450838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006892254523700103\n",
      "Training Loss: 0.006671855461900122\n",
      "Training Loss: 0.007059107101522386\n",
      "Validation Loss: 0.003927311122291878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0068848153809085485\n",
      "Training Loss: 0.00666379693779163\n",
      "Training Loss: 0.007051641303114593\n",
      "Validation Loss: 0.003917482954952238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006877488245954737\n",
      "Training Loss: 0.006655885930522345\n",
      "Training Loss: 0.007044235899811611\n",
      "Validation Loss: 0.003908130429224686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006870259441202506\n",
      "Training Loss: 0.006648104576161131\n",
      "Training Loss: 0.007036880255909637\n",
      "Validation Loss: 0.003899202614059944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006863117018947378\n",
      "Training Loss: 0.006640437543392181\n",
      "Training Loss: 0.007029569931328297\n",
      "Validation Loss: 0.0038906518144930682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006856053171213716\n",
      "Training Loss: 0.006632874421775341\n",
      "Training Loss: 0.007022300000535324\n",
      "Validation Loss: 0.003882437956184567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006849060266977176\n",
      "Training Loss: 0.006625404338119551\n",
      "Training Loss: 0.007015067683532834\n",
      "Validation Loss: 0.0038745200256241506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006842132529709488\n",
      "Training Loss: 0.006618019525194541\n",
      "Training Loss: 0.007007870755624026\n",
      "Validation Loss: 0.0038668733937770464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006835266159614548\n",
      "Training Loss: 0.006610713244881481\n",
      "Training Loss: 0.007000708556734026\n",
      "Validation Loss: 0.003859460960780637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0068284567957744005\n",
      "Training Loss: 0.00660348042845726\n",
      "Training Loss: 0.006993578772526234\n",
      "Validation Loss: 0.003852266142029692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00682170084794052\n",
      "Training Loss: 0.006596315965871327\n",
      "Training Loss: 0.006986481390194968\n",
      "Validation Loss: 0.0038452639056139448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006814997427864\n",
      "Training Loss: 0.006589216223219409\n",
      "Training Loss: 0.006979416887043044\n",
      "Validation Loss: 0.003838436918730816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0068083437113091345\n",
      "Training Loss: 0.0065821777581004425\n",
      "Training Loss: 0.006972383341053501\n",
      "Validation Loss: 0.00383176771515792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006801736110355705\n",
      "Training Loss: 0.006575196993071586\n",
      "Training Loss: 0.006965381596237421\n",
      "Validation Loss: 0.003825235372838261\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006795174350263551\n",
      "Training Loss: 0.006568270155694336\n",
      "Training Loss: 0.006958410043735057\n",
      "Validation Loss: 0.003818834213581815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006788655869895592\n",
      "Training Loss: 0.006561396941542626\n",
      "Training Loss: 0.006951469334308058\n",
      "Validation Loss: 0.0038125464650854636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006782179577276111\n",
      "Training Loss: 0.00655457318178378\n",
      "Training Loss: 0.006944558009272441\n",
      "Validation Loss: 0.0038063669161285075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006775743374601006\n",
      "Training Loss: 0.006547796477098018\n",
      "Training Loss: 0.006937675112858414\n",
      "Validation Loss: 0.003800285050090863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0067693463864270595\n",
      "Training Loss: 0.006541066472418606\n",
      "Training Loss: 0.006930822075810283\n",
      "Validation Loss: 0.0037942920220241454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006762986867688597\n",
      "Training Loss: 0.006534379397635348\n",
      "Training Loss: 0.006923995886463672\n",
      "Validation Loss: 0.003788381006589599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00675666389754042\n",
      "Training Loss: 0.0065277347544906664\n",
      "Training Loss: 0.006917197182774544\n",
      "Validation Loss: 0.0037825437696922697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006750374862458557\n",
      "Training Loss: 0.006521129140164703\n",
      "Training Loss: 0.006910423691151663\n",
      "Validation Loss: 0.0037767741491683245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006744118601782248\n",
      "Training Loss: 0.006514560898067429\n",
      "Training Loss: 0.006903674822533503\n",
      "Validation Loss: 0.003771068834375297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00673789348336868\n",
      "Training Loss: 0.006508028846583329\n",
      "Training Loss: 0.00689694942208007\n",
      "Validation Loss: 0.003765423758625147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006731699381489307\n",
      "Training Loss: 0.006501530937384814\n",
      "Training Loss: 0.006890245788963511\n",
      "Validation Loss: 0.003759830551787039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00672553303767927\n",
      "Training Loss: 0.006495064460905269\n",
      "Training Loss: 0.006883563864976168\n",
      "Validation Loss: 0.003754286163517933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006719393646344543\n",
      "Training Loss: 0.006488628392107784\n",
      "Training Loss: 0.006876901055220514\n",
      "Validation Loss: 0.003748787860019823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006713279202231206\n",
      "Training Loss: 0.006482221169862896\n",
      "Training Loss: 0.006870255871908739\n",
      "Validation Loss: 0.003743331280296271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006707187745487318\n",
      "Training Loss: 0.006475839108461514\n",
      "Training Loss: 0.006863627342972904\n",
      "Validation Loss: 0.0037379151503189227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006701119219651446\n",
      "Training Loss: 0.006469482337124645\n",
      "Training Loss: 0.006857013349654153\n",
      "Validation Loss: 0.0037325327284634113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006695069411653094\n",
      "Training Loss: 0.006463146762107499\n",
      "Training Loss: 0.006850410980405286\n",
      "Validation Loss: 0.0037271821023791693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006689037797623314\n",
      "Training Loss: 0.0064568314608186485\n",
      "Training Loss: 0.006843820265494287\n",
      "Validation Loss: 0.0037218586586185553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006683022844372317\n",
      "Training Loss: 0.006450534637551754\n",
      "Training Loss: 0.00683723843540065\n",
      "Validation Loss: 0.003716560728125944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006677022037329152\n",
      "Training Loss: 0.006444253466906957\n",
      "Training Loss: 0.006830663800938055\n",
      "Validation Loss: 0.003711284127797973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006671034218161367\n",
      "Training Loss: 0.006437986301607452\n",
      "Training Loss: 0.006824095202609896\n",
      "Validation Loss: 0.003706028398513543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006665057282662019\n",
      "Training Loss: 0.006431730818585493\n",
      "Training Loss: 0.006817529398249462\n",
      "Validation Loss: 0.003700786711009784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006659089584136382\n",
      "Training Loss: 0.006425485309446231\n",
      "Training Loss: 0.006810965385520831\n",
      "Validation Loss: 0.0036955614733834114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006653128842590377\n",
      "Training Loss: 0.0064192483050283045\n",
      "Training Loss: 0.006804401428671554\n",
      "Validation Loss: 0.00369034855223648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006647174108074978\n",
      "Training Loss: 0.00641301624418702\n",
      "Training Loss: 0.0067978347605094315\n",
      "Validation Loss: 0.0036851414688601255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006641222601174377\n",
      "Training Loss: 0.006406788852182217\n",
      "Training Loss: 0.006791264725616202\n",
      "Validation Loss: 0.0036799424259892004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006635274139698595\n",
      "Training Loss: 0.006400562752969563\n",
      "Training Loss: 0.006784687590552494\n",
      "Validation Loss: 0.0036747437127436816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006629325362737291\n",
      "Training Loss: 0.006394336244557053\n",
      "Training Loss: 0.006778103152755648\n",
      "Validation Loss: 0.003669544928864147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006623374826740473\n",
      "Training Loss: 0.006388107630773448\n",
      "Training Loss: 0.006771508733509108\n",
      "Validation Loss: 0.003664344290187687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006617421173723414\n",
      "Training Loss: 0.00638187492499128\n",
      "Training Loss: 0.0067649029986932875\n",
      "Validation Loss: 0.003659140288547267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006611462819273583\n",
      "Training Loss: 0.006375636274460703\n",
      "Training Loss: 0.0067582839529495686\n",
      "Validation Loss: 0.003653926636207472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006605498796561733\n",
      "Training Loss: 0.006369389733881689\n",
      "Training Loss: 0.006751650181831792\n",
      "Validation Loss: 0.0036487051931973755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006599526118952781\n",
      "Training Loss: 0.006363133724662475\n",
      "Training Loss: 0.006744999273214489\n",
      "Validation Loss: 0.003643470035415938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006593544180504978\n",
      "Training Loss: 0.006356865724665112\n",
      "Training Loss: 0.006738330107182265\n",
      "Validation Loss: 0.00363822034141572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006587551698321477\n",
      "Training Loss: 0.006350584240281023\n",
      "Training Loss: 0.006731640653451904\n",
      "Validation Loss: 0.0036329528280230386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006581545552471653\n",
      "Training Loss: 0.0063442887749988585\n",
      "Training Loss: 0.006724930111085996\n",
      "Validation Loss: 0.0036276707417865314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006575526780216024\n",
      "Training Loss: 0.006337976523791439\n",
      "Training Loss: 0.006718196566216647\n",
      "Validation Loss: 0.003622362948692498\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.0065694933547638355\n",
      "Training Loss: 0.006331645972677507\n",
      "Training Loss: 0.006711438678903506\n",
      "Validation Loss: 0.0036170327031377998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006563442596234381\n",
      "Training Loss: 0.006325296222348698\n",
      "Training Loss: 0.006704655771609396\n",
      "Validation Loss: 0.0036116770450339724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006557375468546524\n",
      "Training Loss: 0.006318926101666875\n",
      "Training Loss: 0.00669784551137127\n",
      "Validation Loss: 0.0036062932562794577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0065512894943822175\n",
      "Training Loss: 0.006312533307936974\n",
      "Training Loss: 0.006691007459303364\n",
      "Validation Loss: 0.003600881076574828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.00654518368828576\n",
      "Training Loss: 0.006306116954074241\n",
      "Training Loss: 0.006684140387224033\n",
      "Validation Loss: 0.0035954351390429426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006539057279587724\n",
      "Training Loss: 0.00629967603366822\n",
      "Training Loss: 0.006677243142621592\n",
      "Validation Loss: 0.0035899561513319947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006532909243833274\n",
      "Training Loss: 0.00629320896056015\n",
      "Training Loss: 0.006670315437950194\n",
      "Validation Loss: 0.0035844424143015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006526738967513665\n",
      "Training Loss: 0.006286714915186167\n",
      "Training Loss: 0.006663355828495696\n",
      "Validation Loss: 0.003578890155571816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006520544563536532\n",
      "Training Loss: 0.006280192563426681\n",
      "Training Loss: 0.006656362750800326\n",
      "Validation Loss: 0.003573298742052879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006514326063334011\n",
      "Training Loss: 0.006273640890722163\n",
      "Training Loss: 0.006649336848640814\n",
      "Validation Loss: 0.0035676684235798175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006508082334185019\n",
      "Training Loss: 0.006267059766687452\n",
      "Training Loss: 0.006642276494530961\n",
      "Validation Loss: 0.003561993210649725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006501812922651879\n",
      "Training Loss: 0.006260447540553287\n",
      "Training Loss: 0.006635181054007262\n",
      "Validation Loss: 0.0035562766061865547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006495516928844154\n",
      "Training Loss: 0.006253803494037129\n",
      "Training Loss: 0.006628050924045965\n",
      "Validation Loss: 0.003550516799866651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.00648919383820612\n",
      "Training Loss: 0.006247126489179209\n",
      "Training Loss: 0.006620884102303535\n",
      "Validation Loss: 0.0035447053679296477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006482842714176513\n",
      "Training Loss: 0.0062404160801088435\n",
      "Training Loss: 0.006613680626032874\n",
      "Validation Loss: 0.0035388488858791715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006476462644059211\n",
      "Training Loss: 0.006233671445515938\n",
      "Training Loss: 0.006606441106414423\n",
      "Validation Loss: 0.0035329428135176724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006470052578370087\n",
      "Training Loss: 0.00622689196607098\n",
      "Training Loss: 0.006599163394421339\n",
      "Validation Loss: 0.003526985280351776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006463613862870261\n",
      "Training Loss: 0.006220076813478954\n",
      "Training Loss: 0.0065918481419794265\n",
      "Validation Loss: 0.003520977097364624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006457144296145998\n",
      "Training Loss: 0.006213225922547281\n",
      "Training Loss: 0.006584495349088683\n",
      "Validation Loss: 0.00351491468445806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006450643825228326\n",
      "Training Loss: 0.006206338763004169\n",
      "Training Loss: 0.006577103950548917\n",
      "Validation Loss: 0.0035088006197736502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006444111960008741\n",
      "Training Loss: 0.006199414584552869\n",
      "Training Loss: 0.006569673923077062\n",
      "Validation Loss: 0.0035026299890151685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006437547959503718\n",
      "Training Loss: 0.006192452739924192\n",
      "Training Loss: 0.006562205071095378\n",
      "Validation Loss: 0.0034964040819074164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006430951561778784\n",
      "Training Loss: 0.006185452526551671\n",
      "Training Loss: 0.006554696621606126\n",
      "Validation Loss: 0.003490123059338984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.0064243224932579324\n",
      "Training Loss: 0.0061784143839031455\n",
      "Training Loss: 0.006547149918042124\n",
      "Validation Loss: 0.0034837825694696957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00641765984299127\n",
      "Training Loss: 0.0061713373759994285\n",
      "Training Loss: 0.006539563197875396\n",
      "Validation Loss: 0.0034773865534160077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006410963771631941\n",
      "Training Loss: 0.006164221083745361\n",
      "Training Loss: 0.006531937272520736\n",
      "Validation Loss: 0.003470929540965832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00640423341828864\n",
      "Training Loss: 0.006157065905281343\n",
      "Training Loss: 0.0065242713724728675\n",
      "Validation Loss: 0.003464414286845772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006397467789938673\n",
      "Training Loss: 0.006149871297529899\n",
      "Training Loss: 0.006516566381324082\n",
      "Validation Loss: 0.0034578381867535163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006390666785882786\n",
      "Training Loss: 0.006142636107979342\n",
      "Training Loss: 0.006508820710005239\n",
      "Validation Loss: 0.003451205168725148\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006383830970153212\n",
      "Training Loss: 0.006135361318592913\n",
      "Training Loss: 0.006501035462133586\n",
      "Validation Loss: 0.0034445083551004193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006376958908513189\n",
      "Training Loss: 0.006128046305384487\n",
      "Training Loss: 0.0064932100835721936\n",
      "Validation Loss: 0.003437755667353363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006370050319237635\n",
      "Training Loss: 0.006120690621901304\n",
      "Training Loss: 0.006485344462562353\n",
      "Validation Loss: 0.0034309391251482655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006363104328047484\n",
      "Training Loss: 0.006113293506205082\n",
      "Training Loss: 0.006477437957655639\n",
      "Validation Loss: 0.003424059583941537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006356121512362733\n",
      "Training Loss: 0.006105855123023502\n",
      "Training Loss: 0.0064694903674535455\n",
      "Validation Loss: 0.003417117115675231\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006349099835497327\n",
      "Training Loss: 0.006098376546869986\n",
      "Training Loss: 0.006461503492901101\n",
      "Validation Loss: 0.0034101152742867557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006342039879527874\n",
      "Training Loss: 0.006090856110095046\n",
      "Training Loss: 0.0064534750650636855\n",
      "Validation Loss: 0.0034030524417339417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006334941603126936\n",
      "Training Loss: 0.0060832947550807145\n",
      "Training Loss: 0.006445406049024314\n",
      "Validation Loss: 0.003395926607563422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006327803489402868\n",
      "Training Loss: 0.006075690962607041\n",
      "Training Loss: 0.0064372959767933936\n",
      "Validation Loss: 0.003388736718805151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006320625530788675\n",
      "Training Loss: 0.006068046459695324\n",
      "Training Loss: 0.006429145127767697\n",
      "Validation Loss: 0.003381488721796803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006313408123678528\n",
      "Training Loss: 0.006060360300471075\n",
      "Training Loss: 0.006420953162014484\n",
      "Validation Loss: 0.003374179048212559\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006306149487500079\n",
      "Training Loss: 0.006052631739294156\n",
      "Training Loss: 0.006412719389190897\n",
      "Validation Loss: 0.003366808843893114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0062988493905868385\n",
      "Training Loss: 0.006044861895497888\n",
      "Training Loss: 0.006404444396030158\n",
      "Validation Loss: 0.0033593790440851552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006291507938876748\n",
      "Training Loss: 0.0060370501648867505\n",
      "Training Loss: 0.006396127637708559\n",
      "Validation Loss: 0.003351887698505032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00628412468591705\n",
      "Training Loss: 0.006029196609160863\n",
      "Training Loss: 0.006387768733548\n",
      "Validation Loss: 0.0033443400229515737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006276698582223616\n",
      "Training Loss: 0.006021301233558916\n",
      "Training Loss: 0.0063793689059093595\n",
      "Validation Loss: 0.0033367317748057208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006269230234902352\n",
      "Training Loss: 0.006013364759855904\n",
      "Training Loss: 0.00637092771823518\n",
      "Validation Loss: 0.0033290656512404344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006261718276655301\n",
      "Training Loss: 0.006005386536708101\n",
      "Training Loss: 0.006362444248516112\n",
      "Validation Loss: 0.0033213416784164613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006254163791309111\n",
      "Training Loss: 0.005997367491945624\n",
      "Training Loss: 0.0063539189333096146\n",
      "Validation Loss: 0.0033135620708409906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006246564070461318\n",
      "Training Loss: 0.0059893073176499455\n",
      "Training Loss: 0.006345351925119758\n",
      "Validation Loss: 0.003305728546621048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0062389216123847294\n",
      "Training Loss: 0.00598120717855636\n",
      "Training Loss: 0.006336744291475043\n",
      "Validation Loss: 0.003297842443224796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006231235403683968\n",
      "Training Loss: 0.005973067315062508\n",
      "Training Loss: 0.0063280954642687\n",
      "Validation Loss: 0.0032899044454097748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006223505293019116\n",
      "Training Loss: 0.0059648884378839286\n",
      "Training Loss: 0.006319406097754836\n",
      "Validation Loss: 0.0032819170489111977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0062157319532707336\n",
      "Training Loss: 0.005956670311279595\n",
      "Training Loss: 0.006310676828725263\n",
      "Validation Loss: 0.0032738795114178837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006207915344857611\n",
      "Training Loss: 0.005948414832819254\n",
      "Training Loss: 0.006301907215965912\n",
      "Validation Loss: 0.003265796624924569\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006200055049848743\n",
      "Training Loss: 0.005940122731262818\n",
      "Training Loss: 0.006293098939349875\n",
      "Validation Loss: 0.003257668244893129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006192152051953599\n",
      "Training Loss: 0.005931795039796271\n",
      "Training Loss: 0.006284252571640536\n",
      "Validation Loss: 0.003249499668220707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006184207608457655\n",
      "Training Loss: 0.005923433004645631\n",
      "Training Loss: 0.006275368211790919\n",
      "Validation Loss: 0.00324128895574197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0061762212810572235\n",
      "Training Loss: 0.0059150372387375685\n",
      "Training Loss: 0.006266447989037261\n",
      "Validation Loss: 0.0032330427954517555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006168193804915063\n",
      "Training Loss: 0.005906610074453056\n",
      "Training Loss: 0.0062574922910425814\n",
      "Validation Loss: 0.003224762089895817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006160127013572492\n",
      "Training Loss: 0.005898152755107731\n",
      "Training Loss: 0.0062485020980238915\n",
      "Validation Loss: 0.003216452145781577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006152021307498217\n",
      "Training Loss: 0.005889667432638817\n",
      "Training Loss: 0.006239479539217428\n",
      "Validation Loss: 0.003208113931056656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006143878577277064\n",
      "Training Loss: 0.005881155919632874\n",
      "Training Loss: 0.006230426154797897\n",
      "Validation Loss: 0.0031997515660386238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.0061357004451565444\n",
      "Training Loss: 0.005872619000147097\n",
      "Training Loss: 0.00622134302277118\n",
      "Validation Loss: 0.00319136696700216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0061274866975145415\n",
      "Training Loss: 0.005864060703315772\n",
      "Training Loss: 0.006212232189718634\n",
      "Validation Loss: 0.0031829648337253695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006119240925763734\n",
      "Training Loss: 0.005855483149061911\n",
      "Training Loss: 0.006203096726676449\n",
      "Validation Loss: 0.003174554046473644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006110964027466252\n",
      "Training Loss: 0.005846888044034131\n",
      "Training Loss: 0.00619393759756349\n",
      "Validation Loss: 0.0031661300395427043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006102658421150408\n",
      "Training Loss: 0.005838278872543015\n",
      "Training Loss: 0.006184756987495348\n",
      "Validation Loss: 0.0031577018050351338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006094326744787395\n",
      "Training Loss: 0.00582965828711167\n",
      "Training Loss: 0.006175558918621391\n",
      "Validation Loss: 0.0031492771702462787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006085971060674638\n",
      "Training Loss: 0.005821028757491149\n",
      "Training Loss: 0.006166345303645357\n",
      "Validation Loss: 0.003140855617847377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006077593918889761\n",
      "Training Loss: 0.005812395475804806\n",
      "Training Loss: 0.006157118247356266\n",
      "Validation Loss: 0.0031324435192882343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006069198377081193\n",
      "Training Loss: 0.0058037607173901055\n",
      "Training Loss: 0.006147882603108883\n",
      "Validation Loss: 0.003124046531176257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006060786998132244\n",
      "Training Loss: 0.005795127172023058\n",
      "Training Loss: 0.0061386398202739655\n",
      "Validation Loss: 0.0031156707411171512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.00605236318137031\n",
      "Training Loss: 0.005786499937530607\n",
      "Training Loss: 0.006129394001327455\n",
      "Validation Loss: 0.003107319678849635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006043930166051723\n",
      "Training Loss: 0.005777881236281246\n",
      "Training Loss: 0.00612014806130901\n",
      "Validation Loss: 0.003098998068350503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006035491749644279\n",
      "Training Loss: 0.005769277720828541\n",
      "Training Loss: 0.006110908251721412\n",
      "Validation Loss: 0.003090714078966863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006027051292476244\n",
      "Training Loss: 0.00576069038186688\n",
      "Training Loss: 0.006101675032405183\n",
      "Validation Loss: 0.0030824704647712995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006018612348707392\n",
      "Training Loss: 0.005752125093713403\n",
      "Training Loss: 0.006092454510508105\n",
      "Validation Loss: 0.003074274267582746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0060101794434012845\n",
      "Training Loss: 0.005743586685275659\n",
      "Training Loss: 0.006083249961957336\n",
      "Validation Loss: 0.0030661307829903083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00600175533851143\n",
      "Training Loss: 0.005735077974386513\n",
      "Training Loss: 0.006074066273286007\n",
      "Validation Loss: 0.0030580464530778066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005993345736642368\n",
      "Training Loss: 0.005726604317314923\n",
      "Training Loss: 0.006064906744286418\n",
      "Validation Loss: 0.003050024695746768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0059849540016148235\n",
      "Training Loss: 0.00571817050979007\n",
      "Training Loss: 0.006055775771383196\n",
      "Validation Loss: 0.0030420723311037996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005976584739401005\n",
      "Training Loss: 0.005709779059980064\n",
      "Training Loss: 0.006046678576385602\n",
      "Validation Loss: 0.00303419193075028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.0059682422142941505\n",
      "Training Loss: 0.005701436824747361\n",
      "Training Loss: 0.0060376200161408634\n",
      "Validation Loss: 0.003026392508371409\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.00595993081398774\n",
      "Training Loss: 0.005693146315170452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [19:18<04:49, 144.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006028603524900973\n",
      "Validation Loss: 0.003018679150270319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5643742461502552\n",
      "Training Loss: 0.49886204540729523\n",
      "Training Loss: 0.4404246096313\n",
      "Validation Loss: 0.3830808514959357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.33587124064564705\n",
      "Training Loss: 0.2551922767609358\n",
      "Training Loss: 0.16560407001525163\n",
      "Validation Loss: 0.10263795037282987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.08779183024540543\n",
      "Training Loss: 0.07379554899409413\n",
      "Training Loss: 0.06771226823329926\n",
      "Validation Loss: 0.06287979271807027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06393196515738964\n",
      "Training Loss: 0.06294741172343493\n",
      "Training Loss: 0.061547244898974895\n",
      "Validation Loss: 0.05773837525355682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.05823634075000882\n",
      "Training Loss: 0.05610565733164549\n",
      "Training Loss: 0.05401014702394605\n",
      "Validation Loss: 0.04927981513018689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04920900002121925\n",
      "Training Loss: 0.04593820446170867\n",
      "Training Loss: 0.04360648744739592\n",
      "Validation Loss: 0.03855626458783498\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03860855887643993\n",
      "Training Loss: 0.03570340828038752\n",
      "Training Loss: 0.03433153046295047\n",
      "Validation Loss: 0.030071544806274136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.030361219169571997\n",
      "Training Loss: 0.028090656236745417\n",
      "Training Loss: 0.027280585058033466\n",
      "Validation Loss: 0.02370186083102494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.024205567548051476\n",
      "Training Loss: 0.022505858419463037\n",
      "Training Loss: 0.022023493866436185\n",
      "Validation Loss: 0.018989620887245356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.019740710174664854\n",
      "Training Loss: 0.01857670458732173\n",
      "Training Loss: 0.01828831613296643\n",
      "Validation Loss: 0.015604280516128527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.016665621786378326\n",
      "Training Loss: 0.015920116452034564\n",
      "Training Loss: 0.015720305591821672\n",
      "Validation Loss: 0.013159302921358789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.014507808859925718\n",
      "Training Loss: 0.01398260299814865\n",
      "Training Loss: 0.013825733431149274\n",
      "Validation Loss: 0.011291384864389227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.01287307964405045\n",
      "Training Loss: 0.012470970491413026\n",
      "Training Loss: 0.012367597112897784\n",
      "Validation Loss: 0.009844808666600605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.011609662189148367\n",
      "Training Loss: 0.011284604449756444\n",
      "Training Loss: 0.011240683244541288\n",
      "Validation Loss: 0.008721323678625768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010625697248615324\n",
      "Training Loss: 0.010342489901231601\n",
      "Training Loss: 0.01034861924359575\n",
      "Validation Loss: 0.007809911731609635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009816165540833026\n",
      "Training Loss: 0.009527243496850133\n",
      "Training Loss: 0.009554815666051581\n",
      "Validation Loss: 0.006946184863388705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009059707204578445\n",
      "Training Loss: 0.008788198067341\n",
      "Training Loss: 0.008921240936033428\n",
      "Validation Loss: 0.006275698634157522\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00855140145868063\n",
      "Training Loss: 0.00830671435687691\n",
      "Training Loss: 0.008503817487508059\n",
      "Validation Loss: 0.005804937945030043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008188535223016515\n",
      "Training Loss: 0.007943578393897041\n",
      "Training Loss: 0.008186829045880585\n",
      "Validation Loss: 0.005435545570374037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007909342566272244\n",
      "Training Loss: 0.007662219344638288\n",
      "Training Loss: 0.007941846920875833\n",
      "Validation Loss: 0.005142067956706781\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0076923753938172015\n",
      "Training Loss: 0.007442775552626699\n",
      "Training Loss: 0.007750386174302548\n",
      "Validation Loss: 0.00490643810794762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007521179293980822\n",
      "Training Loss: 0.007269238393055275\n",
      "Training Loss: 0.007597906504524871\n",
      "Validation Loss: 0.004713804318485886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007383025781018659\n",
      "Training Loss: 0.00712929577450268\n",
      "Training Loss: 0.007473663138807751\n",
      "Validation Loss: 0.004553068881812557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00726878518355079\n",
      "Training Loss: 0.007014096507336944\n",
      "Training Loss: 0.007370136937825009\n",
      "Validation Loss: 0.004416435581548244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007172190389828756\n",
      "Training Loss: 0.006917473569046706\n",
      "Training Loss: 0.0072821610630489884\n",
      "Validation Loss: 0.0042985513194181615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007088987110182643\n",
      "Training Loss: 0.0068351270060520615\n",
      "Training Loss: 0.007206160727655515\n",
      "Validation Loss: 0.004195681968023687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0070162491541123015\n",
      "Training Loss: 0.006764004344586283\n",
      "Training Loss: 0.00713961360277608\n",
      "Validation Loss: 0.004105148547894081\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.006951914918608963\n",
      "Training Loss: 0.006701878514140844\n",
      "Training Loss: 0.007080691282753833\n",
      "Validation Loss: 0.0040249721646790255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.006894490539561957\n",
      "Training Loss: 0.0066470836603548375\n",
      "Training Loss: 0.007028030997025781\n",
      "Validation Loss: 0.003953613372247541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.006842848035157658\n",
      "Training Loss: 0.006598331620916724\n",
      "Training Loss: 0.006980580326053314\n",
      "Validation Loss: 0.0038898609633547035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00679610590741504\n",
      "Training Loss: 0.006554598825750872\n",
      "Training Loss: 0.006937501500360667\n",
      "Validation Loss: 0.0038326941757578026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0067535416397731755\n",
      "Training Loss: 0.006515051518799737\n",
      "Training Loss: 0.0068981071969028565\n",
      "Validation Loss: 0.0037812523418263105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0067145499488106\n",
      "Training Loss: 0.006478999755345285\n",
      "Training Loss: 0.006861821647617034\n",
      "Validation Loss: 0.0037347917991763587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.006678611343377269\n",
      "Training Loss: 0.0064458690927131105\n",
      "Training Loss: 0.00682816301821731\n",
      "Validation Loss: 0.0036926668548035654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.006645286197308451\n",
      "Training Loss: 0.006415186304366216\n",
      "Training Loss: 0.006796727983164601\n",
      "Validation Loss: 0.0036543034215907703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.006614197746384889\n",
      "Training Loss: 0.00638656183029525\n",
      "Training Loss: 0.006767182968906127\n",
      "Validation Loss: 0.003619219850110455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00658503376354929\n",
      "Training Loss: 0.006359681920148432\n",
      "Training Loss: 0.0067392574233235795\n",
      "Validation Loss: 0.003586998429107532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.006557536334148608\n",
      "Training Loss: 0.00633429640554823\n",
      "Training Loss: 0.0067127334378892555\n",
      "Validation Loss: 0.003557283164451966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.006531497774412856\n",
      "Training Loss: 0.006310209315270186\n",
      "Training Loss: 0.006687438647495583\n",
      "Validation Loss: 0.003529772454129762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.006506750886328519\n",
      "Training Loss: 0.00628726709401235\n",
      "Training Loss: 0.006663238790933974\n",
      "Validation Loss: 0.003504210180508789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.006483159076888114\n",
      "Training Loss: 0.006265348446904681\n",
      "Training Loss: 0.006640026406385005\n",
      "Validation Loss: 0.0034803741355165004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006460618235869333\n",
      "Training Loss: 0.006244359296979383\n",
      "Training Loss: 0.006617719323839992\n",
      "Validation Loss: 0.0034580814659993134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006439041520352475\n",
      "Training Loss: 0.0062242258293554184\n",
      "Training Loss: 0.006596249980502762\n",
      "Validation Loss: 0.003437167322629372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0064183574070921165\n",
      "Training Loss: 0.0062048850406426935\n",
      "Training Loss: 0.006575564470258541\n",
      "Validation Loss: 0.003417488865114832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006398506316472776\n",
      "Training Loss: 0.006186287214513868\n",
      "Training Loss: 0.006555617753765546\n",
      "Validation Loss: 0.0033989286356281194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006379438900039531\n",
      "Training Loss: 0.006168389052036218\n",
      "Training Loss: 0.006536372469272464\n",
      "Validation Loss: 0.0033813770167173797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006361111012520269\n",
      "Training Loss: 0.006151151807280257\n",
      "Training Loss: 0.006517792138038203\n",
      "Validation Loss: 0.003364741970952391\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006343482171650976\n",
      "Training Loss: 0.006134540765779093\n",
      "Training Loss: 0.0064998478081543\n",
      "Validation Loss: 0.003348939851962365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006326515967957675\n",
      "Training Loss: 0.006118523682234808\n",
      "Training Loss: 0.006482509804773145\n",
      "Validation Loss: 0.00333388901859773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006310178702697158\n",
      "Training Loss: 0.0061030708736507224\n",
      "Training Loss: 0.006465751329087653\n",
      "Validation Loss: 0.0033195280885909883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006294439796474763\n",
      "Training Loss: 0.006088153215241619\n",
      "Training Loss: 0.006449546089861542\n",
      "Validation Loss: 0.003305793431158481\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00627926699933596\n",
      "Training Loss: 0.0060737405181862415\n",
      "Training Loss: 0.006433867255691439\n",
      "Validation Loss: 0.0032926325639186615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006264630342484452\n",
      "Training Loss: 0.006059807256679051\n",
      "Training Loss: 0.006418689230922609\n",
      "Validation Loss: 0.00327999892989906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006250501069007442\n",
      "Training Loss: 0.0060463260108372194\n",
      "Training Loss: 0.006403988074162044\n",
      "Validation Loss: 0.0032678424116496124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006236852227593772\n",
      "Training Loss: 0.006033270429470577\n",
      "Training Loss: 0.006389739601290785\n",
      "Validation Loss: 0.003256126635268414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006223656012443826\n",
      "Training Loss: 0.006020614397129975\n",
      "Training Loss: 0.006375919017591514\n",
      "Validation Loss: 0.0032448122340641666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006210888443165459\n",
      "Training Loss: 0.006008336055092513\n",
      "Training Loss: 0.006362503283889964\n",
      "Validation Loss: 0.0032338655012230694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0061985221487702805\n",
      "Training Loss: 0.005996409159852192\n",
      "Training Loss: 0.006349470595014281\n",
      "Validation Loss: 0.0032232560314175286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0061865350813604895\n",
      "Training Loss: 0.005984813611139544\n",
      "Training Loss: 0.006336800748249516\n",
      "Validation Loss: 0.0032129591223626825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006174904658109881\n",
      "Training Loss: 0.005973528502508998\n",
      "Training Loss: 0.006324472365085967\n",
      "Validation Loss: 0.0032029503412293586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006163611211813986\n",
      "Training Loss: 0.005962533475831151\n",
      "Training Loss: 0.006312466822564602\n",
      "Validation Loss: 0.003193207017114658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006152633125893771\n",
      "Training Loss: 0.0059518097783438865\n",
      "Training Loss: 0.006300764965708368\n",
      "Validation Loss: 0.003183706452954937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006141952084144578\n",
      "Training Loss: 0.005941339926212094\n",
      "Training Loss: 0.006289350400329567\n",
      "Validation Loss: 0.0031744371367137085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006131551677244715\n",
      "Training Loss: 0.005931109617231414\n",
      "Training Loss: 0.006278207687428221\n",
      "Validation Loss: 0.003165375837648099\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006121415088418871\n",
      "Training Loss: 0.00592110306606628\n",
      "Training Loss: 0.00626732295146212\n",
      "Validation Loss: 0.0031565129783088235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006111528804758563\n",
      "Training Loss: 0.005911306960042566\n",
      "Training Loss: 0.006256682214443572\n",
      "Validation Loss: 0.0031478365051319426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006101878687040881\n",
      "Training Loss: 0.005901710184989497\n",
      "Training Loss: 0.0062462742946809155\n",
      "Validation Loss: 0.0031393347962058327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00609245263854973\n",
      "Training Loss: 0.005892301407875493\n",
      "Training Loss: 0.006236087991856039\n",
      "Validation Loss: 0.0031309988221488476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006083240338484757\n",
      "Training Loss: 0.005883070629206486\n",
      "Training Loss: 0.0062261128373211246\n",
      "Validation Loss: 0.0031228218674973656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006074231278616935\n",
      "Training Loss: 0.00587401028140448\n",
      "Training Loss: 0.0062163416959811\n",
      "Validation Loss: 0.0031147972547208493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006065417169011198\n",
      "Training Loss: 0.005865112470346503\n",
      "Training Loss: 0.006206766359973699\n",
      "Validation Loss: 0.0031069166751662163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006056789206922986\n",
      "Training Loss: 0.005856371000409127\n",
      "Training Loss: 0.006197379095247015\n",
      "Validation Loss: 0.003099179583381903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006048339508706704\n",
      "Training Loss: 0.0058477792190387845\n",
      "Training Loss: 0.006188173398841173\n",
      "Validation Loss: 0.00309158161444736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00604006222798489\n",
      "Training Loss: 0.005839331982424483\n",
      "Training Loss: 0.006179144635680132\n",
      "Validation Loss: 0.0030841178135172036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0060319501796038824\n",
      "Training Loss: 0.005831024937215261\n",
      "Training Loss: 0.006170287138666027\n",
      "Validation Loss: 0.003076787143317836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006023998251184821\n",
      "Training Loss: 0.00582285471027717\n",
      "Training Loss: 0.006161596552119591\n",
      "Validation Loss: 0.00306958828796371\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006016200617887079\n",
      "Training Loss: 0.005814816898200661\n",
      "Training Loss: 0.006153068693238311\n",
      "Validation Loss: 0.00306251710490062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006008552767452784\n",
      "Training Loss: 0.005806908091763034\n",
      "Training Loss: 0.006144698288408108\n",
      "Validation Loss: 0.0030555754593897906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0060010491136927155\n",
      "Training Loss: 0.005799126271158457\n",
      "Training Loss: 0.006136484443559311\n",
      "Validation Loss: 0.0030487630178817034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.005993685444700532\n",
      "Training Loss: 0.0057914685556897895\n",
      "Training Loss: 0.006128421614994295\n",
      "Validation Loss: 0.003042072170215209\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.005986458025872708\n",
      "Training Loss: 0.005783931609475985\n",
      "Training Loss: 0.006120506628649309\n",
      "Validation Loss: 0.0030355088287190106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0059793615236412734\n",
      "Training Loss: 0.005776514154858887\n",
      "Training Loss: 0.006112736043287441\n",
      "Validation Loss: 0.00302906810002548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.005972391623072326\n",
      "Training Loss: 0.005769213343737647\n",
      "Training Loss: 0.00610510739730671\n",
      "Validation Loss: 0.0030227486473204715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.005965544602368027\n",
      "Training Loss: 0.005762027570744977\n",
      "Training Loss: 0.006097615263424814\n",
      "Validation Loss: 0.0030165499643935415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.005958815410849638\n",
      "Training Loss: 0.005754953422583639\n",
      "Training Loss: 0.006090258596814237\n",
      "Validation Loss: 0.003010467687632177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005952200422179885\n",
      "Training Loss: 0.005747988764778711\n",
      "Training Loss: 0.006083032237365842\n",
      "Validation Loss: 0.003004501157785567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.005945694857509807\n",
      "Training Loss: 0.005741132004186511\n",
      "Training Loss: 0.0060759332648012785\n",
      "Validation Loss: 0.0029986493244997404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005939294610871002\n",
      "Training Loss: 0.005734380302601494\n",
      "Training Loss: 0.006068957737879827\n",
      "Validation Loss: 0.0029929097875262076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005932996347546578\n",
      "Training Loss: 0.00572773193998728\n",
      "Training Loss: 0.006062103247386403\n",
      "Validation Loss: 0.002987277268934367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005926794824190438\n",
      "Training Loss: 0.005721184202702716\n",
      "Training Loss: 0.00605536510120146\n",
      "Validation Loss: 0.0029817513292236778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005920687262550928\n",
      "Training Loss: 0.005714734950452112\n",
      "Training Loss: 0.006048739668331109\n",
      "Validation Loss: 0.002976326417083737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005914668111363426\n",
      "Training Loss: 0.005708380438154564\n",
      "Training Loss: 0.006042223281110637\n",
      "Validation Loss: 0.0029709998994354118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.005908733941614628\n",
      "Training Loss: 0.005702119647758082\n",
      "Training Loss: 0.006035812365007586\n",
      "Validation Loss: 0.0029657692138335846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0059028809517621995\n",
      "Training Loss: 0.005695948470383882\n",
      "Training Loss: 0.006029502143501304\n",
      "Validation Loss: 0.002960628801119629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.005897104740142822\n",
      "Training Loss: 0.005689864372834563\n",
      "Training Loss: 0.006023289592703805\n",
      "Validation Loss: 0.0029555750419542697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00589140186610166\n",
      "Training Loss: 0.005683865601895377\n",
      "Training Loss: 0.0060171700781211255\n",
      "Validation Loss: 0.0029506075138414508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0058857679308857765\n",
      "Training Loss: 0.005677948924712837\n",
      "Training Loss: 0.006011140264454298\n",
      "Validation Loss: 0.0029457178479583746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005880200146930292\n",
      "Training Loss: 0.005672111347666942\n",
      "Training Loss: 0.006005195746547542\n",
      "Validation Loss: 0.002940905794469912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005874695798847824\n",
      "Training Loss: 0.005666351062245667\n",
      "Training Loss: 0.005999334363732487\n",
      "Validation Loss: 0.0029361678543762208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005869250091491267\n",
      "Training Loss: 0.005660664076567627\n",
      "Training Loss: 0.00599355083773844\n",
      "Validation Loss: 0.0029314975018790933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005863861324032768\n",
      "Training Loss: 0.005655049260822125\n",
      "Training Loss: 0.0059878415352432055\n",
      "Validation Loss: 0.002926893987473142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.005858525144285523\n",
      "Training Loss: 0.0056495025218464435\n",
      "Training Loss: 0.005982205274049193\n",
      "Validation Loss: 0.0029223500463190707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005853239308926277\n",
      "Training Loss: 0.005644022052292712\n",
      "Training Loss: 0.005976635506376624\n",
      "Validation Loss: 0.002917869002139719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00584800164506305\n",
      "Training Loss: 0.005638605019194074\n",
      "Training Loss: 0.005971130873076618\n",
      "Validation Loss: 0.0029134415482495275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005842808720190078\n",
      "Training Loss: 0.0056332494312664495\n",
      "Training Loss: 0.0059656875336077065\n",
      "Validation Loss: 0.0029090651876052444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005837658082600683\n",
      "Training Loss: 0.005627952459035441\n",
      "Training Loss: 0.00596030279295519\n",
      "Validation Loss: 0.00290473782342304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.005832547712489031\n",
      "Training Loss: 0.005622711164760403\n",
      "Training Loss: 0.005954973403131589\n",
      "Validation Loss: 0.0029004575891336533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00582747574604582\n",
      "Training Loss: 0.005617523977998644\n",
      "Training Loss: 0.005949697055621072\n",
      "Validation Loss: 0.00289622560572507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005822439501062035\n",
      "Training Loss: 0.005612388814333826\n",
      "Training Loss: 0.005944468705565669\n",
      "Validation Loss: 0.0028920328935210624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.005817437807563692\n",
      "Training Loss: 0.0056073028384707865\n",
      "Training Loss: 0.005939288430963643\n",
      "Validation Loss: 0.002887879304713413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.0058124682574998586\n",
      "Training Loss: 0.005602264738408849\n",
      "Training Loss: 0.005934152170666494\n",
      "Validation Loss: 0.002883766078013466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.00580752887763083\n",
      "Training Loss: 0.005597270853468217\n",
      "Training Loss: 0.005929057694156654\n",
      "Validation Loss: 0.0028796860898499576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005802618071320467\n",
      "Training Loss: 0.005592320310533978\n",
      "Training Loss: 0.005924002572428435\n",
      "Validation Loss: 0.0028756418071812792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.0057977352465968576\n",
      "Training Loss: 0.005587412023451179\n",
      "Training Loss: 0.005918984673335217\n",
      "Validation Loss: 0.002871628536769513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0057928788190474735\n",
      "Training Loss: 0.005582542368210852\n",
      "Training Loss: 0.005914002364734188\n",
      "Validation Loss: 0.0028676462171369054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005788045463268645\n",
      "Training Loss: 0.005577709516510368\n",
      "Training Loss: 0.005909051247872412\n",
      "Validation Loss: 0.002863695396351094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005783235773560591\n",
      "Training Loss: 0.005572911503259092\n",
      "Training Loss: 0.0059041318821255115\n",
      "Validation Loss: 0.002859768643452043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005778447253396735\n",
      "Training Loss: 0.005568148412276059\n",
      "Training Loss: 0.005899240405415185\n",
      "Validation Loss: 0.0028558737020207086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0057736796035896985\n",
      "Training Loss: 0.0055634160252520815\n",
      "Training Loss: 0.005894375643110834\n",
      "Validation Loss: 0.0028519983759170836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005768931556958705\n",
      "Training Loss: 0.005558714942308143\n",
      "Training Loss: 0.0058895352733088656\n",
      "Validation Loss: 0.002848149151698257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005764200661797076\n",
      "Training Loss: 0.005554041875875555\n",
      "Training Loss: 0.005884718198212795\n",
      "Validation Loss: 0.0028443252981713647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005759487132891082\n",
      "Training Loss: 0.005549395299167373\n",
      "Training Loss: 0.00587992163724266\n",
      "Validation Loss: 0.002840523150215825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005754788960330188\n",
      "Training Loss: 0.005544774059671909\n",
      "Training Loss: 0.005875144115998409\n",
      "Validation Loss: 0.002836742676438743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005750105768674985\n",
      "Training Loss: 0.005540176650392823\n",
      "Training Loss: 0.005870383779983968\n",
      "Validation Loss: 0.0028329817211946075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0057454353710636496\n",
      "Training Loss: 0.005535600181901828\n",
      "Training Loss: 0.00586563866934739\n",
      "Validation Loss: 0.0028292414447125256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005740777793107554\n",
      "Training Loss: 0.00553104393708054\n",
      "Training Loss: 0.005860907323658467\n",
      "Validation Loss: 0.002825519365645694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.005736131324665621\n",
      "Training Loss: 0.005526505699381232\n",
      "Training Loss: 0.005856187215540558\n",
      "Validation Loss: 0.0028218140660816534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005731493142666295\n",
      "Training Loss: 0.005521984553779475\n",
      "Training Loss: 0.005851477097021416\n",
      "Validation Loss: 0.002818126605530636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005726864276803099\n",
      "Training Loss: 0.005517478542169556\n",
      "Training Loss: 0.005846774047822692\n",
      "Validation Loss: 0.0028144569028943273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005722243138006888\n",
      "Training Loss: 0.0055129854712868106\n",
      "Training Loss: 0.005842077944544144\n",
      "Validation Loss: 0.002810800764605068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0057176278292899955\n",
      "Training Loss: 0.005508504203171469\n",
      "Training Loss: 0.005837386284256354\n",
      "Validation Loss: 0.0028071617956137223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005713017315720208\n",
      "Training Loss: 0.005504033251199871\n",
      "Training Loss: 0.005832697924342938\n",
      "Validation Loss: 0.00280353419869887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005708410686347634\n",
      "Training Loss: 0.005499570271349512\n",
      "Training Loss: 0.00582800927455537\n",
      "Validation Loss: 0.0027999237370729614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005703806353267282\n",
      "Training Loss: 0.00549511464079842\n",
      "Training Loss: 0.005823319758637808\n",
      "Validation Loss: 0.0027963215500911636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005699202016112395\n",
      "Training Loss: 0.005490663056843914\n",
      "Training Loss: 0.005818626146065071\n",
      "Validation Loss: 0.0027927307338778224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.005694597034016624\n",
      "Training Loss: 0.005486213857657276\n",
      "Training Loss: 0.005813926568371244\n",
      "Validation Loss: 0.002789150449981013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0056899894698290154\n",
      "Training Loss: 0.005481765657314099\n",
      "Training Loss: 0.005809219835791737\n",
      "Validation Loss: 0.0027855794518411663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.005685378462658264\n",
      "Training Loss: 0.005477316218311898\n",
      "Training Loss: 0.005804503362160176\n",
      "Validation Loss: 0.0027820158284157515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005680761381518096\n",
      "Training Loss: 0.005472864441690035\n",
      "Training Loss: 0.005799774744082243\n",
      "Validation Loss: 0.002778458809270785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005676137250848114\n",
      "Training Loss: 0.005468406516010873\n",
      "Training Loss: 0.0057950306619750334\n",
      "Validation Loss: 0.002774905757403022\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005671503613702953\n",
      "Training Loss: 0.005463941236957908\n",
      "Training Loss: 0.005790270707220771\n",
      "Validation Loss: 0.002771358143046415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005666859223274514\n",
      "Training Loss: 0.005459467084729113\n",
      "Training Loss: 0.005785489293048158\n",
      "Validation Loss: 0.0027678110505966994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.005662199499784038\n",
      "Training Loss: 0.005454980829963461\n",
      "Training Loss: 0.005780685757054016\n",
      "Validation Loss: 0.0027642674898477586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005657525397837162\n",
      "Training Loss: 0.00545047928520944\n",
      "Training Loss: 0.005775857547414489\n",
      "Validation Loss: 0.0027607193509681842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00565283267525956\n",
      "Training Loss: 0.0054459609946934506\n",
      "Training Loss: 0.005771000164677389\n",
      "Validation Loss: 0.0027571693612157963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005648119618999772\n",
      "Training Loss: 0.005441422567819245\n",
      "Training Loss: 0.00576611127180513\n",
      "Validation Loss: 0.0027536146860737145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005643383188289591\n",
      "Training Loss: 0.005436863200739026\n",
      "Training Loss: 0.0057611882354831325\n",
      "Validation Loss: 0.0027500516944303274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.0056386207742616535\n",
      "Training Loss: 0.0054322775773471225\n",
      "Training Loss: 0.005756225784425624\n",
      "Validation Loss: 0.002746480888571967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.00563382997061126\n",
      "Training Loss: 0.00542766310274601\n",
      "Training Loss: 0.005751221608952619\n",
      "Validation Loss: 0.0027428958748121944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005629005780792795\n",
      "Training Loss: 0.005423016954446211\n",
      "Training Loss: 0.0057461717230034995\n",
      "Validation Loss: 0.0027392970311737965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005624147094786167\n",
      "Training Loss: 0.005418335529393517\n",
      "Training Loss: 0.005741071462398395\n",
      "Validation Loss: 0.0027356793452577477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005619249392766506\n",
      "Training Loss: 0.0054136156250024214\n",
      "Training Loss: 0.005735915277618915\n",
      "Validation Loss: 0.0027320405214585446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0056143075606087224\n",
      "Training Loss: 0.005408852913533337\n",
      "Training Loss: 0.0057307010795921084\n",
      "Validation Loss: 0.002728376053587607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005609319804352708\n",
      "Training Loss: 0.005404043882153928\n",
      "Training Loss: 0.005725423864787444\n",
      "Validation Loss: 0.0027246850364831057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005604280478437431\n",
      "Training Loss: 0.005399184474954382\n",
      "Training Loss: 0.005720075796707533\n",
      "Validation Loss: 0.0027209592569786847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005599185509490781\n",
      "Training Loss: 0.0053942690457915886\n",
      "Training Loss: 0.005714653969043866\n",
      "Validation Loss: 0.002717197994345778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005594029268831946\n",
      "Training Loss: 0.00538929411501158\n",
      "Training Loss: 0.0057091508351732045\n",
      "Validation Loss: 0.002713393994209388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0055888066295301546\n",
      "Training Loss: 0.005384254689561203\n",
      "Training Loss: 0.005703562319977209\n",
      "Validation Loss: 0.0027095455417325827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005583514058962465\n",
      "Training Loss: 0.005379145619808696\n",
      "Training Loss: 0.005697881701635197\n",
      "Validation Loss: 0.0027056438730652917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0055781427392503245\n",
      "Training Loss: 0.005373959448188543\n",
      "Training Loss: 0.005692099363659509\n",
      "Validation Loss: 0.00270168274886948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005572687135427259\n",
      "Training Loss: 0.0053686933248536664\n",
      "Training Loss: 0.005686210520216264\n",
      "Validation Loss: 0.0026976594562757384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005567141400533728\n",
      "Training Loss: 0.005363337820162997\n",
      "Training Loss: 0.005680206100805663\n",
      "Validation Loss: 0.0026935633177753915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005561497387243435\n",
      "Training Loss: 0.005357889180886559\n",
      "Training Loss: 0.00567407873342745\n",
      "Validation Loss: 0.002689389646670708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005555747125181369\n",
      "Training Loss: 0.00535233901347965\n",
      "Training Loss: 0.00566781890753191\n",
      "Validation Loss: 0.002685128484873541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005549884058418684\n",
      "Training Loss: 0.005346681401715614\n",
      "Training Loss: 0.0056614198326133194\n",
      "Validation Loss: 0.0026807731221524184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005543897970346734\n",
      "Training Loss: 0.005340907351928763\n",
      "Training Loss: 0.005654869467252866\n",
      "Validation Loss: 0.002676315361037432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005537780351005495\n",
      "Training Loss: 0.005335007939138449\n",
      "Training Loss: 0.005648158012190834\n",
      "Validation Loss: 0.0026717418150746085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.0055315213743597266\n",
      "Training Loss: 0.005328977024764754\n",
      "Training Loss: 0.005641276974929496\n",
      "Validation Loss: 0.002667044986594008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005525109393056482\n",
      "Training Loss: 0.005322803422459401\n",
      "Training Loss: 0.005634211977594532\n",
      "Validation Loss: 0.0026622140908278942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005518535131122917\n",
      "Training Loss: 0.00531647969619371\n",
      "Training Loss: 0.00562695263477508\n",
      "Validation Loss: 0.0026572355568890323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005511786342249252\n",
      "Training Loss: 0.005309995230054483\n",
      "Training Loss: 0.005619487909134477\n",
      "Validation Loss: 0.0026520993560552597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005504849588032812\n",
      "Training Loss: 0.005303338884259574\n",
      "Training Loss: 0.0056118034612154585\n",
      "Validation Loss: 0.0026467934059858154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0054977148189209405\n",
      "Training Loss: 0.005296501988195815\n",
      "Training Loss: 0.00560388800164219\n",
      "Validation Loss: 0.0026413000285562672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005490365563891828\n",
      "Training Loss: 0.005289473757147789\n",
      "Training Loss: 0.005595726734027267\n",
      "Validation Loss: 0.0026356075861585443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.0054827901488170025\n",
      "Training Loss: 0.0052822420094162225\n",
      "Training Loss: 0.005587307125679218\n",
      "Validation Loss: 0.002629702095873654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0054749738454120235\n",
      "Training Loss: 0.00527479694224894\n",
      "Training Loss: 0.005578616217244417\n",
      "Validation Loss: 0.002623567463610363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005466902853804641\n",
      "Training Loss: 0.005267126939143055\n",
      "Training Loss: 0.0055696402658941225\n",
      "Validation Loss: 0.002617192123702654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005458562239073217\n",
      "Training Loss: 0.005259221733431332\n",
      "Training Loss: 0.005560364073025994\n",
      "Validation Loss: 0.0026105577544717306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005449936861405149\n",
      "Training Loss: 0.005251070738886483\n",
      "Training Loss: 0.005550777532043867\n",
      "Validation Loss: 0.002603652159777585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005441012530354783\n",
      "Training Loss: 0.005242663659155369\n",
      "Training Loss: 0.005540867709787563\n",
      "Validation Loss: 0.0025964630571497457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005431776529294438\n",
      "Training Loss: 0.005233991513960063\n",
      "Training Loss: 0.005530623172526248\n",
      "Validation Loss: 0.00258897033943847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005422214845311828\n",
      "Training Loss: 0.005225045552360825\n",
      "Training Loss: 0.00552003723976668\n",
      "Validation Loss: 0.0025811720171189877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005412316647707484\n",
      "Training Loss: 0.005215819958248175\n",
      "Training Loss: 0.005509099622722715\n",
      "Validation Loss: 0.002573053126244314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.0054020703182322905\n",
      "Training Loss: 0.005206309758359566\n",
      "Training Loss: 0.005497807425563224\n",
      "Validation Loss: 0.002564610184819092\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005391470232279971\n",
      "Training Loss: 0.005196511704125442\n",
      "Training Loss: 0.005486157504492439\n",
      "Validation Loss: 0.002555841071206783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005380508219823241\n",
      "Training Loss: 0.005186426392174326\n",
      "Training Loss: 0.005474152525421232\n",
      "Validation Loss: 0.002546745703001036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005369184672599658\n",
      "Training Loss: 0.005176056439522654\n",
      "Training Loss: 0.00546179898607079\n",
      "Validation Loss: 0.0025373242031573578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005357501935795881\n",
      "Training Loss: 0.005165409335168078\n",
      "Training Loss: 0.005449106093146838\n",
      "Validation Loss: 0.002527594830568754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005345465237624012\n",
      "Training Loss: 0.005154494878370315\n",
      "Training Loss: 0.005436089496361092\n",
      "Validation Loss: 0.002517569620486642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.0053330855863168835\n",
      "Training Loss: 0.00514332820486743\n",
      "Training Loss: 0.0054227700579212975\n",
      "Validation Loss: 0.0025072715649370816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005320381199708208\n",
      "Training Loss: 0.005131927591282875\n",
      "Training Loss: 0.005409173392108641\n",
      "Validation Loss: 0.0024967267998138422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005307373174000532\n",
      "Training Loss: 0.005120316573884338\n",
      "Training Loss: 0.00539533193805255\n",
      "Validation Loss: 0.0024859674308930386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005294090847601182\n",
      "Training Loss: 0.005108524625538849\n",
      "Training Loss: 0.0053812823013868185\n",
      "Validation Loss: 0.0024750403872837597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005280567901208997\n",
      "Training Loss: 0.005096584357670508\n",
      "Training Loss: 0.005367069546482525\n",
      "Validation Loss: 0.0024639856700754063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005266847650636919\n",
      "Training Loss: 0.005084533374174498\n",
      "Training Loss: 0.005352741428068839\n",
      "Validation Loss: 0.00245285598466989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005252972240559757\n",
      "Training Loss: 0.005072411768487654\n",
      "Training Loss: 0.0053383472072891895\n",
      "Validation Loss: 0.0024417082561975284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0052389965596375985\n",
      "Training Loss: 0.005060263243503869\n",
      "Training Loss: 0.005323945829295553\n",
      "Validation Loss: 0.0024305940644941135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005224972917349077\n",
      "Training Loss: 0.0050481353234499695\n",
      "Training Loss: 0.0053095912351273\n",
      "Validation Loss: 0.0024195707892329336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005210959032992833\n",
      "Training Loss: 0.005036074302624911\n",
      "Training Loss: 0.005295342095196247\n",
      "Validation Loss: 0.002408699063176101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005197015979210846\n",
      "Training Loss: 0.005024128284421749\n",
      "Training Loss: 0.0052812575543066485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [21:43<02:24, 144.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0023980369304798625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5628150989115238\n",
      "Training Loss: 0.43760766252875327\n",
      "Training Loss: 0.30328538186848164\n",
      "Validation Loss: 0.1558233756530151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.12008180791512131\n",
      "Training Loss: 0.07388494988903403\n",
      "Training Loss: 0.06146803373470902\n",
      "Validation Loss: 0.05159084327267797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05661014917306602\n",
      "Training Loss: 0.054122989680618044\n",
      "Training Loss: 0.052495534904301165\n",
      "Validation Loss: 0.0454920989701922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04835805653594434\n",
      "Training Loss: 0.04554391168057918\n",
      "Training Loss: 0.04413143246434629\n",
      "Validation Loss: 0.03886602590844203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04016790666617453\n",
      "Training Loss: 0.037538637798279526\n",
      "Training Loss: 0.03669032054021955\n",
      "Validation Loss: 0.03275595594909084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.03326933030039072\n",
      "Training Loss: 0.030950355427339673\n",
      "Training Loss: 0.030515925604850055\n",
      "Validation Loss: 0.027262098197772932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.027618437767960132\n",
      "Training Loss: 0.025668706130236387\n",
      "Training Loss: 0.0255277898022905\n",
      "Validation Loss: 0.02275468906115615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.02322490271180868\n",
      "Training Loss: 0.021677732071839272\n",
      "Training Loss: 0.021726481718942522\n",
      "Validation Loss: 0.019346851389855146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.019988221128005534\n",
      "Training Loss: 0.018784339176490902\n",
      "Training Loss: 0.018914658054709436\n",
      "Validation Loss: 0.01679573096648863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.017629023811314256\n",
      "Training Loss: 0.016668629944324494\n",
      "Training Loss: 0.01681045507779345\n",
      "Validation Loss: 0.014807878035968274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01586001127259806\n",
      "Training Loss: 0.015051729476545006\n",
      "Training Loss: 0.015185018726624549\n",
      "Validation Loss: 0.013187822765471894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.014477875605225564\n",
      "Training Loss: 0.01375688219210133\n",
      "Training Loss: 0.013893660330213607\n",
      "Validation Loss: 0.011831492002467426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013362574374768883\n",
      "Training Loss: 0.012690804935991763\n",
      "Training Loss: 0.01285365069983527\n",
      "Validation Loss: 0.010684996011426275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.012448733393102884\n",
      "Training Loss: 0.01180837569758296\n",
      "Training Loss: 0.012016596079338342\n",
      "Validation Loss: 0.009717005325920796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.011700567957013845\n",
      "Training Loss: 0.011085524964146316\n",
      "Training Loss: 0.011349961218656971\n",
      "Validation Loss: 0.008906078386235606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.011095572751946748\n",
      "Training Loss: 0.010504336613230407\n",
      "Training Loss: 0.010827416273532436\n",
      "Validation Loss: 0.008235025046958347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.010614994064671918\n",
      "Training Loss: 0.010046571762068197\n",
      "Training Loss: 0.010424035603646188\n",
      "Validation Loss: 0.007687188106787841\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.01023905114387162\n",
      "Training Loss: 0.00969162062741816\n",
      "Training Loss: 0.01011471688747406\n",
      "Validation Loss: 0.0072446583294089924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009946327338693663\n",
      "Training Loss: 0.009417503619333729\n",
      "Training Loss: 0.009875472852727399\n",
      "Validation Loss: 0.0068888500636297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009715916570276022\n",
      "Training Loss: 0.009203433067305013\n",
      "Training Loss: 0.009685740488348528\n",
      "Validation Loss: 0.0066020344043924905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.009529906644020229\n",
      "Training Loss: 0.0090320728009101\n",
      "Training Loss: 0.00952986690448597\n",
      "Validation Loss: 0.006368605582190029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009374746675603092\n",
      "Training Loss: 0.008890532195800915\n",
      "Training Loss: 0.009397206676658243\n",
      "Validation Loss: 0.006175782709392939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009241230465704575\n",
      "Training Loss: 0.008770093311322853\n",
      "Training Loss: 0.00928114875103347\n",
      "Validation Loss: 0.006013666624935825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.009123582220636308\n",
      "Training Loss: 0.008665225529111921\n",
      "Training Loss: 0.009177790731191635\n",
      "Validation Loss: 0.005874897578333536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00901831522001885\n",
      "Training Loss: 0.008572499086149037\n",
      "Training Loss: 0.009084808179177345\n",
      "Validation Loss: 0.005754153006134576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00892328189802356\n",
      "Training Loss: 0.008489720548968762\n",
      "Training Loss: 0.009000691031105816\n",
      "Validation Loss: 0.005647620224142761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008837057836353778\n",
      "Training Loss: 0.00841538859764114\n",
      "Training Loss: 0.008924336398486048\n",
      "Validation Loss: 0.0055525789947740815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008758591166697442\n",
      "Training Loss: 0.008348373096669092\n",
      "Training Loss: 0.00885484429076314\n",
      "Validation Loss: 0.005467051451795556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008687023227103054\n",
      "Training Loss: 0.008287754723569378\n",
      "Training Loss: 0.008791427694959567\n",
      "Validation Loss: 0.005389559932911162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008621608136454597\n",
      "Training Loss: 0.008232747762231157\n",
      "Training Loss: 0.008733385922387243\n",
      "Validation Loss: 0.0053189843958453015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00856168063939549\n",
      "Training Loss: 0.008182661292375997\n",
      "Training Loss: 0.008680090614361688\n",
      "Validation Loss: 0.005254429393563043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.008506636987440287\n",
      "Training Loss: 0.008136883991537615\n",
      "Training Loss: 0.008630978284636513\n",
      "Validation Loss: 0.0051951680392591975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.008455930306809023\n",
      "Training Loss: 0.008094866989413276\n",
      "Training Loss: 0.008585544838570058\n",
      "Validation Loss: 0.0051405774926494684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.008409065009327605\n",
      "Training Loss: 0.008056128394091502\n",
      "Training Loss: 0.008543346136575565\n",
      "Validation Loss: 0.005090138787309524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.008365600204560905\n",
      "Training Loss: 0.008020242340862752\n",
      "Training Loss: 0.00850399294635281\n",
      "Validation Loss: 0.0050433991448116606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.008325139796361326\n",
      "Training Loss: 0.007986836383352056\n",
      "Training Loss: 0.008467143488815054\n",
      "Validation Loss: 0.004999969768065834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.008287336456123739\n",
      "Training Loss: 0.00795558602316305\n",
      "Training Loss: 0.008432504079537466\n",
      "Validation Loss: 0.004959505624294783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.008251882003387436\n",
      "Training Loss: 0.007926209577126428\n",
      "Training Loss: 0.008399816028540954\n",
      "Validation Loss: 0.004921702813262936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.008218505727127194\n",
      "Training Loss: 0.007898465553298593\n",
      "Training Loss: 0.008368856904562563\n",
      "Validation Loss: 0.004886295962974094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.008186969013186171\n",
      "Training Loss: 0.00787214272771962\n",
      "Training Loss: 0.008339434613008052\n",
      "Validation Loss: 0.004853060024298644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00815706655732356\n",
      "Training Loss: 0.007847063542576506\n",
      "Training Loss: 0.008311384544940665\n",
      "Validation Loss: 0.0048217891370145125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.008128617531619966\n",
      "Training Loss: 0.00782307432498783\n",
      "Training Loss: 0.00828456084942445\n",
      "Validation Loss: 0.004792305015634452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.008101462756749243\n",
      "Training Loss: 0.007800042132148519\n",
      "Training Loss: 0.008258838530164212\n",
      "Validation Loss: 0.004764445934423737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00807546213385649\n",
      "Training Loss: 0.007777852579019964\n",
      "Training Loss: 0.008234107166063041\n",
      "Validation Loss: 0.004738076812367928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00805049495655112\n",
      "Training Loss: 0.007756406930275262\n",
      "Training Loss: 0.008210268825059756\n",
      "Validation Loss: 0.004713066190407936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.008026450658217072\n",
      "Training Loss: 0.0077356202795635905\n",
      "Training Loss: 0.00818723588134162\n",
      "Validation Loss: 0.004689305984111649\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.008003235274227336\n",
      "Training Loss: 0.0077154165413230655\n",
      "Training Loss: 0.008164930252823978\n",
      "Validation Loss: 0.004666698473934712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007980761312646792\n",
      "Training Loss: 0.007695728718535974\n",
      "Training Loss: 0.008143282125238328\n",
      "Validation Loss: 0.004645149024684777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007958951439941303\n",
      "Training Loss: 0.0076764978736173365\n",
      "Training Loss: 0.008122223576065154\n",
      "Validation Loss: 0.004624573728383592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007937737419269978\n",
      "Training Loss: 0.007657671025954187\n",
      "Training Loss: 0.008101697795791552\n",
      "Validation Loss: 0.004604897481452129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007917054144199938\n",
      "Training Loss: 0.00763919920194894\n",
      "Training Loss: 0.008081647572107614\n",
      "Validation Loss: 0.004586046773500824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007896845629438758\n",
      "Training Loss: 0.007621039886726066\n",
      "Training Loss: 0.008062022418016568\n",
      "Validation Loss: 0.004567954630402618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007877059751190246\n",
      "Training Loss: 0.007603153116069734\n",
      "Training Loss: 0.008042775853537023\n",
      "Validation Loss: 0.0045505582022721345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007857650170335547\n",
      "Training Loss: 0.00758550388738513\n",
      "Training Loss: 0.0080238649668172\n",
      "Validation Loss: 0.004533800224543371\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007838575361529366\n",
      "Training Loss: 0.007568059503100812\n",
      "Training Loss: 0.00800525010097772\n",
      "Validation Loss: 0.0045176251906524885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00781979606486857\n",
      "Training Loss: 0.007550793008413166\n",
      "Training Loss: 0.007986897106748074\n",
      "Validation Loss: 0.0045019831204933395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00780128066544421\n",
      "Training Loss: 0.007533678410109133\n",
      "Training Loss: 0.007968771846499294\n",
      "Validation Loss: 0.004486825226889818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007783000071067363\n",
      "Training Loss: 0.007516695669619366\n",
      "Training Loss: 0.007950849175686017\n",
      "Validation Loss: 0.004472109338718603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007764929305994883\n",
      "Training Loss: 0.007499825594713912\n",
      "Training Loss: 0.00793310254928656\n",
      "Validation Loss: 0.004457792918605918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007747047162847593\n",
      "Training Loss: 0.007483053209725767\n",
      "Training Loss: 0.007915512368781493\n",
      "Validation Loss: 0.004443836063565163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00772933560772799\n",
      "Training Loss: 0.007466366237495094\n",
      "Training Loss: 0.007898059207946062\n",
      "Validation Loss: 0.004430207345383555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007711778162047267\n",
      "Training Loss: 0.0074497551668901\n",
      "Training Loss: 0.00788072776165791\n",
      "Validation Loss: 0.004416875501969055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007694366401992738\n",
      "Training Loss: 0.0074332122399937365\n",
      "Training Loss: 0.007863506152061746\n",
      "Validation Loss: 0.00440380954460942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007677087491611018\n",
      "Training Loss: 0.007416731937555596\n",
      "Training Loss: 0.007846384168369696\n",
      "Validation Loss: 0.004390985882851515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007659934483235702\n",
      "Training Loss: 0.0074003105028532445\n",
      "Training Loss: 0.007829351667314768\n",
      "Validation Loss: 0.004378380278763728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007642903428059071\n",
      "Training Loss: 0.007383945971960202\n",
      "Training Loss: 0.007812403225107119\n",
      "Validation Loss: 0.0043659687887228436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007625988061772659\n",
      "Training Loss: 0.007367638187715784\n",
      "Training Loss: 0.007795533620519563\n",
      "Validation Loss: 0.0043537351185079206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007609185290057212\n",
      "Training Loss: 0.007351385136134922\n",
      "Training Loss: 0.007778738483320922\n",
      "Validation Loss: 0.004341661723414331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007592494710115716\n",
      "Training Loss: 0.007335188889410347\n",
      "Training Loss: 0.007762014963664115\n",
      "Validation Loss: 0.004329731673514994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007575913491891697\n",
      "Training Loss: 0.007319050224032253\n",
      "Training Loss: 0.007745360411936417\n",
      "Validation Loss: 0.004317929680469666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00755944084492512\n",
      "Training Loss: 0.007302970321616158\n",
      "Training Loss: 0.007728772615082562\n",
      "Validation Loss: 0.004306245971931501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0075430759135633706\n",
      "Training Loss: 0.007286949789850041\n",
      "Training Loss: 0.007712250724434853\n",
      "Validation Loss: 0.0042946658874181715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007526818702463061\n",
      "Training Loss: 0.007270990057149902\n",
      "Training Loss: 0.00769579213229008\n",
      "Validation Loss: 0.004283178006455804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007510667298920453\n",
      "Training Loss: 0.007255092293489724\n",
      "Training Loss: 0.007679396877065301\n",
      "Validation Loss: 0.004271774811753898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0074946211616043\n",
      "Training Loss: 0.00723925755941309\n",
      "Training Loss: 0.007663062514038757\n",
      "Validation Loss: 0.0042604456951297566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007478680226486176\n",
      "Training Loss: 0.007223485686117783\n",
      "Training Loss: 0.007646788767306134\n",
      "Validation Loss: 0.004249181059513534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.00746284302440472\n",
      "Training Loss: 0.007207776494324207\n",
      "Training Loss: 0.007630573206115514\n",
      "Validation Loss: 0.004237971790501157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007447106637991965\n",
      "Training Loss: 0.007192130357725546\n",
      "Training Loss: 0.007614414155250415\n",
      "Validation Loss: 0.004226810069953541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007431468711001798\n",
      "Training Loss: 0.007176544048124924\n",
      "Training Loss: 0.007598309011664242\n",
      "Validation Loss: 0.004215689739630966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.0074159279640298335\n",
      "Training Loss: 0.007161017417674884\n",
      "Training Loss: 0.007582255372544751\n",
      "Validation Loss: 0.004204602605987633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007400480424985289\n",
      "Training Loss: 0.007145548730622977\n",
      "Training Loss: 0.007566250559175387\n",
      "Validation Loss: 0.00419354132439397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007385123268468305\n",
      "Training Loss: 0.007130135617917404\n",
      "Training Loss: 0.007550292441155761\n",
      "Validation Loss: 0.004182501435750739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007369852981064469\n",
      "Training Loss: 0.007114775459049269\n",
      "Training Loss: 0.007534378009149805\n",
      "Validation Loss: 0.0041714726458042025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007354666364844889\n",
      "Training Loss: 0.007099465581122785\n",
      "Training Loss: 0.007518503372557462\n",
      "Validation Loss: 0.0041604511115407\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007339558063540608\n",
      "Training Loss: 0.007084201175021007\n",
      "Training Loss: 0.0075026638165581975\n",
      "Validation Loss: 0.004149429815339992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.0073245244554709646\n",
      "Training Loss: 0.007068981595803052\n",
      "Training Loss: 0.00748685700702481\n",
      "Validation Loss: 0.0041384037801200585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007309561562724411\n",
      "Training Loss: 0.007053801221773028\n",
      "Training Loss: 0.007471079302486032\n",
      "Validation Loss: 0.00412737046959653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007294664509827271\n",
      "Training Loss: 0.007038656731601804\n",
      "Training Loss: 0.007455326135968789\n",
      "Validation Loss: 0.0041163204737488975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.0072798295191023495\n",
      "Training Loss: 0.007023545956471935\n",
      "Training Loss: 0.007439594954485073\n",
      "Validation Loss: 0.0041052518148247275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007265051186550409\n",
      "Training Loss: 0.0070084649871569125\n",
      "Training Loss: 0.007423880698624998\n",
      "Validation Loss: 0.004094157124649775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007250324668129906\n",
      "Training Loss: 0.00699340965365991\n",
      "Training Loss: 0.0074081808363553135\n",
      "Validation Loss: 0.004083032884603638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007235646293265745\n",
      "Training Loss: 0.006978376917541027\n",
      "Training Loss: 0.007392490704078227\n",
      "Validation Loss: 0.004071876988746226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007221012212103233\n",
      "Training Loss: 0.006963363609975204\n",
      "Training Loss: 0.0073768075101543215\n",
      "Validation Loss: 0.004060684288642631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007206417506095022\n",
      "Training Loss: 0.006948366959113628\n",
      "Training Loss: 0.007361129235941916\n",
      "Validation Loss: 0.00404945198509298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007191859249724075\n",
      "Training Loss: 0.0069333850441034885\n",
      "Training Loss: 0.007345450650900602\n",
      "Validation Loss: 0.004038178903479757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.0071773323812522\n",
      "Training Loss: 0.00691841313848272\n",
      "Training Loss: 0.007329769565258175\n",
      "Validation Loss: 0.0040268594257826555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007162833228940144\n",
      "Training Loss: 0.006903449756791815\n",
      "Training Loss: 0.007314084034878761\n",
      "Validation Loss: 0.004015491740369981\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007148358485428616\n",
      "Training Loss: 0.006888492524158209\n",
      "Training Loss: 0.007298390489304438\n",
      "Validation Loss: 0.004004074391396193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007133906662929803\n",
      "Training Loss: 0.006873539830558002\n",
      "Training Loss: 0.007282688709674403\n",
      "Validation Loss: 0.003992606703914032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.00711947278585285\n",
      "Training Loss: 0.006858590041520074\n",
      "Training Loss: 0.007266976796090603\n",
      "Validation Loss: 0.003981087076885814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007105055544525385\n",
      "Training Loss: 0.0068436416226904835\n",
      "Training Loss: 0.007251252178102732\n",
      "Validation Loss: 0.003969516104160483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007090652004117146\n",
      "Training Loss: 0.006828693030402064\n",
      "Training Loss: 0.007235515324864537\n",
      "Validation Loss: 0.0039578920486644745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007076260381145403\n",
      "Training Loss: 0.00681374387233518\n",
      "Training Loss: 0.007219764253823087\n",
      "Validation Loss: 0.003946215619354017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00706187924486585\n",
      "Training Loss: 0.006798793665366247\n",
      "Training Loss: 0.00720400036429055\n",
      "Validation Loss: 0.003934487810337476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.007047507257666439\n",
      "Training Loss: 0.006783841971773654\n",
      "Training Loss: 0.007188222241820768\n",
      "Validation Loss: 0.00392270766543957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007033142948057502\n",
      "Training Loss: 0.0067688876111060385\n",
      "Training Loss: 0.007172431770013646\n",
      "Validation Loss: 0.003910880607783041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.007018786075059324\n",
      "Training Loss: 0.006753932753344998\n",
      "Training Loss: 0.007156629947712645\n",
      "Validation Loss: 0.003899006400613135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.007004437283612787\n",
      "Training Loss: 0.006738976869964972\n",
      "Training Loss: 0.007140815545571968\n",
      "Validation Loss: 0.0038870877868841204\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006990095089422539\n",
      "Training Loss: 0.006724020864348859\n",
      "Training Loss: 0.007124994340119884\n",
      "Validation Loss: 0.0038751270648175744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006975761525100097\n",
      "Training Loss: 0.006709066105540842\n",
      "Training Loss: 0.007109165468718857\n",
      "Validation Loss: 0.003863129679772877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006961436679121107\n",
      "Training Loss: 0.0066941139893606305\n",
      "Training Loss: 0.007093334039673209\n",
      "Validation Loss: 0.003851096631090544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006947121028788388\n",
      "Training Loss: 0.006679166910471395\n",
      "Training Loss: 0.00707750022993423\n",
      "Validation Loss: 0.0038390347728861516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006932817685883492\n",
      "Training Loss: 0.0066642254800535735\n",
      "Training Loss: 0.007061669304966926\n",
      "Validation Loss: 0.003826948273874652\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006918526899535209\n",
      "Training Loss: 0.006649293723748997\n",
      "Training Loss: 0.007045844086678699\n",
      "Validation Loss: 0.0038148419358610603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0069042519689537585\n",
      "Training Loss: 0.006634373876731842\n",
      "Training Loss: 0.00703002888825722\n",
      "Validation Loss: 0.003802720534489647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006889995454112068\n",
      "Training Loss: 0.006619467225973495\n",
      "Training Loss: 0.007014226070605218\n",
      "Validation Loss: 0.003790587645934455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006875758251408115\n",
      "Training Loss: 0.006604577847174369\n",
      "Training Loss: 0.006998441948089748\n",
      "Validation Loss: 0.0037784538744540697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006861545096617192\n",
      "Training Loss: 0.006589708998799324\n",
      "Training Loss: 0.00698267970350571\n",
      "Validation Loss: 0.003766321150711581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006847359754610807\n",
      "Training Loss: 0.006574864971917123\n",
      "Training Loss: 0.0069669458887074145\n",
      "Validation Loss: 0.0037541980174987505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0068332043697591875\n",
      "Training Loss: 0.0065600478393025696\n",
      "Training Loss: 0.006951243916992098\n",
      "Validation Loss: 0.0037420891065757427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006819082205183804\n",
      "Training Loss: 0.006545262694125995\n",
      "Training Loss: 0.006935579703422263\n",
      "Validation Loss: 0.0037300004336062106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006804997919825837\n",
      "Training Loss: 0.006530513261677698\n",
      "Training Loss: 0.0069199577067047355\n",
      "Validation Loss: 0.003717939990698203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0067909547127783295\n",
      "Training Loss: 0.006515802302747033\n",
      "Training Loss: 0.006904383836081251\n",
      "Validation Loss: 0.00370591338409969\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006776956742396578\n",
      "Training Loss: 0.00650113508454524\n",
      "Training Loss: 0.006888860182370991\n",
      "Validation Loss: 0.0036939262109023803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006763006771216169\n",
      "Training Loss: 0.006486514447606169\n",
      "Training Loss: 0.006873394632712007\n",
      "Validation Loss: 0.003681986575705533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006749109860975295\n",
      "Training Loss: 0.0064719445881200955\n",
      "Training Loss: 0.006857990906573832\n",
      "Validation Loss: 0.0036700989389164226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0067352690780535344\n",
      "Training Loss: 0.006457429598085583\n",
      "Training Loss: 0.006842654534848407\n",
      "Validation Loss: 0.0036582699388244683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006721488001057878\n",
      "Training Loss: 0.006442973360535688\n",
      "Training Loss: 0.006827387431403622\n",
      "Validation Loss: 0.0036465041849531987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006707768997875974\n",
      "Training Loss: 0.0064285786321852355\n",
      "Training Loss: 0.0068121948605403305\n",
      "Validation Loss: 0.0036348058577899017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006694115963764489\n",
      "Training Loss: 0.006414248467772268\n",
      "Training Loss: 0.006797081138938665\n",
      "Validation Loss: 0.0036231798546263174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0066805314843077215\n",
      "Training Loss: 0.006399986030883156\n",
      "Training Loss: 0.006782047398737632\n",
      "Validation Loss: 0.0036116298719759236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006667018244042993\n",
      "Training Loss: 0.006385794027009979\n",
      "Training Loss: 0.006767100144643336\n",
      "Validation Loss: 0.0036001597607006014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006653578545665368\n",
      "Training Loss: 0.006371676115668379\n",
      "Training Loss: 0.006752239028573967\n",
      "Validation Loss: 0.0035887721617277085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006640214618528262\n",
      "Training Loss: 0.006357633536099456\n",
      "Training Loss: 0.0067374672938603905\n",
      "Validation Loss: 0.003577473194055845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006626927391625941\n",
      "Training Loss: 0.006343667947221548\n",
      "Training Loss: 0.006722786984173581\n",
      "Validation Loss: 0.0035662626183141817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006613719739252701\n",
      "Training Loss: 0.006329781726235524\n",
      "Training Loss: 0.0067081980779767035\n",
      "Validation Loss: 0.003555144363846839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0066005911573302\n",
      "Training Loss: 0.006315974996541626\n",
      "Training Loss: 0.006693702758057043\n",
      "Validation Loss: 0.003544117126540605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006587542472407222\n",
      "Training Loss: 0.0063022495777113365\n",
      "Training Loss: 0.006679301402764395\n",
      "Validation Loss: 0.003533184451176628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006574575416743755\n",
      "Training Loss: 0.0062886063457699495\n",
      "Training Loss: 0.006664994502207264\n",
      "Validation Loss: 0.003522341699454557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006561688187066466\n",
      "Training Loss: 0.006275045556831174\n",
      "Training Loss: 0.006650781081989407\n",
      "Validation Loss: 0.0035115936404784744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.0065488824038766325\n",
      "Training Loss: 0.006261567138135433\n",
      "Training Loss: 0.006636661625816487\n",
      "Validation Loss: 0.0035009409112625577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006536157438531518\n",
      "Training Loss: 0.006248172104824335\n",
      "Training Loss: 0.006622635591193102\n",
      "Validation Loss: 0.0034903800925972423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006523511641426012\n",
      "Training Loss: 0.006234859673422761\n",
      "Training Loss: 0.006608701867517084\n",
      "Validation Loss: 0.003479912869234601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.00651094576343894\n",
      "Training Loss: 0.006221629403880797\n",
      "Training Loss: 0.006594859737670049\n",
      "Validation Loss: 0.003469537982842728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00649845803854987\n",
      "Training Loss: 0.006208481022622436\n",
      "Training Loss: 0.006581106327939778\n",
      "Validation Loss: 0.0034592500037586922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006486047754297033\n",
      "Training Loss: 0.0061954148201039064\n",
      "Training Loss: 0.006567442762316205\n",
      "Validation Loss: 0.0034490510183020255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006473714214516804\n",
      "Training Loss: 0.00618242877360899\n",
      "Training Loss: 0.006553866551839747\n",
      "Validation Loss: 0.0034389377916964254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006461454783566296\n",
      "Training Loss: 0.006169522784766741\n",
      "Training Loss: 0.006540375856566243\n",
      "Validation Loss: 0.003428912759507389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006449270403245464\n",
      "Training Loss: 0.006156697359401732\n",
      "Training Loss: 0.006526969508850016\n",
      "Validation Loss: 0.0034189697844237924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006437158761546016\n",
      "Training Loss: 0.0061439505888847635\n",
      "Training Loss: 0.006513647072715685\n",
      "Validation Loss: 0.0034091047958334847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006425118378829211\n",
      "Training Loss: 0.0061312831786926834\n",
      "Training Loss: 0.0065004069171845915\n",
      "Validation Loss: 0.003399323910118991\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006413148900028318\n",
      "Training Loss: 0.006118693660246208\n",
      "Training Loss: 0.0064872465986991305\n",
      "Validation Loss: 0.0033896218624300837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006401249364716932\n",
      "Training Loss: 0.006106181850773282\n",
      "Training Loss: 0.0064741657342528925\n",
      "Validation Loss: 0.003379994266917615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006389418411999941\n",
      "Training Loss: 0.006093747644918039\n",
      "Training Loss: 0.006461162188206799\n",
      "Validation Loss: 0.0033704389666280384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006377654592506587\n",
      "Training Loss: 0.0060813909763237466\n",
      "Training Loss: 0.00644823658047244\n",
      "Validation Loss: 0.003360962883694872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006365957771777175\n",
      "Training Loss: 0.006069111186079681\n",
      "Training Loss: 0.006435386408702471\n",
      "Validation Loss: 0.003351551306622333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006354327059816569\n",
      "Training Loss: 0.006056909463368356\n",
      "Training Loss: 0.006422613486647606\n",
      "Validation Loss: 0.0033422140796993223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006342762584681623\n",
      "Training Loss: 0.006044785915291868\n",
      "Training Loss: 0.006409915744443424\n",
      "Validation Loss: 0.003332946078035604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006331263322499581\n",
      "Training Loss: 0.006032740821829066\n",
      "Training Loss: 0.006397293268819339\n",
      "Validation Loss: 0.0033237493133925823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0063198300485964864\n",
      "Training Loss: 0.006020775343058631\n",
      "Training Loss: 0.006384747592965141\n",
      "Validation Loss: 0.0033146197308545535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006308462722226977\n",
      "Training Loss: 0.006008889755466953\n",
      "Training Loss: 0.006372276851907372\n",
      "Validation Loss: 0.003305558743101827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006297160065732896\n",
      "Training Loss: 0.005997085786657408\n",
      "Training Loss: 0.0063598824350629005\n",
      "Validation Loss: 0.0032965660192009606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006285923676914535\n",
      "Training Loss: 0.0059853639116045085\n",
      "Training Loss: 0.006347564035677351\n",
      "Validation Loss: 0.0032876400928421134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.00627475373679772\n",
      "Training Loss: 0.00597372719203122\n",
      "Training Loss: 0.006335323442472145\n",
      "Validation Loss: 0.003278783504233769\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006263650672626682\n",
      "Training Loss: 0.005962175473687239\n",
      "Training Loss: 0.0063231628341600295\n",
      "Validation Loss: 0.003269994432587972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006252615629928186\n",
      "Training Loss: 0.005950712079647928\n",
      "Training Loss: 0.00631108179979492\n",
      "Validation Loss: 0.0032612752127513457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006241649717558175\n",
      "Training Loss: 0.005939337714225985\n",
      "Training Loss: 0.006299081857432612\n",
      "Validation Loss: 0.0032526278381727718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006230753373820334\n",
      "Training Loss: 0.0059280558349564675\n",
      "Training Loss: 0.006287165082758292\n",
      "Validation Loss: 0.0032440488137765212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006219928141217679\n",
      "Training Loss: 0.005916867319610901\n",
      "Training Loss: 0.006275332552613691\n",
      "Validation Loss: 0.003235542181397924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00620917541673407\n",
      "Training Loss: 0.005905776111176237\n",
      "Training Loss: 0.00626358698878903\n",
      "Validation Loss: 0.0032271123203459415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006198496815632098\n",
      "Training Loss: 0.0058947834314312785\n",
      "Training Loss: 0.006251931021688506\n",
      "Validation Loss: 0.003218754545230879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006187893806491047\n",
      "Training Loss: 0.005883893418358639\n",
      "Training Loss: 0.006240364865516312\n",
      "Validation Loss: 0.0032104726572091996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006177367687923834\n",
      "Training Loss: 0.005873107626102865\n",
      "Training Loss: 0.0062288928753696385\n",
      "Validation Loss: 0.003202270273004104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006166920688701794\n",
      "Training Loss: 0.005862429668777622\n",
      "Training Loss: 0.006217515207245014\n",
      "Validation Loss: 0.003194148632634975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.0061565545224584635\n",
      "Training Loss: 0.005851861902046948\n",
      "Training Loss: 0.0062062371266074475\n",
      "Validation Loss: 0.003186106210930294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006146270188619383\n",
      "Training Loss: 0.005841407408588566\n",
      "Training Loss: 0.006195057413424365\n",
      "Validation Loss: 0.0031781496108624708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00613607065344695\n",
      "Training Loss: 0.00583106946607586\n",
      "Training Loss: 0.006183982414659113\n",
      "Validation Loss: 0.003170282241176772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006125957003678195\n",
      "Training Loss: 0.005820849989540875\n",
      "Training Loss: 0.006173011882929132\n",
      "Validation Loss: 0.003162499899149276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006115930705564096\n",
      "Training Loss: 0.005810753057594411\n",
      "Training Loss: 0.0061621499783359466\n",
      "Validation Loss: 0.0031548087809527858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006105995115358382\n",
      "Training Loss: 0.005800782506703399\n",
      "Training Loss: 0.006151398341171443\n",
      "Validation Loss: 0.0031472111154829015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006096151098608971\n",
      "Training Loss: 0.0057909388357074935\n",
      "Training Loss: 0.00614075944875367\n",
      "Validation Loss: 0.0031397100080202303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006086400783387944\n",
      "Training Loss: 0.005781227723928168\n",
      "Training Loss: 0.006130235816817731\n",
      "Validation Loss: 0.0031323050740017983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006076745328609832\n",
      "Training Loss: 0.0057716494193300605\n",
      "Training Loss: 0.006119830716634169\n",
      "Validation Loss: 0.0031249987830020737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006067187570151873\n",
      "Training Loss: 0.005762208417290821\n",
      "Training Loss: 0.006109545837971382\n",
      "Validation Loss: 0.003117794326632127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006057728799642064\n",
      "Training Loss: 0.005752907163114287\n",
      "Training Loss: 0.006099382737302221\n",
      "Validation Loss: 0.003110692600897524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006048369148047641\n",
      "Training Loss: 0.005743747569504194\n",
      "Training Loss: 0.006089344076463022\n",
      "Validation Loss: 0.003103698495241782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006039111607242376\n",
      "Training Loss: 0.005734730214462616\n",
      "Training Loss: 0.006079431449761614\n",
      "Validation Loss: 0.003096811292860448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.00602995709341485\n",
      "Training Loss: 0.005725860421662219\n",
      "Training Loss: 0.006069646540563554\n",
      "Validation Loss: 0.003090033519573593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006020907339407131\n",
      "Training Loss: 0.0057171375839971\n",
      "Training Loss: 0.0060599909065058456\n",
      "Validation Loss: 0.0030833608935210395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006011962231714279\n",
      "Training Loss: 0.005708565773093141\n",
      "Training Loss: 0.006050467102904804\n",
      "Validation Loss: 0.0030768008371605798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006003122842521406\n",
      "Training Loss: 0.005700143844005651\n",
      "Training Loss: 0.0060410734778270124\n",
      "Validation Loss: 0.0030703543269420775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.00599439128418453\n",
      "Training Loss: 0.005691873267060146\n",
      "Training Loss: 0.006031812488799915\n",
      "Validation Loss: 0.003064017909646997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005985765752848237\n",
      "Training Loss: 0.00568375633098185\n",
      "Training Loss: 0.006022684432100505\n",
      "Validation Loss: 0.0030577946061875376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.00597724798717536\n",
      "Training Loss: 0.005675792466499843\n",
      "Training Loss: 0.006013690255931578\n",
      "Validation Loss: 0.003051682325666038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00596883843478281\n",
      "Training Loss: 0.005667981816804968\n",
      "Training Loss: 0.006004829229204915\n",
      "Validation Loss: 0.0030456821544074947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005960536198690533\n",
      "Training Loss: 0.005660325404605828\n",
      "Training Loss: 0.005996101179625839\n",
      "Validation Loss: 0.003039791387390722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005952340760268271\n",
      "Training Loss: 0.005652821034309454\n",
      "Training Loss: 0.0059875047957757485\n",
      "Validation Loss: 0.003034014929755685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005944252815679647\n",
      "Training Loss: 0.0056454690842656415\n",
      "Training Loss: 0.005979041257523932\n",
      "Validation Loss: 0.0030283422334894034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005936271501705051\n",
      "Training Loss: 0.005638269488699734\n",
      "Training Loss: 0.005970707832602784\n",
      "Validation Loss: 0.003022779536621875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.0059283958369633185\n",
      "Training Loss: 0.005631219167844393\n",
      "Training Loss: 0.0059625050163595004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [24:08<00:00, 144.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0030173169111498118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (5692, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.8107583779096603\n",
      "Training Loss: 0.6450993630290032\n",
      "Training Loss: 0.47566025868058204\n",
      "Validation Loss: 0.3314371321643336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.2542605239525437\n",
      "Training Loss: 0.1338967963308096\n",
      "Training Loss: 0.07625713985413313\n",
      "Validation Loss: 0.06710791359707881\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06368175594136119\n",
      "Training Loss: 0.06040060788393021\n",
      "Training Loss: 0.05749554688110948\n",
      "Validation Loss: 0.05621167408365212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05339178711175919\n",
      "Training Loss: 0.050862163659185174\n",
      "Training Loss: 0.04804788750596344\n",
      "Validation Loss: 0.04687438858149762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04469729681499302\n",
      "Training Loss: 0.043142344448715446\n",
      "Training Loss: 0.04056698936037719\n",
      "Validation Loss: 0.03920175126764212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.03756449646316469\n",
      "Training Loss: 0.03655446778982878\n",
      "Training Loss: 0.034013603422790764\n",
      "Validation Loss: 0.032481115342777096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03117032524663955\n",
      "Training Loss: 0.030575257209129632\n",
      "Training Loss: 0.028176578148268162\n",
      "Validation Loss: 0.026672512795148273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.025648727118968963\n",
      "Training Loss: 0.02543120823800564\n",
      "Training Loss: 0.023375324299559\n",
      "Validation Loss: 0.0220565197863773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.02133466077502817\n",
      "Training Loss: 0.021428964813239873\n",
      "Training Loss: 0.01987232531653717\n",
      "Validation Loss: 0.018799667149844965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.018367147436365486\n",
      "Training Loss: 0.018665751637890936\n",
      "Training Loss: 0.017575433906167746\n",
      "Validation Loss: 0.01658987166265842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01639403676148504\n",
      "Training Loss: 0.016702231711242348\n",
      "Training Loss: 0.015856398646719755\n",
      "Validation Loss: 0.014737442269230659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.014800083697773516\n",
      "Training Loss: 0.015057233842089773\n",
      "Training Loss: 0.01440378763480112\n",
      "Validation Loss: 0.013157985453085785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013506257205735893\n",
      "Training Loss: 0.013731154724955558\n",
      "Training Loss: 0.013250304237008095\n",
      "Validation Loss: 0.011899948135813635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.012497120371554047\n",
      "Training Loss: 0.01269716838374734\n",
      "Training Loss: 0.012341328416951\n",
      "Validation Loss: 0.010899839865232117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.011692840056493879\n",
      "Training Loss: 0.011874929913319647\n",
      "Training Loss: 0.011601430380251259\n",
      "Validation Loss: 0.010080031174224582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.011025859012734144\n",
      "Training Loss: 0.011198807517066598\n",
      "Training Loss: 0.010980016766116023\n",
      "Validation Loss: 0.009390867812286936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.010459996389690786\n",
      "Training Loss: 0.010630232612602413\n",
      "Training Loss: 0.010447741986718028\n",
      "Validation Loss: 0.008802735900736592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009972770886961371\n",
      "Training Loss: 0.010142534011974931\n",
      "Training Loss: 0.009983418420888483\n",
      "Validation Loss: 0.008293555927818662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009546421605627985\n",
      "Training Loss: 0.009715737500227988\n",
      "Training Loss: 0.009572337653953582\n",
      "Validation Loss: 0.007846376067289057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009169096217956394\n",
      "Training Loss: 0.009337970721535385\n",
      "Training Loss: 0.00920689390739426\n",
      "Validation Loss: 0.007450042070109355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008835188853554428\n",
      "Training Loss: 0.00900414451956749\n",
      "Training Loss: 0.00888372048502788\n",
      "Validation Loss: 0.007097876265781063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00854189665056765\n",
      "Training Loss: 0.008711578146321699\n",
      "Training Loss: 0.008599946252070367\n",
      "Validation Loss: 0.006784925500213514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008286085152067245\n",
      "Training Loss: 0.008457015031017362\n",
      "Training Loss: 0.008351818308001384\n",
      "Validation Loss: 0.006506655452867154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008063750639557839\n",
      "Training Loss: 0.008236270290799439\n",
      "Training Loss: 0.008135119857033715\n",
      "Validation Loss: 0.0062588737045383355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00787063803523779\n",
      "Training Loss: 0.008044916637009009\n",
      "Training Loss: 0.007945790487574413\n",
      "Validation Loss: 0.006037869620178774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007702742295805365\n",
      "Training Loss: 0.00787878066767007\n",
      "Training Loss: 0.007780198365217075\n",
      "Validation Loss: 0.005840428191854545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007556496240431443\n",
      "Training Loss: 0.007734149595489725\n",
      "Training Loss: 0.00763516835286282\n",
      "Validation Loss: 0.005663793543196713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00742879421566613\n",
      "Training Loss: 0.007607802246930077\n",
      "Training Loss: 0.007507942997617647\n",
      "Validation Loss: 0.005505591522368571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007316958192968741\n",
      "Training Loss: 0.007496985725592822\n",
      "Training Loss: 0.007396135923918337\n",
      "Validation Loss: 0.00536379039423603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00721870242850855\n",
      "Training Loss: 0.007399383402662352\n",
      "Training Loss: 0.007297688907710835\n",
      "Validation Loss: 0.005236634831572098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0071320955653209235\n",
      "Training Loss: 0.007313075182028114\n",
      "Training Loss: 0.00721083848271519\n",
      "Validation Loss: 0.0051225912364806685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007055508849443868\n",
      "Training Loss: 0.007236480915453285\n",
      "Training Loss: 0.007134074876084924\n",
      "Validation Loss: 0.005020308513665216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.006987580842105672\n",
      "Training Loss: 0.0071683103998657315\n",
      "Training Loss: 0.007066110570449382\n",
      "Validation Loss: 0.004928592069262869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.006927171419374645\n",
      "Training Loss: 0.007107512368820608\n",
      "Training Loss: 0.007005837854230776\n",
      "Validation Loss: 0.0048463546534937415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.006873311795061454\n",
      "Training Loss: 0.007053201261442155\n",
      "Training Loss: 0.006952297275420278\n",
      "Validation Loss: 0.0047726004922061405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0068251672526821495\n",
      "Training Loss: 0.007004624059190973\n",
      "Training Loss: 0.0069046457740478216\n",
      "Validation Loss: 0.004706417495552241\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.006782011546893046\n",
      "Training Loss: 0.006961111411219463\n",
      "Training Loss: 0.0068621367146261035\n",
      "Validation Loss: 0.004646960573318006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.006743196428287774\n",
      "Training Loss: 0.006922056978801265\n",
      "Training Loss: 0.006824101757956669\n",
      "Validation Loss: 0.004593443618616445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.006708143805153668\n",
      "Training Loss: 0.006886903498088941\n",
      "Training Loss: 0.006789946580538526\n",
      "Validation Loss: 0.004545164374331159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.006676335824886337\n",
      "Training Loss: 0.006855138946557418\n",
      "Training Loss: 0.006759142333175987\n",
      "Validation Loss: 0.00450147504871188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0066473137715365735\n",
      "Training Loss: 0.0068262972054071724\n",
      "Training Loss: 0.006731225197436288\n",
      "Validation Loss: 0.004461807242641749\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006620674394071102\n",
      "Training Loss: 0.006799961957149207\n",
      "Training Loss: 0.006705788997933269\n",
      "Validation Loss: 0.004425653523315539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006596064034383744\n",
      "Training Loss: 0.006775762062752619\n",
      "Training Loss: 0.006682481263997033\n",
      "Validation Loss: 0.004392571139719672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006573177799582481\n",
      "Training Loss: 0.006753377773566172\n",
      "Training Loss: 0.006661000145832077\n",
      "Validation Loss: 0.004362170702877214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006551754210377112\n",
      "Training Loss: 0.006732529806904495\n",
      "Training Loss: 0.006641086636809632\n",
      "Validation Loss: 0.00433411941146792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006531573107931763\n",
      "Training Loss: 0.00671298480592668\n",
      "Training Loss: 0.006622520688688382\n",
      "Validation Loss: 0.004308122703334673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006512444651452825\n",
      "Training Loss: 0.006694543450139463\n",
      "Training Loss: 0.006605112120741979\n",
      "Validation Loss: 0.004283928262655822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006494209266966209\n",
      "Training Loss: 0.0066770398151129486\n",
      "Training Loss: 0.006588702235603705\n",
      "Validation Loss: 0.004261322851878789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006476734201423823\n",
      "Training Loss: 0.006660334728658199\n",
      "Training Loss: 0.0065731523185968395\n",
      "Validation Loss: 0.004240106820688698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006459905339870602\n",
      "Training Loss: 0.006644309683470056\n",
      "Training Loss: 0.0065583467588294295\n",
      "Validation Loss: 0.004220117079067892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006443626933032647\n",
      "Training Loss: 0.006628871383145452\n",
      "Training Loss: 0.00654418517020531\n",
      "Validation Loss: 0.00420120982662513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006427818650845438\n",
      "Training Loss: 0.006613937207730487\n",
      "Training Loss: 0.006530580229591579\n",
      "Validation Loss: 0.004183259107214347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006412412305362523\n",
      "Training Loss: 0.00659944107173942\n",
      "Training Loss: 0.00651745728449896\n",
      "Validation Loss: 0.004166148568953524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006397347440943122\n",
      "Training Loss: 0.0065853243344463405\n",
      "Training Loss: 0.006504752450855449\n",
      "Validation Loss: 0.004149788145624687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006382575819734484\n",
      "Training Loss: 0.006571537122363224\n",
      "Training Loss: 0.006492404554737732\n",
      "Validation Loss: 0.00413408543616324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006368052670732141\n",
      "Training Loss: 0.0065580383443739265\n",
      "Training Loss: 0.006480365790193901\n",
      "Validation Loss: 0.004118959304976037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006353739433689043\n",
      "Training Loss: 0.006544791873311624\n",
      "Training Loss: 0.0064685896621085705\n",
      "Validation Loss: 0.004104352849169394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006339603731175885\n",
      "Training Loss: 0.006531766436528415\n",
      "Training Loss: 0.006457035000203178\n",
      "Validation Loss: 0.004090193760440047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006325614263769239\n",
      "Training Loss: 0.006518935055937618\n",
      "Training Loss: 0.006445664546918124\n",
      "Validation Loss: 0.00407643626205979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006311745155835524\n",
      "Training Loss: 0.0065062696416862305\n",
      "Training Loss: 0.006434444081969559\n",
      "Validation Loss: 0.004063025598278206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006297968740109354\n",
      "Training Loss: 0.006493746236665174\n",
      "Training Loss: 0.006423338289605454\n",
      "Validation Loss: 0.004049919689534588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006284263806883246\n",
      "Training Loss: 0.006481343929772265\n",
      "Training Loss: 0.00641231813817285\n",
      "Validation Loss: 0.004037071720519093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006270605609752238\n",
      "Training Loss: 0.00646904191467911\n",
      "Training Loss: 0.006401352239772677\n",
      "Validation Loss: 0.0040244470249725444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006256973174167797\n",
      "Training Loss: 0.006456817917060107\n",
      "Training Loss: 0.006390410795575008\n",
      "Validation Loss: 0.004012012406869718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00624334595631808\n",
      "Training Loss: 0.0064446518674958495\n",
      "Training Loss: 0.006379463439807296\n",
      "Validation Loss: 0.003999732750640617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006229701170232147\n",
      "Training Loss: 0.00643252357665915\n",
      "Training Loss: 0.006368479733355343\n",
      "Validation Loss: 0.003987570624181143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006216015574755147\n",
      "Training Loss: 0.006420410830760375\n",
      "Training Loss: 0.0063574280275497585\n",
      "Validation Loss: 0.003975501378181945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006202266670297832\n",
      "Training Loss: 0.006408290964318439\n",
      "Training Loss: 0.0063462756958324465\n",
      "Validation Loss: 0.003963489140373435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0061884302948601545\n",
      "Training Loss: 0.0063961409276816995\n",
      "Training Loss: 0.006334985480643809\n",
      "Validation Loss: 0.003951505336026253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0061744821979664265\n",
      "Training Loss: 0.0063839371537324045\n",
      "Training Loss: 0.006323523140745238\n",
      "Validation Loss: 0.0039395140490515596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006160395444603637\n",
      "Training Loss: 0.0063716525363270195\n",
      "Training Loss: 0.00631184613215737\n",
      "Validation Loss: 0.003927486628853831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006146142923971638\n",
      "Training Loss: 0.006359260822064243\n",
      "Training Loss: 0.006299913596594706\n",
      "Validation Loss: 0.003915389654425423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006131694850046188\n",
      "Training Loss: 0.00634673147869762\n",
      "Training Loss: 0.006287680467357859\n",
      "Validation Loss: 0.003903190781927427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006117023037513718\n",
      "Training Loss: 0.0063340361107839275\n",
      "Training Loss: 0.006275099304039031\n",
      "Validation Loss: 0.003890853205151605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006102099347626791\n",
      "Training Loss: 0.006321146364789456\n",
      "Training Loss: 0.0062621232448145745\n",
      "Validation Loss: 0.0038783401715192485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006086897510103881\n",
      "Training Loss: 0.006308034840039909\n",
      "Training Loss: 0.006248703893506899\n",
      "Validation Loss: 0.003865626306414311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006071396515471861\n",
      "Training Loss: 0.006294675798853859\n",
      "Training Loss: 0.00623479877714999\n",
      "Validation Loss: 0.003852676865749396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006055584421847016\n",
      "Training Loss: 0.006281054357532412\n",
      "Training Loss: 0.006220372546231374\n",
      "Validation Loss: 0.0038394648699466597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006039460167521611\n",
      "Training Loss: 0.006267163271550089\n",
      "Training Loss: 0.006205404285574332\n",
      "Validation Loss: 0.0038259786683176593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006023042232263833\n",
      "Training Loss: 0.006253011951921508\n",
      "Training Loss: 0.006189890064997598\n",
      "Validation Loss: 0.003812216602271067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006006375112337992\n",
      "Training Loss: 0.00623862798733171\n",
      "Training Loss: 0.0061738596379291265\n",
      "Validation Loss: 0.0037981932322243544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.005989529988728464\n",
      "Training Loss: 0.006224065789137967\n",
      "Training Loss: 0.006157374677713961\n",
      "Validation Loss: 0.0037839418294148917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.005972616113722324\n",
      "Training Loss: 0.0062094045378034935\n",
      "Training Loss: 0.006140538477338851\n",
      "Validation Loss: 0.0037695294922332834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.005955773059977219\n",
      "Training Loss: 0.006194752648007125\n",
      "Training Loss: 0.006123494434868917\n",
      "Validation Loss: 0.0037550426649421535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.005939168873010203\n",
      "Training Loss: 0.006180236127111129\n",
      "Training Loss: 0.006106419977732003\n",
      "Validation Loss: 0.0037405871828034352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005922983530908823\n",
      "Training Loss: 0.006165990656591021\n",
      "Training Loss: 0.006089510415913537\n",
      "Validation Loss: 0.0037262782041150868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.005907389837084338\n",
      "Training Loss: 0.0061521480994997544\n",
      "Training Loss: 0.006072957504075021\n",
      "Validation Loss: 0.003712231023864967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005892535822931677\n",
      "Training Loss: 0.006138819981715642\n",
      "Training Loss: 0.006056929868645966\n",
      "Validation Loss: 0.0036985400208701075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.0058785226079635326\n",
      "Training Loss: 0.006126085903379135\n",
      "Training Loss: 0.006041557984426618\n",
      "Validation Loss: 0.0036852806754242838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005865400998154655\n",
      "Training Loss: 0.006113989937584847\n",
      "Training Loss: 0.006026919134892523\n",
      "Validation Loss: 0.0036724945837684144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005853169389301911\n",
      "Training Loss: 0.006102543316083029\n",
      "Training Loss: 0.006013045940781012\n",
      "Validation Loss: 0.003660204912551543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005841789528494701\n",
      "Training Loss: 0.006091729063191451\n",
      "Training Loss: 0.005999931950354948\n",
      "Validation Loss: 0.0036484023276193256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.005831193004269153\n",
      "Training Loss: 0.006081511388183572\n",
      "Training Loss: 0.00598754377104342\n",
      "Validation Loss: 0.003637067987348131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00582130063790828\n",
      "Training Loss: 0.006071845281985589\n",
      "Training Loss: 0.005975829189410433\n",
      "Validation Loss: 0.0036261746799834908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.005812028283253312\n",
      "Training Loss: 0.006062681479379535\n",
      "Training Loss: 0.005964729358674958\n",
      "Validation Loss: 0.003615686425996756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.005803297758102417\n",
      "Training Loss: 0.00605397009756416\n",
      "Training Loss: 0.005954185457667336\n",
      "Validation Loss: 0.0036055725270599712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0057950375252403315\n",
      "Training Loss: 0.006045665413839742\n",
      "Training Loss: 0.0059441431006416676\n",
      "Validation Loss: 0.003595801231221118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005787185908993706\n",
      "Training Loss: 0.006037726391223259\n",
      "Training Loss: 0.0059345469262916594\n",
      "Validation Loss: 0.003586343175658349\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005779688712209463\n",
      "Training Loss: 0.00603011671861168\n",
      "Training Loss: 0.00592535226373002\n",
      "Validation Loss: 0.003577175964810624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005772502366453409\n",
      "Training Loss: 0.006022799185593612\n",
      "Training Loss: 0.00591651864349842\n",
      "Validation Loss: 0.0035682772286236286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005765589076909237\n",
      "Training Loss: 0.006015747970668599\n",
      "Training Loss: 0.005908011180581525\n",
      "Validation Loss: 0.0035596252759144214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.005758916453341954\n",
      "Training Loss: 0.0060089358140248805\n",
      "Training Loss: 0.0058997990819625555\n",
      "Validation Loss: 0.003551203497225063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005752458916394971\n",
      "Training Loss: 0.00600233978475444\n",
      "Training Loss: 0.005891853977227583\n",
      "Validation Loss: 0.0035430021208627256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00574619407474529\n",
      "Training Loss: 0.005995940497377887\n",
      "Training Loss: 0.005884154225932434\n",
      "Validation Loss: 0.003534998746688237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005740102076088078\n",
      "Training Loss: 0.005989719701465219\n",
      "Training Loss: 0.00587667781393975\n",
      "Validation Loss: 0.0035271905290663996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005734168341150508\n",
      "Training Loss: 0.005983662699582055\n",
      "Training Loss: 0.005869409833103419\n",
      "Validation Loss: 0.0035195621077149185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.005728378024068661\n",
      "Training Loss: 0.005977754715713672\n",
      "Training Loss: 0.005862332071410492\n",
      "Validation Loss: 0.0035121060778345032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005722718046163209\n",
      "Training Loss: 0.0059719834185671065\n",
      "Training Loss: 0.0058554314711363985\n",
      "Validation Loss: 0.0035048156167024726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005717180547653697\n",
      "Training Loss: 0.005966337755089626\n",
      "Training Loss: 0.005848695204476826\n",
      "Validation Loss: 0.0034976807623065672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.005711754651856609\n",
      "Training Loss: 0.005960808239178732\n",
      "Training Loss: 0.005842112611280754\n",
      "Validation Loss: 0.0034906940974211427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005706432214938104\n",
      "Training Loss: 0.005955385570996441\n",
      "Training Loss: 0.005835674462141469\n",
      "Validation Loss: 0.0034838469674172445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.005701206725207158\n",
      "Training Loss: 0.005950064277858474\n",
      "Training Loss: 0.005829369991552084\n",
      "Validation Loss: 0.003477140088445308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005696073033032007\n",
      "Training Loss: 0.005944834396941588\n",
      "Training Loss: 0.005823193265823648\n",
      "Validation Loss: 0.003470558682299648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.0056910226814216\n",
      "Training Loss: 0.005939690610393882\n",
      "Training Loss: 0.0058171361382119355\n",
      "Validation Loss: 0.0034641022028746816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005686052709352225\n",
      "Training Loss: 0.005934627880924382\n",
      "Training Loss: 0.005811190838576294\n",
      "Validation Loss: 0.0034577632924604616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005681157409562729\n",
      "Training Loss: 0.00592964231967926\n",
      "Training Loss: 0.005805353765026666\n",
      "Validation Loss: 0.00345153814270632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005676333365263417\n",
      "Training Loss: 0.005924726751400158\n",
      "Training Loss: 0.005799616849981248\n",
      "Validation Loss: 0.003445421015906535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005671576931490563\n",
      "Training Loss: 0.005919877834385261\n",
      "Training Loss: 0.005793975161504932\n",
      "Validation Loss: 0.003439407299267484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005666882643126882\n",
      "Training Loss: 0.005915092716459185\n",
      "Training Loss: 0.005788424838683568\n",
      "Validation Loss: 0.003433493777633425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005662250046734698\n",
      "Training Loss: 0.0059103656088700515\n",
      "Training Loss: 0.0057829615945229305\n",
      "Validation Loss: 0.0034276759009965268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005657675544498488\n",
      "Training Loss: 0.005905696923146024\n",
      "Training Loss: 0.005777578969136812\n",
      "Validation Loss: 0.003421946948007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005653154007159173\n",
      "Training Loss: 0.0059010803722776475\n",
      "Training Loss: 0.005772275861818344\n",
      "Validation Loss: 0.003416306048166007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005648685443447903\n",
      "Training Loss: 0.005896516010398045\n",
      "Training Loss: 0.005767047007102519\n",
      "Validation Loss: 0.0034107478084356596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005644266013405286\n",
      "Training Loss: 0.005891999322338961\n",
      "Training Loss: 0.005761888398556039\n",
      "Validation Loss: 0.0034052700627061508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0056398945965338496\n",
      "Training Loss: 0.005887529015890323\n",
      "Training Loss: 0.005756798586226068\n",
      "Validation Loss: 0.003399869561812767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005635568503057584\n",
      "Training Loss: 0.00588310252816882\n",
      "Training Loss: 0.0057517740066396076\n",
      "Validation Loss: 0.0033945436079285286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.005631286322022788\n",
      "Training Loss: 0.005878719082684256\n",
      "Training Loss: 0.005746811390854418\n",
      "Validation Loss: 0.0033892863488944477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005627045751316473\n",
      "Training Loss: 0.005874374629929662\n",
      "Training Loss: 0.0057419082283740866\n",
      "Validation Loss: 0.003384098887385989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.0056228451646165925\n",
      "Training Loss: 0.0058700695278821515\n",
      "Training Loss: 0.005737061491236091\n",
      "Validation Loss: 0.0033789758512938624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005618683209759183\n",
      "Training Loss: 0.005865802341722883\n",
      "Training Loss: 0.0057322698866482825\n",
      "Validation Loss: 0.0033739115244949634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005614557655644603\n",
      "Training Loss: 0.005861571122077294\n",
      "Training Loss: 0.005727530681760982\n",
      "Validation Loss: 0.0033689092248259636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005610468558152206\n",
      "Training Loss: 0.005857375531923026\n",
      "Training Loss: 0.005722841501701623\n",
      "Validation Loss: 0.0033639636854745783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005606413775240071\n",
      "Training Loss: 0.0058532122289761904\n",
      "Training Loss: 0.005718200803385116\n",
      "Validation Loss: 0.003359072951579027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005602391301072203\n",
      "Training Loss: 0.005849082202767022\n",
      "Training Loss: 0.005713605969795026\n",
      "Validation Loss: 0.003354235078741828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005598402206087485\n",
      "Training Loss: 0.005844982918351889\n",
      "Training Loss: 0.005709056498017162\n",
      "Validation Loss: 0.0033494454816381416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.005594443411682732\n",
      "Training Loss: 0.005840915239532478\n",
      "Training Loss: 0.005704548574285582\n",
      "Validation Loss: 0.0033447038241023763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0055905148823512715\n",
      "Training Loss: 0.005836875985842198\n",
      "Training Loss: 0.005700082745170221\n",
      "Validation Loss: 0.003340008910588418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.005586615416104905\n",
      "Training Loss: 0.005832865851698443\n",
      "Training Loss: 0.005695655758609064\n",
      "Validation Loss: 0.003335361695309494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005582743681734428\n",
      "Training Loss: 0.005828883420326747\n",
      "Training Loss: 0.0056912677979562435\n",
      "Validation Loss: 0.0033307551364466716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.00557889967050869\n",
      "Training Loss: 0.005824928473448381\n",
      "Training Loss: 0.005686916881240904\n",
      "Validation Loss: 0.0033261895139199377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005575082457507961\n",
      "Training Loss: 0.005820999967399984\n",
      "Training Loss: 0.005682601044536568\n",
      "Validation Loss: 0.0033216674935093587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005571291210362688\n",
      "Training Loss: 0.005817097830586136\n",
      "Training Loss: 0.005678318901918829\n",
      "Validation Loss: 0.0033171805631620494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.005567524774232879\n",
      "Training Loss: 0.005813220409909264\n",
      "Training Loss: 0.005674070580862462\n",
      "Validation Loss: 0.0033127300851988825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005563783791731111\n",
      "Training Loss: 0.005809368399786763\n",
      "Training Loss: 0.005669854615116492\n",
      "Validation Loss: 0.003308317202844479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.005560065640602261\n",
      "Training Loss: 0.005805540443980135\n",
      "Training Loss: 0.00566566931840498\n",
      "Validation Loss: 0.00330393861134254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005556371660786681\n",
      "Training Loss: 0.005801735616987571\n",
      "Training Loss: 0.005661514716921374\n",
      "Validation Loss: 0.0032995949575175226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005552700674161315\n",
      "Training Loss: 0.005797954948502593\n",
      "Training Loss: 0.0056573885801481085\n",
      "Validation Loss: 0.0032952835213058114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005549052901915275\n",
      "Training Loss: 0.0057941971119726075\n",
      "Training Loss: 0.0056532902887556705\n",
      "Validation Loss: 0.0032910032929025926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005545426232856698\n",
      "Training Loss: 0.005790463170851581\n",
      "Training Loss: 0.005649219951592386\n",
      "Validation Loss: 0.003286753838693493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005541822306113318\n",
      "Training Loss: 0.005786750469706021\n",
      "Training Loss: 0.005645176748512313\n",
      "Validation Loss: 0.003282535573980363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005538239617599174\n",
      "Training Loss: 0.00578306018258445\n",
      "Training Loss: 0.005641158302896656\n",
      "Validation Loss: 0.0032783442463338625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0055346778308739885\n",
      "Training Loss: 0.005779392673866823\n",
      "Training Loss: 0.00563716511009261\n",
      "Validation Loss: 0.0032741813017892534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005531136692152359\n",
      "Training Loss: 0.005775746197905392\n",
      "Training Loss: 0.005633197200368158\n",
      "Validation Loss: 0.003270048916266624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005527617149055004\n",
      "Training Loss: 0.005772122097550891\n",
      "Training Loss: 0.005629254375817254\n",
      "Validation Loss: 0.0032659449432767256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.00552411860844586\n",
      "Training Loss: 0.005768518600962125\n",
      "Training Loss: 0.00562533381395042\n",
      "Validation Loss: 0.0032618685312872605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005520640866598115\n",
      "Training Loss: 0.005764937503263354\n",
      "Training Loss: 0.005621436621877365\n",
      "Validation Loss: 0.0032578153833956198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005517182101611979\n",
      "Training Loss: 0.005761377689195797\n",
      "Training Loss: 0.005617562264669687\n",
      "Validation Loss: 0.0032537912229191135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005513743638293818\n",
      "Training Loss: 0.005757837649434805\n",
      "Training Loss: 0.005613710194011219\n",
      "Validation Loss: 0.003249791650928222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005510326300282031\n",
      "Training Loss: 0.00575432124081999\n",
      "Training Loss: 0.00560987887554802\n",
      "Validation Loss: 0.0032458174699038435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00550692880875431\n",
      "Training Loss: 0.00575082526775077\n",
      "Training Loss: 0.00560606915561948\n",
      "Validation Loss: 0.0032418722789106743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.0055035521561512726\n",
      "Training Loss: 0.00574735035886988\n",
      "Training Loss: 0.005602281138999387\n",
      "Validation Loss: 0.0032379517025638667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005500193947227672\n",
      "Training Loss: 0.0057438967941561715\n",
      "Training Loss: 0.00559851378784515\n",
      "Validation Loss: 0.0032340558572787415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.0054968568123877045\n",
      "Training Loss: 0.0057404654083075\n",
      "Training Loss: 0.005594766089925543\n",
      "Validation Loss: 0.003230183607678902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005493538727751002\n",
      "Training Loss: 0.005737054944038391\n",
      "Training Loss: 0.005591039775754325\n",
      "Validation Loss: 0.003226339248050883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.00549024180858396\n",
      "Training Loss: 0.005733666604501195\n",
      "Training Loss: 0.005587333204457537\n",
      "Validation Loss: 0.00322252217931359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005486964891897515\n",
      "Training Loss: 0.005730299443239346\n",
      "Training Loss: 0.0055836463032756\n",
      "Validation Loss: 0.00321873026675011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.00548370820179116\n",
      "Training Loss: 0.005726954708225093\n",
      "Training Loss: 0.005579979007015936\n",
      "Validation Loss: 0.0032149639099658457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.00548047166550532\n",
      "Training Loss: 0.005723632264416665\n",
      "Training Loss: 0.005576331624761224\n",
      "Validation Loss: 0.003211223895745247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0054772560583660375\n",
      "Training Loss: 0.005720331219490618\n",
      "Training Loss: 0.005572704571532086\n",
      "Validation Loss: 0.0032075116681615206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005474060318665579\n",
      "Training Loss: 0.005717053101980127\n",
      "Training Loss: 0.005569097088882699\n",
      "Validation Loss: 0.0032038255666612826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005470885328832082\n",
      "Training Loss: 0.005713797998614609\n",
      "Training Loss: 0.005565506665734574\n",
      "Validation Loss: 0.0032001610196540865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005467731106327847\n",
      "Training Loss: 0.005710564856417477\n",
      "Training Loss: 0.005561936912126839\n",
      "Validation Loss: 0.0031965300493109763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005464597305399365\n",
      "Training Loss: 0.005707353051984682\n",
      "Training Loss: 0.005558386185439304\n",
      "Validation Loss: 0.0031929254202234946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.00546148408902809\n",
      "Training Loss: 0.005704165590577759\n",
      "Training Loss: 0.005554854308138601\n",
      "Validation Loss: 0.0031893481866697247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005458392142318189\n",
      "Training Loss: 0.005701001026900485\n",
      "Training Loss: 0.005551341091049835\n",
      "Validation Loss: 0.003185798092274351\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0054553199111251165\n",
      "Training Loss: 0.005697859120555222\n",
      "Training Loss: 0.005547846971312538\n",
      "Validation Loss: 0.00318227841367087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.0054522695671767\n",
      "Training Loss: 0.005694740533363074\n",
      "Training Loss: 0.005544372203294188\n",
      "Validation Loss: 0.0031787866655883664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005449238951550797\n",
      "Training Loss: 0.005691644985927269\n",
      "Training Loss: 0.0055409161618445064\n",
      "Validation Loss: 0.003175322829714317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005446230180677958\n",
      "Training Loss: 0.005688573123188689\n",
      "Training Loss: 0.005537478363257833\n",
      "Validation Loss: 0.0031718907444842495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005443242118344642\n",
      "Training Loss: 0.005685524136060849\n",
      "Training Loss: 0.005534059483325109\n",
      "Validation Loss: 0.003168484606790576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005440273403655738\n",
      "Training Loss: 0.00568249897507485\n",
      "Training Loss: 0.005530658734496683\n",
      "Validation Loss: 0.0031651115349724136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005437326355604455\n",
      "Training Loss: 0.005679495682707056\n",
      "Training Loss: 0.005527277555083856\n",
      "Validation Loss: 0.0031617688292407253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.0054343989817425605\n",
      "Training Loss: 0.005676516848034226\n",
      "Training Loss: 0.0055239132716087625\n",
      "Validation Loss: 0.003158453299946497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005431491765775718\n",
      "Training Loss: 0.00567356233485043\n",
      "Training Loss: 0.005520568414940499\n",
      "Validation Loss: 0.003155169481401112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005428604823537171\n",
      "Training Loss: 0.005670627580257132\n",
      "Training Loss: 0.00551724097749684\n",
      "Validation Loss: 0.003151917340903637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005425738089252263\n",
      "Training Loss: 0.0056677173759089785\n",
      "Training Loss: 0.005513932594913058\n",
      "Validation Loss: 0.0031486987345590352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005422889659530483\n",
      "Training Loss: 0.005664830708410591\n",
      "Training Loss: 0.005510640824213624\n",
      "Validation Loss: 0.003145509210462274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005420061651966535\n",
      "Training Loss: 0.005661965297185816\n",
      "Training Loss: 0.005507366814417765\n",
      "Validation Loss: 0.003142349903335732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005417252401239239\n",
      "Training Loss: 0.005659123075893149\n",
      "Training Loss: 0.00550411092757713\n",
      "Validation Loss: 0.003139224800077173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.00541446189803537\n",
      "Training Loss: 0.0056563017604639755\n",
      "Training Loss: 0.0055008721438935025\n",
      "Validation Loss: 0.0031361300459006028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005411689564352855\n",
      "Training Loss: 0.005653503196663223\n",
      "Training Loss: 0.0054976509284460915\n",
      "Validation Loss: 0.003133065693781533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005408934878651053\n",
      "Training Loss: 0.005650725302984938\n",
      "Training Loss: 0.005494446538505144\n",
      "Validation Loss: 0.00313003285555169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005406197439297103\n",
      "Training Loss: 0.005647969048004598\n",
      "Training Loss: 0.0054912572231842205\n",
      "Validation Loss: 0.0031270292794248196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005403476608917117\n",
      "Training Loss: 0.005645232738461345\n",
      "Training Loss: 0.0054880848323227835\n",
      "Validation Loss: 0.0031240583865725425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0054007729975273835\n",
      "Training Loss: 0.005642516334773973\n",
      "Training Loss: 0.005484929091762751\n",
      "Validation Loss: 0.003121120068427761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005398085191845894\n",
      "Training Loss: 0.005639820469077676\n",
      "Training Loss: 0.0054817883035866545\n",
      "Validation Loss: 0.003118212393673367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0053954135352978485\n",
      "Training Loss: 0.00563714380026795\n",
      "Training Loss: 0.00547866310866084\n",
      "Validation Loss: 0.003115334730527332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.0053927552694221954\n",
      "Training Loss: 0.005634484796901234\n",
      "Training Loss: 0.005475552858551964\n",
      "Validation Loss: 0.003112488649942483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005390112376771867\n",
      "Training Loss: 0.005631845534662716\n",
      "Training Loss: 0.005472456847783178\n",
      "Validation Loss: 0.003109671776523039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005387482715887018\n",
      "Training Loss: 0.005629223222495056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:29<22:25, 149.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005469375138054602\n",
      "Validation Loss: 0.0031068851246519452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.11678840102627873\n",
      "Training Loss: 0.09081743916496635\n",
      "Training Loss: 0.07669586949050426\n",
      "Validation Loss: 0.07242327449278216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06952130001038313\n",
      "Training Loss: 0.0660807149298489\n",
      "Training Loss: 0.06540094584226608\n",
      "Validation Loss: 0.06464656580532535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.062299871267750856\n",
      "Training Loss: 0.0587793224491179\n",
      "Training Loss: 0.05639407007023692\n",
      "Validation Loss: 0.05403291821228654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.050799553534016016\n",
      "Training Loss: 0.047043788749724626\n",
      "Training Loss: 0.04338279821909964\n",
      "Validation Loss: 0.041076272108665345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03824573947116733\n",
      "Training Loss: 0.036218624897301196\n",
      "Training Loss: 0.033087115855887535\n",
      "Validation Loss: 0.03152483015247945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02944950997363776\n",
      "Training Loss: 0.02860745490528643\n",
      "Training Loss: 0.02587249122094363\n",
      "Validation Loss: 0.02439126745912801\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.022980546061880887\n",
      "Training Loss: 0.022686652040574698\n",
      "Training Loss: 0.020430160341784357\n",
      "Validation Loss: 0.01895706769434756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.018335138012189417\n",
      "Training Loss: 0.018457364211790263\n",
      "Training Loss: 0.017049387358129026\n",
      "Validation Loss: 0.01573535451257413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.015800657360814513\n",
      "Training Loss: 0.016127927533816547\n",
      "Training Loss: 0.015260841804556549\n",
      "Validation Loss: 0.013866152891659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.01426533074118197\n",
      "Training Loss: 0.014590472725685685\n",
      "Training Loss: 0.013900220729410648\n",
      "Validation Loss: 0.012383961992526657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012992411011364311\n",
      "Training Loss: 0.013318177529145032\n",
      "Training Loss: 0.012718799971044064\n",
      "Validation Loss: 0.01111738027460622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011904668102506549\n",
      "Training Loss: 0.01224248479353264\n",
      "Training Loss: 0.01171011216705665\n",
      "Validation Loss: 0.010045388089545238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.010995218527968973\n",
      "Training Loss: 0.011345985521329567\n",
      "Training Loss: 0.010868045609677211\n",
      "Validation Loss: 0.00915174889561375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010248438930138945\n",
      "Training Loss: 0.010607304347213358\n",
      "Training Loss: 0.010176256110426038\n",
      "Validation Loss: 0.008415521223234076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009643915235064924\n",
      "Training Loss: 0.010004782483447343\n",
      "Training Loss: 0.00961928311851807\n",
      "Validation Loss: 0.007820026703137025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009166656610323115\n",
      "Training Loss: 0.009528226057300344\n",
      "Training Loss: 0.009186397892190144\n",
      "Validation Loss: 0.007351794234330483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0088013999175746\n",
      "Training Loss: 0.009164814522955566\n",
      "Training Loss: 0.008854592648567632\n",
      "Validation Loss: 0.006984808991056229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00852151727071032\n",
      "Training Loss: 0.008886764737544581\n",
      "Training Loss: 0.008594868608051911\n",
      "Validation Loss: 0.0066900583169831156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008301797795575112\n",
      "Training Loss: 0.008668379329610615\n",
      "Training Loss: 0.0083863141736947\n",
      "Validation Loss: 0.006447045666197043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008125261695822701\n",
      "Training Loss: 0.008492522231535985\n",
      "Training Loss: 0.008215532024623827\n",
      "Validation Loss: 0.006242714113336098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007980882718693466\n",
      "Training Loss: 0.008348138002911582\n",
      "Training Loss: 0.008073564347578213\n",
      "Validation Loss: 0.0060684509507349035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007861168109811842\n",
      "Training Loss: 0.008227758532157167\n",
      "Training Loss: 0.00795410804101266\n",
      "Validation Loss: 0.005918233676321721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0077607754524797205\n",
      "Training Loss: 0.00812609285232611\n",
      "Training Loss: 0.007852547650691122\n",
      "Validation Loss: 0.0057876508583555395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0076757552393246446\n",
      "Training Loss: 0.008039243347011506\n",
      "Training Loss: 0.007765402887016535\n",
      "Validation Loss: 0.005673357286867214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007603102426510304\n",
      "Training Loss: 0.007964268241776153\n",
      "Training Loss: 0.007689990244107321\n",
      "Validation Loss: 0.005572742399278233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00754048399743624\n",
      "Training Loss: 0.007898895812686532\n",
      "Training Loss: 0.00762419817969203\n",
      "Validation Loss: 0.00548371277733842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007486053821630776\n",
      "Training Loss: 0.007841345471097156\n",
      "Training Loss: 0.007566347429528833\n",
      "Validation Loss: 0.005404582809594073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007438336287159473\n",
      "Training Loss: 0.007790207446087152\n",
      "Training Loss: 0.007515080467564985\n",
      "Validation Loss: 0.005333951318615608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007396138207986951\n",
      "Training Loss: 0.007744348897831515\n",
      "Training Loss: 0.007469293792964891\n",
      "Validation Loss: 0.0052706586861501585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007358485895674676\n",
      "Training Loss: 0.007702854629606008\n",
      "Training Loss: 0.007428081907564774\n",
      "Validation Loss: 0.005213724722656725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007324584504822269\n",
      "Training Loss: 0.007664983011782169\n",
      "Training Loss: 0.007390700380783528\n",
      "Validation Loss: 0.005162315653752159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007293778280727565\n",
      "Training Loss: 0.007630121301626786\n",
      "Training Loss: 0.00735653082607314\n",
      "Validation Loss: 0.005115724347918974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007265527471899986\n",
      "Training Loss: 0.007597770104184747\n",
      "Training Loss: 0.007325059577124193\n",
      "Validation Loss: 0.0050733391734447035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007239387085428461\n",
      "Training Loss: 0.007567517089191824\n",
      "Training Loss: 0.007295862432802096\n",
      "Validation Loss: 0.005034635689768815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007214987695915625\n",
      "Training Loss: 0.007539019106188789\n",
      "Training Loss: 0.007268581580137834\n",
      "Validation Loss: 0.004999156983757622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007192026622360573\n",
      "Training Loss: 0.007511994373053312\n",
      "Training Loss: 0.007242919231066481\n",
      "Validation Loss: 0.004966502007243506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007170249649789184\n",
      "Training Loss: 0.007486206670291722\n",
      "Training Loss: 0.007218625654932111\n",
      "Validation Loss: 0.004936327039410643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007149448945419863\n",
      "Training Loss: 0.007461458839243278\n",
      "Training Loss: 0.007195489152800292\n",
      "Validation Loss: 0.004908328730707172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007129448151681572\n",
      "Training Loss: 0.007437584346625954\n",
      "Training Loss: 0.007173329924698919\n",
      "Validation Loss: 0.0048822328027107575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007110100578283891\n",
      "Training Loss: 0.007414443306624889\n",
      "Training Loss: 0.0071519925107713786\n",
      "Validation Loss: 0.004857801942787855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007091280467575416\n",
      "Training Loss: 0.007391913811443373\n",
      "Training Loss: 0.007131340175401419\n",
      "Validation Loss: 0.0048348178113863036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007072877435712143\n",
      "Training Loss: 0.007369888402754441\n",
      "Training Loss: 0.007111251567257568\n",
      "Validation Loss: 0.004813088981167863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007054792601848021\n",
      "Training Loss: 0.007348270983202383\n",
      "Training Loss: 0.007091614295495674\n",
      "Validation Loss: 0.004792432107156917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007036934790667146\n",
      "Training Loss: 0.007326972252922132\n",
      "Training Loss: 0.007072323597967624\n",
      "Validation Loss: 0.004772687156219035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.0070192169479560106\n",
      "Training Loss: 0.007305907646659762\n",
      "Training Loss: 0.007053276505321265\n",
      "Validation Loss: 0.0047536938257641\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007001551983412355\n",
      "Training Loss: 0.007284990168409422\n",
      "Training Loss: 0.007034368310123682\n",
      "Validation Loss: 0.004735301902747891\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006983849937096238\n",
      "Training Loss: 0.007264136391459033\n",
      "Training Loss: 0.007015494182705879\n",
      "Validation Loss: 0.004717372015139528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006966018746607005\n",
      "Training Loss: 0.007243253637570887\n",
      "Training Loss: 0.006996542748529464\n",
      "Validation Loss: 0.004699749349527521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006947957884985954\n",
      "Training Loss: 0.007222249087644741\n",
      "Training Loss: 0.006977393621345982\n",
      "Validation Loss: 0.004682292284056796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006929561889264733\n",
      "Training Loss: 0.007201021483633667\n",
      "Training Loss: 0.006957923293812201\n",
      "Validation Loss: 0.004664844172101551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006910718913422898\n",
      "Training Loss: 0.007179467062815093\n",
      "Training Loss: 0.0069380005146376785\n",
      "Validation Loss: 0.004647252268911329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00689131606486626\n",
      "Training Loss: 0.007157483334303834\n",
      "Training Loss: 0.0069174960756208746\n",
      "Validation Loss: 0.004629364507953019\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00687124424148351\n",
      "Training Loss: 0.00713496973447036\n",
      "Training Loss: 0.006896287293639034\n",
      "Validation Loss: 0.0046110252524056376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0068504047475289554\n",
      "Training Loss: 0.007111840386060066\n",
      "Training Loss: 0.0068742680898867545\n",
      "Validation Loss: 0.004592102671073478\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006828720901394263\n",
      "Training Loss: 0.0070880247320747\n",
      "Training Loss: 0.006851359616266563\n",
      "Validation Loss: 0.0045724663395549725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006806146596791223\n",
      "Training Loss: 0.007063485850230791\n",
      "Training Loss: 0.006827521065715701\n",
      "Validation Loss: 0.004552030920187074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006782669328385964\n",
      "Training Loss: 0.00703821191273164\n",
      "Training Loss: 0.006802753795636818\n",
      "Validation Loss: 0.004530733396963666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006758315346669406\n",
      "Training Loss: 0.0070122269348939885\n",
      "Training Loss: 0.006777101746993139\n",
      "Validation Loss: 0.004508546884485594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006733141737058758\n",
      "Training Loss: 0.00698557935305871\n",
      "Training Loss: 0.006750645044958219\n",
      "Validation Loss: 0.004485476939295408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006707228905288503\n",
      "Training Loss: 0.006958343596197665\n",
      "Training Loss: 0.0067234891711268575\n",
      "Validation Loss: 0.004461548667861505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006680670878849924\n",
      "Training Loss: 0.006930603446089662\n",
      "Training Loss: 0.006695753736421466\n",
      "Validation Loss: 0.004436817684660802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006653564749285579\n",
      "Training Loss: 0.006902449555927888\n",
      "Training Loss: 0.006667560929199681\n",
      "Validation Loss: 0.0044113493497023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0066260008665267375\n",
      "Training Loss: 0.006873973515466787\n",
      "Training Loss: 0.006639027975033969\n",
      "Validation Loss: 0.004385216063505897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0065980639145709575\n",
      "Training Loss: 0.006845258587854914\n",
      "Training Loss: 0.006610262322355993\n",
      "Validation Loss: 0.004358494351487188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006569824020843953\n",
      "Training Loss: 0.0068163827515672895\n",
      "Training Loss: 0.0065813591243932025\n",
      "Validation Loss: 0.004331261136705119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006541344827273861\n",
      "Training Loss: 0.006787415117141791\n",
      "Training Loss: 0.0065524026995990425\n",
      "Validation Loss: 0.004303595191129389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006512677984428592\n",
      "Training Loss: 0.006758418048266321\n",
      "Training Loss: 0.006523466897197068\n",
      "Validation Loss: 0.004275566705350837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006483871801756322\n",
      "Training Loss: 0.0067294491088250655\n",
      "Training Loss: 0.006494619851582684\n",
      "Validation Loss: 0.004247249542929107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0064549719478236515\n",
      "Training Loss: 0.006700562319601886\n",
      "Training Loss: 0.00646592436125502\n",
      "Validation Loss: 0.0042187199133887805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0064260223688324914\n",
      "Training Loss: 0.006671811721753329\n",
      "Training Loss: 0.006437440934823826\n",
      "Validation Loss: 0.004190050915741686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006397069741506129\n",
      "Training Loss: 0.006643252412904985\n",
      "Training Loss: 0.0064092286064988\n",
      "Validation Loss: 0.004161329393855851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006368163137231022\n",
      "Training Loss: 0.006614940417930484\n",
      "Training Loss: 0.006381345696281642\n",
      "Validation Loss: 0.0041326376939129624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006339359492412769\n",
      "Training Loss: 0.006586935808300041\n",
      "Training Loss: 0.006353854564367794\n",
      "Validation Loss: 0.004104081764320183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006310722464113496\n",
      "Training Loss: 0.006559301391243935\n",
      "Training Loss: 0.006326816679211334\n",
      "Validation Loss: 0.00407576621143838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0062823214486707\n",
      "Training Loss: 0.006532101480406709\n",
      "Training Loss: 0.006300294767715969\n",
      "Validation Loss: 0.00404780724980565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006254233963554725\n",
      "Training Loss: 0.006505401664180681\n",
      "Training Loss: 0.006274351581814699\n",
      "Validation Loss: 0.004020335402580376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006226540571078658\n",
      "Training Loss: 0.0064792657195357605\n",
      "Training Loss: 0.006249048481113278\n",
      "Validation Loss: 0.0039934680687284535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0061993238475406545\n",
      "Training Loss: 0.006453752107627224\n",
      "Training Loss: 0.006224440163932741\n",
      "Validation Loss: 0.003967328433972898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006172663513571024\n",
      "Training Loss: 0.006428909292444587\n",
      "Training Loss: 0.006200574242975563\n",
      "Validation Loss: 0.003942020947710098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006146630501025357\n",
      "Training Loss: 0.006404774780094158\n",
      "Training Loss: 0.00617748471966479\n",
      "Validation Loss: 0.003917629513994194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006121284363325685\n",
      "Training Loss: 0.006381373956683092\n",
      "Training Loss: 0.006155192104633897\n",
      "Validation Loss: 0.0038942134634361424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006096668788813986\n",
      "Training Loss: 0.006358713177614845\n",
      "Training Loss: 0.006133699243073352\n",
      "Validation Loss: 0.003871799334805208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00607281181437429\n",
      "Training Loss: 0.006336782912840135\n",
      "Training Loss: 0.0061129910580348225\n",
      "Validation Loss: 0.0038503851209181162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006049720285809599\n",
      "Training Loss: 0.006315559791692067\n",
      "Training Loss: 0.006093036233214662\n",
      "Validation Loss: 0.0038299456100094687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006027383578475565\n",
      "Training Loss: 0.006295005247811787\n",
      "Training Loss: 0.006073791126254946\n",
      "Validation Loss: 0.00381042966305205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006005777835380286\n",
      "Training Loss: 0.006275071606505662\n",
      "Training Loss: 0.006055200889823027\n",
      "Validation Loss: 0.003791772466142442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0059848660067655145\n",
      "Training Loss: 0.00625570155098103\n",
      "Training Loss: 0.006037205149768851\n",
      "Validation Loss: 0.003773901943808024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005964604216860608\n",
      "Training Loss: 0.006236837580800057\n",
      "Training Loss: 0.006019739290350117\n",
      "Validation Loss: 0.0037567387230359435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005944940397748724\n",
      "Training Loss: 0.006218418162607122\n",
      "Training Loss: 0.006002739925170317\n",
      "Validation Loss: 0.0037402043359751782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00592582325451076\n",
      "Training Loss: 0.006200384157709777\n",
      "Training Loss: 0.005986145962961018\n",
      "Validation Loss: 0.0037242249112178602\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00590720018139109\n",
      "Training Loss: 0.006182680792117026\n",
      "Training Loss: 0.005969901056378148\n",
      "Validation Loss: 0.0037087331188507796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005889022927731275\n",
      "Training Loss: 0.0061652572150342165\n",
      "Training Loss: 0.005953955214354209\n",
      "Validation Loss: 0.00369366142163681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00587124410783872\n",
      "Training Loss: 0.006148070546332747\n",
      "Training Loss: 0.005938262608251535\n",
      "Validation Loss: 0.003678961397996277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0058538242836948485\n",
      "Training Loss: 0.006131083352374844\n",
      "Training Loss: 0.005922789133619517\n",
      "Validation Loss: 0.0036645840691256052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.0058367280458332975\n",
      "Training Loss: 0.006114263849158305\n",
      "Training Loss: 0.005907503447961062\n",
      "Validation Loss: 0.00365049621022275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.005819926014519297\n",
      "Training Loss: 0.006097590822027996\n",
      "Training Loss: 0.005892384283943102\n",
      "Validation Loss: 0.0036366669574930343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0058033935219282285\n",
      "Training Loss: 0.00608104497048771\n",
      "Training Loss: 0.00587741210416425\n",
      "Validation Loss: 0.0036230700867501704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.0057871117669856175\n",
      "Training Loss: 0.006064616060466505\n",
      "Training Loss: 0.0058625776710687205\n",
      "Validation Loss: 0.003609690111486262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005771067659370601\n",
      "Training Loss: 0.006048296937078704\n",
      "Training Loss: 0.005847872581798583\n",
      "Validation Loss: 0.003596513640669206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005755251602968201\n",
      "Training Loss: 0.00603208602668019\n",
      "Training Loss: 0.00583329442772083\n",
      "Validation Loss: 0.0035835341530789234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005739657357917167\n",
      "Training Loss: 0.006015985510020983\n",
      "Training Loss: 0.0058188444405095656\n",
      "Validation Loss: 0.0035707434944107375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.005724283125018701\n",
      "Training Loss: 0.0060000007244525476\n",
      "Training Loss: 0.005804526269203052\n",
      "Validation Loss: 0.003558144408272935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005709128966554999\n",
      "Training Loss: 0.005984140693326481\n",
      "Training Loss: 0.00579034773807507\n",
      "Validation Loss: 0.0035457349103728956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.005694196803960949\n",
      "Training Loss: 0.0059684132252004925\n",
      "Training Loss: 0.005776314457762055\n",
      "Validation Loss: 0.0035335171053426737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005679489755420946\n",
      "Training Loss: 0.005952831552713178\n",
      "Training Loss: 0.0057624381844652815\n",
      "Validation Loss: 0.0035214960055812944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005665012177196331\n",
      "Training Loss: 0.005937405131408014\n",
      "Training Loss: 0.005748726277379319\n",
      "Validation Loss: 0.0035096753638478393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0056507676321780305\n",
      "Training Loss: 0.005922147907258477\n",
      "Training Loss: 0.005735189318074845\n",
      "Validation Loss: 0.00349806125532166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005636762852664106\n",
      "Training Loss: 0.005907069557870273\n",
      "Training Loss: 0.005721836384618655\n",
      "Validation Loss: 0.0034866604549820754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005623003717628308\n",
      "Training Loss: 0.005892182156676426\n",
      "Training Loss: 0.005708674216875807\n",
      "Validation Loss: 0.003475478965412365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0056094991671852765\n",
      "Training Loss: 0.0058774923472083174\n",
      "Training Loss: 0.005695710361469537\n",
      "Validation Loss: 0.003464517770256596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.0055962547386297955\n",
      "Training Loss: 0.005863009417371359\n",
      "Training Loss: 0.00568295075034257\n",
      "Validation Loss: 0.003453789415554761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.005583278713165782\n",
      "Training Loss: 0.005848741546215024\n",
      "Training Loss: 0.005670399346272461\n",
      "Validation Loss: 0.0034432864121391616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005570575534366071\n",
      "Training Loss: 0.005834692572243512\n",
      "Training Loss: 0.005658057239488698\n",
      "Validation Loss: 0.0034330145376106577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00555814586870838\n",
      "Training Loss: 0.005820869187300559\n",
      "Training Loss: 0.005645930363680236\n",
      "Validation Loss: 0.0034229719561388655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005545990916434675\n",
      "Training Loss: 0.005807275555562228\n",
      "Training Loss: 0.005634017055854201\n",
      "Validation Loss: 0.003413153438844582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005534108553547412\n",
      "Training Loss: 0.005793915087706409\n",
      "Training Loss: 0.005622316850931384\n",
      "Validation Loss: 0.003403553180004146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.0055224947270471605\n",
      "Training Loss: 0.005780788488918915\n",
      "Training Loss: 0.005610828127828427\n",
      "Validation Loss: 0.0033941678957898546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005511147121433168\n",
      "Training Loss: 0.0057678990488057025\n",
      "Training Loss: 0.005599549941834993\n",
      "Validation Loss: 0.0033849893213678778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005500057260505855\n",
      "Training Loss: 0.005755244560714345\n",
      "Training Loss: 0.005588476468110457\n",
      "Validation Loss: 0.003376013990439307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005489221076131799\n",
      "Training Loss: 0.005742824457702227\n",
      "Training Loss: 0.005577603958663531\n",
      "Validation Loss: 0.0033672297977727283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005478630918078125\n",
      "Training Loss: 0.005730636850348674\n",
      "Training Loss: 0.005566926394822076\n",
      "Validation Loss: 0.0033586256067383658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005468279045308009\n",
      "Training Loss: 0.0057186791411368175\n",
      "Training Loss: 0.005556436472106725\n",
      "Validation Loss: 0.003350196408861306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005458157616085373\n",
      "Training Loss: 0.005706947750586551\n",
      "Training Loss: 0.005546129062422551\n",
      "Validation Loss: 0.003341936245377521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005448260172852315\n",
      "Training Loss: 0.005695437576214317\n",
      "Training Loss: 0.005535997539409436\n",
      "Validation Loss: 0.0033338297527346216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0054385767615167425\n",
      "Training Loss: 0.005684144053375349\n",
      "Training Loss: 0.005526036796509288\n",
      "Validation Loss: 0.003325873800145274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005429099078755825\n",
      "Training Loss: 0.0056730629291269\n",
      "Training Loss: 0.005516239026328549\n",
      "Validation Loss: 0.0033180580129114428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0054198198538506406\n",
      "Training Loss: 0.005662186631816439\n",
      "Training Loss: 0.005506600312655791\n",
      "Validation Loss: 0.0033103745042220847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005410731839947403\n",
      "Training Loss: 0.005651513605262153\n",
      "Training Loss: 0.0054971141938585785\n",
      "Validation Loss: 0.0033028156998870747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005401826794259251\n",
      "Training Loss: 0.005641035827866289\n",
      "Training Loss: 0.005487774962093681\n",
      "Validation Loss: 0.003295373527354069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005393093861057423\n",
      "Training Loss: 0.005630747697723564\n",
      "Training Loss: 0.0054785792710026725\n",
      "Validation Loss: 0.0032880426014334045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0053845293930498885\n",
      "Training Loss: 0.005620645960734691\n",
      "Training Loss: 0.005469522474450059\n",
      "Validation Loss: 0.0032808199051369944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005376124373287894\n",
      "Training Loss: 0.005610723794379737\n",
      "Training Loss: 0.005460600782535039\n",
      "Validation Loss: 0.0032736979061319085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0053678722417680545\n",
      "Training Loss: 0.005600975713750813\n",
      "Training Loss: 0.005451811092789285\n",
      "Validation Loss: 0.003266676447453668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005359766457695514\n",
      "Training Loss: 0.005591397911193781\n",
      "Training Loss: 0.00544315000413917\n",
      "Validation Loss: 0.00325974245069109\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005351800576900132\n",
      "Training Loss: 0.0055819873261498286\n",
      "Training Loss: 0.005434613392571919\n",
      "Validation Loss: 0.0032529001290323946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.005343969911336899\n",
      "Training Loss: 0.005572737999609671\n",
      "Training Loss: 0.005426200435613282\n",
      "Validation Loss: 0.003246142875581059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.005336266255471856\n",
      "Training Loss: 0.005563646939699538\n",
      "Training Loss: 0.005417905580252409\n",
      "Validation Loss: 0.0032394704405019543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.005328687466681003\n",
      "Training Loss: 0.005554708665877115\n",
      "Training Loss: 0.005409729041857645\n",
      "Validation Loss: 0.0032328859107631646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005321226079249754\n",
      "Training Loss: 0.0055459203809732575\n",
      "Training Loss: 0.0054016662522917615\n",
      "Validation Loss: 0.00322637814711884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005313878878368996\n",
      "Training Loss: 0.005537279139971361\n",
      "Training Loss: 0.00539371509803459\n",
      "Validation Loss: 0.0032199500723783807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005306641240022145\n",
      "Training Loss: 0.0055287808796856555\n",
      "Training Loss: 0.0053858709934866055\n",
      "Validation Loss: 0.003213600909567616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005299508419120684\n",
      "Training Loss: 0.005520422068075277\n",
      "Training Loss: 0.0053781336912652475\n",
      "Validation Loss: 0.0032073282335853474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.0052924784907372666\n",
      "Training Loss: 0.0055121994268847625\n",
      "Training Loss: 0.005370498812990263\n",
      "Validation Loss: 0.003201134574829779\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.00528554548509419\n",
      "Training Loss: 0.005504110983456485\n",
      "Training Loss: 0.0053629638184793296\n",
      "Validation Loss: 0.0031950108705643106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.005278708099504001\n",
      "Training Loss: 0.005496153522399254\n",
      "Training Loss: 0.005355526165221818\n",
      "Validation Loss: 0.003188963733571634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005271962299593725\n",
      "Training Loss: 0.005488323624595068\n",
      "Training Loss: 0.00534818108077161\n",
      "Validation Loss: 0.0031829894071685547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005265305084176362\n",
      "Training Loss: 0.0054806179611478\n",
      "Training Loss: 0.0053409280441701415\n",
      "Validation Loss: 0.003177085454481539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005258734780363738\n",
      "Training Loss: 0.005473034032038413\n",
      "Training Loss: 0.005333762665395625\n",
      "Validation Loss: 0.003171254419643181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.00525224877812434\n",
      "Training Loss: 0.005465571881504729\n",
      "Training Loss: 0.005326681573060341\n",
      "Validation Loss: 0.0031654902091616073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0052458433987339955\n",
      "Training Loss: 0.005458225546462927\n",
      "Training Loss: 0.005319683965062723\n",
      "Validation Loss: 0.003159791475758375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005239517449517735\n",
      "Training Loss: 0.005450993143313099\n",
      "Training Loss: 0.005312765393173322\n",
      "Validation Loss: 0.003154162294623766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005233269064337947\n",
      "Training Loss: 0.005443874529155437\n",
      "Training Loss: 0.005305924716521986\n",
      "Validation Loss: 0.003148598130138361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005227096007438377\n",
      "Training Loss: 0.005436866078234744\n",
      "Training Loss: 0.005299157633562573\n",
      "Validation Loss: 0.0031430946383102054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005220996569260023\n",
      "Training Loss: 0.005429965737857856\n",
      "Training Loss: 0.005292464512167499\n",
      "Validation Loss: 0.003137653636003143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005214968594373204\n",
      "Training Loss: 0.005423169547575526\n",
      "Training Loss: 0.005285839335992932\n",
      "Validation Loss: 0.0031322736542912597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005209011195693165\n",
      "Training Loss: 0.0054164754733210425\n",
      "Training Loss: 0.005279281855328008\n",
      "Validation Loss: 0.003126947379937877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005203120720107108\n",
      "Training Loss: 0.005409884034015704\n",
      "Training Loss: 0.0052727901202160865\n",
      "Validation Loss: 0.003121679962685939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005197298441198654\n",
      "Training Loss: 0.005403391108266078\n",
      "Training Loss: 0.005266360496170819\n",
      "Validation Loss: 0.00311646781262701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005191541302483529\n",
      "Training Loss: 0.005396996937924996\n",
      "Training Loss: 0.005259994397056289\n",
      "Validation Loss: 0.003111306407876062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0051858483866089955\n",
      "Training Loss: 0.005390696774120443\n",
      "Training Loss: 0.0052536882320418955\n",
      "Validation Loss: 0.003106194736666224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005180218198220245\n",
      "Training Loss: 0.005384488614799921\n",
      "Training Loss: 0.0052474416815675795\n",
      "Validation Loss: 0.003101135311737196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.00517464961623773\n",
      "Training Loss: 0.005378373113344424\n",
      "Training Loss: 0.005241250397521071\n",
      "Validation Loss: 0.003096120657655672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005169141807127744\n",
      "Training Loss: 0.005372345289506484\n",
      "Training Loss: 0.005235114853130654\n",
      "Validation Loss: 0.003091155357130416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005163691642810591\n",
      "Training Loss: 0.005366405690438114\n",
      "Training Loss: 0.005229033486684785\n",
      "Validation Loss: 0.003086231888292797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005158302561030723\n",
      "Training Loss: 0.00536055183125427\n",
      "Training Loss: 0.005223006617161446\n",
      "Validation Loss: 0.0030813523871677643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.00515296975907404\n",
      "Training Loss: 0.0053547821909887714\n",
      "Training Loss: 0.005217030846397392\n",
      "Validation Loss: 0.0030765147955585897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005147693676990457\n",
      "Training Loss: 0.0053490944753866645\n",
      "Training Loss: 0.0052111072471598165\n",
      "Validation Loss: 0.0030717151461880695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005142474455642514\n",
      "Training Loss: 0.005343487277568784\n",
      "Training Loss: 0.005205235061002895\n",
      "Validation Loss: 0.0030669630609787583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005137310737627559\n",
      "Training Loss: 0.005337957550073043\n",
      "Training Loss: 0.00519941168720834\n",
      "Validation Loss: 0.003062244483761573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005132201940868981\n",
      "Training Loss: 0.005332507441053167\n",
      "Training Loss: 0.005193637104821391\n",
      "Validation Loss: 0.0030575658468100547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005127146042650565\n",
      "Training Loss: 0.005327131497615482\n",
      "Training Loss: 0.00518791195412632\n",
      "Validation Loss: 0.0030529254980730626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005122145082568749\n",
      "Training Loss: 0.005321829883032478\n",
      "Training Loss: 0.005182233916711993\n",
      "Validation Loss: 0.003048317374143582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005117197060026228\n",
      "Training Loss: 0.005316601412196178\n",
      "Training Loss: 0.005176604252774268\n",
      "Validation Loss: 0.0030437487254724995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0051123024011030796\n",
      "Training Loss: 0.005311445039696991\n",
      "Training Loss: 0.0051710224384441976\n",
      "Validation Loss: 0.0030392126161919047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005107460038270801\n",
      "Training Loss: 0.005306358557427302\n",
      "Training Loss: 0.005165487233316526\n",
      "Validation Loss: 0.003034713850722889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.00510266991041135\n",
      "Training Loss: 0.005301341514277738\n",
      "Training Loss: 0.005159999513416551\n",
      "Validation Loss: 0.0030302474722580124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005097932461067103\n",
      "Training Loss: 0.005296392184391152\n",
      "Training Loss: 0.0051545586268184704\n",
      "Validation Loss: 0.003025817506936159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0050932471733540294\n",
      "Training Loss: 0.0052915100401151\n",
      "Training Loss: 0.005149166068877093\n",
      "Validation Loss: 0.003021424599619729\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005088613996631466\n",
      "Training Loss: 0.005286693282541819\n",
      "Training Loss: 0.005143818760407157\n",
      "Validation Loss: 0.003017062317381163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005084031575825066\n",
      "Training Loss: 0.005281941715220455\n",
      "Training Loss: 0.005138521608314477\n",
      "Validation Loss: 0.0030127328269842885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005079501110012643\n",
      "Training Loss: 0.00527725329680834\n",
      "Training Loss: 0.005133267977507785\n",
      "Validation Loss: 0.0030084362232618116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005075023312820122\n",
      "Training Loss: 0.005272628235397861\n",
      "Training Loss: 0.005128063539741561\n",
      "Validation Loss: 0.003004178699770461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005070596551522612\n",
      "Training Loss: 0.005268064656411298\n",
      "Training Loss: 0.005122907577315345\n",
      "Validation Loss: 0.002999951011302431\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005066220729495399\n",
      "Training Loss: 0.005263562218751758\n",
      "Training Loss: 0.005117799593135714\n",
      "Validation Loss: 0.00299575528995856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005061896361876279\n",
      "Training Loss: 0.005259120143018663\n",
      "Training Loss: 0.005112739264732226\n",
      "Validation Loss: 0.0029915977796550128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005057623776956462\n",
      "Training Loss: 0.00525473544781562\n",
      "Training Loss: 0.00510772658395581\n",
      "Validation Loss: 0.002987473261976887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005053401697077789\n",
      "Training Loss: 0.005250411226879806\n",
      "Training Loss: 0.005102765042684041\n",
      "Validation Loss: 0.0029833775093475504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005049230646691285\n",
      "Training Loss: 0.005246143774129451\n",
      "Training Loss: 0.005097851247992367\n",
      "Validation Loss: 0.0029793225517862716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.0050451119139324875\n",
      "Training Loss: 0.005241933501092717\n",
      "Training Loss: 0.005092987913521938\n",
      "Validation Loss: 0.002975298873975538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005041043437086046\n",
      "Training Loss: 0.005237779472954571\n",
      "Training Loss: 0.005088173379772343\n",
      "Validation Loss: 0.0029713109624833704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005037026473437436\n",
      "Training Loss: 0.005233681251411326\n",
      "Training Loss: 0.005083410370862112\n",
      "Validation Loss: 0.002967355942243731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0050330601050518455\n",
      "Training Loss: 0.00522963744122535\n",
      "Training Loss: 0.005078696280252188\n",
      "Validation Loss: 0.0029634346647889175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005029142917483114\n",
      "Training Loss: 0.005225649189087562\n",
      "Training Loss: 0.005074034448480234\n",
      "Validation Loss: 0.002959551796542083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005025278002722189\n",
      "Training Loss: 0.005221711305784993\n",
      "Training Loss: 0.005069421945954673\n",
      "Validation Loss: 0.0029557002047757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005021462524891831\n",
      "Training Loss: 0.005217827666783705\n",
      "Training Loss: 0.005064860637066886\n",
      "Validation Loss: 0.0029518856670906284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005017695924616419\n",
      "Training Loss: 0.005213995518279262\n",
      "Training Loss: 0.005060351293068379\n",
      "Validation Loss: 0.002948104156693967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005013978916686028\n",
      "Training Loss: 0.0052102151582948866\n",
      "Training Loss: 0.0050558938831090925\n",
      "Validation Loss: 0.0029443583694506396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005010311552905477\n",
      "Training Loss: 0.005206485684029758\n",
      "Training Loss: 0.005051485550939106\n",
      "Validation Loss: 0.00294065021967327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005006691952585243\n",
      "Training Loss: 0.005202805670560338\n",
      "Training Loss: 0.005047130970051512\n",
      "Validation Loss: 0.002936976348976029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005003120799665339\n",
      "Training Loss: 0.005199175419402308\n",
      "Training Loss: 0.005042826868011616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:11<20:56, 157.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.002933335821458212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5163809409737588\n",
      "Training Loss: 0.42990536347031594\n",
      "Training Loss: 0.3308638503402472\n",
      "Validation Loss: 0.23604922976051823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.19360246308147908\n",
      "Training Loss: 0.13036352813243865\n",
      "Training Loss: 0.09430380892008543\n",
      "Validation Loss: 0.080144725007455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.07492852268740535\n",
      "Training Loss: 0.0698890676163137\n",
      "Training Loss: 0.06920345993712544\n",
      "Validation Loss: 0.07028171187789922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06821287745609879\n",
      "Training Loss: 0.06624002801254392\n",
      "Training Loss: 0.06630691513419151\n",
      "Validation Loss: 0.06716273662247015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.06501445712521672\n",
      "Training Loss: 0.0629615968838334\n",
      "Training Loss: 0.06261761635541915\n",
      "Validation Loss: 0.06308252573683021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.06077553403563798\n",
      "Training Loss: 0.05859927823767066\n",
      "Training Loss: 0.05767430994659662\n",
      "Validation Loss: 0.057628559995065914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.055127682248130444\n",
      "Training Loss: 0.05287181904539466\n",
      "Training Loss: 0.05124871185049415\n",
      "Validation Loss: 0.05065566393431653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.04801554998382926\n",
      "Training Loss: 0.045883103432133795\n",
      "Training Loss: 0.04363388719037175\n",
      "Validation Loss: 0.04262688803078418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.040075660115107894\n",
      "Training Loss: 0.038387777274474504\n",
      "Training Loss: 0.03582769051194191\n",
      "Validation Loss: 0.03456169529033176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.032407252434641126\n",
      "Training Loss: 0.03126538115553558\n",
      "Training Loss: 0.028661106489598753\n",
      "Validation Loss: 0.027066075844752988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.02552278244867921\n",
      "Training Loss: 0.024772214260883628\n",
      "Training Loss: 0.022397654484957456\n",
      "Validation Loss: 0.020580335080707342\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.01984414691105485\n",
      "Training Loss: 0.019599917931482195\n",
      "Training Loss: 0.018078389228321612\n",
      "Validation Loss: 0.016608703601582165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.016639041216112673\n",
      "Training Loss: 0.016881296331994235\n",
      "Training Loss: 0.016089384437073022\n",
      "Validation Loss: 0.01476549535592118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.015110354300122707\n",
      "Training Loss: 0.015400529806502163\n",
      "Training Loss: 0.014894901094958186\n",
      "Validation Loss: 0.013521120083005576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.014019632302224637\n",
      "Training Loss: 0.014261491992510856\n",
      "Training Loss: 0.01392073878319934\n",
      "Validation Loss: 0.012491829604370876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0131058658240363\n",
      "Training Loss: 0.013302581871394069\n",
      "Training Loss: 0.013082392083015293\n",
      "Validation Loss: 0.011619285786304666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.012329083187505602\n",
      "Training Loss: 0.012490983007010072\n",
      "Training Loss: 0.01235976358409971\n",
      "Validation Loss: 0.010878841038217789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.01167023119982332\n",
      "Training Loss: 0.01180336605058983\n",
      "Training Loss: 0.01173524075653404\n",
      "Validation Loss: 0.010244912292619937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.011108128684572876\n",
      "Training Loss: 0.011216202466748655\n",
      "Training Loss: 0.011191802204120905\n",
      "Validation Loss: 0.009695000820950176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.010623525565024465\n",
      "Training Loss: 0.010710031378548592\n",
      "Training Loss: 0.010715489846188576\n",
      "Validation Loss: 0.009211942922386729\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.01020110361278057\n",
      "Training Loss: 0.010269676719326526\n",
      "Training Loss: 0.010294716276694088\n",
      "Validation Loss: 0.008782272221876329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00982847881037742\n",
      "Training Loss: 0.00988270326051861\n",
      "Training Loss: 0.00991935650119558\n",
      "Validation Loss: 0.00839486929033412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009495433557312936\n",
      "Training Loss: 0.009538716722745448\n",
      "Training Loss: 0.009580719103105366\n",
      "Validation Loss: 0.008040620041540249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.009193794031161814\n",
      "Training Loss: 0.009229358598822728\n",
      "Training Loss: 0.009271837293636054\n",
      "Validation Loss: 0.0077125150658022825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008917476532515138\n",
      "Training Loss: 0.008948341634823009\n",
      "Training Loss: 0.008987580819521099\n",
      "Validation Loss: 0.007405565748137705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008662297301925718\n",
      "Training Loss: 0.008691237890161574\n",
      "Training Loss: 0.008724474852206185\n",
      "Validation Loss: 0.007116543038831919\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00842564417165704\n",
      "Training Loss: 0.00845513522392139\n",
      "Training Loss: 0.008480354035273195\n",
      "Validation Loss: 0.00684357098083985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008206032908055931\n",
      "Training Loss: 0.00823820983292535\n",
      "Training Loss: 0.008253973054233938\n",
      "Validation Loss: 0.006585751814516575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008002717953640968\n",
      "Training Loss: 0.008039348860038445\n",
      "Training Loss: 0.008044666191563011\n",
      "Validation Loss: 0.006342813759791047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00781536121852696\n",
      "Training Loss: 0.007857830345164985\n",
      "Training Loss: 0.0078520478005521\n",
      "Validation Loss: 0.006114831168120832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0076437688420992345\n",
      "Training Loss: 0.007693090647226199\n",
      "Training Loss: 0.007675819034921006\n",
      "Validation Loss: 0.005902023639352051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0074877231533173475\n",
      "Training Loss: 0.007544558927183971\n",
      "Training Loss: 0.007515606021042913\n",
      "Validation Loss: 0.00570458221168184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007346856041112915\n",
      "Training Loss: 0.007411542262416333\n",
      "Training Loss: 0.007370882076211274\n",
      "Validation Loss: 0.005522591872219248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00722060348954983\n",
      "Training Loss: 0.007293184937443584\n",
      "Training Loss: 0.007240926811937243\n",
      "Validation Loss: 0.005355947818397806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007108184220269323\n",
      "Training Loss: 0.007188461205223575\n",
      "Training Loss: 0.007124827241059392\n",
      "Validation Loss: 0.005204308941552227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007008615782251581\n",
      "Training Loss: 0.007096188979921862\n",
      "Training Loss: 0.007021502371644601\n",
      "Validation Loss: 0.005067115895491973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.006920761191286147\n",
      "Training Loss: 0.007015091219218447\n",
      "Training Loss: 0.006929760178318247\n",
      "Validation Loss: 0.004943598127201869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.006843393804738298\n",
      "Training Loss: 0.006943852144759149\n",
      "Training Loss: 0.006848359857685864\n",
      "Validation Loss: 0.004832820826879797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.006775264384923502\n",
      "Training Loss: 0.006881188083207234\n",
      "Training Loss: 0.006776075292145833\n",
      "Validation Loss: 0.004733758450098587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.006715163547778502\n",
      "Training Loss: 0.006825896566733718\n",
      "Training Loss: 0.006711744215572253\n",
      "Validation Loss: 0.0046453270400623175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.006661973473383114\n",
      "Training Loss: 0.00677689554169774\n",
      "Training Loss: 0.006654311449965462\n",
      "Validation Loss: 0.004566447180172617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006614692219300195\n",
      "Training Loss: 0.006733242183690891\n",
      "Training Loss: 0.006602841293206438\n",
      "Validation Loss: 0.004496082940839984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006572449108352885\n",
      "Training Loss: 0.006694132790435106\n",
      "Training Loss: 0.006556523408507928\n",
      "Validation Loss: 0.004433264625598833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006534504343289882\n",
      "Training Loss: 0.006658893935382366\n",
      "Training Loss: 0.006514666508883238\n",
      "Validation Loss: 0.004377109115666009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006500232818070799\n",
      "Training Loss: 0.006626967885531485\n",
      "Training Loss: 0.006476684741210192\n",
      "Validation Loss: 0.004326814072719367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006469114735955373\n",
      "Training Loss: 0.006597890071570873\n",
      "Training Loss: 0.006442080822307616\n",
      "Validation Loss: 0.004281670102336852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00644071632064879\n",
      "Training Loss: 0.006571276992326602\n",
      "Training Loss: 0.006410433615092188\n",
      "Validation Loss: 0.004241040666467312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006414671721868217\n",
      "Training Loss: 0.006546806554542855\n",
      "Training Loss: 0.006381382280960679\n",
      "Validation Loss: 0.004204374573878902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006390677080489695\n",
      "Training Loss: 0.006524210354546085\n",
      "Training Loss: 0.006354618992190808\n",
      "Validation Loss: 0.004171178401500154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006368473733891733\n",
      "Training Loss: 0.006503259339369833\n",
      "Training Loss: 0.0063298753963317725\n",
      "Validation Loss: 0.004141031083614262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006347841817187145\n",
      "Training Loss: 0.006483759810216725\n",
      "Training Loss: 0.006306923656375148\n",
      "Validation Loss: 0.004113558327303048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006328595826635137\n",
      "Training Loss: 0.006465546317631379\n",
      "Training Loss: 0.00628556126379408\n",
      "Validation Loss: 0.004088436545061178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006310573827940971\n",
      "Training Loss: 0.006448472911724821\n",
      "Training Loss: 0.006265611373819411\n",
      "Validation Loss: 0.004065376252859433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006293639183277264\n",
      "Training Loss: 0.006432418200420216\n",
      "Training Loss: 0.006246921568526886\n",
      "Validation Loss: 0.004044135790475215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006277672055875883\n",
      "Training Loss: 0.0064172747556585814\n",
      "Training Loss: 0.006229358217096887\n",
      "Validation Loss: 0.004024500733312073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006262573265703395\n",
      "Training Loss: 0.0064029500115429985\n",
      "Training Loss: 0.006212803425733\n",
      "Validation Loss: 0.0040062834607473875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006248253083322197\n",
      "Training Loss: 0.0063893623754847795\n",
      "Training Loss: 0.0061971540376544\n",
      "Validation Loss: 0.003989318363810628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006234633005224168\n",
      "Training Loss: 0.006376441623433493\n",
      "Training Loss: 0.006182319813524373\n",
      "Validation Loss: 0.003973464343207627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006221647580387071\n",
      "Training Loss: 0.006364123308449052\n",
      "Training Loss: 0.0061682203703094275\n",
      "Validation Loss: 0.003958597668090814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006209237879957073\n",
      "Training Loss: 0.0063523521053139125\n",
      "Training Loss: 0.006154785964172333\n",
      "Validation Loss: 0.003944609615051847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006197351752198301\n",
      "Training Loss: 0.006341079971170984\n",
      "Training Loss: 0.006141955431667156\n",
      "Validation Loss: 0.003931406019137796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006185944338212721\n",
      "Training Loss: 0.0063302592269610615\n",
      "Training Loss: 0.006129674265393987\n",
      "Validation Loss: 0.0039189042094467065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006174971667351201\n",
      "Training Loss: 0.006319852912565693\n",
      "Training Loss: 0.006117892786278389\n",
      "Validation Loss: 0.003907033235418056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006164398429682479\n",
      "Training Loss: 0.006309822528855875\n",
      "Training Loss: 0.006106569248368032\n",
      "Validation Loss: 0.0038957220591798298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006154190096422099\n",
      "Training Loss: 0.006300135653000325\n",
      "Training Loss: 0.006095662825973704\n",
      "Validation Loss: 0.003884918225819266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00614431580179371\n",
      "Training Loss: 0.006290762820281088\n",
      "Training Loss: 0.006085140753421001\n",
      "Validation Loss: 0.003874575674437049\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006134748143376782\n",
      "Training Loss: 0.006281676226644777\n",
      "Training Loss: 0.006074972111964599\n",
      "Validation Loss: 0.0038646432954368044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0061254611145704985\n",
      "Training Loss: 0.0062728525581769645\n",
      "Training Loss: 0.006065127936308272\n",
      "Validation Loss: 0.0038550856034009814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00611643165582791\n",
      "Training Loss: 0.0062642677302937955\n",
      "Training Loss: 0.006055585385183804\n",
      "Validation Loss: 0.0038458688284029787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006107638756511733\n",
      "Training Loss: 0.006255902707925998\n",
      "Training Loss: 0.00604631973314099\n",
      "Validation Loss: 0.0038369588950894814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0060990642145043236\n",
      "Training Loss: 0.006247739406535402\n",
      "Training Loss: 0.006037312169210054\n",
      "Validation Loss: 0.0038283316381249495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006090690462151542\n",
      "Training Loss: 0.00623976064438466\n",
      "Training Loss: 0.006028544955188409\n",
      "Validation Loss: 0.0038199593375824142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006082501118071377\n",
      "Training Loss: 0.006231952381785959\n",
      "Training Loss: 0.0060199999809265135\n",
      "Validation Loss: 0.003811822067148293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0060744812467601154\n",
      "Training Loss: 0.006224300240864978\n",
      "Training Loss: 0.0060116657649632544\n",
      "Validation Loss: 0.0038039027520303686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006066620858036913\n",
      "Training Loss: 0.006216793441562913\n",
      "Training Loss: 0.006003525863052346\n",
      "Validation Loss: 0.003796182674214537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006058906592079439\n",
      "Training Loss: 0.006209422203246504\n",
      "Training Loss: 0.00599556807661429\n",
      "Validation Loss: 0.003788643612413866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0060513300623279065\n",
      "Training Loss: 0.006202174783102237\n",
      "Training Loss: 0.005987783493474126\n",
      "Validation Loss: 0.0037812737128671177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006043878886848688\n",
      "Training Loss: 0.006195045490167104\n",
      "Training Loss: 0.0059801607124973085\n",
      "Validation Loss: 0.0037740572568897702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006036547169787809\n",
      "Training Loss: 0.0061880238342564555\n",
      "Training Loss: 0.005972692224313505\n",
      "Validation Loss: 0.003766992197403412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006029327840660698\n",
      "Training Loss: 0.006181104629067704\n",
      "Training Loss: 0.0059653689194237814\n",
      "Validation Loss: 0.003760057629682542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0060222117730882015\n",
      "Training Loss: 0.006174280816921964\n",
      "Training Loss: 0.005958183028851636\n",
      "Validation Loss: 0.0037532537708613563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006015196083462797\n",
      "Training Loss: 0.00616754773305729\n",
      "Training Loss: 0.005951127370935865\n",
      "Validation Loss: 0.003746566673337869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006008273035404272\n",
      "Training Loss: 0.006160900212125853\n",
      "Training Loss: 0.005944197463104501\n",
      "Validation Loss: 0.003739993300503434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006001438330858946\n",
      "Training Loss: 0.006154334346647374\n",
      "Training Loss: 0.005937385621364228\n",
      "Validation Loss: 0.003733520452299396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.005994687550119124\n",
      "Training Loss: 0.006147845148807392\n",
      "Training Loss: 0.005930686977808364\n",
      "Validation Loss: 0.003727150282736219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005988017871277407\n",
      "Training Loss: 0.006141430870629847\n",
      "Training Loss: 0.0059240983019117266\n",
      "Validation Loss: 0.003720872731371835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.005981424422352575\n",
      "Training Loss: 0.006135087564471178\n",
      "Training Loss: 0.0059176140779163685\n",
      "Validation Loss: 0.003714686981336936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00597490502463188\n",
      "Training Loss: 0.006128811694215983\n",
      "Training Loss: 0.005911230301717296\n",
      "Validation Loss: 0.0037085832478583195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005968457006965764\n",
      "Training Loss: 0.0061226018326124175\n",
      "Training Loss: 0.005904943888890557\n",
      "Validation Loss: 0.0037025626385165902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005962077580625192\n",
      "Training Loss: 0.006116457009338774\n",
      "Training Loss: 0.005898750686901622\n",
      "Validation Loss: 0.0036966205601386853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005955765143735334\n",
      "Training Loss: 0.006110373280243948\n",
      "Training Loss: 0.005892648343578912\n",
      "Validation Loss: 0.0036907564221457527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005949517312692478\n",
      "Training Loss: 0.00610434936650563\n",
      "Training Loss: 0.005886634588241577\n",
      "Validation Loss: 0.003684964904749996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.005943333053728565\n",
      "Training Loss: 0.006098384015494958\n",
      "Training Loss: 0.005880706070456654\n",
      "Validation Loss: 0.003679246793427829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.005937210855772718\n",
      "Training Loss: 0.006092476270860061\n",
      "Training Loss: 0.005874860004987568\n",
      "Validation Loss: 0.0036735971882714356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.005931149242678657\n",
      "Training Loss: 0.00608662600396201\n",
      "Training Loss: 0.005869095716625452\n",
      "Validation Loss: 0.0036680110369866526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.005925146587542258\n",
      "Training Loss: 0.006080830270075239\n",
      "Training Loss: 0.005863410584279336\n",
      "Validation Loss: 0.003662495682568007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0059192038862966\n",
      "Training Loss: 0.0060750895581441\n",
      "Training Loss: 0.005857801425736398\n",
      "Validation Loss: 0.003657044246047212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005913318864768371\n",
      "Training Loss: 0.0060694020433584225\n",
      "Training Loss: 0.005852267143782228\n",
      "Validation Loss: 0.003651652983494438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0059074914443772285\n",
      "Training Loss: 0.006063767614541575\n",
      "Training Loss: 0.005846806765766814\n",
      "Validation Loss: 0.003646324552187508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005901719731627964\n",
      "Training Loss: 0.006058184977737255\n",
      "Training Loss: 0.005841417629271746\n",
      "Validation Loss: 0.003641059536165087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005896005199756474\n",
      "Training Loss: 0.0060526538395788525\n",
      "Training Loss: 0.005836097865249031\n",
      "Validation Loss: 0.003635850882816934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.005890345547813922\n",
      "Training Loss: 0.00604717408248689\n",
      "Training Loss: 0.005830848123878241\n",
      "Validation Loss: 0.0036306995506073985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.0058847408334258946\n",
      "Training Loss: 0.006041744488175027\n",
      "Training Loss: 0.005825664174044505\n",
      "Validation Loss: 0.0036256073665376126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0058791910333093255\n",
      "Training Loss: 0.0060363639768911525\n",
      "Training Loss: 0.005820545604801736\n",
      "Validation Loss: 0.003620570598123072\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005873695095069706\n",
      "Training Loss: 0.0060310315212700515\n",
      "Training Loss: 0.005815491430112161\n",
      "Validation Loss: 0.0036155906462717506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.00586825292208232\n",
      "Training Loss: 0.006025747144012712\n",
      "Training Loss: 0.005810499680810608\n",
      "Validation Loss: 0.0036106623370420147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.005862864006194286\n",
      "Training Loss: 0.006020510111120529\n",
      "Training Loss: 0.005805568325449713\n",
      "Validation Loss: 0.0036057839078535692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005857527617481537\n",
      "Training Loss: 0.0060153182980138805\n",
      "Training Loss: 0.005800698405364528\n",
      "Validation Loss: 0.003600961004195505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005852242287364789\n",
      "Training Loss: 0.006010172888054512\n",
      "Training Loss: 0.0057958855020115154\n",
      "Validation Loss: 0.003596188100264146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0058470092597417535\n",
      "Training Loss: 0.006005071994732134\n",
      "Training Loss: 0.005791128783603199\n",
      "Validation Loss: 0.0035914616460461964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005841825638199225\n",
      "Training Loss: 0.006000013638404198\n",
      "Training Loss: 0.0057864270324353125\n",
      "Validation Loss: 0.0035867874747341016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.0058366919308900835\n",
      "Training Loss: 0.005994999064132572\n",
      "Training Loss: 0.005781779548851773\n",
      "Validation Loss: 0.003582155798284567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005831607422442176\n",
      "Training Loss: 0.005990024524508044\n",
      "Training Loss: 0.005777181874145753\n",
      "Validation Loss: 0.003577571890704083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.005826570824137889\n",
      "Training Loss: 0.00598508988332469\n",
      "Training Loss: 0.005772635279572569\n",
      "Validation Loss: 0.003573028230778036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005821580410702154\n",
      "Training Loss: 0.005980194169678725\n",
      "Training Loss: 0.00576813590771053\n",
      "Validation Loss: 0.0035685274757842503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.00581663669203408\n",
      "Training Loss: 0.00597533441206906\n",
      "Training Loss: 0.005763682822580449\n",
      "Validation Loss: 0.003564066213053348\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005811737191397697\n",
      "Training Loss: 0.005970510205370374\n",
      "Training Loss: 0.005759273114963434\n",
      "Validation Loss: 0.0035596407009445634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005806880076415837\n",
      "Training Loss: 0.005965719888336025\n",
      "Training Loss: 0.005754905029316432\n",
      "Validation Loss: 0.0035552529139402374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005802065738243982\n",
      "Training Loss: 0.0059609615890076385\n",
      "Training Loss: 0.00575057698006276\n",
      "Validation Loss: 0.0035508966055081297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005797291539493017\n",
      "Training Loss: 0.005956233547185548\n",
      "Training Loss: 0.005746285678469576\n",
      "Validation Loss: 0.003546570001295611\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005792556403903291\n",
      "Training Loss: 0.005951532273902558\n",
      "Training Loss: 0.005742028938839212\n",
      "Validation Loss: 0.0035422716029459254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005787858436233364\n",
      "Training Loss: 0.0059468589292373504\n",
      "Training Loss: 0.0057378070510458205\n",
      "Validation Loss: 0.0035380043777417432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005783197074197233\n",
      "Training Loss: 0.0059422102471580725\n",
      "Training Loss: 0.0057336154085351155\n",
      "Validation Loss: 0.00353375820016614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005778570658294484\n",
      "Training Loss: 0.005937585409265011\n",
      "Training Loss: 0.005729452263913117\n",
      "Validation Loss: 0.0035295309930558454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.005773977747303434\n",
      "Training Loss: 0.005932984947576187\n",
      "Training Loss: 0.005725317265023478\n",
      "Validation Loss: 0.003525332087295109\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005769418471609242\n",
      "Training Loss: 0.005928408477338962\n",
      "Training Loss: 0.005721211646450683\n",
      "Validation Loss: 0.0035211571663607624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.005764892005245202\n",
      "Training Loss: 0.005923860488110222\n",
      "Training Loss: 0.005717134765582159\n",
      "Validation Loss: 0.00351700850558373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005760399785358459\n",
      "Training Loss: 0.005919341667322442\n",
      "Training Loss: 0.005713087723124772\n",
      "Validation Loss: 0.00351288705459911\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005755941125098616\n",
      "Training Loss: 0.005914854586590082\n",
      "Training Loss: 0.005709072463796474\n",
      "Validation Loss: 0.0035088004758895446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005751517717144452\n",
      "Training Loss: 0.005910401009023189\n",
      "Training Loss: 0.0057050891494145614\n",
      "Validation Loss: 0.003504747900918252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005747129011433571\n",
      "Training Loss: 0.005905983609845861\n",
      "Training Loss: 0.0057011394033906985\n",
      "Validation Loss: 0.0035007310222855276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005742775493999943\n",
      "Training Loss: 0.00590160300314892\n",
      "Training Loss: 0.005697223024908453\n",
      "Validation Loss: 0.003496756613008636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.00573845811013598\n",
      "Training Loss: 0.00589726023026742\n",
      "Training Loss: 0.005693339352146723\n",
      "Validation Loss: 0.0034928224644665555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005734175605466589\n",
      "Training Loss: 0.005892954443115741\n",
      "Training Loss: 0.005689489915384911\n",
      "Validation Loss: 0.0034889274197002725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005729927968932316\n",
      "Training Loss: 0.0058886823756620285\n",
      "Training Loss: 0.005685671352548525\n",
      "Validation Loss: 0.0034850773138642896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.005725714425207116\n",
      "Training Loss: 0.005884445065748878\n",
      "Training Loss: 0.005681883927900344\n",
      "Validation Loss: 0.00348126391417169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0057215332146734\n",
      "Training Loss: 0.0058802389877382665\n",
      "Training Loss: 0.005678124826517888\n",
      "Validation Loss: 0.003477486917811833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.005717383582377806\n",
      "Training Loss: 0.005876062408206053\n",
      "Training Loss: 0.005674391172360629\n",
      "Validation Loss: 0.0034737500997804355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005713264286168851\n",
      "Training Loss: 0.005871912966831587\n",
      "Training Loss: 0.005670679982285947\n",
      "Validation Loss: 0.0034700378878931566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.0057091730704996735\n",
      "Training Loss: 0.005867788839968853\n",
      "Training Loss: 0.005666992239421234\n",
      "Validation Loss: 0.003466359725525456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00570510903489776\n",
      "Training Loss: 0.005863686894881539\n",
      "Training Loss: 0.005663323168409989\n",
      "Validation Loss: 0.003462711511980324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005701069845235907\n",
      "Training Loss: 0.005859605363802985\n",
      "Training Loss: 0.0056596717913635075\n",
      "Validation Loss: 0.0034590892701702757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.005697053850744851\n",
      "Training Loss: 0.005855540313059464\n",
      "Training Loss: 0.0056560350820655005\n",
      "Validation Loss: 0.0034554921446389025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005693059240002185\n",
      "Training Loss: 0.005851492423098534\n",
      "Training Loss: 0.00565241084608715\n",
      "Validation Loss: 0.003451918772411313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.005689084937912412\n",
      "Training Loss: 0.005847456789924763\n",
      "Training Loss: 0.0056487986439606175\n",
      "Validation Loss: 0.0034483658958205515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005685129130142741\n",
      "Training Loss: 0.005843434020644054\n",
      "Training Loss: 0.005645194969256409\n",
      "Validation Loss: 0.003444830503764698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005681189960450865\n",
      "Training Loss: 0.005839422856224701\n",
      "Training Loss: 0.00564159954956267\n",
      "Validation Loss: 0.0034413069592569064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005677265993435867\n",
      "Training Loss: 0.005835419743671082\n",
      "Training Loss: 0.00563801018637605\n",
      "Validation Loss: 0.003437801667755951\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005673356173792854\n",
      "Training Loss: 0.005831424213829451\n",
      "Training Loss: 0.005634425609605387\n",
      "Validation Loss: 0.0034343105285648216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005669458204647526\n",
      "Training Loss: 0.005827434423263184\n",
      "Training Loss: 0.005630843550898134\n",
      "Validation Loss: 0.00343082742595501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005665570952114649\n",
      "Training Loss: 0.005823449151939712\n",
      "Training Loss: 0.005627264982322231\n",
      "Validation Loss: 0.0034273568092154736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0056616949808085335\n",
      "Training Loss: 0.005819468820700422\n",
      "Training Loss: 0.005623686221661046\n",
      "Validation Loss: 0.00342389526306076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.00565782752353698\n",
      "Training Loss: 0.005815491657122038\n",
      "Training Loss: 0.0056201087083900345\n",
      "Validation Loss: 0.003420439897382402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.00565396728925407\n",
      "Training Loss: 0.005811516588437371\n",
      "Training Loss: 0.005616529162507504\n",
      "Validation Loss: 0.003416991073852719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005650113871670328\n",
      "Training Loss: 0.005807543032569811\n",
      "Training Loss: 0.0056129498739028345\n",
      "Validation Loss: 0.003413551478526356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005646266115945764\n",
      "Training Loss: 0.005803570213611237\n",
      "Training Loss: 0.005609367602737621\n",
      "Validation Loss: 0.0034101157327538377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.0056424237415194515\n",
      "Training Loss: 0.005799596677534282\n",
      "Training Loss: 0.005605781960184686\n",
      "Validation Loss: 0.003406685042545576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005638584651169367\n",
      "Training Loss: 0.005795623260200955\n",
      "Training Loss: 0.005602193037630059\n",
      "Validation Loss: 0.0034032561188417202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005634749043383636\n",
      "Training Loss: 0.005791648159502074\n",
      "Training Loss: 0.005598599680815823\n",
      "Validation Loss: 0.0033998303318113674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0056309155485359955\n",
      "Training Loss: 0.005787671988364309\n",
      "Training Loss: 0.005595003234921023\n",
      "Validation Loss: 0.003396408883540818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005627083773142658\n",
      "Training Loss: 0.0057836950820637865\n",
      "Training Loss: 0.0055913996876915915\n",
      "Validation Loss: 0.003392986480403022\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005623253581579775\n",
      "Training Loss: 0.005779714414384216\n",
      "Training Loss: 0.005587791010621004\n",
      "Validation Loss: 0.003389567087059108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005619423324824311\n",
      "Training Loss: 0.005775731526664458\n",
      "Training Loss: 0.005584178302087821\n",
      "Validation Loss: 0.0033861444661330976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005615593291004188\n",
      "Training Loss: 0.00577174638514407\n",
      "Training Loss: 0.0055805568094365295\n",
      "Validation Loss: 0.0033827224233595843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.00561176200513728\n",
      "Training Loss: 0.005767757633002475\n",
      "Training Loss: 0.005576929763774388\n",
      "Validation Loss: 0.0033793048004441884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005607929477118887\n",
      "Training Loss: 0.005763764907605946\n",
      "Training Loss: 0.005573296168004163\n",
      "Validation Loss: 0.003375881800187354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005604095036978833\n",
      "Training Loss: 0.005759768607094884\n",
      "Training Loss: 0.005569654717692174\n",
      "Validation Loss: 0.0033724567417337905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005600257684709504\n",
      "Training Loss: 0.005755768265808001\n",
      "Training Loss: 0.005566006354638375\n",
      "Validation Loss: 0.0033690297513090995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0055964184133335945\n",
      "Training Loss: 0.00575176413578447\n",
      "Training Loss: 0.005562349113752134\n",
      "Validation Loss: 0.0033656021127519147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0055925760103855285\n",
      "Training Loss: 0.00574775570363272\n",
      "Training Loss: 0.005558685815194622\n",
      "Validation Loss: 0.0033621739535958746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005588729094015434\n",
      "Training Loss: 0.005743743688217364\n",
      "Training Loss: 0.005555013587581925\n",
      "Validation Loss: 0.003358737882776081\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005584877851651982\n",
      "Training Loss: 0.0057397257420234386\n",
      "Training Loss: 0.005551333278999664\n",
      "Validation Loss: 0.0033552983914386858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005581023182021454\n",
      "Training Loss: 0.00573570380336605\n",
      "Training Loss: 0.005547644715406932\n",
      "Validation Loss: 0.003351860823570175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005577163409907371\n",
      "Training Loss: 0.005731675663264468\n",
      "Training Loss: 0.005543947426485829\n",
      "Validation Loss: 0.003348415752145556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005573298356030137\n",
      "Training Loss: 0.005727642800775356\n",
      "Training Loss: 0.005540240346454084\n",
      "Validation Loss: 0.003344964236021042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005569426481961273\n",
      "Training Loss: 0.005723605660605245\n",
      "Training Loss: 0.00553652485483326\n",
      "Validation Loss: 0.0033415101044758986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00556554953684099\n",
      "Training Loss: 0.005719561224686913\n",
      "Training Loss: 0.0055327998904977\n",
      "Validation Loss: 0.0033380511554292917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005561666239518672\n",
      "Training Loss: 0.005715512439492159\n",
      "Training Loss: 0.005529066001181491\n",
      "Validation Loss: 0.0033345845641746196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005557776215719059\n",
      "Training Loss: 0.005711458065197803\n",
      "Training Loss: 0.005525322092580609\n",
      "Validation Loss: 0.003331115065806995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005553879340877757\n",
      "Training Loss: 0.005707397314254194\n",
      "Training Loss: 0.0055215689790202305\n",
      "Validation Loss: 0.003327639577282446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005549973516608588\n",
      "Training Loss: 0.0057033301331102845\n",
      "Training Loss: 0.005517805174458772\n",
      "Validation Loss: 0.0033241546198757095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005546060928609222\n",
      "Training Loss: 0.005699256897787564\n",
      "Training Loss: 0.005514030669583008\n",
      "Validation Loss: 0.003320663702396906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005542141304467805\n",
      "Training Loss: 0.005695177323650569\n",
      "Training Loss: 0.005510246269986965\n",
      "Validation Loss: 0.0033171638085119676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.0055382120446301995\n",
      "Training Loss: 0.005691091108019464\n",
      "Training Loss: 0.005506450841203332\n",
      "Validation Loss: 0.0033136565163679253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005534273998346179\n",
      "Training Loss: 0.005686997632728889\n",
      "Training Loss: 0.005502644572407007\n",
      "Validation Loss: 0.0033101390660060254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.0055303275323240085\n",
      "Training Loss: 0.005682897405931726\n",
      "Training Loss: 0.005498826464754529\n",
      "Validation Loss: 0.0033066118079802713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005526370893931016\n",
      "Training Loss: 0.005678790288511664\n",
      "Training Loss: 0.005494996506022289\n",
      "Validation Loss: 0.0033030729718621444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005522404956282117\n",
      "Training Loss: 0.005674675495247357\n",
      "Training Loss: 0.005491155469208024\n",
      "Validation Loss: 0.0032995302234043815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.0055184290790930395\n",
      "Training Loss: 0.005670553474919871\n",
      "Training Loss: 0.0054873022565152495\n",
      "Validation Loss: 0.0032959715685587417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005514442719286308\n",
      "Training Loss: 0.00566642289981246\n",
      "Training Loss: 0.005483436181675643\n",
      "Validation Loss: 0.0032924014186810997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005510445117251948\n",
      "Training Loss: 0.005662285263533704\n",
      "Training Loss: 0.005479557809303514\n",
      "Validation Loss: 0.0032888224107746997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005506437210133299\n",
      "Training Loss: 0.005658139465376735\n",
      "Training Loss: 0.005475668150465935\n",
      "Validation Loss: 0.0032852315769028545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005502418261021376\n",
      "Training Loss: 0.005653984069940634\n",
      "Training Loss: 0.005471763751702383\n",
      "Validation Loss: 0.003281627317335917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005498387244297191\n",
      "Training Loss: 0.0056498204765375705\n",
      "Training Loss: 0.005467846046667546\n",
      "Validation Loss: 0.0032780069277067196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00549434389162343\n",
      "Training Loss: 0.005645648482604884\n",
      "Training Loss: 0.005463915128493682\n",
      "Validation Loss: 0.0032743727186631956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005490289014996961\n",
      "Training Loss: 0.005641467043315061\n",
      "Training Loss: 0.005459970135125332\n",
      "Validation Loss: 0.003270724775881789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0054862209968268875\n",
      "Training Loss: 0.005637275087065063\n",
      "Training Loss: 0.005456010678899475\n",
      "Validation Loss: 0.0032670652752825884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005482141285319812\n",
      "Training Loss: 0.005633074935758486\n",
      "Training Loss: 0.005452035531052388\n",
      "Validation Loss: 0.003263382955318254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005478047244832851\n",
      "Training Loss: 0.005628864213358611\n",
      "Training Loss: 0.005448045834200456\n",
      "Validation Loss: 0.003259682576590626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005473939841613174\n",
      "Training Loss: 0.005624643779010512\n",
      "Training Loss: 0.005444041535956785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [07:48<18:16, 156.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0032559688990475254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.07555438045412302\n",
      "Training Loss: 0.07164137611165643\n",
      "Training Loss: 0.07218794513493776\n",
      "Validation Loss: 0.07160249011319005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0709733427874744\n",
      "Training Loss: 0.06837806107476353\n",
      "Training Loss: 0.06847324408590794\n",
      "Validation Loss: 0.06722502190661564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06619119692593813\n",
      "Training Loss: 0.06301315324380993\n",
      "Training Loss: 0.06191086631268263\n",
      "Validation Loss: 0.05952024620989065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05775149901397526\n",
      "Training Loss: 0.05377811709418893\n",
      "Training Loss: 0.05103982750326395\n",
      "Validation Loss: 0.04759384502311436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04530558372847736\n",
      "Training Loss: 0.041367842350155115\n",
      "Training Loss: 0.03798928482457995\n",
      "Validation Loss: 0.034637632434455196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.03251611744984984\n",
      "Training Loss: 0.0297665291139856\n",
      "Training Loss: 0.027063364800997077\n",
      "Validation Loss: 0.02468052686955989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.023402341925539076\n",
      "Training Loss: 0.022153574444819243\n",
      "Training Loss: 0.0205809788685292\n",
      "Validation Loss: 0.019101190150537517\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.0186755840992555\n",
      "Training Loss: 0.01838391677243635\n",
      "Training Loss: 0.017583265050780027\n",
      "Validation Loss: 0.016479819756670948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.016531447998713703\n",
      "Training Loss: 0.01659483107039705\n",
      "Training Loss: 0.016087556008715184\n",
      "Validation Loss: 0.015029342055027739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.01531251402804628\n",
      "Training Loss: 0.015491494801826775\n",
      "Training Loss: 0.015066507293377072\n",
      "Validation Loss: 0.013970016497919817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.014391407622024417\n",
      "Training Loss: 0.014625848645810038\n",
      "Training Loss: 0.014207893437705933\n",
      "Validation Loss: 0.01305488458954928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.013580078058876097\n",
      "Training Loss: 0.013850162578746677\n",
      "Training Loss: 0.013401849146466702\n",
      "Validation Loss: 0.012177887164694623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.012792917150072754\n",
      "Training Loss: 0.013084712384734304\n",
      "Training Loss: 0.012584491334855556\n",
      "Validation Loss: 0.011270605176791883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.011980817643925548\n",
      "Training Loss: 0.012286598819773644\n",
      "Training Loss: 0.011740704097319395\n",
      "Validation Loss: 0.010324900410022963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.01116134502692148\n",
      "Training Loss: 0.011482660691253841\n",
      "Training Loss: 0.010922833769582212\n",
      "Validation Loss: 0.009404099584305972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010400756169110537\n",
      "Training Loss: 0.010736723023001105\n",
      "Training Loss: 0.010192718941252678\n",
      "Validation Loss: 0.008572281878493893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009745234691072255\n",
      "Training Loss: 0.010089994246372953\n",
      "Training Loss: 0.009577783907297998\n",
      "Validation Loss: 0.007856762115163415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009205674096010625\n",
      "Training Loss: 0.009552236964227632\n",
      "Training Loss: 0.009077096401015297\n",
      "Validation Loss: 0.00725790208566599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008773051835596561\n",
      "Training Loss: 0.009115167008712888\n",
      "Training Loss: 0.008676442984724418\n",
      "Validation Loss: 0.006764013052059944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008430952050257474\n",
      "Training Loss: 0.00876337852445431\n",
      "Training Loss: 0.008357421945547686\n",
      "Validation Loss: 0.006359559682647834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008161482387222349\n",
      "Training Loss: 0.008479699820745736\n",
      "Training Loss: 0.008101352605735882\n",
      "Validation Loss: 0.00602813768645309\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00794735326897353\n",
      "Training Loss: 0.008247369278687983\n",
      "Training Loss: 0.007891062594717368\n",
      "Validation Loss: 0.005753835151756831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007772804620908573\n",
      "Training Loss: 0.008051586919464171\n",
      "Training Loss: 0.007712649357272312\n",
      "Validation Loss: 0.005523115002126381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007624880467774347\n",
      "Training Loss: 0.00788142867735587\n",
      "Training Loss: 0.007557033568155021\n",
      "Validation Loss: 0.005326708681290195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007494934259448201\n",
      "Training Loss: 0.007731041783699766\n",
      "Training Loss: 0.007419921007240191\n",
      "Validation Loss: 0.005159533175174147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007378996007610113\n",
      "Training Loss: 0.007598640297073871\n",
      "Training Loss: 0.00729995000991039\n",
      "Validation Loss: 0.005018724791778858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007276163615752011\n",
      "Training Loss: 0.007483928450383246\n",
      "Training Loss: 0.007196485133608804\n",
      "Validation Loss: 0.004901567089444633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007186314042191952\n",
      "Training Loss: 0.007386192395351827\n",
      "Training Loss: 0.0071083972160704435\n",
      "Validation Loss: 0.0048047831063577386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007108826395124197\n",
      "Training Loss: 0.007303795720217749\n",
      "Training Loss: 0.00703386441222392\n",
      "Validation Loss: 0.004724756507150662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007042401605285704\n",
      "Training Loss: 0.007234484578948468\n",
      "Training Loss: 0.006970699490047991\n",
      "Validation Loss: 0.004658019903974001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.006985363168641925\n",
      "Training Loss: 0.0071758501639124\n",
      "Training Loss: 0.006916724135517143\n",
      "Validation Loss: 0.0046015624944486895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0069359749311115595\n",
      "Training Loss: 0.007125681176548823\n",
      "Training Loss: 0.006870015058666468\n",
      "Validation Loss: 0.004552963607044619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0068926525593269615\n",
      "Training Loss: 0.0070821115816943345\n",
      "Training Loss: 0.00682898832776118\n",
      "Validation Loss: 0.004510354272906114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.006854049548273906\n",
      "Training Loss: 0.007043653038563207\n",
      "Training Loss: 0.006792390788905323\n",
      "Validation Loss: 0.004472315109340118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0068190716090612115\n",
      "Training Loss: 0.0070091450260952115\n",
      "Training Loss: 0.006759247852605768\n",
      "Validation Loss: 0.004437791548533302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.006786853399826214\n",
      "Training Loss: 0.006977697565453127\n",
      "Training Loss: 0.006728806818136946\n",
      "Validation Loss: 0.00440598601930555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.006756722446298226\n",
      "Training Loss: 0.006948620396433398\n",
      "Training Loss: 0.006700484264292754\n",
      "Validation Loss: 0.004376300066458375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0067281603685114535\n",
      "Training Loss: 0.006921381986467167\n",
      "Training Loss: 0.006673825921607204\n",
      "Validation Loss: 0.004348281632292639\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.006700774094788357\n",
      "Training Loss: 0.0068955671531148255\n",
      "Training Loss: 0.006648479510913603\n",
      "Validation Loss: 0.00432158898355523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0066742685076314956\n",
      "Training Loss: 0.006870851500425487\n",
      "Training Loss: 0.006624168227426707\n",
      "Validation Loss: 0.004295960724029397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.006648424941813573\n",
      "Training Loss: 0.006846983139403164\n",
      "Training Loss: 0.006600677319802344\n",
      "Validation Loss: 0.0042711940032869496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006623085180763155\n",
      "Training Loss: 0.006823766849702224\n",
      "Training Loss: 0.006577844357816502\n",
      "Validation Loss: 0.004247139062172618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006598139188718051\n",
      "Training Loss: 0.0068010544893331824\n",
      "Training Loss: 0.006555545791052282\n",
      "Validation Loss: 0.004223680543566771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006573516926728189\n",
      "Training Loss: 0.006778741183225066\n",
      "Training Loss: 0.00653369574691169\n",
      "Validation Loss: 0.004200740260846411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006549182598246261\n",
      "Training Loss: 0.006756752195069566\n",
      "Training Loss: 0.006512236359994859\n",
      "Validation Loss: 0.004178258222841731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006525125665357337\n",
      "Training Loss: 0.006735046684043482\n",
      "Training Loss: 0.006491137288976461\n",
      "Validation Loss: 0.004156198454602213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006501359444228001\n",
      "Training Loss: 0.006713605601107702\n",
      "Training Loss: 0.006470390516333282\n",
      "Validation Loss: 0.004134548633108229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.0064779163291677835\n",
      "Training Loss: 0.006692435997538268\n",
      "Training Loss: 0.006450003687059507\n",
      "Validation Loss: 0.004113307532074788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0064548417495097965\n",
      "Training Loss: 0.00667155870818533\n",
      "Training Loss: 0.006430000960826874\n",
      "Validation Loss: 0.004092489793671693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006432190331979655\n",
      "Training Loss: 0.006651010189671069\n",
      "Training Loss: 0.006410413506673649\n",
      "Validation Loss: 0.004072118933139934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006410021941992455\n",
      "Training Loss: 0.006630834632087499\n",
      "Training Loss: 0.00639127888251096\n",
      "Validation Loss: 0.004052218820198617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.0063883933081524446\n",
      "Training Loss: 0.006611077102134004\n",
      "Training Loss: 0.00637263081735\n",
      "Validation Loss: 0.004032820968082949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006367355080437846\n",
      "Training Loss: 0.006591783749172464\n",
      "Training Loss: 0.0063545012497343125\n",
      "Validation Loss: 0.004013943208611748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006346947423298843\n",
      "Training Loss: 0.006572995079914108\n",
      "Training Loss: 0.006336913611739874\n",
      "Validation Loss: 0.003995610522027807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006327198049402796\n",
      "Training Loss: 0.006554740119026974\n",
      "Training Loss: 0.006319880825467408\n",
      "Validation Loss: 0.003977831926594457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0063081214053090666\n",
      "Training Loss: 0.006537041614064947\n",
      "Training Loss: 0.006303410760010592\n",
      "Validation Loss: 0.003960615449736753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00628971892350819\n",
      "Training Loss: 0.006519909295020625\n",
      "Training Loss: 0.006287495265132748\n",
      "Validation Loss: 0.003943954205946222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006271978415315971\n",
      "Training Loss: 0.006503342769574374\n",
      "Training Loss: 0.006272122357040643\n",
      "Validation Loss: 0.003927841078191786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006254880161723122\n",
      "Training Loss: 0.006487333155237138\n",
      "Training Loss: 0.006257271863287315\n",
      "Validation Loss: 0.003912258277819858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006238396416883916\n",
      "Training Loss: 0.006471866515930742\n",
      "Training Loss: 0.0062429189553949984\n",
      "Validation Loss: 0.00389718159436761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006222495271940715\n",
      "Training Loss: 0.006456921480130404\n",
      "Training Loss: 0.0062290378799661995\n",
      "Validation Loss: 0.0038825997263925633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006207142816856503\n",
      "Training Loss: 0.006442474023206159\n",
      "Training Loss: 0.006215599739807658\n",
      "Validation Loss: 0.0038684789114893318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006192303961142898\n",
      "Training Loss: 0.006428498736349866\n",
      "Training Loss: 0.006202576739015058\n",
      "Validation Loss: 0.00385479834532428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006177945996169001\n",
      "Training Loss: 0.006414969105971977\n",
      "Training Loss: 0.0061899413599167015\n",
      "Validation Loss: 0.003841531740925327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006164036337286234\n",
      "Training Loss: 0.006401859859470278\n",
      "Training Loss: 0.006177667852025479\n",
      "Validation Loss: 0.003828657953215114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006150544484262355\n",
      "Training Loss: 0.006389143685810268\n",
      "Training Loss: 0.006165731590008363\n",
      "Validation Loss: 0.0038161510235389298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006137443080660887\n",
      "Training Loss: 0.006376798335695639\n",
      "Training Loss: 0.006154109876370058\n",
      "Validation Loss: 0.0038039886897555395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0061247055255807935\n",
      "Training Loss: 0.006364801155868917\n",
      "Training Loss: 0.0061427826929138975\n",
      "Validation Loss: 0.003792153168443507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006112308923038654\n",
      "Training Loss: 0.006353129709605127\n",
      "Training Loss: 0.006131730871857144\n",
      "Validation Loss: 0.00378062362322228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006100232663447969\n",
      "Training Loss: 0.006341765101533383\n",
      "Training Loss: 0.006120938895619475\n",
      "Validation Loss: 0.00376938618235604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006088457790319808\n",
      "Training Loss: 0.006330688965972513\n",
      "Training Loss: 0.006110391122638248\n",
      "Validation Loss: 0.003758418416274774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006076965520624072\n",
      "Training Loss: 0.006319883841788396\n",
      "Training Loss: 0.006100072467233986\n",
      "Validation Loss: 0.003747709509471871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006065739681944251\n",
      "Training Loss: 0.006309334874385968\n",
      "Training Loss: 0.006089971424080432\n",
      "Validation Loss: 0.003737243010761907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0060547659639269115\n",
      "Training Loss: 0.006299027664354071\n",
      "Training Loss: 0.006080076975049451\n",
      "Validation Loss: 0.0037270089561705676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006044031771016307\n",
      "Training Loss: 0.006288948326837272\n",
      "Training Loss: 0.006070379591546953\n",
      "Validation Loss: 0.003716992258795359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006033524742233567\n",
      "Training Loss: 0.006279085272690281\n",
      "Training Loss: 0.0060608695854898545\n",
      "Validation Loss: 0.0037071835668234343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0060232342639938\n",
      "Training Loss: 0.006269427355146035\n",
      "Training Loss: 0.0060515400150325145\n",
      "Validation Loss: 0.0036975731347227113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006013149969512597\n",
      "Training Loss: 0.006259965414647013\n",
      "Training Loss: 0.006042384104803205\n",
      "Validation Loss: 0.0036881531437000866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006003263196325861\n",
      "Training Loss: 0.006250689350999892\n",
      "Training Loss: 0.006033395198173821\n",
      "Validation Loss: 0.0036789145068202712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.005993564628297463\n",
      "Training Loss: 0.006241590323625133\n",
      "Training Loss: 0.006024566995329224\n",
      "Validation Loss: 0.0036698480835184455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.005984047452220693\n",
      "Training Loss: 0.0062326611264143135\n",
      "Training Loss: 0.006015895961900242\n",
      "Validation Loss: 0.0036609525912640133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.005974704772816039\n",
      "Training Loss: 0.006223893336718902\n",
      "Training Loss: 0.0060073764907428995\n",
      "Validation Loss: 0.003652218124290321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00596553000388667\n",
      "Training Loss: 0.006215281399199739\n",
      "Training Loss: 0.005999004861805588\n",
      "Validation Loss: 0.0036436353896462013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.005956516237929464\n",
      "Training Loss: 0.006206820108927786\n",
      "Training Loss: 0.0059907774778548625\n",
      "Validation Loss: 0.003635205667573184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.005947660282836296\n",
      "Training Loss: 0.006198502911720425\n",
      "Training Loss: 0.005982692125835456\n",
      "Validation Loss: 0.00362692209578046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005938955651363358\n",
      "Training Loss: 0.006190323914634064\n",
      "Training Loss: 0.005974745720741339\n",
      "Validation Loss: 0.003618780374749344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.005930397969787009\n",
      "Training Loss: 0.006182279181666672\n",
      "Training Loss: 0.005966933896415867\n",
      "Validation Loss: 0.0036107764433509553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005921983399894089\n",
      "Training Loss: 0.006174364290200174\n",
      "Training Loss: 0.0059592567360959945\n",
      "Validation Loss: 0.0036029070864295526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005913707507424988\n",
      "Training Loss: 0.006166575134266168\n",
      "Training Loss: 0.005951709459768608\n",
      "Validation Loss: 0.003595167998580283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005905566596775316\n",
      "Training Loss: 0.0061589069059118625\n",
      "Training Loss: 0.005944291512714699\n",
      "Validation Loss: 0.003587560772992608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005897558270953595\n",
      "Training Loss: 0.00615135676576756\n",
      "Training Loss: 0.0059369994094595315\n",
      "Validation Loss: 0.003580076768117946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005889677276136354\n",
      "Training Loss: 0.006143921326147392\n",
      "Training Loss: 0.0059298324841074645\n",
      "Validation Loss: 0.0035727178727621945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.005881922546541319\n",
      "Training Loss: 0.006136597484583035\n",
      "Training Loss: 0.005922787333838641\n",
      "Validation Loss: 0.003565474529750645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.005874288990162313\n",
      "Training Loss: 0.006129382122308016\n",
      "Training Loss: 0.00591586327063851\n",
      "Validation Loss: 0.0035583534686083203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.005866776066832244\n",
      "Training Loss: 0.00612227251753211\n",
      "Training Loss: 0.005909056673408486\n",
      "Validation Loss: 0.003551345247594807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.005859379994217306\n",
      "Training Loss: 0.006115265999687836\n",
      "Training Loss: 0.005902367561357096\n",
      "Validation Loss: 0.0035444550213581893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.005852098615141585\n",
      "Training Loss: 0.006108358239289373\n",
      "Training Loss: 0.005895792992669157\n",
      "Validation Loss: 0.0035376749452716264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005844929102458991\n",
      "Training Loss: 0.006101548771839589\n",
      "Training Loss: 0.005889330944628454\n",
      "Validation Loss: 0.0035310053378422063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005837868685484864\n",
      "Training Loss: 0.006094834130490199\n",
      "Training Loss: 0.005882977904984727\n",
      "Validation Loss: 0.003524441541803038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.0058309146016836165\n",
      "Training Loss: 0.006088211917085573\n",
      "Training Loss: 0.005876733415061608\n",
      "Validation Loss: 0.003517987279174326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005824066246277653\n",
      "Training Loss: 0.006081680640345439\n",
      "Training Loss: 0.005870594523148611\n",
      "Validation Loss: 0.003511639672927977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00581732019840274\n",
      "Training Loss: 0.006075237035984174\n",
      "Training Loss: 0.0058645614428678525\n",
      "Validation Loss: 0.0035053963466871825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005810674662352539\n",
      "Training Loss: 0.00606888004927896\n",
      "Training Loss: 0.005858628992573358\n",
      "Validation Loss: 0.003499255021850924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.005804127540905028\n",
      "Training Loss: 0.006062606364721433\n",
      "Training Loss: 0.005852795708924532\n",
      "Validation Loss: 0.0034932106019787785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005797675701323897\n",
      "Training Loss: 0.0060564141313079745\n",
      "Training Loss: 0.005847059260704554\n",
      "Validation Loss: 0.0034872653816952212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005791317320545204\n",
      "Training Loss: 0.006050301560899243\n",
      "Training Loss: 0.005841418049531057\n",
      "Validation Loss: 0.003481422874715514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.005785051072016358\n",
      "Training Loss: 0.006044267629040406\n",
      "Training Loss: 0.005835868946742266\n",
      "Validation Loss: 0.00347567313733992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005778873793315142\n",
      "Training Loss: 0.006038309192517772\n",
      "Training Loss: 0.005830410046619363\n",
      "Validation Loss: 0.003470018964844201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005772784209111706\n",
      "Training Loss: 0.006032423737924546\n",
      "Training Loss: 0.005825038406765088\n",
      "Validation Loss: 0.003464455333384005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.005766779312980361\n",
      "Training Loss: 0.006026613166322931\n",
      "Training Loss: 0.005819752988754772\n",
      "Validation Loss: 0.0034589858439860845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005760858347639441\n",
      "Training Loss: 0.006020871457876637\n",
      "Training Loss: 0.005814549744245596\n",
      "Validation Loss: 0.003453605392688802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.00575501901039388\n",
      "Training Loss: 0.006015199313405901\n",
      "Training Loss: 0.005809428330394439\n",
      "Validation Loss: 0.0034483162113308403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005749259102740325\n",
      "Training Loss: 0.006009595044888556\n",
      "Training Loss: 0.0058043851447291675\n",
      "Validation Loss: 0.003443112188107805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.005743576786480844\n",
      "Training Loss: 0.006004056334495545\n",
      "Training Loss: 0.005799417965463362\n",
      "Validation Loss: 0.0034379961859863878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0057379702164325865\n",
      "Training Loss: 0.005998581852763891\n",
      "Training Loss: 0.005794525308883749\n",
      "Validation Loss: 0.0034329619953864035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005732437091646716\n",
      "Training Loss: 0.005993171045556665\n",
      "Training Loss: 0.005789703520713374\n",
      "Validation Loss: 0.0034280100312826926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005726975983707234\n",
      "Training Loss: 0.005987822607858106\n",
      "Training Loss: 0.005784950643428602\n",
      "Validation Loss: 0.003423135076895398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005721584765124135\n",
      "Training Loss: 0.0059825340477982535\n",
      "Training Loss: 0.005780266535584815\n",
      "Validation Loss: 0.0034183438640386075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005716262246132828\n",
      "Training Loss: 0.005977304538246245\n",
      "Training Loss: 0.005775647537666373\n",
      "Validation Loss: 0.0034136281491340963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005711006887140684\n",
      "Training Loss: 0.005972132219467312\n",
      "Training Loss: 0.005771093256189488\n",
      "Validation Loss: 0.0034089952058504137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005705817360430956\n",
      "Training Loss: 0.005967017428483814\n",
      "Training Loss: 0.005766599117778242\n",
      "Validation Loss: 0.0034044318066601214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005700689920922741\n",
      "Training Loss: 0.005961958939442411\n",
      "Training Loss: 0.005762164756306447\n",
      "Validation Loss: 0.003399941975740046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005695626139640808\n",
      "Training Loss: 0.00595695516502019\n",
      "Training Loss: 0.005757790379575454\n",
      "Validation Loss: 0.003395528044339709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005690623255213722\n",
      "Training Loss: 0.005952005413128063\n",
      "Training Loss: 0.005753470511408522\n",
      "Validation Loss: 0.0033911818516142458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.005685678176232614\n",
      "Training Loss: 0.005947109134285711\n",
      "Training Loss: 0.0057492055249167605\n",
      "Validation Loss: 0.0033869044851966915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005680791923659854\n",
      "Training Loss: 0.005942264902405441\n",
      "Training Loss: 0.005744993457919918\n",
      "Validation Loss: 0.0033826952011408178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.005675961792003363\n",
      "Training Loss: 0.005937472315272316\n",
      "Training Loss: 0.005740832542651333\n",
      "Validation Loss: 0.003378551149560306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005671187028638087\n",
      "Training Loss: 0.0059327310312073675\n",
      "Training Loss: 0.0057367219310253854\n",
      "Validation Loss: 0.0033744711715340864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005666465657413937\n",
      "Training Loss: 0.005928039232967422\n",
      "Training Loss: 0.005732659299392253\n",
      "Validation Loss: 0.003370455744495783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005661798269138671\n",
      "Training Loss: 0.005923396305879578\n",
      "Training Loss: 0.005728644788032398\n",
      "Validation Loss: 0.0033665026513221307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005657182019203902\n",
      "Training Loss: 0.005918802864034661\n",
      "Training Loss: 0.005724675735691563\n",
      "Validation Loss: 0.0033626086402323433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005652616136940196\n",
      "Training Loss: 0.005914258070988581\n",
      "Training Loss: 0.0057207515876507384\n",
      "Validation Loss: 0.00335877438584667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005648099688696675\n",
      "Training Loss: 0.005909760991926305\n",
      "Training Loss: 0.005716869957977906\n",
      "Validation Loss: 0.0033549969741849626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005643631463753991\n",
      "Training Loss: 0.005905311065143906\n",
      "Training Loss: 0.005713032014318742\n",
      "Validation Loss: 0.0033512767659385134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005639210895169527\n",
      "Training Loss: 0.005900907161994837\n",
      "Training Loss: 0.005709234769456089\n",
      "Validation Loss: 0.0033476097153478795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.00563483640551567\n",
      "Training Loss: 0.005896549979806878\n",
      "Training Loss: 0.005705477699520998\n",
      "Validation Loss: 0.003343997631755689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0056305072800023484\n",
      "Training Loss: 0.005892238485394045\n",
      "Training Loss: 0.005701759692747146\n",
      "Validation Loss: 0.0033404370567112576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.005626222509890795\n",
      "Training Loss: 0.005887971062329598\n",
      "Training Loss: 0.005698079442954623\n",
      "Validation Loss: 0.003336927524880307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005621980751748197\n",
      "Training Loss: 0.005883749511558563\n",
      "Training Loss: 0.005694437724305317\n",
      "Validation Loss: 0.0033334681785173632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005617781839682721\n",
      "Training Loss: 0.0058795709774130955\n",
      "Training Loss: 0.005690831016399897\n",
      "Validation Loss: 0.0033300589270408402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00561362452164758\n",
      "Training Loss: 0.005875437032664195\n",
      "Training Loss: 0.00568726085301023\n",
      "Validation Loss: 0.0033266948116812438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005609508084598929\n",
      "Training Loss: 0.0058713460498256605\n",
      "Training Loss: 0.00568372419627849\n",
      "Validation Loss: 0.003323380185913797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.0056054313841741536\n",
      "Training Loss: 0.0058672974666114895\n",
      "Training Loss: 0.005680222606752067\n",
      "Validation Loss: 0.0033201097875043455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005601393643300981\n",
      "Training Loss: 0.005863291537971236\n",
      "Training Loss: 0.005676752866129391\n",
      "Validation Loss: 0.0033168839133773625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00559739452553913\n",
      "Training Loss: 0.0058593268832191825\n",
      "Training Loss: 0.005673314686282538\n",
      "Validation Loss: 0.003313698821892083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.0055934314179467036\n",
      "Training Loss: 0.005855403523892164\n",
      "Training Loss: 0.005669907831470482\n",
      "Validation Loss: 0.0033105568335067186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0055895050783874465\n",
      "Training Loss: 0.005851520626456477\n",
      "Training Loss: 0.005666531986207701\n",
      "Validation Loss: 0.0033074539724418247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.0055856140202377\n",
      "Training Loss: 0.0058476786653045565\n",
      "Training Loss: 0.005663186230231076\n",
      "Validation Loss: 0.0033043928220711145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005581758229527623\n",
      "Training Loss: 0.005843875179998577\n",
      "Training Loss: 0.005659868610091507\n",
      "Validation Loss: 0.0033013709173982525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005577935338369571\n",
      "Training Loss: 0.005840111235738732\n",
      "Training Loss: 0.005656579508213327\n",
      "Validation Loss: 0.003298387058298993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005574146415456198\n",
      "Training Loss: 0.0058363852725597095\n",
      "Training Loss: 0.005653316887328401\n",
      "Validation Loss: 0.003295438606462054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005570388751220889\n",
      "Training Loss: 0.00583269695925992\n",
      "Training Loss: 0.005650081163621507\n",
      "Validation Loss: 0.003292526770840933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005566663225181401\n",
      "Training Loss: 0.005829044827260077\n",
      "Training Loss: 0.005646871605422348\n",
      "Validation Loss: 0.0032896520360634566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.0055629685107851405\n",
      "Training Loss: 0.005825430188560858\n",
      "Training Loss: 0.005643686977564357\n",
      "Validation Loss: 0.003286807501251715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005559302577748895\n",
      "Training Loss: 0.005821851164801046\n",
      "Training Loss: 0.00564052568632178\n",
      "Validation Loss: 0.0032839988167999374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005555666300933808\n",
      "Training Loss: 0.005818307272274979\n",
      "Training Loss: 0.005637388144969009\n",
      "Validation Loss: 0.003281222184494745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005552057680906728\n",
      "Training Loss: 0.005814796758349985\n",
      "Training Loss: 0.005634273035102524\n",
      "Validation Loss: 0.0032784776465203404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0055484758352395145\n",
      "Training Loss: 0.005811321006040089\n",
      "Training Loss: 0.005631180368945934\n",
      "Validation Loss: 0.0032757614337671757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005544920946704224\n",
      "Training Loss: 0.005807876878534444\n",
      "Training Loss: 0.005628108610399068\n",
      "Validation Loss: 0.003273075322876946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00554139064042829\n",
      "Training Loss: 0.005804466479457915\n",
      "Training Loss: 0.005625056125572883\n",
      "Validation Loss: 0.0032704201915426953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.0055378859414486215\n",
      "Training Loss: 0.005801086309365928\n",
      "Training Loss: 0.005622023503528908\n",
      "Validation Loss: 0.0032677907605257847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005534404845093377\n",
      "Training Loss: 0.005797736688400619\n",
      "Training Loss: 0.005619009374058805\n",
      "Validation Loss: 0.003265189771472445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.0055309468292398375\n",
      "Training Loss: 0.005794416650314815\n",
      "Training Loss: 0.005616013880935498\n",
      "Validation Loss: 0.0032626163542108463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005527511998661794\n",
      "Training Loss: 0.005791126935509965\n",
      "Training Loss: 0.00561303547816351\n",
      "Validation Loss: 0.0032600700813397933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005524098251480609\n",
      "Training Loss: 0.005787864439771511\n",
      "Training Loss: 0.005610073111020028\n",
      "Validation Loss: 0.0032575470817228255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005520705910748802\n",
      "Training Loss: 0.005784629763220437\n",
      "Training Loss: 0.005607126318500378\n",
      "Validation Loss: 0.0032550475741291857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005517332681338302\n",
      "Training Loss: 0.005781422249856405\n",
      "Training Loss: 0.0056041934702079745\n",
      "Validation Loss: 0.003252573462734208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.0055139789613895115\n",
      "Training Loss: 0.0057782395725371315\n",
      "Training Loss: 0.005601274797227234\n",
      "Validation Loss: 0.003250122865599193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0055106442898977545\n",
      "Training Loss: 0.005775082184700295\n",
      "Training Loss: 0.005598370378138497\n",
      "Validation Loss: 0.0032476961201977697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005507327559171244\n",
      "Training Loss: 0.005771949528716505\n",
      "Training Loss: 0.005595477837487124\n",
      "Validation Loss: 0.0032452886078501476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005504027613787912\n",
      "Training Loss: 0.00576883991365321\n",
      "Training Loss: 0.005592596646165475\n",
      "Validation Loss: 0.003242900242879882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005500742929871194\n",
      "Training Loss: 0.005765753718442283\n",
      "Training Loss: 0.0055897257238393646\n",
      "Validation Loss: 0.0032405333522853726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0054974745988147335\n",
      "Training Loss: 0.005762688468676061\n",
      "Training Loss: 0.005586866749217734\n",
      "Validation Loss: 0.0032381880537899776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.00549422190815676\n",
      "Training Loss: 0.005759644522913732\n",
      "Training Loss: 0.005584015269414521\n",
      "Validation Loss: 0.0032358609226249744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.0054909831332042814\n",
      "Training Loss: 0.005756620975444093\n",
      "Training Loss: 0.005581173298414796\n",
      "Validation Loss: 0.003233553764862898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005487757246010005\n",
      "Training Loss: 0.005753617183072493\n",
      "Training Loss: 0.005578339082421735\n",
      "Validation Loss: 0.003231262024936758\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005484544853679836\n",
      "Training Loss: 0.005750630527036265\n",
      "Training Loss: 0.005575512112700381\n",
      "Validation Loss: 0.003228987854894962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0054813437128905206\n",
      "Training Loss: 0.005747663726797327\n",
      "Training Loss: 0.005572691463166848\n",
      "Validation Loss: 0.003226729768480101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.0054781542537966745\n",
      "Training Loss: 0.00574471331667155\n",
      "Training Loss: 0.005569876842782833\n",
      "Validation Loss: 0.003224488563594942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005474976159748621\n",
      "Training Loss: 0.005741779202362522\n",
      "Training Loss: 0.005567066976218484\n",
      "Validation Loss: 0.003222261031950939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005471808558795601\n",
      "Training Loss: 0.005738860684796236\n",
      "Training Loss: 0.005564261724357493\n",
      "Validation Loss: 0.0032200495757586374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005468650046386756\n",
      "Training Loss: 0.005735957962460816\n",
      "Training Loss: 0.005561459769960492\n",
      "Validation Loss: 0.0032178501423913985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.0054655009479029106\n",
      "Training Loss: 0.005733069046982564\n",
      "Training Loss: 0.005558661632821895\n",
      "Validation Loss: 0.0032156665627635344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005462360206875019\n",
      "Training Loss: 0.005730194042553194\n",
      "Training Loss: 0.0055558657442452385\n",
      "Validation Loss: 0.0032134939670520886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005459227893734351\n",
      "Training Loss: 0.00572733209002763\n",
      "Training Loss: 0.005553071712492965\n",
      "Validation Loss: 0.0032113347734910635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005456103013129905\n",
      "Training Loss: 0.005724481934448704\n",
      "Training Loss: 0.005550278648734093\n",
      "Validation Loss: 0.0032091876249917355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.0054529853729764\n",
      "Training Loss: 0.00572164406592492\n",
      "Training Loss: 0.005547487291623838\n",
      "Validation Loss: 0.003207050887815487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005449874093174003\n",
      "Training Loss: 0.00571881728770677\n",
      "Training Loss: 0.005544695393764414\n",
      "Validation Loss: 0.003204925324875087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005446768956026062\n",
      "Training Loss: 0.005716000609681942\n",
      "Training Loss: 0.005541904016281478\n",
      "Validation Loss: 0.0032028081301034668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005443669161759317\n",
      "Training Loss: 0.005713193920091726\n",
      "Training Loss: 0.005539110829122364\n",
      "Validation Loss: 0.003200703385558105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005440575118991546\n",
      "Training Loss: 0.005710397204384207\n",
      "Training Loss: 0.005536318014492281\n",
      "Validation Loss: 0.003198605713243544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005437486404553056\n",
      "Training Loss: 0.005707608860684559\n",
      "Training Loss: 0.005533522250480019\n",
      "Validation Loss: 0.0031965179571599354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005434401881648228\n",
      "Training Loss: 0.0057048304087948054\n",
      "Training Loss: 0.005530725380522199\n",
      "Validation Loss: 0.003194436036230829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0054313218052266165\n",
      "Training Loss: 0.005702059555915184\n",
      "Training Loss: 0.005527925443020649\n",
      "Validation Loss: 0.003192363476924849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005428246284718625\n",
      "Training Loss: 0.005699296554084867\n",
      "Training Loss: 0.005525123553816229\n",
      "Validation Loss: 0.0031902991791826077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005425174166448415\n",
      "Training Loss: 0.005696540440549142\n",
      "Training Loss: 0.005522317904978991\n",
      "Validation Loss: 0.003188238922621678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0054221060068812225\n",
      "Training Loss: 0.005693791873636655\n",
      "Training Loss: 0.005519509513978846\n",
      "Validation Loss: 0.003186187122849057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005419040535925888\n",
      "Training Loss: 0.005691049685119651\n",
      "Training Loss: 0.0055166974826715886\n",
      "Validation Loss: 0.0031841396176899794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005415978174423799\n",
      "Training Loss: 0.005688313890132122\n",
      "Training Loss: 0.005513881260994822\n",
      "Validation Loss: 0.0031820974879102843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005412920190137811\n",
      "Training Loss: 0.005685583711601794\n",
      "Training Loss: 0.005511061085271649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [10:24<15:38, 156.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0031800624888960608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.7620271649956704\n",
      "Training Loss: 0.6465881577134133\n",
      "Training Loss: 0.5451381438970566\n",
      "Validation Loss: 0.4671046882867813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.4194460868835449\n",
      "Training Loss: 0.3214970403909683\n",
      "Training Loss: 0.20808771949261426\n",
      "Validation Loss: 0.12514870881699444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.09702121766284108\n",
      "Training Loss: 0.0677462563663721\n",
      "Training Loss: 0.05926484500989318\n",
      "Validation Loss: 0.05903216859514124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05693507734686136\n",
      "Training Loss: 0.055208181273192165\n",
      "Training Loss: 0.05391275055706501\n",
      "Validation Loss: 0.053973323341166037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.05184324819594622\n",
      "Training Loss: 0.05033010955899954\n",
      "Training Loss: 0.04859251762740314\n",
      "Validation Loss: 0.048495534085407015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04634804023429751\n",
      "Training Loss: 0.04514096247032285\n",
      "Training Loss: 0.04310933385044336\n",
      "Validation Loss: 0.04286276711297504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.04079663240350783\n",
      "Training Loss: 0.03988263430073857\n",
      "Training Loss: 0.03766491227783263\n",
      "Validation Loss: 0.03723176275746206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.03531328558921814\n",
      "Training Loss: 0.0346511626150459\n",
      "Training Loss: 0.03234497018158436\n",
      "Validation Loss: 0.03169274882654126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.02999110445845872\n",
      "Training Loss: 0.029540446740575134\n",
      "Training Loss: 0.027261560242623092\n",
      "Validation Loss: 0.026367114877767776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.024980727462098003\n",
      "Training Loss: 0.024723549569025637\n",
      "Training Loss: 0.02265928013715893\n",
      "Validation Loss: 0.021555264182179498\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.020616948339156806\n",
      "Training Loss: 0.020552040659822524\n",
      "Training Loss: 0.018917838740162552\n",
      "Validation Loss: 0.017649471969082113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.01724098189966753\n",
      "Training Loss: 0.017298643202520905\n",
      "Training Loss: 0.01613919493975118\n",
      "Validation Loss: 0.014712309383713965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.014774278129916638\n",
      "Training Loss: 0.014861073831561954\n",
      "Training Loss: 0.01404724579770118\n",
      "Validation Loss: 0.012498606616380007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.01291631321888417\n",
      "Training Loss: 0.01299401780590415\n",
      "Training Loss: 0.012414423425216228\n",
      "Validation Loss: 0.010796493379754966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.011492925283964723\n",
      "Training Loss: 0.011571557293646038\n",
      "Training Loss: 0.011159517178311944\n",
      "Validation Loss: 0.00952066509890255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010429997653700411\n",
      "Training Loss: 0.010517929026391357\n",
      "Training Loss: 0.010219457745552062\n",
      "Validation Loss: 0.008580139167135938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00964837855193764\n",
      "Training Loss: 0.009743641798850148\n",
      "Training Loss: 0.009518444767454639\n",
      "Validation Loss: 0.007879618697883457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00907016689889133\n",
      "Training Loss: 0.009168232686351984\n",
      "Training Loss: 0.008989216376794501\n",
      "Validation Loss: 0.007344356072239913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008634306440362706\n",
      "Training Loss: 0.00873201308073476\n",
      "Training Loss: 0.008581255510216578\n",
      "Validation Loss: 0.006922603348071237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008297750176861882\n",
      "Training Loss: 0.008393940747482702\n",
      "Training Loss: 0.008259410582249984\n",
      "Validation Loss: 0.006580241182766688\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008031530026346444\n",
      "Training Loss: 0.008126504074316471\n",
      "Training Loss: 0.007999982071341947\n",
      "Validation Loss: 0.006295153162222397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007816441567847505\n",
      "Training Loss: 0.007911233130143955\n",
      "Training Loss: 0.007787035303190351\n",
      "Validation Loss: 0.006052939607133942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0076396473171189425\n",
      "Training Loss: 0.007735483751166612\n",
      "Training Loss: 0.007609696140279993\n",
      "Validation Loss: 0.005844059646171466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007492364550707862\n",
      "Training Loss: 0.007590335918357596\n",
      "Training Loss: 0.007460313900373876\n",
      "Validation Loss: 0.005661974596304379\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007368356394581496\n",
      "Training Loss: 0.007469258585479111\n",
      "Training Loss: 0.007333298695739359\n",
      "Validation Loss: 0.005502012913413555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007262998158112168\n",
      "Training Loss: 0.007367293493589386\n",
      "Training Loss: 0.0072243933076970275\n",
      "Validation Loss: 0.005360669625813163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007172704227268695\n",
      "Training Loss: 0.0072805519145913425\n",
      "Training Loss: 0.007130230425391346\n",
      "Validation Loss: 0.0052351859284386956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0070945884892717\n",
      "Training Loss: 0.007205899792024866\n",
      "Training Loss: 0.0070480539253912865\n",
      "Validation Loss: 0.005123280493014105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007026251966599375\n",
      "Training Loss: 0.007140761583577841\n",
      "Training Loss: 0.006975566986948251\n",
      "Validation Loss: 0.0050230318735343185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.006965685121249407\n",
      "Training Loss: 0.007083017852855846\n",
      "Training Loss: 0.006910840674536302\n",
      "Validation Loss: 0.004932770050350535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.006911194694694132\n",
      "Training Loss: 0.007030918075470254\n",
      "Training Loss: 0.006852255889680236\n",
      "Validation Loss: 0.004851058207902262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00686137582291849\n",
      "Training Loss: 0.0069830480520613495\n",
      "Training Loss: 0.006798483252059668\n",
      "Validation Loss: 0.004776661808136851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.006815086739370599\n",
      "Training Loss: 0.006938282065093517\n",
      "Training Loss: 0.0067484455776866525\n",
      "Validation Loss: 0.00470852191897444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00677142443950288\n",
      "Training Loss: 0.00689576105796732\n",
      "Training Loss: 0.00670130887418054\n",
      "Validation Loss: 0.0046457774287058315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.006729711631778628\n",
      "Training Loss: 0.006854860645253211\n",
      "Training Loss: 0.006656453319592402\n",
      "Validation Loss: 0.0045877119592976955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.006689470995916054\n",
      "Training Loss: 0.006815162855200469\n",
      "Training Loss: 0.006613455046899617\n",
      "Validation Loss: 0.004533765575942698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0066503965575248\n",
      "Training Loss: 0.006776419818634167\n",
      "Training Loss: 0.0065720457513816655\n",
      "Validation Loss: 0.004483501746690717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.006612330542411655\n",
      "Training Loss: 0.006738524661632255\n",
      "Training Loss: 0.006532094914000482\n",
      "Validation Loss: 0.004436586433472217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.006575220898957923\n",
      "Training Loss: 0.006701469473773614\n",
      "Training Loss: 0.006493558968650177\n",
      "Validation Loss: 0.004392742702549093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.006539092130842619\n",
      "Training Loss: 0.006665309679228812\n",
      "Training Loss: 0.006456454811850563\n",
      "Validation Loss: 0.004351745071177361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0065040103817591444\n",
      "Training Loss: 0.0066301351774018255\n",
      "Training Loss: 0.006420823051594198\n",
      "Validation Loss: 0.00431339185111999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006470057062106207\n",
      "Training Loss: 0.006596041131997481\n",
      "Training Loss: 0.006386708505451679\n",
      "Validation Loss: 0.004277491911963215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006437308792956173\n",
      "Training Loss: 0.006563111670548096\n",
      "Training Loss: 0.006354139233008027\n",
      "Validation Loss: 0.004243857281549384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006405826227855869\n",
      "Training Loss: 0.0065314144443254915\n",
      "Training Loss: 0.006323123970068991\n",
      "Validation Loss: 0.004212304497179523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006375647833338007\n",
      "Training Loss: 0.006500992445508018\n",
      "Training Loss: 0.006293647760758176\n",
      "Validation Loss: 0.004182647035347319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006346793412230909\n",
      "Training Loss: 0.0064718744729179885\n",
      "Training Loss: 0.006265678885392844\n",
      "Validation Loss: 0.0041547229643021655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00631926583009772\n",
      "Training Loss: 0.006444073612801731\n",
      "Training Loss: 0.006239173555513844\n",
      "Validation Loss: 0.004128381790425838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006293057065922767\n",
      "Training Loss: 0.006417592754587531\n",
      "Training Loss: 0.006214080066420138\n",
      "Validation Loss: 0.004103489063831904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006268148680683225\n",
      "Training Loss: 0.006392425156664103\n",
      "Training Loss: 0.006190345603972674\n",
      "Validation Loss: 0.004079938740626479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006244517329032533\n",
      "Training Loss: 0.006368558267131448\n",
      "Training Loss: 0.006167913551907986\n",
      "Validation Loss: 0.0040576305996438255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00622213335998822\n",
      "Training Loss: 0.006345972039271146\n",
      "Training Loss: 0.006146728944731877\n",
      "Validation Loss: 0.00403648787871359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006200963406590745\n",
      "Training Loss: 0.006324639112572186\n",
      "Training Loss: 0.006126737284939736\n",
      "Validation Loss: 0.0040164356057144955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00618096980615519\n",
      "Training Loss: 0.006304527446627617\n",
      "Training Loss: 0.006107882645446807\n",
      "Validation Loss: 0.003997414398695122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006162109993747436\n",
      "Training Loss: 0.00628559767617844\n",
      "Training Loss: 0.006090112558449618\n",
      "Validation Loss: 0.00397938523857509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00614434126066044\n",
      "Training Loss: 0.0062678033020347355\n",
      "Training Loss: 0.006073371894308366\n",
      "Validation Loss: 0.0039622898905517095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006127614647266455\n",
      "Training Loss: 0.006251092334277928\n",
      "Training Loss: 0.006057606985559687\n",
      "Validation Loss: 0.003946094085028123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006111880515818484\n",
      "Training Loss: 0.006235414458205924\n",
      "Training Loss: 0.006042764589656144\n",
      "Validation Loss: 0.003930749947511266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006097088122041896\n",
      "Training Loss: 0.006220708796754479\n",
      "Training Loss: 0.006028791752760299\n",
      "Validation Loss: 0.003916224141361903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006083185597672128\n",
      "Training Loss: 0.006206920283148065\n",
      "Training Loss: 0.0060156375903170555\n",
      "Validation Loss: 0.0039024774234982604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006070122773526237\n",
      "Training Loss: 0.006193992457701825\n",
      "Training Loss: 0.006003253930830396\n",
      "Validation Loss: 0.0038894661277103543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006057847675983794\n",
      "Training Loss: 0.006181868314743042\n",
      "Training Loss: 0.005991591385100037\n",
      "Validation Loss: 0.003877164258718428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006046312984544784\n",
      "Training Loss: 0.006170491277007386\n",
      "Training Loss: 0.005980603917269036\n",
      "Validation Loss: 0.0038655266719033127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006035469496855512\n",
      "Training Loss: 0.00615980978240259\n",
      "Training Loss: 0.00597024843445979\n",
      "Validation Loss: 0.0038545237258312114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006025271528633311\n",
      "Training Loss: 0.0061497731145937\n",
      "Training Loss: 0.005960480858921074\n",
      "Validation Loss: 0.003844117966815411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006015675613307394\n",
      "Training Loss: 0.006140332591021433\n",
      "Training Loss: 0.005951262500602752\n",
      "Validation Loss: 0.0038342720595465744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006006639037514106\n",
      "Training Loss: 0.00613144182250835\n",
      "Training Loss: 0.005942553243949078\n",
      "Validation Loss: 0.0038249595175769307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0059981210133992135\n",
      "Training Loss: 0.006123057937365957\n",
      "Training Loss: 0.005934318023500964\n",
      "Validation Loss: 0.0038161409218936864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.005990085818921216\n",
      "Training Loss: 0.00611514178046491\n",
      "Training Loss: 0.005926523043308407\n",
      "Validation Loss: 0.0038077890172501334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.005982496258802712\n",
      "Training Loss: 0.0061076555686304344\n",
      "Training Loss: 0.005919135358999484\n",
      "Validation Loss: 0.0037998691301928894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.005975318296113983\n",
      "Training Loss: 0.006100564059452153\n",
      "Training Loss: 0.005912123479647562\n",
      "Validation Loss: 0.0037923509933922984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00596852108486928\n",
      "Training Loss: 0.006093835505307652\n",
      "Training Loss: 0.00590545978397131\n",
      "Validation Loss: 0.0037852086292271075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.005962075262214057\n",
      "Training Loss: 0.0060874397814041\n",
      "Training Loss: 0.005899117434164509\n",
      "Validation Loss: 0.003778414766100141\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.005955951595678926\n",
      "Training Loss: 0.006081348880543374\n",
      "Training Loss: 0.005893071080790833\n",
      "Validation Loss: 0.003771943677860323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.005950126486131921\n",
      "Training Loss: 0.006075538133154623\n",
      "Training Loss: 0.0058872980397427456\n",
      "Validation Loss: 0.003765766298937287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.005944574375171215\n",
      "Training Loss: 0.006069983647321351\n",
      "Training Loss: 0.00588177565659862\n",
      "Validation Loss: 0.0037598671199324846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.005939273504191078\n",
      "Training Loss: 0.0060646621993510055\n",
      "Training Loss: 0.0058764840161893515\n",
      "Validation Loss: 0.0037542180226215823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.005934202487114817\n",
      "Training Loss: 0.006059556005639024\n",
      "Training Loss: 0.005871403351775371\n",
      "Validation Loss: 0.003748806702297474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.005929342592135072\n",
      "Training Loss: 0.006054644467658363\n",
      "Training Loss: 0.00586651808291208\n",
      "Validation Loss: 0.003743608523058192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.005924675841233693\n",
      "Training Loss: 0.0060499124601483345\n",
      "Training Loss: 0.005861810455680825\n",
      "Validation Loss: 0.0037386062462798457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00592018645547796\n",
      "Training Loss: 0.006045344285666943\n",
      "Training Loss: 0.005857266558450647\n",
      "Validation Loss: 0.003733785158504596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.005915858790976927\n",
      "Training Loss: 0.006040926082641817\n",
      "Training Loss: 0.005852872156538069\n",
      "Validation Loss: 0.0037291329896883265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.005911679357523098\n",
      "Training Loss: 0.00603664398600813\n",
      "Training Loss: 0.005848615164286457\n",
      "Validation Loss: 0.003724633514609062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00590763523010537\n",
      "Training Loss: 0.006032486902549863\n",
      "Training Loss: 0.0058444848289946096\n",
      "Validation Loss: 0.0037202753821189067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0059037149185314775\n",
      "Training Loss: 0.006028444759431295\n",
      "Training Loss: 0.005840469131362625\n",
      "Validation Loss: 0.0037160452718197714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.005899907769053243\n",
      "Training Loss: 0.006024506155517884\n",
      "Training Loss: 0.005836559993331321\n",
      "Validation Loss: 0.0037119402962192643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005896203964948654\n",
      "Training Loss: 0.006020663359668106\n",
      "Training Loss: 0.00583274646254722\n",
      "Validation Loss: 0.0037079427209473475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.005892594654578715\n",
      "Training Loss: 0.00601690802956\n",
      "Training Loss: 0.005829022828256711\n",
      "Validation Loss: 0.0037040424198330787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005889071283163503\n",
      "Training Loss: 0.0060132323298603295\n",
      "Training Loss: 0.005825380141614005\n",
      "Validation Loss: 0.0037002426106482744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005885626852978021\n",
      "Training Loss: 0.0060096300765872\n",
      "Training Loss: 0.0058218124450650065\n",
      "Validation Loss: 0.003696524835678257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005882254395983182\n",
      "Training Loss: 0.0060060945228906345\n",
      "Training Loss: 0.005818312849733047\n",
      "Validation Loss: 0.0036928854853940313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005878947227611207\n",
      "Training Loss: 0.006002619204809889\n",
      "Training Loss: 0.0058148754620924595\n",
      "Validation Loss: 0.0036893225428020434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005875700082979165\n",
      "Training Loss: 0.005999201426748186\n",
      "Training Loss: 0.0058114964939886705\n",
      "Validation Loss: 0.003685825341511936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.005872507658204995\n",
      "Training Loss: 0.0059958355978596955\n",
      "Training Loss: 0.005808169562951662\n",
      "Validation Loss: 0.0036823888495041246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0058693645009770985\n",
      "Training Loss: 0.0059925159957492724\n",
      "Training Loss: 0.005804890521103516\n",
      "Validation Loss: 0.003679010297009575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00586626700416673\n",
      "Training Loss: 0.005989240587805398\n",
      "Training Loss: 0.005801657901029103\n",
      "Validation Loss: 0.003675691298800364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.005863212202093564\n",
      "Training Loss: 0.0059860042366199195\n",
      "Training Loss: 0.0057984647527337075\n",
      "Validation Loss: 0.003672413888983847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.005860194790293463\n",
      "Training Loss: 0.005982805257081054\n",
      "Training Loss: 0.005795309325912967\n",
      "Validation Loss: 0.0036691890459172845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005857211424154229\n",
      "Training Loss: 0.00597963890817482\n",
      "Training Loss: 0.005792188605992124\n",
      "Validation Loss: 0.0036660065113179635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005854260002961382\n",
      "Training Loss: 0.005976504011778161\n",
      "Training Loss: 0.00578909959003795\n",
      "Validation Loss: 0.003662864397688026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005851337313069962\n",
      "Training Loss: 0.005973396546323784\n",
      "Training Loss: 0.005786039652302861\n",
      "Validation Loss: 0.0036597558378315205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005848440752597526\n",
      "Training Loss: 0.005970316611928865\n",
      "Training Loss: 0.005783006550045684\n",
      "Validation Loss: 0.0036566800685086695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.0058455672761192545\n",
      "Training Loss: 0.005967260750476271\n",
      "Training Loss: 0.005779997371719219\n",
      "Validation Loss: 0.0036536391936975083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005842716307379306\n",
      "Training Loss: 0.0059642271255142985\n",
      "Training Loss: 0.00577701129601337\n",
      "Validation Loss: 0.003650626435148624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.005839884608867578\n",
      "Training Loss: 0.00596121384005528\n",
      "Training Loss: 0.005774046023143456\n",
      "Validation Loss: 0.003647644348766948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005837070491397753\n",
      "Training Loss: 0.00595821920200251\n",
      "Training Loss: 0.00577109946985729\n",
      "Validation Loss: 0.003644686371475207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005834272776846774\n",
      "Training Loss: 0.005955242195050232\n",
      "Training Loss: 0.005768170884111896\n",
      "Validation Loss: 0.003641749390144571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.005831489416304975\n",
      "Training Loss: 0.005952281554345973\n",
      "Training Loss: 0.00576525860989932\n",
      "Validation Loss: 0.0036388424995585523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005828719395794906\n",
      "Training Loss: 0.005949335448094644\n",
      "Training Loss: 0.005762361383531243\n",
      "Validation Loss: 0.0036359526899779277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005825961796217598\n",
      "Training Loss: 0.005946402585250326\n",
      "Training Loss: 0.005759477324900218\n",
      "Validation Loss: 0.0036330826095242598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.005823214136180468\n",
      "Training Loss: 0.005943482586299069\n",
      "Training Loss: 0.00575660570000764\n",
      "Validation Loss: 0.0036302340521707378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005820476565277204\n",
      "Training Loss: 0.005940574726555497\n",
      "Training Loss: 0.005753745858673938\n",
      "Validation Loss: 0.0036273982023998174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.00581774802703876\n",
      "Training Loss: 0.005937677408219315\n",
      "Training Loss: 0.005750896550598555\n",
      "Validation Loss: 0.003624579045147206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005815025958581827\n",
      "Training Loss: 0.005934790063183755\n",
      "Training Loss: 0.005748056945158168\n",
      "Validation Loss: 0.003621776515665056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00581231094605755\n",
      "Training Loss: 0.005931911400402896\n",
      "Training Loss: 0.005745226176222786\n",
      "Validation Loss: 0.003618988533520004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005809601423097774\n",
      "Training Loss: 0.005929040893679485\n",
      "Training Loss: 0.005742402542964555\n",
      "Validation Loss: 0.003616209147796244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005806897038128227\n",
      "Training Loss: 0.005926177970832214\n",
      "Training Loss: 0.005739585788105615\n",
      "Validation Loss: 0.003613444288480985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005804196606623009\n",
      "Training Loss: 0.005923321457230486\n",
      "Training Loss: 0.005736776270787232\n",
      "Validation Loss: 0.003610692149174682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005801499552326277\n",
      "Training Loss: 0.005920471038552933\n",
      "Training Loss: 0.0057339716836577286\n",
      "Validation Loss: 0.003607949504257295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005798805648228153\n",
      "Training Loss: 0.00591762576950714\n",
      "Training Loss: 0.005731172955129296\n",
      "Validation Loss: 0.003605214821363098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005796113320975564\n",
      "Training Loss: 0.005914786239736713\n",
      "Training Loss: 0.005728377879131585\n",
      "Validation Loss: 0.0036024912260472775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005793422386050224\n",
      "Training Loss: 0.0059119503508554775\n",
      "Training Loss: 0.0057255874393740665\n",
      "Validation Loss: 0.003599774815126458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005790732632158324\n",
      "Training Loss: 0.005909118722192943\n",
      "Training Loss: 0.005722799758077599\n",
      "Validation Loss: 0.0035970645637533973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0057880432123783975\n",
      "Training Loss: 0.005906290653510951\n",
      "Training Loss: 0.005720015004044399\n",
      "Validation Loss: 0.003594363891137659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005785353919491172\n",
      "Training Loss: 0.005903465413721279\n",
      "Training Loss: 0.005717232906608843\n",
      "Validation Loss: 0.0035916669411961448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0057826639100676406\n",
      "Training Loss: 0.005900642611668445\n",
      "Training Loss: 0.005714452433167026\n",
      "Validation Loss: 0.003588973708696705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005779972005984746\n",
      "Training Loss: 0.005897822142578661\n",
      "Training Loss: 0.005711673314217478\n",
      "Validation Loss: 0.003586287320502563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.005777279182220809\n",
      "Training Loss: 0.005895001867902466\n",
      "Training Loss: 0.00570889474125579\n",
      "Validation Loss: 0.0035836035006397058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005774583558086306\n",
      "Training Loss: 0.005892182816169224\n",
      "Training Loss: 0.0057061159977456555\n",
      "Validation Loss: 0.003580922761858765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.0057718850771198045\n",
      "Training Loss: 0.00588936498388648\n",
      "Training Loss: 0.005703338462626562\n",
      "Validation Loss: 0.0035782465273043497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005769183511729352\n",
      "Training Loss: 0.005886546910041943\n",
      "Training Loss: 0.005700559371616691\n",
      "Validation Loss: 0.0035755707400986986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005766477557481267\n",
      "Training Loss: 0.005883728408953175\n",
      "Training Loss: 0.005697778589092195\n",
      "Validation Loss: 0.0035728927946314633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005763767528696917\n",
      "Training Loss: 0.0058809092780575155\n",
      "Training Loss: 0.005694995851954445\n",
      "Validation Loss: 0.0035702176706007356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005761052678572014\n",
      "Training Loss: 0.005878089471370913\n",
      "Training Loss: 0.005692211578134447\n",
      "Validation Loss: 0.0035675407251280346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005758332409895956\n",
      "Training Loss: 0.005875266920775175\n",
      "Training Loss: 0.005689425052842125\n",
      "Validation Loss: 0.0035648649464246262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005755605233134702\n",
      "Training Loss: 0.005872443001717329\n",
      "Training Loss: 0.005686633727164008\n",
      "Validation Loss: 0.0035621852043681264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0057528712012572215\n",
      "Training Loss: 0.005869615284027531\n",
      "Training Loss: 0.0056838391342898835\n",
      "Validation Loss: 0.0035595031124225746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.005750129834632389\n",
      "Training Loss: 0.00586678454594221\n",
      "Training Loss: 0.005681038959883153\n",
      "Validation Loss: 0.0035568176620911934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.00574738034978509\n",
      "Training Loss: 0.005863949310150929\n",
      "Training Loss: 0.00567823335994035\n",
      "Validation Loss: 0.0035541256218677743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005744621913181618\n",
      "Training Loss: 0.005861110020196065\n",
      "Training Loss: 0.0056754222058225424\n",
      "Validation Loss: 0.0035514273704291225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005741853526560589\n",
      "Training Loss: 0.005858264368143864\n",
      "Training Loss: 0.005672603182611056\n",
      "Validation Loss: 0.003548725093505607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005739074546727352\n",
      "Training Loss: 0.00585541243199259\n",
      "Training Loss: 0.0056697764294222\n",
      "Validation Loss: 0.003546010148240609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005736282952711918\n",
      "Training Loss: 0.0058525535743683575\n",
      "Training Loss: 0.005666940447408706\n",
      "Validation Loss: 0.003543290151989485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.0057334787619765844\n",
      "Training Loss: 0.005849686827277764\n",
      "Training Loss: 0.005664093618397601\n",
      "Validation Loss: 0.003540557504401364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005730660221306607\n",
      "Training Loss: 0.005846810859511606\n",
      "Training Loss: 0.005661236637970433\n",
      "Validation Loss: 0.00353781389022832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.005727827055961825\n",
      "Training Loss: 0.005843926100642421\n",
      "Training Loss: 0.005658367805881426\n",
      "Validation Loss: 0.0035350558058923802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005724977075587958\n",
      "Training Loss: 0.005841028337017633\n",
      "Training Loss: 0.005655483746668324\n",
      "Validation Loss: 0.003532282923730195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005722108251065947\n",
      "Training Loss: 0.005838119575055316\n",
      "Training Loss: 0.005652583907358348\n",
      "Validation Loss: 0.003529490085496578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.0057192195544485\n",
      "Training Loss: 0.0058351958403363826\n",
      "Training Loss: 0.005649667105753906\n",
      "Validation Loss: 0.0035266772539124646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.00571630899910815\n",
      "Training Loss: 0.0058322577673243356\n",
      "Training Loss: 0.005646730187581852\n",
      "Validation Loss: 0.003523842161495155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005713374241604469\n",
      "Training Loss: 0.005829301835619844\n",
      "Training Loss: 0.005643772116163745\n",
      "Validation Loss: 0.0035209817742520755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005710413053166121\n",
      "Training Loss: 0.005826327110407874\n",
      "Training Loss: 0.005640789290773682\n",
      "Validation Loss: 0.0035180911105230786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005707423157873564\n",
      "Training Loss: 0.005823331119026989\n",
      "Training Loss: 0.005637780873221345\n",
      "Validation Loss: 0.003515173751060338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0057044016371946785\n",
      "Training Loss: 0.005820311970892362\n",
      "Training Loss: 0.005634743326227181\n",
      "Validation Loss: 0.003512221888189068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005701345310662873\n",
      "Training Loss: 0.005817266207304783\n",
      "Training Loss: 0.0056316723441705106\n",
      "Validation Loss: 0.003509230323114924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005698252431466244\n",
      "Training Loss: 0.005814192776451819\n",
      "Training Loss: 0.005628565378137864\n",
      "Validation Loss: 0.0035061947903281938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005695117773720995\n",
      "Training Loss: 0.005811087139882147\n",
      "Training Loss: 0.005625418220297433\n",
      "Validation Loss: 0.003503113223783923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005691937470110133\n",
      "Training Loss: 0.005807945825508796\n",
      "Training Loss: 0.005622226193081587\n",
      "Validation Loss: 0.0034999771153533393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005688707413501106\n",
      "Training Loss: 0.005804765927023254\n",
      "Training Loss: 0.005618984608445316\n",
      "Validation Loss: 0.0034967818718633793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.00568542247347068\n",
      "Training Loss: 0.00580154407187365\n",
      "Training Loss: 0.005615688520483672\n",
      "Validation Loss: 0.003493522581633892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00568207849515602\n",
      "Training Loss: 0.005798274649423547\n",
      "Training Loss: 0.005612331942538731\n",
      "Validation Loss: 0.0034901925913330295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005678670026827604\n",
      "Training Loss: 0.005794953457079827\n",
      "Training Loss: 0.0056089091929607095\n",
      "Validation Loss: 0.003486785447104635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005675190742476843\n",
      "Training Loss: 0.005791575631592423\n",
      "Training Loss: 0.005605413382872939\n",
      "Validation Loss: 0.0034832919442900614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005671634918544441\n",
      "Training Loss: 0.005788136415067129\n",
      "Training Loss: 0.005601837181602605\n",
      "Validation Loss: 0.003479703807591178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005667995862313546\n",
      "Training Loss: 0.005784628962283022\n",
      "Training Loss: 0.005598173942416906\n",
      "Validation Loss: 0.0034760130658285336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005664267230313272\n",
      "Training Loss: 0.005781047632335685\n",
      "Training Loss: 0.005594415102386847\n",
      "Validation Loss: 0.003472214858335432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005660442194202915\n",
      "Training Loss: 0.005777387019479647\n",
      "Training Loss: 0.005590552525827661\n",
      "Validation Loss: 0.0034682946730917844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005656513951835223\n",
      "Training Loss: 0.005773640383849852\n",
      "Training Loss: 0.005586578155634925\n",
      "Validation Loss: 0.0034642451680840904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005652475863462314\n",
      "Training Loss: 0.005769802636350505\n",
      "Training Loss: 0.005582484693732113\n",
      "Validation Loss: 0.003460058635048401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005648321660119109\n",
      "Training Loss: 0.00576586696319282\n",
      "Training Loss: 0.005578263274510391\n",
      "Validation Loss: 0.003455726250618947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005644045312074013\n",
      "Training Loss: 0.005761829175171442\n",
      "Training Loss: 0.005573906273348257\n",
      "Validation Loss: 0.003451240205812906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005639641575980931\n",
      "Training Loss: 0.0057576831598998976\n",
      "Training Loss: 0.005569407713483088\n",
      "Validation Loss: 0.0034465960827342163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005635106209083461\n",
      "Training Loss: 0.005753425480797887\n",
      "Training Loss: 0.0055647627200232815\n",
      "Validation Loss: 0.0034417881652597715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005630437268991955\n",
      "Training Loss: 0.005749052840983495\n",
      "Training Loss: 0.005559966900036671\n",
      "Validation Loss: 0.003436813166291777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0056256333529017865\n",
      "Training Loss: 0.005744564588530921\n",
      "Training Loss: 0.005555018929298967\n",
      "Validation Loss: 0.0034316765089529785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005620696130790748\n",
      "Training Loss: 0.005739960903301835\n",
      "Training Loss: 0.005549917907919735\n",
      "Validation Loss: 0.0034263721141399124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0056156272848602385\n",
      "Training Loss: 0.005735243473318405\n",
      "Training Loss: 0.005544666990754194\n",
      "Validation Loss: 0.0034209101211038952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.0056104320997837935\n",
      "Training Loss: 0.00573041531664785\n",
      "Training Loss: 0.005539270702865906\n",
      "Validation Loss: 0.0034152985101806397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005605118941748515\n",
      "Training Loss: 0.0057254822825780136\n",
      "Training Loss: 0.005533736370271072\n",
      "Validation Loss: 0.003409546703817009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005599696119897999\n",
      "Training Loss: 0.005720452726236545\n",
      "Training Loss: 0.005528074579779059\n",
      "Validation Loss: 0.003403669722859612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0055941755406092855\n",
      "Training Loss: 0.005715334312408231\n",
      "Training Loss: 0.0055222972395131366\n",
      "Validation Loss: 0.003397686058378077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005588570454274304\n",
      "Training Loss: 0.005710137997521087\n",
      "Training Loss: 0.005516417928738519\n",
      "Validation Loss: 0.0033916091040205837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005582894760882482\n",
      "Training Loss: 0.005704874356160872\n",
      "Training Loss: 0.005510454445029609\n",
      "Validation Loss: 0.003385462101648321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005577164582791738\n",
      "Training Loss: 0.005699556630570441\n",
      "Training Loss: 0.0055044200317934154\n",
      "Validation Loss: 0.00337925993410996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.0055713927565375345\n",
      "Training Loss: 0.005694196445401758\n",
      "Training Loss: 0.005498332470306195\n",
      "Validation Loss: 0.0033730214194844614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005565595564548858\n",
      "Training Loss: 0.005688805248355493\n",
      "Training Loss: 0.005492206240887754\n",
      "Validation Loss: 0.0033667658742130052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005559785873047076\n",
      "Training Loss: 0.005683393654762768\n",
      "Training Loss: 0.0054860588727751744\n",
      "Validation Loss: 0.003360512304731927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005553977834642865\n",
      "Training Loss: 0.005677974951104261\n",
      "Training Loss: 0.0054799046524567525\n",
      "Validation Loss: 0.0033542706658592804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005548180908081121\n",
      "Training Loss: 0.0056725549628026785\n",
      "Training Loss: 0.0054737549589481205\n",
      "Validation Loss: 0.003348055446070483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005542406305903569\n",
      "Training Loss: 0.005667143993778154\n",
      "Training Loss: 0.005467620770214125\n",
      "Validation Loss: 0.0033418799507211935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.0055366618669359016\n",
      "Training Loss: 0.005661749306018465\n",
      "Training Loss: 0.005461513615446165\n",
      "Validation Loss: 0.0033357421170365524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.0055309530894737695\n",
      "Training Loss: 0.005656374879763461\n",
      "Training Loss: 0.005455437830532901\n",
      "Validation Loss: 0.0033296576316541667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005525284785544499\n",
      "Training Loss: 0.005651026096893474\n",
      "Training Loss: 0.005449401196674444\n",
      "Validation Loss: 0.0033236255102759497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005519659138517454\n",
      "Training Loss: 0.00564570562040899\n",
      "Training Loss: 0.005443406755221076\n",
      "Validation Loss: 0.0033176478758464786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0055140798154752705\n",
      "Training Loss: 0.005640416520182043\n",
      "Training Loss: 0.005437458484084346\n",
      "Validation Loss: 0.003311728911469115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0055085467983735726\n",
      "Training Loss: 0.005635159855009988\n",
      "Training Loss: 0.005431555981631391\n",
      "Validation Loss: 0.0033058600625797603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.0055030581401661035\n",
      "Training Loss: 0.0056299353361828255\n",
      "Training Loss: 0.005425700275227427\n",
      "Validation Loss: 0.0033000443670951\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005497612706385553\n",
      "Training Loss: 0.005624742920626886\n",
      "Training Loss: 0.005419890262419358\n",
      "Validation Loss: 0.0032942799957249354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005492208999930881\n",
      "Training Loss: 0.005619582690997049\n",
      "Training Loss: 0.005414124456583522\n",
      "Validation Loss: 0.003288560087159485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.0054868435766547916\n",
      "Training Loss: 0.005614453430171125\n",
      "Training Loss: 0.005408400984597392\n",
      "Validation Loss: 0.0032828827460526667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005481513970880769\n",
      "Training Loss: 0.00560935415851418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [13:00<13:01, 156.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005402717331890017\n",
      "Validation Loss: 0.00327724544527637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5749476671218872\n",
      "Training Loss: 0.42049380019307137\n",
      "Training Loss: 0.3000352159887552\n",
      "Validation Loss: 0.21290082459369403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.17799392949789763\n",
      "Training Loss: 0.12488627322018146\n",
      "Training Loss: 0.08823711948469282\n",
      "Validation Loss: 0.06957313405831209\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06373000966385006\n",
      "Training Loss: 0.05778463952243328\n",
      "Training Loss: 0.055944012384861706\n",
      "Validation Loss: 0.0558721192515968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05351673087105155\n",
      "Training Loss: 0.0510737108066678\n",
      "Training Loss: 0.049237092128023505\n",
      "Validation Loss: 0.047685406401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.044890328869223596\n",
      "Training Loss: 0.041421574121341107\n",
      "Training Loss: 0.03817456188611686\n",
      "Validation Loss: 0.034982932658259115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.032658911566250025\n",
      "Training Loss: 0.029576056664809586\n",
      "Training Loss: 0.026654918426647783\n",
      "Validation Loss: 0.02391943662542473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.022668975689448416\n",
      "Training Loss: 0.02134234954137355\n",
      "Training Loss: 0.020071634529158472\n",
      "Validation Loss: 0.01903618621807336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01868297784589231\n",
      "Training Loss: 0.018431833782233297\n",
      "Training Loss: 0.017877894402481616\n",
      "Validation Loss: 0.01716495245653257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.017081761891022326\n",
      "Training Loss: 0.016907740975730123\n",
      "Training Loss: 0.016525366383139044\n",
      "Validation Loss: 0.015747017412854548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.015852073673158884\n",
      "Training Loss: 0.015674363195430488\n",
      "Training Loss: 0.01541984139708802\n",
      "Validation Loss: 0.014556093826848134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01483620201703161\n",
      "Training Loss: 0.01465880246134475\n",
      "Training Loss: 0.0145196611341089\n",
      "Validation Loss: 0.013580277389480491\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0140175226284191\n",
      "Training Loss: 0.013845094500575215\n",
      "Training Loss: 0.013797297647688538\n",
      "Validation Loss: 0.01279032758824276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013358545741066336\n",
      "Training Loss: 0.01319191612303257\n",
      "Training Loss: 0.013204838341334835\n",
      "Validation Loss: 0.012134737709244147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.012807099199853837\n",
      "Training Loss: 0.01264545002952218\n",
      "Training Loss: 0.012692165840417147\n",
      "Validation Loss: 0.011561880285820265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.012317336399573832\n",
      "Training Loss: 0.012160381502471864\n",
      "Training Loss: 0.012222040402702987\n",
      "Validation Loss: 0.011034187523313286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.011859135704580694\n",
      "Training Loss: 0.011707860094029457\n",
      "Training Loss: 0.011772990331519396\n",
      "Validation Loss: 0.010530225349213468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.011417163265869022\n",
      "Training Loss: 0.011273638580460101\n",
      "Training Loss: 0.01133569875964895\n",
      "Validation Loss: 0.010040683504403307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.010986051673535257\n",
      "Training Loss: 0.01085284854983911\n",
      "Training Loss: 0.010907886226195842\n",
      "Validation Loss: 0.009563034663259397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.010565436806064098\n",
      "Training Loss: 0.010445060271304102\n",
      "Training Loss: 0.01049018355901353\n",
      "Validation Loss: 0.009097395689760366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.010156562502961606\n",
      "Training Loss: 0.010051159677095712\n",
      "Training Loss: 0.010083825894398615\n",
      "Validation Loss: 0.008644355378595045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.009760719826444983\n",
      "Training Loss: 0.009672040233854205\n",
      "Training Loss: 0.009689923878759145\n",
      "Validation Loss: 0.00820442340650669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009378976821899414\n",
      "Training Loss: 0.00930839458713308\n",
      "Training Loss: 0.009309473106404766\n",
      "Validation Loss: 0.00777807881208032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009012265730416403\n",
      "Training Loss: 0.008960712302941829\n",
      "Training Loss: 0.008943334307987242\n",
      "Validation Loss: 0.00736576149480815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008661247871350497\n",
      "Training Loss: 0.008629045811248943\n",
      "Training Loss: 0.008591868430376053\n",
      "Validation Loss: 0.00696749001835588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008325852218549699\n",
      "Training Loss: 0.008312538244063035\n",
      "Training Loss: 0.008254456436261534\n",
      "Validation Loss: 0.006582456756006466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008004885656991973\n",
      "Training Loss: 0.008009233205812052\n",
      "Training Loss: 0.0079294964147266\n",
      "Validation Loss: 0.006209390323603882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0076965724304318426\n",
      "Training Loss: 0.007717166540678591\n",
      "Training Loss: 0.007616106715286151\n",
      "Validation Loss: 0.005848998027288595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0074012936756480486\n",
      "Training Loss: 0.007437931069871411\n",
      "Training Loss: 0.007318306769011542\n",
      "Validation Loss: 0.005508672101344662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007126196621684357\n",
      "Training Loss: 0.00718110800604336\n",
      "Training Loss: 0.007048356261802838\n",
      "Validation Loss: 0.00520378208897087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.006885299514979124\n",
      "Training Loss: 0.006961407620110549\n",
      "Training Loss: 0.0068206536956131455\n",
      "Validation Loss: 0.0049479559719238135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.006689376999856904\n",
      "Training Loss: 0.0067869341187179084\n",
      "Training Loss: 0.006640345297055319\n",
      "Validation Loss: 0.004743170492178394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.006538297550287097\n",
      "Training Loss: 0.006654757460346446\n",
      "Training Loss: 0.00650243409560062\n",
      "Validation Loss: 0.004582299833876614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.006424571266979911\n",
      "Training Loss: 0.0065562457987107334\n",
      "Training Loss: 0.006397779695689678\n",
      "Validation Loss: 0.004455493037782484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.006338901430135593\n",
      "Training Loss: 0.006482144980691373\n",
      "Training Loss: 0.006317393796052784\n",
      "Validation Loss: 0.00435385926988949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.006273176450049505\n",
      "Training Loss: 0.006424930462380871\n",
      "Training Loss: 0.006254188637249172\n",
      "Validation Loss: 0.004270679331149153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.006221398967318237\n",
      "Training Loss: 0.006379282757407055\n",
      "Training Loss: 0.006203140616416931\n",
      "Validation Loss: 0.004201226867408377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.006179452333599329\n",
      "Training Loss: 0.0063416703720577065\n",
      "Training Loss: 0.0061608348571462555\n",
      "Validation Loss: 0.004142205028799938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.006144579098909162\n",
      "Training Loss: 0.006309779899893329\n",
      "Training Loss: 0.006124959398293868\n",
      "Validation Loss: 0.004091274160028467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.006114909350289963\n",
      "Training Loss: 0.006282077921787277\n",
      "Training Loss: 0.006093928230693563\n",
      "Validation Loss: 0.004046738679452768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.006089160729316063\n",
      "Training Loss: 0.006257529391441494\n",
      "Training Loss: 0.006066630242276006\n",
      "Validation Loss: 0.004007339289835706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00606643280829303\n",
      "Training Loss: 0.006235417411080562\n",
      "Training Loss: 0.006042273875209503\n",
      "Validation Loss: 0.0039721184303549775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006046082364628091\n",
      "Training Loss: 0.00621523980749771\n",
      "Training Loss: 0.006020284096593969\n",
      "Validation Loss: 0.003940349101060165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006027641391265206\n",
      "Training Loss: 0.006196631792699918\n",
      "Training Loss: 0.00600023846141994\n",
      "Validation Loss: 0.0039114687661117135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00601076713996008\n",
      "Training Loss: 0.006179331598686986\n",
      "Training Loss: 0.005981817406136542\n",
      "Validation Loss: 0.0038850339907195337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.005995198429445736\n",
      "Training Loss: 0.0061631396604934705\n",
      "Training Loss: 0.005964775537722744\n",
      "Validation Loss: 0.0038606917634056988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.005980736684869044\n",
      "Training Loss: 0.0061479031416820365\n",
      "Training Loss: 0.0059489188517909495\n",
      "Validation Loss: 0.003838154014129338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.005967225347994827\n",
      "Training Loss: 0.006133502177544869\n",
      "Training Loss: 0.005934095272677951\n",
      "Validation Loss: 0.003817192084231843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.005954539814847521\n",
      "Training Loss: 0.006119842928601429\n",
      "Training Loss: 0.005920176930376328\n",
      "Validation Loss: 0.0037976135486695035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0059425792330875995\n",
      "Training Loss: 0.006106847479823045\n",
      "Training Loss: 0.005907059490564279\n",
      "Validation Loss: 0.0037792531300592496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.005931258565979079\n",
      "Training Loss: 0.006094449904048815\n",
      "Training Loss: 0.005894657782628201\n",
      "Validation Loss: 0.0037619815779630136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.005920509264105931\n",
      "Training Loss: 0.006082598406937905\n",
      "Training Loss: 0.0058828962012194095\n",
      "Validation Loss: 0.0037456767534146482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.005910270232707262\n",
      "Training Loss: 0.006071243723854422\n",
      "Training Loss: 0.005871710766223259\n",
      "Validation Loss: 0.0037302451212811965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.0059004918881691995\n",
      "Training Loss: 0.006060344283469021\n",
      "Training Loss: 0.0058610467094695196\n",
      "Validation Loss: 0.003715596527706183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.005891129628289491\n",
      "Training Loss: 0.006049866484827362\n",
      "Training Loss: 0.005850856126635336\n",
      "Validation Loss: 0.0037016630865335256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00588214468152728\n",
      "Training Loss: 0.006039777077967301\n",
      "Training Loss: 0.0058410968107637014\n",
      "Validation Loss: 0.0036883736578642986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.005873502823524177\n",
      "Training Loss: 0.0060300481959711764\n",
      "Training Loss: 0.0058317298971815035\n",
      "Validation Loss: 0.003675671331610614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00586517452262342\n",
      "Training Loss: 0.00602065310580656\n",
      "Training Loss: 0.005822723445598968\n",
      "Validation Loss: 0.003663513494205525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0058571328723337505\n",
      "Training Loss: 0.006011567712412216\n",
      "Training Loss: 0.005814047057065182\n",
      "Validation Loss: 0.0036518483107459594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0058493541192729025\n",
      "Training Loss: 0.006002772649517283\n",
      "Training Loss: 0.00580567353637889\n",
      "Validation Loss: 0.0036406379717590517\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.005841816160827875\n",
      "Training Loss: 0.005994248028728179\n",
      "Training Loss: 0.005797580459038727\n",
      "Validation Loss: 0.003629849449956392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.005834500829223543\n",
      "Training Loss: 0.005985975770745427\n",
      "Training Loss: 0.005789745376678184\n",
      "Validation Loss: 0.0036194473053747264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.005827390128979459\n",
      "Training Loss: 0.005977940310840495\n",
      "Training Loss: 0.005782150282757356\n",
      "Validation Loss: 0.0036094090064171325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0058204694115556775\n",
      "Training Loss: 0.005970124929444864\n",
      "Training Loss: 0.0057747773989103735\n",
      "Validation Loss: 0.0035997018985858375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.005813724522595294\n",
      "Training Loss: 0.005962519135209732\n",
      "Training Loss: 0.005767610486946069\n",
      "Validation Loss: 0.0035903116091667267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.005807143241981976\n",
      "Training Loss: 0.005955107791232876\n",
      "Training Loss: 0.0057606366404797885\n",
      "Validation Loss: 0.0035812108505391673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.005800712936907076\n",
      "Training Loss: 0.00594788134272676\n",
      "Training Loss: 0.005753843003185466\n",
      "Validation Loss: 0.003572386295764885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.005794424933264963\n",
      "Training Loss: 0.00594082705094479\n",
      "Training Loss: 0.005747216930030845\n",
      "Validation Loss: 0.0035638162654332735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00578826847311575\n",
      "Training Loss: 0.005933936813380569\n",
      "Training Loss: 0.005740748526295647\n",
      "Validation Loss: 0.0035554901598638783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00578223590971902\n",
      "Training Loss: 0.005927201487356797\n",
      "Training Loss: 0.0057344285922590645\n",
      "Validation Loss: 0.0035473906769929978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00577631862834096\n",
      "Training Loss: 0.005920612794579938\n",
      "Training Loss: 0.005728247492224909\n",
      "Validation Loss: 0.003539503414675677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0057705113955307755\n",
      "Training Loss: 0.005914162109256722\n",
      "Training Loss: 0.005722198345465585\n",
      "Validation Loss: 0.003531820781717307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.005764806374209001\n",
      "Training Loss: 0.005907843358581886\n",
      "Training Loss: 0.0057162730867275965\n",
      "Validation Loss: 0.0035243285355534863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.005759198235464283\n",
      "Training Loss: 0.005901650728774257\n",
      "Training Loss: 0.005710465160664171\n",
      "Validation Loss: 0.003517017475449679\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.005753681343630888\n",
      "Training Loss: 0.00589557467319537\n",
      "Training Loss: 0.005704770390875638\n",
      "Validation Loss: 0.003509884717837604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.005748251302284188\n",
      "Training Loss: 0.005889613258186727\n",
      "Training Loss: 0.005699180123046972\n",
      "Validation Loss: 0.003502911644113993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.005742902666679583\n",
      "Training Loss: 0.005883760103024542\n",
      "Training Loss: 0.0056936911446973685\n",
      "Validation Loss: 0.0034960931169622568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.005737632623058744\n",
      "Training Loss: 0.005878009145963006\n",
      "Training Loss: 0.0056882978527573866\n",
      "Validation Loss: 0.003489428323437198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.005732436862890608\n",
      "Training Loss: 0.005872357668122277\n",
      "Training Loss: 0.005682995913666673\n",
      "Validation Loss: 0.0034829034591669196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.005727312084054574\n",
      "Training Loss: 0.005866800406365656\n",
      "Training Loss: 0.005677780731930398\n",
      "Validation Loss: 0.003476509903531438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.005722253409330733\n",
      "Training Loss: 0.005861335425288416\n",
      "Training Loss: 0.005672650256892666\n",
      "Validation Loss: 0.0034702493380127327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.005717260411474853\n",
      "Training Loss: 0.005855953434947878\n",
      "Training Loss: 0.005667599993757904\n",
      "Validation Loss: 0.0034641159640813476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0057123291509924455\n",
      "Training Loss: 0.005850657038390637\n",
      "Training Loss: 0.005662624862743541\n",
      "Validation Loss: 0.0034580938746953866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.005707456624368206\n",
      "Training Loss: 0.005845439748372883\n",
      "Training Loss: 0.005657724818447605\n",
      "Validation Loss: 0.0034521890940207444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.00570264104346279\n",
      "Training Loss: 0.005840299784904346\n",
      "Training Loss: 0.005652894628583454\n",
      "Validation Loss: 0.003446391397129661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.005697879820945673\n",
      "Training Loss: 0.005835233798134141\n",
      "Training Loss: 0.005648132367059589\n",
      "Validation Loss: 0.0034406999547264717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005693171275779605\n",
      "Training Loss: 0.0058302384446142245\n",
      "Training Loss: 0.005643435181700625\n",
      "Validation Loss: 0.0034351103711517507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0056885131628951055\n",
      "Training Loss: 0.005825311744702049\n",
      "Training Loss: 0.00563880183850415\n",
      "Validation Loss: 0.0034296167726638946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005683903116732836\n",
      "Training Loss: 0.0058204502338776365\n",
      "Training Loss: 0.005634228453272954\n",
      "Validation Loss: 0.003424212042885843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005679339753696695\n",
      "Training Loss: 0.005815652767778374\n",
      "Training Loss: 0.005629714271053672\n",
      "Validation Loss: 0.0034189019110210743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005674821771099232\n",
      "Training Loss: 0.005810916734626517\n",
      "Training Loss: 0.005625254997285083\n",
      "Validation Loss: 0.003413675985367069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005670347104314715\n",
      "Training Loss: 0.005806238820659928\n",
      "Training Loss: 0.005620849799597636\n",
      "Validation Loss: 0.0034085321573676603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005665914008859545\n",
      "Training Loss: 0.0058016185980523\n",
      "Training Loss: 0.00561649699928239\n",
      "Validation Loss: 0.00340346761605064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00566152096784208\n",
      "Training Loss: 0.005797052044072188\n",
      "Training Loss: 0.005612194626010023\n",
      "Validation Loss: 0.003398478285571707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0056571674830047415\n",
      "Training Loss: 0.005792539033573121\n",
      "Training Loss: 0.005607940327608958\n",
      "Validation Loss: 0.0033935655269436956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.0056528506375616416\n",
      "Training Loss: 0.00578807613463141\n",
      "Training Loss: 0.005603732540039346\n",
      "Validation Loss: 0.0033887242218165587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.005648570884368383\n",
      "Training Loss: 0.005783663269248791\n",
      "Training Loss: 0.005599569277255796\n",
      "Validation Loss: 0.003383950423841689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.005644324777531438\n",
      "Training Loss: 0.005779297686531209\n",
      "Training Loss: 0.005595450603868813\n",
      "Validation Loss: 0.003379243346234637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005640112656401471\n",
      "Training Loss: 0.005774977353867144\n",
      "Training Loss: 0.005591372481430881\n",
      "Validation Loss: 0.003374599618183219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0056359327823156495\n",
      "Training Loss: 0.005770700866123662\n",
      "Training Loss: 0.005587334111332894\n",
      "Validation Loss: 0.003370018527461111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005631783769349568\n",
      "Training Loss: 0.005766467560897581\n",
      "Training Loss: 0.0055833354528294875\n",
      "Validation Loss: 0.003365492193143438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005627664250787348\n",
      "Training Loss: 0.005762274742010049\n",
      "Training Loss: 0.005579372976208106\n",
      "Validation Loss: 0.0033610275314775494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.005623574001365341\n",
      "Training Loss: 0.005758119783713482\n",
      "Training Loss: 0.005575446046423167\n",
      "Validation Loss: 0.0033566185948177337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005619511298136786\n",
      "Training Loss: 0.005754003816982731\n",
      "Training Loss: 0.005571553960326128\n",
      "Validation Loss: 0.003352264200044231\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.005615476096863858\n",
      "Training Loss: 0.005749923474504612\n",
      "Training Loss: 0.005567694103810936\n",
      "Validation Loss: 0.0033479566408551476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.00561146508611273\n",
      "Training Loss: 0.005745878591551445\n",
      "Training Loss: 0.005563866491429508\n",
      "Validation Loss: 0.0033437011821007127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005607478456804529\n",
      "Training Loss: 0.005741867656470276\n",
      "Training Loss: 0.005560068979393691\n",
      "Validation Loss: 0.0033394964680002396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.005603516286355443\n",
      "Training Loss: 0.00573788835783489\n",
      "Training Loss: 0.005556299790041522\n",
      "Validation Loss: 0.003335333251383867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005599575687665492\n",
      "Training Loss: 0.005733940404606983\n",
      "Training Loss: 0.005552559777861461\n",
      "Validation Loss: 0.0033312158585850444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005595657044905238\n",
      "Training Loss: 0.005730022067436949\n",
      "Training Loss: 0.0055488441413035616\n",
      "Validation Loss: 0.0033271419573732224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.005591758181108162\n",
      "Training Loss: 0.005726132654235699\n",
      "Training Loss: 0.0055451550253201275\n",
      "Validation Loss: 0.003323108249532289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005587879156228155\n",
      "Training Loss: 0.005722271010745317\n",
      "Training Loss: 0.005541488938033581\n",
      "Validation Loss: 0.003319113693210516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.005584018268273212\n",
      "Training Loss: 0.005718434365116991\n",
      "Training Loss: 0.005537846427760087\n",
      "Validation Loss: 0.003315157793969795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005580175418290309\n",
      "Training Loss: 0.005714623929234222\n",
      "Training Loss: 0.005534226919990033\n",
      "Validation Loss: 0.003311238432789661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00557634954340756\n",
      "Training Loss: 0.0057108377933036535\n",
      "Training Loss: 0.005530626167310402\n",
      "Validation Loss: 0.0033073557685966487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005572539497516118\n",
      "Training Loss: 0.005707074796664529\n",
      "Training Loss: 0.005527046628994867\n",
      "Validation Loss: 0.0033035067974830443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.00556874517002143\n",
      "Training Loss: 0.005703332994598896\n",
      "Training Loss: 0.005523484688601457\n",
      "Validation Loss: 0.0032996902519606807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005564963446813636\n",
      "Training Loss: 0.005699612683383748\n",
      "Training Loss: 0.005519940835074522\n",
      "Validation Loss: 0.003295905687296868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005561196384951473\n",
      "Training Loss: 0.005695912683731877\n",
      "Training Loss: 0.005516414190060459\n",
      "Validation Loss: 0.0032921512388844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005557441426208243\n",
      "Training Loss: 0.005692231487482786\n",
      "Training Loss: 0.005512902858899906\n",
      "Validation Loss: 0.003288425452185774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005553698589792475\n",
      "Training Loss: 0.0056885671708732845\n",
      "Training Loss: 0.005509405442862772\n",
      "Validation Loss: 0.0032847279936514713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0055499670910649\n",
      "Training Loss: 0.0056849222222808745\n",
      "Training Loss: 0.005505922340671532\n",
      "Validation Loss: 0.003281056479383469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005546245928271674\n",
      "Training Loss: 0.005681293287780136\n",
      "Training Loss: 0.005502451843349263\n",
      "Validation Loss: 0.003277412500609173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005542534327832982\n",
      "Training Loss: 0.005677678469801321\n",
      "Training Loss: 0.005498992740176618\n",
      "Validation Loss: 0.003273792914768911\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.00553883103071712\n",
      "Training Loss: 0.005674080137978308\n",
      "Training Loss: 0.005495546653983183\n",
      "Validation Loss: 0.0032701958461371617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.005535136660328135\n",
      "Training Loss: 0.005670495367376134\n",
      "Training Loss: 0.005492108734324574\n",
      "Validation Loss: 0.003266619314345416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005531449826667085\n",
      "Training Loss: 0.005666923629469238\n",
      "Training Loss: 0.005488680465496145\n",
      "Validation Loss: 0.003263065123177144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00552777047327254\n",
      "Training Loss: 0.005663363463827409\n",
      "Training Loss: 0.005485261571011506\n",
      "Validation Loss: 0.00325953385209288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005524096076260321\n",
      "Training Loss: 0.005659816365805454\n",
      "Training Loss: 0.005481850185315124\n",
      "Validation Loss: 0.003256018704530689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005520427613519132\n",
      "Training Loss: 0.005656280051916838\n",
      "Training Loss: 0.005478445491171442\n",
      "Validation Loss: 0.003252525911980382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.0055167644884204494\n",
      "Training Loss: 0.005652752853929997\n",
      "Training Loss: 0.005475047504878603\n",
      "Validation Loss: 0.0032490501860470583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0055131057900143785\n",
      "Training Loss: 0.005649237113539129\n",
      "Training Loss: 0.0054716539039509375\n",
      "Validation Loss: 0.0032455903024077833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005509450738318264\n",
      "Training Loss: 0.005645727739902213\n",
      "Training Loss: 0.005468266255920753\n",
      "Validation Loss: 0.0032421433382531567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005505798603408039\n",
      "Training Loss: 0.00564222960267216\n",
      "Training Loss: 0.005464881705120206\n",
      "Validation Loss: 0.0032387147637952664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005502149074454792\n",
      "Training Loss: 0.00563873746083118\n",
      "Training Loss: 0.0054615007585380225\n",
      "Validation Loss: 0.003235298493390463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005498502238770016\n",
      "Training Loss: 0.005635253692162223\n",
      "Training Loss: 0.005458122316049412\n",
      "Validation Loss: 0.00323189597765214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0054948562534991655\n",
      "Training Loss: 0.005631775638321414\n",
      "Training Loss: 0.005454746035393327\n",
      "Validation Loss: 0.003228506593300511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.005491212186752819\n",
      "Training Loss: 0.005628303947742097\n",
      "Training Loss: 0.005451370928785764\n",
      "Validation Loss: 0.003225130123201381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0054875677288509905\n",
      "Training Loss: 0.0056248386687366295\n",
      "Training Loss: 0.005447996760485694\n",
      "Validation Loss: 0.0032217634189089113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005483923318679445\n",
      "Training Loss: 0.005621376230265014\n",
      "Training Loss: 0.005444622038630768\n",
      "Validation Loss: 0.003218403099146619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005480278884642757\n",
      "Training Loss: 0.00561792028893251\n",
      "Training Loss: 0.0054412466107169166\n",
      "Validation Loss: 0.0032150553973663725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005476633342914284\n",
      "Training Loss: 0.005614466486731544\n",
      "Training Loss: 0.005437870504683815\n",
      "Validation Loss: 0.0032117183057308782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005472986567765474\n",
      "Training Loss: 0.005611017117626033\n",
      "Training Loss: 0.005434491750784218\n",
      "Validation Loss: 0.0032083857883019058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00546933806152083\n",
      "Training Loss: 0.005607569112326019\n",
      "Training Loss: 0.005431111640064046\n",
      "Validation Loss: 0.0032050629241883836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005465686944662593\n",
      "Training Loss: 0.005604123686207458\n",
      "Training Loss: 0.0054277284711133685\n",
      "Validation Loss: 0.003201748320984581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0054620329313911494\n",
      "Training Loss: 0.0056006814166903495\n",
      "Training Loss: 0.00542434083414264\n",
      "Validation Loss: 0.003198435737390406\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005458374886657112\n",
      "Training Loss: 0.005597239751368761\n",
      "Training Loss: 0.005420949099352583\n",
      "Validation Loss: 0.0031951296089604247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005454714106745087\n",
      "Training Loss: 0.0055937990121310574\n",
      "Training Loss: 0.005417553644510917\n",
      "Validation Loss: 0.0031918302300030345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005451049564289861\n",
      "Training Loss: 0.005590358431218192\n",
      "Training Loss: 0.0054141529439948495\n",
      "Validation Loss: 0.003188532349402399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005447379851248115\n",
      "Training Loss: 0.0055869191681267695\n",
      "Training Loss: 0.0054107455140911045\n",
      "Validation Loss: 0.003185238081600852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005443705366924405\n",
      "Training Loss: 0.00558347822749056\n",
      "Training Loss: 0.005407331900205464\n",
      "Validation Loss: 0.0031819491041562616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.0054400260449619965\n",
      "Training Loss: 0.005580037267645821\n",
      "Training Loss: 0.005403912513866089\n",
      "Validation Loss: 0.0031786606813194963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.00543634022353217\n",
      "Training Loss: 0.005576595668098889\n",
      "Training Loss: 0.005400485318386927\n",
      "Validation Loss: 0.0031753743860054385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005432648729183711\n",
      "Training Loss: 0.005573151703574694\n",
      "Training Loss: 0.005397050890605897\n",
      "Validation Loss: 0.0031720881430128737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005428950760397129\n",
      "Training Loss: 0.005569705466041341\n",
      "Training Loss: 0.00539360775903333\n",
      "Validation Loss: 0.003168802734548121\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005425246638478712\n",
      "Training Loss: 0.005566257830359973\n",
      "Training Loss: 0.005390155833447352\n",
      "Validation Loss: 0.0031655160389746423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.0054215342621319\n",
      "Training Loss: 0.00556280646880623\n",
      "Training Loss: 0.005386695187189617\n",
      "Validation Loss: 0.003162231896036001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005417815123219043\n",
      "Training Loss: 0.005559352542622947\n",
      "Training Loss: 0.00538322519918438\n",
      "Validation Loss: 0.0031589431043327104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005414088569814339\n",
      "Training Loss: 0.00555589527124539\n",
      "Training Loss: 0.005379744852543809\n",
      "Validation Loss: 0.0031556554597781533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.0054103537654737015\n",
      "Training Loss: 0.005552433698321693\n",
      "Training Loss: 0.005376254599541426\n",
      "Validation Loss: 0.0031523635117808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005406609733472578\n",
      "Training Loss: 0.005548969177179969\n",
      "Training Loss: 0.005372753475676291\n",
      "Validation Loss: 0.0031490718450114716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005402857873123139\n",
      "Training Loss: 0.005545498975552618\n",
      "Training Loss: 0.005369241709704511\n",
      "Validation Loss: 0.0031457739323639215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005399097252520733\n",
      "Training Loss: 0.005542024717433378\n",
      "Training Loss: 0.005365717661334202\n",
      "Validation Loss: 0.0031424754585683595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005395327211008407\n",
      "Training Loss: 0.00553854554600548\n",
      "Training Loss: 0.005362181502277963\n",
      "Validation Loss: 0.0031391669344680195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005391546704922803\n",
      "Training Loss: 0.00553506133670453\n",
      "Training Loss: 0.005358633549767546\n",
      "Validation Loss: 0.0031358634816283843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005387757270946167\n",
      "Training Loss: 0.0055315710470313206\n",
      "Training Loss: 0.005355072288075462\n",
      "Validation Loss: 0.0031325478987046258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005383957028971054\n",
      "Training Loss: 0.005528075573965907\n",
      "Training Loss: 0.005351498225936666\n",
      "Validation Loss: 0.0031292282176999314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005380146692041308\n",
      "Training Loss: 0.005524573010625318\n",
      "Training Loss: 0.005347911694552749\n",
      "Validation Loss: 0.0031259052698720206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005376326250261627\n",
      "Training Loss: 0.0055210644361795855\n",
      "Training Loss: 0.005344309993670322\n",
      "Validation Loss: 0.0031225713155640477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005372494131443091\n",
      "Training Loss: 0.005517548983916641\n",
      "Training Loss: 0.0053406951623037454\n",
      "Validation Loss: 0.0031192352324253304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005368651059106924\n",
      "Training Loss: 0.005514026887831278\n",
      "Training Loss: 0.005337065306375735\n",
      "Validation Loss: 0.003115891838011991\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005364797267247923\n",
      "Training Loss: 0.00551049648609478\n",
      "Training Loss: 0.005333422204712406\n",
      "Validation Loss: 0.003112543691499054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005360931024770252\n",
      "Training Loss: 0.005506958880578168\n",
      "Training Loss: 0.0053297627880238\n",
      "Validation Loss: 0.0031091823573538174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005357053711195476\n",
      "Training Loss: 0.005503414123086259\n",
      "Training Loss: 0.0053260888229124245\n",
      "Validation Loss: 0.003105814150780481\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005353164332918822\n",
      "Training Loss: 0.00549986106925644\n",
      "Training Loss: 0.00532239911495708\n",
      "Validation Loss: 0.0031024380031125513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005349262301460839\n",
      "Training Loss: 0.005496300319791771\n",
      "Training Loss: 0.005318693466833792\n",
      "Validation Loss: 0.0030990517449701266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005345348613336682\n",
      "Training Loss: 0.0054927311354549604\n",
      "Training Loss: 0.005314971628249623\n",
      "Validation Loss: 0.0030956595084431133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005341421398334205\n",
      "Training Loss: 0.005489152032532729\n",
      "Training Loss: 0.005311233564279974\n",
      "Validation Loss: 0.003092258647372004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005337482591858134\n",
      "Training Loss: 0.005485565145500004\n",
      "Training Loss: 0.005307478496688418\n",
      "Validation Loss: 0.003088841915230026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005333529974450357\n",
      "Training Loss: 0.005481969541287981\n",
      "Training Loss: 0.0053037082159426065\n",
      "Validation Loss: 0.0030854226991251696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005329564939602278\n",
      "Training Loss: 0.005478363314177841\n",
      "Training Loss: 0.005299920404213481\n",
      "Validation Loss: 0.0030819930180677035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005325587271945551\n",
      "Training Loss: 0.005474749048589729\n",
      "Training Loss: 0.00529611476813443\n",
      "Validation Loss: 0.003078548105569619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005321595625136979\n",
      "Training Loss: 0.005471125862677582\n",
      "Training Loss: 0.005292292626108974\n",
      "Validation Loss: 0.0030750962519714756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005317590783233754\n",
      "Training Loss: 0.005467492463067174\n",
      "Training Loss: 0.005288452683598735\n",
      "Validation Loss: 0.0030716326633164807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005313573200255633\n",
      "Training Loss: 0.005463848662911914\n",
      "Training Loss: 0.005284595378907397\n",
      "Validation Loss: 0.0030681579099089075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005309541648020968\n",
      "Training Loss: 0.005460196008789353\n",
      "Training Loss: 0.005280720169539563\n",
      "Validation Loss: 0.0030646712370112203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005305496394867077\n",
      "Training Loss: 0.005456532432581298\n",
      "Training Loss: 0.005276826930348762\n",
      "Validation Loss: 0.0030611740854265316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.0053014370769960805\n",
      "Training Loss: 0.005452858214266598\n",
      "Training Loss: 0.005272915858076885\n",
      "Validation Loss: 0.0030576655676515167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005297364206635393\n",
      "Training Loss: 0.005449175039539114\n",
      "Training Loss: 0.005268987981253304\n",
      "Validation Loss: 0.0030541463337807255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.00529327817785088\n",
      "Training Loss: 0.005445481720962562\n",
      "Training Loss: 0.005265040107187815\n",
      "Validation Loss: 0.003050613721304186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005289178112288937\n",
      "Training Loss: 0.005441777617088519\n",
      "Training Loss: 0.005261075443122536\n",
      "Validation Loss: 0.0030470725104442976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005285064692725427\n",
      "Training Loss: 0.005438062928733416\n",
      "Training Loss: 0.005257091984385624\n",
      "Validation Loss: 0.0030435165547336757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0052809372782940045\n",
      "Training Loss: 0.005434337863698601\n",
      "Training Loss: 0.005253090659971349\n",
      "Validation Loss: 0.0030399484198875308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005276795757818036\n",
      "Training Loss: 0.005430602023261599\n",
      "Training Loss: 0.005249071200378239\n",
      "Validation Loss: 0.003036370735060884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005272641248884611\n",
      "Training Loss: 0.005426855884725228\n",
      "Training Loss: 0.005245033380342648\n",
      "Validation Loss: 0.003032778156267249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005268472724710591\n",
      "Training Loss: 0.005423099845647812\n",
      "Training Loss: 0.00524097670277115\n",
      "Validation Loss: 0.0030291754087914576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.00526429119578097\n",
      "Training Loss: 0.005419334427569993\n",
      "Training Loss: 0.005236903537879698\n",
      "Validation Loss: 0.003025559676429152\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0052600956952665\n",
      "Training Loss: 0.005415557307424023\n",
      "Training Loss: 0.005232811757596209\n",
      "Validation Loss: 0.003021932225360462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005255887971143239\n",
      "Training Loss: 0.00541177015635185\n",
      "Training Loss: 0.005228702772292308\n",
      "Validation Loss: 0.0030182943871673823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005251667184056714\n",
      "Training Loss: 0.005407973678666167\n",
      "Training Loss: 0.005224574644234963\n",
      "Validation Loss: 0.0030146408799952003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005247432349133305\n",
      "Training Loss: 0.005404165593208745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [15:35<10:23, 155.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005220430359477177\n",
      "Validation Loss: 0.0030109768176158325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.6859463998675346\n",
      "Training Loss: 0.5860076175630092\n",
      "Training Loss: 0.4752473911643028\n",
      "Validation Loss: 0.3743325717998355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.3172069835662842\n",
      "Training Loss: 0.21348011501133443\n",
      "Training Loss: 0.13032891169190408\n",
      "Validation Loss: 0.09251504205167294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.08287257056683302\n",
      "Training Loss: 0.07290759716182947\n",
      "Training Loss: 0.07064192194491625\n",
      "Validation Loss: 0.07101654686201155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06946911809965968\n",
      "Training Loss: 0.06739579578861594\n",
      "Training Loss: 0.06770319478586316\n",
      "Validation Loss: 0.06808335447077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.06647325182333588\n",
      "Training Loss: 0.06417418956756592\n",
      "Training Loss: 0.06370504204183818\n",
      "Validation Loss: 0.06320485820093852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.06109337450005114\n",
      "Training Loss: 0.05819044368341565\n",
      "Training Loss: 0.05625187464058399\n",
      "Validation Loss: 0.054617059804248004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.05187989789992571\n",
      "Training Loss: 0.04878783584572375\n",
      "Training Loss: 0.04568924151360989\n",
      "Validation Loss: 0.04363178535040175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.040996427442878486\n",
      "Training Loss: 0.03866458080708981\n",
      "Training Loss: 0.03560421546921134\n",
      "Validation Loss: 0.03377959585298648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.03170079477131367\n",
      "Training Loss: 0.030279031139798462\n",
      "Training Loss: 0.02776055661495775\n",
      "Validation Loss: 0.026315351927213456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.02488366003613919\n",
      "Training Loss: 0.024239937509410083\n",
      "Training Loss: 0.022358723846264184\n",
      "Validation Loss: 0.021199713084386305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.020348293790593743\n",
      "Training Loss: 0.020229967851191757\n",
      "Training Loss: 0.018852532040327788\n",
      "Validation Loss: 0.017816233205389272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.017418448561802507\n",
      "Training Loss: 0.01759122101124376\n",
      "Training Loss: 0.016553959525190294\n",
      "Validation Loss: 0.015524887809467114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.015468135932460427\n",
      "Training Loss: 0.01578173168003559\n",
      "Training Loss: 0.014961905784439296\n",
      "Validation Loss: 0.013884738040564771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.014087319003883748\n",
      "Training Loss: 0.014465062364470213\n",
      "Training Loss: 0.013782129068858921\n",
      "Validation Loss: 0.012633652856646712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.013041273532435298\n",
      "Training Loss: 0.013448479135986418\n",
      "Training Loss: 0.012851426757406444\n",
      "Validation Loss: 0.01162126924701328\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.012200202036183327\n",
      "Training Loss: 0.012622803500853479\n",
      "Training Loss: 0.012080476272385567\n",
      "Validation Loss: 0.010764309314989976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.011494576544500888\n",
      "Training Loss: 0.011928247916512192\n",
      "Training Loss: 0.01142233856022358\n",
      "Validation Loss: 0.010019736692801201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.010889396423008292\n",
      "Training Loss: 0.01133394566597417\n",
      "Training Loss: 0.010853990130126476\n",
      "Validation Loss: 0.009367277318601278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.010368103636428714\n",
      "Training Loss: 0.010824359168764204\n",
      "Training Loss: 0.010364374562632292\n",
      "Validation Loss: 0.008797512311237246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009922216874547302\n",
      "Training Loss: 0.010390462069772184\n",
      "Training Loss: 0.009946735627017915\n",
      "Validation Loss: 0.008304400999998946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.009545173577498645\n",
      "Training Loss: 0.01002471592510119\n",
      "Training Loss: 0.009594577881507575\n",
      "Validation Loss: 0.007881705212312635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00922988933045417\n",
      "Training Loss: 0.009719300430733711\n",
      "Training Loss: 0.009300572236534209\n",
      "Validation Loss: 0.0075221881845945054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008968481926713139\n",
      "Training Loss: 0.009466005910653622\n",
      "Training Loss: 0.00905682381708175\n",
      "Validation Loss: 0.0072179878774109515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008752874685451389\n",
      "Training Loss: 0.00925675745587796\n",
      "Training Loss: 0.008855532527668401\n",
      "Validation Loss: 0.006961312292802954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008575429876800626\n",
      "Training Loss: 0.009084103867644444\n",
      "Training Loss: 0.008689502524212002\n",
      "Validation Loss: 0.006744892686982168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008429316512774676\n",
      "Training Loss: 0.00894146427162923\n",
      "Training Loss: 0.008552381413755939\n",
      "Validation Loss: 0.006562217417319588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00830865285359323\n",
      "Training Loss: 0.00882321087643504\n",
      "Training Loss: 0.00843874258804135\n",
      "Validation Loss: 0.006407618190402563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008208493023412302\n",
      "Training Loss: 0.008724616899853573\n",
      "Training Loss: 0.00834403334534727\n",
      "Validation Loss: 0.00627625287311633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008124749098205939\n",
      "Training Loss: 0.008641767507651821\n",
      "Training Loss: 0.008264488733839243\n",
      "Validation Loss: 0.006164022024166299\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008054071827791632\n",
      "Training Loss: 0.008571443704422563\n",
      "Training Loss: 0.008197024391265587\n",
      "Validation Loss: 0.006067506294027808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007993743976112456\n",
      "Training Loss: 0.008511027754284441\n",
      "Training Loss: 0.008139136102981866\n",
      "Validation Loss: 0.0059838592221311635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007941571240080521\n",
      "Training Loss: 0.008458394231274724\n",
      "Training Loss: 0.008088804904837162\n",
      "Validation Loss: 0.0059107444916192565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007895801888080313\n",
      "Training Loss: 0.008411835636943579\n",
      "Training Loss: 0.008044411541195586\n",
      "Validation Loss: 0.005846240921364574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00785503416438587\n",
      "Training Loss: 0.008369981345022098\n",
      "Training Loss: 0.008004660365404561\n",
      "Validation Loss: 0.005788775402895604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007818150917300955\n",
      "Training Loss: 0.008331734901294113\n",
      "Training Loss: 0.007968519523274153\n",
      "Validation Loss: 0.005737060166926783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0077842663950286805\n",
      "Training Loss: 0.008296223394572734\n",
      "Training Loss: 0.007935166478855536\n",
      "Validation Loss: 0.00569005087122656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007752679282566533\n",
      "Training Loss: 0.008262751048896462\n",
      "Training Loss: 0.007903951422777026\n",
      "Validation Loss: 0.005646894241191363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007722835841123015\n",
      "Training Loss: 0.00823076834436506\n",
      "Training Loss: 0.007874356468673795\n",
      "Validation Loss: 0.005606885650195181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007694295709952712\n",
      "Training Loss: 0.008199838669970632\n",
      "Training Loss: 0.00784597484394908\n",
      "Validation Loss: 0.005569463619292619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007666716246167198\n",
      "Training Loss: 0.008169618685496972\n",
      "Training Loss: 0.00781848353566602\n",
      "Validation Loss: 0.005534156879640362\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0076398261147551235\n",
      "Training Loss: 0.008139835797483102\n",
      "Training Loss: 0.0077916292229201645\n",
      "Validation Loss: 0.005500589768151135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0076134145620744675\n",
      "Training Loss: 0.008110280983382836\n",
      "Training Loss: 0.007765215110266581\n",
      "Validation Loss: 0.005468453275395579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007587318764999509\n",
      "Training Loss: 0.008080793456174433\n",
      "Training Loss: 0.0077390886575449255\n",
      "Validation Loss: 0.005437497057418307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007561415410600602\n",
      "Training Loss: 0.008051248585106805\n",
      "Training Loss: 0.007713135677622631\n",
      "Validation Loss: 0.005407529444240159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007535613615764305\n",
      "Training Loss: 0.00802156068966724\n",
      "Training Loss: 0.00768726863199845\n",
      "Validation Loss: 0.005378383564961593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007509845609311014\n",
      "Training Loss: 0.007991668866015971\n",
      "Training Loss: 0.00766142803709954\n",
      "Validation Loss: 0.005349938546469582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007484067023033276\n",
      "Training Loss: 0.00796153445611708\n",
      "Training Loss: 0.007635572194121778\n",
      "Validation Loss: 0.0053220916254278485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007458249264163897\n",
      "Training Loss: 0.007931139011634513\n",
      "Training Loss: 0.007609674684936181\n",
      "Validation Loss: 0.005294771252194776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007432376535143703\n",
      "Training Loss: 0.007900480077369139\n",
      "Training Loss: 0.007583723426796496\n",
      "Validation Loss: 0.005267924884219099\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007406445713713765\n",
      "Training Loss: 0.007869571502087638\n",
      "Training Loss: 0.00755771721363999\n",
      "Validation Loss: 0.005241507122795401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007380460732383654\n",
      "Training Loss: 0.007838434565346688\n",
      "Training Loss: 0.007531661572866142\n",
      "Validation Loss: 0.005215490441586236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007354432038264349\n",
      "Training Loss: 0.007807102521182969\n",
      "Training Loss: 0.007505570306675508\n",
      "Validation Loss: 0.005189857666061543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007328376391669735\n",
      "Training Loss: 0.007775615093996748\n",
      "Training Loss: 0.00747946111834608\n",
      "Validation Loss: 0.005164593095195302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0073023135622497645\n",
      "Training Loss: 0.007744019977981225\n",
      "Training Loss: 0.007453358087223023\n",
      "Validation Loss: 0.005139694103756606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0072762683557812124\n",
      "Training Loss: 0.0077123707265127454\n",
      "Training Loss: 0.0074272890598513185\n",
      "Validation Loss: 0.005115161293442623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007250268545467406\n",
      "Training Loss: 0.007680724672973156\n",
      "Training Loss: 0.007401284199440852\n",
      "Validation Loss: 0.005090994332665891\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007224344164133072\n",
      "Training Loss: 0.007649141859728843\n",
      "Training Loss: 0.007375378117430955\n",
      "Validation Loss: 0.005067202702734954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007198529979214072\n",
      "Training Loss: 0.007617687940364703\n",
      "Training Loss: 0.007349608805961907\n",
      "Validation Loss: 0.005043796277369551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007172862562583759\n",
      "Training Loss: 0.0075864292168989775\n",
      "Training Loss: 0.0073240146541502325\n",
      "Validation Loss: 0.005020790965573632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0071473826025612655\n",
      "Training Loss: 0.0075554354395717385\n",
      "Training Loss: 0.0072986382653471085\n",
      "Validation Loss: 0.0049981999118142665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007122132397489623\n",
      "Training Loss: 0.007524772963952273\n",
      "Training Loss: 0.007273523141629994\n",
      "Validation Loss: 0.004976043546980435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0070971582876518365\n",
      "Training Loss: 0.007494514466961846\n",
      "Training Loss: 0.007248712760629133\n",
      "Validation Loss: 0.004954335391599936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007072506217518822\n",
      "Training Loss: 0.007464726498583331\n",
      "Training Loss: 0.007224250047001988\n",
      "Validation Loss: 0.004933096389312381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007048222915036604\n",
      "Training Loss: 0.0074354730278719215\n",
      "Training Loss: 0.007200176981277764\n",
      "Validation Loss: 0.004912343662326339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007024353817105294\n",
      "Training Loss: 0.007406815070426092\n",
      "Training Loss: 0.007176530916476622\n",
      "Validation Loss: 0.004892093627818264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007000942339655012\n",
      "Training Loss: 0.007378804566105828\n",
      "Training Loss: 0.0071533486701082435\n",
      "Validation Loss: 0.004872353858670241\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006978027732111513\n",
      "Training Loss: 0.007351486779516563\n",
      "Training Loss: 0.007130657932721079\n",
      "Validation Loss: 0.004853129029807666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006955643703695387\n",
      "Training Loss: 0.007324900703970343\n",
      "Training Loss: 0.00710848399088718\n",
      "Validation Loss: 0.004834422571558422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006933817164972425\n",
      "Training Loss: 0.007299069755245\n",
      "Training Loss: 0.007086843244032934\n",
      "Validation Loss: 0.00481622809416018\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0069125687784980985\n",
      "Training Loss: 0.00727401024196297\n",
      "Training Loss: 0.007065745930885896\n",
      "Validation Loss: 0.00479853270428904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006891910703852772\n",
      "Training Loss: 0.007249731204938143\n",
      "Training Loss: 0.007045196871040389\n",
      "Validation Loss: 0.0047813260540617315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006871848882874474\n",
      "Training Loss: 0.007226224133046344\n",
      "Training Loss: 0.0070251939713489265\n",
      "Validation Loss: 0.004764585386898913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006852380117634311\n",
      "Training Loss: 0.007203479306772351\n",
      "Training Loss: 0.007005729408701882\n",
      "Validation Loss: 0.004748287047599599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006833495729370043\n",
      "Training Loss: 0.007181475799297914\n",
      "Training Loss: 0.006986790791852399\n",
      "Validation Loss: 0.004732407430014207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0068151822709478435\n",
      "Training Loss: 0.007160187652334571\n",
      "Training Loss: 0.006968362762127072\n",
      "Validation Loss: 0.004716919089557624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006797420355724171\n",
      "Training Loss: 0.007139585245167837\n",
      "Training Loss: 0.006950425041140989\n",
      "Validation Loss: 0.004701796751024641\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006780188861303032\n",
      "Training Loss: 0.007119635379640385\n",
      "Training Loss: 0.006932958662509918\n",
      "Validation Loss: 0.004687011197439573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006763462878298015\n",
      "Training Loss: 0.007100302344188094\n",
      "Training Loss: 0.006915941549232229\n",
      "Validation Loss: 0.004672540184319689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006747217742959038\n",
      "Training Loss: 0.007081552756717429\n",
      "Training Loss: 0.006899351277970709\n",
      "Validation Loss: 0.004658360013952792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006731428315397352\n",
      "Training Loss: 0.007063350119860843\n",
      "Training Loss: 0.006883166335755959\n",
      "Validation Loss: 0.004644451002339215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.00671606817166321\n",
      "Training Loss: 0.007045664000324905\n",
      "Training Loss: 0.006867366936639883\n",
      "Validation Loss: 0.004630790708790628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0067011134710628535\n",
      "Training Loss: 0.007028461534064263\n",
      "Training Loss: 0.006851931899436749\n",
      "Validation Loss: 0.00461736568668334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006686540571972727\n",
      "Training Loss: 0.007011713207466528\n",
      "Training Loss: 0.006836842896882444\n",
      "Validation Loss: 0.0046041585227704785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006672328183194623\n",
      "Training Loss: 0.006995392312528565\n",
      "Training Loss: 0.006822081034188159\n",
      "Validation Loss: 0.004591152812301946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00665845359209925\n",
      "Training Loss: 0.0069794714474119245\n",
      "Training Loss: 0.006807630489347503\n",
      "Validation Loss: 0.004578342087687192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006644898605300114\n",
      "Training Loss: 0.006963929943740368\n",
      "Training Loss: 0.006793474627193064\n",
      "Validation Loss: 0.004565711087400742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0066316453728359195\n",
      "Training Loss: 0.006948745398549363\n",
      "Training Loss: 0.006779600208392367\n",
      "Validation Loss: 0.004553249180369246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006618677513906732\n",
      "Training Loss: 0.006933899055002257\n",
      "Training Loss: 0.006765992972068488\n",
      "Validation Loss: 0.0045409485399513765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006605978843290359\n",
      "Training Loss: 0.0069193722796626386\n",
      "Training Loss: 0.006752640341874212\n",
      "Validation Loss: 0.004528802516085379\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006593536202562973\n",
      "Training Loss: 0.006905149910598993\n",
      "Training Loss: 0.006739530086633749\n",
      "Validation Loss: 0.0045168029472723685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.0065813360246829685\n",
      "Training Loss: 0.006891216202639043\n",
      "Training Loss: 0.0067266516806557776\n",
      "Validation Loss: 0.0045049403679002535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006569365337491036\n",
      "Training Loss: 0.006877556903054938\n",
      "Training Loss: 0.006713994516758248\n",
      "Validation Loss: 0.004493208590952491\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006557614279445261\n",
      "Training Loss: 0.0068641603761352595\n",
      "Training Loss: 0.006701549487188458\n",
      "Validation Loss: 0.004481601250865445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006546071296324954\n",
      "Training Loss: 0.006851013657869771\n",
      "Training Loss: 0.006689305354375392\n",
      "Validation Loss: 0.0044701130553201004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006534726279787719\n",
      "Training Loss: 0.006838104769121856\n",
      "Training Loss: 0.0066772554354975\n",
      "Validation Loss: 0.004458740037693276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006523571346187964\n",
      "Training Loss: 0.006825425024144352\n",
      "Training Loss: 0.00666539061407093\n",
      "Validation Loss: 0.004447472560365967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0065125960553996266\n",
      "Training Loss: 0.006812963966513053\n",
      "Training Loss: 0.006653703654301353\n",
      "Validation Loss: 0.004436308685480879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006501793545903638\n",
      "Training Loss: 0.006800712142139673\n",
      "Training Loss: 0.006642186806420796\n",
      "Validation Loss: 0.004425246532080339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006491156314732507\n",
      "Training Loss: 0.006788660608581267\n",
      "Training Loss: 0.0066308339074021205\n",
      "Validation Loss: 0.004414273134898394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006480676233768463\n",
      "Training Loss: 0.006776799931540154\n",
      "Training Loss: 0.00661963633261621\n",
      "Validation Loss: 0.0044033917875730254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00647034703171812\n",
      "Training Loss: 0.006765123246004805\n",
      "Training Loss: 0.0066085887257941065\n",
      "Validation Loss: 0.004392590874078778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006460161064751446\n",
      "Training Loss: 0.006753621363313869\n",
      "Training Loss: 0.006597685011220164\n",
      "Validation Loss: 0.004381869614825406\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006450112904421985\n",
      "Training Loss: 0.0067422889632871375\n",
      "Training Loss: 0.006586919387336821\n",
      "Validation Loss: 0.004371226101386455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006440197306219488\n",
      "Training Loss: 0.006731116431183182\n",
      "Training Loss: 0.006576285987393931\n",
      "Validation Loss: 0.004360653554204475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006430407515726984\n",
      "Training Loss: 0.006720098383375443\n",
      "Training Loss: 0.006565779632073827\n",
      "Validation Loss: 0.004350152315331225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.0064207376807462425\n",
      "Training Loss: 0.006709228896070272\n",
      "Training Loss: 0.006555394777096808\n",
      "Validation Loss: 0.004339711937472601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006411183137679473\n",
      "Training Loss: 0.0066984992916695775\n",
      "Training Loss: 0.006545127324643545\n",
      "Validation Loss: 0.004329337025574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00640173954074271\n",
      "Training Loss: 0.006687905616709031\n",
      "Training Loss: 0.006534971536020748\n",
      "Validation Loss: 0.00431901854371359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006392401151824743\n",
      "Training Loss: 0.006677440154599026\n",
      "Training Loss: 0.00652492317778524\n",
      "Validation Loss: 0.004308755727997573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006383163058198988\n",
      "Training Loss: 0.006667098498437554\n",
      "Training Loss: 0.006514978207997046\n",
      "Validation Loss: 0.0042985422573355815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.0063740214204881344\n",
      "Training Loss: 0.006656873573665507\n",
      "Training Loss: 0.0065051314671291036\n",
      "Validation Loss: 0.004288378581692454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006364971281727776\n",
      "Training Loss: 0.0066467617620946835\n",
      "Training Loss: 0.006495379648986273\n",
      "Validation Loss: 0.004278263261573117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006356008426519111\n",
      "Training Loss: 0.006636756114312447\n",
      "Training Loss: 0.006485718596959487\n",
      "Validation Loss: 0.0042681920720170135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006347128849010914\n",
      "Training Loss: 0.006626851377659477\n",
      "Training Loss: 0.006476144313346595\n",
      "Validation Loss: 0.004258162011078486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0063383289496414365\n",
      "Training Loss: 0.0066170433536171915\n",
      "Training Loss: 0.006466651811497286\n",
      "Validation Loss: 0.004248170182762898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.0063296037586405875\n",
      "Training Loss: 0.006607327073579654\n",
      "Training Loss: 0.006457239881856367\n",
      "Validation Loss: 0.004238216507279974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.0063209499837830665\n",
      "Training Loss: 0.006597696822718717\n",
      "Training Loss: 0.006447902617510408\n",
      "Validation Loss: 0.004228296165820211\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006312363885808736\n",
      "Training Loss: 0.006588148449081927\n",
      "Training Loss: 0.006438638076651841\n",
      "Validation Loss: 0.004218407801948906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0063038415997289125\n",
      "Training Loss: 0.006578678140649572\n",
      "Training Loss: 0.006429442698135972\n",
      "Validation Loss: 0.004208551380349051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0062953797518275675\n",
      "Training Loss: 0.006569280314724892\n",
      "Training Loss: 0.006420312123373151\n",
      "Validation Loss: 0.004198723240478194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006286974736722187\n",
      "Training Loss: 0.006559950744267553\n",
      "Training Loss: 0.006411244129412808\n",
      "Validation Loss: 0.004188921460175489\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006278623114340008\n",
      "Training Loss: 0.0065506857185391705\n",
      "Training Loss: 0.006402235451387242\n",
      "Validation Loss: 0.00417914344167881\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006270322086056695\n",
      "Training Loss: 0.006541481146705337\n",
      "Training Loss: 0.006393282660283149\n",
      "Validation Loss: 0.004169388122861849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006262068678624928\n",
      "Training Loss: 0.006532331895432435\n",
      "Training Loss: 0.006384383146651089\n",
      "Validation Loss: 0.004159653053116681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006253857716219499\n",
      "Training Loss: 0.006523235435015522\n",
      "Training Loss: 0.006375533209647983\n",
      "Validation Loss: 0.004149940594104694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006245688368217088\n",
      "Training Loss: 0.006514186462154612\n",
      "Training Loss: 0.0063667312543839215\n",
      "Validation Loss: 0.0041402429270327844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00623755652399268\n",
      "Training Loss: 0.006505182132823393\n",
      "Training Loss: 0.006357973660924472\n",
      "Validation Loss: 0.0041305637386041495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.0062294593709520995\n",
      "Training Loss: 0.006496218367246911\n",
      "Training Loss: 0.006349258003756404\n",
      "Validation Loss: 0.004120898980443271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006221394307212904\n",
      "Training Loss: 0.006487291303346865\n",
      "Training Loss: 0.006340580675750971\n",
      "Validation Loss: 0.004111246464857727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.0062133585271658374\n",
      "Training Loss: 0.006478398332837969\n",
      "Training Loss: 0.006331940644886344\n",
      "Validation Loss: 0.004101608613678621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0062053491512779144\n",
      "Training Loss: 0.006469534564530477\n",
      "Training Loss: 0.006323334204498678\n",
      "Validation Loss: 0.004091981904361439\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0061973638931522145\n",
      "Training Loss: 0.0064606969081796705\n",
      "Training Loss: 0.006314759418019094\n",
      "Validation Loss: 0.004082365019712597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0061894002876942975\n",
      "Training Loss: 0.006451883484842256\n",
      "Training Loss: 0.006306213782518171\n",
      "Validation Loss: 0.0040727582036810565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006181456103222445\n",
      "Training Loss: 0.00644308950053528\n",
      "Training Loss: 0.006297695329412818\n",
      "Validation Loss: 0.00406316513969992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006173528381041251\n",
      "Training Loss: 0.006434310730546713\n",
      "Training Loss: 0.0062892007315531375\n",
      "Validation Loss: 0.004053576503425125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0061656152998330075\n",
      "Training Loss: 0.0064255468855844815\n",
      "Training Loss: 0.006280727554112673\n",
      "Validation Loss: 0.00404399526737149\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0061577144748298455\n",
      "Training Loss: 0.006416792022646405\n",
      "Training Loss: 0.006272274244111031\n",
      "Validation Loss: 0.004034419580666202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006149823989835568\n",
      "Training Loss: 0.006408043952542357\n",
      "Training Loss: 0.0062638378283008935\n",
      "Validation Loss: 0.004024850801706021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.0061419420165475455\n",
      "Training Loss: 0.006399301048368215\n",
      "Training Loss: 0.006255416549975052\n",
      "Validation Loss: 0.004015288766332264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006134065958322026\n",
      "Training Loss: 0.006390559880528599\n",
      "Training Loss: 0.006247008445789106\n",
      "Validation Loss: 0.004005731713926691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006126194343087263\n",
      "Training Loss: 0.006381816631765105\n",
      "Training Loss: 0.006238611377193592\n",
      "Validation Loss: 0.003996180598702533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006118326339637861\n",
      "Training Loss: 0.006373068867251277\n",
      "Training Loss: 0.0062302222772268575\n",
      "Validation Loss: 0.003986634945842239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006110459071933292\n",
      "Training Loss: 0.00636431401304435\n",
      "Training Loss: 0.006221840112120844\n",
      "Validation Loss: 0.00397709538516578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006102591725648381\n",
      "Training Loss: 0.006355549719301052\n",
      "Training Loss: 0.006213462564046495\n",
      "Validation Loss: 0.003967559133823751\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006094723089481704\n",
      "Training Loss: 0.006346774594276212\n",
      "Training Loss: 0.006205087747075595\n",
      "Validation Loss: 0.003958028110706907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.0060868516919435935\n",
      "Training Loss: 0.0063379847264150154\n",
      "Training Loss: 0.00619671335327439\n",
      "Validation Loss: 0.003948503797167514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006078975597629324\n",
      "Training Loss: 0.006329178690211847\n",
      "Training Loss: 0.006188338636420667\n",
      "Validation Loss: 0.003938987489470564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006071096463128925\n",
      "Training Loss: 0.0063203544297721235\n",
      "Training Loss: 0.006179961417219601\n",
      "Validation Loss: 0.003929478023462834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006063210760476068\n",
      "Training Loss: 0.00631151064648293\n",
      "Training Loss: 0.006171580061200075\n",
      "Validation Loss: 0.00391997530561966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006055319027509541\n",
      "Training Loss: 0.00630264580307994\n",
      "Training Loss: 0.006163193985703402\n",
      "Validation Loss: 0.003910485455593659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006047421121620573\n",
      "Training Loss: 0.006293757690582424\n",
      "Training Loss: 0.0061548011243576185\n",
      "Validation Loss: 0.0039010061444243772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006039516601595097\n",
      "Training Loss: 0.00628484612039756\n",
      "Training Loss: 0.006146401735022664\n",
      "Validation Loss: 0.00389153750095349\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006031605887110345\n",
      "Training Loss: 0.0062759103847201915\n",
      "Training Loss: 0.006137993744923733\n",
      "Validation Loss: 0.003882084609522076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006023688979330473\n",
      "Training Loss: 0.00626695005572401\n",
      "Training Loss: 0.006129578023683279\n",
      "Validation Loss: 0.0038726512340075347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006015765868942253\n",
      "Training Loss: 0.006257964769029059\n",
      "Training Loss: 0.006121154211577959\n",
      "Validation Loss: 0.0038632367884091448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006007839136291295\n",
      "Training Loss: 0.006248954660841264\n",
      "Training Loss: 0.006112721831304953\n",
      "Validation Loss: 0.003853843226934668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005999907915829681\n",
      "Training Loss: 0.00623992059205193\n",
      "Training Loss: 0.0061042813694803045\n",
      "Validation Loss: 0.003844473553491819\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005991974529461003\n",
      "Training Loss: 0.00623086437350139\n",
      "Training Loss: 0.006095833294093609\n",
      "Validation Loss: 0.0038351339001595724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005984040210023522\n",
      "Training Loss: 0.006221786548267118\n",
      "Training Loss: 0.006087378906086087\n",
      "Validation Loss: 0.0038258237528792593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005976107027963735\n",
      "Training Loss: 0.0062126898014685135\n",
      "Training Loss: 0.00607892015541438\n",
      "Validation Loss: 0.003816550289505695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005968176383757964\n",
      "Training Loss: 0.006203576268162579\n",
      "Training Loss: 0.006070457887253724\n",
      "Validation Loss: 0.0038073168847751753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0059602510748663915\n",
      "Training Loss: 0.006194447383168153\n",
      "Training Loss: 0.006061993999173865\n",
      "Validation Loss: 0.0037981264287961667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005952333229943179\n",
      "Training Loss: 0.006185308411368169\n",
      "Training Loss: 0.00605353154183831\n",
      "Validation Loss: 0.0037889824624257056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005944425694760867\n",
      "Training Loss: 0.00617616088828072\n",
      "Training Loss: 0.0060450716142077\n",
      "Validation Loss: 0.0037798882714535497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005936530482722446\n",
      "Training Loss: 0.0061670101404888555\n",
      "Training Loss: 0.006036618574289605\n",
      "Validation Loss: 0.0037708494725919675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005928651159047149\n",
      "Training Loss: 0.006157858541700989\n",
      "Training Loss: 0.00602817336213775\n",
      "Validation Loss: 0.0037618695125193075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005920788951334544\n",
      "Training Loss: 0.006148711731657386\n",
      "Training Loss: 0.006019739498151466\n",
      "Validation Loss: 0.003752948932109003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005912947137840092\n",
      "Training Loss: 0.006139573909458704\n",
      "Training Loss: 0.00601132093986962\n",
      "Validation Loss: 0.003744093725442091\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.00590512856550049\n",
      "Training Loss: 0.006130448746262118\n",
      "Training Loss: 0.006002919675083831\n",
      "Validation Loss: 0.0037353060710547344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00589733429485932\n",
      "Training Loss: 0.00612134165072348\n",
      "Training Loss: 0.00599453887436539\n",
      "Validation Loss: 0.003726587401247803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005889567252597772\n",
      "Training Loss: 0.006112255956395529\n",
      "Training Loss: 0.005986181704793125\n",
      "Validation Loss: 0.003717942122799041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.0058818281639833\n",
      "Training Loss: 0.006103196456679143\n",
      "Training Loss: 0.005977849473711103\n",
      "Validation Loss: 0.003709366654302255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005874118965584785\n",
      "Training Loss: 0.0060941673553315924\n",
      "Training Loss: 0.005969545333646238\n",
      "Validation Loss: 0.003700861357429766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005866440050886013\n",
      "Training Loss: 0.006085173022001982\n",
      "Training Loss: 0.005961270394036547\n",
      "Validation Loss: 0.0036924283943672695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.00585879193560686\n",
      "Training Loss: 0.006076214715722017\n",
      "Training Loss: 0.0059530271583935245\n",
      "Validation Loss: 0.0036840663635527736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0058511748962337155\n",
      "Training Loss: 0.006067297089612111\n",
      "Training Loss: 0.005944816580740735\n",
      "Validation Loss: 0.0036757740354311937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005843588032876141\n",
      "Training Loss: 0.006058421636116691\n",
      "Training Loss: 0.005936637899721973\n",
      "Validation Loss: 0.0036675467246128353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005836031567887403\n",
      "Training Loss: 0.006049588943715207\n",
      "Training Loss: 0.005928492586826905\n",
      "Validation Loss: 0.003659380338248912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005828502336516977\n",
      "Training Loss: 0.0060408023284981025\n",
      "Training Loss: 0.005920380133320577\n",
      "Validation Loss: 0.0036512755983760265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.00582100038358476\n",
      "Training Loss: 0.006032061869627796\n",
      "Training Loss: 0.005912298781331629\n",
      "Validation Loss: 0.003643224772531539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005813523086253554\n",
      "Training Loss: 0.006023368017631583\n",
      "Training Loss: 0.005904249508748762\n",
      "Validation Loss: 0.0036352210007137044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005806066975346766\n",
      "Training Loss: 0.006014719640952535\n",
      "Training Loss: 0.005896228692145087\n",
      "Validation Loss: 0.003627257805521694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005798631256329827\n",
      "Training Loss: 0.00600611733214464\n",
      "Training Loss: 0.005888234919984825\n",
      "Validation Loss: 0.0036193331784641976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005791210932657122\n",
      "Training Loss: 0.005997558710514567\n",
      "Training Loss: 0.005880265554296784\n",
      "Validation Loss: 0.0036114396205632372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005783804294769652\n",
      "Training Loss: 0.0059890428255312145\n",
      "Training Loss: 0.005872319628251716\n",
      "Validation Loss: 0.0036035745844161244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.00577640843926929\n",
      "Training Loss: 0.005980566481593996\n",
      "Training Loss: 0.0058643930935068055\n",
      "Validation Loss: 0.003595725677677252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005769019876024686\n",
      "Training Loss: 0.0059721286286367106\n",
      "Training Loss: 0.005856483039096929\n",
      "Validation Loss: 0.003587891309119217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005761635132366791\n",
      "Training Loss: 0.005963726105983369\n",
      "Training Loss: 0.0058485868945717815\n",
      "Validation Loss: 0.003580061797303765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005754251069738529\n",
      "Training Loss: 0.005955356388585642\n",
      "Training Loss: 0.00584070073440671\n",
      "Validation Loss: 0.0035722343162162586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005746864575776271\n",
      "Training Loss: 0.005947015584097244\n",
      "Training Loss: 0.005832822248921729\n",
      "Validation Loss: 0.003564400058187377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005739473440335132\n",
      "Training Loss: 0.005938701353734359\n",
      "Training Loss: 0.005824947186047211\n",
      "Validation Loss: 0.0035565566654798438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0057320731901563705\n",
      "Training Loss: 0.005930410993751138\n",
      "Training Loss: 0.005817073381622322\n",
      "Validation Loss: 0.003548697083848372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005724661975982599\n",
      "Training Loss: 0.005922139334725216\n",
      "Training Loss: 0.0058091974828857924\n",
      "Validation Loss: 0.0035408183061151526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005717236541677266\n",
      "Training Loss: 0.005913886102498509\n",
      "Training Loss: 0.005801316779688932\n",
      "Validation Loss: 0.003532914109292618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005709795060683973\n",
      "Training Loss: 0.0059056448307819665\n",
      "Training Loss: 0.005793427072931081\n",
      "Validation Loss: 0.003524980825644112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005702334766974673\n",
      "Training Loss: 0.005897414144710638\n",
      "Training Loss: 0.005785526653053239\n",
      "Validation Loss: 0.0035170152086209964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005694853441091254\n",
      "Training Loss: 0.005889190404559486\n",
      "Training Loss: 0.005777612464735285\n",
      "Validation Loss: 0.003509010890697579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005687349596992135\n",
      "Training Loss: 0.00588097111787647\n",
      "Training Loss: 0.0057696818158729\n",
      "Validation Loss: 0.0035009694035855656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005679820590885356\n",
      "Training Loss: 0.005872751945862547\n",
      "Training Loss: 0.005761732542305253\n",
      "Validation Loss: 0.003492885468046317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005672264945460483\n",
      "Training Loss: 0.005864529550890439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [18:10<07:47, 155.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005753761676605791\n",
      "Validation Loss: 0.003484754888550117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.1207162314094603\n",
      "Training Loss: 0.0948384926095605\n",
      "Training Loss: 0.07849971700459718\n",
      "Validation Loss: 0.07080464012753428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06653410222381353\n",
      "Training Loss: 0.06142652316018939\n",
      "Training Loss: 0.06006213268265128\n",
      "Validation Loss: 0.05898518098539181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.057491825371980665\n",
      "Training Loss: 0.054598179180175066\n",
      "Training Loss: 0.053316905200481414\n",
      "Validation Loss: 0.05142783049201028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04947518683038652\n",
      "Training Loss: 0.04637330072000623\n",
      "Training Loss: 0.044127677427604796\n",
      "Validation Loss: 0.04168286085589213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03956466604024172\n",
      "Training Loss: 0.036969461580738425\n",
      "Training Loss: 0.03423379809595645\n",
      "Validation Loss: 0.031802154564706794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.029931193944066764\n",
      "Training Loss: 0.02825614856556058\n",
      "Training Loss: 0.025385084776207805\n",
      "Validation Loss: 0.022887976008226698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.021458395742811262\n",
      "Training Loss: 0.020253018108196557\n",
      "Training Loss: 0.017763957008719446\n",
      "Validation Loss: 0.015654890753559015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.015349652608856559\n",
      "Training Loss: 0.015129206394776702\n",
      "Training Loss: 0.014121238260995596\n",
      "Validation Loss: 0.012713249352907113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013068313256371766\n",
      "Training Loss: 0.013104822463355958\n",
      "Training Loss: 0.012600831959862262\n",
      "Validation Loss: 0.011186595410998031\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011815297375433147\n",
      "Training Loss: 0.011878990817349404\n",
      "Training Loss: 0.011543861159589141\n",
      "Validation Loss: 0.01006567311797584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010889297146350145\n",
      "Training Loss: 0.010978605360724031\n",
      "Training Loss: 0.010738121473696082\n",
      "Validation Loss: 0.009202152107360908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010182944068219513\n",
      "Training Loss: 0.010286728328792379\n",
      "Training Loss: 0.010107246469706297\n",
      "Validation Loss: 0.008518187712428025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009629078168654815\n",
      "Training Loss: 0.009739523925818503\n",
      "Training Loss: 0.0095995214197319\n",
      "Validation Loss: 0.007962493685053222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009183990124147385\n",
      "Training Loss: 0.009299437636509538\n",
      "Training Loss: 0.009183131005847826\n",
      "Validation Loss: 0.007502114313937137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008820458046393469\n",
      "Training Loss: 0.008942019096575677\n",
      "Training Loss: 0.008837665991159156\n",
      "Validation Loss: 0.007115028373468039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008520601248601451\n",
      "Training Loss: 0.0086500762286596\n",
      "Training Loss: 0.008549233166268095\n",
      "Validation Loss: 0.006786141501415228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008272059560986235\n",
      "Training Loss: 0.008410994897130876\n",
      "Training Loss: 0.008307861945359036\n",
      "Validation Loss: 0.00650479997445442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00806581582990475\n",
      "Training Loss: 0.008215145567664877\n",
      "Training Loss: 0.008105964828282596\n",
      "Validation Loss: 0.006263166212141932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007894891027826817\n",
      "Training Loss: 0.008054873504443094\n",
      "Training Loss: 0.007937423617113382\n",
      "Validation Loss: 0.006055219811805932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007753587511833757\n",
      "Training Loss: 0.007923883822513744\n",
      "Training Loss: 0.0077970759046729655\n",
      "Validation Loss: 0.005876114988291448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007637066039023921\n",
      "Training Loss: 0.007816899199970067\n",
      "Training Loss: 0.007680448630126193\n",
      "Validation Loss: 0.005721827628865336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0075411447952501475\n",
      "Training Loss: 0.007729461600538343\n",
      "Training Loss: 0.007583639865042641\n",
      "Validation Loss: 0.00558891692303456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0074621923326049\n",
      "Training Loss: 0.007657816051505506\n",
      "Training Loss: 0.007503253472968936\n",
      "Validation Loss: 0.005474418205512541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007397089579608291\n",
      "Training Loss: 0.007598832027288154\n",
      "Training Loss: 0.007436372834490612\n",
      "Validation Loss: 0.005375736447972026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007343184830388054\n",
      "Training Loss: 0.007549927749205381\n",
      "Training Loss: 0.007380520857404918\n",
      "Validation Loss: 0.005290609541129363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007298267534933984\n",
      "Training Loss: 0.007509006072068587\n",
      "Training Loss: 0.007333631279179826\n",
      "Validation Loss: 0.005217067202751975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007260519405826926\n",
      "Training Loss: 0.0074743872054386885\n",
      "Training Loss: 0.007294001230038702\n",
      "Validation Loss: 0.005153396310745163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007228467807872221\n",
      "Training Loss: 0.007444736119359732\n",
      "Training Loss: 0.00726024234551005\n",
      "Validation Loss: 0.005098120351269674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0072009370080195366\n",
      "Training Loss: 0.007419008814031259\n",
      "Training Loss: 0.0072312347521074115\n",
      "Validation Loss: 0.005049971258006153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007176992180757224\n",
      "Training Loss: 0.0073963904252741484\n",
      "Training Loss: 0.00720607896335423\n",
      "Validation Loss: 0.0050078605149945854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007155899405479432\n",
      "Training Loss: 0.0073762482195161285\n",
      "Training Loss: 0.007184057296253741\n",
      "Validation Loss: 0.004970869726993227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007137085603317246\n",
      "Training Loss: 0.007358093321090564\n",
      "Training Loss: 0.007164595687063411\n",
      "Validation Loss: 0.004938218535939127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007120101101463661\n",
      "Training Loss: 0.007341545684030279\n",
      "Training Loss: 0.007147237098542973\n",
      "Validation Loss: 0.004909241452991041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007104594383854419\n",
      "Training Loss: 0.007326309431809932\n",
      "Training Loss: 0.007131615098332986\n",
      "Validation Loss: 0.0048833888199368725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0070902915322221816\n",
      "Training Loss: 0.007312154192477465\n",
      "Training Loss: 0.007117434474639595\n",
      "Validation Loss: 0.004860189577219275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007076976642711088\n",
      "Training Loss: 0.007298897411674261\n",
      "Training Loss: 0.007104458850808442\n",
      "Validation Loss: 0.004839245868935721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007064478035317734\n",
      "Training Loss: 0.007286395354894921\n",
      "Training Loss: 0.0070924926886800676\n",
      "Validation Loss: 0.004820229074907269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007052662001224235\n",
      "Training Loss: 0.007274532737210393\n",
      "Training Loss: 0.00708138135029003\n",
      "Validation Loss: 0.004802861649888369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007041420312598348\n",
      "Training Loss: 0.007263215185375884\n",
      "Training Loss: 0.007070995182730257\n",
      "Validation Loss: 0.004786907365608416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007030666870996356\n",
      "Training Loss: 0.007252368034096434\n",
      "Training Loss: 0.007061226945370436\n",
      "Validation Loss: 0.00477217290853935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007020331030944362\n",
      "Training Loss: 0.007241927194409073\n",
      "Training Loss: 0.007051988925086334\n",
      "Validation Loss: 0.004758484752487726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007010355849051848\n",
      "Training Loss: 0.007231841798638925\n",
      "Training Loss: 0.007043206603266299\n",
      "Validation Loss: 0.004745708872679244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007000694746384397\n",
      "Training Loss: 0.007222067000111565\n",
      "Training Loss: 0.007034818773390726\n",
      "Validation Loss: 0.004733721609227359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006991308500291779\n",
      "Training Loss: 0.0072125667450018225\n",
      "Training Loss: 0.007026771383825689\n",
      "Validation Loss: 0.004722423428339947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006982164761284366\n",
      "Training Loss: 0.007203309190226719\n",
      "Training Loss: 0.007019020937150344\n",
      "Validation Loss: 0.004711727679738503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006973235270706936\n",
      "Training Loss: 0.007194266642909497\n",
      "Training Loss: 0.007011528372531757\n",
      "Validation Loss: 0.0047015562258514295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006964496693108231\n",
      "Training Loss: 0.007185414945706725\n",
      "Training Loss: 0.0070042607851792124\n",
      "Validation Loss: 0.004691848612463708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006955929022515192\n",
      "Training Loss: 0.007176734055392444\n",
      "Training Loss: 0.006997188369277865\n",
      "Validation Loss: 0.0046825459935922135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.006947513119084761\n",
      "Training Loss: 0.00716820583678782\n",
      "Training Loss: 0.006990287213120609\n",
      "Validation Loss: 0.004673603414610195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.0069392345461528745\n",
      "Training Loss: 0.007159812467871234\n",
      "Training Loss: 0.006983534748433158\n",
      "Validation Loss: 0.004664973535030829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006931077386252582\n",
      "Training Loss: 0.007151541303610429\n",
      "Training Loss: 0.0069769113115035\n",
      "Validation Loss: 0.0046566217912758666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006923031030455604\n",
      "Training Loss: 0.007143377929460257\n",
      "Training Loss: 0.00697039938531816\n",
      "Validation Loss: 0.004648515525577443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006915081746410578\n",
      "Training Loss: 0.007135311188176274\n",
      "Training Loss: 0.006963984632166103\n",
      "Validation Loss: 0.004640627595507069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006907219825079664\n",
      "Training Loss: 0.007127329689683393\n",
      "Training Loss: 0.006957651649136096\n",
      "Validation Loss: 0.004632930194807312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006899436104577035\n",
      "Training Loss: 0.007119425273267552\n",
      "Training Loss: 0.006951388540910557\n",
      "Validation Loss: 0.00462540193575989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006891719987615943\n",
      "Training Loss: 0.0071115878084674474\n",
      "Training Loss: 0.00694518500007689\n",
      "Validation Loss: 0.0046180175313872565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006884064821060747\n",
      "Training Loss: 0.007103810405824334\n",
      "Training Loss: 0.006939030246576295\n",
      "Validation Loss: 0.004610763250567605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006876461611827835\n",
      "Training Loss: 0.007096086115343497\n",
      "Training Loss: 0.006932914976496249\n",
      "Validation Loss: 0.004603621982864701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006868904480943456\n",
      "Training Loss: 0.007088408058043569\n",
      "Training Loss: 0.006926831940654665\n",
      "Validation Loss: 0.004596575295416575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006861385314259678\n",
      "Training Loss: 0.007080771159380674\n",
      "Training Loss: 0.006920772818848491\n",
      "Validation Loss: 0.004589615056155186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006853900013957173\n",
      "Training Loss: 0.00707317071617581\n",
      "Training Loss: 0.006914731714641675\n",
      "Validation Loss: 0.004582723385518354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006846442014211789\n",
      "Training Loss: 0.007065602366346866\n",
      "Training Loss: 0.006908702859655023\n",
      "Validation Loss: 0.004575890728293426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006839006772497669\n",
      "Training Loss: 0.007058063455624506\n",
      "Training Loss: 0.006902680568164215\n",
      "Validation Loss: 0.004569111087129273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006831590819638222\n",
      "Training Loss: 0.00705054945894517\n",
      "Training Loss: 0.006896660716738552\n",
      "Validation Loss: 0.004562371019326317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00682419040473178\n",
      "Training Loss: 0.007043059822171927\n",
      "Training Loss: 0.006890639858320355\n",
      "Validation Loss: 0.004555664328057737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00681680208304897\n",
      "Training Loss: 0.007035591488238424\n",
      "Training Loss: 0.006884614482987672\n",
      "Validation Loss: 0.0045489865718827995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006809423728846013\n",
      "Training Loss: 0.007028144296491519\n",
      "Training Loss: 0.00687858241959475\n",
      "Validation Loss: 0.004542329470271223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006802053694846108\n",
      "Training Loss: 0.007020716061815619\n",
      "Training Loss: 0.006872540349140763\n",
      "Validation Loss: 0.004535685477809709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006794690050883219\n",
      "Training Loss: 0.007013307296438143\n",
      "Training Loss: 0.0068664870329666885\n",
      "Validation Loss: 0.004529052327669571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0067873330530710515\n",
      "Training Loss: 0.007005917327478528\n",
      "Training Loss: 0.006860420976299793\n",
      "Validation Loss: 0.004522426596063116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006779980374267325\n",
      "Training Loss: 0.006998547777766362\n",
      "Training Loss: 0.0068543406657408925\n",
      "Validation Loss: 0.0045158014589596245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006772633614018559\n",
      "Training Loss: 0.006991196410963312\n",
      "Training Loss: 0.006848246580921114\n",
      "Validation Loss: 0.004509175252535621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006765291461488232\n",
      "Training Loss: 0.006983865970978513\n",
      "Training Loss: 0.006842137763742357\n",
      "Validation Loss: 0.004502545689687844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0067579554743133485\n",
      "Training Loss: 0.006976554478751495\n",
      "Training Loss: 0.006836012843996287\n",
      "Validation Loss: 0.004495913867205591\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0067506264592520895\n",
      "Training Loss: 0.006969263076316565\n",
      "Training Loss: 0.006829872542293742\n",
      "Validation Loss: 0.004489273932275854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006743303862167522\n",
      "Training Loss: 0.0069619921501725916\n",
      "Training Loss: 0.0068237165757454935\n",
      "Validation Loss: 0.004482629305416237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006735989128937945\n",
      "Training Loss: 0.006954741980880499\n",
      "Training Loss: 0.0068175456649623815\n",
      "Validation Loss: 0.0044759765471425956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006728683647233993\n",
      "Training Loss: 0.00694751076749526\n",
      "Training Loss: 0.006811358956620097\n",
      "Validation Loss: 0.004469314151903971\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0067213875893503425\n",
      "Training Loss: 0.00694029797334224\n",
      "Training Loss: 0.006805156009504571\n",
      "Validation Loss: 0.004462645831256268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006714101094985381\n",
      "Training Loss: 0.0069331034482456744\n",
      "Training Loss: 0.006798937745625153\n",
      "Validation Loss: 0.0044559709167924155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006706825242144987\n",
      "Training Loss: 0.006925924535607919\n",
      "Training Loss: 0.00679270429071039\n",
      "Validation Loss: 0.00444929151183643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006699560097185895\n",
      "Training Loss: 0.006918759235413745\n",
      "Training Loss: 0.006786453680833801\n",
      "Validation Loss: 0.004442607560796726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006692305172327906\n",
      "Training Loss: 0.006911605297354981\n",
      "Training Loss: 0.006780185955576599\n",
      "Validation Loss: 0.004435920563992113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006685060089221224\n",
      "Training Loss: 0.006904460230143741\n",
      "Training Loss: 0.006773900176631287\n",
      "Validation Loss: 0.004429229242162088\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006677825027145446\n",
      "Training Loss: 0.0068973208963871\n",
      "Training Loss: 0.006767594418488443\n",
      "Validation Loss: 0.00442253804917374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006670596926705912\n",
      "Training Loss: 0.006890183860668912\n",
      "Training Loss: 0.006761268359841779\n",
      "Validation Loss: 0.004415846576919423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006663375681964681\n",
      "Training Loss: 0.006883043581619858\n",
      "Training Loss: 0.006754919236991555\n",
      "Validation Loss: 0.004409156306097389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006656159311532974\n",
      "Training Loss: 0.006875897456193342\n",
      "Training Loss: 0.0067485464143101125\n",
      "Validation Loss: 0.0044024687141357936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.0066489446442574264\n",
      "Training Loss: 0.006868740193312988\n",
      "Training Loss: 0.006742145613534376\n",
      "Validation Loss: 0.004395784281738354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006641729720868171\n",
      "Training Loss: 0.006861566881416366\n",
      "Training Loss: 0.006735714147798717\n",
      "Validation Loss: 0.004389103615834388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00663451092201285\n",
      "Training Loss: 0.006854371998924762\n",
      "Training Loss: 0.006729250174248591\n",
      "Validation Loss: 0.004382424356724565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006627284970600158\n",
      "Training Loss: 0.006847150867106393\n",
      "Training Loss: 0.006722750012995675\n",
      "Validation Loss: 0.00437574885691401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006620048214681446\n",
      "Training Loss: 0.00683989753597416\n",
      "Training Loss: 0.006716209421865642\n",
      "Validation Loss: 0.00436907464028807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0066127957007847725\n",
      "Training Loss: 0.006832606529351324\n",
      "Training Loss: 0.006709625008516014\n",
      "Validation Loss: 0.004362403566221801\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006605523871257901\n",
      "Training Loss: 0.0068252711824607105\n",
      "Training Loss: 0.006702991025522351\n",
      "Validation Loss: 0.004355730568032628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006598226855276152\n",
      "Training Loss: 0.006817885354394093\n",
      "Training Loss: 0.006696304677752778\n",
      "Validation Loss: 0.004349054940688434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006590900062583387\n",
      "Training Loss: 0.006810442999703809\n",
      "Training Loss: 0.006689559469232336\n",
      "Validation Loss: 0.004342370704496593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006583536983234808\n",
      "Training Loss: 0.006802937134634704\n",
      "Training Loss: 0.006682749543106183\n",
      "Validation Loss: 0.004335676404919601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006576132415793836\n",
      "Training Loss: 0.006795361967524513\n",
      "Training Loss: 0.006675870454637333\n",
      "Validation Loss: 0.004328966367037527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006568679600022733\n",
      "Training Loss: 0.006787710116477683\n",
      "Training Loss: 0.006668915048940107\n",
      "Validation Loss: 0.00432223288912661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006561171996872872\n",
      "Training Loss: 0.006779976492980495\n",
      "Training Loss: 0.00666187840164639\n",
      "Validation Loss: 0.004315472240010381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006553603226784617\n",
      "Training Loss: 0.006772150899050758\n",
      "Training Loss: 0.006654753042384982\n",
      "Validation Loss: 0.0043086782516388415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006545966513222083\n",
      "Training Loss: 0.006764229775872082\n",
      "Training Loss: 0.006647532306378707\n",
      "Validation Loss: 0.004301841581355404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006538254508050159\n",
      "Training Loss: 0.006756203732220456\n",
      "Training Loss: 0.006640210275072604\n",
      "Validation Loss: 0.004294958634673503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0065304600668605415\n",
      "Training Loss: 0.006748066337313503\n",
      "Training Loss: 0.006632780146319419\n",
      "Validation Loss: 0.004288020230479162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006522575900889933\n",
      "Training Loss: 0.0067398110206704585\n",
      "Training Loss: 0.006625234761741012\n",
      "Validation Loss: 0.004281016630434504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006514594552572817\n",
      "Training Loss: 0.0067314307147171345\n",
      "Training Loss: 0.00661756658111699\n",
      "Validation Loss: 0.004273939484029255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006506508477032185\n",
      "Training Loss: 0.006722917393781245\n",
      "Training Loss: 0.006609768249327317\n",
      "Validation Loss: 0.00426677899733395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006498309544986114\n",
      "Training Loss: 0.0067142656608484685\n",
      "Training Loss: 0.006601833915337921\n",
      "Validation Loss: 0.004259530121324521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006489991289563477\n",
      "Training Loss: 0.006705466982675716\n",
      "Training Loss: 0.006593755985377357\n",
      "Validation Loss: 0.004252178610166472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006481544751441106\n",
      "Training Loss: 0.00669651574222371\n",
      "Training Loss: 0.006585526239359751\n",
      "Validation Loss: 0.0042447145423967015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006472964548738674\n",
      "Training Loss: 0.00668740609427914\n",
      "Training Loss: 0.0065771396644413475\n",
      "Validation Loss: 0.004237127587790444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006464242818765342\n",
      "Training Loss: 0.006678131400840357\n",
      "Training Loss: 0.006568589623784646\n",
      "Validation Loss: 0.004229416302274494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006455372521886602\n",
      "Training Loss: 0.006668686080956832\n",
      "Training Loss: 0.0065598692861385645\n",
      "Validation Loss: 0.0042215670037784436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006446347003802657\n",
      "Training Loss: 0.006659063178813085\n",
      "Training Loss: 0.006550973389530554\n",
      "Validation Loss: 0.004213566956596889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006437159719644115\n",
      "Training Loss: 0.0066492583940271285\n",
      "Training Loss: 0.006541895732516423\n",
      "Validation Loss: 0.004205410073124124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006427805596031249\n",
      "Training Loss: 0.006639268510043621\n",
      "Training Loss: 0.006532631579320877\n",
      "Validation Loss: 0.004197087779829509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.0064182783511932935\n",
      "Training Loss: 0.006629087029723451\n",
      "Training Loss: 0.006523177401395515\n",
      "Validation Loss: 0.004188596369735269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.00640857374179177\n",
      "Training Loss: 0.00661871385993436\n",
      "Training Loss: 0.006513527650386095\n",
      "Validation Loss: 0.0041799231947745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006398686069296673\n",
      "Training Loss: 0.006608143055345863\n",
      "Training Loss: 0.006503678691806272\n",
      "Validation Loss: 0.00417106089985333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006388611914590001\n",
      "Training Loss: 0.006597375166602432\n",
      "Training Loss: 0.006493630656041205\n",
      "Validation Loss: 0.004162005103046723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0063783491670619695\n",
      "Training Loss: 0.0065864072134718295\n",
      "Training Loss: 0.0064833780011395\n",
      "Validation Loss: 0.004152751026094336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006367893052520231\n",
      "Training Loss: 0.006575240973616019\n",
      "Training Loss: 0.006472922373795882\n",
      "Validation Loss: 0.004143292699113823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006357244768878445\n",
      "Training Loss: 0.006563876048894599\n",
      "Training Loss: 0.0064622618310386315\n",
      "Validation Loss: 0.00413362464404487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006346401338232681\n",
      "Training Loss: 0.0065523147990461435\n",
      "Training Loss: 0.006451399209909141\n",
      "Validation Loss: 0.0041237435469749185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006335364732658491\n",
      "Training Loss: 0.006540561586152762\n",
      "Training Loss: 0.006440335102961398\n",
      "Validation Loss: 0.004113648945512773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006324135566828772\n",
      "Training Loss: 0.006528620377648622\n",
      "Training Loss: 0.00642907151253894\n",
      "Validation Loss: 0.004103336525751341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006312715352978557\n",
      "Training Loss: 0.006516496606636792\n",
      "Training Loss: 0.006417614105739631\n",
      "Validation Loss: 0.004092809220310301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006301108180778101\n",
      "Training Loss: 0.006504197631729766\n",
      "Training Loss: 0.006405967248720117\n",
      "Validation Loss: 0.00408206397099839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006289317857008428\n",
      "Training Loss: 0.006491730896523222\n",
      "Training Loss: 0.006394136062590405\n",
      "Validation Loss: 0.004071105648292585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0062773500679759306\n",
      "Training Loss: 0.006479106566403061\n",
      "Training Loss: 0.006382128741242923\n",
      "Validation Loss: 0.004059935721118798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006265211591380648\n",
      "Training Loss: 0.006466336108278483\n",
      "Training Loss: 0.006369952970417216\n",
      "Validation Loss: 0.004048557880104341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006252909657196142\n",
      "Training Loss: 0.006453430753899738\n",
      "Training Loss: 0.006357619176851586\n",
      "Validation Loss: 0.004036976319470893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006240453951177187\n",
      "Training Loss: 0.006440405579051003\n",
      "Training Loss: 0.006345136357704177\n",
      "Validation Loss: 0.004025198258930461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0062278527853777636\n",
      "Training Loss: 0.006427272992441431\n",
      "Training Loss: 0.006332518074195832\n",
      "Validation Loss: 0.004013234447279757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006215119121479802\n",
      "Training Loss: 0.0064140496507752685\n",
      "Training Loss: 0.006319775635492988\n",
      "Validation Loss: 0.004001093201020084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006202264275634662\n",
      "Training Loss: 0.006400750898756087\n",
      "Training Loss: 0.0063069229241227735\n",
      "Validation Loss: 0.0039887813199834705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006189301477861591\n",
      "Training Loss: 0.006387395800556988\n",
      "Training Loss: 0.006293974680011161\n",
      "Validation Loss: 0.0039763158727489575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006176243906957098\n",
      "Training Loss: 0.006374001908698119\n",
      "Training Loss: 0.006280945366597734\n",
      "Validation Loss: 0.003963706043700614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006163107186439447\n",
      "Training Loss: 0.006360587787348777\n",
      "Training Loss: 0.006267852462478914\n",
      "Validation Loss: 0.003950970042680045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006149905826896429\n",
      "Training Loss: 0.006347171961097047\n",
      "Training Loss: 0.006254711205838248\n",
      "Validation Loss: 0.003938121215592065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006136657719034702\n",
      "Training Loss: 0.006333774685044773\n",
      "Training Loss: 0.006241539629991166\n",
      "Validation Loss: 0.00392517854467432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006123379290220328\n",
      "Training Loss: 0.006320415753871203\n",
      "Training Loss: 0.006228356395149603\n",
      "Validation Loss: 0.003912158573982881\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006110088416608051\n",
      "Training Loss: 0.006307114626397378\n",
      "Training Loss: 0.0062151796254329384\n",
      "Validation Loss: 0.003899083738973929\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006096801809617318\n",
      "Training Loss: 0.006293890384258702\n",
      "Training Loss: 0.006202027822728269\n",
      "Validation Loss: 0.0038859735104370486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006083540302352048\n",
      "Training Loss: 0.006280763219110668\n",
      "Training Loss: 0.006188921531429514\n",
      "Validation Loss: 0.0038728493702692096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0060703210229985415\n",
      "Training Loss: 0.006267750633414834\n",
      "Training Loss: 0.00617587809509132\n",
      "Validation Loss: 0.0038597336695581842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006057163425139151\n",
      "Training Loss: 0.006254872896824963\n",
      "Training Loss: 0.006162917897454463\n",
      "Validation Loss: 0.0038466467267017435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006044086313922889\n",
      "Training Loss: 0.006242146866279654\n",
      "Training Loss: 0.006150060479412787\n",
      "Validation Loss: 0.0038336183381361072\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006031108828028664\n",
      "Training Loss: 0.006229587995330803\n",
      "Training Loss: 0.0061373233248014\n",
      "Validation Loss: 0.0038206670714510875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.00601824859098997\n",
      "Training Loss: 0.006217213395866565\n",
      "Training Loss: 0.006124724858673289\n",
      "Validation Loss: 0.0038078160259318065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006005523823550902\n",
      "Training Loss: 0.006205037175677716\n",
      "Training Loss: 0.0061122824857011435\n",
      "Validation Loss: 0.003795087520619122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005992951587541029\n",
      "Training Loss: 0.006193073019385337\n",
      "Training Loss: 0.006100012945826166\n",
      "Validation Loss: 0.003782506859495064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005980547535582446\n",
      "Training Loss: 0.006181331194820814\n",
      "Training Loss: 0.006087932065711356\n",
      "Validation Loss: 0.0037700945466987035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005968327696318738\n",
      "Training Loss: 0.0061698222014820205\n",
      "Training Loss: 0.006076052567805163\n",
      "Validation Loss: 0.003757867102741442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005956305756699294\n",
      "Training Loss: 0.006158555665751919\n",
      "Training Loss: 0.006064388470258563\n",
      "Validation Loss: 0.0037458456445778354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005944493839633651\n",
      "Training Loss: 0.006147537302458659\n",
      "Training Loss: 0.006052948667202145\n",
      "Validation Loss: 0.0037340448294201174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005932902648346498\n",
      "Training Loss: 0.006136772977188229\n",
      "Training Loss: 0.006041744246613234\n",
      "Validation Loss: 0.003722478219653281\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005921541498391889\n",
      "Training Loss: 0.006126265485072509\n",
      "Training Loss: 0.006030782307498157\n",
      "Validation Loss: 0.0037111592710572768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005910418194835074\n",
      "Training Loss: 0.0061160171474330125\n",
      "Training Loss: 0.006020069646183401\n",
      "Validation Loss: 0.003700096489144803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005899538956582546\n",
      "Training Loss: 0.006106030856026337\n",
      "Training Loss: 0.006009609110187739\n",
      "Validation Loss: 0.00368929214205258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0058889093977632\n",
      "Training Loss: 0.006096301797660999\n",
      "Training Loss: 0.005999402989400551\n",
      "Validation Loss: 0.0036787631583996535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005878529597539455\n",
      "Training Loss: 0.006086829052655958\n",
      "Training Loss: 0.005989453179063275\n",
      "Validation Loss: 0.0036685034760870457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005868402482592501\n",
      "Training Loss: 0.006077610191423446\n",
      "Training Loss: 0.005979759676847607\n",
      "Validation Loss: 0.003658521269039994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005858529141405598\n",
      "Training Loss: 0.006068640718003735\n",
      "Training Loss: 0.005970320228952914\n",
      "Validation Loss: 0.0036488106471664282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005848907380714081\n",
      "Training Loss: 0.006059914629440754\n",
      "Training Loss: 0.005961131867952645\n",
      "Validation Loss: 0.0036393673528048597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005839534388505854\n",
      "Training Loss: 0.0060514269210398194\n",
      "Training Loss: 0.005952190451789647\n",
      "Validation Loss: 0.003630195501040709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.00583040778466966\n",
      "Training Loss: 0.006043169895419851\n",
      "Training Loss: 0.005943491354119032\n",
      "Validation Loss: 0.0036212868002253804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005821522860787809\n",
      "Training Loss: 0.0060351377149345355\n",
      "Training Loss: 0.005935029897373169\n",
      "Validation Loss: 0.003612636540770489\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005812875112751499\n",
      "Training Loss: 0.006027322321315296\n",
      "Training Loss: 0.0059267985704354945\n",
      "Validation Loss: 0.003604235325081881\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005804457913618535\n",
      "Training Loss: 0.006019716197042726\n",
      "Training Loss: 0.005918790864525363\n",
      "Validation Loss: 0.0035960792166212304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005796265649260022\n",
      "Training Loss: 0.006012311598751694\n",
      "Training Loss: 0.005910999865736812\n",
      "Validation Loss: 0.0035881584227671114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005788291283533908\n",
      "Training Loss: 0.00600510019925423\n",
      "Training Loss: 0.0059034189686644825\n",
      "Validation Loss: 0.003580466067167313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005780529354233295\n",
      "Training Loss: 0.005998074701637961\n",
      "Training Loss: 0.005896040647057816\n",
      "Validation Loss: 0.0035729926004953515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005772972119157203\n",
      "Training Loss: 0.005991228154744022\n",
      "Training Loss: 0.005888856506207958\n",
      "Validation Loss: 0.0035657302000340115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005765612795948982\n",
      "Training Loss: 0.005984552625450306\n",
      "Training Loss: 0.005881861643865704\n",
      "Validation Loss: 0.0035586730685618737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005758444684906863\n",
      "Training Loss: 0.0059780416282592345\n",
      "Training Loss: 0.0058750451810192315\n",
      "Validation Loss: 0.0035518082022258824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005751459846505895\n",
      "Training Loss: 0.005971687560086139\n",
      "Training Loss: 0.005868403313215822\n",
      "Validation Loss: 0.0035451297887621885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.0057446516264462845\n",
      "Training Loss: 0.005965483284089714\n",
      "Training Loss: 0.005861925894860179\n",
      "Validation Loss: 0.0035386290375059577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005738013461814262\n",
      "Training Loss: 0.005959422062151134\n",
      "Training Loss: 0.0058556079305708405\n",
      "Validation Loss: 0.0035323002611109045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005731537915416993\n",
      "Training Loss: 0.00595349840936251\n",
      "Training Loss: 0.005849442610051483\n",
      "Validation Loss: 0.003526133954069797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005725219380692579\n",
      "Training Loss: 0.005947705775615759\n",
      "Training Loss: 0.0058434222789946946\n",
      "Validation Loss: 0.003520121345992378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.00571904884185642\n",
      "Training Loss: 0.005942037397762761\n",
      "Training Loss: 0.0058375405136030165\n",
      "Validation Loss: 0.0035142559562077263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005713022754061967\n",
      "Training Loss: 0.00593648872571066\n",
      "Training Loss: 0.005831793260294944\n",
      "Validation Loss: 0.0035085341470640448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005707133233081549\n",
      "Training Loss: 0.005931055169785395\n",
      "Training Loss: 0.005826171771623194\n",
      "Validation Loss: 0.003502944874802207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005701375976204872\n",
      "Training Loss: 0.005925730263115838\n",
      "Training Loss: 0.005820673739071936\n",
      "Validation Loss: 0.0034974862414600557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005695743369287811\n",
      "Training Loss: 0.005920510718133301\n",
      "Training Loss: 0.005815290156751871\n",
      "Validation Loss: 0.0034921502483893562\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.00569023099844344\n",
      "Training Loss: 0.005915390606969595\n",
      "Training Loss: 0.005810019092168659\n",
      "Validation Loss: 0.0034869355463496084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005684834273997694\n",
      "Training Loss: 0.0059103669662727044\n",
      "Training Loss: 0.005804854645393789\n",
      "Validation Loss: 0.003481826384609377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005679546943865716\n",
      "Training Loss: 0.0059054353123065085\n",
      "Training Loss: 0.005799791121389717\n",
      "Validation Loss: 0.0034768227657847356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005674363800208085\n",
      "Training Loss: 0.005900589398806915\n",
      "Training Loss: 0.0057948242919519544\n",
      "Validation Loss: 0.0034719209305764166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0056692816014401615\n",
      "Training Loss: 0.005895829908549786\n",
      "Training Loss: 0.005789951657643542\n",
      "Validation Loss: 0.0034671160111235185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005664294618181884\n",
      "Training Loss: 0.005891150496900081\n",
      "Training Loss: 0.00578516632434912\n",
      "Validation Loss: 0.003462402375671343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0056593993050046264\n",
      "Training Loss: 0.005886548269190825\n",
      "Training Loss: 0.005780466742580756\n",
      "Validation Loss: 0.0034577776906813047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005654591826605611\n",
      "Training Loss: 0.005882020438439213\n",
      "Training Loss: 0.005775849700439721\n",
      "Validation Loss: 0.003453236671028596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.00564986739133019\n",
      "Training Loss: 0.005877563916146755\n",
      "Training Loss: 0.005771309094270692\n",
      "Validation Loss: 0.0034487761107137365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005645223027095199\n",
      "Training Loss: 0.005873174351872876\n",
      "Training Loss: 0.0057668447017204015\n",
      "Validation Loss: 0.003444392427676514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.0056406551832333205\n",
      "Training Loss: 0.005868852529674768\n",
      "Training Loss: 0.00576245105243288\n",
      "Validation Loss: 0.003440083332197594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005636160529102199\n",
      "Training Loss: 0.0058645936450921\n",
      "Training Loss: 0.00575812665047124\n",
      "Validation Loss: 0.0034358395202074912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.00563173575210385\n",
      "Training Loss: 0.005860395762138069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [20:45<05:10, 155.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005753867622697726\n",
      "Validation Loss: 0.0034316646309930495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.49945110857486724\n",
      "Training Loss: 0.38560754582285883\n",
      "Training Loss: 0.25733418107032774\n",
      "Validation Loss: 0.14674283317133283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.1067841106466949\n",
      "Training Loss: 0.07431630183011294\n",
      "Training Loss: 0.0685567968338728\n",
      "Validation Loss: 0.06812771698564626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06587107971310616\n",
      "Training Loss: 0.06317172229290008\n",
      "Training Loss: 0.06240968065336347\n",
      "Validation Loss: 0.06263004176402359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06040070466697216\n",
      "Training Loss: 0.05818533906713128\n",
      "Training Loss: 0.05739200739189983\n",
      "Validation Loss: 0.05754625204992428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.055285221533849835\n",
      "Training Loss: 0.053182139061391354\n",
      "Training Loss: 0.05189893886446953\n",
      "Validation Loss: 0.05139995782813999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04904449000954628\n",
      "Training Loss: 0.04678133992478251\n",
      "Training Loss: 0.04459010869264603\n",
      "Validation Loss: 0.04311397026052301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.04080185880884528\n",
      "Training Loss: 0.038823459204286336\n",
      "Training Loss: 0.03617903534322977\n",
      "Validation Loss: 0.034601376067554014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.032811224106699226\n",
      "Training Loss: 0.03192781766876578\n",
      "Training Loss: 0.02952775079291314\n",
      "Validation Loss: 0.02827765867951211\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.0270378724578768\n",
      "Training Loss: 0.026930782520212235\n",
      "Training Loss: 0.024848152440972625\n",
      "Validation Loss: 0.023740008128074447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.022950639398768544\n",
      "Training Loss: 0.02327453191857785\n",
      "Training Loss: 0.021490497076883913\n",
      "Validation Loss: 0.02042062270580634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01999427703907713\n",
      "Training Loss: 0.02055886370828375\n",
      "Training Loss: 0.01901469685137272\n",
      "Validation Loss: 0.017924623357215792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.01779102878412232\n",
      "Training Loss: 0.018488327756058423\n",
      "Training Loss: 0.017124246242456138\n",
      "Validation Loss: 0.015981036225291952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.016091649911832064\n",
      "Training Loss: 0.016861405891831965\n",
      "Training Loss: 0.01563135420437902\n",
      "Validation Loss: 0.01441779764358666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.014741298011504114\n",
      "Training Loss: 0.0155492171109654\n",
      "Training Loss: 0.014421041028108449\n",
      "Validation Loss: 0.013128327519706126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.01364464633865282\n",
      "Training Loss: 0.01447006324538961\n",
      "Training Loss: 0.013421918768435716\n",
      "Validation Loss: 0.012045167247879874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.012741019502282142\n",
      "Training Loss: 0.01357066107681021\n",
      "Training Loss: 0.012587462442461402\n",
      "Validation Loss: 0.01112357314592332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.011989512632135301\n",
      "Training Loss: 0.01281448885682039\n",
      "Training Loss: 0.011885374740231783\n",
      "Validation Loss: 0.010332219284341743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.011360746286809444\n",
      "Training Loss: 0.012175005148164927\n",
      "Training Loss: 0.011291729705408215\n",
      "Validation Loss: 0.009648038750629495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.010832212135428563\n",
      "Training Loss: 0.011631565389689059\n",
      "Training Loss: 0.01078759834752418\n",
      "Validation Loss: 0.009053195384592655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.010385438347002491\n",
      "Training Loss: 0.011166673145489768\n",
      "Training Loss: 0.010356836846331135\n",
      "Validation Loss: 0.008532965826550812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.010003964435309171\n",
      "Training Loss: 0.010763788463082164\n",
      "Training Loss: 0.009984239052282646\n",
      "Validation Loss: 0.00807378211011587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009671586232725531\n",
      "Training Loss: 0.010405261530540883\n",
      "Training Loss: 0.009653805072885007\n",
      "Validation Loss: 0.007661219449515005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009370786133222281\n",
      "Training Loss: 0.010070335027994587\n",
      "Training Loss: 0.009347134955460206\n",
      "Validation Loss: 0.007278029732353818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.009081642033997923\n",
      "Training Loss: 0.009733355025527999\n",
      "Training Loss: 0.009042478179326281\n",
      "Validation Loss: 0.006904013228623636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008783006529556587\n",
      "Training Loss: 0.009365933985682204\n",
      "Training Loss: 0.008720869423123077\n",
      "Validation Loss: 0.006530690094550255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008469665930606425\n",
      "Training Loss: 0.008970871433848514\n",
      "Training Loss: 0.008407368753105403\n",
      "Validation Loss: 0.006210767038773452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008198854241054505\n",
      "Training Loss: 0.008640137815382332\n",
      "Training Loss: 0.008181537167401984\n",
      "Validation Loss: 0.006002383893931263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008025786763755604\n",
      "Training Loss: 0.008426727146143094\n",
      "Training Loss: 0.008040914086159319\n",
      "Validation Loss: 0.0058631645855650805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007915790035622195\n",
      "Training Loss: 0.008285166767891497\n",
      "Training Loss: 0.007938536087749526\n",
      "Validation Loss: 0.0057508014129432905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007832768488442525\n",
      "Training Loss: 0.008178084928076715\n",
      "Training Loss: 0.007853180001256987\n",
      "Validation Loss: 0.005651849278855776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007763320837402716\n",
      "Training Loss: 0.008089873299468309\n",
      "Training Loss: 0.0077780944283586\n",
      "Validation Loss: 0.005562420035817064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00770264578750357\n",
      "Training Loss: 0.008013894960749895\n",
      "Training Loss: 0.007710621240548789\n",
      "Validation Loss: 0.005480818156142499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007648526537232101\n",
      "Training Loss: 0.007946878192014992\n",
      "Training Loss: 0.007649377571651712\n",
      "Validation Loss: 0.00540598483593988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007599703557789325\n",
      "Training Loss: 0.007886986030498519\n",
      "Training Loss: 0.007593509244034066\n",
      "Validation Loss: 0.005337177336299687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007555366717278958\n",
      "Training Loss: 0.007833046651212499\n",
      "Training Loss: 0.007542417602380737\n",
      "Validation Loss: 0.005273835011496303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007514936471125111\n",
      "Training Loss: 0.007784231047844514\n",
      "Training Loss: 0.007495634262450039\n",
      "Validation Loss: 0.005215523408704929\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007477967488812283\n",
      "Training Loss: 0.007739899582229554\n",
      "Training Loss: 0.007452766258502379\n",
      "Validation Loss: 0.005161873539752756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007444089776836336\n",
      "Training Loss: 0.007699524791678414\n",
      "Training Loss: 0.007413463708944619\n",
      "Validation Loss: 0.0051125686424732045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007412985134869814\n",
      "Training Loss: 0.0076626547041814775\n",
      "Training Loss: 0.0073774118721485135\n",
      "Validation Loss: 0.005067319580447975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00738437135820277\n",
      "Training Loss: 0.007628894234076142\n",
      "Training Loss: 0.007344324417645111\n",
      "Validation Loss: 0.005025862267481561\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007357994563644752\n",
      "Training Loss: 0.007597894088830799\n",
      "Training Loss: 0.007313933783443645\n",
      "Validation Loss: 0.004987938524475008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007333623239537701\n",
      "Training Loss: 0.007569343044888228\n",
      "Training Loss: 0.007285994010744617\n",
      "Validation Loss: 0.004953306571193291\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007311045705573633\n",
      "Training Loss: 0.0075429640838410705\n",
      "Training Loss: 0.007260278911562636\n",
      "Validation Loss: 0.004921733260447724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007290070445742458\n",
      "Training Loss: 0.007518510590307415\n",
      "Training Loss: 0.007236579663585871\n",
      "Validation Loss: 0.004892991288052349\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007270526185166091\n",
      "Training Loss: 0.0074957667326089\n",
      "Training Loss: 0.007214706861414015\n",
      "Validation Loss: 0.004866868281067254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007252256415085867\n",
      "Training Loss: 0.007474541702540591\n",
      "Training Loss: 0.007194485204527154\n",
      "Validation Loss: 0.004843153835148707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007235123458085582\n",
      "Training Loss: 0.007454666345147416\n",
      "Training Loss: 0.007175755415810272\n",
      "Validation Loss: 0.004821649188793191\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.0072190042934380475\n",
      "Training Loss: 0.007435994405532256\n",
      "Training Loss: 0.007158372229896486\n",
      "Validation Loss: 0.004802160314284265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0072037878807168455\n",
      "Training Loss: 0.007418396616121754\n",
      "Training Loss: 0.007142203364055604\n",
      "Validation Loss: 0.004784510098136125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007189375883899629\n",
      "Training Loss: 0.0074017602007370445\n",
      "Training Loss: 0.007127126773120836\n",
      "Validation Loss: 0.004768517899086301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007175680319778621\n",
      "Training Loss: 0.007385985034052283\n",
      "Training Loss: 0.007113031015032903\n",
      "Validation Loss: 0.0047540223968916395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007162619899027049\n",
      "Training Loss: 0.007370980158448219\n",
      "Training Loss: 0.007099810681538656\n",
      "Validation Loss: 0.004740863740234897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007150121463928372\n",
      "Training Loss: 0.007356665268307552\n",
      "Training Loss: 0.007087368156062439\n",
      "Validation Loss: 0.00472889395216166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007138115162961185\n",
      "Training Loss: 0.00734296411392279\n",
      "Training Loss: 0.007075611103791743\n",
      "Validation Loss: 0.004717975700525253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007126530229579657\n",
      "Training Loss: 0.0073298022046219555\n",
      "Training Loss: 0.007064445128198713\n",
      "Validation Loss: 0.004707978058637779\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007115293493261561\n",
      "Training Loss: 0.007317103325622156\n",
      "Training Loss: 0.007053774051601067\n",
      "Validation Loss: 0.004698782698826843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007104321360820905\n",
      "Training Loss: 0.007304780550766736\n",
      "Training Loss: 0.00704349385923706\n",
      "Validation Loss: 0.0046902886837762725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00709350997582078\n",
      "Training Loss: 0.0072927272284869105\n",
      "Training Loss: 0.007033475731732324\n",
      "Validation Loss: 0.004682400605243662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007082718102028593\n",
      "Training Loss: 0.007280801699962467\n",
      "Training Loss: 0.007023553564213216\n",
      "Validation Loss: 0.004675040402177596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007071747040608898\n",
      "Training Loss: 0.007268803517799825\n",
      "Training Loss: 0.0070135018147993835\n",
      "Validation Loss: 0.004668151539896898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007060316166607663\n",
      "Training Loss: 0.007256458322517574\n",
      "Training Loss: 0.007003004268044606\n",
      "Validation Loss: 0.004661679597508707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007048050516750663\n",
      "Training Loss: 0.00724341964465566\n",
      "Training Loss: 0.006991658764891326\n",
      "Validation Loss: 0.004655550283725175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007034528533695266\n",
      "Training Loss: 0.007229334281291812\n",
      "Training Loss: 0.006979026284534484\n",
      "Validation Loss: 0.004649577544625388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0070194280717987565\n",
      "Training Loss: 0.0072140313789714125\n",
      "Training Loss: 0.006964811043580994\n",
      "Validation Loss: 0.004643347462262498\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007002805703086779\n",
      "Training Loss: 0.007197783993324265\n",
      "Training Loss: 0.006949109376873821\n",
      "Validation Loss: 0.004636099405084433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006985276301857084\n",
      "Training Loss: 0.0071813503978773955\n",
      "Training Loss: 0.006932437327923253\n",
      "Validation Loss: 0.004626820514009994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0069676803762558845\n",
      "Training Loss: 0.007165452366461977\n",
      "Training Loss: 0.006915291218319908\n",
      "Validation Loss: 0.004614583283317474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006950397624168545\n",
      "Training Loss: 0.007150186343351379\n",
      "Training Loss: 0.006897785310866311\n",
      "Validation Loss: 0.004599026376198391\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006933231283910573\n",
      "Training Loss: 0.007135198585456237\n",
      "Training Loss: 0.006879918072372675\n",
      "Validation Loss: 0.004580719338918335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006915947920642793\n",
      "Training Loss: 0.007120284318225458\n",
      "Training Loss: 0.006862009082105942\n",
      "Validation Loss: 0.004561077232415045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0068986529856920244\n",
      "Training Loss: 0.00710561599349603\n",
      "Training Loss: 0.006844697497435845\n",
      "Validation Loss: 0.004541739869177383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0068817156320437785\n",
      "Training Loss: 0.00709155666991137\n",
      "Training Loss: 0.006828590257209726\n",
      "Validation Loss: 0.004523892525918363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006865517792757601\n",
      "Training Loss: 0.007078401241451502\n",
      "Training Loss: 0.006813990760711022\n",
      "Validation Loss: 0.004508046805466201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006850290565053001\n",
      "Training Loss: 0.007066262550652027\n",
      "Training Loss: 0.006800892589963041\n",
      "Validation Loss: 0.004494184103606039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006836085127433762\n",
      "Training Loss: 0.0070550850487779825\n",
      "Training Loss: 0.006789097618311643\n",
      "Validation Loss: 0.004482020223722532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006822821527021006\n",
      "Training Loss: 0.00704472167417407\n",
      "Training Loss: 0.006778340016608126\n",
      "Validation Loss: 0.00447118908083171\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006810354143381119\n",
      "Training Loss: 0.007034997363807634\n",
      "Training Loss: 0.006768357880646363\n",
      "Validation Loss: 0.004461332012407398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006798523971810937\n",
      "Training Loss: 0.007025751635665074\n",
      "Training Loss: 0.006758933347300627\n",
      "Validation Loss: 0.004452157592965981\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0067871875572018325\n",
      "Training Loss: 0.0070168605493381615\n",
      "Training Loss: 0.006749898082343862\n",
      "Validation Loss: 0.004443420630911093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006776224343338981\n",
      "Training Loss: 0.007008227268233896\n",
      "Training Loss: 0.006741126309498214\n",
      "Validation Loss: 0.004434956140224979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006765539110638201\n",
      "Training Loss: 0.006999785241205246\n",
      "Training Loss: 0.006732530680019408\n",
      "Validation Loss: 0.0044266323289530495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006755059253191575\n",
      "Training Loss: 0.0069914875389076765\n",
      "Training Loss: 0.006724049805779941\n",
      "Validation Loss: 0.0044183613767774165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006744729956844822\n",
      "Training Loss: 0.006983299879357219\n",
      "Training Loss: 0.006715641304035671\n",
      "Validation Loss: 0.0044100836005710655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0067345083586405965\n",
      "Training Loss: 0.006975199655862525\n",
      "Training Loss: 0.006707273461506702\n",
      "Validation Loss: 0.00440175508036477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006724361450178549\n",
      "Training Loss: 0.0069671685912180694\n",
      "Training Loss: 0.006698926997487433\n",
      "Validation Loss: 0.004393356870545932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006714262485038489\n",
      "Training Loss: 0.006959195528179407\n",
      "Training Loss: 0.006690587421762757\n",
      "Validation Loss: 0.004384871355121892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006704193433979527\n",
      "Training Loss: 0.006951267285039649\n",
      "Training Loss: 0.0066822422988479955\n",
      "Validation Loss: 0.004376288519758898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0066941360174678265\n",
      "Training Loss: 0.0069433751748874785\n",
      "Training Loss: 0.0066738848679233345\n",
      "Validation Loss: 0.00436760759729306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006684076886158436\n",
      "Training Loss: 0.006935513045173139\n",
      "Training Loss: 0.006665508468286134\n",
      "Validation Loss: 0.004358825825803568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006674004294909537\n",
      "Training Loss: 0.0069276716641616075\n",
      "Training Loss: 0.006657107294886373\n",
      "Validation Loss: 0.004349943882199737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00666390925180167\n",
      "Training Loss: 0.006919844972435385\n",
      "Training Loss: 0.006648675615433603\n",
      "Validation Loss: 0.0043409671431689865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006653782104840502\n",
      "Training Loss: 0.00691202690359205\n",
      "Training Loss: 0.0066402109654154625\n",
      "Validation Loss: 0.0043318950586816235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006643616742221639\n",
      "Training Loss: 0.006904209922067821\n",
      "Training Loss: 0.006631709207431414\n",
      "Validation Loss: 0.004322731456054856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006633405353641137\n",
      "Training Loss: 0.006896389786852523\n",
      "Training Loss: 0.006623166975914501\n",
      "Validation Loss: 0.00431348025286047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00662314333836548\n",
      "Training Loss: 0.0068885590555146335\n",
      "Training Loss: 0.006614581107860431\n",
      "Validation Loss: 0.004304141306522397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006612826328491792\n",
      "Training Loss: 0.00688071264885366\n",
      "Training Loss: 0.006605947847128845\n",
      "Validation Loss: 0.004294717305057337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0066024491225834935\n",
      "Training Loss: 0.006872846654150635\n",
      "Training Loss: 0.006597265827585943\n",
      "Validation Loss: 0.004285219188235449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006592009954620153\n",
      "Training Loss: 0.00686495438683778\n",
      "Training Loss: 0.006588532849564217\n",
      "Validation Loss: 0.0042756414917308125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006581505874637514\n",
      "Training Loss: 0.006857031075051054\n",
      "Training Loss: 0.00657974586240016\n",
      "Validation Loss: 0.00426598691729452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006570934588089585\n",
      "Training Loss: 0.006849072790937498\n",
      "Training Loss: 0.0065709055436309425\n",
      "Validation Loss: 0.004256261903086279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006560295219533146\n",
      "Training Loss: 0.006841075054835528\n",
      "Training Loss: 0.006562007842003368\n",
      "Validation Loss: 0.004246469771520894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006549588869092986\n",
      "Training Loss: 0.006833034574519843\n",
      "Training Loss: 0.006553054163232446\n",
      "Validation Loss: 0.004236610138689408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.0065388128766790034\n",
      "Training Loss: 0.00682494708802551\n",
      "Training Loss: 0.0065440437797224145\n",
      "Validation Loss: 0.004226694831211287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006527971131727099\n",
      "Training Loss: 0.00681680909707211\n",
      "Training Loss: 0.006534976795664988\n",
      "Validation Loss: 0.004216722054459322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0065170641464646906\n",
      "Training Loss: 0.006808618184877559\n",
      "Training Loss: 0.006525853026541881\n",
      "Validation Loss: 0.004206692580175534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006506093248026446\n",
      "Training Loss: 0.006800371386343613\n",
      "Training Loss: 0.00651667382044252\n",
      "Validation Loss: 0.0041966220001648236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006495063311886043\n",
      "Training Loss: 0.006792067111236974\n",
      "Training Loss: 0.006507440395653248\n",
      "Validation Loss: 0.004186507239885461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006483977037714794\n",
      "Training Loss: 0.006783702115644701\n",
      "Training Loss: 0.006498154061264358\n",
      "Validation Loss: 0.004176355197272274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006472838922636583\n",
      "Training Loss: 0.006775275633553974\n",
      "Training Loss: 0.006488817562931217\n",
      "Validation Loss: 0.004166176122759752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006461653728038073\n",
      "Training Loss: 0.006766786938533187\n",
      "Training Loss: 0.006479433643980883\n",
      "Validation Loss: 0.004155974435551992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.0064504268765449525\n",
      "Training Loss: 0.0067582353920442985\n",
      "Training Loss: 0.006470005029113963\n",
      "Validation Loss: 0.004145755216065961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006439165653428063\n",
      "Training Loss: 0.006749620086629875\n",
      "Training Loss: 0.006460533671197481\n",
      "Validation Loss: 0.004135523731113945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006427874194923788\n",
      "Training Loss: 0.006740941393072717\n",
      "Training Loss: 0.006451024822890759\n",
      "Validation Loss: 0.004125289922433622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006416561279911548\n",
      "Training Loss: 0.006732200374244712\n",
      "Training Loss: 0.0064414817572105675\n",
      "Validation Loss: 0.004115060425698339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006405233530094847\n",
      "Training Loss: 0.006723396432353184\n",
      "Training Loss: 0.006431908024824224\n",
      "Validation Loss: 0.004104839003477455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006393896630033851\n",
      "Training Loss: 0.006714533072081395\n",
      "Training Loss: 0.006422307510511018\n",
      "Validation Loss: 0.004094641173671764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.00638255943544209\n",
      "Training Loss: 0.006705609308555722\n",
      "Training Loss: 0.0064126855909125875\n",
      "Validation Loss: 0.004084465030470884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006371230370132252\n",
      "Training Loss: 0.0066966271423734725\n",
      "Training Loss: 0.006403046129853465\n",
      "Validation Loss: 0.004074319740600382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006359916678629816\n",
      "Training Loss: 0.006687590117799118\n",
      "Training Loss: 0.006393393165781163\n",
      "Validation Loss: 0.004064211194152326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0063486247439868745\n",
      "Training Loss: 0.006678499630652368\n",
      "Training Loss: 0.006383731942623854\n",
      "Validation Loss: 0.004054153222313381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006337361913174391\n",
      "Training Loss: 0.006669356792699545\n",
      "Training Loss: 0.00637406510009896\n",
      "Validation Loss: 0.004044143511819538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006326134518021717\n",
      "Training Loss: 0.006660163970664144\n",
      "Training Loss: 0.00636439669993706\n",
      "Validation Loss: 0.004034191942930723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006314950271043927\n",
      "Training Loss: 0.006650921824621037\n",
      "Training Loss: 0.006354730663006194\n",
      "Validation Loss: 0.004024299331862228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006303814644925296\n",
      "Training Loss: 0.006641634737025015\n",
      "Training Loss: 0.006345070435781963\n",
      "Validation Loss: 0.004014477324724364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0062927340588066726\n",
      "Training Loss: 0.0066323041985742745\n",
      "Training Loss: 0.006335418479866348\n",
      "Validation Loss: 0.004004724763250083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006281713350908831\n",
      "Training Loss: 0.006622931933961808\n",
      "Training Loss: 0.0063257778965635225\n",
      "Validation Loss: 0.003995043040499133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006270755345467478\n",
      "Training Loss: 0.006613519471138716\n",
      "Training Loss: 0.00631615093909204\n",
      "Validation Loss: 0.003985439790831356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006259864912135526\n",
      "Training Loss: 0.006604066957370378\n",
      "Training Loss: 0.006306537231430411\n",
      "Validation Loss: 0.003975915994620725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006249043920543045\n",
      "Training Loss: 0.00659457640722394\n",
      "Training Loss: 0.006296939552994445\n",
      "Validation Loss: 0.003966473781352005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006238294976064936\n",
      "Training Loss: 0.006585047406842932\n",
      "Training Loss: 0.006287357808905654\n",
      "Validation Loss: 0.003957114864554089\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006227618415141478\n",
      "Training Loss: 0.006575481496984139\n",
      "Training Loss: 0.006277790432795883\n",
      "Validation Loss: 0.003947840057826193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0062170163274277\n",
      "Training Loss: 0.006565878039691597\n",
      "Training Loss: 0.006268236901960335\n",
      "Validation Loss: 0.003938643045964117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006206483220448717\n",
      "Training Loss: 0.006556236142059788\n",
      "Training Loss: 0.006258696248987689\n",
      "Validation Loss: 0.0039295330055037075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006196023081429303\n",
      "Training Loss: 0.006546553740045056\n",
      "Training Loss: 0.0062491641094675286\n",
      "Validation Loss: 0.003920500467562776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006185629523242824\n",
      "Training Loss: 0.006536830518161878\n",
      "Training Loss: 0.006239638304687105\n",
      "Validation Loss: 0.003911546115590824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006175302033079788\n",
      "Training Loss: 0.006527063711546361\n",
      "Training Loss: 0.006230113373603672\n",
      "Validation Loss: 0.0039026707128276316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006165035313460976\n",
      "Training Loss: 0.006517249901080504\n",
      "Training Loss: 0.006220586027484387\n",
      "Validation Loss: 0.00389386980017396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006154825165285729\n",
      "Training Loss: 0.006507389000616968\n",
      "Training Loss: 0.006211049782577902\n",
      "Validation Loss: 0.0038851404397779806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006144665243919007\n",
      "Training Loss: 0.006497470943722874\n",
      "Training Loss: 0.006201497097499668\n",
      "Validation Loss: 0.003876479012300417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.00613454858714249\n",
      "Training Loss: 0.006487497019115836\n",
      "Training Loss: 0.006191921185236424\n",
      "Validation Loss: 0.003867884235210675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00612446921528317\n",
      "Training Loss: 0.0064774595003109425\n",
      "Training Loss: 0.006182312127784826\n",
      "Validation Loss: 0.003859350495720596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.0061144168244209145\n",
      "Training Loss: 0.006467352939071133\n",
      "Training Loss: 0.006172660521115176\n",
      "Validation Loss: 0.003850872761810596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006104384767240845\n",
      "Training Loss: 0.006457169628702104\n",
      "Training Loss: 0.006162955342442728\n",
      "Validation Loss: 0.003842448024340811\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.00609436237544287\n",
      "Training Loss: 0.006446903179166839\n",
      "Training Loss: 0.006153185211587697\n",
      "Validation Loss: 0.0038340676620372393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006084339247317985\n",
      "Training Loss: 0.006436545861652121\n",
      "Training Loss: 0.0061433345713885505\n",
      "Validation Loss: 0.003825722898623456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006074303290806711\n",
      "Training Loss: 0.006426089978776872\n",
      "Training Loss: 0.006133389308815822\n",
      "Validation Loss: 0.003817413632726569\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.00606424369616434\n",
      "Training Loss: 0.006415523517644033\n",
      "Training Loss: 0.006123335663578473\n",
      "Validation Loss: 0.003809121842208329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006054149322444573\n",
      "Training Loss: 0.006404839952010661\n",
      "Training Loss: 0.006113155447528698\n",
      "Validation Loss: 0.0038008396350255424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.0060440053074853495\n",
      "Training Loss: 0.006394027337664738\n",
      "Training Loss: 0.00610283202084247\n",
      "Validation Loss: 0.003792552008644123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006033802311285399\n",
      "Training Loss: 0.006383077338105067\n",
      "Training Loss: 0.006092348617967218\n",
      "Validation Loss: 0.003784243806835599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006023527349461801\n",
      "Training Loss: 0.0063719794119242576\n",
      "Training Loss: 0.006081689675920643\n",
      "Validation Loss: 0.0037758944123156704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0060131683212239296\n",
      "Training Loss: 0.0063607258861884475\n",
      "Training Loss: 0.00607083999319002\n",
      "Validation Loss: 0.003767485558997128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006002717441879213\n",
      "Training Loss: 0.006349306756164879\n",
      "Training Loss: 0.006059788452694193\n",
      "Validation Loss: 0.0037589907820148164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005992167043150403\n",
      "Training Loss: 0.006337716967100278\n",
      "Training Loss: 0.006048524492653087\n",
      "Validation Loss: 0.0037503835229789105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005981506890966557\n",
      "Training Loss: 0.006325950312893838\n",
      "Training Loss: 0.006037044048425742\n",
      "Validation Loss: 0.0037416471907439947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005970733030699194\n",
      "Training Loss: 0.00631400297745131\n",
      "Training Loss: 0.0060253438993822786\n",
      "Validation Loss: 0.003732755931952361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005959838415728882\n",
      "Training Loss: 0.0063018715812359\n",
      "Training Loss: 0.006013425081036985\n",
      "Validation Loss: 0.0037236983738734982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0059488197299651805\n",
      "Training Loss: 0.0062895545945502816\n",
      "Training Loss: 0.006001292574219406\n",
      "Validation Loss: 0.003714468774877572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005937671120045706\n",
      "Training Loss: 0.006277053236262872\n",
      "Training Loss: 0.005988951462786645\n",
      "Validation Loss: 0.003705050774033736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0059263864159584045\n",
      "Training Loss: 0.00626436787773855\n",
      "Training Loss: 0.005976405843393877\n",
      "Validation Loss: 0.0036954544046422823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005914959307410754\n",
      "Training Loss: 0.00625149977975525\n",
      "Training Loss: 0.00596366461890284\n",
      "Validation Loss: 0.00368568463332093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005903383295517415\n",
      "Training Loss: 0.006238452869001776\n",
      "Training Loss: 0.005950733697391115\n",
      "Validation Loss: 0.003675749317449884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005891650030971505\n",
      "Training Loss: 0.006225229888223112\n",
      "Training Loss: 0.005937616910669022\n",
      "Validation Loss: 0.0036656609762543706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.0058797528309514745\n",
      "Training Loss: 0.006211834406713024\n",
      "Training Loss: 0.0059243199304910375\n",
      "Validation Loss: 0.003655429430478619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005867682814132422\n",
      "Training Loss: 0.006198271432658657\n",
      "Training Loss: 0.00591084765503183\n",
      "Validation Loss: 0.0036450685505504104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0058554318093229085\n",
      "Training Loss: 0.006184547239681706\n",
      "Training Loss: 0.005897203809581697\n",
      "Validation Loss: 0.003634590626134422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005842992819380015\n",
      "Training Loss: 0.006170666321413592\n",
      "Training Loss: 0.005883393472759053\n",
      "Validation Loss: 0.00362400727783424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005830357697559521\n",
      "Training Loss: 0.0061566381761804225\n",
      "Training Loss: 0.005869422570103779\n",
      "Validation Loss: 0.003613327778980471\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.00581752288620919\n",
      "Training Loss: 0.006142469387268648\n",
      "Training Loss: 0.005855296648223885\n",
      "Validation Loss: 0.003602561772424267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005804481643717736\n",
      "Training Loss: 0.0061281702271662655\n",
      "Training Loss: 0.005841023583780042\n",
      "Validation Loss: 0.0035917168166593053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005791234850767069\n",
      "Training Loss: 0.0061137534165754915\n",
      "Training Loss: 0.005826614478137344\n",
      "Validation Loss: 0.00358080539755586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005777783415978775\n",
      "Training Loss: 0.006099228862440214\n",
      "Training Loss: 0.005812079097959213\n",
      "Validation Loss: 0.003569829035053302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0057641268958104775\n",
      "Training Loss: 0.006084610213292763\n",
      "Training Loss: 0.0057974304555682464\n",
      "Validation Loss: 0.0035588031986550418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005750276554026641\n",
      "Training Loss: 0.006069912275997922\n",
      "Training Loss: 0.005782684115692973\n",
      "Validation Loss: 0.003547738472999105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005736240939004347\n",
      "Training Loss: 0.006055151073960588\n",
      "Training Loss: 0.005767857683240436\n",
      "Validation Loss: 0.003536643613433319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005722035896615125\n",
      "Training Loss: 0.006040344588691369\n",
      "Training Loss: 0.0057529722084291275\n",
      "Validation Loss: 0.003525529016565343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005707679577171803\n",
      "Training Loss: 0.006025510731851682\n",
      "Training Loss: 0.005738045072648674\n",
      "Validation Loss: 0.0035144122346210177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005693194575724192\n",
      "Training Loss: 0.00601066869450733\n",
      "Training Loss: 0.0057231000845786185\n",
      "Validation Loss: 0.003503305903567901\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005678606198052875\n",
      "Training Loss: 0.0059958377096336335\n",
      "Training Loss: 0.005708157328190282\n",
      "Validation Loss: 0.0034922260818532093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0056639434321550655\n",
      "Training Loss: 0.005981036640005186\n",
      "Training Loss: 0.005693240480031819\n",
      "Validation Loss: 0.003481185702695982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005649238579208031\n",
      "Training Loss: 0.005966288902563974\n",
      "Training Loss: 0.0056783695775084195\n",
      "Validation Loss: 0.0034702061816102962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005634524261695333\n",
      "Training Loss: 0.0059516117069870235\n",
      "Training Loss: 0.005663565547438338\n",
      "Validation Loss: 0.003459303495945053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.00561983477906324\n",
      "Training Loss: 0.005937027658801526\n",
      "Training Loss: 0.005648848721757531\n",
      "Validation Loss: 0.003448488437335185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.00560520441737026\n",
      "Training Loss: 0.005922552648698911\n",
      "Training Loss: 0.00563423651328776\n",
      "Validation Loss: 0.003437780130921413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005590666556381621\n",
      "Training Loss: 0.0059082053194288164\n",
      "Training Loss: 0.005619744367431849\n",
      "Validation Loss: 0.003427188555066463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.0055762543331366035\n",
      "Training Loss: 0.005893999286927283\n",
      "Training Loss: 0.005605385814560577\n",
      "Validation Loss: 0.003416725893483989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00556199497601483\n",
      "Training Loss: 0.005879947219509632\n",
      "Training Loss: 0.005591170221450738\n",
      "Validation Loss: 0.0034063999348822355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.00554791372444015\n",
      "Training Loss: 0.0058660587581107395\n",
      "Training Loss: 0.005577106623677537\n",
      "Validation Loss: 0.0033962194954327654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005534032383002341\n",
      "Training Loss: 0.005852339846896939\n",
      "Training Loss: 0.005563199413591065\n",
      "Validation Loss: 0.0033861877798270225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005520369462901726\n",
      "Training Loss: 0.005838790754787624\n",
      "Training Loss: 0.005549446668592282\n",
      "Validation Loss: 0.0033763063021182093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005506934439763427\n",
      "Training Loss: 0.005825410921825096\n",
      "Training Loss: 0.005535848223953508\n",
      "Validation Loss: 0.0033665731381834225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005493735161726363\n",
      "Training Loss: 0.005812196286860853\n",
      "Training Loss: 0.005522397523745895\n",
      "Validation Loss: 0.003356980413637972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0054807740729302164\n",
      "Training Loss: 0.005799139264272526\n",
      "Training Loss: 0.0055090876470785585\n",
      "Validation Loss: 0.003347524706656218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005468050932395272\n",
      "Training Loss: 0.005786228215438314\n",
      "Training Loss: 0.005495908288867213\n",
      "Validation Loss: 0.0033381971036178177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005455560479895212\n",
      "Training Loss: 0.005773447499377653\n",
      "Training Loss: 0.005482846745871938\n",
      "Validation Loss: 0.003328984273006365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005443290527909994\n",
      "Training Loss: 0.005760784142185002\n",
      "Training Loss: 0.005469888064544648\n",
      "Validation Loss: 0.0033198770225895675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005431228745146654\n",
      "Training Loss: 0.005748218582593836\n",
      "Training Loss: 0.005457018903689459\n",
      "Validation Loss: 0.0033108612285074096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005419360806117765\n",
      "Training Loss: 0.005735732519533485\n",
      "Training Loss: 0.005444222690421156\n",
      "Validation Loss: 0.003301920519037737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.00540766728867311\n",
      "Training Loss: 0.005723304862622172\n",
      "Training Loss: 0.005431481432751752\n",
      "Validation Loss: 0.003293037290941254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.00539612753840629\n",
      "Training Loss: 0.005710916299140081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [23:20<02:35, 155.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0054187816148623825\n",
      "Validation Loss: 0.003284199184573287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5108993147313595\n",
      "Training Loss: 0.4473809024691582\n",
      "Training Loss: 0.357487793341279\n",
      "Validation Loss: 0.25067108082637357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.1887810906022787\n",
      "Training Loss: 0.10977435629814863\n",
      "Training Loss: 0.07297030368819833\n",
      "Validation Loss: 0.06328560173344076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.060242934804409745\n",
      "Training Loss: 0.05783965075388551\n",
      "Training Loss: 0.057008204571902754\n",
      "Validation Loss: 0.05639435166723273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05563240783289075\n",
      "Training Loss: 0.05411767950281501\n",
      "Training Loss: 0.05300019647926092\n",
      "Validation Loss: 0.05178766353369764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.05089874255470932\n",
      "Training Loss: 0.0492037797998637\n",
      "Training Loss: 0.047465157480910423\n",
      "Validation Loss: 0.045722457098910645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04464181664399803\n",
      "Training Loss: 0.0429092603828758\n",
      "Training Loss: 0.0406527481880039\n",
      "Validation Loss: 0.03863620695270849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.037481207894161345\n",
      "Training Loss: 0.03606997697614133\n",
      "Training Loss: 0.033643290363252164\n",
      "Validation Loss: 0.031697103371739054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.030672730403020976\n",
      "Training Loss: 0.029789441605098544\n",
      "Training Loss: 0.02740645066369325\n",
      "Validation Loss: 0.025600026754055465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.02474549107719213\n",
      "Training Loss: 0.0242725985404104\n",
      "Training Loss: 0.022021919027902185\n",
      "Validation Loss: 0.020366038520182116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.01980429021641612\n",
      "Training Loss: 0.01983790223253891\n",
      "Training Loss: 0.018094599638134243\n",
      "Validation Loss: 0.016805228327264946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01664640014525503\n",
      "Training Loss: 0.01710702394368127\n",
      "Training Loss: 0.015832983909640462\n",
      "Validation Loss: 0.014711607108939062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.014816880086436867\n",
      "Training Loss: 0.015402087427210063\n",
      "Training Loss: 0.014343891395255923\n",
      "Validation Loss: 0.013185201848469925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.01350411177612841\n",
      "Training Loss: 0.014106779019348323\n",
      "Training Loss: 0.013166414615698159\n",
      "Validation Loss: 0.01191705892260155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.01244417164241895\n",
      "Training Loss: 0.013041114236693829\n",
      "Training Loss: 0.012185518075712025\n",
      "Validation Loss: 0.010835969997203668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.01156566228484735\n",
      "Training Loss: 0.012149591899942606\n",
      "Training Loss: 0.011361684778239577\n",
      "Validation Loss: 0.009911949275417274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010835030225571245\n",
      "Training Loss: 0.01140283112647012\n",
      "Training Loss: 0.010671283134724945\n",
      "Validation Loss: 0.009123684011734603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.01022834881907329\n",
      "Training Loss: 0.010778391752392053\n",
      "Training Loss: 0.010094984931638464\n",
      "Validation Loss: 0.008452811203844678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0097255414375104\n",
      "Training Loss: 0.010256751223932952\n",
      "Training Loss: 0.009615445877425372\n",
      "Validation Loss: 0.007882893366707762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00930924016982317\n",
      "Training Loss: 0.009820778713328765\n",
      "Training Loss: 0.009217164744623006\n",
      "Validation Loss: 0.007399400625524394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00896461117779836\n",
      "Training Loss: 0.009455815302208065\n",
      "Training Loss: 0.008886669565690682\n",
      "Validation Loss: 0.006989761205976096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008679249160923063\n",
      "Training Loss: 0.009149653386557474\n",
      "Training Loss: 0.008612556139705702\n",
      "Validation Loss: 0.006643284411755589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008442919319495559\n",
      "Training Loss: 0.008892281906446442\n",
      "Training Loss: 0.008385298625798896\n",
      "Validation Loss: 0.006350885545625613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.00824720429489389\n",
      "Training Loss: 0.008675537450471893\n",
      "Training Loss: 0.008196988173294813\n",
      "Validation Loss: 0.006104841263274129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008085189639823511\n",
      "Training Loss: 0.008492769286967815\n",
      "Training Loss: 0.008041065152501687\n",
      "Validation Loss: 0.005898508537571166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007951158893993124\n",
      "Training Loss: 0.008338514424394816\n",
      "Training Loss: 0.007912052450701595\n",
      "Validation Loss: 0.005726089978360393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00784034086856991\n",
      "Training Loss: 0.008208230412565172\n",
      "Training Loss: 0.007805326075758785\n",
      "Validation Loss: 0.005582446581684053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007748705920530483\n",
      "Training Loss: 0.008098082641372456\n",
      "Training Loss: 0.0077169436344411224\n",
      "Validation Loss: 0.005462981865144848\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007672805192414671\n",
      "Training Loss: 0.008004772800486535\n",
      "Training Loss: 0.0076435176096856594\n",
      "Validation Loss: 0.005363591768768396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007609667667420581\n",
      "Training Loss: 0.007925435979850591\n",
      "Training Loss: 0.007582135270349681\n",
      "Validation Loss: 0.005280640252258922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007556740222498775\n",
      "Training Loss: 0.007857583173317835\n",
      "Training Loss: 0.007530318893259391\n",
      "Validation Loss: 0.00521096195816324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007511854965705425\n",
      "Training Loss: 0.007799067427404225\n",
      "Training Loss: 0.007485998847987503\n",
      "Validation Loss: 0.0051518843059292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007473213514313102\n",
      "Training Loss: 0.007748072609538212\n",
      "Training Loss: 0.0074474821600597355\n",
      "Validation Loss: 0.005101184787103132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007439356249524281\n",
      "Training Loss: 0.007703095215838403\n",
      "Training Loss: 0.00741342764114961\n",
      "Validation Loss: 0.005057083969292221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007409138709772378\n",
      "Training Loss: 0.007662924221949652\n",
      "Training Loss: 0.007382802872452885\n",
      "Validation Loss: 0.005018194325090376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0073816879652440544\n",
      "Training Loss: 0.007626599797513336\n",
      "Training Loss: 0.007354826079681516\n",
      "Validation Loss: 0.004983432704760703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0073563466360792515\n",
      "Training Loss: 0.007593376016011462\n",
      "Training Loss: 0.007328918926650658\n",
      "Validation Loss: 0.004951981848545289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0073326362739317115\n",
      "Training Loss: 0.007562683899886906\n",
      "Training Loss: 0.007304664333350957\n",
      "Validation Loss: 0.0049232278899498955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007310211518779397\n",
      "Training Loss: 0.007534086590167135\n",
      "Training Loss: 0.007281757962191477\n",
      "Validation Loss: 0.004896705516933181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0072888285934459415\n",
      "Training Loss: 0.007507254834054038\n",
      "Training Loss: 0.007259982739342376\n",
      "Validation Loss: 0.004872059875319639\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007268310867948458\n",
      "Training Loss: 0.007481934983516112\n",
      "Training Loss: 0.007239182227058336\n",
      "Validation Loss: 0.004849028671578912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007248537504347041\n",
      "Training Loss: 0.007457935797283426\n",
      "Training Loss: 0.0072192439122591165\n",
      "Validation Loss: 0.004827401867617717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007229421057272703\n",
      "Training Loss: 0.00743510578176938\n",
      "Training Loss: 0.007200083718635142\n",
      "Validation Loss: 0.004807017270077983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007210901490179822\n",
      "Training Loss: 0.007413325714878738\n",
      "Training Loss: 0.007181640642229468\n",
      "Validation Loss: 0.004787746483978051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007192934169434011\n",
      "Training Loss: 0.007392502394504845\n",
      "Training Loss: 0.007163863622117787\n",
      "Validation Loss: 0.004769480676034444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007175486088963226\n",
      "Training Loss: 0.007372553176246584\n",
      "Training Loss: 0.007146712666144595\n",
      "Validation Loss: 0.004752135444484818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007158531141467393\n",
      "Training Loss: 0.007353413589298725\n",
      "Training Loss: 0.0071301541279535745\n",
      "Validation Loss: 0.004735630522272811\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007142047745874152\n",
      "Training Loss: 0.007335027173394337\n",
      "Training Loss: 0.0071141585160512475\n",
      "Validation Loss: 0.004719908016320485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007126019316492602\n",
      "Training Loss: 0.0073173410305753354\n",
      "Training Loss: 0.00709869852871634\n",
      "Validation Loss: 0.00470490660910819\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007110428665764629\n",
      "Training Loss: 0.007300311732105911\n",
      "Training Loss: 0.007083748368313536\n",
      "Validation Loss: 0.0046905764866505195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007095260203350336\n",
      "Training Loss: 0.0072838967491406946\n",
      "Training Loss: 0.0070692833815701305\n",
      "Validation Loss: 0.004676867713314596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007080498628783971\n",
      "Training Loss: 0.007268056998727843\n",
      "Training Loss: 0.007055279235355556\n",
      "Validation Loss: 0.004663743524095357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007066128883743659\n",
      "Training Loss: 0.007252758382819593\n",
      "Training Loss: 0.007041713852668181\n",
      "Validation Loss: 0.004651163861003778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007052134552504867\n",
      "Training Loss: 0.007237964645028115\n",
      "Training Loss: 0.007028562144841999\n",
      "Validation Loss: 0.004639093985184609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007038501086644828\n",
      "Training Loss: 0.007223645487101749\n",
      "Training Loss: 0.007015804965049028\n",
      "Validation Loss: 0.004627502709757955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007025214042514562\n",
      "Training Loss: 0.007209768074098974\n",
      "Training Loss: 0.007003419123357162\n",
      "Validation Loss: 0.004616356461329825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00701225554686971\n",
      "Training Loss: 0.007196304994868115\n",
      "Training Loss: 0.006991381689440459\n",
      "Validation Loss: 0.00460562517858644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00699961039586924\n",
      "Training Loss: 0.007183227053610608\n",
      "Training Loss: 0.006979671518784016\n",
      "Validation Loss: 0.004595281120672236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006987261791946367\n",
      "Training Loss: 0.007170505120884627\n",
      "Training Loss: 0.006968267072224989\n",
      "Validation Loss: 0.004585298541488566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006975193712860346\n",
      "Training Loss: 0.0071581154828891155\n",
      "Training Loss: 0.006957149744266644\n",
      "Validation Loss: 0.004575651613184449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006963389972224831\n",
      "Training Loss: 0.007146031111478806\n",
      "Training Loss: 0.0069462989538442346\n",
      "Validation Loss: 0.0045663177917366115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006951835073996335\n",
      "Training Loss: 0.007134230048395693\n",
      "Training Loss: 0.006935696481959895\n",
      "Validation Loss: 0.004557274626646442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0069405141961760815\n",
      "Training Loss: 0.007122688899980858\n",
      "Training Loss: 0.006925323280738666\n",
      "Validation Loss: 0.0045485037125207566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006929412635508924\n",
      "Training Loss: 0.0071113877929747105\n",
      "Training Loss: 0.006915164880920202\n",
      "Validation Loss: 0.004539979543939777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006918516455916688\n",
      "Training Loss: 0.007100306565407663\n",
      "Training Loss: 0.006905204303329811\n",
      "Validation Loss: 0.004531692183089934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006907812295248732\n",
      "Training Loss: 0.00708942614030093\n",
      "Training Loss: 0.006895428521092981\n",
      "Validation Loss: 0.004523618815184226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006897289276821539\n",
      "Training Loss: 0.0070787321764510126\n",
      "Training Loss: 0.006885824128985405\n",
      "Validation Loss: 0.004515746435715577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006886936200316995\n",
      "Training Loss: 0.007068208457203582\n",
      "Training Loss: 0.00687637928291224\n",
      "Validation Loss: 0.00450805592641046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006876741856103763\n",
      "Training Loss: 0.007057842897484079\n",
      "Training Loss: 0.006867083350662142\n",
      "Validation Loss: 0.004500542431180313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00686669854214415\n",
      "Training Loss: 0.0070476225332822655\n",
      "Training Loss: 0.006857929030666128\n",
      "Validation Loss: 0.004493186085516315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006856798056978732\n",
      "Training Loss: 0.0070375391480047254\n",
      "Training Loss: 0.006848908376414328\n",
      "Validation Loss: 0.004485981952231587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006847033933736384\n",
      "Training Loss: 0.007027582481969148\n",
      "Training Loss: 0.006840014365734532\n",
      "Validation Loss: 0.004478913957509474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006837398706702516\n",
      "Training Loss: 0.007017745898338035\n",
      "Training Loss: 0.006831241690088063\n",
      "Validation Loss: 0.004471978970562641\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006827889007981866\n",
      "Training Loss: 0.0070080249779857695\n",
      "Training Loss: 0.006822587555507198\n",
      "Validation Loss: 0.004465166284451575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006818500010995194\n",
      "Training Loss: 0.006998414666159078\n",
      "Training Loss: 0.006814048234373331\n",
      "Validation Loss: 0.004458471989452714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006809229388600215\n",
      "Training Loss: 0.006988910806830973\n",
      "Training Loss: 0.006805620860541239\n",
      "Validation Loss: 0.004451884749460589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006800073240883648\n",
      "Training Loss: 0.006979511877289042\n",
      "Training Loss: 0.006797305428190157\n",
      "Validation Loss: 0.004445406571004456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006791030241874978\n",
      "Training Loss: 0.00697021622210741\n",
      "Training Loss: 0.006789098376175389\n",
      "Validation Loss: 0.004439026387434536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.00678209689212963\n",
      "Training Loss: 0.006961023842450231\n",
      "Training Loss: 0.006781001130584627\n",
      "Validation Loss: 0.004432744302739797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006773274337174371\n",
      "Training Loss: 0.006951932986266911\n",
      "Training Loss: 0.00677301186718978\n",
      "Validation Loss: 0.004426550918672067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006764559774892404\n",
      "Training Loss: 0.006942944377660751\n",
      "Training Loss: 0.00676513142650947\n",
      "Validation Loss: 0.00442044889577926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006755952715175226\n",
      "Training Loss: 0.006934057169128209\n",
      "Training Loss: 0.0067573584290221336\n",
      "Validation Loss: 0.004414431542142431\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006747450835537166\n",
      "Training Loss: 0.006925273346714675\n",
      "Training Loss: 0.006749692455632612\n",
      "Validation Loss: 0.004408497245605575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0067390539031475785\n",
      "Training Loss: 0.006916593099012971\n",
      "Training Loss: 0.006742135193198919\n",
      "Validation Loss: 0.004402646081380839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006730761626968161\n",
      "Training Loss: 0.006908016639063135\n",
      "Training Loss: 0.0067346847243607046\n",
      "Validation Loss: 0.0043968745334638975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0067225718905683605\n",
      "Training Loss: 0.006899544324260205\n",
      "Training Loss: 0.0067273402283899485\n",
      "Validation Loss: 0.004391176949171454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00671448468696326\n",
      "Training Loss: 0.006891175457276404\n",
      "Training Loss: 0.006720101557439193\n",
      "Validation Loss: 0.0043855529066614725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006706497998675331\n",
      "Training Loss: 0.006882912856526673\n",
      "Training Loss: 0.00671296825283207\n",
      "Validation Loss: 0.004380002965773927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006698610224993899\n",
      "Training Loss: 0.006874755478929728\n",
      "Training Loss: 0.006705938953673467\n",
      "Validation Loss: 0.004374521812607189\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006690821463707835\n",
      "Training Loss: 0.006866702990373596\n",
      "Training Loss: 0.006699013713514433\n",
      "Validation Loss: 0.004369111737534613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.0066831304249353705\n",
      "Training Loss: 0.006858755165012553\n",
      "Training Loss: 0.006692189408931881\n",
      "Validation Loss: 0.00436376453850816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006675533414818346\n",
      "Training Loss: 0.006850911506917328\n",
      "Training Loss: 0.006685465287882835\n",
      "Validation Loss: 0.004358486018635416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0066680320748128\n",
      "Training Loss: 0.006843171826330945\n",
      "Training Loss: 0.006678839616943151\n",
      "Validation Loss: 0.00435326807070105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006660622979979962\n",
      "Training Loss: 0.006835536304861307\n",
      "Training Loss: 0.00667231286643073\n",
      "Validation Loss: 0.0043481152911482145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0066533063538372515\n",
      "Training Loss: 0.006828002918045968\n",
      "Training Loss: 0.006665881384396926\n",
      "Validation Loss: 0.004343022717283306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006646078262710944\n",
      "Training Loss: 0.006820570250274613\n",
      "Training Loss: 0.006659543779678642\n",
      "Validation Loss: 0.004337986843566295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006638938871910796\n",
      "Training Loss: 0.006813238675240427\n",
      "Training Loss: 0.006653296982403844\n",
      "Validation Loss: 0.004333004759614136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006631886450340971\n",
      "Training Loss: 0.006806005161488429\n",
      "Training Loss: 0.006647141051944345\n",
      "Validation Loss: 0.004328082698878696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.0066249186079949144\n",
      "Training Loss: 0.006798870168859139\n",
      "Training Loss: 0.006641072743805126\n",
      "Validation Loss: 0.00432321340044479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006618034858256579\n",
      "Training Loss: 0.006791831267764792\n",
      "Training Loss: 0.006635092282667756\n",
      "Validation Loss: 0.004318397263917821\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006611233140574768\n",
      "Training Loss: 0.006784886217210442\n",
      "Training Loss: 0.006629196120193228\n",
      "Validation Loss: 0.004313634431219838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006604512527119368\n",
      "Training Loss: 0.006778034176677466\n",
      "Training Loss: 0.006623382868710905\n",
      "Validation Loss: 0.0043089250200742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.0065978708991315214\n",
      "Training Loss: 0.0067712744325399395\n",
      "Training Loss: 0.00661765162134543\n",
      "Validation Loss: 0.004304261978197676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006591306113405153\n",
      "Training Loss: 0.006764605039497837\n",
      "Training Loss: 0.006611998273292556\n",
      "Validation Loss: 0.004299646930172621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0065848178486339745\n",
      "Training Loss: 0.0067580228939186785\n",
      "Training Loss: 0.006606422015465796\n",
      "Validation Loss: 0.004295078008775756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0065784043550957\n",
      "Training Loss: 0.00675152791198343\n",
      "Training Loss: 0.006600920826895162\n",
      "Validation Loss: 0.0042905562892137615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006572062722407282\n",
      "Training Loss: 0.006745118162361905\n",
      "Training Loss: 0.006595493711065501\n",
      "Validation Loss: 0.0042860780906696086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006565792637411505\n",
      "Training Loss: 0.0067387891677208244\n",
      "Training Loss: 0.006590136489830911\n",
      "Validation Loss: 0.004281641520413287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006559591621626168\n",
      "Training Loss: 0.006732541766250506\n",
      "Training Loss: 0.006584849767386913\n",
      "Validation Loss: 0.004277249300470471\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.0065534590627066795\n",
      "Training Loss: 0.006726374119753018\n",
      "Training Loss: 0.00657963149365969\n",
      "Validation Loss: 0.004272898664342218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.00654739378252998\n",
      "Training Loss: 0.00672028309549205\n",
      "Training Loss: 0.006574479236733168\n",
      "Validation Loss: 0.004268587850102255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006541393350344152\n",
      "Training Loss: 0.006714268111390993\n",
      "Training Loss: 0.0065693901979830115\n",
      "Validation Loss: 0.004264313511137086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006535456400597468\n",
      "Training Loss: 0.006708326215157285\n",
      "Training Loss: 0.006564363852376119\n",
      "Validation Loss: 0.004260075673607461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006529580490896478\n",
      "Training Loss: 0.006702455468475818\n",
      "Training Loss: 0.006559397024102509\n",
      "Validation Loss: 0.004255872730589524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006523765538586304\n",
      "Training Loss: 0.006696655539562926\n",
      "Training Loss: 0.0065544905688148\n",
      "Validation Loss: 0.004251706118962278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006518008790444583\n",
      "Training Loss: 0.006690922445850447\n",
      "Training Loss: 0.006549640266457573\n",
      "Validation Loss: 0.004247576271686075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006512308827368542\n",
      "Training Loss: 0.00668525489512831\n",
      "Training Loss: 0.006544845113530755\n",
      "Validation Loss: 0.004243475608030606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006506664847256616\n",
      "Training Loss: 0.006679650840815157\n",
      "Training Loss: 0.006540103470906615\n",
      "Validation Loss: 0.004239408199262041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006501074269181117\n",
      "Training Loss: 0.006674109409796074\n",
      "Training Loss: 0.006535413302481174\n",
      "Validation Loss: 0.004235371048666872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0064955350093077865\n",
      "Training Loss: 0.006668627541512251\n",
      "Training Loss: 0.006530773304402829\n",
      "Validation Loss: 0.00423136090904244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006490046476246789\n",
      "Training Loss: 0.006663203621283174\n",
      "Training Loss: 0.006526180319488048\n",
      "Validation Loss: 0.004227379141401583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006484605772420764\n",
      "Training Loss: 0.006657835567602887\n",
      "Training Loss: 0.006521634651580826\n",
      "Validation Loss: 0.004223423780418221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006479211946716532\n",
      "Training Loss: 0.006652521694777533\n",
      "Training Loss: 0.006517133103916422\n",
      "Validation Loss: 0.004219490999429162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006473863503197208\n",
      "Training Loss: 0.0066472601552959535\n",
      "Training Loss: 0.00651267436449416\n",
      "Validation Loss: 0.004215581046961499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006468557259067893\n",
      "Training Loss: 0.006642048307694495\n",
      "Training Loss: 0.006508256956003607\n",
      "Validation Loss: 0.004211698172828496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006463293597334996\n",
      "Training Loss: 0.006636884739855305\n",
      "Training Loss: 0.006503879169467836\n",
      "Validation Loss: 0.0042078338427406345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006458070122171193\n",
      "Training Loss: 0.006631767286453396\n",
      "Training Loss: 0.006499538493808359\n",
      "Validation Loss: 0.004203989384355798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006452884362079203\n",
      "Training Loss: 0.006626695630839095\n",
      "Training Loss: 0.006495234221220016\n",
      "Validation Loss: 0.004200164146271398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006447734461398795\n",
      "Training Loss: 0.0066216648987028745\n",
      "Training Loss: 0.006490964373806491\n",
      "Validation Loss: 0.0041963558453082875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006442619311856106\n",
      "Training Loss: 0.00661667428445071\n",
      "Training Loss: 0.0064867261587642135\n",
      "Validation Loss: 0.004192563060283912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006437536119483412\n",
      "Training Loss: 0.006611722612287849\n",
      "Training Loss: 0.0064825196017045525\n",
      "Validation Loss: 0.004188784619196831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006432484360411763\n",
      "Training Loss: 0.006606806867057458\n",
      "Training Loss: 0.0064783408935181796\n",
      "Validation Loss: 0.0041850183729417205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006427460047416389\n",
      "Training Loss: 0.006601926217554137\n",
      "Training Loss: 0.006474190243752673\n",
      "Validation Loss: 0.004181265879391033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006422462949994951\n",
      "Training Loss: 0.006597076989710331\n",
      "Training Loss: 0.0064700647059362385\n",
      "Validation Loss: 0.004177522063359953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0064174919482320545\n",
      "Training Loss: 0.006592259019380435\n",
      "Training Loss: 0.006465963938971982\n",
      "Validation Loss: 0.004173785584110222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006412542898906395\n",
      "Training Loss: 0.006587469191290438\n",
      "Training Loss: 0.0064618835086002946\n",
      "Validation Loss: 0.004170055569180947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006407614975469187\n",
      "Training Loss: 0.006582705988548696\n",
      "Training Loss: 0.006457823642995209\n",
      "Validation Loss: 0.004166331834138863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.00640270633623004\n",
      "Training Loss: 0.006577966642798856\n",
      "Training Loss: 0.006453782301396132\n",
      "Validation Loss: 0.004162610675276289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0063978151942137625\n",
      "Training Loss: 0.006573251021327451\n",
      "Training Loss: 0.006449758124072105\n",
      "Validation Loss: 0.00415889541304597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006392940101213753\n",
      "Training Loss: 0.006568554954137653\n",
      "Training Loss: 0.006445749066770077\n",
      "Validation Loss: 0.004155180533416569\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.0063880791049450636\n",
      "Training Loss: 0.006563877643784508\n",
      "Training Loss: 0.006441753042163327\n",
      "Validation Loss: 0.004151463180288589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.0063832288433332\n",
      "Training Loss: 0.006559217404574155\n",
      "Training Loss: 0.0064377687056548895\n",
      "Validation Loss: 0.004147744197346103\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006378388217417524\n",
      "Training Loss: 0.0065545713983010505\n",
      "Training Loss: 0.006433793243486434\n",
      "Validation Loss: 0.004144018634975878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006373554981546476\n",
      "Training Loss: 0.006549937762320042\n",
      "Training Loss: 0.006429825968807563\n",
      "Validation Loss: 0.004140289220435733\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0063687272113747894\n",
      "Training Loss: 0.006545314023969695\n",
      "Training Loss: 0.006425864911871031\n",
      "Validation Loss: 0.004136553955698658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006363903470337391\n",
      "Training Loss: 0.006540698843309656\n",
      "Training Loss: 0.00642190761398524\n",
      "Validation Loss: 0.004132808572638863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006359079771209508\n",
      "Training Loss: 0.006536089512519538\n",
      "Training Loss: 0.006417952623451129\n",
      "Validation Loss: 0.004129048824059159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006354255318874493\n",
      "Training Loss: 0.006531485003652051\n",
      "Training Loss: 0.0064139968494419\n",
      "Validation Loss: 0.004125277768804828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006349427145905793\n",
      "Training Loss: 0.00652688137604855\n",
      "Training Loss: 0.006410039940383285\n",
      "Validation Loss: 0.004121490315340585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006344594352412969\n",
      "Training Loss: 0.006522278230404481\n",
      "Training Loss: 0.0064060788578353825\n",
      "Validation Loss: 0.0041176849594235084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.00633975381613709\n",
      "Training Loss: 0.00651767224422656\n",
      "Training Loss: 0.0064021124073769895\n",
      "Validation Loss: 0.004113863476060247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006334902573144063\n",
      "Training Loss: 0.006513061217265204\n",
      "Training Loss: 0.00639813874848187\n",
      "Validation Loss: 0.004110019592557814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006330040090251714\n",
      "Training Loss: 0.0065084432438015935\n",
      "Training Loss: 0.006394154587760568\n",
      "Validation Loss: 0.004106152059740565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006325162586290389\n",
      "Training Loss: 0.006503816351760179\n",
      "Training Loss: 0.006390158974099904\n",
      "Validation Loss: 0.004102257559117809\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006320268447743729\n",
      "Training Loss: 0.006499177858931944\n",
      "Training Loss: 0.006386149105383083\n",
      "Validation Loss: 0.004098337052750998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006315355066908524\n",
      "Training Loss: 0.006494524674490094\n",
      "Training Loss: 0.00638212343910709\n",
      "Validation Loss: 0.004094387014825525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006310419227229431\n",
      "Training Loss: 0.006489855715772137\n",
      "Training Loss: 0.006378079652786255\n",
      "Validation Loss: 0.004090401395014749\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006305459483992308\n",
      "Training Loss: 0.006485167524078861\n",
      "Training Loss: 0.00637401521904394\n",
      "Validation Loss: 0.00408638296439574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.00630047274637036\n",
      "Training Loss: 0.006480458341538906\n",
      "Training Loss: 0.006369928346248344\n",
      "Validation Loss: 0.004082329470528227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006295456347288564\n",
      "Training Loss: 0.006475724508054555\n",
      "Training Loss: 0.006365815961034968\n",
      "Validation Loss: 0.004078231213661434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006290408050408587\n",
      "Training Loss: 0.006470965502085164\n",
      "Training Loss: 0.006361676355591044\n",
      "Validation Loss: 0.0040740925502136685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006285323812626302\n",
      "Training Loss: 0.006466176287503913\n",
      "Training Loss: 0.006357506414642558\n",
      "Validation Loss: 0.004069907309518855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006280201906338334\n",
      "Training Loss: 0.0064613561099395155\n",
      "Training Loss: 0.006353304116055369\n",
      "Validation Loss: 0.004065675319570085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006275038282619789\n",
      "Training Loss: 0.006456500368658453\n",
      "Training Loss: 0.006349067178089172\n",
      "Validation Loss: 0.004061387963671489\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006269831301178783\n",
      "Training Loss: 0.006451607700437307\n",
      "Training Loss: 0.006344791881274432\n",
      "Validation Loss: 0.004057048358876007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006264577866531908\n",
      "Training Loss: 0.006446675176266581\n",
      "Training Loss: 0.006340476478217169\n",
      "Validation Loss: 0.004052649263234997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006259273337200284\n",
      "Training Loss: 0.006441699140705168\n",
      "Training Loss: 0.006336118613835424\n",
      "Validation Loss: 0.0040481917022497215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006253915993729606\n",
      "Training Loss: 0.006436676307348534\n",
      "Training Loss: 0.00633171543944627\n",
      "Validation Loss: 0.004043668486947047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006248501669615507\n",
      "Training Loss: 0.006431604806566611\n",
      "Training Loss: 0.0063272630632855\n",
      "Validation Loss: 0.00403907932628867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.00624302766053006\n",
      "Training Loss: 0.006426481259986758\n",
      "Training Loss: 0.006322759167524054\n",
      "Validation Loss: 0.0040344196401819\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006237490712665022\n",
      "Training Loss: 0.006421301973750815\n",
      "Training Loss: 0.006318201762624085\n",
      "Validation Loss: 0.004029683465284578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006231885900488124\n",
      "Training Loss: 0.006416063338983804\n",
      "Training Loss: 0.006313586407341063\n",
      "Validation Loss: 0.004024870764971659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006226211173925549\n",
      "Training Loss: 0.006410763546591624\n",
      "Training Loss: 0.0063089102983940396\n",
      "Validation Loss: 0.0040199767204336405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0062204622384160755\n",
      "Training Loss: 0.0064053987618535755\n",
      "Training Loss: 0.006304170658695512\n",
      "Validation Loss: 0.0040149973807437865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006214635473443195\n",
      "Training Loss: 0.00639996508252807\n",
      "Training Loss: 0.006299364665756002\n",
      "Validation Loss: 0.004009927091910765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006208727373741567\n",
      "Training Loss: 0.006394459886942059\n",
      "Training Loss: 0.006294488678686321\n",
      "Validation Loss: 0.0040047652234605855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0062027338205371055\n",
      "Training Loss: 0.006388879641890526\n",
      "Training Loss: 0.006289540028083138\n",
      "Validation Loss: 0.003999506969664121\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.0061966515297535805\n",
      "Training Loss: 0.00638322105165571\n",
      "Training Loss: 0.006284514819853939\n",
      "Validation Loss: 0.003994147458082337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0061904759600292895\n",
      "Training Loss: 0.006377480888040736\n",
      "Training Loss: 0.006279410165734589\n",
      "Validation Loss: 0.003988683375456695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006184203907614574\n",
      "Training Loss: 0.0063716563815250996\n",
      "Training Loss: 0.006274223432410508\n",
      "Validation Loss: 0.003983110520371309\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0061778318218421195\n",
      "Training Loss: 0.006365743428468704\n",
      "Training Loss: 0.006268950091325678\n",
      "Validation Loss: 0.0039774249477856115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.0061713558749761435\n",
      "Training Loss: 0.006359739033505321\n",
      "Training Loss: 0.0062635884818155315\n",
      "Validation Loss: 0.003971624812712956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006164771917974576\n",
      "Training Loss: 0.006353641430614516\n",
      "Training Loss: 0.006258133999072015\n",
      "Validation Loss: 0.003965702883014979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006158077642321586\n",
      "Training Loss: 0.006347447612206451\n",
      "Training Loss: 0.006252585852635093\n",
      "Validation Loss: 0.003959660587722457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006151269298279658\n",
      "Training Loss: 0.006341155206318945\n",
      "Training Loss: 0.006246939917327836\n",
      "Validation Loss: 0.003953491312744661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.0061443434690590945\n",
      "Training Loss: 0.006334761044709012\n",
      "Training Loss: 0.00624119374610018\n",
      "Validation Loss: 0.0039471952523251344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006137297180248425\n",
      "Training Loss: 0.006328264456242323\n",
      "Training Loss: 0.006235345725435763\n",
      "Validation Loss: 0.003940766429387326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006130129055818543\n",
      "Training Loss: 0.006321662653353996\n",
      "Training Loss: 0.006229392414097674\n",
      "Validation Loss: 0.003934204853087497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006122835571877658\n",
      "Training Loss: 0.006314954332774505\n",
      "Training Loss: 0.006223333341185935\n",
      "Validation Loss: 0.003927507098329913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006115415474632755\n",
      "Training Loss: 0.0063081402477109805\n",
      "Training Loss: 0.006217165807611309\n",
      "Validation Loss: 0.003920671221371112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006107868320541456\n",
      "Training Loss: 0.00630121806578245\n",
      "Training Loss: 0.006210889122448862\n",
      "Validation Loss: 0.003913697109065866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.0061001918651163575\n",
      "Training Loss: 0.006294190571061335\n",
      "Training Loss: 0.006204502743785269\n",
      "Validation Loss: 0.003906590280023644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.00609238759148866\n",
      "Training Loss: 0.006287057711160742\n",
      "Training Loss: 0.006198006795602851\n",
      "Validation Loss: 0.003899342086809698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006084455489180982\n",
      "Training Loss: 0.006279821764328517\n",
      "Training Loss: 0.006191401559044607\n",
      "Validation Loss: 0.0038919595091111876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006076396926073357\n",
      "Training Loss: 0.006272484429646283\n",
      "Training Loss: 0.006184687585919164\n",
      "Validation Loss: 0.003884442197028129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0060682137624826285\n",
      "Training Loss: 0.006265049274079501\n",
      "Training Loss: 0.006177867718506604\n",
      "Validation Loss: 0.003876798724091162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.0060599102103151385\n",
      "Training Loss: 0.0062575199565617365\n",
      "Training Loss: 0.006170942866592668\n",
      "Validation Loss: 0.0038690262243905094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006051489018136636\n",
      "Training Loss: 0.006249903017887846\n",
      "Training Loss: 0.006163916844525374\n",
      "Validation Loss: 0.003861133132804855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006042956155724823\n",
      "Training Loss: 0.006242202816647478\n",
      "Training Loss: 0.006156792669789865\n",
      "Validation Loss: 0.0038531253341941183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.0060343163111247124\n",
      "Training Loss: 0.00623442615265958\n",
      "Training Loss: 0.006149575138115324\n",
      "Validation Loss: 0.0038450098461785425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006025578082771972\n",
      "Training Loss: 0.006226580180809833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [25:55<00:00, 155.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006142269764677621\n",
      "Validation Loss: 0.00383679581782519\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (28500, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.05741132697090506\n",
      "Training Loss: 0.053655036222189666\n",
      "Training Loss: 0.05432945285923779\n",
      "Validation Loss: 0.053074505567299514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0488231041142717\n",
      "Training Loss: 0.044384276093915105\n",
      "Training Loss: 0.04231510546058417\n",
      "Validation Loss: 0.03819134993625156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.03374564039288089\n",
      "Training Loss: 0.028277328456752\n",
      "Training Loss: 0.025849825323093684\n",
      "Validation Loss: 0.022820346827848993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.01977320486679673\n",
      "Training Loss: 0.016799800004810093\n",
      "Training Loss: 0.015892053158022463\n",
      "Validation Loss: 0.014047096126315215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.012186548920581117\n",
      "Training Loss: 0.010088495732634328\n",
      "Training Loss: 0.009444272364489734\n",
      "Validation Loss: 0.007948408562564449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.006935367131372914\n",
      "Training Loss: 0.005156569896498695\n",
      "Training Loss: 0.00449848200660199\n",
      "Validation Loss: 0.0037435430489229354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.002973780500469729\n",
      "Training Loss: 0.0017099639079242478\n",
      "Training Loss: 0.0014747014282329473\n",
      "Validation Loss: 0.002217201091247098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.0011650787140388274\n",
      "Training Loss: 0.000694986055168556\n",
      "Training Loss: 0.0007584499685617629\n",
      "Validation Loss: 0.0016510603503713886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.000753292662629974\n",
      "Training Loss: 0.000541615986294346\n",
      "Training Loss: 0.0005850268019275972\n",
      "Validation Loss: 0.001172352377344917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.0005885948603099678\n",
      "Training Loss: 0.0004702912376524182\n",
      "Training Loss: 0.0004952737540588714\n",
      "Validation Loss: 0.00086673951730344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0005020009525469504\n",
      "Training Loss: 0.00042606548257026586\n",
      "Training Loss: 0.0004414031553824316\n",
      "Validation Loss: 0.0006854496373869531\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0004529336210907786\n",
      "Training Loss: 0.0003947183228228823\n",
      "Training Loss: 0.00040499743179680083\n",
      "Validation Loss: 0.0005758649644571398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00042138919827266363\n",
      "Training Loss: 0.0003695213227183558\n",
      "Training Loss: 0.0003774874471127987\n",
      "Validation Loss: 0.0005049647321418357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00039802235143724827\n",
      "Training Loss: 0.0003479876334677101\n",
      "Training Loss: 0.0003551562809661846\n",
      "Validation Loss: 0.0004548802670173797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.00037890109946602023\n",
      "Training Loss: 0.0003292663516913308\n",
      "Training Loss: 0.00033635379564657343\n",
      "Validation Loss: 0.0004166740401886048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0003624177438177867\n",
      "Training Loss: 0.0003129251661448507\n",
      "Training Loss: 0.0003202025493737892\n",
      "Validation Loss: 0.0003859592816502044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0003478489203916979\n",
      "Training Loss: 0.0002985949194408022\n",
      "Training Loss: 0.00030612386053689987\n",
      "Validation Loss: 0.00036047057916078026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00033479683646874035\n",
      "Training Loss: 0.00028593354531039947\n",
      "Training Loss: 0.0002936961864179466\n",
      "Validation Loss: 0.0003389268142731698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0003230048670229735\n",
      "Training Loss: 0.00027464837568913936\n",
      "Training Loss: 0.0002826041530715884\n",
      "Validation Loss: 0.00032050378645640757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.0003122858663118677\n",
      "Training Loss: 0.00026450224771906505\n",
      "Training Loss: 0.000272613033412199\n",
      "Validation Loss: 0.0003046116472749704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00030249402163462947\n",
      "Training Loss: 0.0002553088081549504\n",
      "Training Loss: 0.00026354400422860634\n",
      "Validation Loss: 0.000290788954066301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00029350916633120506\n",
      "Training Loss: 0.0002469217482212116\n",
      "Training Loss: 0.0002552622320217779\n",
      "Validation Loss: 0.000278666357516659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0002852317303040763\n",
      "Training Loss: 0.0002392252402387385\n",
      "Training Loss: 0.00024765989037405233\n",
      "Validation Loss: 0.0002679363545651673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00027757477459090297\n",
      "Training Loss: 0.00023212713886096027\n",
      "Training Loss: 0.00024065099460131024\n",
      "Validation Loss: 0.00025835619351383186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00027046517468988897\n",
      "Training Loss: 0.0002255516141121916\n",
      "Training Loss: 0.00023416461786837317\n",
      "Validation Loss: 0.00024972556442907863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00026383935186458985\n",
      "Training Loss: 0.00021943692854620167\n",
      "Training Loss: 0.00022814166695752646\n",
      "Validation Loss: 0.0002418881411951302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0002576439587937784\n",
      "Training Loss: 0.00021373096051320318\n",
      "Training Loss: 0.00022253228900808608\n",
      "Validation Loss: 0.00023471506320991753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00025183270867273677\n",
      "Training Loss: 0.0002083900240904768\n",
      "Training Loss: 0.0002172927307401551\n",
      "Validation Loss: 0.00022810720327654278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0002463656009058468\n",
      "Training Loss: 0.0002033764532643545\n",
      "Training Loss: 0.00021238598154013744\n",
      "Validation Loss: 0.00022198504188197424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00024120933983795112\n",
      "Training Loss: 0.00019865831714923842\n",
      "Training Loss: 0.00020777898869710044\n",
      "Validation Loss: 0.00021628291105617393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00023633383454580326\n",
      "Training Loss: 0.0001942074437829433\n",
      "Training Loss: 0.00020344328968349145\n",
      "Validation Loss: 0.00021094979889680411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00023171391894720726\n",
      "Training Loss: 0.00018999999518200638\n",
      "Training Loss: 0.00019935351498133968\n",
      "Validation Loss: 0.0002059456624981445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0002273274316394236\n",
      "Training Loss: 0.0001860138173105952\n",
      "Training Loss: 0.000195486991215148\n",
      "Validation Loss: 0.00020123393465490132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00022315463327686304\n",
      "Training Loss: 0.00018223036135168514\n",
      "Training Loss: 0.00019182355725206435\n",
      "Validation Loss: 0.00019678903673808195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00021917804373515536\n",
      "Training Loss: 0.00017863272712929758\n",
      "Training Loss: 0.00018834479453289533\n",
      "Validation Loss: 0.00019258439492710912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0002153820615785662\n",
      "Training Loss: 0.00017520563640573527\n",
      "Training Loss: 0.00018503446619433817\n",
      "Validation Loss: 0.0001886006478170192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00021175230947847011\n",
      "Training Loss: 0.00017193555073390598\n",
      "Training Loss: 0.00018187791252785246\n",
      "Validation Loss: 0.00018481886865956358\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0002082763515500119\n",
      "Training Loss: 0.00016880996703548588\n",
      "Training Loss: 0.00017886130397528176\n",
      "Validation Loss: 0.00018122314031643327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0002049426723169745\n",
      "Training Loss: 0.00016581757738094892\n",
      "Training Loss: 0.00017597244290300294\n",
      "Validation Loss: 0.0001777986829468962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00020174055149254854\n",
      "Training Loss: 0.00016294845914671896\n",
      "Training Loss: 0.00017320039869446192\n",
      "Validation Loss: 0.0001745318318937913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00019866026155796135\n",
      "Training Loss: 0.00016019309739931487\n",
      "Training Loss: 0.00017053489633326536\n",
      "Validation Loss: 0.00017140989984909538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00019569254840462236\n",
      "Training Loss: 0.00015754274925711798\n",
      "Training Loss: 0.00016796664605863042\n",
      "Validation Loss: 0.0001684220244007949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00019282906843727686\n",
      "Training Loss: 0.00015498921084144968\n",
      "Training Loss: 0.00016548731075090471\n",
      "Validation Loss: 0.00016555708434986698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00019006215887202416\n",
      "Training Loss: 0.00015252526640324504\n",
      "Training Loss: 0.0001630894142726902\n",
      "Validation Loss: 0.00016280506638446403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00018738436745479703\n",
      "Training Loss: 0.00015014448375950452\n",
      "Training Loss: 0.00016076582194727963\n",
      "Validation Loss: 0.0001601564697389886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00018478911319107282\n",
      "Training Loss: 0.00014784060313104418\n",
      "Training Loss: 0.0001585105015328736\n",
      "Validation Loss: 0.0001576035123884487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0001822700992670434\n",
      "Training Loss: 0.00014560755698767025\n",
      "Training Loss: 0.00015631791200576117\n",
      "Validation Loss: 0.0001551374349791525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.0001798216770112049\n",
      "Training Loss: 0.00014344024752062977\n",
      "Training Loss: 0.0001541827723485767\n",
      "Validation Loss: 0.0001527513669428659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00017743857071764069\n",
      "Training Loss: 0.00014133410073554841\n",
      "Training Loss: 0.00015210090303298783\n",
      "Validation Loss: 0.00015043884827156966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00017511604079118115\n",
      "Training Loss: 0.00013928445154306245\n",
      "Training Loss: 0.00015006808447651565\n",
      "Validation Loss: 0.00014819357880349322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00017284960509641678\n",
      "Training Loss: 0.00013728735937547753\n",
      "Training Loss: 0.0001480806580002536\n",
      "Validation Loss: 0.00014601085019697504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00017063519009752782\n",
      "Training Loss: 0.00013533909359466633\n",
      "Training Loss: 0.00014613539531637798\n",
      "Validation Loss: 0.00014388502301259772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.0001684693122842873\n",
      "Training Loss: 0.00013343617492864724\n",
      "Training Loss: 0.0001442294366461283\n",
      "Validation Loss: 0.00014181205136829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0001663481554351165\n",
      "Training Loss: 0.00013157573295757174\n",
      "Training Loss: 0.00014235994394766748\n",
      "Validation Loss: 0.00013978776101038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00016426897478595494\n",
      "Training Loss: 0.0001297545755187457\n",
      "Training Loss: 0.00014052503420316497\n",
      "Validation Loss: 0.00013780864163676638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00016222885073148064\n",
      "Training Loss: 0.0001279704622538702\n",
      "Training Loss: 0.00013872207904569222\n",
      "Validation Loss: 0.00013587124573113919\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00016022513993448227\n",
      "Training Loss: 0.0001262207384206704\n",
      "Training Loss: 0.00013694946750547387\n",
      "Validation Loss: 0.00013397317797058717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00015825570608285489\n",
      "Training Loss: 0.00012450344229364418\n",
      "Training Loss: 0.00013520521573809674\n",
      "Validation Loss: 0.0001321112155759631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0001563183407051838\n",
      "Training Loss: 0.0001228163612904609\n",
      "Training Loss: 0.0001334878892339475\n",
      "Validation Loss: 0.00013028330176076565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00015441103700140955\n",
      "Training Loss: 0.00012115765683120117\n",
      "Training Loss: 0.00013179600869989372\n",
      "Validation Loss: 0.00012848678235375988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0001525319197207864\n",
      "Training Loss: 0.00011952575430768775\n",
      "Training Loss: 0.00013012833533139202\n",
      "Validation Loss: 0.00012672024355054142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00015067955668200737\n",
      "Training Loss: 0.0001179190845323319\n",
      "Training Loss: 0.00012848363525336026\n",
      "Validation Loss: 0.00012498149334625055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0001488525235072302\n",
      "Training Loss: 0.00011633621443252196\n",
      "Training Loss: 0.0001268607077508932\n",
      "Validation Loss: 0.0001232686986083301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0001470492190492223\n",
      "Training Loss: 0.00011477583420855808\n",
      "Training Loss: 0.0001252588539136923\n",
      "Validation Loss: 0.00012158067147538532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.0001452686633092526\n",
      "Training Loss: 0.00011323674449158717\n",
      "Training Loss: 0.00012367697243462317\n",
      "Validation Loss: 0.00011991625269933792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00014350954737892606\n",
      "Training Loss: 0.00011171792810273474\n",
      "Training Loss: 0.00012211428545924719\n",
      "Validation Loss: 0.00011827365437710888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00014177088401993388\n",
      "Training Loss: 0.00011021833854101714\n",
      "Training Loss: 0.00012057015750542632\n",
      "Validation Loss: 0.00011665238325599859\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00014005212504343944\n",
      "Training Loss: 0.0001087370999630366\n",
      "Training Loss: 0.00011904371018317761\n",
      "Validation Loss: 0.00011505129825738468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0001383521426942025\n",
      "Training Loss: 0.00010727339489676525\n",
      "Training Loss: 0.00011753475306250038\n",
      "Validation Loss: 0.00011346941978394007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00013667025134054712\n",
      "Training Loss: 0.00010582670784970105\n",
      "Training Loss: 0.00011604267307120608\n",
      "Validation Loss: 0.0001119062294645609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00013500593415301408\n",
      "Training Loss: 0.00010439617945849022\n",
      "Training Loss: 0.00011456687367171981\n",
      "Validation Loss: 0.00011036094276298601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00013335858939171884\n",
      "Training Loss: 0.0001029814481989888\n",
      "Training Loss: 0.00011310710558973369\n",
      "Validation Loss: 0.00010883321838366428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00013172780401873751\n",
      "Training Loss: 0.00010158194263567565\n",
      "Training Loss: 0.00011166302565470687\n",
      "Validation Loss: 0.00010732250954655622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0001301130702267983\n",
      "Training Loss: 0.00010019736059803108\n",
      "Training Loss: 0.00011023439448763383\n",
      "Validation Loss: 0.00010582842596602531\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00012851428242356634\n",
      "Training Loss: 9.882716202810116e-05\n",
      "Training Loss: 0.0001088211554906593\n",
      "Validation Loss: 0.00010435086003556361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00012693089855019934\n",
      "Training Loss: 9.747121578584483e-05\n",
      "Training Loss: 0.00010742314365415951\n",
      "Validation Loss: 0.00010288965211330332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.00012536292064396548\n",
      "Training Loss: 9.612951872441044e-05\n",
      "Training Loss: 0.00010604017770674546\n",
      "Validation Loss: 0.00010144449051847587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0001238100154841959\n",
      "Training Loss: 9.480166530920542e-05\n",
      "Training Loss: 0.00010467222386978392\n",
      "Validation Loss: 0.00010001546926626392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0001222723834507633\n",
      "Training Loss: 9.348768561721954e-05\n",
      "Training Loss: 0.00010331943289202173\n",
      "Validation Loss: 9.860273459115264e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00012074974327333621\n",
      "Training Loss: 9.218750698892109e-05\n",
      "Training Loss: 0.00010198194122494897\n",
      "Validation Loss: 9.720610983657005e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.00011924219998036279\n",
      "Training Loss: 9.090125801776594e-05\n",
      "Training Loss: 0.00010065963281704171\n",
      "Validation Loss: 9.582581324036837e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00011774987602620968\n",
      "Training Loss: 8.96289390311722e-05\n",
      "Training Loss: 9.935295896866592e-05\n",
      "Validation Loss: 9.446227984758633e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00011627310614130693\n",
      "Training Loss: 8.837080018565757e-05\n",
      "Training Loss: 9.806186037167208e-05\n",
      "Validation Loss: 9.311562960933413e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.00011481149722385453\n",
      "Training Loss: 8.712689020285325e-05\n",
      "Training Loss: 9.678671445726649e-05\n",
      "Validation Loss: 9.17860076155643e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0001133658473190735\n",
      "Training Loss: 8.589759197093372e-05\n",
      "Training Loss: 9.552792581416724e-05\n",
      "Validation Loss: 9.04738106921e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00011193616259333794\n",
      "Training Loss: 8.468307330986136e-05\n",
      "Training Loss: 9.428557981664199e-05\n",
      "Validation Loss: 8.917957706564286e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.00011052282052332884\n",
      "Training Loss: 8.348363960976713e-05\n",
      "Training Loss: 9.306008963903878e-05\n",
      "Validation Loss: 8.790301127304333e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00010912623274634825\n",
      "Training Loss: 8.229967557781493e-05\n",
      "Training Loss: 9.185194150632014e-05\n",
      "Validation Loss: 8.664515418500189e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00010774653707812832\n",
      "Training Loss: 8.113154924103582e-05\n",
      "Training Loss: 9.066135308785305e-05\n",
      "Validation Loss: 8.540671580009035e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00010638462430506479\n",
      "Training Loss: 7.997967172741482e-05\n",
      "Training Loss: 8.948896335823519e-05\n",
      "Validation Loss: 8.418748146734002e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00010504054980629008\n",
      "Training Loss: 7.884459673732636e-05\n",
      "Training Loss: 8.83349182367965e-05\n",
      "Validation Loss: 8.298802954362891e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0001037149798412429\n",
      "Training Loss: 7.772653645588435e-05\n",
      "Training Loss: 8.7199812869585e-05\n",
      "Validation Loss: 8.180908759406132e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00010240835636977863\n",
      "Training Loss: 7.662609309591061e-05\n",
      "Training Loss: 8.608406380517409e-05\n",
      "Validation Loss: 8.06508236605572e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00010112124973602477\n",
      "Training Loss: 7.554360134236049e-05\n",
      "Training Loss: 8.498811132085394e-05\n",
      "Validation Loss: 7.951393996499769e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 9.985417574171152e-05\n",
      "Training Loss: 7.44797369952721e-05\n",
      "Training Loss: 8.391216316340433e-05\n",
      "Validation Loss: 7.839843135698583e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 9.860746145932353e-05\n",
      "Training Loss: 7.343478009715909e-05\n",
      "Training Loss: 8.285682501991687e-05\n",
      "Validation Loss: 7.730527840465768e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 9.738203946653812e-05\n",
      "Training Loss: 7.240939953589987e-05\n",
      "Training Loss: 8.182268687050964e-05\n",
      "Validation Loss: 7.623463965644354e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 9.617787958632107e-05\n",
      "Training Loss: 7.140374989830889e-05\n",
      "Training Loss: 8.080971198978659e-05\n",
      "Validation Loss: 7.5186895342443e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 9.499612268882629e-05\n",
      "Training Loss: 7.041851328267513e-05\n",
      "Training Loss: 7.981831447978038e-05\n",
      "Validation Loss: 7.416228520137185e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 9.383659820741741e-05\n",
      "Training Loss: 6.945394694412244e-05\n",
      "Training Loss: 7.884913046837028e-05\n",
      "Validation Loss: 7.316150968721702e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 9.270007304621685e-05\n",
      "Training Loss: 6.851058593383641e-05\n",
      "Training Loss: 7.790211982865003e-05\n",
      "Validation Loss: 7.218435132855437e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 9.158708166978613e-05\n",
      "Training Loss: 6.758854715371854e-05\n",
      "Training Loss: 7.69774354830588e-05\n",
      "Validation Loss: 7.123152903495997e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 9.049767715623602e-05\n",
      "Training Loss: 6.668816439741931e-05\n",
      "Training Loss: 7.607556504808599e-05\n",
      "Validation Loss: 7.030288838649632e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 8.943256062593719e-05\n",
      "Training Loss: 6.58097888708653e-05\n",
      "Training Loss: 7.51963685343071e-05\n",
      "Validation Loss: 6.939888123852551e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 8.839183557029174e-05\n",
      "Training Loss: 6.495351655757986e-05\n",
      "Training Loss: 7.433999705881433e-05\n",
      "Validation Loss: 6.851935844413551e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 8.737574662518455e-05\n",
      "Training Loss: 6.411946172192984e-05\n",
      "Training Loss: 7.350653254434292e-05\n",
      "Validation Loss: 6.766443117627981e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 8.63845151343412e-05\n",
      "Training Loss: 6.330797423288459e-05\n",
      "Training Loss: 7.269595255820604e-05\n",
      "Validation Loss: 6.68341173693764e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 8.5418148082681e-05\n",
      "Training Loss: 6.251876622627606e-05\n",
      "Training Loss: 7.19080647240844e-05\n",
      "Validation Loss: 6.602839657512305e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 8.44769421928504e-05\n",
      "Training Loss: 6.175191861530039e-05\n",
      "Training Loss: 7.114287839613098e-05\n",
      "Validation Loss: 6.524710420563587e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 8.356090954293905e-05\n",
      "Training Loss: 6.100743499246164e-05\n",
      "Training Loss: 7.039999364678806e-05\n",
      "Validation Loss: 6.448999233674676e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 8.266966347946437e-05\n",
      "Training Loss: 6.0285118102001435e-05\n",
      "Training Loss: 6.967939142668911e-05\n",
      "Validation Loss: 6.375677436521522e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 8.180351455848723e-05\n",
      "Training Loss: 5.958472175279894e-05\n",
      "Training Loss: 6.898063928019838e-05\n",
      "Validation Loss: 6.304723711161458e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 8.096209558971168e-05\n",
      "Training Loss: 5.890614470445143e-05\n",
      "Training Loss: 6.830344555964984e-05\n",
      "Validation Loss: 6.236121486396636e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 8.014523094061587e-05\n",
      "Training Loss: 5.8248961840945414e-05\n",
      "Training Loss: 6.764740749076736e-05\n",
      "Validation Loss: 6.169819885706581e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 7.935244296277233e-05\n",
      "Training Loss: 5.7612847913333096e-05\n",
      "Training Loss: 6.701210573737625e-05\n",
      "Validation Loss: 6.10574559359929e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 7.858349761590943e-05\n",
      "Training Loss: 5.699748165625351e-05\n",
      "Training Loss: 6.639707188242027e-05\n",
      "Validation Loss: 6.043857880040684e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 7.783798746004322e-05\n",
      "Training Loss: 5.640224040234898e-05\n",
      "Training Loss: 6.580169092558208e-05\n",
      "Validation Loss: 5.984115629738819e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 7.711569856382993e-05\n",
      "Training Loss: 5.5826915354373344e-05\n",
      "Training Loss: 6.522560118810361e-05\n",
      "Validation Loss: 5.9264687591708485e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 7.641579643859587e-05\n",
      "Training Loss: 5.52708412078573e-05\n",
      "Training Loss: 6.46682026263079e-05\n",
      "Validation Loss: 5.870856914166171e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 7.573799699457595e-05\n",
      "Training Loss: 5.47334666862298e-05\n",
      "Training Loss: 6.41289191071337e-05\n",
      "Validation Loss: 5.817240569515715e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 7.508168824188032e-05\n",
      "Training Loss: 5.4214338824749575e-05\n",
      "Training Loss: 6.360710568060313e-05\n",
      "Validation Loss: 5.7654693198324575e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 7.444632074566471e-05\n",
      "Training Loss: 5.371285974888451e-05\n",
      "Training Loss: 6.310228231086512e-05\n",
      "Validation Loss: 5.7155960379266493e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 7.383115007087327e-05\n",
      "Training Loss: 5.322839581367589e-05\n",
      "Training Loss: 6.261375543545e-05\n",
      "Validation Loss: 5.6674968163861195e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 7.323580782667705e-05\n",
      "Training Loss: 5.276027422496554e-05\n",
      "Training Loss: 6.214106593233738e-05\n",
      "Validation Loss: 5.6211138966768324e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 7.265947127507388e-05\n",
      "Training Loss: 5.230804702023306e-05\n",
      "Training Loss: 6.168332926336007e-05\n",
      "Validation Loss: 5.5763696396302855e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 7.21016234047056e-05\n",
      "Training Loss: 5.187110796669003e-05\n",
      "Training Loss: 6.124025489953055e-05\n",
      "Validation Loss: 5.53319331823771e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 7.1561586023563e-05\n",
      "Training Loss: 5.144876755821315e-05\n",
      "Training Loss: 6.081106496367283e-05\n",
      "Validation Loss: 5.4915449929078964e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 7.103873401774763e-05\n",
      "Training Loss: 5.104052137085091e-05\n",
      "Training Loss: 6.0395384284674943e-05\n",
      "Validation Loss: 5.4513626156641e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 7.053240283767082e-05\n",
      "Training Loss: 5.064558338290226e-05\n",
      "Training Loss: 5.999230772886221e-05\n",
      "Validation Loss: 5.412588847974895e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 7.004191591477138e-05\n",
      "Training Loss: 5.02636261171574e-05\n",
      "Training Loss: 5.9601648931675296e-05\n",
      "Validation Loss: 5.375117310128251e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 6.956669476039679e-05\n",
      "Training Loss: 4.989394446056395e-05\n",
      "Training Loss: 5.9222599579698e-05\n",
      "Validation Loss: 5.338931690489977e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 6.910624730608106e-05\n",
      "Training Loss: 4.9536032915966646e-05\n",
      "Training Loss: 5.88547874986034e-05\n",
      "Validation Loss: 5.30394698400639e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 6.865990286314627e-05\n",
      "Training Loss: 4.918926495065534e-05\n",
      "Training Loss: 5.849764258528012e-05\n",
      "Validation Loss: 5.270098563925601e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 6.822693000685831e-05\n",
      "Training Loss: 4.885326836756576e-05\n",
      "Training Loss: 5.815065790557128e-05\n",
      "Validation Loss: 5.2373669614405186e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 6.780708868973306e-05\n",
      "Training Loss: 4.852743620631372e-05\n",
      "Training Loss: 5.781355502676888e-05\n",
      "Validation Loss: 5.205667814786129e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 6.739936116446189e-05\n",
      "Training Loss: 4.821136466489406e-05\n",
      "Training Loss: 5.7485592078592164e-05\n",
      "Validation Loss: 5.17500809896927e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 6.700388600165752e-05\n",
      "Training Loss: 4.7904517432471037e-05\n",
      "Training Loss: 5.716663325074478e-05\n",
      "Validation Loss: 5.145235831293852e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 6.661923623141775e-05\n",
      "Training Loss: 4.760645384067175e-05\n",
      "Training Loss: 5.685616823484452e-05\n",
      "Validation Loss: 5.116425864195734e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 6.624618142723194e-05\n",
      "Training Loss: 4.7316833656623204e-05\n",
      "Training Loss: 5.6553756626271936e-05\n",
      "Validation Loss: 5.088422912695534e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 6.588261217075342e-05\n",
      "Training Loss: 4.7035216771291746e-05\n",
      "Training Loss: 5.62590508525318e-05\n",
      "Validation Loss: 5.061330697510661e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 6.55301422921184e-05\n",
      "Training Loss: 4.6761172675360286e-05\n",
      "Training Loss: 5.597180785116507e-05\n",
      "Validation Loss: 5.034910130367341e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 6.518607702219015e-05\n",
      "Training Loss: 4.649447988413158e-05\n",
      "Training Loss: 5.569171267779893e-05\n",
      "Validation Loss: 5.009297858756899e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 6.48521445282313e-05\n",
      "Training Loss: 4.623470663318585e-05\n",
      "Training Loss: 5.541834426821879e-05\n",
      "Validation Loss: 4.9843781096242716e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 6.452609006828425e-05\n",
      "Training Loss: 4.5981429884704994e-05\n",
      "Training Loss: 5.515141815067182e-05\n",
      "Validation Loss: 4.960121733664268e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 6.420924245503556e-05\n",
      "Training Loss: 4.5734540576631845e-05\n",
      "Training Loss: 5.489069638770161e-05\n",
      "Validation Loss: 4.93651418407118e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 6.389953332472942e-05\n",
      "Training Loss: 4.549357243377017e-05\n",
      "Training Loss: 5.463596608478838e-05\n",
      "Validation Loss: 4.913542774415822e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 6.35985503822667e-05\n",
      "Training Loss: 4.5258593390826716e-05\n",
      "Training Loss: 5.438692374355014e-05\n",
      "Validation Loss: 4.89113367569935e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 6.330392755899084e-05\n",
      "Training Loss: 4.5028917438685314e-05\n",
      "Training Loss: 5.4143415886755975e-05\n",
      "Validation Loss: 4.869304774821215e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 6.301731532857957e-05\n",
      "Training Loss: 4.480455108023307e-05\n",
      "Training Loss: 5.390516068928264e-05\n",
      "Validation Loss: 4.847952268289774e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 6.273659972521273e-05\n",
      "Training Loss: 4.4585159571397526e-05\n",
      "Training Loss: 5.3672146732424155e-05\n",
      "Validation Loss: 4.827193518732007e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 6.246344290048e-05\n",
      "Training Loss: 4.437067296294117e-05\n",
      "Training Loss: 5.344376168523013e-05\n",
      "Validation Loss: 4.806853285935064e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 6.21955043880007e-05\n",
      "Training Loss: 4.416086170976996e-05\n",
      "Training Loss: 5.3220363606669705e-05\n",
      "Validation Loss: 4.787046625066334e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 6.193469811023533e-05\n",
      "Training Loss: 4.395544728595269e-05\n",
      "Training Loss: 5.3001291325927015e-05\n",
      "Validation Loss: 4.767628342960961e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 6.167857019136136e-05\n",
      "Training Loss: 4.375430920163126e-05\n",
      "Training Loss: 5.278686059227766e-05\n",
      "Validation Loss: 4.7487211452718245e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 6.142914320662384e-05\n",
      "Training Loss: 4.355727986194324e-05\n",
      "Training Loss: 5.2576462962861115e-05\n",
      "Validation Loss: 4.7301730620766354e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 6.118418965797901e-05\n",
      "Training Loss: 4.336416343221572e-05\n",
      "Training Loss: 5.237025603946677e-05\n",
      "Validation Loss: 4.7120564613067654e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 6.0945461063965924e-05\n",
      "Training Loss: 4.3174915867894013e-05\n",
      "Training Loss: 5.216806048110811e-05\n",
      "Validation Loss: 4.694248136831774e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 6.071048740977858e-05\n",
      "Training Loss: 4.298930447021121e-05\n",
      "Training Loss: 5.19697955223819e-05\n",
      "Validation Loss: 4.6769213770275704e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 6.048174704574194e-05\n",
      "Training Loss: 4.280740485683055e-05\n",
      "Training Loss: 5.177508393671815e-05\n",
      "Validation Loss: 4.659897240344435e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 6.025639238941949e-05\n",
      "Training Loss: 4.262879052021162e-05\n",
      "Training Loss: 5.1584167867986255e-05\n",
      "Validation Loss: 4.643238010308022e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 6.003688865348522e-05\n",
      "Training Loss: 4.245356484034346e-05\n",
      "Training Loss: 5.1396730675605795e-05\n",
      "Validation Loss: 4.6268548022055075e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 5.982041413517436e-05\n",
      "Training Loss: 4.2281511564397075e-05\n",
      "Training Loss: 5.1212763153216657e-05\n",
      "Validation Loss: 4.610881671468316e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 5.960956854778487e-05\n",
      "Training Loss: 4.211272879047101e-05\n",
      "Training Loss: 5.1032031701652156e-05\n",
      "Validation Loss: 4.595119160798828e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 5.9401497173894315e-05\n",
      "Training Loss: 4.1946840842683744e-05\n",
      "Training Loss: 5.0854669252657915e-05\n",
      "Validation Loss: 4.579743869797905e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 5.9198767085035795e-05\n",
      "Training Loss: 4.1783941835547015e-05\n",
      "Training Loss: 5.068050568752369e-05\n",
      "Validation Loss: 4.564599474976062e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 5.8998550275646264e-05\n",
      "Training Loss: 4.1623908903147825e-05\n",
      "Training Loss: 5.050940151704708e-05\n",
      "Validation Loss: 4.549800823798669e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 5.8803564475056194e-05\n",
      "Training Loss: 4.146679237919671e-05\n",
      "Training Loss: 5.034120627215089e-05\n",
      "Validation Loss: 4.535208867555105e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 5.8610697728909144e-05\n",
      "Training Loss: 4.131215091319973e-05\n",
      "Training Loss: 5.0176067154552585e-05\n",
      "Validation Loss: 4.5209601599769865e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 5.842285706421535e-05\n",
      "Training Loss: 4.11603235079383e-05\n",
      "Training Loss: 5.001365052521578e-05\n",
      "Validation Loss: 4.5068993959023245e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 5.823707167564862e-05\n",
      "Training Loss: 4.1011011001046425e-05\n",
      "Training Loss: 4.985428793816027e-05\n",
      "Validation Loss: 4.493137630254679e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 5.8056027014572465e-05\n",
      "Training Loss: 4.0864316051738566e-05\n",
      "Training Loss: 4.969746687265797e-05\n",
      "Validation Loss: 4.4795548753907576e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 5.787679522200051e-05\n",
      "Training Loss: 4.071998674589849e-05\n",
      "Training Loss: 4.9543398536116004e-05\n",
      "Validation Loss: 4.46629442577749e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 5.770219122496201e-05\n",
      "Training Loss: 4.057811604070594e-05\n",
      "Training Loss: 4.939191368293905e-05\n",
      "Validation Loss: 4.453191998824847e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 5.7529329833414525e-05\n",
      "Training Loss: 4.043860674755706e-05\n",
      "Training Loss: 4.924314070649416e-05\n",
      "Validation Loss: 4.440381727884445e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 5.7360937371413454e-05\n",
      "Training Loss: 4.030137629570163e-05\n",
      "Training Loss: 4.9096650013780166e-05\n",
      "Validation Loss: 4.4276963742529995e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 5.719391601815005e-05\n",
      "Training Loss: 4.016629670104521e-05\n",
      "Training Loss: 4.895288764828365e-05\n",
      "Validation Loss: 4.415305761540367e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 5.703128790628398e-05\n",
      "Training Loss: 4.003352562222062e-05\n",
      "Training Loss: 4.881136735548353e-05\n",
      "Validation Loss: 4.403065710566092e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 5.686999336830922e-05\n",
      "Training Loss: 3.9902810817693536e-05\n",
      "Training Loss: 4.8672234172499884e-05\n",
      "Validation Loss: 4.391121902198791e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 5.671287171935546e-05\n",
      "Training Loss: 3.977428588314069e-05\n",
      "Training Loss: 4.853533495861484e-05\n",
      "Validation Loss: 4.3792338243967215e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 5.655696239955432e-05\n",
      "Training Loss: 3.964783375749903e-05\n",
      "Training Loss: 4.8401103592823345e-05\n",
      "Validation Loss: 4.3676606294999205e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 5.640509894419665e-05\n",
      "Training Loss: 3.952338565795799e-05\n",
      "Training Loss: 4.826856098134158e-05\n",
      "Validation Loss: 4.356180642992441e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 5.625433143450209e-05\n",
      "Training Loss: 3.940077137258413e-05\n",
      "Training Loss: 4.81385194439099e-05\n",
      "Validation Loss: 4.344984662300581e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 5.610750578398438e-05\n",
      "Training Loss: 3.928038614731122e-05\n",
      "Training Loss: 4.801041757900748e-05\n",
      "Validation Loss: 4.33386812597092e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 5.596155008788628e-05\n",
      "Training Loss: 3.9161723716460987e-05\n",
      "Training Loss: 4.788452489265182e-05\n",
      "Validation Loss: 4.3230222693156895e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 5.581963208442175e-05\n",
      "Training Loss: 3.904503169451345e-05\n",
      "Training Loss: 4.7760656918853784e-05\n",
      "Validation Loss: 4.312213518766911e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 5.5678365893072627e-05\n",
      "Training Loss: 3.8930127154799265e-05\n",
      "Training Loss: 4.763887382068788e-05\n",
      "Validation Loss: 4.3017228026758274e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 5.5541010428896694e-05\n",
      "Training Loss: 3.881701786895064e-05\n",
      "Training Loss: 4.751896287871205e-05\n",
      "Validation Loss: 4.291274624622755e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 5.540425542221783e-05\n",
      "Training Loss: 3.870565184570296e-05\n",
      "Training Loss: 4.740106068993555e-05\n",
      "Validation Loss: 4.28109174361943e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 5.5271186438403676e-05\n",
      "Training Loss: 3.8596169667926004e-05\n",
      "Training Loss: 4.7284930421938045e-05\n",
      "Validation Loss: 4.27094384801595e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 5.513874125881557e-05\n",
      "Training Loss: 3.8488209786464725e-05\n",
      "Training Loss: 4.7170842624382206e-05\n",
      "Validation Loss: 4.261050991588266e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 5.501002692653856e-05\n",
      "Training Loss: 3.8382092518531864e-05\n",
      "Training Loss: 4.705832932586418e-05\n",
      "Validation Loss: 4.251229388705468e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 5.48815169804584e-05\n",
      "Training Loss: 3.82774037211675e-05\n",
      "Training Loss: 4.69479900357328e-05\n",
      "Validation Loss: 4.2416522546773194e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 5.47567541434546e-05\n",
      "Training Loss: 3.817452280145517e-05\n",
      "Training Loss: 4.68390684136466e-05\n",
      "Validation Loss: 4.232089381832665e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 5.4632290743938936e-05\n",
      "Training Loss: 3.8073149319188815e-05\n",
      "Training Loss: 4.6732049618185556e-05\n",
      "Validation Loss: 4.2228000847388284e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 5.451144502330862e-05\n",
      "Training Loss: 3.7973377238813555e-05\n",
      "Training Loss: 4.662661327756723e-05\n",
      "Validation Loss: 4.213491516065404e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 5.439069826024934e-05\n",
      "Training Loss: 3.7875084537972724e-05\n",
      "Training Loss: 4.652291307593259e-05\n",
      "Validation Loss: 4.2044714212280584e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 5.4273552163977003e-05\n",
      "Training Loss: 3.777839718168252e-05\n",
      "Training Loss: 4.642080240273572e-05\n",
      "Validation Loss: 4.195449998170782e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 5.415643318883667e-05\n",
      "Training Loss: 3.76830371305914e-05\n",
      "Training Loss: 4.632039050875392e-05\n",
      "Validation Loss: 4.186701275347935e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 5.404282128893101e-05\n",
      "Training Loss: 3.7589356538774154e-05\n",
      "Training Loss: 4.622137334536092e-05\n",
      "Validation Loss: 4.177886741897229e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 5.3929178284306546e-05\n",
      "Training Loss: 3.749679060774725e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:34<23:12, 154.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.612398646031579e-05\n",
      "Validation Loss: 4.169397316524809e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.07084026709388126\n",
      "Training Loss: 0.06503131538629532\n",
      "Training Loss: 0.06534381029196083\n",
      "Validation Loss: 0.06342324110145649\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.058974684135755524\n",
      "Training Loss: 0.054436979377642275\n",
      "Training Loss: 0.0542410190962255\n",
      "Validation Loss: 0.05135316441484382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04706657256116159\n",
      "Training Loss: 0.04210296215489507\n",
      "Training Loss: 0.040755901485681534\n",
      "Validation Loss: 0.038168319126884086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.03452131414800533\n",
      "Training Loss: 0.030122920973226427\n",
      "Training Loss: 0.02882563738152385\n",
      "Validation Loss: 0.0271619272201186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.023957249031227548\n",
      "Training Loss: 0.0203070808731718\n",
      "Training Loss: 0.019292730807792396\n",
      "Validation Loss: 0.01891015566168667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.016043486159760506\n",
      "Training Loss: 0.01324820168199949\n",
      "Training Loss: 0.012508182257879525\n",
      "Validation Loss: 0.013286773380928076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.010494125926634297\n",
      "Training Loss: 0.008217406565090641\n",
      "Training Loss: 0.007525115826865658\n",
      "Validation Loss: 0.009362054908951598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.00625880493724253\n",
      "Training Loss: 0.004238521727384068\n",
      "Training Loss: 0.0036993560794508083\n",
      "Validation Loss: 0.006943489528873287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.0033459947592928076\n",
      "Training Loss: 0.0018153396745037753\n",
      "Training Loss: 0.0017433036236616318\n",
      "Validation Loss: 0.005562161357701871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.0021184058199287393\n",
      "Training Loss: 0.0010538099108816823\n",
      "Training Loss: 0.0011313199485448423\n",
      "Validation Loss: 0.0043293980561429635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0015560311220906443\n",
      "Training Loss: 0.0007793875008792384\n",
      "Training Loss: 0.0008435000229655998\n",
      "Validation Loss: 0.0033498163610694177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0011724990452057682\n",
      "Training Loss: 0.0006044415732321795\n",
      "Training Loss: 0.0006527022075897549\n",
      "Validation Loss: 0.0026186960906292617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.0008976674510995508\n",
      "Training Loss: 0.00048594508960377427\n",
      "Training Loss: 0.0005232505906315055\n",
      "Validation Loss: 0.002048623362743149\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0007030429029327934\n",
      "Training Loss: 0.0004087939637975069\n",
      "Training Loss: 0.0004363248567096889\n",
      "Validation Loss: 0.001588889885742186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0005675272207008675\n",
      "Training Loss: 0.000359398093278287\n",
      "Training Loss: 0.0003776756109436974\n",
      "Validation Loss: 0.0012194231285627282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.00047469062697928164\n",
      "Training Loss: 0.0003270248879562132\n",
      "Training Loss: 0.00033707564951328094\n",
      "Validation Loss: 0.0009310072191612889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00041148419295495843\n",
      "Training Loss: 0.00030442234776273836\n",
      "Training Loss: 0.0003076908828370506\n",
      "Validation Loss: 0.0007139864666917193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0003679935675972956\n",
      "Training Loss: 0.00028722603503410937\n",
      "Training Loss: 0.00028530204683193007\n",
      "Validation Loss: 0.0005559390720622248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0003372488833701937\n",
      "Training Loss: 0.00027306662585033334\n",
      "Training Loss: 0.000267486000630015\n",
      "Validation Loss: 0.0004439442308150033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.0003147044682918931\n",
      "Training Loss: 0.0002608065381718916\n",
      "Training Loss: 0.00025290601643064293\n",
      "Validation Loss: 0.0003667177830373455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0002975336567760678\n",
      "Training Loss: 0.0002499507195170736\n",
      "Training Loss: 0.00024079278235149105\n",
      "Validation Loss: 0.00031496603786651035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00028398844275216104\n",
      "Training Loss: 0.00024027501658565597\n",
      "Training Loss: 0.00023063983862812166\n",
      "Validation Loss: 0.0002810324401937404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0002729481061032857\n",
      "Training Loss: 0.0002316430780047085\n",
      "Training Loss: 0.0002220620646403404\n",
      "Validation Loss: 0.00025885205186466594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00026366934231191407\n",
      "Training Loss: 0.00022393501207261578\n",
      "Training Loss: 0.0002147407287702663\n",
      "Validation Loss: 0.00024398447195391086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0002556530959918746\n",
      "Training Loss: 0.00021703291266021553\n",
      "Training Loss: 0.0002084084453235846\n",
      "Validation Loss: 0.00023348241028430861\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00024856591058778575\n",
      "Training Loss: 0.00021082153798488435\n",
      "Training Loss: 0.00020284711124986642\n",
      "Validation Loss: 0.0002255373373362785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00024218350154114887\n",
      "Training Loss: 0.00020519501209491863\n",
      "Training Loss: 0.00019788617712038103\n",
      "Validation Loss: 0.0002191028513735045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0002363560302183032\n",
      "Training Loss: 0.00020006092312542024\n",
      "Training Loss: 0.0001933960023598047\n",
      "Validation Loss: 0.00021358303413589045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00023097974903066643\n",
      "Training Loss: 0.00019534110517270166\n",
      "Training Loss: 0.00018928124820376979\n",
      "Validation Loss: 0.00020864584296483943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00022598177634790772\n",
      "Training Loss: 0.00019097223788776317\n",
      "Training Loss: 0.0001854718082904583\n",
      "Validation Loss: 0.00020410350272582394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0002213089256110834\n",
      "Training Loss: 0.0001869031695605372\n",
      "Training Loss: 0.00018191643419413595\n",
      "Validation Loss: 0.00019985081247326112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00021692039495974314\n",
      "Training Loss: 0.00018309286453586538\n",
      "Training Loss: 0.00017857702820037958\n",
      "Validation Loss: 0.00019582652691568593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00021278457687003537\n",
      "Training Loss: 0.0001795084796140145\n",
      "Training Loss: 0.00017542439258249942\n",
      "Validation Loss: 0.00019199530893427926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00020887543550998088\n",
      "Training Loss: 0.00017612317662496935\n",
      "Training Loss: 0.00017243641454115277\n",
      "Validation Loss: 0.00018833399102159806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00020517148346698376\n",
      "Training Loss: 0.0001729154919848952\n",
      "Training Loss: 0.00016959528547886294\n",
      "Validation Loss: 0.00018482814722232065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00020165416992313113\n",
      "Training Loss: 0.00016986759012070253\n",
      "Training Loss: 0.0001668866467116459\n",
      "Validation Loss: 0.00018146364051430732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00019830767858366015\n",
      "Training Loss: 0.0001669645458969171\n",
      "Training Loss: 0.00016429859155323357\n",
      "Validation Loss: 0.0001782334098463886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00019511778767991928\n",
      "Training Loss: 0.00016419392077295924\n",
      "Training Loss: 0.00016182126046260237\n",
      "Validation Loss: 0.0001751286836428989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00019207230736355995\n",
      "Training Loss: 0.0001615445834431739\n",
      "Training Loss: 0.00015944619195579435\n",
      "Validation Loss: 0.00017214227248106827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00018916024378995644\n",
      "Training Loss: 0.00015900811184110352\n",
      "Training Loss: 0.00015716609772425727\n",
      "Validation Loss: 0.00016926902418582063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00018637219784068293\n",
      "Training Loss: 0.00015657580481274637\n",
      "Training Loss: 0.00015497456914090435\n",
      "Validation Loss: 0.00016650189683603233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00018369924579019425\n",
      "Training Loss: 0.00015424095870912425\n",
      "Training Loss: 0.00015286586443835404\n",
      "Validation Loss: 0.0001638349096149826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00018113338208422647\n",
      "Training Loss: 0.00015199720353848534\n",
      "Training Loss: 0.00015083514352227213\n",
      "Validation Loss: 0.00016126414358153484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0001786680398072349\n",
      "Training Loss: 0.00014983942191975074\n",
      "Training Loss: 0.00014887800836731912\n",
      "Validation Loss: 0.00015878573485474844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00017629709178436316\n",
      "Training Loss: 0.00014776273925235729\n",
      "Training Loss: 0.00014699060056955204\n",
      "Validation Loss: 0.0001563945202842967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00017401461336703506\n",
      "Training Loss: 0.00014576280165783827\n",
      "Training Loss: 0.00014516950634060777\n",
      "Validation Loss: 0.00015408686268845773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00017181585490106955\n",
      "Training Loss: 0.00014383566503965993\n",
      "Training Loss: 0.000143411249955534\n",
      "Validation Loss: 0.00015185971971548272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00016969618422081113\n",
      "Training Loss: 0.00014197775870343322\n",
      "Training Loss: 0.00014171313307087985\n",
      "Validation Loss: 0.00014970931649228343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00016765152826337727\n",
      "Training Loss: 0.0001401862180500757\n",
      "Training Loss: 0.00014007275329277035\n",
      "Validation Loss: 0.00014763244800040698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.0001656779674704012\n",
      "Training Loss: 0.00013845770741681917\n",
      "Training Loss: 0.00013848737862645066\n",
      "Validation Loss: 0.00014562748998450637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00016377244292016259\n",
      "Training Loss: 0.00013678971276021913\n",
      "Training Loss: 0.00013695525434741283\n",
      "Validation Loss: 0.0001436908437273324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00016193151988773026\n",
      "Training Loss: 0.00013518013207431068\n",
      "Training Loss: 0.00013547414086133357\n",
      "Validation Loss: 0.00014182069334607006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00016015269295166946\n",
      "Training Loss: 0.00013362614308789488\n",
      "Training Loss: 0.00013404216924755018\n",
      "Validation Loss: 0.00014001420344500096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00015843305745875114\n",
      "Training Loss: 0.00013212596762969043\n",
      "Training Loss: 0.0001326577767576964\n",
      "Validation Loss: 0.00013826971772186369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00015677036653869437\n",
      "Training Loss: 0.000130677561792254\n",
      "Training Loss: 0.0001313191110966727\n",
      "Validation Loss: 0.0001365856020701552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00015516233570451733\n",
      "Training Loss: 0.0001292791243213287\n",
      "Training Loss: 0.00013002493726162355\n",
      "Validation Loss: 0.00013495947878459192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00015360701230747508\n",
      "Training Loss: 0.00012792867524694885\n",
      "Training Loss: 0.00012877370063506531\n",
      "Validation Loss: 0.00013338926618508708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00015210230214506736\n",
      "Training Loss: 0.0001266248110368906\n",
      "Training Loss: 0.00012756408395944163\n",
      "Validation Loss: 0.0001318742526788984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0001506463975965744\n",
      "Training Loss: 0.00012536575424746844\n",
      "Training Loss: 0.0001263946388826298\n",
      "Validation Loss: 0.00013041183369801891\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0001492376309033716\n",
      "Training Loss: 0.00012415007546223933\n",
      "Training Loss: 0.000125264157923084\n",
      "Validation Loss: 0.00012900045897296284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00014787435551625095\n",
      "Training Loss: 0.00012297635512368288\n",
      "Training Loss: 0.00012417167989042354\n",
      "Validation Loss: 0.00012763888543907272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00014655503261565172\n",
      "Training Loss: 0.00012184305607661372\n",
      "Training Loss: 0.00012311577716900502\n",
      "Validation Loss: 0.00012632572318406335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00014527802203701868\n",
      "Training Loss: 0.00012074884500179906\n",
      "Training Loss: 0.00012209539972900528\n",
      "Validation Loss: 0.00012505900778113133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00014404229820684123\n",
      "Training Loss: 0.00011969247942033689\n",
      "Training Loss: 0.00012110940286220285\n",
      "Validation Loss: 0.0001238376206744219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00014284613212112163\n",
      "Training Loss: 0.00011867255489050876\n",
      "Training Loss: 0.0001201567818679905\n",
      "Validation Loss: 0.00012265974569498702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0001416883886759024\n",
      "Training Loss: 0.00011768780153943225\n",
      "Training Loss: 0.00011923638821826898\n",
      "Validation Loss: 0.00012152366937524665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00014056778911253787\n",
      "Training Loss: 0.00011673737084493041\n",
      "Training Loss: 0.00011834734616058995\n",
      "Validation Loss: 0.000120428978518473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00013948300156698678\n",
      "Training Loss: 0.00011581959910472506\n",
      "Training Loss: 0.00011748837654522504\n",
      "Validation Loss: 0.00011937368135170728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00013843299188920355\n",
      "Training Loss: 0.00011493358290863398\n",
      "Training Loss: 0.00011665881342196372\n",
      "Validation Loss: 0.00011835632284693132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0001374164950539125\n",
      "Training Loss: 0.00011407819409214425\n",
      "Training Loss: 0.00011585742155148182\n",
      "Validation Loss: 0.00011737614450600191\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00013643249938468215\n",
      "Training Loss: 0.00011325228784698993\n",
      "Training Loss: 0.0001150834615691565\n",
      "Validation Loss: 0.00011643073974462394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0001354798681495595\n",
      "Training Loss: 0.0001124547176368651\n",
      "Training Loss: 0.00011433575056798872\n",
      "Validation Loss: 0.00011551976505993327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00013455744943712488\n",
      "Training Loss: 0.00011168467417519424\n",
      "Training Loss: 0.00011361369961377931\n",
      "Validation Loss: 0.00011464196847626819\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00013366445411520545\n",
      "Training Loss: 0.00011094088512436428\n",
      "Training Loss: 0.00011291604906546126\n",
      "Validation Loss: 0.00011379605293155548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0001327997483622312\n",
      "Training Loss: 0.00011022251281247009\n",
      "Training Loss: 0.00011224228183891683\n",
      "Validation Loss: 0.00011298030254652128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00013196238292948693\n",
      "Training Loss: 0.00010952860363431682\n",
      "Training Loss: 0.00011159134865010856\n",
      "Validation Loss: 0.0001121938733100823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0001311514188091678\n",
      "Training Loss: 0.0001088580086525326\n",
      "Training Loss: 0.00011096233552962076\n",
      "Validation Loss: 0.00011143587839337108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.00013036579250183422\n",
      "Training Loss: 0.00010820998763847456\n",
      "Training Loss: 0.00011035456117497233\n",
      "Validation Loss: 0.00011070469067970897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00012960475271029282\n",
      "Training Loss: 0.0001075836451491341\n",
      "Training Loss: 0.00010976725938235177\n",
      "Validation Loss: 0.00010999968537689302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00012886724958661945\n",
      "Training Loss: 0.00010697803822949936\n",
      "Training Loss: 0.00010919941338215722\n",
      "Validation Loss: 0.00010931985231222365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.00012815282835617836\n",
      "Training Loss: 0.00010639245433594625\n",
      "Training Loss: 0.00010865060875403287\n",
      "Validation Loss: 0.00010866370428813977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00012746012125717244\n",
      "Training Loss: 0.00010582589517980523\n",
      "Training Loss: 0.00010811981951519556\n",
      "Validation Loss: 0.00010803102995442316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0001267889382870635\n",
      "Training Loss: 0.00010527784646001237\n",
      "Training Loss: 0.00010760647790448275\n",
      "Validation Loss: 0.00010742007576441262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.00012613810878974618\n",
      "Training Loss: 0.00010474710782546026\n",
      "Training Loss: 0.0001071098838292528\n",
      "Validation Loss: 0.00010683003249264249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0001255068988939456\n",
      "Training Loss: 0.00010423347553114581\n",
      "Training Loss: 0.00010662930640137347\n",
      "Validation Loss: 0.00010626097136583269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00012489470730542963\n",
      "Training Loss: 0.00010373591674579075\n",
      "Training Loss: 0.00010616414702781185\n",
      "Validation Loss: 0.00010571070792077612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.00012430077630597224\n",
      "Training Loss: 0.00010325377490516985\n",
      "Training Loss: 0.00010571378504209861\n",
      "Validation Loss: 0.0001051789001057126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0001237244072217436\n",
      "Training Loss: 0.00010278644363097556\n",
      "Training Loss: 0.00010527749561333621\n",
      "Validation Loss: 0.00010466517267743481\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00012316491493038483\n",
      "Training Loss: 0.00010233329895527277\n",
      "Training Loss: 0.0001048548364724411\n",
      "Validation Loss: 0.00010416864549032846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00012262160824320746\n",
      "Training Loss: 0.00010189361552875197\n",
      "Training Loss: 0.0001044452301266574\n",
      "Validation Loss: 0.00010368823367049996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00012209378966872463\n",
      "Training Loss: 0.0001014670363838377\n",
      "Training Loss: 0.00010404799148091115\n",
      "Validation Loss: 0.0001032235115335527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0001215808906727034\n",
      "Training Loss: 0.00010105278438459209\n",
      "Training Loss: 0.00010366279400841449\n",
      "Validation Loss: 0.0001027738239980444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0001210823926885496\n",
      "Training Loss: 0.00010065047307762142\n",
      "Training Loss: 0.00010328895355996792\n",
      "Validation Loss: 0.00010233887704171036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00012059785099154397\n",
      "Training Loss: 0.00010025949482951546\n",
      "Training Loss: 0.00010292613280398654\n",
      "Validation Loss: 0.00010191757538767264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.0001201266363295872\n",
      "Training Loss: 9.987936048673874e-05\n",
      "Training Loss: 0.00010257384198666841\n",
      "Validation Loss: 0.00010150906915911814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00011966823175498576\n",
      "Training Loss: 9.950967222721374e-05\n",
      "Training Loss: 0.0001022314684723824\n",
      "Validation Loss: 0.00010111339138398926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00011922229022275133\n",
      "Training Loss: 9.91498086386855e-05\n",
      "Training Loss: 0.00010189876121330599\n",
      "Validation Loss: 0.00010072932062112056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.00011878819625962933\n",
      "Training Loss: 9.879947060653649e-05\n",
      "Training Loss: 0.00010157525455724681\n",
      "Validation Loss: 0.00010035677321743759\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00011836549188956269\n",
      "Training Loss: 9.845823200521408e-05\n",
      "Training Loss: 0.00010126062875315256\n",
      "Validation Loss: 9.999535643473383e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.00011795381408774119\n",
      "Training Loss: 9.81256333489e-05\n",
      "Training Loss: 0.0001009543921554723\n",
      "Validation Loss: 9.964439651115897e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.000117552788778994\n",
      "Training Loss: 9.780124229109788e-05\n",
      "Training Loss: 0.00010065614850645943\n",
      "Validation Loss: 9.930355392927514e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00011716182948475761\n",
      "Training Loss: 9.748488657351117e-05\n",
      "Training Loss: 0.00010036563371613738\n",
      "Validation Loss: 9.897230218362136e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00011678073373332154\n",
      "Training Loss: 9.717610909319774e-05\n",
      "Training Loss: 0.00010008256797846116\n",
      "Validation Loss: 9.865000131693694e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0001164089902977139\n",
      "Training Loss: 9.687455050880089e-05\n",
      "Training Loss: 9.980650073885045e-05\n",
      "Validation Loss: 9.833673962174124e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.00011604633898969041\n",
      "Training Loss: 9.657992502070555e-05\n",
      "Training Loss: 9.953724025763222e-05\n",
      "Validation Loss: 9.803162094940081e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.00011569250504180673\n",
      "Training Loss: 9.629199195842374e-05\n",
      "Training Loss: 9.927434283781623e-05\n",
      "Validation Loss: 9.773501197956607e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00011534685228980379\n",
      "Training Loss: 9.601028047654836e-05\n",
      "Training Loss: 9.901778587845911e-05\n",
      "Validation Loss: 9.744557608203476e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00011500932977469347\n",
      "Training Loss: 9.573475394972775e-05\n",
      "Training Loss: 9.876720946522255e-05\n",
      "Validation Loss: 9.716406002349032e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.00011467957259810647\n",
      "Training Loss: 9.546499148200383e-05\n",
      "Training Loss: 9.852215546743537e-05\n",
      "Validation Loss: 9.688937416796578e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.00011435729752520273\n",
      "Training Loss: 9.5200836622098e-05\n",
      "Training Loss: 9.828262081100547e-05\n",
      "Validation Loss: 9.662151726873806e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.00011404219870200905\n",
      "Training Loss: 9.494196031482715e-05\n",
      "Training Loss: 9.804827010157169e-05\n",
      "Validation Loss: 9.63601350725113e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.00011373415020898392\n",
      "Training Loss: 9.468820524489275e-05\n",
      "Training Loss: 9.781891746570182e-05\n",
      "Validation Loss: 9.610511901218763e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00011343264119204832\n",
      "Training Loss: 9.443928655855416e-05\n",
      "Training Loss: 9.759426247910597e-05\n",
      "Validation Loss: 9.585613277910821e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00011313750831504877\n",
      "Training Loss: 9.419523569704325e-05\n",
      "Training Loss: 9.737438206684601e-05\n",
      "Validation Loss: 9.561260962522631e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.00011284867748145188\n",
      "Training Loss: 9.395556311574183e-05\n",
      "Training Loss: 9.715889061226335e-05\n",
      "Validation Loss: 9.537490517318934e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.0001125657575630612\n",
      "Training Loss: 9.372028685902478e-05\n",
      "Training Loss: 9.694761588434631e-05\n",
      "Validation Loss: 9.514247417581408e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.00011228857465539477\n",
      "Training Loss: 9.348902757665201e-05\n",
      "Training Loss: 9.674032702605473e-05\n",
      "Validation Loss: 9.491481792343272e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.00011201682921637257\n",
      "Training Loss: 9.326184441306395e-05\n",
      "Training Loss: 9.653690402956272e-05\n",
      "Validation Loss: 9.469205328100491e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.00011175051356076437\n",
      "Training Loss: 9.303848852141527e-05\n",
      "Training Loss: 9.633725835556106e-05\n",
      "Validation Loss: 9.447409079104056e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.00011148927756948979\n",
      "Training Loss: 9.281872974497673e-05\n",
      "Training Loss: 9.614113679162984e-05\n",
      "Validation Loss: 9.426060287194232e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.00011123306995614257\n",
      "Training Loss: 9.260253594220558e-05\n",
      "Training Loss: 9.594848926099075e-05\n",
      "Validation Loss: 9.405165685697529e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.00011098154823230288\n",
      "Training Loss: 9.23896793028689e-05\n",
      "Training Loss: 9.575905814926955e-05\n",
      "Validation Loss: 9.384643128848101e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.00011073459833824017\n",
      "Training Loss: 9.218018025421771e-05\n",
      "Training Loss: 9.557298661093227e-05\n",
      "Validation Loss: 9.364538626858815e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.00011049215157981962\n",
      "Training Loss: 9.197377185955702e-05\n",
      "Training Loss: 9.538976466501481e-05\n",
      "Validation Loss: 9.344820497635021e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.00011025404068277566\n",
      "Training Loss: 9.177029541206139e-05\n",
      "Training Loss: 9.520955286461686e-05\n",
      "Validation Loss: 9.325474769703055e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.0001100199413485825\n",
      "Training Loss: 9.156972512755601e-05\n",
      "Training Loss: 9.503227572167816e-05\n",
      "Validation Loss: 9.306490645623568e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00010979002767271596\n",
      "Training Loss: 9.137206248851726e-05\n",
      "Training Loss: 9.48576021437475e-05\n",
      "Validation Loss: 9.28782708572552e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.00010956378578157455\n",
      "Training Loss: 9.117699730268214e-05\n",
      "Training Loss: 9.46855857000628e-05\n",
      "Validation Loss: 9.269517079118987e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.00010934133231785381\n",
      "Training Loss: 9.098461264329671e-05\n",
      "Training Loss: 9.451599585190707e-05\n",
      "Validation Loss: 9.25150562896592e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.00010912237683442073\n",
      "Training Loss: 9.07946659845038e-05\n",
      "Training Loss: 9.434897206119785e-05\n",
      "Validation Loss: 9.233805240307519e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.00010890698204093496\n",
      "Training Loss: 9.060716970452632e-05\n",
      "Training Loss: 9.418416361768322e-05\n",
      "Validation Loss: 9.216444183100443e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.00010869492228266609\n",
      "Training Loss: 9.042198918905342e-05\n",
      "Training Loss: 9.402169925124327e-05\n",
      "Validation Loss: 9.199325563458025e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.00010848611115761742\n",
      "Training Loss: 9.023920523759443e-05\n",
      "Training Loss: 9.386140026435896e-05\n",
      "Validation Loss: 9.182472985322532e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00010828042119101155\n",
      "Training Loss: 9.005837852782861e-05\n",
      "Training Loss: 9.370326636599203e-05\n",
      "Validation Loss: 9.165913115283004e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0001080778112191183\n",
      "Training Loss: 8.987985728708736e-05\n",
      "Training Loss: 9.354708441605908e-05\n",
      "Validation Loss: 9.149588749188409e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.00010787800712932949\n",
      "Training Loss: 8.970331923592312e-05\n",
      "Training Loss: 9.339283479675942e-05\n",
      "Validation Loss: 9.133517897077653e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.00010768116179860953\n",
      "Training Loss: 8.952872072768513e-05\n",
      "Training Loss: 9.32404847117141e-05\n",
      "Validation Loss: 9.117683284682826e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.00010748703718491015\n",
      "Training Loss: 8.935606190789258e-05\n",
      "Training Loss: 9.309003769885748e-05\n",
      "Validation Loss: 9.10208474543355e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.00010729556454862177\n",
      "Training Loss: 8.918519794860913e-05\n",
      "Training Loss: 9.294120216509328e-05\n",
      "Validation Loss: 9.086716266445753e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.00010710666544582636\n",
      "Training Loss: 8.901621054974385e-05\n",
      "Training Loss: 9.279427508772642e-05\n",
      "Validation Loss: 9.071543392176895e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00010692030457903456\n",
      "Training Loss: 8.884890983608785e-05\n",
      "Training Loss: 9.264869794606056e-05\n",
      "Validation Loss: 9.056604755713717e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.0001067362686535489\n",
      "Training Loss: 8.868321049703809e-05\n",
      "Training Loss: 9.250494496882312e-05\n",
      "Validation Loss: 9.041814009220472e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00010655457271241175\n",
      "Training Loss: 8.851928271724318e-05\n",
      "Training Loss: 9.236279577635287e-05\n",
      "Validation Loss: 9.027292368924729e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.00010637517377290351\n",
      "Training Loss: 8.835683465804322e-05\n",
      "Training Loss: 9.222204465913819e-05\n",
      "Validation Loss: 9.012884098676418e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00010619797664730868\n",
      "Training Loss: 8.819601420327672e-05\n",
      "Training Loss: 9.208262533320521e-05\n",
      "Validation Loss: 8.998732037173213e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.00010602283978187189\n",
      "Training Loss: 8.803651815469493e-05\n",
      "Training Loss: 9.19448349486629e-05\n",
      "Validation Loss: 8.984734285241869e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.00010584990152892715\n",
      "Training Loss: 8.787857852439629e-05\n",
      "Training Loss: 9.18082523639896e-05\n",
      "Validation Loss: 8.970867267553434e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.000105678804402487\n",
      "Training Loss: 8.772205824243428e-05\n",
      "Training Loss: 9.167305363916967e-05\n",
      "Validation Loss: 8.957217104059024e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.00010550972026976524\n",
      "Training Loss: 8.756687556342513e-05\n",
      "Training Loss: 9.153906860774441e-05\n",
      "Validation Loss: 8.943693738432701e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.00010534243459005666\n",
      "Training Loss: 8.741294545870915e-05\n",
      "Training Loss: 9.140636990196072e-05\n",
      "Validation Loss: 8.93035990741461e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.0001051770690446574\n",
      "Training Loss: 8.726036450752872e-05\n",
      "Training Loss: 9.127489745878847e-05\n",
      "Validation Loss: 8.917133222025717e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.00010501342830139037\n",
      "Training Loss: 8.710900144251354e-05\n",
      "Training Loss: 9.114447184401797e-05\n",
      "Validation Loss: 8.904093598236991e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.00010485149388841819\n",
      "Training Loss: 8.695889271621127e-05\n",
      "Training Loss: 9.101534490582708e-05\n",
      "Validation Loss: 8.891147528752146e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.00010469124515111617\n",
      "Training Loss: 8.680985831233557e-05\n",
      "Training Loss: 9.08871712454129e-05\n",
      "Validation Loss: 8.878376145608098e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.00010453254678395752\n",
      "Training Loss: 8.666206795169274e-05\n",
      "Training Loss: 9.076014463062165e-05\n",
      "Validation Loss: 8.865717750319327e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00010437544538035581\n",
      "Training Loss: 8.651531360555965e-05\n",
      "Training Loss: 9.063407921530597e-05\n",
      "Validation Loss: 8.853197299829211e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.00010421987231893581\n",
      "Training Loss: 8.63697338354541e-05\n",
      "Training Loss: 9.05090835840383e-05\n",
      "Validation Loss: 8.840805319042385e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.00010406576756395224\n",
      "Training Loss: 8.622519975688192e-05\n",
      "Training Loss: 9.038495344611875e-05\n",
      "Validation Loss: 8.828526512097392e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.00010391310443083057\n",
      "Training Loss: 8.608154998910323e-05\n",
      "Training Loss: 9.02618554300716e-05\n",
      "Validation Loss: 8.816352455438248e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00010376182900472486\n",
      "Training Loss: 8.593897041464515e-05\n",
      "Training Loss: 9.01396716471936e-05\n",
      "Validation Loss: 8.80430681329957e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.00010361190765252104\n",
      "Training Loss: 8.579735645071196e-05\n",
      "Training Loss: 9.001842765428592e-05\n",
      "Validation Loss: 8.792398774643557e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.00010346327128900157\n",
      "Training Loss: 8.565672718759743e-05\n",
      "Training Loss: 8.989796424430097e-05\n",
      "Validation Loss: 8.780547094001929e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.00010331584104278591\n",
      "Training Loss: 8.551700969292142e-05\n",
      "Training Loss: 8.977842805506952e-05\n",
      "Validation Loss: 8.768831776251318e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.00010316971656720852\n",
      "Training Loss: 8.537810233974597e-05\n",
      "Training Loss: 8.96595892663754e-05\n",
      "Validation Loss: 8.75719968748496e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.00010302478159246675\n",
      "Training Loss: 8.52400426811073e-05\n",
      "Training Loss: 8.954159707172949e-05\n",
      "Validation Loss: 8.745670419649399e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.00010288097341799584\n",
      "Training Loss: 8.510294289408193e-05\n",
      "Training Loss: 8.942439716520311e-05\n",
      "Validation Loss: 8.73423500655754e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.00010273832186612709\n",
      "Training Loss: 8.496651847053727e-05\n",
      "Training Loss: 8.930793870604248e-05\n",
      "Validation Loss: 8.722891239874493e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.00010259670103550889\n",
      "Training Loss: 8.483087724016514e-05\n",
      "Training Loss: 8.91922002483625e-05\n",
      "Validation Loss: 8.711640036248294e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.00010245612174003327\n",
      "Training Loss: 8.469598644296639e-05\n",
      "Training Loss: 8.907721062314521e-05\n",
      "Validation Loss: 8.7004519280506e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00010231661698526296\n",
      "Training Loss: 8.45618534458481e-05\n",
      "Training Loss: 8.896281237866788e-05\n",
      "Validation Loss: 8.689342894796753e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.00010217807643130072\n",
      "Training Loss: 8.442848936283553e-05\n",
      "Training Loss: 8.884915480848576e-05\n",
      "Validation Loss: 8.678344485733863e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.00010204062803495617\n",
      "Training Loss: 8.429582793723966e-05\n",
      "Training Loss: 8.873604630935006e-05\n",
      "Validation Loss: 8.667405203023725e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.00010190393812990806\n",
      "Training Loss: 8.416373395448318e-05\n",
      "Training Loss: 8.862368530571984e-05\n",
      "Validation Loss: 8.656539299163649e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.00010176809234508255\n",
      "Training Loss: 8.403240453844774e-05\n",
      "Training Loss: 8.851174746268953e-05\n",
      "Validation Loss: 8.64577079912042e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.00010163314781493683\n",
      "Training Loss: 8.39015348446992e-05\n",
      "Training Loss: 8.840050675644306e-05\n",
      "Validation Loss: 8.635070101396256e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.00010149915602596594\n",
      "Training Loss: 8.377145183658286e-05\n",
      "Training Loss: 8.828986031403474e-05\n",
      "Validation Loss: 8.62440437221052e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00010136580116522965\n",
      "Training Loss: 8.364179666386917e-05\n",
      "Training Loss: 8.817970161544509e-05\n",
      "Validation Loss: 8.613810676027069e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.00010123337182449177\n",
      "Training Loss: 8.35127448226558e-05\n",
      "Training Loss: 8.807009397060028e-05\n",
      "Validation Loss: 8.60326506247812e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.00010110157236340456\n",
      "Training Loss: 8.338435419318558e-05\n",
      "Training Loss: 8.796085983703961e-05\n",
      "Validation Loss: 8.592830028156344e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.00010097056658196379\n",
      "Training Loss: 8.325630252329574e-05\n",
      "Training Loss: 8.78522649873048e-05\n",
      "Validation Loss: 8.58240287578135e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.00010084022599585296\n",
      "Training Loss: 8.312878110700695e-05\n",
      "Training Loss: 8.774401235314144e-05\n",
      "Validation Loss: 8.572038562336919e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.00010071046822304197\n",
      "Training Loss: 8.300177889395854e-05\n",
      "Training Loss: 8.76363508632494e-05\n",
      "Validation Loss: 8.561718893841398e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.00010058140478577115\n",
      "Training Loss: 8.28751444350928e-05\n",
      "Training Loss: 8.75290426574793e-05\n",
      "Validation Loss: 8.551475480856149e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.00010045294185147213\n",
      "Training Loss: 8.274891695691621e-05\n",
      "Training Loss: 8.742217756662285e-05\n",
      "Validation Loss: 8.541242538300916e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.00010032492929894942\n",
      "Training Loss: 8.26232127383264e-05\n",
      "Training Loss: 8.731569862902689e-05\n",
      "Validation Loss: 8.531101709164697e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.0001001975693179702\n",
      "Training Loss: 8.249775176409457e-05\n",
      "Training Loss: 8.720959419406427e-05\n",
      "Validation Loss: 8.520963603403064e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00010007066903199302\n",
      "Training Loss: 8.237272495534854e-05\n",
      "Training Loss: 8.710375394002767e-05\n",
      "Validation Loss: 8.510899797227139e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 9.994422523050161e-05\n",
      "Training Loss: 8.224797998991562e-05\n",
      "Training Loss: 8.699837307176495e-05\n",
      "Validation Loss: 8.500860729307104e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 9.981838386920572e-05\n",
      "Training Loss: 8.212363953134627e-05\n",
      "Training Loss: 8.689324504302931e-05\n",
      "Validation Loss: 8.49085016433788e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 9.969277779418917e-05\n",
      "Training Loss: 8.1999535950672e-05\n",
      "Training Loss: 8.678846282236918e-05\n",
      "Validation Loss: 8.480883244895298e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 9.956775376849691e-05\n",
      "Training Loss: 8.187563054889323e-05\n",
      "Training Loss: 8.668398334521043e-05\n",
      "Validation Loss: 8.470933062199038e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 9.944302688381867e-05\n",
      "Training Loss: 8.175201295671286e-05\n",
      "Training Loss: 8.657960604978143e-05\n",
      "Validation Loss: 8.461039700439746e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 9.931875655638578e-05\n",
      "Training Loss: 8.162861064192839e-05\n",
      "Training Loss: 8.647552841466677e-05\n",
      "Validation Loss: 8.451123689196669e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 9.919475775859609e-05\n",
      "Training Loss: 8.15053649512265e-05\n",
      "Training Loss: 8.637180468213046e-05\n",
      "Validation Loss: 8.441253089330622e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 9.907104746162076e-05\n",
      "Training Loss: 8.138221196531958e-05\n",
      "Training Loss: 8.626821888356062e-05\n",
      "Validation Loss: 8.431414478130474e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 9.894774767417402e-05\n",
      "Training Loss: 8.125929191010072e-05\n",
      "Training Loss: 8.616481670287613e-05\n",
      "Validation Loss: 8.421595245298897e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 9.882471128548787e-05\n",
      "Training Loss: 8.113642372336471e-05\n",
      "Training Loss: 8.606160011368047e-05\n",
      "Validation Loss: 8.411777778317709e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 9.870179073004693e-05\n",
      "Training Loss: 8.101365577203978e-05\n",
      "Training Loss: 8.595845943091263e-05\n",
      "Validation Loss: 8.401965936918918e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 9.85791334278474e-05\n",
      "Training Loss: 8.089089535133098e-05\n",
      "Training Loss: 8.585548354858474e-05\n",
      "Validation Loss: 8.39215128323988e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 9.845663412306749e-05\n",
      "Training Loss: 8.076818223344162e-05\n",
      "Training Loss: 8.575260301768139e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:11<20:48, 156.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.38237291533373e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.04908873355947435\n",
      "Training Loss: 0.044909021565690634\n",
      "Training Loss: 0.04259732223115861\n",
      "Validation Loss: 0.03826148018994358\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.033428770628524944\n",
      "Training Loss: 0.02725463093724102\n",
      "Training Loss: 0.022301403074525297\n",
      "Validation Loss: 0.017242321216114118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.014258908757144582\n",
      "Training Loss: 0.010395429829368369\n",
      "Training Loss: 0.007245605478528887\n",
      "Validation Loss: 0.004318313263068917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.0031592390107834946\n",
      "Training Loss: 0.0017692464336869307\n",
      "Training Loss: 0.0014606111943430732\n",
      "Validation Loss: 0.0013572504601521115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.0010943124174082185\n",
      "Training Loss: 0.0007915685878833755\n",
      "Training Loss: 0.0008353228674241108\n",
      "Validation Loss: 0.0009515494456628516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.000721184400281345\n",
      "Training Loss: 0.0005499245229293592\n",
      "Training Loss: 0.000596166235191049\n",
      "Validation Loss: 0.0006982335626877572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.0005520202982734191\n",
      "Training Loss: 0.0004393311215972062\n",
      "Training Loss: 0.0004781803789228434\n",
      "Validation Loss: 0.0005395722879931393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.0004672394759836607\n",
      "Training Loss: 0.0003818744836462429\n",
      "Training Loss: 0.00041206707501260096\n",
      "Validation Loss: 0.00045254207725520246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.00041800883876021546\n",
      "Training Loss: 0.00034463198004232255\n",
      "Training Loss: 0.0003678375780145871\n",
      "Validation Loss: 0.0004094873612312982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.00038308008881713816\n",
      "Training Loss: 0.000315452957584057\n",
      "Training Loss: 0.0003340390511220903\n",
      "Validation Loss: 0.00038671706437873603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0003547110554018218\n",
      "Training Loss: 0.0002907767038050224\n",
      "Training Loss: 0.00030663647048641\n",
      "Validation Loss: 0.0003705293281782769\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0003303508937415245\n",
      "Training Loss: 0.00026951218304020584\n",
      "Training Loss: 0.00028387188485794467\n",
      "Validation Loss: 0.00035567206786448407\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.0003090341276811159\n",
      "Training Loss: 0.0002510649100076989\n",
      "Training Loss: 0.00026464589973329566\n",
      "Validation Loss: 0.00034102278201071694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00029018791045928085\n",
      "Training Loss: 0.00023490294257499044\n",
      "Training Loss: 0.0002481115371119813\n",
      "Validation Loss: 0.00032671352221697226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0002733210246515228\n",
      "Training Loss: 0.0002205188157677185\n",
      "Training Loss: 0.00023357498248515184\n",
      "Validation Loss: 0.0003129527845231586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0002579735598737898\n",
      "Training Loss: 0.00020745574998727535\n",
      "Training Loss: 0.00022047101705538808\n",
      "Validation Loss: 0.00029976662421524474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00024373420474148587\n",
      "Training Loss: 0.00019532677801180397\n",
      "Training Loss: 0.00020834453800489428\n",
      "Validation Loss: 0.0002869742612970543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00023024940985123975\n",
      "Training Loss: 0.0001838180553022539\n",
      "Training Loss: 0.0001968374274110829\n",
      "Validation Loss: 0.00027429365692431307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00021723554578784388\n",
      "Training Loss: 0.00017269015977944947\n",
      "Training Loss: 0.00018568066558145803\n",
      "Validation Loss: 0.0002614086372202283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00020448295792448333\n",
      "Training Loss: 0.0001617786427777901\n",
      "Training Loss: 0.00017469397842432956\n",
      "Validation Loss: 0.0002480218681739643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00019186124940461012\n",
      "Training Loss: 0.00015099848784302594\n",
      "Training Loss: 0.00016378846783482004\n",
      "Validation Loss: 0.00023395787543398748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00017933214796357787\n",
      "Training Loss: 0.00014035313433851114\n",
      "Training Loss: 0.00015297474130420596\n",
      "Validation Loss: 0.00021917880092567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.00016695442565833218\n",
      "Training Loss: 0.00012993479551369092\n",
      "Training Loss: 0.00014236462682674757\n",
      "Validation Loss: 0.00020386607764194604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00015488389935853776\n",
      "Training Loss: 0.0001199155753965897\n",
      "Training Loss: 0.00013215333037805977\n",
      "Validation Loss: 0.0001884043968663279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00014334777568365099\n",
      "Training Loss: 0.00011051227766074589\n",
      "Training Loss: 0.00012258346452654223\n",
      "Validation Loss: 0.0001732918717811771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00013259704584925203\n",
      "Training Loss: 0.00010193668938882183\n",
      "Training Loss: 0.00011388803934096358\n",
      "Validation Loss: 0.0001590416379278824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00012284996064408914\n",
      "Training Loss: 9.434174523448747e-05\n",
      "Training Loss: 0.00010623509013385046\n",
      "Validation Loss: 0.00014604791359805236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00011424444074691565\n",
      "Training Loss: 8.779096679973009e-05\n",
      "Training Loss: 9.968983894395933e-05\n",
      "Validation Loss: 0.00013453381672682074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00010681887422833825\n",
      "Training Loss: 8.225729574405705e-05\n",
      "Training Loss: 9.421425205800915e-05\n",
      "Validation Loss: 0.00012455365344721123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00010052163204818498\n",
      "Training Loss: 7.764571531879483e-05\n",
      "Training Loss: 8.969564205472125e-05\n",
      "Validation Loss: 0.00011601967292059844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 9.524328491352208e-05\n",
      "Training Loss: 7.382712155049376e-05\n",
      "Training Loss: 8.598254743901634e-05\n",
      "Validation Loss: 0.000108778640618296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 9.084637174055387e-05\n",
      "Training Loss: 7.066650140586716e-05\n",
      "Training Loss: 8.292265235468221e-05\n",
      "Validation Loss: 0.00010264106660972094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 8.719099005702447e-05\n",
      "Training Loss: 6.803946695072227e-05\n",
      "Training Loss: 8.037940064696158e-05\n",
      "Validation Loss: 9.742547817030539e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 8.414866791099484e-05\n",
      "Training Loss: 6.584101472071779e-05\n",
      "Training Loss: 7.8240317284326e-05\n",
      "Validation Loss: 9.296910459678646e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 8.160690001659531e-05\n",
      "Training Loss: 6.398575921593874e-05\n",
      "Training Loss: 7.641920124115131e-05\n",
      "Validation Loss: 8.913314434650009e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 7.947176581637905e-05\n",
      "Training Loss: 6.24055294201753e-05\n",
      "Training Loss: 7.484834839942778e-05\n",
      "Validation Loss: 8.580830995066372e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 7.766572791751969e-05\n",
      "Training Loss: 6.104764307565347e-05\n",
      "Training Loss: 7.347762548306491e-05\n",
      "Validation Loss: 8.290700467379916e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 7.612602236804377e-05\n",
      "Training Loss: 5.986981529986224e-05\n",
      "Training Loss: 7.226846533285425e-05\n",
      "Validation Loss: 8.035700663507608e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 7.480208329070592e-05\n",
      "Training Loss: 5.8839175994762624e-05\n",
      "Training Loss: 7.119205989511101e-05\n",
      "Validation Loss: 7.810458147728598e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 7.365367156126013e-05\n",
      "Training Loss: 5.792931006908475e-05\n",
      "Training Loss: 7.022483824130177e-05\n",
      "Validation Loss: 7.610566048283493e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 7.264882452545862e-05\n",
      "Training Loss: 5.711919710392976e-05\n",
      "Training Loss: 6.93497123893394e-05\n",
      "Validation Loss: 7.432350843516636e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 7.176173618518078e-05\n",
      "Training Loss: 5.6392005080851956e-05\n",
      "Training Loss: 6.855209300738352e-05\n",
      "Validation Loss: 7.272690422059588e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 7.097165145296458e-05\n",
      "Training Loss: 5.573449332587188e-05\n",
      "Training Loss: 6.782044380997831e-05\n",
      "Validation Loss: 7.129432358422572e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 7.026200324162347e-05\n",
      "Training Loss: 5.513504635928257e-05\n",
      "Training Loss: 6.714552517678385e-05\n",
      "Validation Loss: 7.000234096737453e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 6.961959647924231e-05\n",
      "Training Loss: 5.458485519739043e-05\n",
      "Training Loss: 6.651953777691233e-05\n",
      "Validation Loss: 6.883407687392934e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 6.903326673636912e-05\n",
      "Training Loss: 5.407623656992655e-05\n",
      "Training Loss: 6.59360138251941e-05\n",
      "Validation Loss: 6.777432618752315e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 6.849443534065358e-05\n",
      "Training Loss: 5.360321390071476e-05\n",
      "Training Loss: 6.538979662309429e-05\n",
      "Validation Loss: 6.680818550899204e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 6.799572088311834e-05\n",
      "Training Loss: 5.316062739439076e-05\n",
      "Training Loss: 6.487606392965972e-05\n",
      "Validation Loss: 6.592473226171504e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 6.753127665433567e-05\n",
      "Training Loss: 5.27443369219327e-05\n",
      "Training Loss: 6.439126825171116e-05\n",
      "Validation Loss: 6.511437147585976e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 6.709608005621704e-05\n",
      "Training Loss: 5.23505831233706e-05\n",
      "Training Loss: 6.393177579411713e-05\n",
      "Validation Loss: 6.436740387583627e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 6.668626299415337e-05\n",
      "Training Loss: 5.197671413043281e-05\n",
      "Training Loss: 6.349516145292e-05\n",
      "Validation Loss: 6.367592996366e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 6.629824245919735e-05\n",
      "Training Loss: 5.1620263398035605e-05\n",
      "Training Loss: 6.307870518412528e-05\n",
      "Validation Loss: 6.303374925409208e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 6.592934273157879e-05\n",
      "Training Loss: 5.127901257310441e-05\n",
      "Training Loss: 6.268044665375783e-05\n",
      "Validation Loss: 6.243451211498161e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 6.557734408943361e-05\n",
      "Training Loss: 5.0951269222423435e-05\n",
      "Training Loss: 6.22985903191875e-05\n",
      "Validation Loss: 6.1872724738473e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 6.524007271309529e-05\n",
      "Training Loss: 5.063556533514202e-05\n",
      "Training Loss: 6.193178553075995e-05\n",
      "Validation Loss: 6.134434461988818e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 6.491599971013784e-05\n",
      "Training Loss: 5.033077964981203e-05\n",
      "Training Loss: 6.157834512123373e-05\n",
      "Validation Loss: 6.0845495160689365e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 6.460364304075483e-05\n",
      "Training Loss: 5.0035807780659526e-05\n",
      "Training Loss: 6.123753456449777e-05\n",
      "Validation Loss: 6.037250719866401e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 6.430203412037372e-05\n",
      "Training Loss: 4.974985294211365e-05\n",
      "Training Loss: 6.090764296004636e-05\n",
      "Validation Loss: 5.992276344820792e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 6.4010016044449e-05\n",
      "Training Loss: 4.947188849655504e-05\n",
      "Training Loss: 6.058857274183538e-05\n",
      "Validation Loss: 5.949348016063882e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 6.372688229930646e-05\n",
      "Training Loss: 4.9201379808891943e-05\n",
      "Training Loss: 6.0278891596681204e-05\n",
      "Validation Loss: 5.9082736738622604e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 6.345170770146069e-05\n",
      "Training Loss: 4.893804586345141e-05\n",
      "Training Loss: 5.997814615511743e-05\n",
      "Validation Loss: 5.868855897573299e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 6.318397046470637e-05\n",
      "Training Loss: 4.8681125558687196e-05\n",
      "Training Loss: 5.968588525320229e-05\n",
      "Validation Loss: 5.830912544021548e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 6.29231370112393e-05\n",
      "Training Loss: 4.843028827053786e-05\n",
      "Training Loss: 5.940116061083245e-05\n",
      "Validation Loss: 5.794389845208713e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 6.266880408475118e-05\n",
      "Training Loss: 4.8185256860051594e-05\n",
      "Training Loss: 5.912370127134636e-05\n",
      "Validation Loss: 5.759034612627433e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 6.242043357815419e-05\n",
      "Training Loss: 4.794552178509548e-05\n",
      "Training Loss: 5.885321931145882e-05\n",
      "Validation Loss: 5.724841544127976e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 6.217789248694317e-05\n",
      "Training Loss: 4.771084198637254e-05\n",
      "Training Loss: 5.8589118243617125e-05\n",
      "Validation Loss: 5.6916444883130825e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 6.194058058099472e-05\n",
      "Training Loss: 4.748113787627517e-05\n",
      "Training Loss: 5.833115162658942e-05\n",
      "Validation Loss: 5.659424121486052e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 6.170835980810807e-05\n",
      "Training Loss: 4.7255936701731114e-05\n",
      "Training Loss: 5.807889575862646e-05\n",
      "Validation Loss: 5.6280875760626e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 6.148105202555599e-05\n",
      "Training Loss: 4.7035516292908145e-05\n",
      "Training Loss: 5.7832175680232465e-05\n",
      "Validation Loss: 5.597600107812264e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 6.125842894562083e-05\n",
      "Training Loss: 4.681916617073512e-05\n",
      "Training Loss: 5.759071446846065e-05\n",
      "Validation Loss: 5.5678306437309065e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 6.104011665684084e-05\n",
      "Training Loss: 4.660706062168174e-05\n",
      "Training Loss: 5.735417227242578e-05\n",
      "Validation Loss: 5.5387888265061755e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 6.082623257498199e-05\n",
      "Training Loss: 4.6398849824527134e-05\n",
      "Training Loss: 5.712236752970057e-05\n",
      "Validation Loss: 5.510445643768036e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 6.061640624466236e-05\n",
      "Training Loss: 4.619447358663819e-05\n",
      "Training Loss: 5.689526871265116e-05\n",
      "Validation Loss: 5.482725994246966e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 6.0410477394725604e-05\n",
      "Training Loss: 4.5993856199402215e-05\n",
      "Training Loss: 5.667250075475749e-05\n",
      "Validation Loss: 5.455625315140894e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 6.020848554726399e-05\n",
      "Training Loss: 4.579704774187121e-05\n",
      "Training Loss: 5.64538605249254e-05\n",
      "Validation Loss: 5.429089025526767e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 6.001003926485282e-05\n",
      "Training Loss: 4.560366131954652e-05\n",
      "Training Loss: 5.623939974611858e-05\n",
      "Validation Loss: 5.403134901427436e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 5.981536943181709e-05\n",
      "Training Loss: 4.54136218468193e-05\n",
      "Training Loss: 5.602898437700787e-05\n",
      "Validation Loss: 5.3776685475119e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 5.9624235823321215e-05\n",
      "Training Loss: 4.522700462302964e-05\n",
      "Training Loss: 5.582217319897609e-05\n",
      "Validation Loss: 5.3527271426972814e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 5.9436415590425895e-05\n",
      "Training Loss: 4.504359464135632e-05\n",
      "Training Loss: 5.561909228163131e-05\n",
      "Validation Loss: 5.328315271245639e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 5.9251993329780815e-05\n",
      "Training Loss: 4.486343749476873e-05\n",
      "Training Loss: 5.5419596196770724e-05\n",
      "Validation Loss: 5.304309798304346e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 5.907073113576189e-05\n",
      "Training Loss: 4.468626018251598e-05\n",
      "Training Loss: 5.522337435195368e-05\n",
      "Validation Loss: 5.28076605538506e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 5.889262924483774e-05\n",
      "Training Loss: 4.451221749832257e-05\n",
      "Training Loss: 5.50308423999013e-05\n",
      "Validation Loss: 5.2576524963063836e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 5.871760463833198e-05\n",
      "Training Loss: 4.434109149769938e-05\n",
      "Training Loss: 5.484123479163827e-05\n",
      "Validation Loss: 5.2349777566694154e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 5.854556331541971e-05\n",
      "Training Loss: 4.417288997046853e-05\n",
      "Training Loss: 5.465495947191812e-05\n",
      "Validation Loss: 5.212699426940591e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 5.8376474339638665e-05\n",
      "Training Loss: 4.4007384742599244e-05\n",
      "Training Loss: 5.447173242373538e-05\n",
      "Validation Loss: 5.1908217505769335e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 5.821016454319761e-05\n",
      "Training Loss: 4.384473889331275e-05\n",
      "Training Loss: 5.4291374030981384e-05\n",
      "Validation Loss: 5.169324102997747e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 5.8046481935889463e-05\n",
      "Training Loss: 4.368484171209275e-05\n",
      "Training Loss: 5.4114132271934065e-05\n",
      "Validation Loss: 5.148212501174722e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 5.7885698627160306e-05\n",
      "Training Loss: 4.352759894800329e-05\n",
      "Training Loss: 5.393980720782565e-05\n",
      "Validation Loss: 5.127465125921201e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 5.772750241703761e-05\n",
      "Training Loss: 4.337286412692265e-05\n",
      "Training Loss: 5.376790170430468e-05\n",
      "Validation Loss: 5.107056904307683e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 5.75718272875747e-05\n",
      "Training Loss: 4.3220800423569015e-05\n",
      "Training Loss: 5.359902693271579e-05\n",
      "Validation Loss: 5.087038561101876e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 5.741875753074055e-05\n",
      "Training Loss: 4.307115680603601e-05\n",
      "Training Loss: 5.3432900108418836e-05\n",
      "Validation Loss: 5.067309438744089e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 5.7267995305210204e-05\n",
      "Training Loss: 4.29240859739366e-05\n",
      "Training Loss: 5.326910132680496e-05\n",
      "Validation Loss: 5.047931129441811e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 5.711978550152708e-05\n",
      "Training Loss: 4.2779305026670044e-05\n",
      "Training Loss: 5.310800582265074e-05\n",
      "Validation Loss: 5.028868949767876e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 5.697374600686089e-05\n",
      "Training Loss: 4.2636867869987325e-05\n",
      "Training Loss: 5.294918493291334e-05\n",
      "Validation Loss: 5.0101245766670084e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 5.6830299422472307e-05\n",
      "Training Loss: 4.249664849794499e-05\n",
      "Training Loss: 5.279281405819347e-05\n",
      "Validation Loss: 4.9916812621519426e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 5.6688687875521284e-05\n",
      "Training Loss: 4.235879473071691e-05\n",
      "Training Loss: 5.263900940462918e-05\n",
      "Validation Loss: 4.973537642491577e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 5.654975015659147e-05\n",
      "Training Loss: 4.2223116140576166e-05\n",
      "Training Loss: 5.2487268471850254e-05\n",
      "Validation Loss: 4.95567299295861e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 5.641237719373748e-05\n",
      "Training Loss: 4.2089594530807516e-05\n",
      "Training Loss: 5.2338022182993885e-05\n",
      "Validation Loss: 4.938106904988631e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 5.627770285627775e-05\n",
      "Training Loss: 4.1958222582252346e-05\n",
      "Training Loss: 5.219072184900142e-05\n",
      "Validation Loss: 4.920798808986516e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 5.614461682398541e-05\n",
      "Training Loss: 4.1828829087080524e-05\n",
      "Training Loss: 5.204585533192585e-05\n",
      "Validation Loss: 4.903762301387104e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 5.601382016720891e-05\n",
      "Training Loss: 4.1701508489495606e-05\n",
      "Training Loss: 5.190297617900797e-05\n",
      "Validation Loss: 4.886989448126503e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 5.588463636740926e-05\n",
      "Training Loss: 4.157621198146444e-05\n",
      "Training Loss: 5.176223768557975e-05\n",
      "Validation Loss: 4.870505073300551e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 5.5757878044460085e-05\n",
      "Training Loss: 4.1452850553014287e-05\n",
      "Training Loss: 5.162341420145822e-05\n",
      "Validation Loss: 4.854257660676768e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 5.56324804574615e-05\n",
      "Training Loss: 4.1331451577661937e-05\n",
      "Training Loss: 5.148665145497944e-05\n",
      "Validation Loss: 4.838268697322961e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 5.550943476919201e-05\n",
      "Training Loss: 4.1211792693047754e-05\n",
      "Training Loss: 5.135190506734943e-05\n",
      "Validation Loss: 4.82252340752689e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 5.538765814890212e-05\n",
      "Training Loss: 4.1094148223237425e-05\n",
      "Training Loss: 5.121914847222797e-05\n",
      "Validation Loss: 4.807018827766493e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 5.526814738459507e-05\n",
      "Training Loss: 4.097815019576956e-05\n",
      "Training Loss: 5.108812230446347e-05\n",
      "Validation Loss: 4.7917360349315e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 5.5149840409285386e-05\n",
      "Training Loss: 4.086399010702735e-05\n",
      "Training Loss: 5.095895580325305e-05\n",
      "Validation Loss: 4.776676772390407e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 5.503372100747583e-05\n",
      "Training Loss: 4.0751570963948325e-05\n",
      "Training Loss: 5.083164412553742e-05\n",
      "Validation Loss: 4.7618418484694045e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 5.491871181902752e-05\n",
      "Training Loss: 4.06407873219905e-05\n",
      "Training Loss: 5.070596804671368e-05\n",
      "Validation Loss: 4.7472121852397424e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 5.48058442814181e-05\n",
      "Training Loss: 4.053160301509706e-05\n",
      "Training Loss: 5.058222902334819e-05\n",
      "Validation Loss: 4.7327907293620634e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 5.469400855872664e-05\n",
      "Training Loss: 4.042415057256221e-05\n",
      "Training Loss: 5.046002451763343e-05\n",
      "Validation Loss: 4.718620701761834e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 5.458429960299327e-05\n",
      "Training Loss: 4.031824993489863e-05\n",
      "Training Loss: 5.033954619193537e-05\n",
      "Validation Loss: 4.7046207052180045e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 5.447549436667032e-05\n",
      "Training Loss: 4.021386356043877e-05\n",
      "Training Loss: 5.022077982630435e-05\n",
      "Validation Loss: 4.6908335053977387e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 5.4368766582229e-05\n",
      "Training Loss: 4.011101515061455e-05\n",
      "Training Loss: 5.010341229535697e-05\n",
      "Validation Loss: 4.6772269199842985e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 5.426291050525833e-05\n",
      "Training Loss: 4.0009660472151155e-05\n",
      "Training Loss: 4.998778987555852e-05\n",
      "Validation Loss: 4.663828783092224e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 5.415893178906117e-05\n",
      "Training Loss: 3.99097148851979e-05\n",
      "Training Loss: 4.9873474936248385e-05\n",
      "Validation Loss: 4.650634615204632e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 5.405597511753513e-05\n",
      "Training Loss: 3.981132934086418e-05\n",
      "Training Loss: 4.976092218839767e-05\n",
      "Validation Loss: 4.637607550107072e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 5.3954726020037924e-05\n",
      "Training Loss: 3.9714157599064495e-05\n",
      "Training Loss: 4.964964668033645e-05\n",
      "Validation Loss: 4.6247318790888076e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 5.3854316192882833e-05\n",
      "Training Loss: 3.9618391274416356e-05\n",
      "Training Loss: 4.954001041824085e-05\n",
      "Validation Loss: 4.612067321207004e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 5.375561339178603e-05\n",
      "Training Loss: 3.9524054241155685e-05\n",
      "Training Loss: 4.94316393542249e-05\n",
      "Validation Loss: 4.599576572361278e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 5.3657881812796405e-05\n",
      "Training Loss: 3.943092642430201e-05\n",
      "Training Loss: 4.9324733040521097e-05\n",
      "Validation Loss: 4.587265538646718e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 5.356174988719431e-05\n",
      "Training Loss: 3.933923586146193e-05\n",
      "Training Loss: 4.921897410440579e-05\n",
      "Validation Loss: 4.575082982810681e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 5.3466363899588034e-05\n",
      "Training Loss: 3.924868565036377e-05\n",
      "Training Loss: 4.9114928287963266e-05\n",
      "Validation Loss: 4.563092835688325e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 5.337268680023044e-05\n",
      "Training Loss: 3.9159376779025476e-05\n",
      "Training Loss: 4.901202571545582e-05\n",
      "Validation Loss: 4.551263251169382e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 5.327970038933927e-05\n",
      "Training Loss: 3.907131487721927e-05\n",
      "Training Loss: 4.891028402198572e-05\n",
      "Validation Loss: 4.539589817182644e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 5.318832409557217e-05\n",
      "Training Loss: 3.89843767743514e-05\n",
      "Training Loss: 4.8809880527187486e-05\n",
      "Validation Loss: 4.5280317607740584e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 5.309743894940766e-05\n",
      "Training Loss: 3.889858129014101e-05\n",
      "Training Loss: 4.8710710325394756e-05\n",
      "Validation Loss: 4.5166606964761574e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 5.300832028297009e-05\n",
      "Training Loss: 3.881380413986335e-05\n",
      "Training Loss: 4.8612820592097705e-05\n",
      "Validation Loss: 4.505445380080223e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 5.29197037508311e-05\n",
      "Training Loss: 3.8730288895294504e-05\n",
      "Training Loss: 4.851600077017792e-05\n",
      "Validation Loss: 4.494371434416638e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 5.283270862491918e-05\n",
      "Training Loss: 3.864783059270849e-05\n",
      "Training Loss: 4.842036357786128e-05\n",
      "Validation Loss: 4.483415564669138e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 5.274611704180643e-05\n",
      "Training Loss: 3.856640093090391e-05\n",
      "Training Loss: 4.832602022361243e-05\n",
      "Validation Loss: 4.472619520987628e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 5.26610084875756e-05\n",
      "Training Loss: 3.848591908081289e-05\n",
      "Training Loss: 4.823259276236058e-05\n",
      "Validation Loss: 4.4619165786509786e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 5.257643536424439e-05\n",
      "Training Loss: 3.840658639319372e-05\n",
      "Training Loss: 4.814032368813059e-05\n",
      "Validation Loss: 4.451413113283604e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 5.2493339187549284e-05\n",
      "Training Loss: 3.832822897038568e-05\n",
      "Training Loss: 4.804913558473345e-05\n",
      "Validation Loss: 4.4409898104215774e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 5.241058849605906e-05\n",
      "Training Loss: 3.8250725303896615e-05\n",
      "Training Loss: 4.795888298303907e-05\n",
      "Validation Loss: 4.430740859226737e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 5.232942867678503e-05\n",
      "Training Loss: 3.817427966851028e-05\n",
      "Training Loss: 4.7869924374026595e-05\n",
      "Validation Loss: 4.4205525667299356e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 5.2248504441649854e-05\n",
      "Training Loss: 3.8098750080735045e-05\n",
      "Training Loss: 4.7781827406652154e-05\n",
      "Validation Loss: 4.4105633720759664e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 5.216907368321699e-05\n",
      "Training Loss: 3.8024035420676226e-05\n",
      "Training Loss: 4.769471740019071e-05\n",
      "Validation Loss: 4.4006382239878006e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 5.208993534779438e-05\n",
      "Training Loss: 3.795024305645711e-05\n",
      "Training Loss: 4.760863156661799e-05\n",
      "Validation Loss: 4.390858276473297e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 5.201224918664593e-05\n",
      "Training Loss: 3.787732340697403e-05\n",
      "Training Loss: 4.752344364533201e-05\n",
      "Validation Loss: 4.381173816705342e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 5.193473041344987e-05\n",
      "Training Loss: 3.780534619409082e-05\n",
      "Training Loss: 4.743924144804623e-05\n",
      "Validation Loss: 4.371623520690652e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 5.185870893683386e-05\n",
      "Training Loss: 3.773406074287777e-05\n",
      "Training Loss: 4.735592912766151e-05\n",
      "Validation Loss: 4.362172418613421e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 5.178276946708138e-05\n",
      "Training Loss: 3.766362038504667e-05\n",
      "Training Loss: 4.727363696929387e-05\n",
      "Validation Loss: 4.352843925108174e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 5.170832027033612e-05\n",
      "Training Loss: 3.7594064817767506e-05\n",
      "Training Loss: 4.719211848623672e-05\n",
      "Validation Loss: 4.343609869087476e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 5.1634042065416e-05\n",
      "Training Loss: 3.752517304064895e-05\n",
      "Training Loss: 4.7111453950492434e-05\n",
      "Validation Loss: 4.33448704401333e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 5.1561001653226414e-05\n",
      "Training Loss: 3.745706988183883e-05\n",
      "Training Loss: 4.703168815012759e-05\n",
      "Validation Loss: 4.3254797469927235e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 5.1488224839886244e-05\n",
      "Training Loss: 3.738977988859915e-05\n",
      "Training Loss: 4.6952742754911016e-05\n",
      "Validation Loss: 4.3165517849905716e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 5.141661942388964e-05\n",
      "Training Loss: 3.7323175085930415e-05\n",
      "Training Loss: 4.687461150297168e-05\n",
      "Validation Loss: 4.307730329161091e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 5.1345220208531826e-05\n",
      "Training Loss: 3.725726678112551e-05\n",
      "Training Loss: 4.679730989664677e-05\n",
      "Validation Loss: 4.2990149408519194e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 5.127512119997846e-05\n",
      "Training Loss: 3.7192086188042596e-05\n",
      "Training Loss: 4.6720831319362334e-05\n",
      "Validation Loss: 4.290404958124639e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 5.12050718248247e-05\n",
      "Training Loss: 3.712763994144552e-05\n",
      "Training Loss: 4.6645129023090705e-05\n",
      "Validation Loss: 4.281871525982455e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 5.1136275328644845e-05\n",
      "Training Loss: 3.706375284991736e-05\n",
      "Training Loss: 4.657026242512075e-05\n",
      "Validation Loss: 4.273422542467139e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 5.106752071242227e-05\n",
      "Training Loss: 3.700056262459839e-05\n",
      "Training Loss: 4.649604060887214e-05\n",
      "Validation Loss: 4.2650808915894825e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 5.100005573922317e-05\n",
      "Training Loss: 3.6938090861440284e-05\n",
      "Training Loss: 4.642258806597965e-05\n",
      "Validation Loss: 4.256823784886733e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 5.093269326380323e-05\n",
      "Training Loss: 3.687608682184873e-05\n",
      "Training Loss: 4.6349843241841885e-05\n",
      "Validation Loss: 4.248669636049936e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 5.086647420512236e-05\n",
      "Training Loss: 3.6814932777815556e-05\n",
      "Training Loss: 4.627773344509478e-05\n",
      "Validation Loss: 4.240578777314389e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 5.080018806438602e-05\n",
      "Training Loss: 3.6754282239144234e-05\n",
      "Training Loss: 4.620647163392278e-05\n",
      "Validation Loss: 4.232564683508336e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 5.073520250334696e-05\n",
      "Training Loss: 3.669420162168535e-05\n",
      "Training Loss: 4.613589058862999e-05\n",
      "Validation Loss: 4.224664649024071e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 5.0670188702497395e-05\n",
      "Training Loss: 3.66346352416258e-05\n",
      "Training Loss: 4.606585072451708e-05\n",
      "Validation Loss: 4.216844372882059e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 5.0606312724994497e-05\n",
      "Training Loss: 3.657577200783635e-05\n",
      "Training Loss: 4.599656502250582e-05\n",
      "Validation Loss: 4.209094980100151e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 5.054243012182269e-05\n",
      "Training Loss: 3.651739732276837e-05\n",
      "Training Loss: 4.592788955505966e-05\n",
      "Validation Loss: 4.201387108050665e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 5.0479653234560827e-05\n",
      "Training Loss: 3.645950866939529e-05\n",
      "Training Loss: 4.585985924677516e-05\n",
      "Validation Loss: 4.193802288079568e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 5.0416919000326745e-05\n",
      "Training Loss: 3.6402214793724854e-05\n",
      "Training Loss: 4.579259016736614e-05\n",
      "Validation Loss: 4.186278980862911e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 5.035524492768673e-05\n",
      "Training Loss: 3.6345458831874566e-05\n",
      "Training Loss: 4.572582031869388e-05\n",
      "Validation Loss: 4.178834480340259e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 5.029356600061874e-05\n",
      "Training Loss: 3.628918331969544e-05\n",
      "Training Loss: 4.565976727462839e-05\n",
      "Validation Loss: 4.171460101348162e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 5.02328617949388e-05\n",
      "Training Loss: 3.623342605351354e-05\n",
      "Training Loss: 4.559412750040792e-05\n",
      "Validation Loss: 4.1641323840328336e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 5.017213464498127e-05\n",
      "Training Loss: 3.617807113869276e-05\n",
      "Training Loss: 4.5529187768806875e-05\n",
      "Validation Loss: 4.1568992480350656e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 5.0112537944642096e-05\n",
      "Training Loss: 3.6123285715348176e-05\n",
      "Training Loss: 4.546487137304211e-05\n",
      "Validation Loss: 4.149754518498974e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 5.005289605833241e-05\n",
      "Training Loss: 3.606910506505301e-05\n",
      "Training Loss: 4.5401100401250005e-05\n",
      "Validation Loss: 4.1426480595291244e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 4.9994222868008366e-05\n",
      "Training Loss: 3.601521093287374e-05\n",
      "Training Loss: 4.533797552539909e-05\n",
      "Validation Loss: 4.135624794798787e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 4.9935506751808134e-05\n",
      "Training Loss: 3.596184577872919e-05\n",
      "Training Loss: 4.5275269662852225e-05\n",
      "Validation Loss: 4.128665055718608e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 4.987774846085813e-05\n",
      "Training Loss: 3.5908910367652427e-05\n",
      "Training Loss: 4.521307238064765e-05\n",
      "Validation Loss: 4.1217504337070616e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 4.98199018466039e-05\n",
      "Training Loss: 3.5856521596997483e-05\n",
      "Training Loss: 4.515150920724409e-05\n",
      "Validation Loss: 4.114927972633074e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 4.976324174322144e-05\n",
      "Training Loss: 3.5804482656658365e-05\n",
      "Training Loss: 4.509038556079759e-05\n",
      "Validation Loss: 4.108152940174927e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 4.970619599134807e-05\n",
      "Training Loss: 3.575282441033778e-05\n",
      "Training Loss: 4.502986323132063e-05\n",
      "Validation Loss: 4.101463723395938e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 4.9650311641471486e-05\n",
      "Training Loss: 3.570164192979064e-05\n",
      "Training Loss: 4.4969782338739604e-05\n",
      "Validation Loss: 4.094788454586818e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 4.959431287261395e-05\n",
      "Training Loss: 3.565088089999336e-05\n",
      "Training Loss: 4.4910300503033795e-05\n",
      "Validation Loss: 4.0881959929710106e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 4.953926154485089e-05\n",
      "Training Loss: 3.5600416363195106e-05\n",
      "Training Loss: 4.4851171328446074e-05\n",
      "Validation Loss: 4.08168304367403e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 4.948396338022576e-05\n",
      "Training Loss: 3.555056287723346e-05\n",
      "Training Loss: 4.4792737189709444e-05\n",
      "Validation Loss: 4.0752003284335056e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 4.94298083663125e-05\n",
      "Training Loss: 3.550092558043616e-05\n",
      "Training Loss: 4.4734709063050105e-05\n",
      "Validation Loss: 4.068783278965925e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 4.937532023177482e-05\n",
      "Training Loss: 3.545175672797996e-05\n",
      "Training Loss: 4.467704950911866e-05\n",
      "Validation Loss: 4.062435958617703e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 4.932196405206923e-05\n",
      "Training Loss: 3.540292628940733e-05\n",
      "Training Loss: 4.4620030139412846e-05\n",
      "Validation Loss: 4.056108364851895e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 4.926831815737387e-05\n",
      "Training Loss: 3.5354454651042035e-05\n",
      "Training Loss: 4.4563334859049065e-05\n",
      "Validation Loss: 4.049843363226797e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 4.921571428440075e-05\n",
      "Training Loss: 3.530641374027255e-05\n",
      "Training Loss: 4.450721517514466e-05\n",
      "Validation Loss: 4.043664100638043e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 4.916280496445324e-05\n",
      "Training Loss: 3.525877004449285e-05\n",
      "Training Loss: 4.445144199507922e-05\n",
      "Validation Loss: 4.0374987323691916e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 4.9110876416307294e-05\n",
      "Training Loss: 3.5211431090829136e-05\n",
      "Training Loss: 4.439608633674652e-05\n",
      "Validation Loss: 4.0314250475531796e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 4.905879428633853e-05\n",
      "Training Loss: 3.516429177125247e-05\n",
      "Training Loss: 4.4341337097648645e-05\n",
      "Validation Loss: 4.025396287687819e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 4.900770179801839e-05\n",
      "Training Loss: 3.511770046998208e-05\n",
      "Training Loss: 4.4286905508670313e-05\n",
      "Validation Loss: 4.019379903081827e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 4.895625422705052e-05\n",
      "Training Loss: 3.5071363231509165e-05\n",
      "Training Loss: 4.4232980008018787e-05\n",
      "Validation Loss: 4.0134485937854285e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 4.8905802316312474e-05\n",
      "Training Loss: 3.5025370766561534e-05\n",
      "Training Loss: 4.417924412337015e-05\n",
      "Validation Loss: 4.007544601009112e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 4.8855157058369517e-05\n",
      "Training Loss: 3.4979698543793344e-05\n",
      "Training Loss: 4.412612934174831e-05\n",
      "Validation Loss: 4.0016966811359206e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 4.8805409219312426e-05\n",
      "Training Loss: 3.493429432410267e-05\n",
      "Training Loss: 4.407334903135052e-05\n",
      "Validation Loss: 3.9959034735004655e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 4.8755468230865515e-05\n",
      "Training Loss: 3.488933491780699e-05\n",
      "Training Loss: 4.402102353651571e-05\n",
      "Validation Loss: 3.99014957136469e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 4.870644829225057e-05\n",
      "Training Loss: 3.4844613608129294e-05\n",
      "Training Loss: 4.3969001558252786e-05\n",
      "Validation Loss: 3.984423838272541e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 4.865701710969006e-05\n",
      "Training Loss: 3.480028625972409e-05\n",
      "Training Loss: 4.391743887481425e-05\n",
      "Validation Loss: 3.978773712292474e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 4.860861959969043e-05\n",
      "Training Loss: 3.475616134664961e-05\n",
      "Training Loss: 4.386633113881544e-05\n",
      "Validation Loss: 3.973152879450609e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 4.8559970978203637e-05\n",
      "Training Loss: 3.471233917935024e-05\n",
      "Training Loss: 4.381547490993398e-05\n",
      "Validation Loss: 3.967605232574396e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 4.8512194730392366e-05\n",
      "Training Loss: 3.466892319693216e-05\n",
      "Training Loss: 4.3764987653958085e-05\n",
      "Validation Loss: 3.962086388322389e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 4.8464128369687386e-05\n",
      "Training Loss: 3.462569954990613e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [07:48<18:15, 156.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.3715051215258425e-05\n",
      "Validation Loss: 3.956581251126347e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.4338964268565178\n",
      "Training Loss: 0.32126023549586535\n",
      "Training Loss: 0.26399158280342816\n",
      "Validation Loss: 0.1900256635683976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.17001607619225978\n",
      "Training Loss: 0.11584463950712234\n",
      "Training Loss: 0.0975441172812134\n",
      "Validation Loss: 0.07460831003682164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06772601612843573\n",
      "Training Loss: 0.057717892117798326\n",
      "Training Loss: 0.059173643100075425\n",
      "Validation Loss: 0.05936191342457124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05499150823801756\n",
      "Training Loss: 0.05293051270768046\n",
      "Training Loss: 0.054101153234951196\n",
      "Validation Loss: 0.055139944103828976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.05072803440503776\n",
      "Training Loss: 0.048984873360022906\n",
      "Training Loss: 0.04982746527064592\n",
      "Validation Loss: 0.05052779260185662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04619789864867926\n",
      "Training Loss: 0.044241493064910174\n",
      "Training Loss: 0.044543762444518506\n",
      "Validation Loss: 0.04440952261145949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.040162437185645106\n",
      "Training Loss: 0.03762681316118687\n",
      "Training Loss: 0.03720547269564122\n",
      "Validation Loss: 0.0361393696911047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.032173555524786936\n",
      "Training Loss: 0.029530397336930036\n",
      "Training Loss: 0.028704621873330324\n",
      "Validation Loss: 0.02735360532873467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.023932270322593468\n",
      "Training Loss: 0.021649682878050955\n",
      "Training Loss: 0.02074668158311397\n",
      "Validation Loss: 0.019527631501792774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.01682570731645683\n",
      "Training Loss: 0.015012815878726542\n",
      "Training Loss: 0.014230351643636823\n",
      "Validation Loss: 0.013227938694010876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.011320724623510614\n",
      "Training Loss: 0.009888272259850055\n",
      "Training Loss: 0.009179080619942397\n",
      "Validation Loss: 0.008265134758117158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.006987415190087632\n",
      "Training Loss: 0.005619899486191571\n",
      "Training Loss: 0.004670665339217521\n",
      "Validation Loss: 0.0035752570465876817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.0026641460703103804\n",
      "Training Loss: 0.001492801689892076\n",
      "Training Loss: 0.001145921029310557\n",
      "Validation Loss: 0.0014958573872186872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0010012170506524852\n",
      "Training Loss: 0.0007681770601629978\n",
      "Training Loss: 0.0007722893903701334\n",
      "Validation Loss: 0.001270681474452022\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0008076247909048107\n",
      "Training Loss: 0.0006421612128178822\n",
      "Training Loss: 0.0006362508954043732\n",
      "Validation Loss: 0.001127474249525027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0006885943312227027\n",
      "Training Loss: 0.0005520640575559809\n",
      "Training Loss: 0.0005429948810342466\n",
      "Validation Loss: 0.0010167355405551308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00060396832486731\n",
      "Training Loss: 0.0004861785829416476\n",
      "Training Loss: 0.00047670176048995926\n",
      "Validation Loss: 0.0009128299169471289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0005397736557642929\n",
      "Training Loss: 0.00043565209525695534\n",
      "Training Loss: 0.0004270682956848759\n",
      "Validation Loss: 0.0008107800211782275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00048816974471264983\n",
      "Training Loss: 0.0003948765141831245\n",
      "Training Loss: 0.0003881833251580247\n",
      "Validation Loss: 0.0007150045470491554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00044585458890651354\n",
      "Training Loss: 0.000361243363659014\n",
      "Training Loss: 0.00035712995097128444\n",
      "Validation Loss: 0.0006297122020165834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0004112699280085508\n",
      "Training Loss: 0.000333476518826501\n",
      "Training Loss: 0.000332204706282937\n",
      "Validation Loss: 0.0005565208403015603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0003831802340937429\n",
      "Training Loss: 0.00031065089071489636\n",
      "Training Loss: 0.0003121252072378411\n",
      "Validation Loss: 0.0004952804515238987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0003604199376059114\n",
      "Training Loss: 0.0002919224087963812\n",
      "Training Loss: 0.0002958321681217058\n",
      "Validation Loss: 0.0004449522501581055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0003419238176866202\n",
      "Training Loss: 0.0002765107235973119\n",
      "Training Loss: 0.0002824523979870719\n",
      "Validation Loss: 0.000404104716559804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0003267736707130098\n",
      "Training Loss: 0.0002637286502067582\n",
      "Training Loss: 0.00027128729358082636\n",
      "Validation Loss: 0.00037119203535552147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00031420759558386635\n",
      "Training Loss: 0.0002529985721776029\n",
      "Training Loss: 0.0002617947540784371\n",
      "Validation Loss: 0.0003447116756801274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0003036138694733381\n",
      "Training Loss: 0.0002438571055608918\n",
      "Training Loss: 0.0002535642787552206\n",
      "Validation Loss: 0.0003233050695016164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00029451623719069177\n",
      "Training Loss: 0.00023594219390361105\n",
      "Training Loss: 0.00024629055191326187\n",
      "Validation Loss: 0.00030582048075915877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00028655059159063965\n",
      "Training Loss: 0.00022897863269463414\n",
      "Training Loss: 0.00023974953594006366\n",
      "Validation Loss: 0.000291331657689206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00027944667170231696\n",
      "Training Loss: 0.00022275904506386724\n",
      "Training Loss: 0.0002337784509290941\n",
      "Validation Loss: 0.0002791126165228367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00027300502741127273\n",
      "Training Loss: 0.0002171288938552607\n",
      "Training Loss: 0.00022825930900580716\n",
      "Validation Loss: 0.0002686106580246784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00026708037868957037\n",
      "Training Loss: 0.00021197282701905352\n",
      "Training Loss: 0.00022310598636977375\n",
      "Validation Loss: 0.000259416492329191\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00026156696443649705\n",
      "Training Loss: 0.00020720412911032327\n",
      "Training Loss: 0.000218255613654037\n",
      "Validation Loss: 0.00025122392085659466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.000256387437475496\n",
      "Training Loss: 0.00020275751710869373\n",
      "Training Loss: 0.00021366192864661571\n",
      "Validation Loss: 0.00024381004869211936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00025148636115773115\n",
      "Training Loss: 0.00019858308191032846\n",
      "Training Loss: 0.0002092902006188524\n",
      "Validation Loss: 0.00023701312933594585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00024682118022610665\n",
      "Training Loss: 0.00019464277875158587\n",
      "Training Loss: 0.00020511351354798535\n",
      "Validation Loss: 0.00023070964523234008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0002423606605589157\n",
      "Training Loss: 0.0001909062551567331\n",
      "Training Loss: 0.0002011118572045234\n",
      "Validation Loss: 0.00022481366969269616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0002380800152241136\n",
      "Training Loss: 0.0001873495381551038\n",
      "Training Loss: 0.00019726858321519102\n",
      "Validation Loss: 0.0002192594252806026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00023396130662149518\n",
      "Training Loss: 0.00018395343051452073\n",
      "Training Loss: 0.000193570711362554\n",
      "Validation Loss: 0.0002139995492317222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00022998973767244025\n",
      "Training Loss: 0.0001807025551715924\n",
      "Training Loss: 0.00019000774529558839\n",
      "Validation Loss: 0.00020899655957303396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00022615300567849773\n",
      "Training Loss: 0.00017758396090357563\n",
      "Training Loss: 0.00018657079963304568\n",
      "Validation Loss: 0.00020422496870676777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00022244186902753427\n",
      "Training Loss: 0.00017458721917137154\n",
      "Training Loss: 0.00018325239418118144\n",
      "Validation Loss: 0.0001996605781876885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00021884849418711384\n",
      "Training Loss: 0.00017170288303532287\n",
      "Training Loss: 0.00018004616709731635\n",
      "Validation Loss: 0.0001952894495291965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00021536507108976366\n",
      "Training Loss: 0.00016892413643290638\n",
      "Training Loss: 0.00017694676436804\n",
      "Validation Loss: 0.00019109980172962946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.0002119869178022782\n",
      "Training Loss: 0.00016624393016172689\n",
      "Training Loss: 0.00017394914641045034\n",
      "Validation Loss: 0.00018707766503212042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0002087086272877059\n",
      "Training Loss: 0.00016365670768209384\n",
      "Training Loss: 0.0001710491522862867\n",
      "Validation Loss: 0.00018321579691575935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0002055258457403397\n",
      "Training Loss: 0.00016115748549054841\n",
      "Training Loss: 0.0001682430070468399\n",
      "Validation Loss: 0.0001795056720020307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00020243458349796127\n",
      "Training Loss: 0.0001587421948715928\n",
      "Training Loss: 0.00016552734525248524\n",
      "Validation Loss: 0.00017594082041132118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00019943169885664247\n",
      "Training Loss: 0.0001564065079401189\n",
      "Training Loss: 0.00016289925177261465\n",
      "Validation Loss: 0.00017251584150277738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00019651392085506814\n",
      "Training Loss: 0.00015414747333124978\n",
      "Training Loss: 0.0001603557716225623\n",
      "Validation Loss: 0.00016922469324761938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00019367889295608621\n",
      "Training Loss: 0.00015196188151094247\n",
      "Training Loss: 0.00015789439317813957\n",
      "Validation Loss: 0.00016606243559763652\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.0001909235181119584\n",
      "Training Loss: 0.00014984678147811792\n",
      "Training Loss: 0.00015551293779935804\n",
      "Validation Loss: 0.00016302341799509417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00018824618266080506\n",
      "Training Loss: 0.00014779963939872686\n",
      "Training Loss: 0.00015320903767133132\n",
      "Validation Loss: 0.00016010398807277473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00018564478841653909\n",
      "Training Loss: 0.00014581822415493662\n",
      "Training Loss: 0.0001509805650493945\n",
      "Validation Loss: 0.000157299687957726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00018311665869987336\n",
      "Training Loss: 0.00014390003476364655\n",
      "Training Loss: 0.00014882546487569924\n",
      "Validation Loss: 0.00015460536733473746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00018066062026264262\n",
      "Training Loss: 0.00014204317299117974\n",
      "Training Loss: 0.00014674208156066016\n",
      "Validation Loss: 0.00015201842075696456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00017827499677878223\n",
      "Training Loss: 0.0001402458366646897\n",
      "Training Loss: 0.000144728424565983\n",
      "Validation Loss: 0.0001495335565389754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00017595778592294665\n",
      "Training Loss: 0.00013850576569893747\n",
      "Training Loss: 0.0001427827870247711\n",
      "Validation Loss: 0.00014714766149062484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00017370768406181015\n",
      "Training Loss: 0.00013682157312359778\n",
      "Training Loss: 0.00014090340211623699\n",
      "Validation Loss: 0.0001448575643162973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00017152312882899424\n",
      "Training Loss: 0.00013519143038138282\n",
      "Training Loss: 0.0001390886744593445\n",
      "Validation Loss: 0.000142658118584018\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00016940272120336886\n",
      "Training Loss: 0.00013361368168261832\n",
      "Training Loss: 0.00013733697054703952\n",
      "Validation Loss: 0.00014054762394745635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00016734510401875013\n",
      "Training Loss: 0.00013208682257754846\n",
      "Training Loss: 0.0001356464238051558\n",
      "Validation Loss: 0.00013852156146466758\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0001653489602904301\n",
      "Training Loss: 0.00013060925415629753\n",
      "Training Loss: 0.0001340156630067213\n",
      "Validation Loss: 0.00013657706929305359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00016341254815415595\n",
      "Training Loss: 0.00012917967189423506\n",
      "Training Loss: 0.00013244250953903247\n",
      "Validation Loss: 0.00013471107957413776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00016153447702890844\n",
      "Training Loss: 0.0001277965450208285\n",
      "Training Loss: 0.00013092571620290983\n",
      "Validation Loss: 0.0001329192774197979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00015971384329532156\n",
      "Training Loss: 0.00012645816192161875\n",
      "Training Loss: 0.0001294635372596531\n",
      "Validation Loss: 0.00013119990513444187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0001579487595881801\n",
      "Training Loss: 0.00012516354624494852\n",
      "Training Loss: 0.00012805441983800847\n",
      "Validation Loss: 0.00012954970811682707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00015623807252268307\n",
      "Training Loss: 0.00012391109937198052\n",
      "Training Loss: 0.00012669660490246314\n",
      "Validation Loss: 0.0001279656337348488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0001545803342014551\n",
      "Training Loss: 0.0001226994976059359\n",
      "Training Loss: 0.0001253884971174557\n",
      "Validation Loss: 0.00012644557406592152\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00015297445537726162\n",
      "Training Loss: 0.00012152752211477491\n",
      "Training Loss: 0.00012412836686962692\n",
      "Validation Loss: 0.00012498633130623573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00015141855516048963\n",
      "Training Loss: 0.00012039387302138493\n",
      "Training Loss: 0.00012291469534829957\n",
      "Validation Loss: 0.00012358516959353806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00014991141282735042\n",
      "Training Loss: 0.00011929735501325922\n",
      "Training Loss: 0.00012174573577794945\n",
      "Validation Loss: 0.0001222401562413682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00014845195122688892\n",
      "Training Loss: 0.00011823623015516204\n",
      "Training Loss: 0.00012062001146659896\n",
      "Validation Loss: 0.00012094844788315528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00014703810367791448\n",
      "Training Loss: 0.0001172099599170906\n",
      "Training Loss: 0.00011953569077377324\n",
      "Validation Loss: 0.00011970733802617145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00014566878902769531\n",
      "Training Loss: 0.0001162165932055359\n",
      "Training Loss: 0.00011849146028907853\n",
      "Validation Loss: 0.00011851623224920536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00014434266966418364\n",
      "Training Loss: 0.00011525566306772816\n",
      "Training Loss: 0.00011748539647669531\n",
      "Validation Loss: 0.0001173705878408215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0001430583468209079\n",
      "Training Loss: 0.00011432562991103623\n",
      "Training Loss: 0.00011651642603283108\n",
      "Validation Loss: 0.00011627012032334002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.00014181440303218551\n",
      "Training Loss: 0.00011342550436893361\n",
      "Training Loss: 0.00011558278852135118\n",
      "Validation Loss: 0.00011521214245670748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0001406095084257686\n",
      "Training Loss: 0.00011255387248638726\n",
      "Training Loss: 0.00011468301912827884\n",
      "Validation Loss: 0.0001141950821231271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.0001394423644615017\n",
      "Training Loss: 0.00011170995068823686\n",
      "Training Loss: 0.00011381561210328073\n",
      "Validation Loss: 0.00011321613515627157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0001383112961138977\n",
      "Training Loss: 0.00011089242808338895\n",
      "Training Loss: 0.0001129793008112756\n",
      "Validation Loss: 0.00011227466419451672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00013721528248424874\n",
      "Training Loss: 0.00011010043192982266\n",
      "Training Loss: 0.00011217277752621157\n",
      "Validation Loss: 0.00011136823072928145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00013615314380331257\n",
      "Training Loss: 0.00010933315243164544\n",
      "Training Loss: 0.00011139447001369262\n",
      "Validation Loss: 0.00011049542058827591\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.00013512353138139588\n",
      "Training Loss: 0.00010858916380129813\n",
      "Training Loss: 0.00011064337804782554\n",
      "Validation Loss: 0.00010965449385704039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00013412514627816563\n",
      "Training Loss: 0.00010786778597321245\n",
      "Training Loss: 0.00010991820416165865\n",
      "Validation Loss: 0.00010884417072324385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00013315681149833836\n",
      "Training Loss: 0.00010716814841543965\n",
      "Training Loss: 0.00010921779523414443\n",
      "Validation Loss: 0.00010806292711902315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.00013221754071309988\n",
      "Training Loss: 0.00010648931361174618\n",
      "Training Loss: 0.00010854095608920034\n",
      "Validation Loss: 0.00010730935013924956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0001313062556891964\n",
      "Training Loss: 0.0001058304404887167\n",
      "Training Loss: 0.00010788665033032884\n",
      "Validation Loss: 0.00010658168111752203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00013042159616816207\n",
      "Training Loss: 0.00010519053331336182\n",
      "Training Loss: 0.00010725384974193731\n",
      "Validation Loss: 0.00010587944526694913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00012956264876265778\n",
      "Training Loss: 0.00010456900844474148\n",
      "Training Loss: 0.00010664148694559117\n",
      "Validation Loss: 0.00010520072615956574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00012872848191364028\n",
      "Training Loss: 0.00010396514603598917\n",
      "Training Loss: 0.0001060486329424748\n",
      "Validation Loss: 0.00010454461420869868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.00012791809146619926\n",
      "Training Loss: 0.0001033779370936827\n",
      "Training Loss: 0.00010547433395458938\n",
      "Validation Loss: 0.00010391026953175754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00012713040207927407\n",
      "Training Loss: 0.00010280694543325808\n",
      "Training Loss: 0.0001049179693836777\n",
      "Validation Loss: 0.00010329654438730482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00012636476505576867\n",
      "Training Loss: 0.00010225133634776284\n",
      "Training Loss: 0.00010437846580316546\n",
      "Validation Loss: 0.00010270213554096618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00012562025879560678\n",
      "Training Loss: 0.00010171048013944528\n",
      "Training Loss: 0.00010385505357589864\n",
      "Validation Loss: 0.00010212630407428212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00012489596353589148\n",
      "Training Loss: 0.00010118381993379444\n",
      "Training Loss: 0.00010334716841498448\n",
      "Validation Loss: 0.00010156764576830927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00012419106561537775\n",
      "Training Loss: 0.00010067073890240863\n",
      "Training Loss: 0.00010285394092989009\n",
      "Validation Loss: 0.00010102624122062868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.00012350488130323357\n",
      "Training Loss: 0.00010017064766543627\n",
      "Training Loss: 0.00010237466052785749\n",
      "Validation Loss: 0.0001005008054071981\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00012283662094887405\n",
      "Training Loss: 9.968299305910477e-05\n",
      "Training Loss: 0.00010190896293806872\n",
      "Validation Loss: 9.999071565115617e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.00012218567494528542\n",
      "Training Loss: 9.920730967678537e-05\n",
      "Training Loss: 0.00010145586568796716\n",
      "Validation Loss: 9.949495851992907e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00012155113880908174\n",
      "Training Loss: 9.874309749648091e-05\n",
      "Training Loss: 0.00010101491505338345\n",
      "Validation Loss: 9.901324460003983e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00012093259134871914\n",
      "Training Loss: 9.82897040194075e-05\n",
      "Training Loss: 0.00010058582066449162\n",
      "Validation Loss: 9.854448012702868e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00012032934696435405\n",
      "Training Loss: 9.784697938812314e-05\n",
      "Training Loss: 0.00010016789880410215\n",
      "Validation Loss: 9.808842839723521e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00011974086112331861\n",
      "Training Loss: 9.741430852045597e-05\n",
      "Training Loss: 9.976040676065167e-05\n",
      "Validation Loss: 9.764439167493753e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.00011916663792817417\n",
      "Training Loss: 9.699112301859713e-05\n",
      "Training Loss: 9.936339037722064e-05\n",
      "Validation Loss: 9.721160024148477e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.00011860594479003339\n",
      "Training Loss: 9.657760623667855e-05\n",
      "Training Loss: 9.897592839934077e-05\n",
      "Validation Loss: 9.678972245832014e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00011805846747847681\n",
      "Training Loss: 9.617270029593783e-05\n",
      "Training Loss: 9.859786482138588e-05\n",
      "Validation Loss: 9.63784102546679e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00011752362802781136\n",
      "Training Loss: 9.577652661391767e-05\n",
      "Training Loss: 9.822880138017353e-05\n",
      "Validation Loss: 9.597682162237699e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.00011700102374106791\n",
      "Training Loss: 9.538836510728288e-05\n",
      "Training Loss: 9.786834878013905e-05\n",
      "Validation Loss: 9.558507000302813e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.00011649006434709008\n",
      "Training Loss: 9.500817849584564e-05\n",
      "Training Loss: 9.7515883799133e-05\n",
      "Validation Loss: 9.520230809500666e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.00011599040465171129\n",
      "Training Loss: 9.463560001677252e-05\n",
      "Training Loss: 9.71715653577121e-05\n",
      "Validation Loss: 9.482811801104474e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.00011550164059372037\n",
      "Training Loss: 9.427027725905646e-05\n",
      "Training Loss: 9.683456627044506e-05\n",
      "Validation Loss: 9.446226000220755e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00011502329986797122\n",
      "Training Loss: 9.391192269504244e-05\n",
      "Training Loss: 9.650502192016574e-05\n",
      "Validation Loss: 9.410458798729554e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00011455524312623311\n",
      "Training Loss: 9.35603997004364e-05\n",
      "Training Loss: 9.6182309289361e-05\n",
      "Validation Loss: 9.375453078319787e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.00011409686753268034\n",
      "Training Loss: 9.321518829892739e-05\n",
      "Training Loss: 9.586634644620062e-05\n",
      "Validation Loss: 9.341191791586272e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.00011364791452251665\n",
      "Training Loss: 9.287639020840289e-05\n",
      "Training Loss: 9.555677002936136e-05\n",
      "Validation Loss: 9.307648411940841e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.00011320804111164762\n",
      "Training Loss: 9.254362866158772e-05\n",
      "Training Loss: 9.525349433715746e-05\n",
      "Validation Loss: 9.274768135685336e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.0001127769727827399\n",
      "Training Loss: 9.221656673616963e-05\n",
      "Training Loss: 9.495611809143156e-05\n",
      "Validation Loss: 9.24254686600598e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.00011235443641453457\n",
      "Training Loss: 9.189510676151258e-05\n",
      "Training Loss: 9.466447341765161e-05\n",
      "Validation Loss: 9.210960479833191e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.00011194014083685034\n",
      "Training Loss: 9.157899286037719e-05\n",
      "Training Loss: 9.437853623239789e-05\n",
      "Validation Loss: 9.180005830724062e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.00011153372857734211\n",
      "Training Loss: 9.126812272370444e-05\n",
      "Training Loss: 9.409765628333844e-05\n",
      "Validation Loss: 9.149567756211265e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0001111349221855562\n",
      "Training Loss: 9.096223015149007e-05\n",
      "Training Loss: 9.382191224176495e-05\n",
      "Validation Loss: 9.119719203901307e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.00011074358284531627\n",
      "Training Loss: 9.066123064258136e-05\n",
      "Training Loss: 9.355119543215551e-05\n",
      "Validation Loss: 9.090417047394858e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.0001103594786445683\n",
      "Training Loss: 9.036487635057711e-05\n",
      "Training Loss: 9.32852009555063e-05\n",
      "Validation Loss: 9.061610616596083e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.00010998238324646082\n",
      "Training Loss: 9.007309797198104e-05\n",
      "Training Loss: 9.30240134766791e-05\n",
      "Validation Loss: 9.033356132584211e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.00010961194518131378\n",
      "Training Loss: 8.978559529168706e-05\n",
      "Training Loss: 9.276718927594629e-05\n",
      "Validation Loss: 9.005554916206001e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00010924800571046945\n",
      "Training Loss: 8.950252865361108e-05\n",
      "Training Loss: 9.251465803117754e-05\n",
      "Validation Loss: 8.978231400168e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.00010889044998748432\n",
      "Training Loss: 8.92233728973224e-05\n",
      "Training Loss: 9.226623159975134e-05\n",
      "Validation Loss: 8.951342156609152e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.00010853902725102671\n",
      "Training Loss: 8.894818499356916e-05\n",
      "Training Loss: 9.202183320667246e-05\n",
      "Validation Loss: 8.9249429937594e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.00010819344433002698\n",
      "Training Loss: 8.867682883646921e-05\n",
      "Training Loss: 9.178146462090808e-05\n",
      "Validation Loss: 8.898923400859153e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.00010785373858652747\n",
      "Training Loss: 8.840919794238289e-05\n",
      "Training Loss: 9.154466173185937e-05\n",
      "Validation Loss: 8.873318805281803e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.00010751963257916941\n",
      "Training Loss: 8.814516520942561e-05\n",
      "Training Loss: 9.131161540153699e-05\n",
      "Validation Loss: 8.8481142565695e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.00010719089118083503\n",
      "Training Loss: 8.788472195192298e-05\n",
      "Training Loss: 9.108218077471974e-05\n",
      "Validation Loss: 8.823308474276335e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00010686740993151033\n",
      "Training Loss: 8.762760107856593e-05\n",
      "Training Loss: 9.085607025554055e-05\n",
      "Validation Loss: 8.79887945782766e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.00010654922402864031\n",
      "Training Loss: 8.737377165743965e-05\n",
      "Training Loss: 9.063332266578073e-05\n",
      "Validation Loss: 8.774799206027606e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.00010623582664720743\n",
      "Training Loss: 8.71231236942549e-05\n",
      "Training Loss: 9.041378440088011e-05\n",
      "Validation Loss: 8.7510938418122e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.00010592725467176933\n",
      "Training Loss: 8.687564809406467e-05\n",
      "Training Loss: 9.01974248154147e-05\n",
      "Validation Loss: 8.72770796469125e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0001056235593796373\n",
      "Training Loss: 8.663123467158584e-05\n",
      "Training Loss: 8.998403062832949e-05\n",
      "Validation Loss: 8.704643510151236e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.00010532430231251055\n",
      "Training Loss: 8.638964994133857e-05\n",
      "Training Loss: 8.977369194781205e-05\n",
      "Validation Loss: 8.681921379197927e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.00010502953476589028\n",
      "Training Loss: 8.615093450316636e-05\n",
      "Training Loss: 8.956612251495244e-05\n",
      "Validation Loss: 8.659511042444566e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00010473906010247447\n",
      "Training Loss: 8.5914987967044e-05\n",
      "Training Loss: 8.936143562095822e-05\n",
      "Validation Loss: 8.637418633359915e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.0001044529402633998\n",
      "Training Loss: 8.5681792224932e-05\n",
      "Training Loss: 8.915949037145765e-05\n",
      "Validation Loss: 8.615611940502971e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00010417078358386789\n",
      "Training Loss: 8.545130437596526e-05\n",
      "Training Loss: 8.896016288417741e-05\n",
      "Validation Loss: 8.594094208419438e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0001038926417913899\n",
      "Training Loss: 8.522329961124342e-05\n",
      "Training Loss: 8.876333649368462e-05\n",
      "Validation Loss: 8.572868460923724e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00010361852670939697\n",
      "Training Loss: 8.499784006744448e-05\n",
      "Training Loss: 8.856904395543097e-05\n",
      "Validation Loss: 8.551921417349374e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.00010334808916923066\n",
      "Training Loss: 8.477479565044632e-05\n",
      "Training Loss: 8.837724399199943e-05\n",
      "Validation Loss: 8.531251103377553e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.00010308140962933976\n",
      "Training Loss: 8.455425454485521e-05\n",
      "Training Loss: 8.818780124784099e-05\n",
      "Validation Loss: 8.510800907561645e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.00010281831980137213\n",
      "Training Loss: 8.433594981397618e-05\n",
      "Training Loss: 8.800071308087354e-05\n",
      "Validation Loss: 8.490624793594588e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.00010255883280478884\n",
      "Training Loss: 8.411995560891227e-05\n",
      "Training Loss: 8.781598173754901e-05\n",
      "Validation Loss: 8.47069463867392e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.00010230264874280692\n",
      "Training Loss: 8.390622272600012e-05\n",
      "Training Loss: 8.763325393829291e-05\n",
      "Validation Loss: 8.451043859065648e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.00010204996817265056\n",
      "Training Loss: 8.369469658646267e-05\n",
      "Training Loss: 8.745295282551524e-05\n",
      "Validation Loss: 8.431596939118116e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.00010180054576267139\n",
      "Training Loss: 8.348531616320543e-05\n",
      "Training Loss: 8.727454356176167e-05\n",
      "Validation Loss: 8.412373844794786e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.00010155427141398831\n",
      "Training Loss: 8.327803911015508e-05\n",
      "Training Loss: 8.709827199709252e-05\n",
      "Validation Loss: 8.393409744927299e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.00010131116715001554\n",
      "Training Loss: 8.307278050779133e-05\n",
      "Training Loss: 8.692393564160738e-05\n",
      "Validation Loss: 8.374626480197937e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.00010107124194291828\n",
      "Training Loss: 8.28694264691876e-05\n",
      "Training Loss: 8.675167269757367e-05\n",
      "Validation Loss: 8.3560881025375e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00010083424613185343\n",
      "Training Loss: 8.26681493435899e-05\n",
      "Training Loss: 8.658137827296741e-05\n",
      "Validation Loss: 8.337741407527839e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.00010060011990844941\n",
      "Training Loss: 8.24688409193186e-05\n",
      "Training Loss: 8.641280309348077e-05\n",
      "Validation Loss: 8.31965351689985e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.00010036905814104103\n",
      "Training Loss: 8.227134112530621e-05\n",
      "Training Loss: 8.624630105714459e-05\n",
      "Validation Loss: 8.301717668238391e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.000100140667686901\n",
      "Training Loss: 8.207578483052203e-05\n",
      "Training Loss: 8.60814526095055e-05\n",
      "Validation Loss: 8.283975117858186e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 9.991519601044275e-05\n",
      "Training Loss: 8.188188664462359e-05\n",
      "Training Loss: 8.59185011131558e-05\n",
      "Validation Loss: 8.266441626587079e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 9.96923164166219e-05\n",
      "Training Loss: 8.168993171238981e-05\n",
      "Training Loss: 8.575721140459791e-05\n",
      "Validation Loss: 8.24908503510118e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 9.947221373295179e-05\n",
      "Training Loss: 8.149967172357719e-05\n",
      "Training Loss: 8.559747599065303e-05\n",
      "Validation Loss: 8.231913010747397e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 9.925468354140322e-05\n",
      "Training Loss: 8.131119838253653e-05\n",
      "Training Loss: 8.543956907487882e-05\n",
      "Validation Loss: 8.214936520601165e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 9.903982458581595e-05\n",
      "Training Loss: 8.112427019113966e-05\n",
      "Training Loss: 8.52834229635846e-05\n",
      "Validation Loss: 8.198139503394814e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 9.88273843040588e-05\n",
      "Training Loss: 8.093906802059792e-05\n",
      "Training Loss: 8.51286666102169e-05\n",
      "Validation Loss: 8.181519692544918e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 9.86173708406568e-05\n",
      "Training Loss: 8.075546129475697e-05\n",
      "Training Loss: 8.49755163608279e-05\n",
      "Validation Loss: 8.165071265241576e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 9.84099004563177e-05\n",
      "Training Loss: 8.05734942878189e-05\n",
      "Training Loss: 8.48240336017625e-05\n",
      "Validation Loss: 8.148780459501477e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 9.820465852044435e-05\n",
      "Training Loss: 8.03932068447466e-05\n",
      "Training Loss: 8.467391360227339e-05\n",
      "Validation Loss: 8.132645264217235e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 9.8001821629623e-05\n",
      "Training Loss: 8.021442004064738e-05\n",
      "Training Loss: 8.4525348806892e-05\n",
      "Validation Loss: 8.116688375880228e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 9.780124873941532e-05\n",
      "Training Loss: 8.003709965123562e-05\n",
      "Training Loss: 8.437840902388416e-05\n",
      "Validation Loss: 8.100884187616032e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 9.760294889929355e-05\n",
      "Training Loss: 7.986134523889632e-05\n",
      "Training Loss: 8.423271585343172e-05\n",
      "Validation Loss: 8.085272549599242e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 9.740669790062384e-05\n",
      "Training Loss: 7.968704566337693e-05\n",
      "Training Loss: 8.408862951000628e-05\n",
      "Validation Loss: 8.069802631295071e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 9.721235731831257e-05\n",
      "Training Loss: 7.951438645250164e-05\n",
      "Training Loss: 8.394575685997551e-05\n",
      "Validation Loss: 8.054481557419319e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 9.70197500737413e-05\n",
      "Training Loss: 7.934296540042852e-05\n",
      "Training Loss: 8.380435649996799e-05\n",
      "Validation Loss: 8.039370457256891e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 9.682862631962053e-05\n",
      "Training Loss: 7.917316403108998e-05\n",
      "Training Loss: 8.366435470179568e-05\n",
      "Validation Loss: 8.024404365294665e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 9.663929846738028e-05\n",
      "Training Loss: 7.900480781245279e-05\n",
      "Training Loss: 8.352577835466945e-05\n",
      "Validation Loss: 8.009618904089733e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 9.645196259043587e-05\n",
      "Training Loss: 7.883772554123425e-05\n",
      "Training Loss: 8.338847213053669e-05\n",
      "Validation Loss: 7.994994653375451e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 9.626624867905775e-05\n",
      "Training Loss: 7.867210388212698e-05\n",
      "Training Loss: 8.325236546625093e-05\n",
      "Validation Loss: 7.980533251264185e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 9.608243170987407e-05\n",
      "Training Loss: 7.850784969377855e-05\n",
      "Training Loss: 8.311767013765348e-05\n",
      "Validation Loss: 7.96621012709233e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 9.590040649982257e-05\n",
      "Training Loss: 7.834488604203216e-05\n",
      "Training Loss: 8.298415789340652e-05\n",
      "Validation Loss: 7.952038555394916e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 9.572007063070487e-05\n",
      "Training Loss: 7.818323829269502e-05\n",
      "Training Loss: 8.285188324862247e-05\n",
      "Validation Loss: 7.937953691243513e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 9.554137519899087e-05\n",
      "Training Loss: 7.80228683106543e-05\n",
      "Training Loss: 8.272070566818001e-05\n",
      "Validation Loss: 7.924031672629415e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 9.536438500617805e-05\n",
      "Training Loss: 7.786375187606608e-05\n",
      "Training Loss: 8.259086876932997e-05\n",
      "Validation Loss: 7.910244825366084e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 9.518897450561781e-05\n",
      "Training Loss: 7.770599098876119e-05\n",
      "Training Loss: 8.246206267358503e-05\n",
      "Validation Loss: 7.896568157765399e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 9.501532058948215e-05\n",
      "Training Loss: 7.754935677439789e-05\n",
      "Training Loss: 8.233442930759338e-05\n",
      "Validation Loss: 7.883026388667071e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 9.484313579832815e-05\n",
      "Training Loss: 7.739396555734856e-05\n",
      "Training Loss: 8.220800830713415e-05\n",
      "Validation Loss: 7.869619739824302e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 9.467250703892204e-05\n",
      "Training Loss: 7.723983607320406e-05\n",
      "Training Loss: 8.208266846395418e-05\n",
      "Validation Loss: 7.85629606551165e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 9.450344690321799e-05\n",
      "Training Loss: 7.708687898229983e-05\n",
      "Training Loss: 8.195821926619829e-05\n",
      "Validation Loss: 7.843094171517662e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 9.433592083496478e-05\n",
      "Training Loss: 7.69350785685674e-05\n",
      "Training Loss: 8.183516210465314e-05\n",
      "Validation Loss: 7.830022757312445e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 9.416985146344814e-05\n",
      "Training Loss: 7.678438139009813e-05\n",
      "Training Loss: 8.17130473205907e-05\n",
      "Validation Loss: 7.817086888474918e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 9.40052949499659e-05\n",
      "Training Loss: 7.663489123842738e-05\n",
      "Training Loss: 8.159193002029497e-05\n",
      "Validation Loss: 7.804235721185536e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 9.384210437929141e-05\n",
      "Training Loss: 7.648660304766963e-05\n",
      "Training Loss: 8.147194293087523e-05\n",
      "Validation Loss: 7.791510992053977e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 9.368033680857479e-05\n",
      "Training Loss: 7.633935180820117e-05\n",
      "Training Loss: 8.135293368468411e-05\n",
      "Validation Loss: 7.778889795098509e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 9.352002577998065e-05\n",
      "Training Loss: 7.619325235282304e-05\n",
      "Training Loss: 8.123495720610663e-05\n",
      "Validation Loss: 7.766364101218152e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 9.336105199054146e-05\n",
      "Training Loss: 7.604820912092692e-05\n",
      "Training Loss: 8.111792581985355e-05\n",
      "Validation Loss: 7.753952414031517e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 9.320340642261726e-05\n",
      "Training Loss: 7.590422891553317e-05\n",
      "Training Loss: 8.10019429991371e-05\n",
      "Validation Loss: 7.741654961423235e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 9.304715709276934e-05\n",
      "Training Loss: 7.576140666969877e-05\n",
      "Training Loss: 8.088687937743088e-05\n",
      "Validation Loss: 7.729442615037146e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 9.28921749255096e-05\n",
      "Training Loss: 7.561960291241121e-05\n",
      "Training Loss: 8.077271647380257e-05\n",
      "Validation Loss: 7.717338964508864e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 9.273849315377447e-05\n",
      "Training Loss: 7.547881842583593e-05\n",
      "Training Loss: 8.065967701440968e-05\n",
      "Validation Loss: 7.705330215154145e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 9.258609105472715e-05\n",
      "Training Loss: 7.533909776611835e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [10:25<15:39, 156.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 8.054732286836952e-05\n",
      "Validation Loss: 7.693430574506514e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.12427674357779324\n",
      "Training Loss: 0.09642664343584328\n",
      "Training Loss: 0.08916038043331355\n",
      "Validation Loss: 0.0755569320015107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06887117587029934\n",
      "Training Loss: 0.0581352368183434\n",
      "Training Loss: 0.058481905655935404\n",
      "Validation Loss: 0.05597758921532986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05137700781458989\n",
      "Training Loss: 0.0481675311550498\n",
      "Training Loss: 0.04845761620439589\n",
      "Validation Loss: 0.046827790102387745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04203544195595896\n",
      "Training Loss: 0.039075170760042965\n",
      "Training Loss: 0.038370178020559254\n",
      "Validation Loss: 0.03678300381334645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.032203330047923376\n",
      "Training Loss: 0.029308903189375998\n",
      "Training Loss: 0.02839430422289297\n",
      "Validation Loss: 0.027253652999983325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02327305650629569\n",
      "Training Loss: 0.020642088900785893\n",
      "Training Loss: 0.01982081598136574\n",
      "Validation Loss: 0.019254878766342912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.016079400758026167\n",
      "Training Loss: 0.013800860193441622\n",
      "Training Loss: 0.01309555227169767\n",
      "Validation Loss: 0.012875657081290076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.010439093428431079\n",
      "Training Loss: 0.008329096830566414\n",
      "Training Loss: 0.007496049699839204\n",
      "Validation Loss: 0.007390278784605266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.005210873826581519\n",
      "Training Loss: 0.003277605370094534\n",
      "Training Loss: 0.0028361106748343444\n",
      "Validation Loss: 0.003970788890532521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.0022758097313635515\n",
      "Training Loss: 0.0014711279702896718\n",
      "Training Loss: 0.0014993211203545797\n",
      "Validation Loss: 0.002790476932266225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0015639583566371584\n",
      "Training Loss: 0.0010497484418738167\n",
      "Training Loss: 0.0010661259428889026\n",
      "Validation Loss: 0.0020509840874132186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0011651337697549025\n",
      "Training Loss: 0.000793959448201349\n",
      "Training Loss: 0.0008094927381898742\n",
      "Validation Loss: 0.0015177563299801661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.0008860421108693117\n",
      "Training Loss: 0.0006227361057972303\n",
      "Training Loss: 0.0006376069401449058\n",
      "Validation Loss: 0.001120432918162734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0006879253865918145\n",
      "Training Loss: 0.0005068510893033817\n",
      "Training Loss: 0.0005176922884857049\n",
      "Validation Loss: 0.0008255723019175001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0005489641984604532\n",
      "Training Loss: 0.0004269344246131368\n",
      "Training Loss: 0.00043248557260085364\n",
      "Validation Loss: 0.0006160790563738915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0004533153965894599\n",
      "Training Loss: 0.0003700159947766224\n",
      "Training Loss: 0.00037087366919877243\n",
      "Validation Loss: 0.00047486942304622674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00038730109630705554\n",
      "Training Loss: 0.0003275873672464513\n",
      "Training Loss: 0.0003251888711747597\n",
      "Validation Loss: 0.0003828556501922025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0003404439920268487\n",
      "Training Loss: 0.0002946578475894057\n",
      "Training Loss: 0.00029050405730231434\n",
      "Validation Loss: 0.00032318894632175053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00030604796775151043\n",
      "Training Loss: 0.00026853119223233077\n",
      "Training Loss: 0.0002638236895290902\n",
      "Validation Loss: 0.00028357805373222997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.0002801954529422801\n",
      "Training Loss: 0.00024763650126260475\n",
      "Training Loss: 0.00024318353891430888\n",
      "Validation Loss: 0.00025603053070247705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0002604360503755743\n",
      "Training Loss: 0.0002308261953294277\n",
      "Training Loss: 0.0002270763557680766\n",
      "Validation Loss: 0.00023572609110017898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0002450359610884334\n",
      "Training Loss: 0.0002171576016553445\n",
      "Training Loss: 0.00021428649703011615\n",
      "Validation Loss: 0.00021990711177474284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.00023273539221918327\n",
      "Training Loss: 0.00020588034354659612\n",
      "Training Loss: 0.00020389317411172669\n",
      "Validation Loss: 0.00020704682899807094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00022265597075602273\n",
      "Training Loss: 0.00019642811381345382\n",
      "Training Loss: 0.00019524601633747808\n",
      "Validation Loss: 0.0001962901604181323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00021420260716695339\n",
      "Training Loss: 0.00018838710951968096\n",
      "Training Loss: 0.00018790243171679322\n",
      "Validation Loss: 0.00018713323820367315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00020697621559520485\n",
      "Training Loss: 0.00018145708072552224\n",
      "Training Loss: 0.00018156110012569116\n",
      "Validation Loss: 0.00017925105364636774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0002007027098443359\n",
      "Training Loss: 0.0001754172396249487\n",
      "Training Loss: 0.0001760124870816071\n",
      "Validation Loss: 0.00017241497224542113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00019518860359312384\n",
      "Training Loss: 0.000170101546409569\n",
      "Training Loss: 0.00017110591588789247\n",
      "Validation Loss: 0.00016645016800661262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00019029235485504615\n",
      "Training Loss: 0.00016538341982595738\n",
      "Training Loss: 0.00016672838171871262\n",
      "Validation Loss: 0.00016121653212660143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00018590708346891916\n",
      "Training Loss: 0.0001611635992958327\n",
      "Training Loss: 0.00016279392370051936\n",
      "Validation Loss: 0.00015659874061588853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00018194934569692122\n",
      "Training Loss: 0.0001573628844198538\n",
      "Training Loss: 0.00015923352088066168\n",
      "Validation Loss: 0.00015249994794430677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00017835326189015178\n",
      "Training Loss: 0.00015391794820970972\n",
      "Training Loss: 0.00015599202544763102\n",
      "Validation Loss: 0.0001488393877531216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00017506524462078234\n",
      "Training Loss: 0.00015077722277055726\n",
      "Training Loss: 0.0001530240995089116\n",
      "Validation Loss: 0.00014554867076195692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.0001720410489178903\n",
      "Training Loss: 0.0001478977954138827\n",
      "Training Loss: 0.000150292398120655\n",
      "Validation Loss: 0.0001425712695042799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00016924522849876667\n",
      "Training Loss: 0.00014524429045195575\n",
      "Training Loss: 0.000147765848578274\n",
      "Validation Loss: 0.00013985973574368943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00016664712813508232\n",
      "Training Loss: 0.00014278789813033655\n",
      "Training Loss: 0.00014541819924488664\n",
      "Validation Loss: 0.00013737497604605767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0001642218683991814\n",
      "Training Loss: 0.0001405036108008062\n",
      "Training Loss: 0.00014322721532153082\n",
      "Validation Loss: 0.00013508380255117434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00016194811163586565\n",
      "Training Loss: 0.00013837071060152084\n",
      "Training Loss: 0.00014117444197836448\n",
      "Validation Loss: 0.00013295941731444197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00015980808970198268\n",
      "Training Loss: 0.0001363715093884821\n",
      "Training Loss: 0.00013924362123361787\n",
      "Validation Loss: 0.00013097877935037145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00015778648416016949\n",
      "Training Loss: 0.00013449103162201936\n",
      "Training Loss: 0.00013742124845521176\n",
      "Validation Loss: 0.00012912344907286505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0001558703472437628\n",
      "Training Loss: 0.0001327161223434814\n",
      "Training Loss: 0.000135695668614062\n",
      "Validation Loss: 0.00012737776857004186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00015404877447508625\n",
      "Training Loss: 0.00013103604768730293\n",
      "Training Loss: 0.0001340567179431673\n",
      "Validation Loss: 0.00012572871836393173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00015231210323690903\n",
      "Training Loss: 0.0001294409675301722\n",
      "Training Loss: 0.0001324959154590033\n",
      "Validation Loss: 0.00012416514628159675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00015065231405969826\n",
      "Training Loss: 0.0001279227734721644\n",
      "Training Loss: 0.00013100561904138885\n",
      "Validation Loss: 0.00012267780668603182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00014906215687005898\n",
      "Training Loss: 0.00012647393374209059\n",
      "Training Loss: 0.000129579441036185\n",
      "Validation Loss: 0.0001212593652893334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0001475355895672692\n",
      "Training Loss: 0.00012508828254794934\n",
      "Training Loss: 0.0001282113955130626\n",
      "Validation Loss: 0.00011990268313035884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00014606725040721357\n",
      "Training Loss: 0.00012376019960356644\n",
      "Training Loss: 0.0001268969994816871\n",
      "Validation Loss: 0.0001186024436914052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00014465249498243793\n",
      "Training Loss: 0.00012248488986188022\n",
      "Training Loss: 0.00012563126141685644\n",
      "Validation Loss: 0.00011735368892852953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0001432872313489497\n",
      "Training Loss: 0.00012125799029490736\n",
      "Training Loss: 0.00012441100039723097\n",
      "Validation Loss: 0.00011615205825405559\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00014196790045389206\n",
      "Training Loss: 0.00012007546340100816\n",
      "Training Loss: 0.00012323242546699475\n",
      "Validation Loss: 0.00011499436652556643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00014069095646846108\n",
      "Training Loss: 0.00011893431386852172\n",
      "Training Loss: 0.00012209279064336441\n",
      "Validation Loss: 0.00011387700102572575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.0001394537958003639\n",
      "Training Loss: 0.00011783116671722382\n",
      "Training Loss: 0.00012098893448637682\n",
      "Validation Loss: 0.00011279696076946513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00013825383763105492\n",
      "Training Loss: 0.00011676346231070057\n",
      "Training Loss: 0.00011991888753982493\n",
      "Validation Loss: 0.00011175211996109528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00013708875943848397\n",
      "Training Loss: 0.00011572859705665905\n",
      "Training Loss: 0.00011888032615388511\n",
      "Validation Loss: 0.00011074017920384832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00013595639969935292\n",
      "Training Loss: 0.00011472455128568981\n",
      "Training Loss: 0.00011787136843850022\n",
      "Validation Loss: 0.00010975891288243668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0001348548875284905\n",
      "Training Loss: 0.00011374940384484945\n",
      "Training Loss: 0.00011689021863276139\n",
      "Validation Loss: 0.00010880665258503469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00013378272133195422\n",
      "Training Loss: 0.00011280098477072897\n",
      "Training Loss: 0.00011593526076467242\n",
      "Validation Loss: 0.00010788189211688292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00013273805827338948\n",
      "Training Loss: 0.00011187798540959192\n",
      "Training Loss: 0.0001150050990327145\n",
      "Validation Loss: 0.0001069823891034656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00013171976259400254\n",
      "Training Loss: 0.00011097872700702283\n",
      "Training Loss: 0.00011409843365981942\n",
      "Validation Loss: 0.00010610744098567318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00013072616669887794\n",
      "Training Loss: 0.00011010197998075455\n",
      "Training Loss: 0.00011321396596031263\n",
      "Validation Loss: 0.00010525530645925632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0001297563031585014\n",
      "Training Loss: 0.00010924661347416986\n",
      "Training Loss: 0.00011235061931074596\n",
      "Validation Loss: 0.00010442508519599357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00012880904683697735\n",
      "Training Loss: 0.00010841130694643652\n",
      "Training Loss: 0.00011150725080369739\n",
      "Validation Loss: 0.00010361542840502317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00012788312564225633\n",
      "Training Loss: 0.00010759470571429119\n",
      "Training Loss: 0.00011068299680118799\n",
      "Validation Loss: 0.00010282523462694699\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00012697770092927384\n",
      "Training Loss: 0.00010679643998628307\n",
      "Training Loss: 0.00010987699846737087\n",
      "Validation Loss: 0.00010205376877544613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00012609188572241693\n",
      "Training Loss: 0.00010601502649478788\n",
      "Training Loss: 0.00010908836282396805\n",
      "Validation Loss: 0.00010129965999674803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00012522487000751425\n",
      "Training Loss: 0.00010525006439820572\n",
      "Training Loss: 0.00010831603349288343\n",
      "Validation Loss: 0.00010056246095230695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0001243756765870785\n",
      "Training Loss: 0.00010450050344843476\n",
      "Training Loss: 0.00010755985384093947\n",
      "Validation Loss: 9.984123630346495e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00012354345835774438\n",
      "Training Loss: 0.00010376568956417031\n",
      "Training Loss: 0.00010681864156140363\n",
      "Validation Loss: 9.913473234754226e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00012272774691155064\n",
      "Training Loss: 0.00010304483327672643\n",
      "Training Loss: 0.0001060919152587303\n",
      "Validation Loss: 9.844270911078515e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00012192762717859295\n",
      "Training Loss: 0.00010233751760097221\n",
      "Training Loss: 0.00010537903202930466\n",
      "Validation Loss: 9.776430771340488e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0001211427436919621\n",
      "Training Loss: 0.00010164291417822823\n",
      "Training Loss: 0.000104679469804978\n",
      "Validation Loss: 9.70988628651366e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00012037207830871922\n",
      "Training Loss: 0.00010096033304762386\n",
      "Training Loss: 0.00010399247714303782\n",
      "Validation Loss: 9.644554857106741e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00011961521726334467\n",
      "Training Loss: 0.0001002894908287999\n",
      "Training Loss: 0.00010331754263461335\n",
      "Validation Loss: 9.580428906722292e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00011887138985912315\n",
      "Training Loss: 9.962949976397794e-05\n",
      "Training Loss: 0.00010265445002005435\n",
      "Validation Loss: 9.517379934999901e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00011814028959634016\n",
      "Training Loss: 9.898028237330436e-05\n",
      "Training Loss: 0.00010200239919868182\n",
      "Validation Loss: 9.455395199816604e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00011742135273379973\n",
      "Training Loss: 9.834090305048449e-05\n",
      "Training Loss: 0.00010136095484995166\n",
      "Validation Loss: 9.394407191117925e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.00011671385504996579\n",
      "Training Loss: 9.771123699465533e-05\n",
      "Training Loss: 0.0001007297440264665\n",
      "Validation Loss: 9.334387325222624e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.000116017367627137\n",
      "Training Loss: 9.709079323329206e-05\n",
      "Training Loss: 0.00010010825888457476\n",
      "Validation Loss: 9.275249973715484e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00011533142755979498\n",
      "Training Loss: 9.647876679991896e-05\n",
      "Training Loss: 9.949605249857996e-05\n",
      "Validation Loss: 9.216977978825669e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00011465564324680599\n",
      "Training Loss: 9.587500786437885e-05\n",
      "Training Loss: 9.889264195408032e-05\n",
      "Validation Loss: 9.159528032254906e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0001139892322862579\n",
      "Training Loss: 9.527900039756786e-05\n",
      "Training Loss: 9.829766961956921e-05\n",
      "Validation Loss: 9.102837971573188e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00011333202250170871\n",
      "Training Loss: 9.469035871006781e-05\n",
      "Training Loss: 9.771076589458972e-05\n",
      "Validation Loss: 9.04686407256725e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00011268334922533541\n",
      "Training Loss: 9.41087738101487e-05\n",
      "Training Loss: 9.713155168356025e-05\n",
      "Validation Loss: 8.991583451737252e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.00011204289308807347\n",
      "Training Loss: 9.353358766020392e-05\n",
      "Training Loss: 9.655955591370002e-05\n",
      "Validation Loss: 8.93699880793208e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00011141016092551581\n",
      "Training Loss: 9.296452099988528e-05\n",
      "Training Loss: 9.599440400052118e-05\n",
      "Validation Loss: 8.882990674424088e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.0001107848048741289\n",
      "Training Loss: 9.240116231012507e-05\n",
      "Training Loss: 9.543569997731538e-05\n",
      "Validation Loss: 8.829560066986008e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.000110166256690718\n",
      "Training Loss: 9.184314122649084e-05\n",
      "Training Loss: 9.488315968155802e-05\n",
      "Validation Loss: 8.77670131711547e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00010955397860925586\n",
      "Training Loss: 9.129020337240945e-05\n",
      "Training Loss: 9.433633241314965e-05\n",
      "Validation Loss: 8.72432732383336e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00010894780377384449\n",
      "Training Loss: 9.074166155187413e-05\n",
      "Training Loss: 9.379476447975321e-05\n",
      "Validation Loss: 8.672442142055383e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00010834717022589757\n",
      "Training Loss: 9.01973462987371e-05\n",
      "Training Loss: 9.325835801973881e-05\n",
      "Validation Loss: 8.620998902147273e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00010775174277114275\n",
      "Training Loss: 8.965674014689284e-05\n",
      "Training Loss: 9.272665205571684e-05\n",
      "Validation Loss: 8.569970034156714e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.00010716094834606338\n",
      "Training Loss: 8.911960531804653e-05\n",
      "Training Loss: 9.219905762620329e-05\n",
      "Validation Loss: 8.519325678555126e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00010657453607564094\n",
      "Training Loss: 8.858550319928326e-05\n",
      "Training Loss: 9.167560346213576e-05\n",
      "Validation Loss: 8.469040043503432e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00010599190222819743\n",
      "Training Loss: 8.805390051747963e-05\n",
      "Training Loss: 9.115564751482452e-05\n",
      "Validation Loss: 8.419082359467395e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00010541261698563176\n",
      "Training Loss: 8.752456214097038e-05\n",
      "Training Loss: 9.063896303814545e-05\n",
      "Validation Loss: 8.369461558911271e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00010483645909516782\n",
      "Training Loss: 8.69971312204143e-05\n",
      "Training Loss: 9.012527049890196e-05\n",
      "Validation Loss: 8.320048745486786e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00010426292675219884\n",
      "Training Loss: 8.647115971143648e-05\n",
      "Training Loss: 8.961409926087072e-05\n",
      "Validation Loss: 8.270924595972554e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.00010369159384936211\n",
      "Training Loss: 8.594634937253431e-05\n",
      "Training Loss: 8.910519913115423e-05\n",
      "Validation Loss: 8.222036983037408e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00010312196239283367\n",
      "Training Loss: 8.542219138689689e-05\n",
      "Training Loss: 8.859820704856247e-05\n",
      "Validation Loss: 8.173322579280599e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.00010255368954858568\n",
      "Training Loss: 8.489855452353367e-05\n",
      "Training Loss: 8.809292001387802e-05\n",
      "Validation Loss: 8.12478962124965e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00010198628096077301\n",
      "Training Loss: 8.437478464657034e-05\n",
      "Training Loss: 8.758897108236852e-05\n",
      "Validation Loss: 8.07645372517297e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00010141959895918263\n",
      "Training Loss: 8.385075547266752e-05\n",
      "Training Loss: 8.708618788659806e-05\n",
      "Validation Loss: 8.028217525044168e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00010085305849315774\n",
      "Training Loss: 8.332621860063227e-05\n",
      "Training Loss: 8.658407135953893e-05\n",
      "Validation Loss: 7.980135226747469e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00010028631472778216\n",
      "Training Loss: 8.280053381895414e-05\n",
      "Training Loss: 8.60826407733839e-05\n",
      "Validation Loss: 7.932162877674028e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 9.97191332589864e-05\n",
      "Training Loss: 8.22738098759146e-05\n",
      "Training Loss: 8.55815348586475e-05\n",
      "Validation Loss: 7.884305760046445e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 9.91511228858144e-05\n",
      "Training Loss: 8.17455232663633e-05\n",
      "Training Loss: 8.508063931913057e-05\n",
      "Validation Loss: 7.836508216876589e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 9.858211965365626e-05\n",
      "Training Loss: 8.121551376007119e-05\n",
      "Training Loss: 8.457959358565859e-05\n",
      "Validation Loss: 7.788816975754047e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 9.801159619200917e-05\n",
      "Training Loss: 8.068356924013642e-05\n",
      "Training Loss: 8.407858559621673e-05\n",
      "Validation Loss: 7.741210371799692e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 9.743946925482306e-05\n",
      "Training Loss: 8.01494377265044e-05\n",
      "Training Loss: 8.357726416761579e-05\n",
      "Validation Loss: 7.693647797607942e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 9.686559494184621e-05\n",
      "Training Loss: 7.961313993746443e-05\n",
      "Training Loss: 8.30756433060742e-05\n",
      "Validation Loss: 7.646183827459476e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 9.628983955735749e-05\n",
      "Training Loss: 7.907456257726153e-05\n",
      "Training Loss: 8.257395343207463e-05\n",
      "Validation Loss: 7.598795432233111e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 9.571210744070413e-05\n",
      "Training Loss: 7.85336944500159e-05\n",
      "Training Loss: 8.207200991819263e-05\n",
      "Validation Loss: 7.551508758879617e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 9.51323144181515e-05\n",
      "Training Loss: 7.799058888394938e-05\n",
      "Training Loss: 8.156996636898839e-05\n",
      "Validation Loss: 7.504299222428733e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 9.455061112930707e-05\n",
      "Training Loss: 7.744519787138416e-05\n",
      "Training Loss: 8.106803054033662e-05\n",
      "Validation Loss: 7.457197273580594e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 9.396705290782847e-05\n",
      "Training Loss: 7.689784194099047e-05\n",
      "Training Loss: 8.05664891777269e-05\n",
      "Validation Loss: 7.410227258179895e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 9.338196811768284e-05\n",
      "Training Loss: 7.634860448433755e-05\n",
      "Training Loss: 8.00654694194236e-05\n",
      "Validation Loss: 7.363438834637348e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 9.279547225560236e-05\n",
      "Training Loss: 7.579793262721068e-05\n",
      "Training Loss: 7.956527271744562e-05\n",
      "Validation Loss: 7.316758069208937e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 9.220812340572593e-05\n",
      "Training Loss: 7.524593136167823e-05\n",
      "Training Loss: 7.906655755505199e-05\n",
      "Validation Loss: 7.270291010509743e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 9.161993604720919e-05\n",
      "Training Loss: 7.469331882475671e-05\n",
      "Training Loss: 7.85693471061677e-05\n",
      "Validation Loss: 7.2239994255285e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 9.103188749577384e-05\n",
      "Training Loss: 7.414017597511701e-05\n",
      "Training Loss: 7.807430089087574e-05\n",
      "Validation Loss: 7.177963088702455e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 9.044410404385417e-05\n",
      "Training Loss: 7.358721225045884e-05\n",
      "Training Loss: 7.758195014503145e-05\n",
      "Validation Loss: 7.132169647254128e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 8.985729998585157e-05\n",
      "Training Loss: 7.303488886464039e-05\n",
      "Training Loss: 7.709262373282399e-05\n",
      "Validation Loss: 7.086642756221e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 8.927210949877918e-05\n",
      "Training Loss: 7.248371861351188e-05\n",
      "Training Loss: 7.660681335437402e-05\n",
      "Validation Loss: 7.041408939125524e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 8.868926277500578e-05\n",
      "Training Loss: 7.193428220944042e-05\n",
      "Training Loss: 7.612507322846796e-05\n",
      "Validation Loss: 6.996486661775859e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 8.810943716525799e-05\n",
      "Training Loss: 7.138709453556658e-05\n",
      "Training Loss: 7.564797743725649e-05\n",
      "Validation Loss: 6.951881813405675e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 8.753330334002385e-05\n",
      "Training Loss: 7.084274048793304e-05\n",
      "Training Loss: 7.51758735623298e-05\n",
      "Validation Loss: 6.90765718491604e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 8.696159457940666e-05\n",
      "Training Loss: 7.030176562693669e-05\n",
      "Training Loss: 7.470917719729187e-05\n",
      "Validation Loss: 6.863769609031458e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 8.6394914687844e-05\n",
      "Training Loss: 6.9764627855875e-05\n",
      "Training Loss: 7.424843581247842e-05\n",
      "Validation Loss: 6.820275852527977e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 8.583393262597383e-05\n",
      "Training Loss: 6.923190177531069e-05\n",
      "Training Loss: 7.379389149718918e-05\n",
      "Validation Loss: 6.777172681078933e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 8.527930058335186e-05\n",
      "Training Loss: 6.870403639823052e-05\n",
      "Training Loss: 7.33457665592141e-05\n",
      "Validation Loss: 6.734457345762135e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 8.47315956661987e-05\n",
      "Training Loss: 6.818154588927427e-05\n",
      "Training Loss: 7.290464526704454e-05\n",
      "Validation Loss: 6.692153242051411e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 8.419126157605206e-05\n",
      "Training Loss: 6.766465226519358e-05\n",
      "Training Loss: 7.247058495522651e-05\n",
      "Validation Loss: 6.650270137306711e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 8.365889822925965e-05\n",
      "Training Loss: 6.715379758588824e-05\n",
      "Training Loss: 7.204369803730515e-05\n",
      "Validation Loss: 6.608800263012619e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 8.313477879710262e-05\n",
      "Training Loss: 6.664933413503604e-05\n",
      "Training Loss: 7.162433842495375e-05\n",
      "Validation Loss: 6.567770289845785e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 8.261938162831939e-05\n",
      "Training Loss: 6.615146722197096e-05\n",
      "Training Loss: 7.121247126178786e-05\n",
      "Validation Loss: 6.527180566275532e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 8.211299335471267e-05\n",
      "Training Loss: 6.566064580056264e-05\n",
      "Training Loss: 7.080824613694858e-05\n",
      "Validation Loss: 6.487022632979225e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 8.161579982242984e-05\n",
      "Training Loss: 6.517694171179756e-05\n",
      "Training Loss: 7.041174796540873e-05\n",
      "Validation Loss: 6.447368080474651e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 8.112798424463108e-05\n",
      "Training Loss: 6.470057242495386e-05\n",
      "Training Loss: 7.002277087394759e-05\n",
      "Validation Loss: 6.408132773348564e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 8.064968353210133e-05\n",
      "Training Loss: 6.4231731239488e-05\n",
      "Training Loss: 6.964148443330486e-05\n",
      "Validation Loss: 6.369402878559678e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 8.018113451726095e-05\n",
      "Training Loss: 6.377060275099211e-05\n",
      "Training Loss: 6.926793622369587e-05\n",
      "Validation Loss: 6.331159849569406e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 7.972230961968308e-05\n",
      "Training Loss: 6.331733202387113e-05\n",
      "Training Loss: 6.890195134474198e-05\n",
      "Validation Loss: 6.293415659006876e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 7.927320476937894e-05\n",
      "Training Loss: 6.287192431500443e-05\n",
      "Training Loss: 6.854350323465041e-05\n",
      "Validation Loss: 6.256211037928071e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 7.883391806899453e-05\n",
      "Training Loss: 6.243459138204344e-05\n",
      "Training Loss: 6.819252744207915e-05\n",
      "Validation Loss: 6.219523316411121e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 7.840433664568991e-05\n",
      "Training Loss: 6.200528775480052e-05\n",
      "Training Loss: 6.784888680613221e-05\n",
      "Validation Loss: 6.183401009355988e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 7.798458559591382e-05\n",
      "Training Loss: 6.158421891541365e-05\n",
      "Training Loss: 6.751255752988073e-05\n",
      "Validation Loss: 6.14784082623128e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 7.757437240798027e-05\n",
      "Training Loss: 6.117137133060168e-05\n",
      "Training Loss: 6.718350850860588e-05\n",
      "Validation Loss: 6.112861623212543e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 7.717383477029216e-05\n",
      "Training Loss: 6.076669490084896e-05\n",
      "Training Loss: 6.68615224867608e-05\n",
      "Validation Loss: 6.078479824343427e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 7.678266537368472e-05\n",
      "Training Loss: 6.037042162461148e-05\n",
      "Training Loss: 6.654654836893314e-05\n",
      "Validation Loss: 6.044697207737167e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 7.640085680122865e-05\n",
      "Training Loss: 5.998237418680219e-05\n",
      "Training Loss: 6.62385026589618e-05\n",
      "Validation Loss: 6.01156204814625e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 7.602837131344131e-05\n",
      "Training Loss: 5.960257195511076e-05\n",
      "Training Loss: 6.593726585379045e-05\n",
      "Validation Loss: 5.979042385518093e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 7.566500482425909e-05\n",
      "Training Loss: 5.923102703945915e-05\n",
      "Training Loss: 6.564272398918548e-05\n",
      "Validation Loss: 5.947178119078692e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 7.531049370754773e-05\n",
      "Training Loss: 5.886784319955041e-05\n",
      "Training Loss: 6.535477523357258e-05\n",
      "Validation Loss: 5.915969928394312e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 7.496495000395953e-05\n",
      "Training Loss: 5.8512787700237825e-05\n",
      "Training Loss: 6.507337001949054e-05\n",
      "Validation Loss: 5.8854145157802325e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 7.46279896429769e-05\n",
      "Training Loss: 5.8165858945358195e-05\n",
      "Training Loss: 6.479830920852692e-05\n",
      "Validation Loss: 5.855530172299e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 7.429963110098469e-05\n",
      "Training Loss: 5.7827032637760564e-05\n",
      "Training Loss: 6.452956687553523e-05\n",
      "Validation Loss: 5.826303393487149e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 7.397957937428145e-05\n",
      "Training Loss: 5.7496191393511255e-05\n",
      "Training Loss: 6.426692500099306e-05\n",
      "Validation Loss: 5.7977488426474617e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 7.366773133526294e-05\n",
      "Training Loss: 5.717324121633283e-05\n",
      "Training Loss: 6.401032288522402e-05\n",
      "Validation Loss: 5.769853955468299e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 7.336384679547336e-05\n",
      "Training Loss: 5.6858189263948586e-05\n",
      "Training Loss: 6.375972303430899e-05\n",
      "Validation Loss: 5.742627790108129e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 7.306785659238812e-05\n",
      "Training Loss: 5.655083946749073e-05\n",
      "Training Loss: 6.351493135753117e-05\n",
      "Validation Loss: 5.7160630481274476e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 7.277956498910498e-05\n",
      "Training Loss: 5.6251143482768385e-05\n",
      "Training Loss: 6.327576583316841e-05\n",
      "Validation Loss: 5.69014131685711e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 7.24986482237e-05\n",
      "Training Loss: 5.595898498995666e-05\n",
      "Training Loss: 6.304230711521086e-05\n",
      "Validation Loss: 5.664877846172888e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 7.222511482723348e-05\n",
      "Training Loss: 5.567418185819406e-05\n",
      "Training Loss: 6.281427043177246e-05\n",
      "Validation Loss: 5.640238688418608e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 7.195863244305656e-05\n",
      "Training Loss: 5.539668242363405e-05\n",
      "Training Loss: 6.259152105030807e-05\n",
      "Validation Loss: 5.616230057282511e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 7.169910154971149e-05\n",
      "Training Loss: 5.512637409538001e-05\n",
      "Training Loss: 6.237402897568245e-05\n",
      "Validation Loss: 5.59283593697166e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 7.144625419186923e-05\n",
      "Training Loss: 5.486306721650181e-05\n",
      "Training Loss: 6.216170987954683e-05\n",
      "Validation Loss: 5.5700600170710234e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 7.119989229522616e-05\n",
      "Training Loss: 5.46065434718912e-05\n",
      "Training Loss: 6.195434799792565e-05\n",
      "Validation Loss: 5.547878516337957e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 7.096005777384562e-05\n",
      "Training Loss: 5.435671790564811e-05\n",
      "Training Loss: 6.175194578190712e-05\n",
      "Validation Loss: 5.5262716302698546e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 7.072632201470696e-05\n",
      "Training Loss: 5.411343171999761e-05\n",
      "Training Loss: 6.155415156172239e-05\n",
      "Validation Loss: 5.5052389235355434e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 7.049857210859046e-05\n",
      "Training Loss: 5.38765696092014e-05\n",
      "Training Loss: 6.136107353086118e-05\n",
      "Validation Loss: 5.48477090162348e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 7.02767165921614e-05\n",
      "Training Loss: 5.364588681004534e-05\n",
      "Training Loss: 6.117243510288972e-05\n",
      "Validation Loss: 5.464819553432453e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 7.00604736812238e-05\n",
      "Training Loss: 5.3421367792907406e-05\n",
      "Training Loss: 6.098820494116808e-05\n",
      "Validation Loss: 5.4454021230841965e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 6.98496797667758e-05\n",
      "Training Loss: 5.320275156009302e-05\n",
      "Training Loss: 6.080834764361498e-05\n",
      "Validation Loss: 5.4265080410239925e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 6.964422787405056e-05\n",
      "Training Loss: 5.2989871728641444e-05\n",
      "Training Loss: 6.063263532269048e-05\n",
      "Validation Loss: 5.408118767866582e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 6.944389660020534e-05\n",
      "Training Loss: 5.2782658317482853e-05\n",
      "Training Loss: 6.046090174095298e-05\n",
      "Validation Loss: 5.390212456833897e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 6.924846913989314e-05\n",
      "Training Loss: 5.2580813248823686e-05\n",
      "Training Loss: 6.029315465184482e-05\n",
      "Validation Loss: 5.372769695323574e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 6.905784288392169e-05\n",
      "Training Loss: 5.238428332177136e-05\n",
      "Training Loss: 6.012925449795148e-05\n",
      "Validation Loss: 5.3557962371669825e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 6.887192419071652e-05\n",
      "Training Loss: 5.2192923785696624e-05\n",
      "Training Loss: 5.9969054736939144e-05\n",
      "Validation Loss: 5.3392519843777684e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 6.869047690543084e-05\n",
      "Training Loss: 5.200662925744837e-05\n",
      "Training Loss: 5.981251833873102e-05\n",
      "Validation Loss: 5.323136893525004e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 6.851336893305415e-05\n",
      "Training Loss: 5.182512641113135e-05\n",
      "Training Loss: 5.965939851648727e-05\n",
      "Validation Loss: 5.307442244189547e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 6.834039553723415e-05\n",
      "Training Loss: 5.164833075923525e-05\n",
      "Training Loss: 5.950981664227584e-05\n",
      "Validation Loss: 5.292151479991159e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 6.817149923790566e-05\n",
      "Training Loss: 5.1476097733029745e-05\n",
      "Training Loss: 5.9363481273067006e-05\n",
      "Validation Loss: 5.277254041594164e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 6.800647945510718e-05\n",
      "Training Loss: 5.1308287647771065e-05\n",
      "Training Loss: 5.9220430730420046e-05\n",
      "Validation Loss: 5.262742783333727e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 6.784521752706496e-05\n",
      "Training Loss: 5.114474508900457e-05\n",
      "Training Loss: 5.908039930545783e-05\n",
      "Validation Loss: 5.2485797455579466e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 6.768758574253297e-05\n",
      "Training Loss: 5.098539644905031e-05\n",
      "Training Loss: 5.8943446388184386e-05\n",
      "Validation Loss: 5.23477228597677e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 6.753347314315761e-05\n",
      "Training Loss: 5.0829898500523993e-05\n",
      "Training Loss: 5.880947042896878e-05\n",
      "Validation Loss: 5.221307226114159e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 6.738268852586771e-05\n",
      "Training Loss: 5.067829972631444e-05\n",
      "Training Loss: 5.867832815965812e-05\n",
      "Validation Loss: 5.208172184068368e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 6.723517469708895e-05\n",
      "Training Loss: 5.053042325698698e-05\n",
      "Training Loss: 5.854997741607804e-05\n",
      "Validation Loss: 5.19535301872964e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 6.709082785619103e-05\n",
      "Training Loss: 5.038625752376902e-05\n",
      "Training Loss: 5.842427834522823e-05\n",
      "Validation Loss: 5.182842807208248e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 6.694950968721969e-05\n",
      "Training Loss: 5.0245611969330636e-05\n",
      "Training Loss: 5.830118769154069e-05\n",
      "Validation Loss: 5.170627536132456e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 6.68109830985486e-05\n",
      "Training Loss: 5.0108341813484e-05\n",
      "Training Loss: 5.818066108531639e-05\n",
      "Validation Loss: 5.158695321778794e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 6.667547334473057e-05\n",
      "Training Loss: 4.997430359708233e-05\n",
      "Training Loss: 5.806251864669321e-05\n",
      "Validation Loss: 5.147050994177273e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 6.654258219896292e-05\n",
      "Training Loss: 4.984336289680868e-05\n",
      "Training Loss: 5.7946778565565185e-05\n",
      "Validation Loss: 5.1356592787291693e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 6.641229105753155e-05\n",
      "Training Loss: 4.9715618781647206e-05\n",
      "Training Loss: 5.783332083865389e-05\n",
      "Validation Loss: 5.12453837554756e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 6.62846020077268e-05\n",
      "Training Loss: 4.959071814937488e-05\n",
      "Training Loss: 5.772207224254089e-05\n",
      "Validation Loss: 5.113656423193614e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 6.615925190544658e-05\n",
      "Training Loss: 4.946869169543788e-05\n",
      "Training Loss: 5.761309092576994e-05\n",
      "Validation Loss: 5.1030231956696646e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 6.603631592952297e-05\n",
      "Training Loss: 4.9349382829859676e-05\n",
      "Training Loss: 5.750612186602666e-05\n",
      "Validation Loss: 5.092613578148139e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 6.591559826119919e-05\n",
      "Training Loss: 4.923274609836881e-05\n",
      "Training Loss: 5.740123132909503e-05\n",
      "Validation Loss: 5.0824339611066984e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 6.579711306585523e-05\n",
      "Training Loss: 4.911866355996608e-05\n",
      "Training Loss: 5.72982991934623e-05\n",
      "Validation Loss: 5.072460597536489e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 6.568067808984779e-05\n",
      "Training Loss: 4.90070713476598e-05\n",
      "Training Loss: 5.719727161249466e-05\n",
      "Validation Loss: 5.0626929259011746e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 6.556636905770574e-05\n",
      "Training Loss: 4.8897878675688846e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [13:02<13:03, 156.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.709808172468911e-05\n",
      "Validation Loss: 5.0531333389893445e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.8916546854376793\n",
      "Training Loss: 0.7223198622465133\n",
      "Training Loss: 0.5558583548665047\n",
      "Validation Loss: 0.3647985958986068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.28557821583002807\n",
      "Training Loss: 0.14751780695747585\n",
      "Training Loss: 0.09543887469917536\n",
      "Validation Loss: 0.06590287387894278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.058132888386026024\n",
      "Training Loss: 0.049522831160575154\n",
      "Training Loss: 0.0516750618442893\n",
      "Validation Loss: 0.05123916433684612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.047796673852717506\n",
      "Training Loss: 0.04625560256652534\n",
      "Training Loss: 0.048438966684043405\n",
      "Validation Loss: 0.04874584587353669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.045372420594794675\n",
      "Training Loss: 0.04389927030541003\n",
      "Training Loss: 0.04569323143921793\n",
      "Validation Loss: 0.04583048204148418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.0425502010982018\n",
      "Training Loss: 0.04094361376482993\n",
      "Training Loss: 0.042363211866468194\n",
      "Validation Loss: 0.042122258694863385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.038889601946575564\n",
      "Training Loss: 0.036867292155511676\n",
      "Training Loss: 0.037610121620818976\n",
      "Validation Loss: 0.03629245577652133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.03319085439128685\n",
      "Training Loss: 0.03035425779176876\n",
      "Training Loss: 0.030223111538216472\n",
      "Validation Loss: 0.02782870497387112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.025401579647004836\n",
      "Training Loss: 0.022383597006555647\n",
      "Training Loss: 0.02183230559807271\n",
      "Validation Loss: 0.01963802616457256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.017803861798893195\n",
      "Training Loss: 0.015540498976479284\n",
      "Training Loss: 0.01496522932080552\n",
      "Validation Loss: 0.013471618299294013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012062251801835374\n",
      "Training Loss: 0.010544986596796662\n",
      "Training Loss: 0.009911002260632813\n",
      "Validation Loss: 0.008953506667873288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.007784202493494377\n",
      "Training Loss: 0.006621232250472531\n",
      "Training Loss: 0.005963843853096478\n",
      "Validation Loss: 0.0057115622497231735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.004497886335011572\n",
      "Training Loss: 0.0036096056932001376\n",
      "Training Loss: 0.0032168728703982196\n",
      "Validation Loss: 0.004021201415178418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0025630879765958527\n",
      "Training Loss: 0.0020396470969717482\n",
      "Training Loss: 0.0019845299809821883\n",
      "Validation Loss: 0.0033558047735629333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0018254067818634211\n",
      "Training Loss: 0.0015086978774343151\n",
      "Training Loss: 0.0015483028076414484\n",
      "Validation Loss: 0.0028263476099740464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0014984627137891947\n",
      "Training Loss: 0.0012686167540960013\n",
      "Training Loss: 0.0013032858874066733\n",
      "Validation Loss: 0.002318562080709557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0012664669002697337\n",
      "Training Loss: 0.0010922913481772412\n",
      "Training Loss: 0.0011139129870571195\n",
      "Validation Loss: 0.0018879099836667183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0010801201898721048\n",
      "Training Loss: 0.0009455523801443633\n",
      "Training Loss: 0.000957444889791077\n",
      "Validation Loss: 0.0015380017134345272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0009275097500358242\n",
      "Training Loss: 0.0008204545791522833\n",
      "Training Loss: 0.0008255698905850295\n",
      "Validation Loss: 0.0012562122932384104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.0008010881670634262\n",
      "Training Loss: 0.000712816880113678\n",
      "Training Loss: 0.0007131997433316428\n",
      "Validation Loss: 0.001030210040482232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0006953116947261151\n",
      "Training Loss: 0.0006197362173406873\n",
      "Training Loss: 0.0006168130831792951\n",
      "Validation Loss: 0.0008497350547381603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0006060865035397001\n",
      "Training Loss: 0.0005390428892860655\n",
      "Training Loss: 0.0005338562299584737\n",
      "Validation Loss: 0.0007061113925844305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0005303665929386625\n",
      "Training Loss: 0.00046903126196411903\n",
      "Training Loss: 0.0004623884001193801\n",
      "Validation Loss: 0.0005920224944378113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00046583822113461794\n",
      "Training Loss: 0.00040826897820807063\n",
      "Training Loss: 0.0004008260330010671\n",
      "Validation Loss: 0.0005013128416220333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0004106276071252069\n",
      "Training Loss: 0.0003553917194585665\n",
      "Training Loss: 0.00034770117425068746\n",
      "Validation Loss: 0.0004286688661400302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.0003629850440484006\n",
      "Training Loss: 0.0003088636130632949\n",
      "Training Loss: 0.00030144347194436703\n",
      "Validation Loss: 0.0003693109902905122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0003210827191651333\n",
      "Training Loss: 0.00026698705514718315\n",
      "Training Loss: 0.0002605553672037786\n",
      "Validation Loss: 0.0003191370858249694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0002834195434479625\n",
      "Training Loss: 0.0002289259415192646\n",
      "Training Loss: 0.00022468826551630628\n",
      "Validation Loss: 0.00027576633547550446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00025005543855513676\n",
      "Training Loss: 0.00019615170665929327\n",
      "Training Loss: 0.00019526215244695778\n",
      "Validation Loss: 0.00023902035757325055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00022257003245613306\n",
      "Training Loss: 0.00017102000463637524\n",
      "Training Loss: 0.0001734093872801168\n",
      "Validation Loss: 0.00020922822099482495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00020171174128336133\n",
      "Training Loss: 0.000153670878153207\n",
      "Training Loss: 0.00015816372868357576\n",
      "Validation Loss: 0.0001858204426691904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00018647547076398042\n",
      "Training Loss: 0.00014222886062270846\n",
      "Training Loss: 0.00014757282038772247\n",
      "Validation Loss: 0.00016783457386338157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0001754141350284044\n",
      "Training Loss: 0.00013473518514729222\n",
      "Training Loss: 0.00014012714580530883\n",
      "Validation Loss: 0.00015435078429608225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00016743980271712643\n",
      "Training Loss: 0.00012977090758795385\n",
      "Training Loss: 0.00013485276800565772\n",
      "Validation Loss: 0.00014434149018730812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00016165371573151788\n",
      "Training Loss: 0.00012626102916328817\n",
      "Training Loss: 0.00013097955710691166\n",
      "Validation Loss: 0.00013677206881991142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0001572489636055252\n",
      "Training Loss: 0.00012346567176791724\n",
      "Training Loss: 0.0001279172659451433\n",
      "Validation Loss: 0.00013086015153450636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0001536524818948237\n",
      "Training Loss: 0.00012100405469027464\n",
      "Training Loss: 0.00012530913209047868\n",
      "Validation Loss: 0.00012609751426547456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00015054283258905343\n",
      "Training Loss: 0.00011872688952280442\n",
      "Training Loss: 0.0001229739156042342\n",
      "Validation Loss: 0.0001221545175866687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00014775537455534503\n",
      "Training Loss: 0.0001165822517577908\n",
      "Training Loss: 0.00012082371727956343\n",
      "Validation Loss: 0.00011880841129516667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0001452021085697197\n",
      "Training Loss: 0.00011454979436166468\n",
      "Training Loss: 0.00011881250734404602\n",
      "Validation Loss: 0.00011590399689533555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00014283126182817796\n",
      "Training Loss: 0.00011261803801971837\n",
      "Training Loss: 0.00011691387574501277\n",
      "Validation Loss: 0.000113333348115171\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0001406086807310203\n",
      "Training Loss: 0.0001107781169412192\n",
      "Training Loss: 0.00011511039467222872\n",
      "Validation Loss: 0.00011101760754356516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00013851046585841687\n",
      "Training Loss: 0.0001090218434092094\n",
      "Training Loss: 0.00011338956189320015\n",
      "Validation Loss: 0.00010890173112028186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0001365187938699819\n",
      "Training Loss: 0.00010734229304944165\n",
      "Training Loss: 0.00011174214742823096\n",
      "Validation Loss: 0.00010694442687636592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00013462025443004678\n",
      "Training Loss: 0.00010573325701443537\n",
      "Training Loss: 0.00011016078207831014\n",
      "Validation Loss: 0.00010511643604025195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0001328038460633252\n",
      "Training Loss: 0.0001041893287037965\n",
      "Training Loss: 0.00010863979754503816\n",
      "Validation Loss: 0.00010339465862170471\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00013106119492476865\n",
      "Training Loss: 0.00010270575234244461\n",
      "Training Loss: 0.00010717429174292192\n",
      "Validation Loss: 0.0001017624369697852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00012938537511217874\n",
      "Training Loss: 0.00010127853181984392\n",
      "Training Loss: 0.00010576037685495976\n",
      "Validation Loss: 0.00010020710592113338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00012777115362041513\n",
      "Training Loss: 9.990417344852176e-05\n",
      "Training Loss: 0.00010439526092341111\n",
      "Validation Loss: 9.871868756266175e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00012621372767171124\n",
      "Training Loss: 9.857975944214558e-05\n",
      "Training Loss: 0.00010307603302862844\n",
      "Validation Loss: 9.72904828936254e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00012470933584154408\n",
      "Training Loss: 9.730282970849658e-05\n",
      "Training Loss: 0.00010180081552789488\n",
      "Validation Loss: 9.59164066382604e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00012325517899625994\n",
      "Training Loss: 9.607105835129914e-05\n",
      "Training Loss: 0.00010056779748992994\n",
      "Validation Loss: 9.459127563735656e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00012184850234007172\n",
      "Training Loss: 9.488287309068255e-05\n",
      "Training Loss: 9.937547249137424e-05\n",
      "Validation Loss: 9.331245309204972e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00012048744463754701\n",
      "Training Loss: 9.373655122544732e-05\n",
      "Training Loss: 9.822284899200895e-05\n",
      "Validation Loss: 9.207659629252059e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00011917008696400444\n",
      "Training Loss: 9.263085416023386e-05\n",
      "Training Loss: 9.710906226246153e-05\n",
      "Validation Loss: 9.088266392864988e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00011789512456743977\n",
      "Training Loss: 9.156447381428734e-05\n",
      "Training Loss: 9.603284391232592e-05\n",
      "Validation Loss: 8.972804863241323e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00011666123827126284\n",
      "Training Loss: 9.053637185388652e-05\n",
      "Training Loss: 9.499397567196865e-05\n",
      "Validation Loss: 8.861184336167886e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00011546737518074224\n",
      "Training Loss: 8.954571580943593e-05\n",
      "Training Loss: 9.39913802267256e-05\n",
      "Validation Loss: 8.753331541116454e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00011431248391090776\n",
      "Training Loss: 8.859138517436805e-05\n",
      "Training Loss: 9.302445544562943e-05\n",
      "Validation Loss: 8.64913348001271e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00011319549383188133\n",
      "Training Loss: 8.76725110992993e-05\n",
      "Training Loss: 9.20925567879749e-05\n",
      "Validation Loss: 8.548537269316409e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00011211584826014586\n",
      "Training Loss: 8.678830919052416e-05\n",
      "Training Loss: 9.119535808167711e-05\n",
      "Validation Loss: 8.451410841199719e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00011107241726676875\n",
      "Training Loss: 8.593777873102227e-05\n",
      "Training Loss: 9.033177076162247e-05\n",
      "Validation Loss: 8.35774864365734e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00011006422771970393\n",
      "Training Loss: 8.512005626471364e-05\n",
      "Training Loss: 8.950116096457351e-05\n",
      "Validation Loss: 8.267469781734117e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00010909056188211252\n",
      "Training Loss: 8.433412143858732e-05\n",
      "Training Loss: 8.87027602402668e-05\n",
      "Validation Loss: 8.180547606213387e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00010815056642968557\n",
      "Training Loss: 8.35790791643376e-05\n",
      "Training Loss: 8.793562403297984e-05\n",
      "Validation Loss: 8.096843401780758e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00010724295542786421\n",
      "Training Loss: 8.285378965410927e-05\n",
      "Training Loss: 8.719889523490564e-05\n",
      "Validation Loss: 8.016346200338887e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00010636687274200085\n",
      "Training Loss: 8.21573695884581e-05\n",
      "Training Loss: 8.64915394822674e-05\n",
      "Validation Loss: 7.93898404041878e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00010552123234447208\n",
      "Training Loss: 8.148839643581595e-05\n",
      "Training Loss: 8.58125258673681e-05\n",
      "Validation Loss: 7.864620601027495e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00010470486292433634\n",
      "Training Loss: 8.084599495305156e-05\n",
      "Training Loss: 8.516061079717474e-05\n",
      "Validation Loss: 7.793165555545436e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00010391663361588144\n",
      "Training Loss: 8.022888524465088e-05\n",
      "Training Loss: 8.453500332961994e-05\n",
      "Validation Loss: 7.724564711884085e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00010315544592231163\n",
      "Training Loss: 7.963578137150762e-05\n",
      "Training Loss: 8.393417418574245e-05\n",
      "Validation Loss: 7.65870373685134e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00010242007430861122\n",
      "Training Loss: 7.90656290246261e-05\n",
      "Training Loss: 8.33572468809507e-05\n",
      "Validation Loss: 7.595432172432115e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00010170933193876408\n",
      "Training Loss: 7.851717064113472e-05\n",
      "Training Loss: 8.280277628273324e-05\n",
      "Validation Loss: 7.534687904225894e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00010102191673468042\n",
      "Training Loss: 7.798921835274086e-05\n",
      "Training Loss: 8.226962594108044e-05\n",
      "Validation Loss: 7.476385347759338e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00010035678643362189\n",
      "Training Loss: 7.748063821509276e-05\n",
      "Training Loss: 8.175672553988988e-05\n",
      "Validation Loss: 7.420353010653099e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 9.971285009669373e-05\n",
      "Training Loss: 7.699035651057783e-05\n",
      "Training Loss: 8.126276357870665e-05\n",
      "Validation Loss: 7.366515131998517e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 9.908882456329594e-05\n",
      "Training Loss: 7.65169890883044e-05\n",
      "Training Loss: 8.078671668954485e-05\n",
      "Validation Loss: 7.314732336331115e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 9.848369651535905e-05\n",
      "Training Loss: 7.605968076404679e-05\n",
      "Training Loss: 8.032734315293056e-05\n",
      "Validation Loss: 7.26493411635152e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 9.789617438400455e-05\n",
      "Training Loss: 7.561737335436192e-05\n",
      "Training Loss: 7.988371782630566e-05\n",
      "Validation Loss: 7.21700641938032e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 9.732562817134749e-05\n",
      "Training Loss: 7.518900708873844e-05\n",
      "Training Loss: 7.945471567381901e-05\n",
      "Validation Loss: 7.170817721242691e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 9.677080947767536e-05\n",
      "Training Loss: 7.477368544641649e-05\n",
      "Training Loss: 7.903944311237864e-05\n",
      "Validation Loss: 7.126300660060264e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 9.62308656926325e-05\n",
      "Training Loss: 7.43704871092632e-05\n",
      "Training Loss: 7.86368574381413e-05\n",
      "Validation Loss: 7.083371532685254e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 9.570490006353793e-05\n",
      "Training Loss: 7.397858835247461e-05\n",
      "Training Loss: 7.824618714039389e-05\n",
      "Validation Loss: 7.041889263204661e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 9.519207756966352e-05\n",
      "Training Loss: 7.359721639204508e-05\n",
      "Training Loss: 7.786654388837633e-05\n",
      "Validation Loss: 7.0017708234384e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 9.469171695400291e-05\n",
      "Training Loss: 7.322556729377538e-05\n",
      "Training Loss: 7.749728943053923e-05\n",
      "Validation Loss: 6.962997543197478e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 9.420298344593903e-05\n",
      "Training Loss: 7.286309720257122e-05\n",
      "Training Loss: 7.713754736869305e-05\n",
      "Validation Loss: 6.925432777034382e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 9.372522322337318e-05\n",
      "Training Loss: 7.25089767956888e-05\n",
      "Training Loss: 7.678675807710533e-05\n",
      "Validation Loss: 6.889023755862132e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 9.32578603260481e-05\n",
      "Training Loss: 7.216277208499378e-05\n",
      "Training Loss: 7.644421897566645e-05\n",
      "Validation Loss: 6.853696580170496e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 9.28002729142463e-05\n",
      "Training Loss: 7.182385435498873e-05\n",
      "Training Loss: 7.610949993704708e-05\n",
      "Validation Loss: 6.819387379416665e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 9.235177788468718e-05\n",
      "Training Loss: 7.149177424253139e-05\n",
      "Training Loss: 7.578187998205977e-05\n",
      "Validation Loss: 6.78603668746475e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 9.191209755954333e-05\n",
      "Training Loss: 7.116597750609798e-05\n",
      "Training Loss: 7.546095186626189e-05\n",
      "Validation Loss: 6.753580085009407e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 9.148066009856848e-05\n",
      "Training Loss: 7.084614789619081e-05\n",
      "Training Loss: 7.514634739436588e-05\n",
      "Validation Loss: 6.721976426101566e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 9.105703600198467e-05\n",
      "Training Loss: 7.053185283893982e-05\n",
      "Training Loss: 7.483757036879979e-05\n",
      "Validation Loss: 6.691165204306906e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 9.064075987680553e-05\n",
      "Training Loss: 7.022273005077295e-05\n",
      "Training Loss: 7.45340370303893e-05\n",
      "Validation Loss: 6.661112703430548e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 9.02315675830323e-05\n",
      "Training Loss: 6.99182685912092e-05\n",
      "Training Loss: 7.423578128509689e-05\n",
      "Validation Loss: 6.631744902355667e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 8.982915801425406e-05\n",
      "Training Loss: 6.961846115700609e-05\n",
      "Training Loss: 7.394227142413002e-05\n",
      "Validation Loss: 6.603055671190161e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 8.943307150730107e-05\n",
      "Training Loss: 6.932282268280687e-05\n",
      "Training Loss: 7.365317182575381e-05\n",
      "Validation Loss: 6.574987507386989e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 8.904314005121705e-05\n",
      "Training Loss: 6.903114029682911e-05\n",
      "Training Loss: 7.336834479247045e-05\n",
      "Validation Loss: 6.547502737427412e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 8.865878349752165e-05\n",
      "Training Loss: 6.874320601127693e-05\n",
      "Training Loss: 7.308746896796947e-05\n",
      "Validation Loss: 6.520576152979629e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 8.828026681385381e-05\n",
      "Training Loss: 6.845888599855244e-05\n",
      "Training Loss: 7.281030430476676e-05\n",
      "Validation Loss: 6.494167704086783e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 8.79068884478329e-05\n",
      "Training Loss: 6.817771557507513e-05\n",
      "Training Loss: 7.253675077208755e-05\n",
      "Validation Loss: 6.468235810490534e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 8.753875812089973e-05\n",
      "Training Loss: 6.789978810957109e-05\n",
      "Training Loss: 7.226652946428657e-05\n",
      "Validation Loss: 6.4427751940559e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 8.717538348264498e-05\n",
      "Training Loss: 6.762475773939513e-05\n",
      "Training Loss: 7.199940168902685e-05\n",
      "Validation Loss: 6.4177698405228e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 8.681657669512788e-05\n",
      "Training Loss: 6.735246628068125e-05\n",
      "Training Loss: 7.173534047524299e-05\n",
      "Validation Loss: 6.393160722152234e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 8.646221924664132e-05\n",
      "Training Loss: 6.708280510338227e-05\n",
      "Training Loss: 7.147403922999729e-05\n",
      "Validation Loss: 6.368950307864651e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 8.611205809756939e-05\n",
      "Training Loss: 6.681573523565021e-05\n",
      "Training Loss: 7.121562632164569e-05\n",
      "Validation Loss: 6.345123432602327e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 8.576598961553827e-05\n",
      "Training Loss: 6.655096182385022e-05\n",
      "Training Loss: 7.095972303659436e-05\n",
      "Validation Loss: 6.321630662262506e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 8.542386596673168e-05\n",
      "Training Loss: 6.62885295741944e-05\n",
      "Training Loss: 7.07062772403333e-05\n",
      "Validation Loss: 6.298476146797982e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 8.508574495408539e-05\n",
      "Training Loss: 6.602827572351089e-05\n",
      "Training Loss: 7.0455268241858e-05\n",
      "Validation Loss: 6.275635527590259e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 8.475114654174832e-05\n",
      "Training Loss: 6.577004329301417e-05\n",
      "Training Loss: 7.02064589222573e-05\n",
      "Validation Loss: 6.253112925467862e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 8.442015216587606e-05\n",
      "Training Loss: 6.551384729846177e-05\n",
      "Training Loss: 6.995974687470153e-05\n",
      "Validation Loss: 6.230857438362711e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 8.409272611515916e-05\n",
      "Training Loss: 6.525952277115721e-05\n",
      "Training Loss: 6.971523561787762e-05\n",
      "Validation Loss: 6.208887997560309e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 8.376861122542322e-05\n",
      "Training Loss: 6.500708267594746e-05\n",
      "Training Loss: 6.947250142729899e-05\n",
      "Validation Loss: 6.187178910346283e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 8.344774979832437e-05\n",
      "Training Loss: 6.475641210272442e-05\n",
      "Training Loss: 6.923183084836637e-05\n",
      "Validation Loss: 6.165720283155515e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 8.312991349157528e-05\n",
      "Training Loss: 6.450739234423963e-05\n",
      "Training Loss: 6.899283405800816e-05\n",
      "Validation Loss: 6.144502912719147e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 8.281515846192633e-05\n",
      "Training Loss: 6.426008304515563e-05\n",
      "Training Loss: 6.875574371861148e-05\n",
      "Validation Loss: 6.123531474248706e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 8.250342192241078e-05\n",
      "Training Loss: 6.401429658581037e-05\n",
      "Training Loss: 6.852037103271868e-05\n",
      "Validation Loss: 6.102759273366491e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 8.21945148300074e-05\n",
      "Training Loss: 6.377016659371293e-05\n",
      "Training Loss: 6.828653111142558e-05\n",
      "Validation Loss: 6.082208543130343e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 8.188847543351585e-05\n",
      "Training Loss: 6.352747334858577e-05\n",
      "Training Loss: 6.805423034620616e-05\n",
      "Validation Loss: 6.061861736423943e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 8.158513404396217e-05\n",
      "Training Loss: 6.328631762244186e-05\n",
      "Training Loss: 6.7823656913788e-05\n",
      "Validation Loss: 6.04171330532961e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 8.128450147069089e-05\n",
      "Training Loss: 6.304667020231137e-05\n",
      "Training Loss: 6.75944744057233e-05\n",
      "Validation Loss: 6.0217649947486953e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 8.098641197648248e-05\n",
      "Training Loss: 6.28083372475885e-05\n",
      "Training Loss: 6.736683388226084e-05\n",
      "Validation Loss: 6.0019945920614416e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 8.069101057117222e-05\n",
      "Training Loss: 6.257141358219087e-05\n",
      "Training Loss: 6.714055923112027e-05\n",
      "Validation Loss: 5.982397803737523e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 8.039807978093449e-05\n",
      "Training Loss: 6.233582626919088e-05\n",
      "Training Loss: 6.691579677180925e-05\n",
      "Validation Loss: 5.9629868951816116e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 8.010769619431812e-05\n",
      "Training Loss: 6.210162282968668e-05\n",
      "Training Loss: 6.669239489610845e-05\n",
      "Validation Loss: 5.9437542302148764e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 7.981962938629295e-05\n",
      "Training Loss: 6.186873976730567e-05\n",
      "Training Loss: 6.64702974472675e-05\n",
      "Validation Loss: 5.924677768408411e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 7.953402228395135e-05\n",
      "Training Loss: 6.163716999253666e-05\n",
      "Training Loss: 6.624963305966958e-05\n",
      "Validation Loss: 5.9057676189491106e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 7.925076014998922e-05\n",
      "Training Loss: 6.140687906736275e-05\n",
      "Training Loss: 6.603027192113587e-05\n",
      "Validation Loss: 5.887003346308549e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 7.896996098224918e-05\n",
      "Training Loss: 6.117787581160882e-05\n",
      "Training Loss: 6.581218809969869e-05\n",
      "Validation Loss: 5.868389804020532e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 7.869143004427315e-05\n",
      "Training Loss: 6.095017054803975e-05\n",
      "Training Loss: 6.559542500326642e-05\n",
      "Validation Loss: 5.84993781762677e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 7.841522570743109e-05\n",
      "Training Loss: 6.072366166790744e-05\n",
      "Training Loss: 6.537983719226759e-05\n",
      "Validation Loss: 5.8316366801264345e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 7.814131471150177e-05\n",
      "Training Loss: 6.049845844245283e-05\n",
      "Training Loss: 6.516568320876104e-05\n",
      "Validation Loss: 5.813471918290918e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 7.786967573338188e-05\n",
      "Training Loss: 6.027458231073979e-05\n",
      "Training Loss: 6.495282001196756e-05\n",
      "Validation Loss: 5.795461130331746e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 7.760035582577984e-05\n",
      "Training Loss: 6.005186678066821e-05\n",
      "Training Loss: 6.474118876212743e-05\n",
      "Validation Loss: 5.7775835869230495e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 7.73332617154665e-05\n",
      "Training Loss: 5.983052388501165e-05\n",
      "Training Loss: 6.453083096857881e-05\n",
      "Validation Loss: 5.75983711447468e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 7.706846752171259e-05\n",
      "Training Loss: 5.961044023251816e-05\n",
      "Training Loss: 6.432178902514352e-05\n",
      "Validation Loss: 5.7422289460242776e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 7.680580081796506e-05\n",
      "Training Loss: 5.9391617683104413e-05\n",
      "Training Loss: 6.411402885305507e-05\n",
      "Validation Loss: 5.724768693602364e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 7.654553254724306e-05\n",
      "Training Loss: 5.917417981891049e-05\n",
      "Training Loss: 6.390762924638693e-05\n",
      "Validation Loss: 5.707460891397695e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 7.628737623235793e-05\n",
      "Training Loss: 5.8957981314051724e-05\n",
      "Training Loss: 6.37025428659399e-05\n",
      "Validation Loss: 5.6902769480647486e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 7.603163277508429e-05\n",
      "Training Loss: 5.874313335198167e-05\n",
      "Training Loss: 6.349885536565125e-05\n",
      "Validation Loss: 5.6732316464690944e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 7.577811139981349e-05\n",
      "Training Loss: 5.8529547936814196e-05\n",
      "Training Loss: 6.329640891863165e-05\n",
      "Validation Loss: 5.6563205387728784e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 7.552673860573123e-05\n",
      "Training Loss: 5.831734791172494e-05\n",
      "Training Loss: 6.309533281182666e-05\n",
      "Validation Loss: 5.6395526570760124e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 7.527761652909249e-05\n",
      "Training Loss: 5.8106539559048545e-05\n",
      "Training Loss: 6.289563737254866e-05\n",
      "Validation Loss: 5.6229014098994155e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 7.503080575133935e-05\n",
      "Training Loss: 5.789705136066914e-05\n",
      "Training Loss: 6.269735145224331e-05\n",
      "Validation Loss: 5.6064118856984046e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 7.47862791740772e-05\n",
      "Training Loss: 5.768901105511759e-05\n",
      "Training Loss: 6.250041784824135e-05\n",
      "Validation Loss: 5.59005474918123e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 7.454407730620005e-05\n",
      "Training Loss: 5.7482318743495854e-05\n",
      "Training Loss: 6.230489584595489e-05\n",
      "Validation Loss: 5.573823836222003e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 7.430403019952791e-05\n",
      "Training Loss: 5.72770771350406e-05\n",
      "Training Loss: 6.211086953044287e-05\n",
      "Validation Loss: 5.557748393206811e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 7.406639049349906e-05\n",
      "Training Loss: 5.707327856725897e-05\n",
      "Training Loss: 6.191823575136369e-05\n",
      "Validation Loss: 5.541796668040569e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 7.38309796224712e-05\n",
      "Training Loss: 5.687102087222229e-05\n",
      "Training Loss: 6.172716266519273e-05\n",
      "Validation Loss: 5.526018241980228e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 7.359793346040533e-05\n",
      "Training Loss: 5.66702388982776e-05\n",
      "Training Loss: 6.153756346520823e-05\n",
      "Validation Loss: 5.510346407166079e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 7.336710677463998e-05\n",
      "Training Loss: 5.6470844572231724e-05\n",
      "Training Loss: 6.134943045253749e-05\n",
      "Validation Loss: 5.494845999329412e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 7.313873568818963e-05\n",
      "Training Loss: 5.627314424600627e-05\n",
      "Training Loss: 6.116286897849931e-05\n",
      "Validation Loss: 5.4794897780820054e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 7.291253510175011e-05\n",
      "Training Loss: 5.6076789996950537e-05\n",
      "Training Loss: 6.097790993408125e-05\n",
      "Validation Loss: 5.464274597491904e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 7.268875152931287e-05\n",
      "Training Loss: 5.588215611396663e-05\n",
      "Training Loss: 6.079444617171248e-05\n",
      "Validation Loss: 5.449203415460698e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 7.246727408983134e-05\n",
      "Training Loss: 5.568909115709175e-05\n",
      "Training Loss: 6.0612579659391486e-05\n",
      "Validation Loss: 5.434293106691768e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 7.224819574275899e-05\n",
      "Training Loss: 5.5497601201750514e-05\n",
      "Training Loss: 6.0432279115048e-05\n",
      "Validation Loss: 5.41953584953068e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 7.203141270110791e-05\n",
      "Training Loss: 5.530774437602304e-05\n",
      "Training Loss: 6.0253653168729214e-05\n",
      "Validation Loss: 5.4049293738173444e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 7.181697154464927e-05\n",
      "Training Loss: 5.5119500668752156e-05\n",
      "Training Loss: 6.007675553519221e-05\n",
      "Validation Loss: 5.390473121081137e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 7.160488799854647e-05\n",
      "Training Loss: 5.493299583804401e-05\n",
      "Training Loss: 5.990145215491793e-05\n",
      "Validation Loss: 5.376178255625e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 7.139519364955049e-05\n",
      "Training Loss: 5.4748077022850336e-05\n",
      "Training Loss: 5.9727684792960644e-05\n",
      "Validation Loss: 5.362023849873653e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 7.118778661151737e-05\n",
      "Training Loss: 5.456487155470313e-05\n",
      "Training Loss: 5.955581360467477e-05\n",
      "Validation Loss: 5.348041447453734e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 7.09828095159537e-05\n",
      "Training Loss: 5.4383379099363085e-05\n",
      "Training Loss: 5.9385526960795686e-05\n",
      "Validation Loss: 5.33420051540182e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 7.078016458763159e-05\n",
      "Training Loss: 5.420356967761108e-05\n",
      "Training Loss: 5.9216932218078e-05\n",
      "Validation Loss: 5.320533225815606e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 7.057991526835395e-05\n",
      "Training Loss: 5.402554895908907e-05\n",
      "Training Loss: 5.905013137635251e-05\n",
      "Validation Loss: 5.307007166449918e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 7.03820100898156e-05\n",
      "Training Loss: 5.3849214993988425e-05\n",
      "Training Loss: 5.888504939321137e-05\n",
      "Validation Loss: 5.2936619606166304e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 7.018647859240446e-05\n",
      "Training Loss: 5.367457935108177e-05\n",
      "Training Loss: 5.872174291198462e-05\n",
      "Validation Loss: 5.28045966552526e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 6.999321724833863e-05\n",
      "Training Loss: 5.350174218165193e-05\n",
      "Training Loss: 5.8560073530316007e-05\n",
      "Validation Loss: 5.267429860702649e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 6.98023573932005e-05\n",
      "Training Loss: 5.333070398819473e-05\n",
      "Training Loss: 5.8400201805852706e-05\n",
      "Validation Loss: 5.25454444685013e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 6.961370837871072e-05\n",
      "Training Loss: 5.316139103797468e-05\n",
      "Training Loss: 5.82421332865124e-05\n",
      "Validation Loss: 5.241830158002414e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 6.942742489172815e-05\n",
      "Training Loss: 5.2993800578633455e-05\n",
      "Training Loss: 5.808569392229401e-05\n",
      "Validation Loss: 5.229269420473674e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 6.924342266756867e-05\n",
      "Training Loss: 5.2828057073384115e-05\n",
      "Training Loss: 5.79310477769468e-05\n",
      "Validation Loss: 5.2168496985655875e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 6.906179887664621e-05\n",
      "Training Loss: 5.2664086367713026e-05\n",
      "Training Loss: 5.7778284367486774e-05\n",
      "Validation Loss: 5.204616945775342e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 6.88823719156062e-05\n",
      "Training Loss: 5.2501858399409684e-05\n",
      "Training Loss: 5.762711276020127e-05\n",
      "Validation Loss: 5.192510192235082e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 6.870524084661156e-05\n",
      "Training Loss: 5.2341446139507755e-05\n",
      "Training Loss: 5.747775881900452e-05\n",
      "Validation Loss: 5.1805846907698427e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 6.853034351934185e-05\n",
      "Training Loss: 5.218269955435062e-05\n",
      "Training Loss: 5.7330198642375764e-05\n",
      "Validation Loss: 5.168789486683482e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 6.835764366769581e-05\n",
      "Training Loss: 5.202579117622008e-05\n",
      "Training Loss: 5.718428657473851e-05\n",
      "Validation Loss: 5.157167493308315e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 6.818716437010153e-05\n",
      "Training Loss: 5.187063721677987e-05\n",
      "Training Loss: 5.7040196238631325e-05\n",
      "Validation Loss: 5.14570127644843e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 6.801882075706089e-05\n",
      "Training Loss: 5.171723306489184e-05\n",
      "Training Loss: 5.689774630354805e-05\n",
      "Validation Loss: 5.134378700480983e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 6.785269987176434e-05\n",
      "Training Loss: 5.156561744570354e-05\n",
      "Training Loss: 5.675716236964945e-05\n",
      "Validation Loss: 5.123210165324605e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 6.768873844066547e-05\n",
      "Training Loss: 5.141569816032643e-05\n",
      "Training Loss: 5.661818286171183e-05\n",
      "Validation Loss: 5.112188155896108e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 6.752683496415557e-05\n",
      "Training Loss: 5.1267519673956485e-05\n",
      "Training Loss: 5.648084962103894e-05\n",
      "Validation Loss: 5.1013097025420034e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 6.736704872764676e-05\n",
      "Training Loss: 5.1121059948400215e-05\n",
      "Training Loss: 5.6345267325923486e-05\n",
      "Validation Loss: 5.0905743857706356e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 6.720933607994084e-05\n",
      "Training Loss: 5.0976292289988126e-05\n",
      "Training Loss: 5.621138182505092e-05\n",
      "Validation Loss: 5.079986543565161e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 6.705367373797343e-05\n",
      "Training Loss: 5.083315861497795e-05\n",
      "Training Loss: 5.607905888609821e-05\n",
      "Validation Loss: 5.06951817013114e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 6.68999738400089e-05\n",
      "Training Loss: 5.069172553930912e-05\n",
      "Training Loss: 5.594839992227208e-05\n",
      "Validation Loss: 5.059218234093984e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 6.674832310636703e-05\n",
      "Training Loss: 5.05519574335267e-05\n",
      "Training Loss: 5.581939343301201e-05\n",
      "Validation Loss: 5.0490499448601494e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 6.659850781034038e-05\n",
      "Training Loss: 5.0413899127761394e-05\n",
      "Training Loss: 5.569190567257465e-05\n",
      "Validation Loss: 5.038996965247841e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 6.645075961387193e-05\n",
      "Training Loss: 5.027739289630517e-05\n",
      "Training Loss: 5.5566078144693166e-05\n",
      "Validation Loss: 5.0290927380925764e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 6.630484616380272e-05\n",
      "Training Loss: 5.0142490699727205e-05\n",
      "Training Loss: 5.544175325212564e-05\n",
      "Validation Loss: 5.01930775948842e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 6.616078435399686e-05\n",
      "Training Loss: 5.0009195293796436e-05\n",
      "Training Loss: 5.531899665129458e-05\n",
      "Validation Loss: 5.009641752499346e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 6.601854802738671e-05\n",
      "Training Loss: 4.987740076103364e-05\n",
      "Training Loss: 5.519778555935772e-05\n",
      "Validation Loss: 5.000115021850045e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 6.587816423461845e-05\n",
      "Training Loss: 4.9747273997127196e-05\n",
      "Training Loss: 5.50779819559466e-05\n",
      "Validation Loss: 4.9907059287199467e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 6.573944877800386e-05\n",
      "Training Loss: 4.961862440609366e-05\n",
      "Training Loss: 5.495969185631111e-05\n",
      "Validation Loss: 4.981422995789738e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 6.560253419138462e-05\n",
      "Training Loss: 4.949145323735138e-05\n",
      "Training Loss: 5.484295857058896e-05\n",
      "Validation Loss: 4.972242895542223e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 6.546731587377508e-05\n",
      "Training Loss: 4.93657433048611e-05\n",
      "Training Loss: 5.472749648106401e-05\n",
      "Validation Loss: 4.963192404932087e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 6.533383870873876e-05\n",
      "Training Loss: 4.924151151726619e-05\n",
      "Training Loss: 5.461351957819716e-05\n",
      "Validation Loss: 4.954235707240452e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 6.520196340261464e-05\n",
      "Training Loss: 4.9118801706526936e-05\n",
      "Training Loss: 5.450086649034347e-05\n",
      "Validation Loss: 4.945393828145396e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 6.507168766574978e-05\n",
      "Training Loss: 4.899742918382799e-05\n",
      "Training Loss: 5.438961010895582e-05\n",
      "Validation Loss: 4.9366633079903857e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 6.49430938324258e-05\n",
      "Training Loss: 4.887744271968586e-05\n",
      "Training Loss: 5.4279706723718846e-05\n",
      "Validation Loss: 4.92803566241614e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 6.481590847215557e-05\n",
      "Training Loss: 4.875885181149897e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [15:38<10:26, 156.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.4171109991330016e-05\n",
      "Validation Loss: 4.919505917815115e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5322212404012681\n",
      "Training Loss: 0.44293069586157796\n",
      "Training Loss: 0.3845992911607027\n",
      "Validation Loss: 0.29133233302429823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.25124514654278757\n",
      "Training Loss: 0.157516708932817\n",
      "Training Loss: 0.10712992276996375\n",
      "Validation Loss: 0.07013857221816865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.061031922330148515\n",
      "Training Loss: 0.048754022647626696\n",
      "Training Loss: 0.04908243734855205\n",
      "Validation Loss: 0.047356097550874346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04369761236011982\n",
      "Training Loss: 0.04038411552552134\n",
      "Training Loss: 0.040433300095610324\n",
      "Validation Loss: 0.038394748651830665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03449084339139517\n",
      "Training Loss: 0.03091540271881968\n",
      "Training Loss: 0.030096002877689897\n",
      "Validation Loss: 0.027937700817612616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.024649978368652226\n",
      "Training Loss: 0.021974644778529184\n",
      "Training Loss: 0.02104551433818415\n",
      "Validation Loss: 0.019356378393373296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.016994755520136094\n",
      "Training Loss: 0.01518200219841674\n",
      "Training Loss: 0.01442368890857324\n",
      "Validation Loss: 0.01326644362546922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01168741771718487\n",
      "Training Loss: 0.010459959832951426\n",
      "Training Loss: 0.009864205912454054\n",
      "Validation Loss: 0.009068772266095693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.007950949878431857\n",
      "Training Loss: 0.0069524911371991035\n",
      "Training Loss: 0.006221847130800598\n",
      "Validation Loss: 0.005317020182905907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.004449265662115068\n",
      "Training Loss: 0.003449989389628172\n",
      "Training Loss: 0.0026271300701773727\n",
      "Validation Loss: 0.0019322168263489004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0015789328970276983\n",
      "Training Loss: 0.001104524812399177\n",
      "Training Loss: 0.0008909280707302969\n",
      "Validation Loss: 0.0008292948796735616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0007756847556811408\n",
      "Training Loss: 0.0006654858983529266\n",
      "Training Loss: 0.0006439511541975662\n",
      "Validation Loss: 0.0006989590547981494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.000648351871768682\n",
      "Training Loss: 0.0005729143336793641\n",
      "Training Loss: 0.0005559443406673381\n",
      "Validation Loss: 0.0006279003037286273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0005678111218003323\n",
      "Training Loss: 0.0005014403932727873\n",
      "Training Loss: 0.000482127569775912\n",
      "Validation Loss: 0.0005615232392996445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0005001259045820917\n",
      "Training Loss: 0.0004401430586949573\n",
      "Training Loss: 0.00041964332915085835\n",
      "Validation Loss: 0.0004989442942347482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0004431108466087608\n",
      "Training Loss: 0.00038841454883367985\n",
      "Training Loss: 0.0003683218136575306\n",
      "Validation Loss: 0.0004417723239487131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00039590615255292506\n",
      "Training Loss: 0.0003456310285400832\n",
      "Training Loss: 0.000327191489705001\n",
      "Validation Loss: 0.0003913539292400682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0003574289295647759\n",
      "Training Loss: 0.00031073418002051765\n",
      "Training Loss: 0.0002947394603324938\n",
      "Validation Loss: 0.00034806463828430056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00032632782495056745\n",
      "Training Loss: 0.0002824130623957899\n",
      "Training Loss: 0.0002692547515107435\n",
      "Validation Loss: 0.0003115441454150989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.0003011919316850253\n",
      "Training Loss: 0.00025935276547897954\n",
      "Training Loss: 0.0002491159016426536\n",
      "Validation Loss: 0.0002810810723265481\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0002807255439620349\n",
      "Training Loss: 0.00024038733965426218\n",
      "Training Loss: 0.00023294870472454933\n",
      "Validation Loss: 0.0002558526042714752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0002638375698734308\n",
      "Training Loss: 0.00022456215821875958\n",
      "Training Loss: 0.0002196791525784647\n",
      "Validation Loss: 0.0002350161251066883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0002496607667490025\n",
      "Training Loss: 0.00021113419830726343\n",
      "Training Loss: 0.0002085133851505816\n",
      "Validation Loss: 0.00021777104040993027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00023753268640575698\n",
      "Training Loss: 0.0001995404458102712\n",
      "Training Loss: 0.00019888359118340305\n",
      "Validation Loss: 0.00020339586585629312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0002269584225359722\n",
      "Training Loss: 0.00018935908628918695\n",
      "Training Loss: 0.00019039004258956992\n",
      "Validation Loss: 0.00019127518823828152\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00021757103084382834\n",
      "Training Loss: 0.00018027471509412862\n",
      "Training Loss: 0.000182750627900532\n",
      "Validation Loss: 0.00018090793839312458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00020909820190354367\n",
      "Training Loss: 0.0001720516300338204\n",
      "Training Loss: 0.0001757655670189706\n",
      "Validation Loss: 0.00017190120516726197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00020133641017309857\n",
      "Training Loss: 0.00016451243896881351\n",
      "Training Loss: 0.00016929142746448632\n",
      "Validation Loss: 0.00016395297480107474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00019413309424635373\n",
      "Training Loss: 0.00015752608695038362\n",
      "Training Loss: 0.00016322570172633277\n",
      "Validation Loss: 0.00015683636329515466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00018737588527073968\n",
      "Training Loss: 0.00015099609884600796\n",
      "Training Loss: 0.00015749649670397049\n",
      "Validation Loss: 0.0001503817577767212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0001809831741047674\n",
      "Training Loss: 0.00014485461077129002\n",
      "Training Loss: 0.0001520546420942992\n",
      "Validation Loss: 0.00014446589207846351\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00017489856283646078\n",
      "Training Loss: 0.0001390553248802462\n",
      "Training Loss: 0.00014686910413729492\n",
      "Validation Loss: 0.00013899954434093794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0001690855716879014\n",
      "Training Loss: 0.00013356837946048471\n",
      "Training Loss: 0.0001419219070521649\n",
      "Validation Loss: 0.0001339189109356166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00016352293509044102\n",
      "Training Loss: 0.00012837616238357442\n",
      "Training Loss: 0.0001372039989746554\n",
      "Validation Loss: 0.0001291787476894273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00015820019461898482\n",
      "Training Loss: 0.00012346845155661868\n",
      "Training Loss: 0.0001327126636169851\n",
      "Validation Loss: 0.00012474779800817324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.000153114426866523\n",
      "Training Loss: 0.00011883938456776377\n",
      "Training Loss: 0.000128447771021456\n",
      "Validation Loss: 0.0001206031476327001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00014826711047135176\n",
      "Training Loss: 0.00011448508705143468\n",
      "Training Loss: 0.00012441078107258363\n",
      "Validation Loss: 0.00011672835050754412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00014366132651048248\n",
      "Training Loss: 0.00011040182684155298\n",
      "Training Loss: 0.00012060271459631622\n",
      "Validation Loss: 0.00011311052080958015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00013930099245953897\n",
      "Training Loss: 0.00010658547391358297\n",
      "Training Loss: 0.00011702323329700448\n",
      "Validation Loss: 0.00010973848582559666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00013518807780201313\n",
      "Training Loss: 0.00010302952601705329\n",
      "Training Loss: 0.00011366999369784025\n",
      "Validation Loss: 0.0001066015164611967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00013132262260114657\n",
      "Training Loss: 9.972659831873898e-05\n",
      "Training Loss: 0.00011053902215280687\n",
      "Validation Loss: 0.00010368879337762705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.000127702521494939\n",
      "Training Loss: 9.666690129051858e-05\n",
      "Training Loss: 0.00010762382525172143\n",
      "Validation Loss: 0.000100989128839685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00012432290584911244\n",
      "Training Loss: 9.38393443084351e-05\n",
      "Training Loss: 0.00010491625962458784\n",
      "Validation Loss: 9.849090277006571e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00012117616485738835\n",
      "Training Loss: 9.12315921186746e-05\n",
      "Training Loss: 0.000102406713176606\n",
      "Validation Loss: 9.618162783206142e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00011825297410723578\n",
      "Training Loss: 8.883029835033085e-05\n",
      "Training Loss: 0.00010008373569689866\n",
      "Validation Loss: 9.404840737547244e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00011554191333743801\n",
      "Training Loss: 8.662130890570552e-05\n",
      "Training Loss: 9.793572915441473e-05\n",
      "Validation Loss: 9.207863759717399e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00011303060619866301\n",
      "Training Loss: 8.459045008748944e-05\n",
      "Training Loss: 9.595026427632547e-05\n",
      "Validation Loss: 9.025920869819683e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00011070561211454333\n",
      "Training Loss: 8.272359487364156e-05\n",
      "Training Loss: 9.41149185746326e-05\n",
      "Validation Loss: 8.857749339205859e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00010855354325940425\n",
      "Training Loss: 8.100668046154169e-05\n",
      "Training Loss: 9.241715825737629e-05\n",
      "Validation Loss: 8.702106754171428e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00010656044163624756\n",
      "Training Loss: 7.942645786897629e-05\n",
      "Training Loss: 9.084516175789759e-05\n",
      "Validation Loss: 8.557932542214657e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00010471335461261333\n",
      "Training Loss: 7.797016737185913e-05\n",
      "Training Loss: 8.938748675063835e-05\n",
      "Validation Loss: 8.424069108698174e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00010299957329152675\n",
      "Training Loss: 7.662610561510518e-05\n",
      "Training Loss: 8.803356630778581e-05\n",
      "Validation Loss: 8.29955868672248e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00010140707303889939\n",
      "Training Loss: 7.53830991425275e-05\n",
      "Training Loss: 8.677328571138788e-05\n",
      "Validation Loss: 8.183459818467505e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 9.992469431381323e-05\n",
      "Training Loss: 7.423109257160831e-05\n",
      "Training Loss: 8.559757275179436e-05\n",
      "Validation Loss: 8.07492827467347e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 9.854206125964993e-05\n",
      "Training Loss: 7.316080998407415e-05\n",
      "Training Loss: 8.449809485682635e-05\n",
      "Validation Loss: 7.97323130867104e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 9.724978961457964e-05\n",
      "Training Loss: 7.216405207600473e-05\n",
      "Training Loss: 8.346728528522362e-05\n",
      "Validation Loss: 7.877687859659448e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 9.603935222457949e-05\n",
      "Training Loss: 7.123309067083027e-05\n",
      "Training Loss: 8.24982222638937e-05\n",
      "Validation Loss: 7.787618455387949e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 9.490270581409277e-05\n",
      "Training Loss: 7.036124292881141e-05\n",
      "Training Loss: 8.158487134096504e-05\n",
      "Validation Loss: 7.702577071479559e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 9.383303528011311e-05\n",
      "Training Loss: 6.954244663575082e-05\n",
      "Training Loss: 8.072164651821367e-05\n",
      "Validation Loss: 7.62199997399385e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 9.282383803565608e-05\n",
      "Training Loss: 6.87712137823837e-05\n",
      "Training Loss: 7.990380593582814e-05\n",
      "Validation Loss: 7.545474176204357e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 9.186961052819243e-05\n",
      "Training Loss: 6.80428502664654e-05\n",
      "Training Loss: 7.912701372333686e-05\n",
      "Validation Loss: 7.472624054244488e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 9.096507181766356e-05\n",
      "Training Loss: 6.735310059411858e-05\n",
      "Training Loss: 7.83873548516567e-05\n",
      "Validation Loss: 7.403123899156311e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 9.010603665956297e-05\n",
      "Training Loss: 6.669826630059105e-05\n",
      "Training Loss: 7.768143639623304e-05\n",
      "Validation Loss: 7.336638698566429e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 8.92884180530018e-05\n",
      "Training Loss: 6.607491460727034e-05\n",
      "Training Loss: 7.700632389060047e-05\n",
      "Validation Loss: 7.272931968523818e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 8.850863078350812e-05\n",
      "Training Loss: 6.54801442851749e-05\n",
      "Training Loss: 7.635938561179501e-05\n",
      "Validation Loss: 7.211749580369286e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 8.776338215284341e-05\n",
      "Training Loss: 6.49114750467561e-05\n",
      "Training Loss: 7.573812481496134e-05\n",
      "Validation Loss: 7.152920598150303e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 8.705006811396743e-05\n",
      "Training Loss: 6.436650738578465e-05\n",
      "Training Loss: 7.514062020163692e-05\n",
      "Validation Loss: 7.096198071573444e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 8.636597072836594e-05\n",
      "Training Loss: 6.384328146850748e-05\n",
      "Training Loss: 7.456508762516024e-05\n",
      "Validation Loss: 7.041461359743184e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 8.570896750370594e-05\n",
      "Training Loss: 6.333995761906408e-05\n",
      "Training Loss: 7.400983000479755e-05\n",
      "Validation Loss: 6.988575534010993e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 8.50771836394415e-05\n",
      "Training Loss: 6.285499051955412e-05\n",
      "Training Loss: 7.347337250394049e-05\n",
      "Validation Loss: 6.937371048724947e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 8.446853975783597e-05\n",
      "Training Loss: 6.238698756533267e-05\n",
      "Training Loss: 7.295455703570042e-05\n",
      "Validation Loss: 6.887769169746238e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 8.388168641886296e-05\n",
      "Training Loss: 6.193468133915303e-05\n",
      "Training Loss: 7.245223106110644e-05\n",
      "Validation Loss: 6.839634585212275e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 8.331493452715222e-05\n",
      "Training Loss: 6.149706289306777e-05\n",
      "Training Loss: 7.196544918770088e-05\n",
      "Validation Loss: 6.792885403300399e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 8.276730200122984e-05\n",
      "Training Loss: 6.107300368967117e-05\n",
      "Training Loss: 7.149329157073225e-05\n",
      "Validation Loss: 6.74747068055541e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 8.223753801757994e-05\n",
      "Training Loss: 6.066173563340271e-05\n",
      "Training Loss: 7.10348385018733e-05\n",
      "Validation Loss: 6.703277358610649e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 8.172453266070079e-05\n",
      "Training Loss: 6.026258378824423e-05\n",
      "Training Loss: 7.058958996822184e-05\n",
      "Validation Loss: 6.660296500914239e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 8.122740047838305e-05\n",
      "Training Loss: 5.9874500625483054e-05\n",
      "Training Loss: 7.015674781541747e-05\n",
      "Validation Loss: 6.618374636877633e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 8.074532468981488e-05\n",
      "Training Loss: 5.949725384652993e-05\n",
      "Training Loss: 6.973590149755182e-05\n",
      "Validation Loss: 6.577519339832557e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 8.027755853618146e-05\n",
      "Training Loss: 5.913000935379387e-05\n",
      "Training Loss: 6.932643147138151e-05\n",
      "Validation Loss: 6.537687475204447e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 7.982346835888165e-05\n",
      "Training Loss: 5.8772492748175866e-05\n",
      "Training Loss: 6.89278197933163e-05\n",
      "Validation Loss: 6.4988113668794e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 7.938220229789295e-05\n",
      "Training Loss: 5.8424100075171737e-05\n",
      "Training Loss: 6.853973248780675e-05\n",
      "Validation Loss: 6.46085857144417e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 7.895344981989183e-05\n",
      "Training Loss: 5.80843980105783e-05\n",
      "Training Loss: 6.816181722115289e-05\n",
      "Validation Loss: 6.423803306767767e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 7.853663252262778e-05\n",
      "Training Loss: 5.775314042693935e-05\n",
      "Training Loss: 6.779349128009926e-05\n",
      "Validation Loss: 6.387596627217625e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 7.813112052190263e-05\n",
      "Training Loss: 5.742989752889116e-05\n",
      "Training Loss: 6.743468616150494e-05\n",
      "Validation Loss: 6.352204929008325e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 7.773655509026866e-05\n",
      "Training Loss: 5.711433655960718e-05\n",
      "Training Loss: 6.70848702384319e-05\n",
      "Validation Loss: 6.317614004606338e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 7.735251699159563e-05\n",
      "Training Loss: 5.680617600319238e-05\n",
      "Training Loss: 6.674383560039132e-05\n",
      "Validation Loss: 6.283788377075918e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 7.697852343881095e-05\n",
      "Training Loss: 5.65052079355155e-05\n",
      "Training Loss: 6.641125777150592e-05\n",
      "Validation Loss: 6.25067482820321e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 7.661430804546398e-05\n",
      "Training Loss: 5.621118760245736e-05\n",
      "Training Loss: 6.608691579458537e-05\n",
      "Validation Loss: 6.218282902062108e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 7.62595630112628e-05\n",
      "Training Loss: 5.592376006916311e-05\n",
      "Training Loss: 6.577059319624823e-05\n",
      "Validation Loss: 6.186613709462436e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 7.591375144329504e-05\n",
      "Training Loss: 5.564277518715244e-05\n",
      "Training Loss: 6.546189109940314e-05\n",
      "Validation Loss: 6.155571865869962e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 7.557679181445565e-05\n",
      "Training Loss: 5.536803889754083e-05\n",
      "Training Loss: 6.516071751320851e-05\n",
      "Validation Loss: 6.125191683760646e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 7.524820278376865e-05\n",
      "Training Loss: 5.5099316714404264e-05\n",
      "Training Loss: 6.486673230938323e-05\n",
      "Validation Loss: 6.095465038996419e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 7.492782019198785e-05\n",
      "Training Loss: 5.483638814439473e-05\n",
      "Training Loss: 6.457967939240916e-05\n",
      "Validation Loss: 6.0663073690081006e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 7.461518699983572e-05\n",
      "Training Loss: 5.4579194215875757e-05\n",
      "Training Loss: 6.429950676647422e-05\n",
      "Validation Loss: 6.037779421399392e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 7.431012001234194e-05\n",
      "Training Loss: 5.4327439088410756e-05\n",
      "Training Loss: 6.402587586308072e-05\n",
      "Validation Loss: 6.009797644775277e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 7.401238678539813e-05\n",
      "Training Loss: 5.4081027033134885e-05\n",
      "Training Loss: 6.375859151376062e-05\n",
      "Validation Loss: 5.982397702058059e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 7.372172575742297e-05\n",
      "Training Loss: 5.383975895256299e-05\n",
      "Training Loss: 6.349744713588734e-05\n",
      "Validation Loss: 5.9555041981807694e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 7.343779272105167e-05\n",
      "Training Loss: 5.360345685403445e-05\n",
      "Training Loss: 6.324226254037058e-05\n",
      "Validation Loss: 5.929162901675942e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 7.316051414818503e-05\n",
      "Training Loss: 5.337197555491002e-05\n",
      "Training Loss: 6.299278735241387e-05\n",
      "Validation Loss: 5.9033225630280846e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 7.288951464488491e-05\n",
      "Training Loss: 5.31452062250537e-05\n",
      "Training Loss: 6.274891609336919e-05\n",
      "Validation Loss: 5.878005461280726e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 7.262464308951167e-05\n",
      "Training Loss: 5.292293469210563e-05\n",
      "Training Loss: 6.25103502670754e-05\n",
      "Validation Loss: 5.853164979720879e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 7.236558409204008e-05\n",
      "Training Loss: 5.270503836982243e-05\n",
      "Training Loss: 6.22769319352301e-05\n",
      "Validation Loss: 5.828768040843765e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 7.211219543933112e-05\n",
      "Training Loss: 5.2491419983198287e-05\n",
      "Training Loss: 6.204861655078276e-05\n",
      "Validation Loss: 5.804826345962958e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 7.186421591541147e-05\n",
      "Training Loss: 5.2281852208579946e-05\n",
      "Training Loss: 6.182509478549037e-05\n",
      "Validation Loss: 5.781342773782475e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 7.162145990150747e-05\n",
      "Training Loss: 5.2076298252359266e-05\n",
      "Training Loss: 6.160627287954412e-05\n",
      "Validation Loss: 5.758262396953756e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 7.138381851291342e-05\n",
      "Training Loss: 5.1874651926482326e-05\n",
      "Training Loss: 6.139186871678248e-05\n",
      "Validation Loss: 5.7356022889405396e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 7.115106233413825e-05\n",
      "Training Loss: 5.1676631105692646e-05\n",
      "Training Loss: 6.118185098785033e-05\n",
      "Validation Loss: 5.7133749210611875e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 7.092294954873068e-05\n",
      "Training Loss: 5.148227495283209e-05\n",
      "Training Loss: 6.097600334214803e-05\n",
      "Validation Loss: 5.6915112585802185e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 7.069927346947224e-05\n",
      "Training Loss: 5.129136503455811e-05\n",
      "Training Loss: 6.0774230305469246e-05\n",
      "Validation Loss: 5.670045564922189e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 7.047995277844166e-05\n",
      "Training Loss: 5.1103816540489786e-05\n",
      "Training Loss: 6.057623311789939e-05\n",
      "Validation Loss: 5.648928756497472e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 7.026481612683711e-05\n",
      "Training Loss: 5.091955109492119e-05\n",
      "Training Loss: 6.038210035967495e-05\n",
      "Validation Loss: 5.6281633339055454e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 7.005367952842789e-05\n",
      "Training Loss: 5.0738402487695564e-05\n",
      "Training Loss: 6.0191575130374986e-05\n",
      "Validation Loss: 5.6077682212785834e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 6.984644277963526e-05\n",
      "Training Loss: 5.056034339304461e-05\n",
      "Training Loss: 6.00044074417383e-05\n",
      "Validation Loss: 5.5877041820954374e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 6.96428714081776e-05\n",
      "Training Loss: 5.038514992975252e-05\n",
      "Training Loss: 5.982075280371646e-05\n",
      "Validation Loss: 5.567987710911142e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 6.944286751604522e-05\n",
      "Training Loss: 5.021287187446433e-05\n",
      "Training Loss: 5.964026059245953e-05\n",
      "Validation Loss: 5.548570208518643e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 6.924631219817456e-05\n",
      "Training Loss: 5.004324146739236e-05\n",
      "Training Loss: 5.946292842963885e-05\n",
      "Validation Loss: 5.5294296344890314e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 6.905305447389765e-05\n",
      "Training Loss: 4.9876338575813864e-05\n",
      "Training Loss: 5.9288651546012264e-05\n",
      "Validation Loss: 5.510643035286398e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 6.886294743935651e-05\n",
      "Training Loss: 4.9711975443642586e-05\n",
      "Training Loss: 5.9117137338944304e-05\n",
      "Validation Loss: 5.492094392087729e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 6.867597694508732e-05\n",
      "Training Loss: 4.9550118510524045e-05\n",
      "Training Loss: 5.8948511218659404e-05\n",
      "Validation Loss: 5.47388064374348e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 6.849191696119306e-05\n",
      "Training Loss: 4.939057683714054e-05\n",
      "Training Loss: 5.8782515270650035e-05\n",
      "Validation Loss: 5.4559155251921396e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 6.831064760035588e-05\n",
      "Training Loss: 4.923340603454562e-05\n",
      "Training Loss: 5.8619231995180596e-05\n",
      "Validation Loss: 5.4382316489720955e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 6.813212320366802e-05\n",
      "Training Loss: 4.907849641767825e-05\n",
      "Training Loss: 5.84584170837843e-05\n",
      "Validation Loss: 5.4207830150895215e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 6.795628201643921e-05\n",
      "Training Loss: 4.8925696846708887e-05\n",
      "Training Loss: 5.830001335198176e-05\n",
      "Validation Loss: 5.403570001648956e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 6.778294111427386e-05\n",
      "Training Loss: 4.877498324731278e-05\n",
      "Training Loss: 5.814399924474856e-05\n",
      "Validation Loss: 5.386635188331005e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 6.761203671430849e-05\n",
      "Training Loss: 4.862629734816437e-05\n",
      "Training Loss: 5.7990173777398015e-05\n",
      "Validation Loss: 5.369944287696363e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 6.744351599763832e-05\n",
      "Training Loss: 4.8479582314939765e-05\n",
      "Training Loss: 5.7838529241962535e-05\n",
      "Validation Loss: 5.353426895147023e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 6.727723167159638e-05\n",
      "Training Loss: 4.833472924019589e-05\n",
      "Training Loss: 5.768905567947513e-05\n",
      "Validation Loss: 5.3372126228751264e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 6.71130988234836e-05\n",
      "Training Loss: 4.819175439479295e-05\n",
      "Training Loss: 5.7541563128324926e-05\n",
      "Validation Loss: 5.321140090242981e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 6.695111937233378e-05\n",
      "Training Loss: 4.805044248996637e-05\n",
      "Training Loss: 5.7396011861783336e-05\n",
      "Validation Loss: 5.3053271825815446e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 6.679113915652124e-05\n",
      "Training Loss: 4.791094796246398e-05\n",
      "Training Loss: 5.725244211589598e-05\n",
      "Validation Loss: 5.289693351361176e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 6.663314250317854e-05\n",
      "Training Loss: 4.777308339271258e-05\n",
      "Training Loss: 5.711065233299451e-05\n",
      "Validation Loss: 5.274272876867849e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 6.647709332128216e-05\n",
      "Training Loss: 4.763683574083188e-05\n",
      "Training Loss: 5.697072408111126e-05\n",
      "Validation Loss: 5.25903506621014e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 6.632286361536899e-05\n",
      "Training Loss: 4.750211691089135e-05\n",
      "Training Loss: 5.683241487076884e-05\n",
      "Validation Loss: 5.2439837392657966e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 6.61703224568555e-05\n",
      "Training Loss: 4.736892075470678e-05\n",
      "Training Loss: 5.669583725193661e-05\n",
      "Validation Loss: 5.229124226031437e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 6.60196181684114e-05\n",
      "Training Loss: 4.7237180547199385e-05\n",
      "Training Loss: 5.65608572014753e-05\n",
      "Validation Loss: 5.214453083711949e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 6.587049051177019e-05\n",
      "Training Loss: 4.710692208391265e-05\n",
      "Training Loss: 5.6427458648613534e-05\n",
      "Validation Loss: 5.1999685906543e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 6.572301237383726e-05\n",
      "Training Loss: 4.6977968611372487e-05\n",
      "Training Loss: 5.629552078062261e-05\n",
      "Validation Loss: 5.1855831878108374e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 6.557699182167198e-05\n",
      "Training Loss: 4.68503940805931e-05\n",
      "Training Loss: 5.6165155792768926e-05\n",
      "Validation Loss: 5.1713972154400096e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 6.543253425434159e-05\n",
      "Training Loss: 4.672405059636731e-05\n",
      "Training Loss: 5.603610251455393e-05\n",
      "Validation Loss: 5.157380170469091e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 6.528951155360119e-05\n",
      "Training Loss: 4.659905143171272e-05\n",
      "Training Loss: 5.5908553908921023e-05\n",
      "Validation Loss: 5.1435257584794116e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 6.514795448310906e-05\n",
      "Training Loss: 4.6475226336042395e-05\n",
      "Training Loss: 5.578232190146082e-05\n",
      "Validation Loss: 5.129809268806496e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 6.500774275991717e-05\n",
      "Training Loss: 4.635261979274219e-05\n",
      "Training Loss: 5.5657309690104737e-05\n",
      "Validation Loss: 5.1162444698205576e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 6.486882750550649e-05\n",
      "Training Loss: 4.623118121116931e-05\n",
      "Training Loss: 5.5533620661663007e-05\n",
      "Validation Loss: 5.102828815447384e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 6.473123951764137e-05\n",
      "Training Loss: 4.6110845942166635e-05\n",
      "Training Loss: 5.541125556192128e-05\n",
      "Validation Loss: 5.0895516344527925e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 6.459488938389768e-05\n",
      "Training Loss: 4.5991653034889165e-05\n",
      "Training Loss: 5.529005081825744e-05\n",
      "Validation Loss: 5.076420866265671e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 6.445982478226142e-05\n",
      "Training Loss: 4.587353368151525e-05\n",
      "Training Loss: 5.5169944366753044e-05\n",
      "Validation Loss: 5.0634127265776656e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 6.432581942817705e-05\n",
      "Training Loss: 4.575643508360372e-05\n",
      "Training Loss: 5.505105988504511e-05\n",
      "Validation Loss: 5.050534255797481e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 6.419306340376352e-05\n",
      "Training Loss: 4.5640372275101984e-05\n",
      "Training Loss: 5.493330626904935e-05\n",
      "Validation Loss: 5.03779376149498e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 6.406139259752308e-05\n",
      "Training Loss: 4.552524799692037e-05\n",
      "Training Loss: 5.4816649399072045e-05\n",
      "Validation Loss: 5.0251778058859444e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 6.393087086962623e-05\n",
      "Training Loss: 4.541113235063676e-05\n",
      "Training Loss: 5.4700980613233696e-05\n",
      "Validation Loss: 5.0126796426145906e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 6.380141567660758e-05\n",
      "Training Loss: 4.529794639665852e-05\n",
      "Training Loss: 5.4586341611866374e-05\n",
      "Validation Loss: 5.0003062801551186e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 6.367298722580017e-05\n",
      "Training Loss: 4.518574512530904e-05\n",
      "Training Loss: 5.447274671951163e-05\n",
      "Validation Loss: 4.988052300882629e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 6.35455872543389e-05\n",
      "Training Loss: 4.507439321514539e-05\n",
      "Training Loss: 5.43601952449535e-05\n",
      "Validation Loss: 4.9759035289426216e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 6.341917278405163e-05\n",
      "Training Loss: 4.496399936670059e-05\n",
      "Training Loss: 5.424861182063978e-05\n",
      "Validation Loss: 4.963866145577883e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 6.329377270276381e-05\n",
      "Training Loss: 4.485441285851266e-05\n",
      "Training Loss: 5.413790369402705e-05\n",
      "Validation Loss: 4.9519566813655675e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 6.316928082242157e-05\n",
      "Training Loss: 4.474570818047141e-05\n",
      "Training Loss: 5.402816796731713e-05\n",
      "Validation Loss: 4.940135875003353e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 6.304570691099798e-05\n",
      "Training Loss: 4.4637843191139834e-05\n",
      "Training Loss: 5.391935449324592e-05\n",
      "Validation Loss: 4.928439303573592e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 6.292314962365709e-05\n",
      "Training Loss: 4.453078224969431e-05\n",
      "Training Loss: 5.381151257097372e-05\n",
      "Validation Loss: 4.916842118199271e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 6.280144147694955e-05\n",
      "Training Loss: 4.4424510297176314e-05\n",
      "Training Loss: 5.370436981138482e-05\n",
      "Validation Loss: 4.905345842284016e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 6.268058690011457e-05\n",
      "Training Loss: 4.431912755308076e-05\n",
      "Training Loss: 5.359825664299933e-05\n",
      "Validation Loss: 4.8939700184674936e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 6.256065072875572e-05\n",
      "Training Loss: 4.421444332365354e-05\n",
      "Training Loss: 5.349287798253499e-05\n",
      "Validation Loss: 4.882692112485611e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 6.244154329351659e-05\n",
      "Training Loss: 4.411053811509191e-05\n",
      "Training Loss: 5.3388336757507206e-05\n",
      "Validation Loss: 4.871466456463392e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 6.232328958049038e-05\n",
      "Training Loss: 4.4007344690726314e-05\n",
      "Training Loss: 5.328462750640028e-05\n",
      "Validation Loss: 4.8603803984252825e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 6.220585047003624e-05\n",
      "Training Loss: 4.390498637576457e-05\n",
      "Training Loss: 5.318176631590177e-05\n",
      "Validation Loss: 4.849377093930517e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 6.208924033899166e-05\n",
      "Training Loss: 4.3803296641726774e-05\n",
      "Training Loss: 5.3079662295658635e-05\n",
      "Validation Loss: 4.8384620512979896e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 6.197343460371484e-05\n",
      "Training Loss: 4.370236974409636e-05\n",
      "Training Loss: 5.297838167507507e-05\n",
      "Validation Loss: 4.8276642435544246e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 6.185837892644486e-05\n",
      "Training Loss: 4.360208172329294e-05\n",
      "Training Loss: 5.287783423455039e-05\n",
      "Validation Loss: 4.8169290851782016e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 6.174416433623265e-05\n",
      "Training Loss: 4.350254580231194e-05\n",
      "Training Loss: 5.2777996427266774e-05\n",
      "Validation Loss: 4.8063031522616166e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 6.163065895634646e-05\n",
      "Training Loss: 4.340367985605553e-05\n",
      "Training Loss: 5.26789357945745e-05\n",
      "Validation Loss: 4.795757891269603e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 6.151795840196428e-05\n",
      "Training Loss: 4.330550052145554e-05\n",
      "Training Loss: 5.2580639617190174e-05\n",
      "Validation Loss: 4.785286639387042e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 6.140597912917655e-05\n",
      "Training Loss: 4.3208024735577055e-05\n",
      "Training Loss: 5.2483076106000224e-05\n",
      "Validation Loss: 4.7749282606510154e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 6.129473005330511e-05\n",
      "Training Loss: 4.311123473144107e-05\n",
      "Training Loss: 5.238624582489138e-05\n",
      "Validation Loss: 4.764628441110933e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 6.11842492753567e-05\n",
      "Training Loss: 4.3015040466798383e-05\n",
      "Training Loss: 5.22900458759068e-05\n",
      "Validation Loss: 4.754418674831081e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 6.107443868131667e-05\n",
      "Training Loss: 4.291954811833421e-05\n",
      "Training Loss: 5.2194590921317285e-05\n",
      "Validation Loss: 4.7443044379403716e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 6.096548967434501e-05\n",
      "Training Loss: 4.282472096747369e-05\n",
      "Training Loss: 5.209979458868474e-05\n",
      "Validation Loss: 4.7342655846202096e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 6.08571661609858e-05\n",
      "Training Loss: 4.273049562698361e-05\n",
      "Training Loss: 5.200577484401947e-05\n",
      "Validation Loss: 4.7243117228135e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 6.074958064573366e-05\n",
      "Training Loss: 4.263689991148567e-05\n",
      "Training Loss: 5.1912350127167887e-05\n",
      "Validation Loss: 4.714439028554879e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 6.064260511720932e-05\n",
      "Training Loss: 4.2543928896066066e-05\n",
      "Training Loss: 5.181961112612043e-05\n",
      "Validation Loss: 4.704661004264002e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 6.053642693359507e-05\n",
      "Training Loss: 4.245162408778924e-05\n",
      "Training Loss: 5.172752163161931e-05\n",
      "Validation Loss: 4.6949363532609384e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 6.043090038247101e-05\n",
      "Training Loss: 4.2359921058050534e-05\n",
      "Training Loss: 5.163617052403424e-05\n",
      "Validation Loss: 4.6852817517441856e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 6.03259939362033e-05\n",
      "Training Loss: 4.22688718003883e-05\n",
      "Training Loss: 5.154543061053118e-05\n",
      "Validation Loss: 4.6757128407233305e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 6.0221831711260164e-05\n",
      "Training Loss: 4.217837579517436e-05\n",
      "Training Loss: 5.1455303721468224e-05\n",
      "Validation Loss: 4.6662215821557316e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 6.011836179595775e-05\n",
      "Training Loss: 4.208854900525694e-05\n",
      "Training Loss: 5.136584592719373e-05\n",
      "Validation Loss: 4.656824601144681e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 6.001556905857797e-05\n",
      "Training Loss: 4.199929263677404e-05\n",
      "Training Loss: 5.1277084210141766e-05\n",
      "Validation Loss: 4.647488324817357e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 5.991345832171646e-05\n",
      "Training Loss: 4.19106374056355e-05\n",
      "Training Loss: 5.118882077340459e-05\n",
      "Validation Loss: 4.638214108985103e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 5.98118870016151e-05\n",
      "Training Loss: 4.182262393669589e-05\n",
      "Training Loss: 5.110123537861e-05\n",
      "Validation Loss: 4.6290247911620715e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 5.971109990014156e-05\n",
      "Training Loss: 4.1735164195415564e-05\n",
      "Training Loss: 5.1014288610531365e-05\n",
      "Validation Loss: 4.619913762438587e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 5.9610904575038145e-05\n",
      "Training Loss: 4.1648288718079126e-05\n",
      "Training Loss: 5.092791972856503e-05\n",
      "Validation Loss: 4.6108532561457864e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 5.951137446118082e-05\n",
      "Training Loss: 4.156205518711431e-05\n",
      "Training Loss: 5.084215596752983e-05\n",
      "Validation Loss: 4.601877449357325e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 5.9412550265278696e-05\n",
      "Training Loss: 4.1476388817045516e-05\n",
      "Training Loss: 5.0757058186263745e-05\n",
      "Validation Loss: 4.5929718305231884e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 5.931423409947456e-05\n",
      "Training Loss: 4.1391318488877006e-05\n",
      "Training Loss: 5.067257069867992e-05\n",
      "Validation Loss: 4.584132998235382e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 5.9216766064764667e-05\n",
      "Training Loss: 4.13067879526352e-05\n",
      "Training Loss: 5.058860110693786e-05\n",
      "Validation Loss: 4.5753681878308314e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 5.911978355698011e-05\n",
      "Training Loss: 4.122287419249915e-05\n",
      "Training Loss: 5.050527025787233e-05\n",
      "Validation Loss: 4.566675985760606e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 5.9023458079536794e-05\n",
      "Training Loss: 4.1139515140002914e-05\n",
      "Training Loss: 5.042254580530425e-05\n",
      "Validation Loss: 4.558051459804283e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 5.892784250590921e-05\n",
      "Training Loss: 4.105675929849895e-05\n",
      "Training Loss: 5.0340383961611226e-05\n",
      "Validation Loss: 4.5494694644771644e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 5.8832760603308996e-05\n",
      "Training Loss: 4.097456564522872e-05\n",
      "Training Loss: 5.025876973149934e-05\n",
      "Validation Loss: 4.5409830381379765e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 5.8738405020903886e-05\n",
      "Training Loss: 4.089296680376719e-05\n",
      "Training Loss: 5.017782717004593e-05\n",
      "Validation Loss: 4.532553581933764e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 5.8644645357617264e-05\n",
      "Training Loss: 4.08118969789939e-05\n",
      "Training Loss: 5.009737509453771e-05\n",
      "Validation Loss: 4.5242124890157784e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 5.855150643810703e-05\n",
      "Training Loss: 4.073148621955625e-05\n",
      "Training Loss: 5.001751241024976e-05\n",
      "Validation Loss: 4.5158990309410204e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 5.845893040941519e-05\n",
      "Training Loss: 4.065153199007909e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [18:15<07:49, 156.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.99382362841061e-05\n",
      "Validation Loss: 4.5076643767500307e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.05475916323717683\n",
      "Training Loss: 0.048480663057416676\n",
      "Training Loss: 0.047276290571317076\n",
      "Validation Loss: 0.043147843121812586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.03920330994005781\n",
      "Training Loss: 0.033611341402865945\n",
      "Training Loss: 0.03232106330804527\n",
      "Validation Loss: 0.02938461626534549\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.02559911419979471\n",
      "Training Loss: 0.02145523331244476\n",
      "Training Loss: 0.020623951056040823\n",
      "Validation Loss: 0.020266684924587188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.01703328313509701\n",
      "Training Loss: 0.013919462769990787\n",
      "Training Loss: 0.01324475764296949\n",
      "Validation Loss: 0.013699857655420816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.011278077132628824\n",
      "Training Loss: 0.00882245331275044\n",
      "Training Loss: 0.008224898045882582\n",
      "Validation Loss: 0.008987626062151505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.007218677001073957\n",
      "Training Loss: 0.005365631972599658\n",
      "Training Loss: 0.00490891135588754\n",
      "Validation Loss: 0.005839507099766849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.004494492441735929\n",
      "Training Loss: 0.0031959575199289247\n",
      "Training Loss: 0.002921401791245444\n",
      "Validation Loss: 0.003900124678182876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.002823985887225717\n",
      "Training Loss: 0.001979342061677016\n",
      "Training Loss: 0.0018450043456687125\n",
      "Validation Loss: 0.002760612894715532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.001880930421029916\n",
      "Training Loss: 0.0013478411169489846\n",
      "Training Loss: 0.0012838808512606193\n",
      "Validation Loss: 0.0020767040816812615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.0013621679369680351\n",
      "Training Loss: 0.0010220099563593976\n",
      "Training Loss: 0.000983658267359715\n",
      "Validation Loss: 0.0016391699314277667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0010700183392327745\n",
      "Training Loss: 0.0008474275324260816\n",
      "Training Loss: 0.0008149733106256463\n",
      "Validation Loss: 0.001338710872271017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0008972621148859617\n",
      "Training Loss: 0.0007471846696716966\n",
      "Training Loss: 0.000713706407987047\n",
      "Validation Loss: 0.0011200479013005564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.000787491182127269\n",
      "Training Loss: 0.00068254233301559\n",
      "Training Loss: 0.0006465855777059914\n",
      "Validation Loss: 0.000955270613640811\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0007108729204628616\n",
      "Training Loss: 0.0006343611382908421\n",
      "Training Loss: 0.0005965633071173215\n",
      "Validation Loss: 0.0008290904059710526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.000652030069322791\n",
      "Training Loss: 0.0005939514774217969\n",
      "Training Loss: 0.000555493861756986\n",
      "Validation Loss: 0.0007314236303745623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0006033803127502324\n",
      "Training Loss: 0.0005578276577580255\n",
      "Training Loss: 0.000519772449915763\n",
      "Validation Loss: 0.0006547167202247846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0005613383177842479\n",
      "Training Loss: 0.0005247936726664193\n",
      "Training Loss: 0.0004878912360436516\n",
      "Validation Loss: 0.000593275625954887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.000524249391455669\n",
      "Training Loss: 0.0004945199224675889\n",
      "Training Loss: 0.00045921695047582037\n",
      "Validation Loss: 0.0005429845303787557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.000491316373263544\n",
      "Training Loss: 0.0004669157061289297\n",
      "Training Loss: 0.0004334186321284506\n",
      "Validation Loss: 0.0005009878451969956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00046206389968574514\n",
      "Training Loss: 0.0004418858991266461\n",
      "Training Loss: 0.00041023479101568225\n",
      "Validation Loss: 0.000465312378815888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00043610655899101403\n",
      "Training Loss: 0.00041926287784008307\n",
      "Training Loss: 0.00038939337402553063\n",
      "Validation Loss: 0.0004345698589429631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0004130605317550362\n",
      "Training Loss: 0.0003988035194197437\n",
      "Training Loss: 0.0003705980872109649\n",
      "Validation Loss: 0.00040775622848455344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0003925271757907467\n",
      "Training Loss: 0.0003802211838774383\n",
      "Training Loss: 0.00035354204424947966\n",
      "Validation Loss: 0.0003840969339977123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0003741124012231012\n",
      "Training Loss: 0.0003632147782627726\n",
      "Training Loss: 0.0003379331518954132\n",
      "Validation Loss: 0.0003629910694716467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00035744696582696634\n",
      "Training Loss: 0.0003475027219610638\n",
      "Training Loss: 0.0003235097867946024\n",
      "Validation Loss: 0.00034396294469250566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00034220847628603225\n",
      "Training Loss: 0.0003328413990311674\n",
      "Training Loss: 0.00031005459943116875\n",
      "Validation Loss: 0.0003266343578769501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0003281302308096201\n",
      "Training Loss: 0.0003190349319629604\n",
      "Training Loss: 0.00029739592337136856\n",
      "Validation Loss: 0.00031070677856875455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0003150032225676114\n",
      "Training Loss: 0.0003059357198799262\n",
      "Training Loss: 0.000285406803341175\n",
      "Validation Loss: 0.00029595651493140947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0003026693903666455\n",
      "Training Loss: 0.0002934395698684966\n",
      "Training Loss: 0.0002739975229997071\n",
      "Validation Loss: 0.0002822114237348073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00029101406827976463\n",
      "Training Loss: 0.0002814764687354909\n",
      "Training Loss: 0.00026310692679544446\n",
      "Validation Loss: 0.00026934368463443705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0002799556252648472\n",
      "Training Loss: 0.0002700035329871753\n",
      "Training Loss: 0.00025269648409448564\n",
      "Validation Loss: 0.0002572581618684187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00026943648656015286\n",
      "Training Loss: 0.00025899555745127143\n",
      "Training Loss: 0.0002427419710875256\n",
      "Validation Loss: 0.0002458836672630742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00025941554413293487\n",
      "Training Loss: 0.0002484397223997803\n",
      "Training Loss: 0.00023322832254052628\n",
      "Validation Loss: 0.0002351635425277002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00024986290918604936\n",
      "Training Loss: 0.00023832911934732693\n",
      "Training Loss: 0.0002241465965016687\n",
      "Validation Loss: 0.0002250580886886403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00024075601693766658\n",
      "Training Loss: 0.00022866206669277744\n",
      "Training Loss: 0.00021548959410210955\n",
      "Validation Loss: 0.0002155284428533449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00023207581038150237\n",
      "Training Loss: 0.00021943517436739056\n",
      "Training Loss: 0.00020725114323795425\n",
      "Validation Loss: 0.00020654395631752553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00022380753533070673\n",
      "Training Loss: 0.00021064678157927118\n",
      "Training Loss: 0.00019942543787692556\n",
      "Validation Loss: 0.00019807849130710963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.000215936627391784\n",
      "Training Loss: 0.00020229222738635144\n",
      "Training Loss: 0.00019200429083866767\n",
      "Validation Loss: 0.00019010422817772134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00020845129343797454\n",
      "Training Loss: 0.0001943654939896078\n",
      "Training Loss: 0.00018497933035177994\n",
      "Validation Loss: 0.00018259860334683765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0002013398802591837\n",
      "Training Loss: 0.00018685862618440297\n",
      "Training Loss: 0.00017834116048106807\n",
      "Validation Loss: 0.00017553727432161314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00019459226627077441\n",
      "Training Loss: 0.00017976264583921875\n",
      "Training Loss: 0.0001720789724640781\n",
      "Validation Loss: 0.00016889957210939807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00018819810882632736\n",
      "Training Loss: 0.00017306637893852895\n",
      "Training Loss: 0.0001661811316080275\n",
      "Validation Loss: 0.00016266501711725958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00018214869964140235\n",
      "Training Loss: 0.0001667577687840094\n",
      "Training Loss: 0.00016063562346971594\n",
      "Validation Loss: 0.00015681343176582007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00017643355055042777\n",
      "Training Loss: 0.00016082357708000928\n",
      "Training Loss: 0.00015542871156867477\n",
      "Validation Loss: 0.00015132523162975211\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00017104372256653732\n",
      "Training Loss: 0.0001552499464378343\n",
      "Training Loss: 0.00015054676092404406\n",
      "Validation Loss: 0.00014618347960820532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00016596864243183517\n",
      "Training Loss: 0.00015002231966718683\n",
      "Training Loss: 0.00014597499312003493\n",
      "Validation Loss: 0.00014136931345552165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00016119708208861994\n",
      "Training Loss: 0.00014512500261844254\n",
      "Training Loss: 0.000141698312418157\n",
      "Validation Loss: 0.00013686585319529318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00015671728087909286\n",
      "Training Loss: 0.00014054231903173786\n",
      "Training Loss: 0.0001377010245960264\n",
      "Validation Loss: 0.00013265656080068184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00015251642351358897\n",
      "Training Loss: 0.00013625768193378462\n",
      "Training Loss: 0.00013396699068835005\n",
      "Validation Loss: 0.0001287242720424187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00014858117794574354\n",
      "Training Loss: 0.00013225453251834553\n",
      "Training Loss: 0.00013048043292656074\n",
      "Validation Loss: 0.0001250516991838983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00014489759922071244\n",
      "Training Loss: 0.00012851591975959308\n",
      "Training Loss: 0.00012722528466838412\n",
      "Validation Loss: 0.00012162359057123815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00014145097473374334\n",
      "Training Loss: 0.00012502539046181483\n",
      "Training Loss: 0.00012418558115314226\n",
      "Validation Loss: 0.00011842393909768709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00013822695758790359\n",
      "Training Loss: 0.00012176638138953421\n",
      "Training Loss: 0.0001213461894167267\n",
      "Validation Loss: 0.00011543742968999059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0001352107897946553\n",
      "Training Loss: 0.00011872237641910032\n",
      "Training Loss: 0.00011869233049765172\n",
      "Validation Loss: 0.00011264944903691838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.000132388268084469\n",
      "Training Loss: 0.00011587832256736873\n",
      "Training Loss: 0.00011620970610238146\n",
      "Validation Loss: 0.0001100457139329408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00012974532884982182\n",
      "Training Loss: 0.0001132193603370979\n",
      "Training Loss: 0.00011388530462681956\n",
      "Validation Loss: 0.00010761297219207255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00012726856797598885\n",
      "Training Loss: 0.00011073100326029817\n",
      "Training Loss: 0.00011170651589054615\n",
      "Validation Loss: 0.00010533914732906361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0001249450668638019\n",
      "Training Loss: 0.00010839996561117005\n",
      "Training Loss: 0.00010966160865791608\n",
      "Validation Loss: 0.00010321194635804878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00012276306994863262\n",
      "Training Loss: 0.00010621383487887215\n",
      "Training Loss: 0.00010773997159958526\n",
      "Validation Loss: 0.00010122005991679236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00012071092288351793\n",
      "Training Loss: 0.00010416102021736151\n",
      "Training Loss: 0.00010593176486509037\n",
      "Validation Loss: 9.935352201782837e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00011877829365403159\n",
      "Training Loss: 0.00010223066143225878\n",
      "Training Loss: 0.00010422752188787854\n",
      "Validation Loss: 9.760223460279724e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00011695549781506998\n",
      "Training Loss: 0.00010041291586276201\n",
      "Training Loss: 0.000102619222661815\n",
      "Validation Loss: 9.595778465154581e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00011523337548169366\n",
      "Training Loss: 9.869850935501746e-05\n",
      "Training Loss: 0.00010109899744747963\n",
      "Validation Loss: 9.44112890680076e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00011360399747900374\n",
      "Training Loss: 9.707898240776558e-05\n",
      "Training Loss: 9.966013727535028e-05\n",
      "Validation Loss: 9.29556146341414e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00011205956761841662\n",
      "Training Loss: 9.554689931064787e-05\n",
      "Training Loss: 9.829621219978435e-05\n",
      "Validation Loss: 9.158332640448392e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00011059352446864068\n",
      "Training Loss: 9.409491348378651e-05\n",
      "Training Loss: 9.700148348201765e-05\n",
      "Validation Loss: 9.028830268260698e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00010919926282440429\n",
      "Training Loss: 9.271681205973437e-05\n",
      "Training Loss: 9.577071010426152e-05\n",
      "Validation Loss: 8.906427510839749e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00010787140339743928\n",
      "Training Loss: 9.140667064457375e-05\n",
      "Training Loss: 9.459904875257052e-05\n",
      "Validation Loss: 8.790604180136102e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0001066046161668055\n",
      "Training Loss: 9.015911002279608e-05\n",
      "Training Loss: 9.348210645839573e-05\n",
      "Validation Loss: 8.680825745675443e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00010539444412643206\n",
      "Training Loss: 8.896928623471468e-05\n",
      "Training Loss: 9.241609115633764e-05\n",
      "Validation Loss: 8.576648827768755e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00010423652771351045\n",
      "Training Loss: 8.78329913939524e-05\n",
      "Training Loss: 9.13972956732323e-05\n",
      "Validation Loss: 8.477662231598515e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00010312697602785193\n",
      "Training Loss: 8.674578909449337e-05\n",
      "Training Loss: 9.042246943863575e-05\n",
      "Validation Loss: 8.383458514779275e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00010206213974015555\n",
      "Training Loss: 8.57043931955559e-05\n",
      "Training Loss: 8.948856614551914e-05\n",
      "Validation Loss: 8.293715606842863e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.000101038824132047\n",
      "Training Loss: 8.470531370221578e-05\n",
      "Training Loss: 8.859286798724497e-05\n",
      "Validation Loss: 8.208106440209766e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00010005432885009214\n",
      "Training Loss: 8.37456601402664e-05\n",
      "Training Loss: 8.773290618592e-05\n",
      "Validation Loss: 8.126310892161139e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 9.910607794154202e-05\n",
      "Training Loss: 8.282280666207953e-05\n",
      "Training Loss: 8.690644441230688e-05\n",
      "Validation Loss: 8.048067829395734e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 9.819179131682177e-05\n",
      "Training Loss: 8.193412281798373e-05\n",
      "Training Loss: 8.611142849986209e-05\n",
      "Validation Loss: 7.973160946482054e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 9.730927089549369e-05\n",
      "Training Loss: 8.107744803965034e-05\n",
      "Training Loss: 8.534584715562232e-05\n",
      "Validation Loss: 7.90132231343429e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 9.645678468586994e-05\n",
      "Training Loss: 8.025065423680644e-05\n",
      "Training Loss: 8.460800780085264e-05\n",
      "Validation Loss: 7.832386493166187e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 9.563242757394619e-05\n",
      "Training Loss: 7.945197794470004e-05\n",
      "Training Loss: 8.389614815314417e-05\n",
      "Validation Loss: 7.766136696885583e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 9.483469506449182e-05\n",
      "Training Loss: 7.867959632221755e-05\n",
      "Training Loss: 8.320902253217355e-05\n",
      "Validation Loss: 7.702404539312727e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 9.406192072674457e-05\n",
      "Training Loss: 7.793191958171519e-05\n",
      "Training Loss: 8.254490286162764e-05\n",
      "Validation Loss: 7.641015123594565e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 9.331292285423843e-05\n",
      "Training Loss: 7.720759960648138e-05\n",
      "Training Loss: 8.190278015717922e-05\n",
      "Validation Loss: 7.581817277405003e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 9.258649394269015e-05\n",
      "Training Loss: 7.650538129837514e-05\n",
      "Training Loss: 8.128142469104204e-05\n",
      "Validation Loss: 7.524693357093415e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 9.188121094211966e-05\n",
      "Training Loss: 7.582391063806426e-05\n",
      "Training Loss: 8.067951402153995e-05\n",
      "Validation Loss: 7.46948841746355e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 9.119626485244225e-05\n",
      "Training Loss: 7.516211259826377e-05\n",
      "Training Loss: 8.009633190340537e-05\n",
      "Validation Loss: 7.416124368687173e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 9.053044867869175e-05\n",
      "Training Loss: 7.451887714523764e-05\n",
      "Training Loss: 7.953074578836095e-05\n",
      "Validation Loss: 7.364475820058226e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 8.98828114168282e-05\n",
      "Training Loss: 7.389332604816445e-05\n",
      "Training Loss: 7.898185472186015e-05\n",
      "Validation Loss: 7.314408342128364e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 8.92524191931443e-05\n",
      "Training Loss: 7.328449853957864e-05\n",
      "Training Loss: 7.84488347653678e-05\n",
      "Validation Loss: 7.265875971692306e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 8.863882322657446e-05\n",
      "Training Loss: 7.269163499586284e-05\n",
      "Training Loss: 7.79307609082025e-05\n",
      "Validation Loss: 7.218765193592231e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 8.804115453585837e-05\n",
      "Training Loss: 7.211388685846032e-05\n",
      "Training Loss: 7.742710596176039e-05\n",
      "Validation Loss: 7.172999273044818e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 8.745846205783892e-05\n",
      "Training Loss: 7.155054114718951e-05\n",
      "Training Loss: 7.693704001212608e-05\n",
      "Validation Loss: 7.128503396957518e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 8.689030195000668e-05\n",
      "Training Loss: 7.100099554008921e-05\n",
      "Training Loss: 7.64599910689867e-05\n",
      "Validation Loss: 7.085213322814402e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 8.633610686956673e-05\n",
      "Training Loss: 7.046446499771264e-05\n",
      "Training Loss: 7.599507246595749e-05\n",
      "Validation Loss: 7.043064167365639e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 8.57948779457729e-05\n",
      "Training Loss: 6.994035558818723e-05\n",
      "Training Loss: 7.554211919341469e-05\n",
      "Validation Loss: 7.001977377349453e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 8.5266229066292e-05\n",
      "Training Loss: 6.942830956631952e-05\n",
      "Training Loss: 7.510022961469076e-05\n",
      "Validation Loss: 6.961891842386168e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 8.474963887692865e-05\n",
      "Training Loss: 6.892764211443137e-05\n",
      "Training Loss: 7.466907640264253e-05\n",
      "Validation Loss: 6.922802527553992e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 8.424465655480162e-05\n",
      "Training Loss: 6.843779000064388e-05\n",
      "Training Loss: 7.424810029988294e-05\n",
      "Validation Loss: 6.88458863049654e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 8.375088026696176e-05\n",
      "Training Loss: 6.795849101763451e-05\n",
      "Training Loss: 7.383672243122419e-05\n",
      "Validation Loss: 6.847254953141457e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 8.32677021935524e-05\n",
      "Training Loss: 6.748911418071658e-05\n",
      "Training Loss: 7.343471421336289e-05\n",
      "Validation Loss: 6.810745088933912e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 8.27947475545443e-05\n",
      "Training Loss: 6.702933977521752e-05\n",
      "Training Loss: 7.30415299312881e-05\n",
      "Validation Loss: 6.775009812239598e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 8.233156684582354e-05\n",
      "Training Loss: 6.657863371856365e-05\n",
      "Training Loss: 7.265675135840865e-05\n",
      "Validation Loss: 6.739997352882854e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 8.187787345377729e-05\n",
      "Training Loss: 6.613687524350098e-05\n",
      "Training Loss: 7.228013909752917e-05\n",
      "Validation Loss: 6.705693364862138e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 8.14331703713833e-05\n",
      "Training Loss: 6.570348135028326e-05\n",
      "Training Loss: 7.191122521817306e-05\n",
      "Validation Loss: 6.672082929909582e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 8.099721895177937e-05\n",
      "Training Loss: 6.527834440021251e-05\n",
      "Training Loss: 7.154968393479067e-05\n",
      "Validation Loss: 6.639107583866329e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 8.056944368490803e-05\n",
      "Training Loss: 6.48609115751242e-05\n",
      "Training Loss: 7.11952620804368e-05\n",
      "Validation Loss: 6.60669989229881e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 8.014976174308686e-05\n",
      "Training Loss: 6.445097202231409e-05\n",
      "Training Loss: 7.084755181040237e-05\n",
      "Validation Loss: 6.574909201426022e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 7.973788134222559e-05\n",
      "Training Loss: 6.404831418421964e-05\n",
      "Training Loss: 7.050628907109058e-05\n",
      "Validation Loss: 6.543656841489118e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 7.933331225103757e-05\n",
      "Training Loss: 6.365254691445443e-05\n",
      "Training Loss: 7.017133601493697e-05\n",
      "Validation Loss: 6.512934669444803e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 7.893574452282337e-05\n",
      "Training Loss: 6.326358912701835e-05\n",
      "Training Loss: 6.984232235026866e-05\n",
      "Validation Loss: 6.482731406536873e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 7.854515575218102e-05\n",
      "Training Loss: 6.288108415446913e-05\n",
      "Training Loss: 6.951903171284357e-05\n",
      "Validation Loss: 6.452996563546528e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 7.816109765371947e-05\n",
      "Training Loss: 6.250476386867377e-05\n",
      "Training Loss: 6.92012660056207e-05\n",
      "Validation Loss: 6.423668488484887e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 7.778347434395982e-05\n",
      "Training Loss: 6.213451973053453e-05\n",
      "Training Loss: 6.888879627695133e-05\n",
      "Validation Loss: 6.394861624398748e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 7.741191540844739e-05\n",
      "Training Loss: 6.177004209803271e-05\n",
      "Training Loss: 6.85813582231276e-05\n",
      "Validation Loss: 6.366460262102061e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 7.704623591507698e-05\n",
      "Training Loss: 6.141124509213115e-05\n",
      "Training Loss: 6.827877153682493e-05\n",
      "Validation Loss: 6.338445270527056e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 7.668617862691463e-05\n",
      "Training Loss: 6.105788220338582e-05\n",
      "Training Loss: 6.798089652420458e-05\n",
      "Validation Loss: 6.310822644674487e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 7.633170011558832e-05\n",
      "Training Loss: 6.070980539334414e-05\n",
      "Training Loss: 6.768744708097075e-05\n",
      "Validation Loss: 6.283555459059459e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 7.598241613777645e-05\n",
      "Training Loss: 6.036676499661553e-05\n",
      "Training Loss: 6.73984356035362e-05\n",
      "Validation Loss: 6.25665470272835e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 7.563825003671809e-05\n",
      "Training Loss: 6.0028639504707824e-05\n",
      "Training Loss: 6.711360915687692e-05\n",
      "Validation Loss: 6.230107223774631e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 7.529903810336691e-05\n",
      "Training Loss: 5.9695452500818645e-05\n",
      "Training Loss: 6.683276668809413e-05\n",
      "Validation Loss: 6.203899618903348e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 7.496449195969035e-05\n",
      "Training Loss: 5.936679362093855e-05\n",
      "Training Loss: 6.65559277695138e-05\n",
      "Validation Loss: 6.177990284352368e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 7.463463990461605e-05\n",
      "Training Loss: 5.904276390083396e-05\n",
      "Training Loss: 6.628283588725026e-05\n",
      "Validation Loss: 6.152385991769601e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 7.430928036228579e-05\n",
      "Training Loss: 5.8723123170238975e-05\n",
      "Training Loss: 6.601338116979605e-05\n",
      "Validation Loss: 6.127106339743967e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 7.398816230306693e-05\n",
      "Training Loss: 5.840778778292588e-05\n",
      "Training Loss: 6.574742345037521e-05\n",
      "Validation Loss: 6.102077040952608e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 7.367117446392512e-05\n",
      "Training Loss: 5.8096514540011415e-05\n",
      "Training Loss: 6.548495106926566e-05\n",
      "Validation Loss: 6.077354038516818e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 7.33583363762591e-05\n",
      "Training Loss: 5.778944377652806e-05\n",
      "Training Loss: 6.522569788103283e-05\n",
      "Validation Loss: 6.0528669922185536e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 7.304934033072641e-05\n",
      "Training Loss: 5.748628439960157e-05\n",
      "Training Loss: 6.496971135675267e-05\n",
      "Validation Loss: 6.0286815752395624e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 7.274422402133496e-05\n",
      "Training Loss: 5.718697772863379e-05\n",
      "Training Loss: 6.471683115250925e-05\n",
      "Validation Loss: 6.004715967801428e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 7.244271542276692e-05\n",
      "Training Loss: 5.689162797807512e-05\n",
      "Training Loss: 6.446702869197907e-05\n",
      "Validation Loss: 5.980961423426451e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 7.214484784526576e-05\n",
      "Training Loss: 5.6599736558382575e-05\n",
      "Training Loss: 6.422004853448015e-05\n",
      "Validation Loss: 5.957525651834924e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 7.185043981280614e-05\n",
      "Training Loss: 5.631163326142996e-05\n",
      "Training Loss: 6.397613097306021e-05\n",
      "Validation Loss: 5.934253072206211e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 7.155953559504269e-05\n",
      "Training Loss: 5.60270090272752e-05\n",
      "Training Loss: 6.37348916825431e-05\n",
      "Validation Loss: 5.911225581472495e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 7.127177952042984e-05\n",
      "Training Loss: 5.574591143158614e-05\n",
      "Training Loss: 6.349632689307327e-05\n",
      "Validation Loss: 5.8884137590130296e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 7.098736595708033e-05\n",
      "Training Loss: 5.546827770103846e-05\n",
      "Training Loss: 6.326048563551012e-05\n",
      "Validation Loss: 5.865795608340786e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 7.070598439895548e-05\n",
      "Training Loss: 5.519385710158531e-05\n",
      "Training Loss: 6.302730069364771e-05\n",
      "Validation Loss: 5.843426534544521e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 7.042779420316947e-05\n",
      "Training Loss: 5.492278579822596e-05\n",
      "Training Loss: 6.279655944126717e-05\n",
      "Validation Loss: 5.821228856557661e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 7.015261903688951e-05\n",
      "Training Loss: 5.4654965010740854e-05\n",
      "Training Loss: 6.256834929899923e-05\n",
      "Validation Loss: 5.7992574874221106e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 6.988018280935648e-05\n",
      "Training Loss: 5.439038885469927e-05\n",
      "Training Loss: 6.234251968180615e-05\n",
      "Validation Loss: 5.7774276852245074e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 6.961081145618663e-05\n",
      "Training Loss: 5.412884698671405e-05\n",
      "Training Loss: 6.211918405824691e-05\n",
      "Validation Loss: 5.7558410604501714e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 6.934418675427878e-05\n",
      "Training Loss: 5.387042720485624e-05\n",
      "Training Loss: 6.189812150296348e-05\n",
      "Validation Loss: 5.7343903852066186e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 6.908024734002538e-05\n",
      "Training Loss: 5.3615088709193515e-05\n",
      "Training Loss: 6.167933408505632e-05\n",
      "Validation Loss: 5.7131733259400666e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 6.881898032133904e-05\n",
      "Training Loss: 5.336284150871506e-05\n",
      "Training Loss: 6.146289158550644e-05\n",
      "Validation Loss: 5.6921069382665696e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 6.856045054064453e-05\n",
      "Training Loss: 5.311341119977442e-05\n",
      "Training Loss: 6.12485820784059e-05\n",
      "Validation Loss: 5.671233977634248e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 6.830452717622393e-05\n",
      "Training Loss: 5.28669373215962e-05\n",
      "Training Loss: 6.103646446263155e-05\n",
      "Validation Loss: 5.650511186840039e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 6.805107792843046e-05\n",
      "Training Loss: 5.2623386272898644e-05\n",
      "Training Loss: 6.082655167119811e-05\n",
      "Validation Loss: 5.629977154517854e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 6.78002974973424e-05\n",
      "Training Loss: 5.238268522589351e-05\n",
      "Training Loss: 6.06187545827197e-05\n",
      "Validation Loss: 5.609604923857874e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 6.755183729183045e-05\n",
      "Training Loss: 5.2144879455227055e-05\n",
      "Training Loss: 6.0413051778596126e-05\n",
      "Validation Loss: 5.589392170028139e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 6.730587323545478e-05\n",
      "Training Loss: 5.190990828396025e-05\n",
      "Training Loss: 6.02094142095666e-05\n",
      "Validation Loss: 5.569360474622586e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 6.706235826186457e-05\n",
      "Training Loss: 5.167766607883095e-05\n",
      "Training Loss: 6.000795322961494e-05\n",
      "Validation Loss: 5.549489169629595e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 6.682111149075354e-05\n",
      "Training Loss: 5.1448189838083634e-05\n",
      "Training Loss: 5.9808336004607554e-05\n",
      "Validation Loss: 5.529768521923001e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 6.658236152361497e-05\n",
      "Training Loss: 5.1221487206021264e-05\n",
      "Training Loss: 5.961090961136506e-05\n",
      "Validation Loss: 5.5102311266688214e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 6.634588110500772e-05\n",
      "Training Loss: 5.099752203022945e-05\n",
      "Training Loss: 5.941537077887915e-05\n",
      "Validation Loss: 5.4908360111307395e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 6.611162476929167e-05\n",
      "Training Loss: 5.077616808193852e-05\n",
      "Training Loss: 5.922185498093313e-05\n",
      "Validation Loss: 5.471589106440497e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 6.587971636690782e-05\n",
      "Training Loss: 5.0557565605231505e-05\n",
      "Training Loss: 5.9030276850080555e-05\n",
      "Validation Loss: 5.4524891127360036e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 6.56500449667874e-05\n",
      "Training Loss: 5.034154791246692e-05\n",
      "Training Loss: 5.88406630663485e-05\n",
      "Validation Loss: 5.433584424843482e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 6.542270890349755e-05\n",
      "Training Loss: 5.012820641240978e-05\n",
      "Training Loss: 5.8653045634855516e-05\n",
      "Validation Loss: 5.414817768100517e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 6.51974030324709e-05\n",
      "Training Loss: 4.991756232811895e-05\n",
      "Training Loss: 5.846728300184623e-05\n",
      "Validation Loss: 5.396209762489235e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 6.497434873836027e-05\n",
      "Training Loss: 4.970951617451647e-05\n",
      "Training Loss: 5.8283440855575465e-05\n",
      "Validation Loss: 5.3777543746874787e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 6.475362338733249e-05\n",
      "Training Loss: 4.950402530539577e-05\n",
      "Training Loss: 5.8101547949718224e-05\n",
      "Validation Loss: 5.3594548339123926e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 6.453482915731002e-05\n",
      "Training Loss: 4.9301196918349886e-05\n",
      "Training Loss: 5.7921532722957635e-05\n",
      "Validation Loss: 5.3412803588778415e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 6.431834488921594e-05\n",
      "Training Loss: 4.910084652237856e-05\n",
      "Training Loss: 5.7743450033740375e-05\n",
      "Validation Loss: 5.3232986451139063e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 6.410399168998993e-05\n",
      "Training Loss: 4.890309514394175e-05\n",
      "Training Loss: 5.756717607255268e-05\n",
      "Validation Loss: 5.305433102947656e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 6.389186601154506e-05\n",
      "Training Loss: 4.870792393830925e-05\n",
      "Training Loss: 5.739291963436699e-05\n",
      "Validation Loss: 5.287748807235954e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 6.368179842866084e-05\n",
      "Training Loss: 4.8515252269680784e-05\n",
      "Training Loss: 5.722047979816125e-05\n",
      "Validation Loss: 5.2702047755343975e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 6.347388152335043e-05\n",
      "Training Loss: 4.832510920550703e-05\n",
      "Training Loss: 5.7049839663250166e-05\n",
      "Validation Loss: 5.2528048655311865e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 6.32680764010729e-05\n",
      "Training Loss: 4.8137536223293866e-05\n",
      "Training Loss: 5.688111424205999e-05\n",
      "Validation Loss: 5.2355847038710266e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 6.30643733393299e-05\n",
      "Training Loss: 4.79524153888633e-05\n",
      "Training Loss: 5.6714220720550655e-05\n",
      "Validation Loss: 5.2184906942355235e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 6.286278603511164e-05\n",
      "Training Loss: 4.7769809843885016e-05\n",
      "Training Loss: 5.6549230021119004e-05\n",
      "Validation Loss: 5.2015462341423084e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 6.266333132771252e-05\n",
      "Training Loss: 4.7589614209755384e-05\n",
      "Training Loss: 5.638606532556878e-05\n",
      "Validation Loss: 5.184780566911756e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 6.246592992283696e-05\n",
      "Training Loss: 4.7411879236278765e-05\n",
      "Training Loss: 5.6224698137157245e-05\n",
      "Validation Loss: 5.168156514648646e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 6.227070844943228e-05\n",
      "Training Loss: 4.7236635236913574e-05\n",
      "Training Loss: 5.606515301906256e-05\n",
      "Validation Loss: 5.1516624138498574e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 6.207748069300578e-05\n",
      "Training Loss: 4.706380150309997e-05\n",
      "Training Loss: 5.5907443734213306e-05\n",
      "Validation Loss: 5.135361641989445e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 6.188645484598965e-05\n",
      "Training Loss: 4.6893400817680234e-05\n",
      "Training Loss: 5.575155478254601e-05\n",
      "Validation Loss: 5.119174566674844e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 6.16973814294397e-05\n",
      "Training Loss: 4.6725494694328515e-05\n",
      "Training Loss: 5.559746226481366e-05\n",
      "Validation Loss: 5.103154618165023e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 6.151040676741104e-05\n",
      "Training Loss: 4.655989037473773e-05\n",
      "Training Loss: 5.5445328243877156e-05\n",
      "Validation Loss: 5.087310369213974e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 6.132559212801425e-05\n",
      "Training Loss: 4.639663353827927e-05\n",
      "Training Loss: 5.529490333856302e-05\n",
      "Validation Loss: 5.071587472403745e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 6.114280205565592e-05\n",
      "Training Loss: 4.623572486252669e-05\n",
      "Training Loss: 5.514624961733716e-05\n",
      "Validation Loss: 5.0560329210190064e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 6.09620384648224e-05\n",
      "Training Loss: 4.607728351402329e-05\n",
      "Training Loss: 5.499936550450002e-05\n",
      "Validation Loss: 5.0406207050441426e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 6.0783338290093526e-05\n",
      "Training Loss: 4.592100659920107e-05\n",
      "Training Loss: 5.4854305192293394e-05\n",
      "Validation Loss: 5.0253891356660867e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 6.06067580247327e-05\n",
      "Training Loss: 4.576712584821507e-05\n",
      "Training Loss: 5.4710963202069255e-05\n",
      "Validation Loss: 5.0102852240884664e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 6.043215576937655e-05\n",
      "Training Loss: 4.5615569688379766e-05\n",
      "Training Loss: 5.4569333519793874e-05\n",
      "Validation Loss: 4.9953335046972894e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 6.025956619396311e-05\n",
      "Training Loss: 4.546613938146038e-05\n",
      "Training Loss: 5.442952115799926e-05\n",
      "Validation Loss: 4.980558193044468e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 6.008903630572604e-05\n",
      "Training Loss: 4.531904695795675e-05\n",
      "Training Loss: 5.4291429466957195e-05\n",
      "Validation Loss: 4.9659337967088424e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 5.992054576381634e-05\n",
      "Training Loss: 4.5174105789556055e-05\n",
      "Training Loss: 5.415506105464374e-05\n",
      "Validation Loss: 4.951448812626245e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 5.975403305455984e-05\n",
      "Training Loss: 4.503143904003082e-05\n",
      "Training Loss: 5.40203680338891e-05\n",
      "Validation Loss: 4.9371425570263476e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 5.95895113883671e-05\n",
      "Training Loss: 4.4890902572660706e-05\n",
      "Training Loss: 5.3887472545284255e-05\n",
      "Validation Loss: 4.922936161900897e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 5.942692341250222e-05\n",
      "Training Loss: 4.47525704794316e-05\n",
      "Training Loss: 5.375606375991992e-05\n",
      "Validation Loss: 4.9089261277034625e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 5.926647472733748e-05\n",
      "Training Loss: 4.4616341401706446e-05\n",
      "Training Loss: 5.362642150657848e-05\n",
      "Validation Loss: 4.895059431914836e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 5.910783218496363e-05\n",
      "Training Loss: 4.448215658158006e-05\n",
      "Training Loss: 5.3498442064210394e-05\n",
      "Validation Loss: 4.881351803172886e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 5.895125857932726e-05\n",
      "Training Loss: 4.4350069219944996e-05\n",
      "Training Loss: 5.3372063009646806e-05\n",
      "Validation Loss: 4.867788644598599e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 5.879653184365452e-05\n",
      "Training Loss: 4.421999790793052e-05\n",
      "Training Loss: 5.3247301073042765e-05\n",
      "Validation Loss: 4.854373129715344e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 5.8643746588131765e-05\n",
      "Training Loss: 4.409198986650153e-05\n",
      "Training Loss: 5.312418333687674e-05\n",
      "Validation Loss: 4.841089696455629e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 5.849285166732443e-05\n",
      "Training Loss: 4.396598859784717e-05\n",
      "Training Loss: 5.300260347667063e-05\n",
      "Validation Loss: 4.8279642761484496e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 5.834388728999329e-05\n",
      "Training Loss: 4.3841879582942054e-05\n",
      "Training Loss: 5.288259166263742e-05\n",
      "Validation Loss: 4.815013994374659e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 5.819683877234638e-05\n",
      "Training Loss: 4.371978851850145e-05\n",
      "Training Loss: 5.276404805954371e-05\n",
      "Validation Loss: 4.802175864538543e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 5.805155703455966e-05\n",
      "Training Loss: 4.3599518908195025e-05\n",
      "Training Loss: 5.2647057484591644e-05\n",
      "Validation Loss: 4.7894971369336664e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 5.790812803752487e-05\n",
      "Training Loss: 4.348108562226116e-05\n",
      "Training Loss: 5.2531631063175155e-05\n",
      "Validation Loss: 4.776967104559201e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 5.776659525508876e-05\n",
      "Training Loss: 4.336459578553331e-05\n",
      "Training Loss: 5.2417603185404005e-05\n",
      "Validation Loss: 4.764577369917716e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 5.76268089844234e-05\n",
      "Training Loss: 4.32497449355651e-05\n",
      "Training Loss: 5.230507379337723e-05\n",
      "Validation Loss: 4.752323755465011e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 5.7488807483423445e-05\n",
      "Training Loss: 4.3136781273460655e-05\n",
      "Training Loss: 5.2194050817888636e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [20:51<05:12, 156.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.740225919060444e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.6389418071508408\n",
      "Training Loss: 0.4930721065402031\n",
      "Training Loss: 0.4147577270120382\n",
      "Validation Loss: 0.3170050396845582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.2831168277561665\n",
      "Training Loss: 0.19073029836639763\n",
      "Training Loss: 0.15085585260763765\n",
      "Validation Loss: 0.10567545505721918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.09330260055139661\n",
      "Training Loss: 0.0691681267786771\n",
      "Training Loss: 0.07030203658156096\n",
      "Validation Loss: 0.06514027721007888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06152171130030183\n",
      "Training Loss: 0.05779966252390295\n",
      "Training Loss: 0.061690000798553225\n",
      "Validation Loss: 0.06054370465238443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.057088728767994326\n",
      "Training Loss: 0.054685711720958353\n",
      "Training Loss: 0.057715640626847746\n",
      "Validation Loss: 0.056837570152423356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.05346096883433347\n",
      "Training Loss: 0.05119207929354161\n",
      "Training Loss: 0.053676246432587504\n",
      "Validation Loss: 0.0527110348424215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.04942259932337038\n",
      "Training Loss: 0.04698736840393394\n",
      "Training Loss: 0.048755444986745715\n",
      "Validation Loss: 0.04731896945557902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.0440776511137301\n",
      "Training Loss: 0.04102347343228757\n",
      "Training Loss: 0.04158059116452932\n",
      "Validation Loss: 0.03914572212719516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.03605593299714201\n",
      "Training Loss: 0.0323464972153306\n",
      "Training Loss: 0.031588908173143866\n",
      "Validation Loss: 0.02858307487017402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.026386234756355407\n",
      "Training Loss: 0.023077736651757733\n",
      "Training Loss: 0.02207994237774983\n",
      "Validation Loss: 0.019533680307187055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.018141878876485863\n",
      "Training Loss: 0.015429286502767354\n",
      "Training Loss: 0.01485793103929609\n",
      "Validation Loss: 0.013108819901022348\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011869754242943599\n",
      "Training Loss: 0.009924816818675027\n",
      "Training Loss: 0.00982063274946995\n",
      "Validation Loss: 0.00874417677608036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00759735704807099\n",
      "Training Loss: 0.006272756701800972\n",
      "Training Loss: 0.006370202468242496\n",
      "Validation Loss: 0.005729452950822378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00474975532561075\n",
      "Training Loss: 0.0038711439256439916\n",
      "Training Loss: 0.004034056949603837\n",
      "Validation Loss: 0.0036861226250407067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0029317270015599205\n",
      "Training Loss: 0.002389276454341598\n",
      "Training Loss: 0.002564782828267198\n",
      "Validation Loss: 0.0023865834096959385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.001866583261435153\n",
      "Training Loss: 0.0015618865824944806\n",
      "Training Loss: 0.0017104774108156562\n",
      "Validation Loss: 0.0016082365875488168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0012766883514996152\n",
      "Training Loss: 0.0011177639669040218\n",
      "Training Loss: 0.0012178415730886628\n",
      "Validation Loss: 0.0011600142592051474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0009422446886310354\n",
      "Training Loss: 0.0008620430330483942\n",
      "Training Loss: 0.0009178502475697314\n",
      "Validation Loss: 0.0009119548626228372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0007417630792042473\n",
      "Training Loss: 0.000699656269789557\n",
      "Training Loss: 0.0007263455605425406\n",
      "Validation Loss: 0.0007766928532608168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.0006170014038070804\n",
      "Training Loss: 0.000590547616884578\n",
      "Training Loss: 0.0006016569597704802\n",
      "Validation Loss: 0.000695201492275823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0005371765816744301\n",
      "Training Loss: 0.0005151006356754806\n",
      "Training Loss: 0.000519465897596092\n",
      "Validation Loss: 0.0006332722846667146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0004842938128786045\n",
      "Training Loss: 0.0004615923579694936\n",
      "Training Loss: 0.0004640044153347844\n",
      "Validation Loss: 0.0005767331311065218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0004475522736538551\n",
      "Training Loss: 0.00042239247290126513\n",
      "Training Loss: 0.0004249710953445174\n",
      "Validation Loss: 0.0005236899655909419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0004204460032997304\n",
      "Training Loss: 0.00039247667431482116\n",
      "Training Loss: 0.000395917113746691\n",
      "Validation Loss: 0.00047636917878754616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0003991005785064772\n",
      "Training Loss: 0.000368625174232875\n",
      "Training Loss: 0.00037302054959582166\n",
      "Validation Loss: 0.00043631971673451344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00038130075565277364\n",
      "Training Loss: 0.0003488528983507422\n",
      "Training Loss: 0.0003541024762307643\n",
      "Validation Loss: 0.0004034661856729124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0003658445853216108\n",
      "Training Loss: 0.0003319665022718254\n",
      "Training Loss: 0.00033793282171245664\n",
      "Validation Loss: 0.00037676563430538273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00035209918478358305\n",
      "Training Loss: 0.0003172406846715603\n",
      "Training Loss: 0.0003238002536818385\n",
      "Validation Loss: 0.00035492645711814616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0003397241738275625\n",
      "Training Loss: 0.0003042187977553112\n",
      "Training Loss: 0.0003112739199787029\n",
      "Validation Loss: 0.00033680035786152546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00032852241329237584\n",
      "Training Loss: 0.0002925971235890756\n",
      "Training Loss: 0.0003000736849935492\n",
      "Validation Loss: 0.0003214991253178064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00031836203239436143\n",
      "Training Loss: 0.0002821602551193791\n",
      "Training Loss: 0.0002900021650930285\n",
      "Validation Loss: 0.00030837355873526565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0003091387069434859\n",
      "Training Loss: 0.00027274510593997545\n",
      "Training Loss: 0.0002809070682633319\n",
      "Validation Loss: 0.0002969592656636757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00030075843424128836\n",
      "Training Loss: 0.0002642195247972268\n",
      "Training Loss: 0.0002726629772951128\n",
      "Validation Loss: 0.0002869185466122136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.0002931318052833376\n",
      "Training Loss: 0.00025647277900134216\n",
      "Training Loss: 0.0002651613765192451\n",
      "Validation Loss: 0.00027800128640939896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00028617345000384373\n",
      "Training Loss: 0.00024940762959886343\n",
      "Training Loss: 0.0002583083658100804\n",
      "Validation Loss: 0.00027001487572132635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00027980297891190277\n",
      "Training Loss: 0.0002429395333456341\n",
      "Training Loss: 0.00025202075546985723\n",
      "Validation Loss: 0.00026280722931404127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0002739464411024528\n",
      "Training Loss: 0.0002369935680326307\n",
      "Training Loss: 0.00024622602173621997\n",
      "Validation Loss: 0.0002562557229599876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0002685370362996764\n",
      "Training Loss: 0.00023150400742451892\n",
      "Training Loss: 0.00024086135588731849\n",
      "Validation Loss: 0.0002502597889044123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00026351608501499866\n",
      "Training Loss: 0.00022641393832600442\n",
      "Training Loss: 0.00023587285446410533\n",
      "Validation Loss: 0.0002447370017271782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0002588330862272414\n",
      "Training Loss: 0.000221673663945694\n",
      "Training Loss: 0.0002312139172863681\n",
      "Validation Loss: 0.0002396186172201565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00025444427386901226\n",
      "Training Loss: 0.00021724084956076695\n",
      "Training Loss: 0.00022684552357532084\n",
      "Validation Loss: 0.0002348480092621869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0002503128454372927\n",
      "Training Loss: 0.00021307911689291359\n",
      "Training Loss: 0.00022273376340308459\n",
      "Validation Loss: 0.00023037792414654402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.000246407729719067\n",
      "Training Loss: 0.00020915729717671638\n",
      "Training Loss: 0.00021885045451199402\n",
      "Validation Loss: 0.00022616915699023247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0002427027263911441\n",
      "Training Loss: 0.0002054490425871336\n",
      "Training Loss: 0.00021517099434277044\n",
      "Validation Loss: 0.0002221897617611953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00023917597447507434\n",
      "Training Loss: 0.00020193140024275637\n",
      "Training Loss: 0.00021167483238969\n",
      "Validation Loss: 0.0002184119456093837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00023580892542668152\n",
      "Training Loss: 0.00019858466817822772\n",
      "Training Loss: 0.00020834414648561504\n",
      "Validation Loss: 0.00021481334222065354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00023258600958797615\n",
      "Training Loss: 0.00019539237062417668\n",
      "Training Loss: 0.0002051633898736327\n",
      "Validation Loss: 0.0002113750911887743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00022949384883759195\n",
      "Training Loss: 0.0001923397052451037\n",
      "Training Loss: 0.00020211958057188894\n",
      "Validation Loss: 0.00020808149941770485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0002265213029568258\n",
      "Training Loss: 0.00018941486392577646\n",
      "Training Loss: 0.00019920095804991432\n",
      "Validation Loss: 0.00020491909075072532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00022365859229466877\n",
      "Training Loss: 0.00018660679808817803\n",
      "Training Loss: 0.00019639774731331272\n",
      "Validation Loss: 0.00020187667071828463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00022089716761911405\n",
      "Training Loss: 0.00018390609338894137\n",
      "Training Loss: 0.00019370097938008256\n",
      "Validation Loss: 0.00019894392577309312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00021822970044013345\n",
      "Training Loss: 0.00018130455160644487\n",
      "Training Loss: 0.0001911029730399605\n",
      "Validation Loss: 0.00019611320066758892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.0002156499026932579\n",
      "Training Loss: 0.00017879498611364397\n",
      "Training Loss: 0.00018859668540244457\n",
      "Validation Loss: 0.00019337634397886453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00021315141679224326\n",
      "Training Loss: 0.00017637119664868807\n",
      "Training Loss: 0.00018617588764755055\n",
      "Validation Loss: 0.00019072837138982109\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00021072989016829524\n",
      "Training Loss: 0.00017402737417796744\n",
      "Training Loss: 0.00018383553011517507\n",
      "Validation Loss: 0.00018816227306712554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.000208380509957351\n",
      "Training Loss: 0.0001717585648111708\n",
      "Training Loss: 0.00018157053938921307\n",
      "Validation Loss: 0.0001856741988642293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00020609898001566762\n",
      "Training Loss: 0.00016956038460193667\n",
      "Training Loss: 0.0001793763157184003\n",
      "Validation Loss: 0.0001832592359768865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0002038819369772682\n",
      "Training Loss: 0.00016742858044381138\n",
      "Training Loss: 0.00017724913112033392\n",
      "Validation Loss: 0.00018091325914151076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00020172573214949808\n",
      "Training Loss: 0.0001653598342454643\n",
      "Training Loss: 0.00017518522372483858\n",
      "Validation Loss: 0.00017863354332803283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00019962761951319407\n",
      "Training Loss: 0.0001633510876308719\n",
      "Training Loss: 0.00017318144293312798\n",
      "Validation Loss: 0.0001764162611783668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0001975846545974491\n",
      "Training Loss: 0.00016139892446517478\n",
      "Training Loss: 0.0001712348318505974\n",
      "Validation Loss: 0.00017425870985820173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00019559445085178594\n",
      "Training Loss: 0.00015950085822623804\n",
      "Training Loss: 0.0001693424580116698\n",
      "Validation Loss: 0.00017215830137481614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00019365450672921723\n",
      "Training Loss: 0.00015765439347887878\n",
      "Training Loss: 0.00016750215074353035\n",
      "Validation Loss: 0.0001701128388386484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00019176289368260768\n",
      "Training Loss: 0.0001558576432580594\n",
      "Training Loss: 0.0001657111335225636\n",
      "Validation Loss: 0.00016812001944998975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00018991750011991825\n",
      "Training Loss: 0.00015410822967169225\n",
      "Training Loss: 0.00016396777451518573\n",
      "Validation Loss: 0.0001661778239875357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0001881164796759549\n",
      "Training Loss: 0.00015240427675962563\n",
      "Training Loss: 0.00016226989600909292\n",
      "Validation Loss: 0.00016428432783786878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00018635813336004503\n",
      "Training Loss: 0.00015074434641064726\n",
      "Training Loss: 0.00016061566397183923\n",
      "Validation Loss: 0.00016243764532212002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00018464081371348583\n",
      "Training Loss: 0.00014912652535713276\n",
      "Training Loss: 0.0001590033614411368\n",
      "Validation Loss: 0.00016063695773155313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00018296333868420334\n",
      "Training Loss: 0.00014754923948203213\n",
      "Training Loss: 0.00015743167929031188\n",
      "Validation Loss: 0.00015887960889200114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00018132392049665213\n",
      "Training Loss: 0.0001460111202140979\n",
      "Training Loss: 0.0001558987659700506\n",
      "Validation Loss: 0.00015716461722364288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00017972148159969947\n",
      "Training Loss: 0.00014451102268139948\n",
      "Training Loss: 0.00015440343608133844\n",
      "Validation Loss: 0.00015549051764292323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00017815476652685902\n",
      "Training Loss: 0.00014304756643468864\n",
      "Training Loss: 0.00015294441938749515\n",
      "Validation Loss: 0.00015385717593294993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00017662254236711306\n",
      "Training Loss: 0.0001416197163052857\n",
      "Training Loss: 0.0001515204655515845\n",
      "Validation Loss: 0.00015226214044345438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00017512386046291794\n",
      "Training Loss: 0.00014022604820638663\n",
      "Training Loss: 0.00015013016158263781\n",
      "Validation Loss: 0.0001507044111799025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0001736574283677328\n",
      "Training Loss: 0.0001388657034294738\n",
      "Training Loss: 0.00014877254465318402\n",
      "Validation Loss: 0.00014918276285876916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00017222242091520458\n",
      "Training Loss: 0.00013753771103438338\n",
      "Training Loss: 0.00014744681921001755\n",
      "Validation Loss: 0.00014769664606350223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0001708179938941612\n",
      "Training Loss: 0.00013624094830447575\n",
      "Training Loss: 0.00014615162950576633\n",
      "Validation Loss: 0.0001462449209417643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0001694430429051863\n",
      "Training Loss: 0.00013497469477442793\n",
      "Training Loss: 0.00014488614673609845\n",
      "Validation Loss: 0.00014482653873375476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00016809699465738959\n",
      "Training Loss: 0.00013373796236919587\n",
      "Training Loss: 0.00014364951037350692\n",
      "Validation Loss: 0.0001434406678138688\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.000166778766324569\n",
      "Training Loss: 0.00013252975235445775\n",
      "Training Loss: 0.00014244073994632345\n",
      "Validation Loss: 0.0001420866621342969\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0001654878076260502\n",
      "Training Loss: 0.00013134953553162632\n",
      "Training Loss: 0.00014125897963822352\n",
      "Validation Loss: 0.00014076304545229055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00016422325563326013\n",
      "Training Loss: 0.00013019625948800239\n",
      "Training Loss: 0.00014010368693561758\n",
      "Validation Loss: 0.00013946930154274463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00016298420126986457\n",
      "Training Loss: 0.00012906949166790582\n",
      "Training Loss: 0.00013897377419198165\n",
      "Validation Loss: 0.00013820492660690864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0001617700124370458\n",
      "Training Loss: 0.00012796823721146212\n",
      "Training Loss: 0.00013786845878712483\n",
      "Validation Loss: 0.00013696841603397456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00016058015087764944\n",
      "Training Loss: 0.0001268919561698567\n",
      "Training Loss: 0.00013678742388947284\n",
      "Validation Loss: 0.0001357600007538443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00015941385474434354\n",
      "Training Loss: 0.00012583987134348718\n",
      "Training Loss: 0.0001357297487447795\n",
      "Validation Loss: 0.00013457821795159004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0001582703777057759\n",
      "Training Loss: 0.00012481127097998978\n",
      "Training Loss: 0.00013469474464727682\n",
      "Validation Loss: 0.00013342240381870795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00015714926548753282\n",
      "Training Loss: 0.00012380569121887676\n",
      "Training Loss: 0.00013368193218411763\n",
      "Validation Loss: 0.00013229235148092005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00015605004118697253\n",
      "Training Loss: 0.00012282244006200926\n",
      "Training Loss: 0.00013269049326481764\n",
      "Validation Loss: 0.00013118672600438493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.0001549718666683475\n",
      "Training Loss: 0.0001218608592353121\n",
      "Training Loss: 0.0001317199636105215\n",
      "Validation Loss: 0.00013010527187218664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00015391447754154798\n",
      "Training Loss: 0.0001209203843063733\n",
      "Training Loss: 0.00013076971868940745\n",
      "Validation Loss: 0.00012904710033427783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.00015287726891983767\n",
      "Training Loss: 0.0001200006191720604\n",
      "Training Loss: 0.0001298393417346233\n",
      "Validation Loss: 0.00012801211680320949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00015185975484200754\n",
      "Training Loss: 0.00011910082652320853\n",
      "Training Loss: 0.0001289278616059164\n",
      "Validation Loss: 0.00012699945290570327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00015086141303982003\n",
      "Training Loss: 0.00011822053429568768\n",
      "Training Loss: 0.00012803548332158244\n",
      "Validation Loss: 0.00012600853872580945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.0001498817386345763\n",
      "Training Loss: 0.00011735917154510389\n",
      "Training Loss: 0.00012716098505734407\n",
      "Validation Loss: 0.00012503845268991917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00014892031491399395\n",
      "Training Loss: 0.00011651637625618605\n",
      "Training Loss: 0.00012630434445782158\n",
      "Validation Loss: 0.00012408909902517459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00014797673566135927\n",
      "Training Loss: 0.00011569156104087596\n",
      "Training Loss: 0.00012546495969218086\n",
      "Validation Loss: 0.00012315998141316362\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.0001470505856195814\n",
      "Training Loss: 0.00011488425709103467\n",
      "Training Loss: 0.00012464223773349658\n",
      "Validation Loss: 0.00012225025954209608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0001461412610296975\n",
      "Training Loss: 0.0001140940455297823\n",
      "Training Loss: 0.00012383605256218288\n",
      "Validation Loss: 0.00012135977144016271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.00014524862159305486\n",
      "Training Loss: 0.00011332049032716896\n",
      "Training Loss: 0.00012304567548198974\n",
      "Validation Loss: 0.00012048749830979288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00014437211815675254\n",
      "Training Loss: 0.00011256323741690722\n",
      "Training Loss: 0.00012227072020323248\n",
      "Validation Loss: 0.00011963352613400255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00014351142111991067\n",
      "Training Loss: 0.00011182175356225344\n",
      "Training Loss: 0.00012151119767622731\n",
      "Validation Loss: 0.00011879720357151865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00014266608290199655\n",
      "Training Loss: 0.00011109569650216144\n",
      "Training Loss: 0.00012076619873369054\n",
      "Validation Loss: 0.00011797798353573046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00014183584929924108\n",
      "Training Loss: 0.00011038459097107989\n",
      "Training Loss: 0.00012003558039396012\n",
      "Validation Loss: 0.00011717545084741615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0001410203813429689\n",
      "Training Loss: 0.00010968815234264185\n",
      "Training Loss: 0.00011931903144613897\n",
      "Validation Loss: 0.00011638962400304101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.0001402194862748729\n",
      "Training Loss: 0.00010900611890974687\n",
      "Training Loss: 0.00011861627832331579\n",
      "Validation Loss: 0.00011561939037379448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00013943249330623076\n",
      "Training Loss: 0.00010833785629074555\n",
      "Training Loss: 0.00011792664369750128\n",
      "Validation Loss: 0.0001148649540952514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00013865931927284692\n",
      "Training Loss: 0.0001076832384478621\n",
      "Training Loss: 0.00011725020869562285\n",
      "Validation Loss: 0.0001141257668545161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.00013789967362754397\n",
      "Training Loss: 0.00010704176840590662\n",
      "Training Loss: 0.00011658648601951426\n",
      "Validation Loss: 0.00011340115051598843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.00013715316685193103\n",
      "Training Loss: 0.00010641324276548402\n",
      "Training Loss: 0.00011593510915190563\n",
      "Validation Loss: 0.00011269103144125469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.00013641970697790385\n",
      "Training Loss: 0.00010579734947896213\n",
      "Training Loss: 0.000115295955520196\n",
      "Validation Loss: 0.00011199500340297347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.00013569871549407253\n",
      "Training Loss: 0.00010519385665247683\n",
      "Training Loss: 0.00011466862362794927\n",
      "Validation Loss: 0.00011131292766743612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00013499015843990492\n",
      "Training Loss: 0.0001046022482751141\n",
      "Training Loss: 0.00011405285929868115\n",
      "Validation Loss: 0.00011064418559430267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00013429362268652768\n",
      "Training Loss: 0.00010402233694549067\n",
      "Training Loss: 0.00011344840136189305\n",
      "Validation Loss: 0.00010998842564854232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.00013360903156353743\n",
      "Training Loss: 0.00010345390768634388\n",
      "Training Loss: 0.00011285498179859132\n",
      "Validation Loss: 0.00010934569489906066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.00013293596794028417\n",
      "Training Loss: 0.00010289661448041443\n",
      "Training Loss: 0.00011227235550904879\n",
      "Validation Loss: 0.00010871527711367052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.00013227434572399944\n",
      "Training Loss: 0.00010235031005322526\n",
      "Training Loss: 0.0001117003343279066\n",
      "Validation Loss: 0.0001080970498682536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.00013162389186618383\n",
      "Training Loss: 0.00010181468178416253\n",
      "Training Loss: 0.00011113868204120081\n",
      "Validation Loss: 0.00010749126424466187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.00013098426896249293\n",
      "Training Loss: 0.00010128931856343115\n",
      "Training Loss: 0.00011058720428991364\n",
      "Validation Loss: 0.00010689704765937176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.00013035536381721612\n",
      "Training Loss: 0.00010077437819745683\n",
      "Training Loss: 0.00011004554905412078\n",
      "Validation Loss: 0.00010631380845031313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0001297370322754432\n",
      "Training Loss: 0.00010026933979133901\n",
      "Training Loss: 0.00010951370144539396\n",
      "Validation Loss: 0.00010574204914907537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0001291289530308859\n",
      "Training Loss: 9.977394061934319e-05\n",
      "Training Loss: 0.00010899129955760145\n",
      "Validation Loss: 0.00010518117631547509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.00012853101185100968\n",
      "Training Loss: 9.928815878083696e-05\n",
      "Training Loss: 0.00010847827468751347\n",
      "Validation Loss: 0.00010463100776443876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.00012794293823390035\n",
      "Training Loss: 9.881160515760712e-05\n",
      "Training Loss: 0.00010797428533805942\n",
      "Validation Loss: 0.00010409124849267367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.00012736465341731674\n",
      "Training Loss: 9.834423026404693e-05\n",
      "Training Loss: 0.0001074793218049308\n",
      "Validation Loss: 0.00010356176401759247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.00012679582703640336\n",
      "Training Loss: 9.788562958419789e-05\n",
      "Training Loss: 0.00010699310688323749\n",
      "Validation Loss: 0.00010304219818515756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0001262364195281407\n",
      "Training Loss: 9.743582721966959e-05\n",
      "Training Loss: 0.00010651546987901384\n",
      "Validation Loss: 0.00010253210117359609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.0001256860509965918\n",
      "Training Loss: 9.699459853436565e-05\n",
      "Training Loss: 0.00010604628294458963\n",
      "Validation Loss: 0.00010203232347286369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.00012514470841779257\n",
      "Training Loss: 9.656169647314527e-05\n",
      "Training Loss: 0.00010558526667409752\n",
      "Validation Loss: 0.00010154165136739036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.00012461207847081824\n",
      "Training Loss: 9.61370132972661e-05\n",
      "Training Loss: 0.00010513244797948574\n",
      "Validation Loss: 0.00010106027793574796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.00012408801330821007\n",
      "Training Loss: 9.572030406161502e-05\n",
      "Training Loss: 0.00010468758985552995\n",
      "Validation Loss: 0.00010058753800008111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.00012357241581412382\n",
      "Training Loss: 9.531129299830354e-05\n",
      "Training Loss: 0.00010425058921100572\n",
      "Validation Loss: 0.00010012383260667714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.00012306511061979108\n",
      "Training Loss: 9.49101298556343e-05\n",
      "Training Loss: 0.00010382115162428818\n",
      "Validation Loss: 9.96688021270243e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00012256598312887946\n",
      "Training Loss: 9.451647847527055e-05\n",
      "Training Loss: 0.00010339925668631622\n",
      "Validation Loss: 9.922215813889268e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0001220749083404371\n",
      "Training Loss: 9.413017454789951e-05\n",
      "Training Loss: 0.00010298479176526598\n",
      "Validation Loss: 9.878391257812284e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.00012159171439634519\n",
      "Training Loss: 9.375105963954411e-05\n",
      "Training Loss: 0.00010257748170261038\n",
      "Validation Loss: 9.83537352061667e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.00012111631465813844\n",
      "Training Loss: 9.337892262919922e-05\n",
      "Training Loss: 0.0001021773354113975\n",
      "Validation Loss: 9.793143261744303e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.00012064839605955058\n",
      "Training Loss: 9.30139806769148e-05\n",
      "Training Loss: 0.0001017841285738541\n",
      "Validation Loss: 9.751685685044863e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.00012018799396173562\n",
      "Training Loss: 9.265564796805847e-05\n",
      "Training Loss: 0.00010139777746189793\n",
      "Validation Loss: 9.711006132011391e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.00011973507169386721\n",
      "Training Loss: 9.230398108229564e-05\n",
      "Training Loss: 0.00010101804412443016\n",
      "Validation Loss: 9.671093588560857e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00011928945903491695\n",
      "Training Loss: 9.195886612360482e-05\n",
      "Training Loss: 0.00010064503232570132\n",
      "Validation Loss: 9.631868786609527e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.00011885082614753627\n",
      "Training Loss: 9.162010706859292e-05\n",
      "Training Loss: 0.00010027837580310006\n",
      "Validation Loss: 9.593397299703498e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00011841931936942273\n",
      "Training Loss: 9.128760352723475e-05\n",
      "Training Loss: 9.991809155508235e-05\n",
      "Validation Loss: 9.555628718332495e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.00011799468942626846\n",
      "Training Loss: 9.096125727410253e-05\n",
      "Training Loss: 9.956416644854471e-05\n",
      "Validation Loss: 9.518568570998019e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0001175768360553775\n",
      "Training Loss: 9.064095974281372e-05\n",
      "Training Loss: 9.921627316543891e-05\n",
      "Validation Loss: 9.482158024633811e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.00011716565251845167\n",
      "Training Loss: 9.032650405970344e-05\n",
      "Training Loss: 9.88744190090074e-05\n",
      "Validation Loss: 9.446413598320607e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0001167609216827259\n",
      "Training Loss: 9.001771632938471e-05\n",
      "Training Loss: 9.853847213889822e-05\n",
      "Validation Loss: 9.411333149125384e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.00011636276949502644\n",
      "Training Loss: 8.971475260295847e-05\n",
      "Training Loss: 9.820832153309311e-05\n",
      "Validation Loss: 9.376895877210884e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.00011597092810916365\n",
      "Training Loss: 8.941739628426148e-05\n",
      "Training Loss: 9.788386209038436e-05\n",
      "Validation Loss: 9.343096868240005e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.00011558522510313196\n",
      "Training Loss: 8.912523978324316e-05\n",
      "Training Loss: 9.756496793670521e-05\n",
      "Validation Loss: 9.309880470334136e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.00011520572012159391\n",
      "Training Loss: 8.883857831278874e-05\n",
      "Training Loss: 9.725159309709853e-05\n",
      "Validation Loss: 9.277268923193497e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.00011483225662232144\n",
      "Training Loss: 8.855703750668908e-05\n",
      "Training Loss: 9.694364741335448e-05\n",
      "Validation Loss: 9.245252793620791e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.00011446466076449724\n",
      "Training Loss: 8.82805787387042e-05\n",
      "Training Loss: 9.664093208812119e-05\n",
      "Validation Loss: 9.213824561423311e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.00011410296627218486\n",
      "Training Loss: 8.800913531558762e-05\n",
      "Training Loss: 9.634349183215818e-05\n",
      "Validation Loss: 9.182959278854817e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0001137468611705117\n",
      "Training Loss: 8.774262202678074e-05\n",
      "Training Loss: 9.60510902950773e-05\n",
      "Validation Loss: 9.152660805647316e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00011339650087393239\n",
      "Training Loss: 8.748082865167817e-05\n",
      "Training Loss: 9.576362858751964e-05\n",
      "Validation Loss: 9.122873888464822e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.00011305153677312774\n",
      "Training Loss: 8.722372372176324e-05\n",
      "Training Loss: 9.548117487611308e-05\n",
      "Validation Loss: 9.093654609407596e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.00011271199728071223\n",
      "Training Loss: 8.697125937942474e-05\n",
      "Training Loss: 9.520351712126285e-05\n",
      "Validation Loss: 9.064939395817888e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.00011237781145609916\n",
      "Training Loss: 8.672321455378551e-05\n",
      "Training Loss: 9.493050803939696e-05\n",
      "Validation Loss: 9.036743592608555e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00011204897331481334\n",
      "Training Loss: 8.64796375935839e-05\n",
      "Training Loss: 9.466215431530145e-05\n",
      "Validation Loss: 9.009048370173557e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.00011172513142810204\n",
      "Training Loss: 8.624033906016848e-05\n",
      "Training Loss: 9.439843324798858e-05\n",
      "Validation Loss: 8.981842595888982e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.00011140633661852916\n",
      "Training Loss: 8.600517408922314e-05\n",
      "Training Loss: 9.413909649083507e-05\n",
      "Validation Loss: 8.95512318871379e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.0001110924883687403\n",
      "Training Loss: 8.5774186436538e-05\n",
      "Training Loss: 9.388420358845906e-05\n",
      "Validation Loss: 8.92886223227016e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.00011078351162723266\n",
      "Training Loss: 8.554715039281291e-05\n",
      "Training Loss: 9.363350761304901e-05\n",
      "Validation Loss: 8.903053107684847e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.00011047934751331922\n",
      "Training Loss: 8.53240587093751e-05\n",
      "Training Loss: 9.338693917015917e-05\n",
      "Validation Loss: 8.877752630785303e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.00011017983630154049\n",
      "Training Loss: 8.510485473379958e-05\n",
      "Training Loss: 9.314455841376912e-05\n",
      "Validation Loss: 8.852817733967324e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.00010988497383550566\n",
      "Training Loss: 8.488930219755276e-05\n",
      "Training Loss: 9.290618286286189e-05\n",
      "Validation Loss: 8.82835154473295e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.00010959452735733066\n",
      "Training Loss: 8.467742346510931e-05\n",
      "Training Loss: 9.267175776585646e-05\n",
      "Validation Loss: 8.804296629002718e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.00010930838610875072\n",
      "Training Loss: 8.446909997473995e-05\n",
      "Training Loss: 9.244121261872351e-05\n",
      "Validation Loss: 8.780652244874208e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0001090268053849286\n",
      "Training Loss: 8.426426723417535e-05\n",
      "Training Loss: 9.221444763170439e-05\n",
      "Validation Loss: 8.757426496047404e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.00010874927847908112\n",
      "Training Loss: 8.406284311604395e-05\n",
      "Training Loss: 9.199137283758319e-05\n",
      "Validation Loss: 8.734581429001828e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.00010847604970877\n",
      "Training Loss: 8.386477999920316e-05\n",
      "Training Loss: 9.177191054732248e-05\n",
      "Validation Loss: 8.712120260691776e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.00010820681118275388\n",
      "Training Loss: 8.366983778614668e-05\n",
      "Training Loss: 9.155598409961385e-05\n",
      "Validation Loss: 8.69003938583937e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.00010794158440148749\n",
      "Training Loss: 8.347820564722497e-05\n",
      "Training Loss: 9.134349612395454e-05\n",
      "Validation Loss: 8.668347443622377e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.0001076802677471278\n",
      "Training Loss: 8.328950058967167e-05\n",
      "Training Loss: 9.113441034969583e-05\n",
      "Validation Loss: 8.647003821525697e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0001074228397465049\n",
      "Training Loss: 8.310384535434423e-05\n",
      "Training Loss: 9.092860710552486e-05\n",
      "Validation Loss: 8.626015425577637e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00010716913004216622\n",
      "Training Loss: 8.292118966892304e-05\n",
      "Training Loss: 9.072618880964001e-05\n",
      "Validation Loss: 8.605356941168364e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.00010691912884794875\n",
      "Training Loss: 8.274131312646204e-05\n",
      "Training Loss: 9.052686714312585e-05\n",
      "Validation Loss: 8.58506957862691e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.00010667257437489752\n",
      "Training Loss: 8.256423787315725e-05\n",
      "Training Loss: 9.033052947415854e-05\n",
      "Validation Loss: 8.565078882016229e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.00010642970129993046\n",
      "Training Loss: 8.238983421506419e-05\n",
      "Training Loss: 9.013725923068705e-05\n",
      "Validation Loss: 8.545407114540334e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.00010619016662531066\n",
      "Training Loss: 8.221796789712244e-05\n",
      "Training Loss: 8.994702131531084e-05\n",
      "Validation Loss: 8.526037694782337e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.00010595399556223128\n",
      "Training Loss: 8.204877915886755e-05\n",
      "Training Loss: 8.975957978691441e-05\n",
      "Validation Loss: 8.507009770868679e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.0001057212149771658\n",
      "Training Loss: 8.188202633391484e-05\n",
      "Training Loss: 8.957496515904495e-05\n",
      "Validation Loss: 8.488256551143503e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.00010549154302680108\n",
      "Training Loss: 8.171769401087659e-05\n",
      "Training Loss: 8.939304388150049e-05\n",
      "Validation Loss: 8.469797452807745e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.00010526510409363255\n",
      "Training Loss: 8.155575802447857e-05\n",
      "Training Loss: 8.921387409827731e-05\n",
      "Validation Loss: 8.451628503719936e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.00010504170077183517\n",
      "Training Loss: 8.139609344652854e-05\n",
      "Training Loss: 8.903740158530126e-05\n",
      "Validation Loss: 8.433746374516324e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00010482133795449045\n",
      "Training Loss: 8.123856829115538e-05\n",
      "Training Loss: 8.886335787792632e-05\n",
      "Validation Loss: 8.416105120385907e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.0001046039114407904\n",
      "Training Loss: 8.108329680908355e-05\n",
      "Training Loss: 8.869180166584556e-05\n",
      "Validation Loss: 8.39874790962609e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.00010438938260449504\n",
      "Training Loss: 8.093016836028256e-05\n",
      "Training Loss: 8.852271316754923e-05\n",
      "Validation Loss: 8.381631973503992e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.00010417762528049934\n",
      "Training Loss: 8.077904224137455e-05\n",
      "Training Loss: 8.835605000967917e-05\n",
      "Validation Loss: 8.364778115944492e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.00010396861282060854\n",
      "Training Loss: 8.062992098530231e-05\n",
      "Training Loss: 8.81915515401488e-05\n",
      "Validation Loss: 8.348161858255357e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.00010376234327850397\n",
      "Training Loss: 8.048264316130371e-05\n",
      "Training Loss: 8.802938120425097e-05\n",
      "Validation Loss: 8.331809012713747e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.00010355873821936257\n",
      "Training Loss: 8.033737824462151e-05\n",
      "Training Loss: 8.786949487330276e-05\n",
      "Validation Loss: 8.315668050824334e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.00010335765966374311\n",
      "Training Loss: 8.019388065804379e-05\n",
      "Training Loss: 8.771175972469791e-05\n",
      "Validation Loss: 8.299752376903976e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00010315900469322514\n",
      "Training Loss: 8.005225099168456e-05\n",
      "Training Loss: 8.755590210057562e-05\n",
      "Validation Loss: 8.284063573882214e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.00010296289390680613\n",
      "Training Loss: 7.991215216406999e-05\n",
      "Training Loss: 8.740230071452971e-05\n",
      "Validation Loss: 8.268605599593857e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.00010276920012074698\n",
      "Training Loss: 7.977385955200589e-05\n",
      "Training Loss: 8.72506231553416e-05\n",
      "Validation Loss: 8.253341663445364e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.00010257777444167004\n",
      "Training Loss: 7.963722854128718e-05\n",
      "Training Loss: 8.710078937838261e-05\n",
      "Validation Loss: 8.238253940362483e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.00010238866987492656\n",
      "Training Loss: 7.950211011575447e-05\n",
      "Training Loss: 8.695300617546309e-05\n",
      "Validation Loss: 8.223435669902612e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.00010220178465715435\n",
      "Training Loss: 7.936856040487328e-05\n",
      "Training Loss: 8.680687011747068e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [23:28<02:36, 156.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.208777674891087e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.11850544886663555\n",
      "Training Loss: 0.07951082970248535\n",
      "Training Loss: 0.0673461021669209\n",
      "Validation Loss: 0.05564253886617469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.05154082630760968\n",
      "Training Loss: 0.04619625052437186\n",
      "Training Loss: 0.04797817710787058\n",
      "Validation Loss: 0.046418553385674285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04367328011746394\n",
      "Training Loss: 0.041002688501030206\n",
      "Training Loss: 0.041991016725078226\n",
      "Validation Loss: 0.03999133149601435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.03700094294443261\n",
      "Training Loss: 0.03390131450956688\n",
      "Training Loss: 0.033962642033584414\n",
      "Validation Loss: 0.031318473671510645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.028187336057890207\n",
      "Training Loss: 0.024933705020230262\n",
      "Training Loss: 0.02439847035333514\n",
      "Validation Loss: 0.021890961593854126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.01912730838812422\n",
      "Training Loss: 0.016544870442012326\n",
      "Training Loss: 0.016084818879608064\n",
      "Validation Loss: 0.01444018819942296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.012507985149277374\n",
      "Training Loss: 0.010860838072258048\n",
      "Training Loss: 0.01062131014186889\n",
      "Validation Loss: 0.009695925747222278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.008534349258989096\n",
      "Training Loss: 0.007480474913027137\n",
      "Training Loss: 0.007312887851148844\n",
      "Validation Loss: 0.006756713004322366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.006088230205932632\n",
      "Training Loss: 0.005329097339417785\n",
      "Training Loss: 0.005151874281000346\n",
      "Validation Loss: 0.004775998343483367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.004357643553521484\n",
      "Training Loss: 0.003733283703913912\n",
      "Training Loss: 0.0035115118202520535\n",
      "Validation Loss: 0.003240326494030822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0029125625325832514\n",
      "Training Loss: 0.0023659890313865615\n",
      "Training Loss: 0.00211659575230442\n",
      "Validation Loss: 0.0019873751358788334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.0016901980491820722\n",
      "Training Loss: 0.0013116762989375274\n",
      "Training Loss: 0.0011731850690557622\n",
      "Validation Loss: 0.001292429395475205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.0010369440243812279\n",
      "Training Loss: 0.0008734118993015727\n",
      "Training Loss: 0.0008421852984611178\n",
      "Validation Loss: 0.0010030906058172957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0008079376402019988\n",
      "Training Loss: 0.0007157691746397177\n",
      "Training Loss: 0.0006991186821687734\n",
      "Validation Loss: 0.0007877429017569514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0006696040915267076\n",
      "Training Loss: 0.0006059593668760499\n",
      "Training Loss: 0.0005935837180004455\n",
      "Validation Loss: 0.0006274611868514952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.0005649658268521307\n",
      "Training Loss: 0.0005149937066744315\n",
      "Training Loss: 0.0005040110197296599\n",
      "Validation Loss: 0.000508446341381785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0004785810608154861\n",
      "Training Loss: 0.00043361571930290667\n",
      "Training Loss: 0.0004250508386758156\n",
      "Validation Loss: 0.0004217293719418368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0004082156920412672\n",
      "Training Loss: 0.00036487765613856026\n",
      "Training Loss: 0.0003618295338310418\n",
      "Validation Loss: 0.00036357192604984367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0003568703174823895\n",
      "Training Loss: 0.00031422911823028696\n",
      "Training Loss: 0.0003183149043979938\n",
      "Validation Loss: 0.00032655861348226365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00032320700207492335\n",
      "Training Loss: 0.00028091117907024453\n",
      "Training Loss: 0.0002909018925129203\n",
      "Validation Loss: 0.0003011986592672033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00030087089115113483\n",
      "Training Loss: 0.0002587973621484707\n",
      "Training Loss: 0.00027231412983383054\n",
      "Validation Loss: 0.0002816543528343174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00028413126317900606\n",
      "Training Loss: 0.0002423795252070704\n",
      "Training Loss: 0.00025766620568902\n",
      "Validation Loss: 0.00026586651004977744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.00027034623260988153\n",
      "Training Loss: 0.0002289635259694478\n",
      "Training Loss: 0.0002450847897125641\n",
      "Validation Loss: 0.0002529417008313277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00025860448622552214\n",
      "Training Loss: 0.00021750707624960342\n",
      "Training Loss: 0.0002339963369013276\n",
      "Validation Loss: 0.0002421641765977256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0002484958731656661\n",
      "Training Loss: 0.00020755441604705993\n",
      "Training Loss: 0.00022416636486013885\n",
      "Validation Loss: 0.00023297343509869514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00023973663926881271\n",
      "Training Loss: 0.0001988370392609795\n",
      "Training Loss: 0.00021543315404414897\n",
      "Validation Loss: 0.0002249862841023734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00023210150113300187\n",
      "Training Loss: 0.00019115998031338677\n",
      "Training Loss: 0.00020765788613061887\n",
      "Validation Loss: 0.0002179508260729215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00022540688576555112\n",
      "Training Loss: 0.00018436596492392708\n",
      "Training Loss: 0.0002007167139527155\n",
      "Validation Loss: 0.00021169612456729185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00021950148020550843\n",
      "Training Loss: 0.00017832280329457717\n",
      "Training Loss: 0.00019449911967967638\n",
      "Validation Loss: 0.00020609629517708895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00021425931423436852\n",
      "Training Loss: 0.00017291796755671384\n",
      "Training Loss: 0.00018890699142502852\n",
      "Validation Loss: 0.00020105251134961864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00020957425906090066\n",
      "Training Loss: 0.0001680549954471644\n",
      "Training Loss: 0.0001838538503216114\n",
      "Validation Loss: 0.00019648363086979657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00020535684903734365\n",
      "Training Loss: 0.00016365166395189589\n",
      "Training Loss: 0.00017926372813235504\n",
      "Validation Loss: 0.00019231869420478136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0002015314136224333\n",
      "Training Loss: 0.0001596380533919728\n",
      "Training Loss: 0.00017507104843389243\n",
      "Validation Loss: 0.00018849825966263484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00019803418312221765\n",
      "Training Loss: 0.00015595479793773848\n",
      "Training Loss: 0.00017121893955845735\n",
      "Validation Loss: 0.00018497100404857428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0001948121546956827\n",
      "Training Loss: 0.00015255189326126127\n",
      "Training Loss: 0.0001676587223664683\n",
      "Validation Loss: 0.0001816916240825909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0001918202984961681\n",
      "Training Loss: 0.0001493874533298367\n",
      "Training Loss: 0.00016434889856100198\n",
      "Validation Loss: 0.00017862384429259036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00018902174662798642\n",
      "Training Loss: 0.00014642658154116362\n",
      "Training Loss: 0.00016125444297358628\n",
      "Validation Loss: 0.00017573517378765614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00018638576053490397\n",
      "Training Loss: 0.00014364010274221074\n",
      "Training Loss: 0.0001583458726054232\n",
      "Validation Loss: 0.00017299858316189865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0001838871310974355\n",
      "Training Loss: 0.0001410039512848016\n",
      "Training Loss: 0.00015559869021672057\n",
      "Validation Loss: 0.0001703918007499371\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00018150492787754046\n",
      "Training Loss: 0.00013849827446392736\n",
      "Training Loss: 0.0001529922164627351\n",
      "Validation Loss: 0.00016789603220142575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00017922222288689228\n",
      "Training Loss: 0.0001361066665231192\n",
      "Training Loss: 0.00015050942180096173\n",
      "Validation Loss: 0.00016549575452648989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00017702489703879108\n",
      "Training Loss: 0.0001338156399287982\n",
      "Training Loss: 0.00014813607707765187\n",
      "Validation Loss: 0.00016317778988267175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00017490184305643197\n",
      "Training Loss: 0.0001316141556344519\n",
      "Training Loss: 0.0001458608583561727\n",
      "Validation Loss: 0.00016093134579707848\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0001728434214783192\n",
      "Training Loss: 0.00012949334026416182\n",
      "Training Loss: 0.0001436739914242935\n",
      "Validation Loss: 0.0001587473308789188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00017084237821109129\n",
      "Training Loss: 0.00012744575515171163\n",
      "Training Loss: 0.0001415675885618839\n",
      "Validation Loss: 0.00015661820400688728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0001688923599795089\n",
      "Training Loss: 0.0001254653959222196\n",
      "Training Loss: 0.0001395350536949991\n",
      "Validation Loss: 0.0001545373776597638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00016698843715857949\n",
      "Training Loss: 0.00012354727658021148\n",
      "Training Loss: 0.00013757105311015038\n",
      "Validation Loss: 0.0001525003921864829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00016512656071427046\n",
      "Training Loss: 0.00012168723689683248\n",
      "Training Loss: 0.00013567100662839949\n",
      "Validation Loss: 0.0001505027449955664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00016330346357790404\n",
      "Training Loss: 0.00011988172484052484\n",
      "Training Loss: 0.0001338309718266828\n",
      "Validation Loss: 0.00014854100888615914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00016151650339452317\n",
      "Training Loss: 0.00011812791054580884\n",
      "Training Loss: 0.00013204754804974073\n",
      "Validation Loss: 0.0001466126894106463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0001597634320387442\n",
      "Training Loss: 0.00011642334045973257\n",
      "Training Loss: 0.0001303180530794634\n",
      "Validation Loss: 0.00014471489251601075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00015804259688593448\n",
      "Training Loss: 0.00011476574105472537\n",
      "Training Loss: 0.00012863972635386743\n",
      "Validation Loss: 0.0001428469877487004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00015635247646059725\n",
      "Training Loss: 0.00011315313369777868\n",
      "Training Loss: 0.00012701038250270357\n",
      "Validation Loss: 0.00014100592584889433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00015469193509488834\n",
      "Training Loss: 0.00011158371745295881\n",
      "Training Loss: 0.00012542801685412995\n",
      "Validation Loss: 0.00013919065556334582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00015305997776522419\n",
      "Training Loss: 0.00011005614634996164\n",
      "Training Loss: 0.00012389074375278143\n",
      "Validation Loss: 0.00013740134887852486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00015145583340199663\n",
      "Training Loss: 0.00010856883023734554\n",
      "Training Loss: 0.0001223967946407356\n",
      "Validation Loss: 0.00013563558210346067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00014987885815571645\n",
      "Training Loss: 0.00010712049712310545\n",
      "Training Loss: 0.0001209447210021608\n",
      "Validation Loss: 0.00013389301445355424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0001483285937229084\n",
      "Training Loss: 0.00010570998178081936\n",
      "Training Loss: 0.00011953301932408067\n",
      "Validation Loss: 0.0001321728369077207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0001468045690398867\n",
      "Training Loss: 0.00010433614012072213\n",
      "Training Loss: 0.0001181602475753607\n",
      "Validation Loss: 0.0001304747792540623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0001453065624264127\n",
      "Training Loss: 0.00010299780940840719\n",
      "Training Loss: 0.00011682514770654961\n",
      "Validation Loss: 0.0001287987810776051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00014383435949639535\n",
      "Training Loss: 0.00010169392198804417\n",
      "Training Loss: 0.00011552640069567132\n",
      "Validation Loss: 0.0001271442026459073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0001423877130218898\n",
      "Training Loss: 0.00010042374827207823\n",
      "Training Loss: 0.00011426287621361552\n",
      "Validation Loss: 0.00012551228052431592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00014096647534643126\n",
      "Training Loss: 9.91862474984373e-05\n",
      "Training Loss: 0.00011303334830699897\n",
      "Validation Loss: 0.00012390228926306826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00013957043079244614\n",
      "Training Loss: 9.798052717997053e-05\n",
      "Training Loss: 0.00011183674907442764\n",
      "Validation Loss: 0.00012231474059089113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00013819953529491612\n",
      "Training Loss: 9.680580914391613e-05\n",
      "Training Loss: 0.00011067181683756644\n",
      "Validation Loss: 0.0001207504608603639\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00013685347423233907\n",
      "Training Loss: 9.56612665868306e-05\n",
      "Training Loss: 0.00010953752544082818\n",
      "Validation Loss: 0.00011920942634287201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00013553193160987576\n",
      "Training Loss: 9.454600774006395e-05\n",
      "Training Loss: 0.00010843285484952502\n",
      "Validation Loss: 0.00011769276222642812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00013423467189568327\n",
      "Training Loss: 9.345938796286646e-05\n",
      "Training Loss: 0.00010735667430708418\n",
      "Validation Loss: 0.00011620076518002872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00013296140767124598\n",
      "Training Loss: 9.240055102054612e-05\n",
      "Training Loss: 0.00010630799303726235\n",
      "Validation Loss: 0.00011473335256228443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0001317117750477337\n",
      "Training Loss: 9.136871293776495e-05\n",
      "Training Loss: 0.00010528562778745254\n",
      "Validation Loss: 0.00011329228371405304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0001304854356112628\n",
      "Training Loss: 9.036310149895143e-05\n",
      "Training Loss: 0.0001042885815968475\n",
      "Validation Loss: 0.00011187602270316408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00012928178442962236\n",
      "Training Loss: 8.938282968301792e-05\n",
      "Training Loss: 0.00010331582136132056\n",
      "Validation Loss: 0.00011048617165052042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00012810044368507078\n",
      "Training Loss: 8.842718931191484e-05\n",
      "Training Loss: 0.0001023663563955779\n",
      "Validation Loss: 0.00010912276543371099\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00012694090857621633\n",
      "Training Loss: 8.749525825805904e-05\n",
      "Training Loss: 0.00010143884211174736\n",
      "Validation Loss: 0.00010778466075658145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00012580240183524439\n",
      "Training Loss: 8.658630723402894e-05\n",
      "Training Loss: 0.00010053264138150553\n",
      "Validation Loss: 0.00010647287836853935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00012468451037420892\n",
      "Training Loss: 8.56994214336737e-05\n",
      "Training Loss: 9.964637428311107e-05\n",
      "Validation Loss: 0.00010518645610594258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.00012358639968169883\n",
      "Training Loss: 8.483365404572396e-05\n",
      "Training Loss: 9.877917587800766e-05\n",
      "Validation Loss: 0.00010392590661723169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.00012250776027485698\n",
      "Training Loss: 8.39883446951717e-05\n",
      "Training Loss: 9.79300017161222e-05\n",
      "Validation Loss: 0.00010269040939511909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00012144758715294301\n",
      "Training Loss: 8.316268386806769e-05\n",
      "Training Loss: 9.709793201182038e-05\n",
      "Validation Loss: 0.00010147894399676843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00012040532500577683\n",
      "Training Loss: 8.235580604377901e-05\n",
      "Training Loss: 9.628198734390025e-05\n",
      "Validation Loss: 0.000100291389367413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.00011938033908336365\n",
      "Training Loss: 8.156684928508185e-05\n",
      "Training Loss: 9.54812624877377e-05\n",
      "Validation Loss: 9.912740189177926e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00011837177587494807\n",
      "Training Loss: 8.079522015577823e-05\n",
      "Training Loss: 9.469485552472178e-05\n",
      "Validation Loss: 9.798585034240092e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00011737930602976121\n",
      "Training Loss: 8.004013787285658e-05\n",
      "Training Loss: 9.392199900958076e-05\n",
      "Validation Loss: 9.686630505967422e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.00011640209579127258\n",
      "Training Loss: 7.930090876470786e-05\n",
      "Training Loss: 9.316192921687616e-05\n",
      "Validation Loss: 9.576798485918363e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00011543939400326054\n",
      "Training Loss: 7.857691212848295e-05\n",
      "Training Loss: 9.241382235359197e-05\n",
      "Validation Loss: 9.468970024448772e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00011449060618360818\n",
      "Training Loss: 7.78673592958512e-05\n",
      "Training Loss: 9.167704961782875e-05\n",
      "Validation Loss: 9.363118584751442e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.00011355521879522711\n",
      "Training Loss: 7.717184483226447e-05\n",
      "Training Loss: 9.095099645492155e-05\n",
      "Validation Loss: 9.259155357223504e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00011263263222645037\n",
      "Training Loss: 7.648967919976713e-05\n",
      "Training Loss: 9.023502681429818e-05\n",
      "Validation Loss: 9.157018121186411e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00011172225110385625\n",
      "Training Loss: 7.582045510389435e-05\n",
      "Training Loss: 8.952860702265752e-05\n",
      "Validation Loss: 9.056548050251917e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.000110823564355087\n",
      "Training Loss: 7.516366179515898e-05\n",
      "Training Loss: 8.883126175987855e-05\n",
      "Validation Loss: 8.957857763367898e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00010993599432367773\n",
      "Training Loss: 7.451877112089277e-05\n",
      "Training Loss: 8.814250912564603e-05\n",
      "Validation Loss: 8.860708455838985e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.00010905914174145436\n",
      "Training Loss: 7.388552584416175e-05\n",
      "Training Loss: 8.746203284317743e-05\n",
      "Validation Loss: 8.765113206505559e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00010819259425261407\n",
      "Training Loss: 7.326340857616743e-05\n",
      "Training Loss: 8.678944161601975e-05\n",
      "Validation Loss: 8.671020430156613e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00010733603965036309\n",
      "Training Loss: 7.265220169301756e-05\n",
      "Training Loss: 8.612444155460252e-05\n",
      "Validation Loss: 8.578404845905149e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00010648891656273917\n",
      "Training Loss: 7.205162040008873e-05\n",
      "Training Loss: 8.546672507691256e-05\n",
      "Validation Loss: 8.487166835468007e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.000105651121793926\n",
      "Training Loss: 7.146135424136446e-05\n",
      "Training Loss: 8.481618180667283e-05\n",
      "Validation Loss: 8.397298606825971e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0001048223200814391\n",
      "Training Loss: 7.088118837145885e-05\n",
      "Training Loss: 8.417263900810212e-05\n",
      "Validation Loss: 8.308762819090108e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.00010400227639820514\n",
      "Training Loss: 7.031103606095712e-05\n",
      "Training Loss: 8.35361016470415e-05\n",
      "Validation Loss: 8.221588051343092e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00010319084348793695\n",
      "Training Loss: 6.975075756599835e-05\n",
      "Training Loss: 8.290638170819875e-05\n",
      "Validation Loss: 8.135730451122685e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.00010238788311880853\n",
      "Training Loss: 6.920020154666418e-05\n",
      "Training Loss: 8.228338858316419e-05\n",
      "Validation Loss: 8.05117523811808e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00010159338540233876\n",
      "Training Loss: 6.865936950362084e-05\n",
      "Training Loss: 8.166742835783225e-05\n",
      "Validation Loss: 7.9679405874057e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00010080740604962558\n",
      "Training Loss: 6.812819109654811e-05\n",
      "Training Loss: 8.105843737212126e-05\n",
      "Validation Loss: 7.886017041262553e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00010002989344229718\n",
      "Training Loss: 6.760673525150196e-05\n",
      "Training Loss: 8.045652483360754e-05\n",
      "Validation Loss: 7.805449750991061e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 9.9260911838428e-05\n",
      "Training Loss: 6.709503523779858e-05\n",
      "Training Loss: 7.986205758697906e-05\n",
      "Validation Loss: 7.726246538245658e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 9.850067774550553e-05\n",
      "Training Loss: 6.65930905006462e-05\n",
      "Training Loss: 7.927495754302072e-05\n",
      "Validation Loss: 7.648485818842009e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 9.774928754950451e-05\n",
      "Training Loss: 6.61011158308611e-05\n",
      "Training Loss: 7.869570261391345e-05\n",
      "Validation Loss: 7.572124778572503e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 9.700705283876232e-05\n",
      "Training Loss: 6.561919607065647e-05\n",
      "Training Loss: 7.812446279331197e-05\n",
      "Validation Loss: 7.497339520648055e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 9.627429208649119e-05\n",
      "Training Loss: 6.514746759876288e-05\n",
      "Training Loss: 7.756171269193146e-05\n",
      "Validation Loss: 7.424062794066895e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 9.55512144878412e-05\n",
      "Training Loss: 6.468605905411095e-05\n",
      "Training Loss: 7.700767564983835e-05\n",
      "Validation Loss: 7.352407249455926e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 9.483815109206261e-05\n",
      "Training Loss: 6.42351744500047e-05\n",
      "Training Loss: 7.646260963156237e-05\n",
      "Validation Loss: 7.28242575247207e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 9.413567354386033e-05\n",
      "Training Loss: 6.379495606552154e-05\n",
      "Training Loss: 7.592701409066649e-05\n",
      "Validation Loss: 7.214201113629827e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 9.344402844135402e-05\n",
      "Training Loss: 6.336560233194177e-05\n",
      "Training Loss: 7.5401226717986e-05\n",
      "Validation Loss: 7.147780209716791e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 9.276361103957242e-05\n",
      "Training Loss: 6.294728938655681e-05\n",
      "Training Loss: 7.488556791486189e-05\n",
      "Validation Loss: 7.083246645266995e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 9.209483328504576e-05\n",
      "Training Loss: 6.254006742437922e-05\n",
      "Training Loss: 7.438034200731636e-05\n",
      "Validation Loss: 7.02066568112386e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 9.143819926293872e-05\n",
      "Training Loss: 6.214403570993454e-05\n",
      "Training Loss: 7.388603853542008e-05\n",
      "Validation Loss: 6.960068065361637e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 9.079394968011911e-05\n",
      "Training Loss: 6.175934370048707e-05\n",
      "Training Loss: 7.340277221373981e-05\n",
      "Validation Loss: 6.901549001637515e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 9.016257259190752e-05\n",
      "Training Loss: 6.138606278454972e-05\n",
      "Training Loss: 7.293099141861603e-05\n",
      "Validation Loss: 6.845143029290177e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 8.95443336162316e-05\n",
      "Training Loss: 6.102413701682963e-05\n",
      "Training Loss: 7.24707828658211e-05\n",
      "Validation Loss: 6.790895846085292e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 8.893954337054311e-05\n",
      "Training Loss: 6.067352206173382e-05\n",
      "Training Loss: 7.202232878626091e-05\n",
      "Validation Loss: 6.738814510314891e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 8.83485170061249e-05\n",
      "Training Loss: 6.033417813341657e-05\n",
      "Training Loss: 7.158586694913538e-05\n",
      "Validation Loss: 6.688959844181676e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 8.77713878708164e-05\n",
      "Training Loss: 6.000597733418544e-05\n",
      "Training Loss: 7.116129323094356e-05\n",
      "Validation Loss: 6.641331155090106e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 8.720841198737616e-05\n",
      "Training Loss: 5.968878703697556e-05\n",
      "Training Loss: 7.074892121636367e-05\n",
      "Validation Loss: 6.595905204173168e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 8.665953298987006e-05\n",
      "Training Loss: 5.938232206744942e-05\n",
      "Training Loss: 7.034842484245019e-05\n",
      "Validation Loss: 6.55267991236685e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 8.612479103248916e-05\n",
      "Training Loss: 5.908633057515544e-05\n",
      "Training Loss: 6.995973970788327e-05\n",
      "Validation Loss: 6.51162817238595e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 8.560412696624553e-05\n",
      "Training Loss: 5.8800508718377386e-05\n",
      "Training Loss: 6.95828742982485e-05\n",
      "Validation Loss: 6.472709848944607e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 8.509752320151164e-05\n",
      "Training Loss: 5.8524481312360875e-05\n",
      "Training Loss: 6.921742504346185e-05\n",
      "Validation Loss: 6.435862105411544e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 8.460471380203672e-05\n",
      "Training Loss: 5.825789338132381e-05\n",
      "Training Loss: 6.88632232731834e-05\n",
      "Validation Loss: 6.401046746585951e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 8.412550340835878e-05\n",
      "Training Loss: 5.8000314918444925e-05\n",
      "Training Loss: 6.852007476936705e-05\n",
      "Validation Loss: 6.368158449149224e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 8.365961724621229e-05\n",
      "Training Loss: 5.7751291033127925e-05\n",
      "Training Loss: 6.818744765951123e-05\n",
      "Validation Loss: 6.337131001120643e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 8.320665146129614e-05\n",
      "Training Loss: 5.751040114546413e-05\n",
      "Training Loss: 6.786506146454485e-05\n",
      "Validation Loss: 6.307877403456035e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 8.2766516970878e-05\n",
      "Training Loss: 5.7277069367955845e-05\n",
      "Training Loss: 6.755249102297966e-05\n",
      "Validation Loss: 6.280274359330965e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 8.233847232077097e-05\n",
      "Training Loss: 5.7050900052217914e-05\n",
      "Training Loss: 6.724931691678648e-05\n",
      "Validation Loss: 6.254238485453652e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 8.192226979417683e-05\n",
      "Training Loss: 5.683142762791249e-05\n",
      "Training Loss: 6.695508228858671e-05\n",
      "Validation Loss: 6.22965583261248e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 8.151740744551717e-05\n",
      "Training Loss: 5.661812698008362e-05\n",
      "Training Loss: 6.666939938440919e-05\n",
      "Validation Loss: 6.206425038389364e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 8.112344095025037e-05\n",
      "Training Loss: 5.641053769977589e-05\n",
      "Training Loss: 6.639171581809933e-05\n",
      "Validation Loss: 6.18442442593344e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 8.073992051322421e-05\n",
      "Training Loss: 5.620829414056061e-05\n",
      "Training Loss: 6.612164806028886e-05\n",
      "Validation Loss: 6.163537458316283e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 8.036633081928812e-05\n",
      "Training Loss: 5.6010820289884575e-05\n",
      "Training Loss: 6.585867819921987e-05\n",
      "Validation Loss: 6.143686602136471e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 8.000210092632188e-05\n",
      "Training Loss: 5.581782386570921e-05\n",
      "Training Loss: 6.560239606187679e-05\n",
      "Validation Loss: 6.124736908818347e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 7.964691627876163e-05\n",
      "Training Loss: 5.562889839438867e-05\n",
      "Training Loss: 6.535247778629128e-05\n",
      "Validation Loss: 6.10661516506032e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 7.930017891339957e-05\n",
      "Training Loss: 5.5443577878122596e-05\n",
      "Training Loss: 6.510840542432561e-05\n",
      "Validation Loss: 6.089199928027575e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 7.896150966871574e-05\n",
      "Training Loss: 5.526167199150222e-05\n",
      "Training Loss: 6.48698295799477e-05\n",
      "Validation Loss: 6.072406589420721e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 7.863048053195598e-05\n",
      "Training Loss: 5.508272469342046e-05\n",
      "Training Loss: 6.463636530952499e-05\n",
      "Validation Loss: 6.0561718093206797e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 7.830664045059165e-05\n",
      "Training Loss: 5.490658641065238e-05\n",
      "Training Loss: 6.440776212912169e-05\n",
      "Validation Loss: 6.040409118285108e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 7.79896197832386e-05\n",
      "Training Loss: 5.4732955550207405e-05\n",
      "Training Loss: 6.418354400011594e-05\n",
      "Validation Loss: 6.0250269904898826e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 7.767901960278322e-05\n",
      "Training Loss: 5.456153965951671e-05\n",
      "Training Loss: 6.396358148322179e-05\n",
      "Validation Loss: 6.0099916936451336e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 7.737447318049817e-05\n",
      "Training Loss: 5.439224699330225e-05\n",
      "Training Loss: 6.37474755922085e-05\n",
      "Validation Loss: 5.995213351024575e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 7.707565106557013e-05\n",
      "Training Loss: 5.4224777059062035e-05\n",
      "Training Loss: 6.35350625088904e-05\n",
      "Validation Loss: 5.980660053415357e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 7.678228215809214e-05\n",
      "Training Loss: 5.405906152645912e-05\n",
      "Training Loss: 6.332609571472858e-05\n",
      "Validation Loss: 5.9663019185515286e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 7.649407053577307e-05\n",
      "Training Loss: 5.389492657059236e-05\n",
      "Training Loss: 6.312031050583755e-05\n",
      "Validation Loss: 5.9520391056302994e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 7.621076625582645e-05\n",
      "Training Loss: 5.3732230965124474e-05\n",
      "Training Loss: 6.291760207659536e-05\n",
      "Validation Loss: 5.937885734301438e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 7.593198499534992e-05\n",
      "Training Loss: 5.357085830610231e-05\n",
      "Training Loss: 6.271773738262709e-05\n",
      "Validation Loss: 5.923803922577759e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 7.565773195210568e-05\n",
      "Training Loss: 5.341083536222868e-05\n",
      "Training Loss: 6.252056969060504e-05\n",
      "Validation Loss: 5.909750743331244e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 7.538759395629313e-05\n",
      "Training Loss: 5.325197153069894e-05\n",
      "Training Loss: 6.232600465864379e-05\n",
      "Validation Loss: 5.895753111984591e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 7.512152888921265e-05\n",
      "Training Loss: 5.309425594532513e-05\n",
      "Training Loss: 6.21339122972131e-05\n",
      "Validation Loss: 5.881735977086106e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 7.485926035997182e-05\n",
      "Training Loss: 5.2937631439817776e-05\n",
      "Training Loss: 6.194422064709215e-05\n",
      "Validation Loss: 5.8677099511104835e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 7.460066361090867e-05\n",
      "Training Loss: 5.2782051573103675e-05\n",
      "Training Loss: 6.175667374009209e-05\n",
      "Validation Loss: 5.853644999272577e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 7.434560641286225e-05\n",
      "Training Loss: 5.2627533143549954e-05\n",
      "Training Loss: 6.157136000638275e-05\n",
      "Validation Loss: 5.839572599286206e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 7.409393477701087e-05\n",
      "Training Loss: 5.2473956282028665e-05\n",
      "Training Loss: 6.138812617336953e-05\n",
      "Validation Loss: 5.82545531905749e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 7.384554388863763e-05\n",
      "Training Loss: 5.2321406931241656e-05\n",
      "Training Loss: 6.120693657067022e-05\n",
      "Validation Loss: 5.8113168522007923e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 7.360034622934108e-05\n",
      "Training Loss: 5.216983518266716e-05\n",
      "Training Loss: 6.102762738009915e-05\n",
      "Validation Loss: 5.7971231429935746e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 7.335819873333094e-05\n",
      "Training Loss: 5.2019127886069327e-05\n",
      "Training Loss: 6.08502551813217e-05\n",
      "Validation Loss: 5.782871291016358e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 7.31190451438124e-05\n",
      "Training Loss: 5.186951626455993e-05\n",
      "Training Loss: 6.067480142974091e-05\n",
      "Validation Loss: 5.768609358465562e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 7.288279234671791e-05\n",
      "Training Loss: 5.17207883649462e-05\n",
      "Training Loss: 6.05011053266935e-05\n",
      "Validation Loss: 5.7542939908017525e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 7.264931002964658e-05\n",
      "Training Loss: 5.1573080693287924e-05\n",
      "Training Loss: 6.032923624388786e-05\n",
      "Validation Loss: 5.7399578314759176e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 7.241860077328966e-05\n",
      "Training Loss: 5.14262967067225e-05\n",
      "Training Loss: 6.0159103932164725e-05\n",
      "Validation Loss: 5.725600196067747e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 7.219060004899802e-05\n",
      "Training Loss: 5.128045975197892e-05\n",
      "Training Loss: 5.999066115236928e-05\n",
      "Validation Loss: 5.711219517231737e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 7.196523444122249e-05\n",
      "Training Loss: 5.113568311344352e-05\n",
      "Training Loss: 5.9823992219207864e-05\n",
      "Validation Loss: 5.696816908332468e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 7.17424474305517e-05\n",
      "Training Loss: 5.09918585999003e-05\n",
      "Training Loss: 5.9658881405084685e-05\n",
      "Validation Loss: 5.682408097752333e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 7.152217484303947e-05\n",
      "Training Loss: 5.084901674536013e-05\n",
      "Training Loss: 5.949542061898683e-05\n",
      "Validation Loss: 5.667999145638471e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 7.130437930527478e-05\n",
      "Training Loss: 5.070715333431508e-05\n",
      "Training Loss: 5.933358524998766e-05\n",
      "Validation Loss: 5.653583434905976e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 7.108900775392612e-05\n",
      "Training Loss: 5.056636590097696e-05\n",
      "Training Loss: 5.917335568483395e-05\n",
      "Validation Loss: 5.6391684599444756e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 7.08760635075123e-05\n",
      "Training Loss: 5.042654534236135e-05\n",
      "Training Loss: 5.9014668713643915e-05\n",
      "Validation Loss: 5.62478224826387e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 7.066546201485835e-05\n",
      "Training Loss: 5.028777244206139e-05\n",
      "Training Loss: 5.885753716484032e-05\n",
      "Validation Loss: 5.610406000148819e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 7.045723188070952e-05\n",
      "Training Loss: 5.0149976289048936e-05\n",
      "Training Loss: 5.870192495876836e-05\n",
      "Validation Loss: 5.596029677179288e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 7.02511908946235e-05\n",
      "Training Loss: 5.001324170052612e-05\n",
      "Training Loss: 5.854782553797122e-05\n",
      "Validation Loss: 5.581724785565967e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 7.004742696153698e-05\n",
      "Training Loss: 4.98775428513909e-05\n",
      "Training Loss: 5.8395260125507776e-05\n",
      "Validation Loss: 5.567445892982791e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 6.984595865105802e-05\n",
      "Training Loss: 4.9742893716029356e-05\n",
      "Training Loss: 5.8244108790859174e-05\n",
      "Validation Loss: 5.5532000927220055e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 6.964666493672667e-05\n",
      "Training Loss: 4.960921442716426e-05\n",
      "Training Loss: 5.809442866848258e-05\n",
      "Validation Loss: 5.5390037298851626e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 6.944945170289429e-05\n",
      "Training Loss: 4.947660561583689e-05\n",
      "Training Loss: 5.7946206047745364e-05\n",
      "Validation Loss: 5.5248892141626745e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 6.925444902890377e-05\n",
      "Training Loss: 4.9345013931088036e-05\n",
      "Training Loss: 5.7799352512120094e-05\n",
      "Validation Loss: 5.510808957777126e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 6.906155357683019e-05\n",
      "Training Loss: 4.921441444139418e-05\n",
      "Training Loss: 5.765392169905681e-05\n",
      "Validation Loss: 5.4967695581417705e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 6.887074109044988e-05\n",
      "Training Loss: 4.9084906488587874e-05\n",
      "Training Loss: 5.75098647732375e-05\n",
      "Validation Loss: 5.4828093213340195e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 6.86820098633234e-05\n",
      "Training Loss: 4.8956393191019745e-05\n",
      "Training Loss: 5.7367173831153195e-05\n",
      "Validation Loss: 5.468915831984765e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 6.849531185707746e-05\n",
      "Training Loss: 4.882889708369476e-05\n",
      "Training Loss: 5.722580565361568e-05\n",
      "Validation Loss: 5.455093335594836e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 6.831054260715063e-05\n",
      "Training Loss: 4.870243667937757e-05\n",
      "Training Loss: 5.708572066851048e-05\n",
      "Validation Loss: 5.441347060736865e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 6.812784711996755e-05\n",
      "Training Loss: 4.857695382497695e-05\n",
      "Training Loss: 5.694701976608485e-05\n",
      "Validation Loss: 5.427679706259737e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 6.794707739004479e-05\n",
      "Training Loss: 4.845251756023572e-05\n",
      "Training Loss: 5.680955093339435e-05\n",
      "Validation Loss: 5.4140726471937186e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 6.776824437110918e-05\n",
      "Training Loss: 4.8329031362754906e-05\n",
      "Training Loss: 5.667337920840509e-05\n",
      "Validation Loss: 5.4005620528146264e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 6.759130499858656e-05\n",
      "Training Loss: 4.8206552089595786e-05\n",
      "Training Loss: 5.6538405951869206e-05\n",
      "Validation Loss: 5.387143209078572e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 6.741626377106514e-05\n",
      "Training Loss: 4.808511130249826e-05\n",
      "Training Loss: 5.6404693400509134e-05\n",
      "Validation Loss: 5.373784976011061e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 6.724308221578212e-05\n",
      "Training Loss: 4.796456222038614e-05\n",
      "Training Loss: 5.627218657991762e-05\n",
      "Validation Loss: 5.360506300481636e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 6.707175916517371e-05\n",
      "Training Loss: 4.7845012502421014e-05\n",
      "Training Loss: 5.614078932467237e-05\n",
      "Validation Loss: 5.347329648797762e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 6.690222150382397e-05\n",
      "Training Loss: 4.772644139620752e-05\n",
      "Training Loss: 5.601065915016079e-05\n",
      "Validation Loss: 5.334263536231324e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 6.6734430630504e-05\n",
      "Training Loss: 4.7608799316094516e-05\n",
      "Training Loss: 5.588166291545349e-05\n",
      "Validation Loss: 5.321259162260145e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 6.656850836066042e-05\n",
      "Training Loss: 4.74920837928039e-05\n",
      "Training Loss: 5.575379475430964e-05\n",
      "Validation Loss: 5.308348484893001e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 6.640423248882143e-05\n",
      "Training Loss: 4.737629404189647e-05\n",
      "Training Loss: 5.562695997014089e-05\n",
      "Validation Loss: 5.295517856855318e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 6.624166910455642e-05\n",
      "Training Loss: 4.7261440145121014e-05\n",
      "Training Loss: 5.5501324122815274e-05\n",
      "Validation Loss: 5.282786186439756e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 6.60807742065117e-05\n",
      "Training Loss: 4.7147483389835546e-05\n",
      "Training Loss: 5.5376725385940516e-05\n",
      "Validation Loss: 5.2701675552301554e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 6.59216089138681e-05\n",
      "Training Loss: 4.703443063363011e-05\n",
      "Training Loss: 5.525318611034891e-05\n",
      "Validation Loss: 5.257626824030094e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 6.576401292250011e-05\n",
      "Training Loss: 4.6922273486416086e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [26:04<00:00, 156.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.513069872449705e-05\n",
      "Validation Loss: 5.245162172828264e-05\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2841, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.08888492422178387\n",
      "Training Loss: 0.07051561569795012\n",
      "Training Loss: 0.06519016770645976\n",
      "Training Loss: 0.05275305886520073\n",
      "Training Loss: 0.03814738139510155\n",
      "Training Loss: 0.034479016633704306\n",
      "Training Loss: 0.035141308079473674\n",
      "Validation Loss: 0.03992075967857063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.05008892323821783\n",
      "Training Loss: 0.04640601293183863\n",
      "Training Loss: 0.04438015290535986\n",
      "Training Loss: 0.03274045457786997\n",
      "Training Loss: 0.019289126484654844\n",
      "Training Loss: 0.01641108887735754\n",
      "Training Loss: 0.015709728219080718\n",
      "Validation Loss: 0.02049198701248717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.030591227165423333\n",
      "Training Loss: 0.027766130627132953\n",
      "Training Loss: 0.026744674937799574\n",
      "Training Loss: 0.016359912301413714\n",
      "Training Loss: 0.005092295458307489\n",
      "Training Loss: 0.0036737063684267922\n",
      "Training Loss: 0.0026899043688899836\n",
      "Validation Loss: 0.008170764187389238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.019693675313610583\n",
      "Training Loss: 0.018061698619276284\n",
      "Training Loss: 0.01791471348842606\n",
      "Training Loss: 0.009707480569632025\n",
      "Training Loss: 0.0012188885887735523\n",
      "Training Loss: 0.0010430907670524903\n",
      "Training Loss: 0.001078235724417027\n",
      "Validation Loss: 0.006195328310319512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.016342490250244736\n",
      "Training Loss: 0.015303983567282558\n",
      "Training Loss: 0.015168819453101605\n",
      "Training Loss: 0.008529925766342785\n",
      "Training Loss: 0.0014992767327930779\n",
      "Training Loss: 0.0012157077339361422\n",
      "Training Loss: 0.0013613539289508481\n",
      "Validation Loss: 0.005489755291400184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.014279513615183531\n",
      "Training Loss: 0.013566035646945238\n",
      "Training Loss: 0.013437636161688716\n",
      "Training Loss: 0.007789587018196471\n",
      "Training Loss: 0.0016475337529846\n",
      "Training Loss: 0.0013254111574497074\n",
      "Training Loss: 0.0015223729827266652\n",
      "Validation Loss: 0.004924907981922104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.012727359305135905\n",
      "Training Loss: 0.012181620511692018\n",
      "Training Loss: 0.012045677280984818\n",
      "Training Loss: 0.007130546511034481\n",
      "Training Loss: 0.001665377530589467\n",
      "Training Loss: 0.0013471981667680666\n",
      "Training Loss: 0.0015622224847174947\n",
      "Validation Loss: 0.004407256155157957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.011454224684275687\n",
      "Training Loss: 0.011034730109386146\n",
      "Training Loss: 0.010892862282926217\n",
      "Training Loss: 0.006552978915715357\n",
      "Training Loss: 0.0016144669990171678\n",
      "Training Loss: 0.0013140689296415075\n",
      "Training Loss: 0.0015308513605850748\n",
      "Validation Loss: 0.0039464157736992765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.010427600624971091\n",
      "Training Loss: 0.010110751858446747\n",
      "Training Loss: 0.009963569307001308\n",
      "Training Loss: 0.006071216173004359\n",
      "Training Loss: 0.001528797934006434\n",
      "Training Loss: 0.0012508837698260323\n",
      "Training Loss: 0.0014619539626437473\n",
      "Validation Loss: 0.0035506386825664856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.009631145324092358\n",
      "Training Loss: 0.009393828770844265\n",
      "Training Loss: 0.00923911801772192\n",
      "Training Loss: 0.005686246527329786\n",
      "Training Loss: 0.0014306810665584634\n",
      "Training Loss: 0.0011762341124995147\n",
      "Training Loss: 0.0013784371072688372\n",
      "Validation Loss: 0.0032202559031680408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.009038235387997702\n",
      "Training Loss: 0.008857582065975294\n",
      "Training Loss: 0.008692738817771897\n",
      "Training Loss: 0.005391077648819191\n",
      "Training Loss: 0.001335733759769937\n",
      "Training Loss: 0.0011030544753884897\n",
      "Training Loss: 0.001295307699474506\n",
      "Validation Loss: 0.0029511618665995056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008616098517086357\n",
      "Training Loss: 0.008471732201287522\n",
      "Training Loss: 0.008295043945545331\n",
      "Training Loss: 0.005174507420015288\n",
      "Training Loss: 0.0012529043119138806\n",
      "Training Loss: 0.0010385996039258315\n",
      "Training Loss: 0.0012209855921537383\n",
      "Validation Loss: 0.002737267436860792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008330325512215495\n",
      "Training Loss: 0.00820584045141004\n",
      "Training Loss: 0.00801625466439873\n",
      "Training Loss: 0.0050224239712406415\n",
      "Training Loss: 0.0011854598424542928\n",
      "Training Loss: 0.000985634056996787\n",
      "Training Loss: 0.0011589574492245447\n",
      "Validation Loss: 0.002571308487317305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008146710748551413\n",
      "Training Loss: 0.00803021977422759\n",
      "Training Loss: 0.007826963731786237\n",
      "Training Loss: 0.004919154962844913\n",
      "Training Loss: 0.0011329814889177213\n",
      "Training Loss: 0.0009440666317823343\n",
      "Training Loss: 0.001109466689376859\n",
      "Validation Loss: 0.0024451921664113844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008033321981783956\n",
      "Training Loss: 0.007917326395399868\n",
      "Training Loss: 0.007700059611815959\n",
      "Training Loss: 0.004849637277802685\n",
      "Training Loss: 0.0010931921115843578\n",
      "Training Loss: 0.0009122824382211547\n",
      "Training Loss: 0.001070894237200264\n",
      "Validation Loss: 0.002350523978714179\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007963398712454363\n",
      "Training Loss: 0.007844110256992281\n",
      "Training Loss: 0.007613259246572852\n",
      "Training Loss: 0.004801412793021882\n",
      "Training Loss: 0.0010631796316010877\n",
      "Training Loss: 0.0008880513909389265\n",
      "Training Loss: 0.0010407876552199014\n",
      "Validation Loss: 0.002279405898505243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.007917426060885191\n",
      "Training Loss: 0.007793677963782102\n",
      "Training Loss: 0.0075504705950152125\n",
      "Training Loss: 0.004765514649479882\n",
      "Training Loss: 0.0010401312969770516\n",
      "Training Loss: 0.0008691364839614835\n",
      "Training Loss: 0.0010165998565935296\n",
      "Validation Loss: 0.0022251341976565467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00788307075505145\n",
      "Training Loss: 0.007755190226016566\n",
      "Training Loss: 0.007501329153310508\n",
      "Training Loss: 0.004736175809230189\n",
      "Training Loss: 0.0010216812787984964\n",
      "Training Loss: 0.000853600539121544\n",
      "Training Loss: 0.0009960746436991031\n",
      "Validation Loss: 0.0021824582893233955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00785350693622604\n",
      "Training Loss: 0.007722422519000247\n",
      "Training Loss: 0.007459681242471561\n",
      "Training Loss: 0.0047099558316404\n",
      "Training Loss: 0.0010059868386451854\n",
      "Training Loss: 0.0008399103359261062\n",
      "Training Loss: 0.0009773742425750243\n",
      "Validation Loss: 0.0021475024214180098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007825384752359242\n",
      "Training Loss: 0.007692097234539687\n",
      "Training Loss: 0.0074220322258770465\n",
      "Training Loss: 0.004684860221022973\n",
      "Training Loss: 0.0009916670607344714\n",
      "Training Loss: 0.0008268953226797748\n",
      "Training Loss: 0.0009590535693860148\n",
      "Validation Loss: 0.0021174903664727476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0077972419571597125\n",
      "Training Loss: 0.00766256517264992\n",
      "Training Loss: 0.0073863722302485255\n",
      "Training Loss: 0.004659721768257441\n",
      "Training Loss: 0.0009777005160867703\n",
      "Training Loss: 0.0008136721460323315\n",
      "Training Loss: 0.0009399533030227758\n",
      "Validation Loss: 0.00209046226578646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007768537644296885\n",
      "Training Loss: 0.007633006136165932\n",
      "Training Loss: 0.007351486068218946\n",
      "Training Loss: 0.004633803391043329\n",
      "Training Loss: 0.0009633050364936935\n",
      "Training Loss: 0.0007995494367787615\n",
      "Training Loss: 0.0009190979847335256\n",
      "Validation Loss: 0.002065011590966878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007739132998976856\n",
      "Training Loss: 0.007602977277711034\n",
      "Training Loss: 0.007316542025655508\n",
      "Training Loss: 0.0046065741080383305\n",
      "Training Loss: 0.0009478410089650424\n",
      "Training Loss: 0.0007839492287166649\n",
      "Training Loss: 0.0008955974842683645\n",
      "Validation Loss: 0.0020401245879082615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007709057267056778\n",
      "Training Loss: 0.007572209114441648\n",
      "Training Loss: 0.007280903162900358\n",
      "Training Loss: 0.004577589180407813\n",
      "Training Loss: 0.0009307400765828788\n",
      "Training Loss: 0.0007663548259733943\n",
      "Training Loss: 0.0008685786938440287\n",
      "Validation Loss: 0.0020150664404831645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007678399144206196\n",
      "Training Loss: 0.0075404893246013675\n",
      "Training Loss: 0.007244037559721619\n",
      "Training Loss: 0.004546432061033556\n",
      "Training Loss: 0.0009114123911422212\n",
      "Training Loss: 0.0007462364409002476\n",
      "Training Loss: 0.0008371367314975942\n",
      "Validation Loss: 0.0019893501495004177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007647277587093413\n",
      "Training Loss: 0.00750762052484788\n",
      "Training Loss: 0.00720550069003366\n",
      "Training Loss: 0.0045126825285842645\n",
      "Training Loss: 0.0008892118379299063\n",
      "Training Loss: 0.0007230281938973348\n",
      "Training Loss: 0.0008003430576354731\n",
      "Validation Loss: 0.0019627610226519306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007615871339803562\n",
      "Training Loss: 0.007473413029219955\n",
      "Training Loss: 0.0071650030370801684\n",
      "Training Loss: 0.004475921708071837\n",
      "Training Loss: 0.0008633930096402765\n",
      "Training Loss: 0.0006961261069955071\n",
      "Training Loss: 0.0007573852891800925\n",
      "Validation Loss: 0.0019355349121475767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007584392880089581\n",
      "Training Loss: 0.007437651678919792\n",
      "Training Loss: 0.007122480124235153\n",
      "Training Loss: 0.004435807327681686\n",
      "Training Loss: 0.0008331991295563057\n",
      "Training Loss: 0.0006650312132842373\n",
      "Training Loss: 0.0007079559654812329\n",
      "Validation Loss: 0.0019084738433615685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00755302952020429\n",
      "Training Loss: 0.007400067370617762\n",
      "Training Loss: 0.007078167318832129\n",
      "Training Loss: 0.0043921758524084\n",
      "Training Loss: 0.0007980966199829709\n",
      "Training Loss: 0.0006296854948595865\n",
      "Training Loss: 0.0006528779489599401\n",
      "Validation Loss: 0.0018828614767072269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007521650034468621\n",
      "Training Loss: 0.007360255811363459\n",
      "Training Loss: 0.007032469391124323\n",
      "Training Loss: 0.004345184258709196\n",
      "Training Loss: 0.0007581986304285238\n",
      "Training Loss: 0.0005909483547293349\n",
      "Training Loss: 0.0005945679928845493\n",
      "Validation Loss: 0.001859829672686372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0074894153908826415\n",
      "Training Loss: 0.0073175506631378085\n",
      "Training Loss: 0.006985463706078008\n",
      "Training Loss: 0.004295460806170013\n",
      "Training Loss: 0.0007146873486635741\n",
      "Training Loss: 0.0005507882723031799\n",
      "Training Loss: 0.0005365715515654302\n",
      "Validation Loss: 0.0018396545199359932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0074547553923912345\n",
      "Training Loss: 0.00727093088789843\n",
      "Training Loss: 0.006936372705968097\n",
      "Training Loss: 0.0042441020156547896\n",
      "Training Loss: 0.0006695873398712138\n",
      "Training Loss: 0.0005116119759622961\n",
      "Training Loss: 0.0004821251809335081\n",
      "Validation Loss: 0.0018221478772891184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0074160850758198645\n",
      "Training Loss: 0.007219188269227743\n",
      "Training Loss: 0.006883829719154164\n",
      "Training Loss: 0.004192399475432467\n",
      "Training Loss: 0.0006248347061045933\n",
      "Training Loss: 0.0004751724247762468\n",
      "Training Loss: 0.00043310933462635147\n",
      "Validation Loss: 0.0018076051497149146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007372646400472149\n",
      "Training Loss: 0.0071616160892881454\n",
      "Training Loss: 0.006827039136551321\n",
      "Training Loss: 0.0041414284182974374\n",
      "Training Loss: 0.0005815351976343663\n",
      "Training Loss: 0.000442198626260506\n",
      "Training Loss: 0.00039024532947223633\n",
      "Validation Loss: 0.00179687406077906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007324749431572855\n",
      "Training Loss: 0.0070988083933480085\n",
      "Training Loss: 0.006766585673904047\n",
      "Training Loss: 0.00409191114740679\n",
      "Training Loss: 0.0005403069905878511\n",
      "Training Loss: 0.0004128482118539978\n",
      "Training Loss: 0.0003537538459931966\n",
      "Validation Loss: 0.0017907459997137736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007273533201077953\n",
      "Training Loss: 0.007032691173953935\n",
      "Training Loss: 0.006704215040663257\n",
      "Training Loss: 0.0040443672318360765\n",
      "Training Loss: 0.0005019341602019267\n",
      "Training Loss: 0.0003871411116051604\n",
      "Training Loss: 0.00032370732002164006\n",
      "Validation Loss: 0.0017895028528679784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0072205442504491655\n",
      "Training Loss: 0.006965863786172121\n",
      "Training Loss: 0.006642060910817236\n",
      "Training Loss: 0.003999278091723682\n",
      "Training Loss: 0.00046746983782213646\n",
      "Training Loss: 0.0003651069929037476\n",
      "Training Loss: 0.00029999924805451883\n",
      "Validation Loss: 0.00179281605840665\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 37\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007167223508004099\n",
      "Training Loss: 0.00690074059413746\n",
      "Training Loss: 0.006581945684738457\n",
      "Training Loss: 0.003957117485551862\n",
      "Training Loss: 0.00043780136817076707\n",
      "Training Loss: 0.0003467511760391062\n",
      "Training Loss: 0.00028219697229360464\n",
      "Validation Loss: 0.0017997971359561442\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 38\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007114659808576107\n",
      "Training Loss: 0.006839053881121799\n",
      "Training Loss: 0.006525040853302926\n",
      "Training Loss: 0.003918313057656633\n",
      "Training Loss: 0.0004132973750893143\n",
      "Training Loss: 0.00033196442418557124\n",
      "Training Loss: 0.000269532633064955\n",
      "Validation Loss: 0.0018091129303060922\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 39\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007063580424292013\n",
      "Training Loss: 0.006781726764747873\n",
      "Training Loss: 0.006471867387881502\n",
      "Training Loss: 0.003883115853459458\n",
      "Training Loss: 0.0003937717035660171\n",
      "Training Loss: 0.0003204622488919995\n",
      "Training Loss: 0.00026105639906745634\n",
      "Validation Loss: 0.0018192094201381207\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 40\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007014434662414715\n",
      "Training Loss: 0.00672901482321322\n",
      "Training Loss: 0.0064224821189418435\n",
      "Training Loss: 0.003851555231749444\n",
      "Training Loss: 0.0003786549375217874\n",
      "Training Loss: 0.0003117933473549783\n",
      "Training Loss: 0.0002558190797935822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:03<09:28, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0018286267608046193\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 41\n",
      "Early stopping after 41 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.42176127672195435\n",
      "Training Loss: 0.3070780324190855\n",
      "Training Loss: 0.19552391223609447\n",
      "Training Loss: 0.09326465732418\n",
      "Training Loss: 0.04998886138666421\n",
      "Training Loss: 0.046106445202603936\n",
      "Training Loss: 0.04760081340558827\n",
      "Validation Loss: 0.05363020335746169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06561742205172777\n",
      "Training Loss: 0.06422138864174486\n",
      "Training Loss: 0.06375715361908078\n",
      "Training Loss: 0.05374377598142019\n",
      "Training Loss: 0.041332180891185996\n",
      "Training Loss: 0.03964565138798207\n",
      "Training Loss: 0.04093392410315573\n",
      "Validation Loss: 0.04682814975858628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.0584881847910583\n",
      "Training Loss: 0.05698623228818178\n",
      "Training Loss: 0.056341107785701755\n",
      "Training Loss: 0.045982186043820546\n",
      "Training Loss: 0.03338194869458675\n",
      "Training Loss: 0.031708993492648004\n",
      "Training Loss: 0.0325414772843942\n",
      "Validation Loss: 0.03861651807144452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04999975395388901\n",
      "Training Loss: 0.04835774540901184\n",
      "Training Loss: 0.047640404189005496\n",
      "Training Loss: 0.03712094333925051\n",
      "Training Loss: 0.0246670145355165\n",
      "Training Loss: 0.023290646898094566\n",
      "Training Loss: 0.02374776083510369\n",
      "Validation Loss: 0.03010684081914831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.041126771681010726\n",
      "Training Loss: 0.03941332412883639\n",
      "Training Loss: 0.03875352705828845\n",
      "Training Loss: 0.028449010110925883\n",
      "Training Loss: 0.01677345559000969\n",
      "Training Loss: 0.015739164375700058\n",
      "Training Loss: 0.016000064022373407\n",
      "Validation Loss: 0.02241357481578009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.0328752729203552\n",
      "Training Loss: 0.03125332404859364\n",
      "Training Loss: 0.030828102570958436\n",
      "Training Loss: 0.021249164009932427\n",
      "Training Loss: 0.010862114715855568\n",
      "Training Loss: 0.01016283996985294\n",
      "Training Loss: 0.010437731601996347\n",
      "Validation Loss: 0.016574464729648738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.026286031967028976\n",
      "Training Loss: 0.02487626411486417\n",
      "Training Loss: 0.024714585128240287\n",
      "Training Loss: 0.01615476783015765\n",
      "Training Loss: 0.007146907539572566\n",
      "Training Loss: 0.006654995991848409\n",
      "Training Loss: 0.00693560425308533\n",
      "Validation Loss: 0.012566062317435605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.021407993515022098\n",
      "Training Loss: 0.020206666770391166\n",
      "Training Loss: 0.020191834813449532\n",
      "Training Loss: 0.012653067065402866\n",
      "Training Loss: 0.004882408290286549\n",
      "Training Loss: 0.004489087084075436\n",
      "Training Loss: 0.004741211439250037\n",
      "Validation Loss: 0.009810480604834212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01775788143509999\n",
      "Training Loss: 0.016727357006166132\n",
      "Training Loss: 0.01673203822923824\n",
      "Training Loss: 0.010110272857709789\n",
      "Training Loss: 0.003387668197101448\n",
      "Training Loss: 0.0030369916144991293\n",
      "Training Loss: 0.0032369008980458604\n",
      "Validation Loss: 0.0077643936773769085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.014862421341240406\n",
      "Training Loss: 0.013954666154459118\n",
      "Training Loss: 0.013889878005720675\n",
      "Training Loss: 0.008116253813204822\n",
      "Training Loss: 0.0022859174807672387\n",
      "Training Loss: 0.001971702334994916\n",
      "Training Loss: 0.0021339571045245974\n",
      "Validation Loss: 0.006065015942259423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012499179979786277\n",
      "Training Loss: 0.01174241465749219\n",
      "Training Loss: 0.011639806835446506\n",
      "Training Loss: 0.006734586854872759\n",
      "Training Loss: 0.0015851700275379698\n",
      "Training Loss: 0.0013455992224044166\n",
      "Training Loss: 0.001520766760368133\n",
      "Validation Loss: 0.004721875146183112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010895244365092366\n",
      "Training Loss: 0.010356652569025755\n",
      "Training Loss: 0.010289505399996415\n",
      "Training Loss: 0.006059160718577914\n",
      "Training Loss: 0.0012901711614176747\n",
      "Training Loss: 0.0011053167089994532\n",
      "Training Loss: 0.0012774986738804729\n",
      "Validation Loss: 0.003790850570374814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00999300965340808\n",
      "Training Loss: 0.009618196000810713\n",
      "Training Loss: 0.009577308953739703\n",
      "Training Loss: 0.005708577658515424\n",
      "Training Loss: 0.0011467575255301198\n",
      "Training Loss: 0.000983702484954847\n",
      "Training Loss: 0.0011401771487726364\n",
      "Validation Loss: 0.0032244870802806166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009473798867547885\n",
      "Training Loss: 0.009194949590601027\n",
      "Training Loss: 0.009162731856340542\n",
      "Training Loss: 0.005487623073859141\n",
      "Training Loss: 0.0010474485714439651\n",
      "Training Loss: 0.0008973756842169678\n",
      "Training Loss: 0.0010392659637727775\n",
      "Validation Loss: 0.0028997902979259814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009165186771424487\n",
      "Training Loss: 0.008940086234360933\n",
      "Training Loss: 0.008905339335324242\n",
      "Training Loss: 0.005341359372541774\n",
      "Training Loss: 0.0009697826554474887\n",
      "Training Loss: 0.0008301809468684951\n",
      "Training Loss: 0.0009599572249862831\n",
      "Validation Loss: 0.002701127493674675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008977219434455038\n",
      "Training Loss: 0.0087819677463267\n",
      "Training Loss: 0.008739247306948528\n",
      "Training Loss: 0.0052408077933068856\n",
      "Training Loss: 0.0009066166603588499\n",
      "Training Loss: 0.0007758898220345146\n",
      "Training Loss: 0.0008961750270100311\n",
      "Validation Loss: 0.0025674241488365186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008859231991227717\n",
      "Training Loss: 0.008680570714641362\n",
      "Training Loss: 0.008627765737473965\n",
      "Training Loss: 0.005168718583445297\n",
      "Training Loss: 0.0008548507296654861\n",
      "Training Loss: 0.0007315414305776358\n",
      "Training Loss: 0.0008446683722286252\n",
      "Validation Loss: 0.0024709775807355157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008781731181079522\n",
      "Training Loss: 0.00861242918879725\n",
      "Training Loss: 0.008549097351497038\n",
      "Training Loss: 0.005114600241213339\n",
      "Training Loss: 0.0008125214085157495\n",
      "Training Loss: 0.0006953153442009352\n",
      "Training Loss: 0.0008031622113048798\n",
      "Validation Loss: 0.0023985072526856665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008727259858278557\n",
      "Training Loss: 0.008563534886343404\n",
      "Training Loss: 0.008490061471238732\n",
      "Training Loss: 0.005071957003383432\n",
      "Training Loss: 0.0007779982479405589\n",
      "Training Loss: 0.0006657752591127064\n",
      "Training Loss: 0.0007697841662593418\n",
      "Validation Loss: 0.002342659523172133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00868558296118863\n",
      "Training Loss: 0.008525601642904803\n",
      "Training Loss: 0.008442755759460852\n",
      "Training Loss: 0.005036769462458323\n",
      "Training Loss: 0.0007498581238542101\n",
      "Training Loss: 0.0006417058944498421\n",
      "Training Loss: 0.0007429495848191437\n",
      "Validation Loss: 0.002298767421192277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008650870177662\n",
      "Training Loss: 0.008493859937880188\n",
      "Training Loss: 0.008402537208748981\n",
      "Training Loss: 0.005006578299944522\n",
      "Training Loss: 0.000726892218881403\n",
      "Training Loss: 0.0006220807495265035\n",
      "Training Loss: 0.0007213428096292773\n",
      "Validation Loss: 0.0022636149041001486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00861993509111926\n",
      "Training Loss: 0.008465661950176583\n",
      "Training Loss: 0.008366740599740297\n",
      "Training Loss: 0.004979889664100483\n",
      "Training Loss: 0.0007081052108696894\n",
      "Training Loss: 0.0006060565351072001\n",
      "Training Loss: 0.0007038952799484832\n",
      "Validation Loss: 0.002234913422872159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008591119281481952\n",
      "Training Loss: 0.008439579040277749\n",
      "Training Loss: 0.008333854756783695\n",
      "Training Loss: 0.004955790802196134\n",
      "Training Loss: 0.0006926987130282214\n",
      "Training Loss: 0.000592953401755949\n",
      "Training Loss: 0.0006897559237404494\n",
      "Validation Loss: 0.002211007459742307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008563600030029192\n",
      "Training Loss: 0.008414855664595962\n",
      "Training Loss: 0.008303017283324152\n",
      "Training Loss: 0.004933704862050945\n",
      "Training Loss: 0.0006800348378965281\n",
      "Training Loss: 0.0005822252994403243\n",
      "Training Loss: 0.0006782463572744746\n",
      "Validation Loss: 0.002190689979123705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008536986517719924\n",
      "Training Loss: 0.008391087597701699\n",
      "Training Loss: 0.008273722174344585\n",
      "Training Loss: 0.004913246246869676\n",
      "Training Loss: 0.000669601979534491\n",
      "Training Loss: 0.00057343259195477\n",
      "Training Loss: 0.0006688280451635364\n",
      "Validation Loss: 0.0021730764468278116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008511097172740846\n",
      "Training Loss: 0.008368047662079334\n",
      "Training Loss: 0.008245652198093012\n",
      "Training Loss: 0.0048941317570279355\n",
      "Training Loss: 0.0006609863304765895\n",
      "Training Loss: 0.0005662161473810556\n",
      "Training Loss: 0.0006610697197174886\n",
      "Validation Loss: 0.00215751330304127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008485838428605348\n",
      "Training Loss: 0.008345588750671595\n",
      "Training Loss: 0.00821857902687043\n",
      "Training Loss: 0.004876141101995017\n",
      "Training Loss: 0.0006538548376192921\n",
      "Training Loss: 0.0005602864029060584\n",
      "Training Loss: 0.0006546292088751215\n",
      "Validation Loss: 0.002143514516684035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008461151340743527\n",
      "Training Loss: 0.008323607087368146\n",
      "Training Loss: 0.008192336289212107\n",
      "Training Loss: 0.004859092940605479\n",
      "Training Loss: 0.0006479356578347506\n",
      "Training Loss: 0.0005554053022569861\n",
      "Training Loss: 0.000649232944342657\n",
      "Validation Loss: 0.0021307153889101892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008436981908744201\n",
      "Training Loss: 0.008302014691289515\n",
      "Training Loss: 0.008166781548643485\n",
      "Training Loss: 0.00484282946024905\n",
      "Training Loss: 0.0006430101242585806\n",
      "Training Loss: 0.0005513806919043418\n",
      "Training Loss: 0.0006446673625032418\n",
      "Validation Loss: 0.0021188458677839964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008413277053041384\n",
      "Training Loss: 0.008280738039175048\n",
      "Training Loss: 0.008141792635433376\n",
      "Training Loss: 0.004827218421414727\n",
      "Training Loss: 0.0006389047377524549\n",
      "Training Loss: 0.0005480602005627588\n",
      "Training Loss: 0.0006407658787065885\n",
      "Validation Loss: 0.0021077031973829627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008389980404172093\n",
      "Training Loss: 0.008259709326084703\n",
      "Training Loss: 0.00811726298648864\n",
      "Training Loss: 0.00481214700921555\n",
      "Training Loss: 0.0006354821488639572\n",
      "Training Loss: 0.0005453219641640317\n",
      "Training Loss: 0.0006373995058675064\n",
      "Validation Loss: 0.002097128780470631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.008367034676484763\n",
      "Training Loss: 0.00823887161561288\n",
      "Training Loss: 0.00809309617150575\n",
      "Training Loss: 0.004797518102277536\n",
      "Training Loss: 0.0006326339398947311\n",
      "Training Loss: 0.0005430690979483188\n",
      "Training Loss: 0.0006344692136190133\n",
      "Validation Loss: 0.0020870045226957642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.008344387713586912\n",
      "Training Loss: 0.008218175589572638\n",
      "Training Loss: 0.008069212066475302\n",
      "Training Loss: 0.0047832502849632875\n",
      "Training Loss: 0.0006302749801398022\n",
      "Training Loss: 0.0005412260230150422\n",
      "Training Loss: 0.00063189993139531\n",
      "Validation Loss: 0.0020772407863861165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.008321989465039224\n",
      "Training Loss: 0.008197580841369926\n",
      "Training Loss: 0.008045539777958766\n",
      "Training Loss: 0.004769275378785096\n",
      "Training Loss: 0.0006283366689967807\n",
      "Training Loss: 0.0005397307285602437\n",
      "Training Loss: 0.0006296334018406923\n",
      "Validation Loss: 0.0020677672092709516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.008299794695340097\n",
      "Training Loss: 0.008177052718820051\n",
      "Training Loss: 0.008022019490599632\n",
      "Training Loss: 0.004755540741607547\n",
      "Training Loss: 0.0006267695032511256\n",
      "Training Loss: 0.0005385384284454631\n",
      "Training Loss: 0.0006276267323846696\n",
      "Validation Loss: 0.0020585257066993655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.008277764355298131\n",
      "Training Loss: 0.008156564040109514\n",
      "Training Loss: 0.007998599720885978\n",
      "Training Loss: 0.004741999427060364\n",
      "Training Loss: 0.0006255313286237652\n",
      "Training Loss: 0.0005376088945558877\n",
      "Training Loss: 0.0006258442539547104\n",
      "Validation Loss: 0.002049477567415761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00825586854130961\n",
      "Training Loss: 0.008136097773676737\n",
      "Training Loss: 0.007975244994740933\n",
      "Training Loss: 0.004728616069623968\n",
      "Training Loss: 0.0006245864829179481\n",
      "Training Loss: 0.0005369095716014271\n",
      "Training Loss: 0.0006242577439843444\n",
      "Validation Loss: 0.0020405840361817857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.008234080740949138\n",
      "Training Loss: 0.008115639840252698\n",
      "Training Loss: 0.007951924108201638\n",
      "Training Loss: 0.004715362611314049\n",
      "Training Loss: 0.0006239057863422204\n",
      "Training Loss: 0.0005364122776154545\n",
      "Training Loss: 0.0006228437768004369\n",
      "Validation Loss: 0.0020318178772622867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.008212383550126106\n",
      "Training Loss: 0.008095186108257622\n",
      "Training Loss: 0.007928618369624019\n",
      "Training Loss: 0.0047022173470759295\n",
      "Training Loss: 0.000623462753574131\n",
      "Training Loss: 0.0005360902089887532\n",
      "Training Loss: 0.000621579455328174\n",
      "Validation Loss: 0.0020231557745649565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00819076974526979\n",
      "Training Loss: 0.00807473732624203\n",
      "Training Loss: 0.007905318753328174\n",
      "Training Loss: 0.004689166451134952\n",
      "Training Loss: 0.0006232339006237452\n",
      "Training Loss: 0.0005359217981094844\n",
      "Training Loss: 0.0006204467744828435\n",
      "Validation Loss: 0.0020145774643025834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.008169233246007934\n",
      "Training Loss: 0.008054300297517329\n",
      "Training Loss: 0.007882019756361842\n",
      "Training Loss: 0.004676199026725954\n",
      "Training Loss: 0.0006231965789629612\n",
      "Training Loss: 0.0005358835317383636\n",
      "Training Loss: 0.0006194266006787075\n",
      "Validation Loss: 0.0020060671357375183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.008147775861434638\n",
      "Training Loss: 0.008033885180484503\n",
      "Training Loss: 0.00785872693755664\n",
      "Training Loss: 0.004663307736409479\n",
      "Training Loss: 0.0006233273874386214\n",
      "Training Loss: 0.0005359525598032633\n",
      "Training Loss: 0.0006185001013363945\n",
      "Validation Loss: 0.001997607330114089\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.008126408476382494\n",
      "Training Loss: 0.008013511114986613\n",
      "Training Loss: 0.007835451302817091\n",
      "Training Loss: 0.004650492179207504\n",
      "Training Loss: 0.0006236047775746556\n",
      "Training Loss: 0.0005361085640106467\n",
      "Training Loss: 0.0006176493073871825\n",
      "Validation Loss: 0.0019891905714539736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.008105142567073927\n",
      "Training Loss: 0.00799319624202326\n",
      "Training Loss: 0.007812209236435592\n",
      "Training Loss: 0.004637752699636621\n",
      "Training Loss: 0.0006240076904941816\n",
      "Training Loss: 0.000536329886999738\n",
      "Training Loss: 0.0006168566226551775\n",
      "Validation Loss: 0.0019808071730322684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.008083996035857126\n",
      "Training Loss: 0.007972964001819492\n",
      "Training Loss: 0.007789020921336487\n",
      "Training Loss: 0.004625092950736871\n",
      "Training Loss: 0.0006245141229737782\n",
      "Training Loss: 0.0005365961947245523\n",
      "Training Loss: 0.0006161050088849152\n",
      "Validation Loss: 0.001972448912199346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.008062985789729282\n",
      "Training Loss: 0.007952839322388171\n",
      "Training Loss: 0.007765911179594695\n",
      "Training Loss: 0.004612518668509437\n",
      "Training Loss: 0.0006251042228541337\n",
      "Training Loss: 0.0005368883629853371\n",
      "Training Loss: 0.0006153766063653165\n",
      "Validation Loss: 0.0019641075411803623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.008042137745069339\n",
      "Training Loss: 0.00793285055900924\n",
      "Training Loss: 0.007742907773936167\n",
      "Training Loss: 0.004600037567142863\n",
      "Training Loss: 0.0006257560595258838\n",
      "Training Loss: 0.0005371856598503655\n",
      "Training Loss: 0.000614654432356474\n",
      "Validation Loss: 0.0019557788480406325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.008021473905537278\n",
      "Training Loss: 0.007913023683940992\n",
      "Training Loss: 0.007720037805847823\n",
      "Training Loss: 0.004587656339572277\n",
      "Training Loss: 0.0006264506109437207\n",
      "Training Loss: 0.0005374726472291513\n",
      "Training Loss: 0.0006139246725797421\n",
      "Validation Loss: 0.001947463599290029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00800101608154364\n",
      "Training Loss: 0.007893384242197498\n",
      "Training Loss: 0.007697329544462264\n",
      "Training Loss: 0.0045753856902592815\n",
      "Training Loss: 0.0006271708657004638\n",
      "Training Loss: 0.0005377325617882889\n",
      "Training Loss: 0.0006131727934553055\n",
      "Validation Loss: 0.0019391590973740786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007980788316344842\n",
      "Training Loss: 0.007873959076823667\n",
      "Training Loss: 0.007674811145989224\n",
      "Training Loss: 0.0045632332794048125\n",
      "Training Loss: 0.0006278988564008614\n",
      "Training Loss: 0.0005379510955754085\n",
      "Training Loss: 0.000612386238281033\n",
      "Validation Loss: 0.0019308654864493946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007960813487879932\n",
      "Training Loss: 0.007854770923731848\n",
      "Training Loss: 0.0076525114430114624\n",
      "Training Loss: 0.004551208860430051\n",
      "Training Loss: 0.0006286186360375723\n",
      "Training Loss: 0.0005381145911087515\n",
      "Training Loss: 0.0006115528246300527\n",
      "Validation Loss: 0.0019225804286717686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007941109624225647\n",
      "Training Loss: 0.007835840140469372\n",
      "Training Loss: 0.007630451428703964\n",
      "Training Loss: 0.004539321260454017\n",
      "Training Loss: 0.0006293198430648772\n",
      "Training Loss: 0.0005382146764532081\n",
      "Training Loss: 0.0006106649903085781\n",
      "Validation Loss: 0.0019143102091605415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007921693585813046\n",
      "Training Loss: 0.007817184833111241\n",
      "Training Loss: 0.007608654908835888\n",
      "Training Loss: 0.0045275787454738745\n",
      "Training Loss: 0.0006299891514936463\n",
      "Training Loss: 0.0005382426136930008\n",
      "Training Loss: 0.0006097161628713366\n",
      "Validation Loss: 0.001906057467099021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007902579189976677\n",
      "Training Loss: 0.007798818730516359\n",
      "Training Loss: 0.00758713856106624\n",
      "Training Loss: 0.004515988164421288\n",
      "Training Loss: 0.000630619455332635\n",
      "Training Loss: 0.0005381926144764293\n",
      "Training Loss: 0.000608699712829548\n",
      "Validation Loss: 0.001897824909688455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007883779964176938\n",
      "Training Loss: 0.007780754970153794\n",
      "Training Loss: 0.007565919040935114\n",
      "Training Loss: 0.004504556557294564\n",
      "Training Loss: 0.0006312039942713455\n",
      "Training Loss: 0.000538062826381065\n",
      "Training Loss: 0.0006076163522084244\n",
      "Validation Loss: 0.0018896226554695685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007865297278622166\n",
      "Training Loss: 0.007762997865211218\n",
      "Training Loss: 0.007545008480083198\n",
      "Training Loss: 0.004493288697849493\n",
      "Training Loss: 0.0006317390741605777\n",
      "Training Loss: 0.0005378505350381601\n",
      "Training Loss: 0.000606461945353658\n",
      "Validation Loss: 0.0018814495441587537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007847139878431336\n",
      "Training Loss: 0.007745553886052221\n",
      "Training Loss: 0.0075244125642348085\n",
      "Training Loss: 0.004482188538167975\n",
      "Training Loss: 0.00063222130331269\n",
      "Training Loss: 0.0005375574557547225\n",
      "Training Loss: 0.000605239779833937\n",
      "Validation Loss: 0.0018733188304797248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007829306473722682\n",
      "Training Loss: 0.007728423125809058\n",
      "Training Loss: 0.007504136329516769\n",
      "Training Loss: 0.004471260949212592\n",
      "Training Loss: 0.0006326531194645213\n",
      "Training Loss: 0.000537187680893112\n",
      "Training Loss: 0.0006039537247124827\n",
      "Validation Loss: 0.0018652329950162633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007811795267043635\n",
      "Training Loss: 0.00771160245523788\n",
      "Training Loss: 0.007484181146137417\n",
      "Training Loss: 0.00446050747676054\n",
      "Training Loss: 0.0006330358381819678\n",
      "Training Loss: 0.0005367459458648227\n",
      "Training Loss: 0.0006026073909015394\n",
      "Validation Loss: 0.0018571982349222002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007794600744964555\n",
      "Training Loss: 0.007695087610627525\n",
      "Training Loss: 0.007464545429684222\n",
      "Training Loss: 0.004449928890462616\n",
      "Training Loss: 0.0006333718797395704\n",
      "Training Loss: 0.0005362369203066919\n",
      "Training Loss: 0.0006012063035450411\n",
      "Validation Loss: 0.0018492254656054994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007777717075077817\n",
      "Training Loss: 0.00767887267516926\n",
      "Training Loss: 0.007445226638810709\n",
      "Training Loss: 0.004439526153291808\n",
      "Training Loss: 0.0006336670782184228\n",
      "Training Loss: 0.0005356689087784617\n",
      "Training Loss: 0.0005997581723204349\n",
      "Validation Loss: 0.001841319266777339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007761135825421661\n",
      "Training Loss: 0.007662948027136736\n",
      "Training Loss: 0.007426216749008745\n",
      "Training Loss: 0.004429301380150718\n",
      "Training Loss: 0.0006339263152767671\n",
      "Training Loss: 0.0005350490326964064\n",
      "Training Loss: 0.0005982684186164988\n",
      "Validation Loss: 0.0018334866377999414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007744846666464582\n",
      "Training Loss: 0.007647302930708974\n",
      "Training Loss: 0.007407506842864678\n",
      "Training Loss: 0.004419250935534365\n",
      "Training Loss: 0.0006341564026661217\n",
      "Training Loss: 0.0005343870915385196\n",
      "Training Loss: 0.0005967475408397149\n",
      "Validation Loss: 0.0018257351456147232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00772883660858497\n",
      "Training Loss: 0.00763192675774917\n",
      "Training Loss: 0.00738908929284662\n",
      "Training Loss: 0.004409373647431494\n",
      "Training Loss: 0.0006343652979558101\n",
      "Training Loss: 0.0005336920152331004\n",
      "Training Loss: 0.0005952029519539792\n",
      "Validation Loss: 0.0018180711160536876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007713095260551199\n",
      "Training Loss: 0.007616806480800733\n",
      "Training Loss: 0.0073709518602117895\n",
      "Training Loss: 0.00439966800622642\n",
      "Training Loss: 0.0006345596849132562\n",
      "Training Loss: 0.0005329725470801349\n",
      "Training Loss: 0.0005936424474930391\n",
      "Validation Loss: 0.001810501025645638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007697607838781551\n",
      "Training Loss: 0.0076019279251340775\n",
      "Training Loss: 0.007353081504115835\n",
      "Training Loss: 0.004390131926847971\n",
      "Training Loss: 0.0006347474648646312\n",
      "Training Loss: 0.0005322382740996545\n",
      "Training Loss: 0.0005920749122014968\n",
      "Validation Loss: 0.0018030279395035347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007682362416526303\n",
      "Training Loss: 0.007587278735591099\n",
      "Training Loss: 0.007335466938093305\n",
      "Training Loss: 0.004380761276843259\n",
      "Training Loss: 0.0006349351348035271\n",
      "Training Loss: 0.0005314980820548954\n",
      "Training Loss: 0.0005905087257997366\n",
      "Validation Loss: 0.0017956598336029666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007667344721267\n",
      "Training Loss: 0.007572842848021537\n",
      "Training Loss: 0.007318092887289822\n",
      "Training Loss: 0.0043715511878690445\n",
      "Training Loss: 0.0006351332959457068\n",
      "Training Loss: 0.0005307619350787718\n",
      "Training Loss: 0.0005889519229822326\n",
      "Validation Loss: 0.0017884018581228902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007652541175484657\n",
      "Training Loss: 0.007558607981191017\n",
      "Training Loss: 0.007300947904586792\n",
      "Training Loss: 0.004362499009439489\n",
      "Training Loss: 0.0006353452672192362\n",
      "Training Loss: 0.0005300355266081169\n",
      "Training Loss: 0.0005874110597505933\n",
      "Validation Loss: 0.0017812568916174432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00763793975696899\n",
      "Training Loss: 0.007544559573289007\n",
      "Training Loss: 0.007284016924677417\n",
      "Training Loss: 0.004353600140020717\n",
      "Training Loss: 0.0006355790183442877\n",
      "Training Loss: 0.0005293284143408528\n",
      "Training Loss: 0.0005858915143471677\n",
      "Validation Loss: 0.0017742280680350506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007623527630930767\n",
      "Training Loss: 0.0075306844810256734\n",
      "Training Loss: 0.007267284478293732\n",
      "Training Loss: 0.004344848264736356\n",
      "Training Loss: 0.0006358408511732705\n",
      "Training Loss: 0.0005286479077039985\n",
      "Training Loss: 0.0005844033545145067\n",
      "Validation Loss: 0.0017673208138230519\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007609289033571259\n",
      "Training Loss: 0.00751696617458947\n",
      "Training Loss: 0.0072507381381001325\n",
      "Training Loss: 0.0043362396215525225\n",
      "Training Loss: 0.0006361370382364839\n",
      "Training Loss: 0.0005279997453180841\n",
      "Training Loss: 0.000582949034505873\n",
      "Validation Loss: 0.001760538576967833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.0075952147750649604\n",
      "Training Loss: 0.007503393206279725\n",
      "Training Loss: 0.0072343640611507\n",
      "Training Loss: 0.004327768740331521\n",
      "Training Loss: 0.0006364733744703699\n",
      "Training Loss: 0.0005273915441648569\n",
      "Training Loss: 0.0005815365340095013\n",
      "Validation Loss: 0.0017538802904924482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0075812901940662415\n",
      "Training Loss: 0.007489950087037869\n",
      "Training Loss: 0.0072181464568711814\n",
      "Training Loss: 0.0043194311395927795\n",
      "Training Loss: 0.0006368533516069874\n",
      "Training Loss: 0.0005268270990200108\n",
      "Training Loss: 0.0005801696199341678\n",
      "Validation Loss: 0.0017473533056756613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00756750387372449\n",
      "Training Loss: 0.0074766238528536635\n",
      "Training Loss: 0.007202073275111616\n",
      "Training Loss: 0.0043112190146348435\n",
      "Training Loss: 0.0006372812034533126\n",
      "Training Loss: 0.0005263107061182382\n",
      "Training Loss: 0.0005788508379919222\n",
      "Validation Loss: 0.0017409553603214222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007553847114322707\n",
      "Training Loss: 0.007463403841247782\n",
      "Training Loss: 0.007186132082715631\n",
      "Training Loss: 0.004303129433901631\n",
      "Training Loss: 0.00063775994014577\n",
      "Training Loss: 0.0005258470963599393\n",
      "Training Loss: 0.0005775851974613033\n",
      "Validation Loss: 0.001734687973769584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007540308847092092\n",
      "Training Loss: 0.007450276829767972\n",
      "Training Loss: 0.0071703066921327266\n",
      "Training Loss: 0.004295153263155953\n",
      "Training Loss: 0.0006382943045900902\n",
      "Training Loss: 0.0005254414786759298\n",
      "Training Loss: 0.0005763785710587399\n",
      "Validation Loss: 0.0017285564148489887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007526872832095251\n",
      "Training Loss: 0.007437226533074864\n",
      "Training Loss: 0.007154586624819785\n",
      "Training Loss: 0.004287287727784132\n",
      "Training Loss: 0.0006388874338153983\n",
      "Training Loss: 0.0005250958425313001\n",
      "Training Loss: 0.0005752321582986042\n",
      "Validation Loss: 0.0017225584749386155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007513534093741328\n",
      "Training Loss: 0.007424245625152252\n",
      "Training Loss: 0.007138957458082586\n",
      "Training Loss: 0.004279526395112043\n",
      "Training Loss: 0.0006395415720908204\n",
      "Training Loss: 0.000524812984658638\n",
      "Training Loss: 0.0005741486324404832\n",
      "Validation Loss: 0.0017166964365090923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007500280593521893\n",
      "Training Loss: 0.0074113200732972475\n",
      "Training Loss: 0.007123408253537491\n",
      "Training Loss: 0.004271863667527214\n",
      "Training Loss: 0.0006402590045763646\n",
      "Training Loss: 0.0005245959732565098\n",
      "Training Loss: 0.0005731322944484418\n",
      "Validation Loss: 0.0017109712500130402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007487102886661887\n",
      "Training Loss: 0.0073984386376105245\n",
      "Training Loss: 0.007107927055330947\n",
      "Training Loss: 0.004264294256136054\n",
      "Training Loss: 0.0006410420864995103\n",
      "Training Loss: 0.0005244471670448548\n",
      "Training Loss: 0.0005721851911948761\n",
      "Validation Loss: 0.0017053823330468404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007473990577273071\n",
      "Training Loss: 0.007385590760386549\n",
      "Training Loss: 0.00709250078885816\n",
      "Training Loss: 0.004256814005348133\n",
      "Training Loss: 0.000641890132392291\n",
      "Training Loss: 0.000524367423786316\n",
      "Training Loss: 0.0005713088416086975\n",
      "Validation Loss: 0.0016999319016437258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007460937243886292\n",
      "Training Loss: 0.007372766937478446\n",
      "Training Loss: 0.007077120075700804\n",
      "Training Loss: 0.004249418429171783\n",
      "Training Loss: 0.0006428077971213497\n",
      "Training Loss: 0.0005243597972003044\n",
      "Training Loss: 0.0005705065435904544\n",
      "Validation Loss: 0.0016946181487501337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007447934451047331\n",
      "Training Loss: 0.007359957422595471\n",
      "Training Loss: 0.007061774655012414\n",
      "Training Loss: 0.0042421016951993806\n",
      "Training Loss: 0.000643794995485223\n",
      "Training Loss: 0.0005244250673422358\n",
      "Training Loss: 0.0005697811840946088\n",
      "Validation Loss: 0.0016894455177143516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007434970926260576\n",
      "Training Loss: 0.007347150908899493\n",
      "Training Loss: 0.007046453380025923\n",
      "Training Loss: 0.004234860648139147\n",
      "Training Loss: 0.0006448557737166994\n",
      "Training Loss: 0.0005245655817998341\n",
      "Training Loss: 0.0005691360211494611\n",
      "Validation Loss: 0.001684413030178963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007422040903475135\n",
      "Training Loss: 0.007334339187364094\n",
      "Training Loss: 0.007031148296082392\n",
      "Training Loss: 0.004227691559790401\n",
      "Training Loss: 0.0006459889806865248\n",
      "Training Loss: 0.0005247821579541778\n",
      "Training Loss: 0.0005685707802331308\n",
      "Validation Loss: 0.0016795211740418892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007409140329109505\n",
      "Training Loss: 0.007321517336531542\n",
      "Training Loss: 0.00701585193281062\n",
      "Training Loss: 0.004220592728161137\n",
      "Training Loss: 0.0006471956145833246\n",
      "Training Loss: 0.0005250757224712288\n",
      "Training Loss: 0.0005680902970198077\n",
      "Validation Loss: 0.0016747724498344814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007396258004009723\n",
      "Training Loss: 0.007308674369705841\n",
      "Training Loss: 0.007000554644037038\n",
      "Training Loss: 0.0042135601499467155\n",
      "Training Loss: 0.0006484780391474487\n",
      "Training Loss: 0.0005254475388210267\n",
      "Training Loss: 0.000567695096542593\n",
      "Validation Loss: 0.001670166564120367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007383392172632739\n",
      "Training Loss: 0.0072958080231910576\n",
      "Training Loss: 0.006985254028113559\n",
      "Training Loss: 0.004206591391048278\n",
      "Training Loss: 0.0006498358914541313\n",
      "Training Loss: 0.00052589702703699\n",
      "Training Loss: 0.0005673873964406085\n",
      "Validation Loss: 0.0016657053566540413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00737053819000721\n",
      "Training Loss: 0.007282910393550992\n",
      "Training Loss: 0.006969941578572616\n",
      "Training Loss: 0.004199685758503619\n",
      "Training Loss: 0.0006512699931772659\n",
      "Training Loss: 0.0005264261388947489\n",
      "Training Loss: 0.0005671695619821549\n",
      "Validation Loss: 0.0016613909959433816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007357691947836429\n",
      "Training Loss: 0.007269978495896794\n",
      "Training Loss: 0.006954614669084549\n",
      "Training Loss: 0.004192842332704458\n",
      "Training Loss: 0.0006527810228726593\n",
      "Training Loss: 0.0005270359734277008\n",
      "Training Loss: 0.0005670444421411958\n",
      "Validation Loss: 0.0016572241247252279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007344848412321881\n",
      "Training Loss: 0.00725700790528208\n",
      "Training Loss: 0.0069392686430364845\n",
      "Training Loss: 0.004186060224310495\n",
      "Training Loss: 0.0006543705540389055\n",
      "Training Loss: 0.0005277264548931271\n",
      "Training Loss: 0.0005670136211119825\n",
      "Validation Loss: 0.0016532081317972768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007332007130607963\n",
      "Training Loss: 0.007243996813776903\n",
      "Training Loss: 0.0069239012827165426\n",
      "Training Loss: 0.00417933656644891\n",
      "Training Loss: 0.0006560396801069146\n",
      "Training Loss: 0.0005284991669032024\n",
      "Training Loss: 0.0005670793247554685\n",
      "Validation Loss: 0.0016493448816577308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007319164867512881\n",
      "Training Loss: 0.0072309437446529045\n",
      "Training Loss: 0.006908513646339998\n",
      "Training Loss: 0.0041726760796154845\n",
      "Training Loss: 0.0006577841320540756\n",
      "Training Loss: 0.0005293517095560674\n",
      "Training Loss: 0.0005672415440494661\n",
      "Validation Loss: 0.0016456352973994294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007306323667289689\n",
      "Training Loss: 0.0072178485651966185\n",
      "Training Loss: 0.006893104306655005\n",
      "Training Loss: 0.0041660770515591136\n",
      "Training Loss: 0.00065960769301455\n",
      "Training Loss: 0.0005302860566007439\n",
      "Training Loss: 0.000567503619749914\n",
      "Validation Loss: 0.0016420814598917487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00729348293854855\n",
      "Training Loss: 0.007204712719540112\n",
      "Training Loss: 0.006877675845753401\n",
      "Training Loss: 0.004159539952670457\n",
      "Training Loss: 0.0006615088444232243\n",
      "Training Loss: 0.0005313008648954564\n",
      "Training Loss: 0.000567865166667616\n",
      "Validation Loss: 0.0016386860055384166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007280644949059933\n",
      "Training Loss: 0.007191538881743327\n",
      "Training Loss: 0.006862232773564756\n",
      "Training Loss: 0.004153066915096133\n",
      "Training Loss: 0.0006634852303977822\n",
      "Training Loss: 0.0005323961502290331\n",
      "Training Loss: 0.0005683274284092476\n",
      "Validation Loss: 0.001635450751475784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007267812903737649\n",
      "Training Loss: 0.007178328025620431\n",
      "Training Loss: 0.006846776441670954\n",
      "Training Loss: 0.004146662051789462\n",
      "Training Loss: 0.0006655379108269698\n",
      "Training Loss: 0.0005335705877951113\n",
      "Training Loss: 0.0005688910989556462\n",
      "Validation Loss: 0.0016323766792223577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007254990069195628\n",
      "Training Loss: 0.00716508807206992\n",
      "Training Loss: 0.006831315668532625\n",
      "Training Loss: 0.004140326675260439\n",
      "Training Loss: 0.0006676642157981405\n",
      "Training Loss: 0.0005348237966245506\n",
      "Training Loss: 0.0005695568402006757\n",
      "Validation Loss: 0.0016294682133233887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007242181728361175\n",
      "Training Loss: 0.007151822056621313\n",
      "Training Loss: 0.006815853043226525\n",
      "Training Loss: 0.004134061729273526\n",
      "Training Loss: 0.0006698619340750156\n",
      "Training Loss: 0.0005361537155840778\n",
      "Training Loss: 0.0005703239153081086\n",
      "Validation Loss: 0.0016267251775753493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007229392242152244\n",
      "Training Loss: 0.007138536953134462\n",
      "Training Loss: 0.006800402213120833\n",
      "Training Loss: 0.00412787101980939\n",
      "Training Loss: 0.0006721277526958148\n",
      "Training Loss: 0.0005375570918840822\n",
      "Training Loss: 0.0005711894553678576\n",
      "Validation Loss: 0.0016241490243356813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007216630624607205\n",
      "Training Loss: 0.007125242396723479\n",
      "Training Loss: 0.006784968690481037\n",
      "Training Loss: 0.0041217590738233416\n",
      "Training Loss: 0.0006744602560502244\n",
      "Training Loss: 0.0005390328907378716\n",
      "Training Loss: 0.0005721543532854412\n",
      "Validation Loss: 0.001621737867305561\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007203904089983552\n",
      "Training Loss: 0.007111945379874669\n",
      "Training Loss: 0.006769564643036574\n",
      "Training Loss: 0.004115726969612297\n",
      "Training Loss: 0.0006768531464331317\n",
      "Training Loss: 0.0005405773504753597\n",
      "Training Loss: 0.0005732151091069681\n",
      "Validation Loss: 0.0016194951029129027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.007191219239030033\n",
      "Training Loss: 0.007098654424771667\n",
      "Training Loss: 0.006754200179129839\n",
      "Training Loss: 0.004109779299251386\n",
      "Training Loss: 0.0006793068483966635\n",
      "Training Loss: 0.0005421890236902982\n",
      "Training Loss: 0.0005743709289527032\n",
      "Validation Loss: 0.0016174185044966702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.00717858562595211\n",
      "Training Loss: 0.00708537980215624\n",
      "Training Loss: 0.006738884669030085\n",
      "Training Loss: 0.00410391780838836\n",
      "Training Loss: 0.0006818157847737894\n",
      "Training Loss: 0.0005438641813816503\n",
      "Training Loss: 0.0005756198025483173\n",
      "Validation Loss: 0.001615510351093894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007166009838692844\n",
      "Training Loss: 0.0070721310289809484\n",
      "Training Loss: 0.0067236316483467815\n",
      "Training Loss: 0.004098147075637826\n",
      "Training Loss: 0.0006843729701358825\n",
      "Training Loss: 0.0005455978331156075\n",
      "Training Loss: 0.0005769549395336071\n",
      "Validation Loss: 0.001613762607049783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.007153507402399555\n",
      "Training Loss: 0.0070589225483126935\n",
      "Training Loss: 0.006708455976331606\n",
      "Training Loss: 0.004092469737515785\n",
      "Training Loss: 0.0006869730656035245\n",
      "Training Loss: 0.0005473828859976493\n",
      "Training Loss: 0.000578371806332143\n",
      "Validation Loss: 0.0016121754334164323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.007141086987685412\n",
      "Training Loss: 0.00704576400341466\n",
      "Training Loss: 0.006693370260763914\n",
      "Training Loss: 0.004086887986413785\n",
      "Training Loss: 0.0006896118531585671\n",
      "Training Loss: 0.0005492183699243469\n",
      "Training Loss: 0.0005798675836558686\n",
      "Validation Loss: 0.0016107470040647347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.007128756269812584\n",
      "Training Loss: 0.007032666334416717\n",
      "Training Loss: 0.006678386193234473\n",
      "Training Loss: 0.00408140344567073\n",
      "Training Loss: 0.0006922820523323026\n",
      "Training Loss: 0.0005510981902625645\n",
      "Training Loss: 0.0005814378373906947\n",
      "Validation Loss: 0.0016094729177216034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.007116525087039918\n",
      "Training Loss: 0.007019640798098407\n",
      "Training Loss: 0.006663518558489159\n",
      "Training Loss: 0.004076021618238883\n",
      "Training Loss: 0.0006949775187240448\n",
      "Training Loss: 0.0005530135775188682\n",
      "Training Loss: 0.0005830719609366497\n",
      "Validation Loss: 0.0016083464263859884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.007104410931933671\n",
      "Training Loss: 0.007006701753125526\n",
      "Training Loss: 0.006648781221592799\n",
      "Training Loss: 0.004070742039111792\n",
      "Training Loss: 0.0006976898716675351\n",
      "Training Loss: 0.0005549617089855019\n",
      "Training Loss: 0.0005847677431302145\n",
      "Validation Loss: 0.001607360719707062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.007092415838269517\n",
      "Training Loss: 0.006993860263610259\n",
      "Training Loss: 0.006634187524905428\n",
      "Training Loss: 0.004065565029814025\n",
      "Training Loss: 0.0007004123761726078\n",
      "Training Loss: 0.0005569344748073491\n",
      "Training Loss: 0.0005865164070564788\n",
      "Validation Loss: 0.0016065133859365062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.007080555169377476\n",
      "Training Loss: 0.006981125561287627\n",
      "Training Loss: 0.006619747543008998\n",
      "Training Loss: 0.004060493937649881\n",
      "Training Loss: 0.000703137795208022\n",
      "Training Loss: 0.0005589253648213343\n",
      "Training Loss: 0.0005883106595865684\n",
      "Validation Loss: 0.0016057911367231479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.007068834231467917\n",
      "Training Loss: 0.00696850979118608\n",
      "Training Loss: 0.006605475131655112\n",
      "Training Loss: 0.004055529671531986\n",
      "Training Loss: 0.0007058589413645677\n",
      "Training Loss: 0.000560930326973903\n",
      "Training Loss: 0.0005901454731065314\n",
      "Validation Loss: 0.0016051931003146119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.007057263586902991\n",
      "Training Loss: 0.006956020346842706\n",
      "Training Loss: 0.006591378422454\n",
      "Training Loss: 0.004050670968426857\n",
      "Training Loss: 0.0007085700477182399\n",
      "Training Loss: 0.0005629422178026289\n",
      "Training Loss: 0.0005920129831793019\n",
      "Validation Loss: 0.0016047087673940225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.007045848763082177\n",
      "Training Loss: 0.006943669557804242\n",
      "Training Loss: 0.006577470826450735\n",
      "Training Loss: 0.004045917711046058\n",
      "Training Loss: 0.0007112609023897675\n",
      "Training Loss: 0.0005649526231718483\n",
      "Training Loss: 0.0005939037901407573\n",
      "Validation Loss: 0.0016043262640890676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.007034599346807227\n",
      "Training Loss: 0.006931466250680387\n",
      "Training Loss: 0.006563760366989299\n",
      "Training Loss: 0.004041270487432485\n",
      "Training Loss: 0.000713924817246152\n",
      "Training Loss: 0.0005669562959519681\n",
      "Training Loss: 0.0005958105407626135\n",
      "Validation Loss: 0.0016040375643917306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.007023521400988102\n",
      "Training Loss: 0.0069194162974599745\n",
      "Training Loss: 0.006550255108159035\n",
      "Training Loss: 0.004036727814891492\n",
      "Training Loss: 0.000716557548075798\n",
      "Training Loss: 0.0005689489623182453\n",
      "Training Loss: 0.0005977291602175682\n",
      "Validation Loss: 0.0016038362890039833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.007012619505403563\n",
      "Training Loss: 0.006907527216244489\n",
      "Training Loss: 0.006536960384109989\n",
      "Training Loss: 0.004032288834932843\n",
      "Training Loss: 0.000719148889038479\n",
      "Training Loss: 0.0005709204222512198\n",
      "Training Loss: 0.000599647129929508\n",
      "Validation Loss: 0.001603709908781315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.007001903026830405\n",
      "Training Loss: 0.006895809404086322\n",
      "Training Loss: 0.006523887417279184\n",
      "Training Loss: 0.004027952619580901\n",
      "Training Loss: 0.0007216926273395075\n",
      "Training Loss: 0.0005728668013034622\n",
      "Training Loss: 0.0006015600825776346\n",
      "Validation Loss: 0.0016036480035713948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0069913700129836795\n",
      "Training Loss: 0.006884263579268008\n",
      "Training Loss: 0.0065110373939387504\n",
      "Training Loss: 0.004023715584917226\n",
      "Training Loss: 0.0007241846904798877\n",
      "Training Loss: 0.0005747844924189849\n",
      "Training Loss: 0.0006034615854878211\n",
      "Validation Loss: 0.0016036466936265163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006981027107685805\n",
      "Training Loss: 0.006872896859422326\n",
      "Training Loss: 0.0064984147914219645\n",
      "Training Loss: 0.004019577223007218\n",
      "Training Loss: 0.0007266183346655452\n",
      "Training Loss: 0.0005766662952373736\n",
      "Training Loss: 0.0006053443663404323\n",
      "Validation Loss: 0.0016036883558688184\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 122\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006970876686973497\n",
      "Training Loss: 0.006861713930265978\n",
      "Training Loss: 0.006486024755286052\n",
      "Training Loss: 0.004015534434802248\n",
      "Training Loss: 0.0007289888639206765\n",
      "Training Loss: 0.0005785075028688879\n",
      "Training Loss: 0.0006072020143619739\n",
      "Validation Loss: 0.001603767800769221\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 123\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006960918466793373\n",
      "Training Loss: 0.006850715312175452\n",
      "Training Loss: 0.00647386543918401\n",
      "Training Loss: 0.004011585830085096\n",
      "Training Loss: 0.00073129215350491\n",
      "Training Loss: 0.0005803049462701893\n",
      "Training Loss: 0.0006090301314543467\n",
      "Validation Loss: 0.001603882065350678\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 124\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006951152920955792\n",
      "Training Loss: 0.006839902033098042\n",
      "Training Loss: 0.006461940583540127\n",
      "Training Loss: 0.004007726974814432\n",
      "Training Loss: 0.0007335245783178834\n",
      "Training Loss: 0.0005820555723767029\n",
      "Training Loss: 0.0006108232024416793\n",
      "Validation Loss: 0.0016040192086494629\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 125\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.0069415828352794055\n",
      "Training Loss: 0.006829280130332336\n",
      "Training Loss: 0.006450251876376569\n",
      "Training Loss: 0.004003957636959967\n",
      "Training Loss: 0.0007356813008664176\n",
      "Training Loss: 0.00058375375570904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [04:17<18:40, 140.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0006125753559899749\n",
      "Validation Loss: 0.0016041660496279638\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 126\n",
      "Early stopping after 126 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.09993705168366432\n",
      "Training Loss: 0.08442944569513201\n",
      "Training Loss: 0.07666544709354639\n",
      "Training Loss: 0.0618616428412497\n",
      "Training Loss: 0.047135779550299045\n",
      "Training Loss: 0.043839839231222866\n",
      "Training Loss: 0.04307379352860153\n",
      "Validation Loss: 0.04689692079406999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.05751606917008758\n",
      "Training Loss: 0.05336274392902851\n",
      "Training Loss: 0.050399145502597095\n",
      "Training Loss: 0.037951575609477005\n",
      "Training Loss: 0.022711944431066514\n",
      "Training Loss: 0.019569408132229002\n",
      "Training Loss: 0.016143576726317405\n",
      "Validation Loss: 0.02035615758356474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.032194641074165704\n",
      "Training Loss: 0.029209297448396683\n",
      "Training Loss: 0.02815667212475091\n",
      "Training Loss: 0.016843271183315665\n",
      "Training Loss: 0.0033445364743238315\n",
      "Training Loss: 0.002887377665465465\n",
      "Training Loss: 0.002223753300277167\n",
      "Validation Loss: 0.010271811044574601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.02356137543451041\n",
      "Training Loss: 0.02184157508891076\n",
      "Training Loss: 0.021953555806539952\n",
      "Training Loss: 0.011977158504159889\n",
      "Training Loss: 0.000900493888912024\n",
      "Training Loss: 0.000865230576855538\n",
      "Training Loss: 0.0007654274672677275\n",
      "Validation Loss: 0.007721837076708615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.019711943808943033\n",
      "Training Loss: 0.018324724682606756\n",
      "Training Loss: 0.018486048355698587\n",
      "Training Loss: 0.009806503691503394\n",
      "Training Loss: 0.0005109364972668117\n",
      "Training Loss: 0.00045242714357300427\n",
      "Training Loss: 0.000441326949512586\n",
      "Validation Loss: 0.00616576144135381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.01683407131116837\n",
      "Training Loss: 0.0157606838317588\n",
      "Training Loss: 0.015926859392784536\n",
      "Training Loss: 0.008446279721538304\n",
      "Training Loss: 0.0004986562894191593\n",
      "Training Loss: 0.0004137986435671337\n",
      "Training Loss: 0.00043133071219926935\n",
      "Validation Loss: 0.005160483545878787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01467779603553936\n",
      "Training Loss: 0.013847737167961895\n",
      "Training Loss: 0.01400507270358503\n",
      "Training Loss: 0.007519217132703489\n",
      "Training Loss: 0.00056186453661212\n",
      "Training Loss: 0.0004655322027247166\n",
      "Training Loss: 0.0005001975198319997\n",
      "Validation Loss: 0.004457363621737243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01305165363010019\n",
      "Training Loss: 0.012408167305402458\n",
      "Training Loss: 0.012547868699766696\n",
      "Training Loss: 0.006844135678911698\n",
      "Training Loss: 0.00061310170818615\n",
      "Training Loss: 0.0005149056084337644\n",
      "Training Loss: 0.0005629233900617691\n",
      "Validation Loss: 0.003931066367190073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.011815237966366111\n",
      "Training Loss: 0.011314140253234654\n",
      "Training Loss: 0.011430462221615017\n",
      "Training Loss: 0.006328189449559432\n",
      "Training Loss: 0.000634494486512267\n",
      "Training Loss: 0.0005388158291680156\n",
      "Training Loss: 0.0005963872529173386\n",
      "Validation Loss: 0.003520972638319888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.010873519838787616\n",
      "Training Loss: 0.010479317028075457\n",
      "Training Loss: 0.010569296091562137\n",
      "Training Loss: 0.0059253351822553665\n",
      "Training Loss: 0.000632450377488567\n",
      "Training Loss: 0.0005406442468301975\n",
      "Training Loss: 0.0006039420562956366\n",
      "Validation Loss: 0.0031967934603412194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010160451685078443\n",
      "Training Loss: 0.009844842765014619\n",
      "Training Loss: 0.00990777334664017\n",
      "Training Loss: 0.005610880224267021\n",
      "Training Loss: 0.0006181221895894851\n",
      "Training Loss: 0.0005301658030657563\n",
      "Training Loss: 0.0005962364851802704\n",
      "Validation Loss: 0.002940366505069679\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.00962610736838542\n",
      "Training Loss: 0.009367088295985013\n",
      "Training Loss: 0.00940373634803109\n",
      "Training Loss: 0.005368057305458933\n",
      "Training Loss: 0.0006000900642175111\n",
      "Training Loss: 0.0005153644182064454\n",
      "Training Loss: 0.0005822931283910294\n",
      "Validation Loss: 0.0027381397188272266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009230113158700988\n",
      "Training Loss: 0.009010926540941\n",
      "Training Loss: 0.009022832059999928\n",
      "Training Loss: 0.005182736271162867\n",
      "Training Loss: 0.0005830053229510668\n",
      "Training Loss: 0.0005006636168036493\n",
      "Training Loss: 0.0005673263751668856\n",
      "Validation Loss: 0.002578893239461217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00893915921333246\n",
      "Training Loss: 0.008747311101760715\n",
      "Training Loss: 0.00873634101706557\n",
      "Training Loss: 0.005042326425973442\n",
      "Training Loss: 0.0005686427433465724\n",
      "Training Loss: 0.00048784008737129625\n",
      "Training Loss: 0.0005536378004035214\n",
      "Validation Loss: 0.0024533709480094963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008726238558301702\n",
      "Training Loss: 0.008552683597663417\n",
      "Training Loss: 0.00852080125710927\n",
      "Training Loss: 0.004936068331517163\n",
      "Training Loss: 0.0005573136261227774\n",
      "Training Loss: 0.00047733204446558374\n",
      "Training Loss: 0.0005420015237177722\n",
      "Validation Loss: 0.0023541803393697836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008570149379083887\n",
      "Training Loss: 0.008408569869352504\n",
      "Training Loss: 0.008357716734753922\n",
      "Training Loss: 0.004855248391759232\n",
      "Training Loss: 0.0005487878350322716\n",
      "Training Loss: 0.0004690774853588664\n",
      "Training Loss: 0.0005325542829814366\n",
      "Validation Loss: 0.0022755244684999473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00845474559115246\n",
      "Training Loss: 0.008300892241531983\n",
      "Training Loss: 0.008232922703027725\n",
      "Training Loss: 0.004793113216219353\n",
      "Training Loss: 0.0005426900475504226\n",
      "Training Loss: 0.00046285396070743444\n",
      "Training Loss: 0.0005251657271219301\n",
      "Validation Loss: 0.00221287367926703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008368048967095093\n",
      "Training Loss: 0.008219176838174462\n",
      "Training Loss: 0.008135818865848705\n",
      "Training Loss: 0.004744553598284256\n",
      "Training Loss: 0.0005386381999051082\n",
      "Training Loss: 0.00045840007260267157\n",
      "Training Loss: 0.0005196061279639252\n",
      "Validation Loss: 0.0021627093897478426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008301364879589528\n",
      "Training Loss: 0.008155775441555307\n",
      "Training Loss: 0.008058614977635443\n",
      "Training Loss: 0.004705801653617527\n",
      "Training Loss: 0.0005362787471676711\n",
      "Training Loss: 0.0004554484866093844\n",
      "Training Loss: 0.0005156050508230692\n",
      "Validation Loss: 0.002122284147388316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00824848928488791\n",
      "Training Loss: 0.008105181229766459\n",
      "Training Loss: 0.00799564252840355\n",
      "Training Loss: 0.004674097422030172\n",
      "Training Loss: 0.0005353000270406483\n",
      "Training Loss: 0.00045374758183243103\n",
      "Training Loss: 0.0005128959135981859\n",
      "Validation Loss: 0.002089466691464718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008205076517770067\n",
      "Training Loss: 0.008063495357055217\n",
      "Training Loss: 0.007942834357963875\n",
      "Training Loss: 0.004647456908933236\n",
      "Training Loss: 0.0005354361121499096\n",
      "Training Loss: 0.000453068991228065\n",
      "Training Loss: 0.0005112269208621\n",
      "Validation Loss: 0.002062606098010878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008168112973216922\n",
      "Training Loss: 0.008027985048247501\n",
      "Training Loss: 0.007897289039101451\n",
      "Training Loss: 0.004624455068187672\n",
      "Training Loss: 0.0005364592040496063\n",
      "Training Loss: 0.00045321439110921344\n",
      "Training Loss: 0.0005103776340547484\n",
      "Validation Loss: 0.0020404128329263747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008135543941752985\n",
      "Training Loss: 0.007996756612556055\n",
      "Training Loss: 0.007856951073044911\n",
      "Training Loss: 0.004604080712451833\n",
      "Training Loss: 0.0005381882283472805\n",
      "Training Loss: 0.0004540183883909776\n",
      "Training Loss: 0.0005101606932294089\n",
      "Validation Loss: 0.0020218900315378957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008105955766513944\n",
      "Training Loss: 0.007968494013184682\n",
      "Training Loss: 0.007820356752490624\n",
      "Training Loss: 0.004585607046319638\n",
      "Training Loss: 0.0005404771030589473\n",
      "Training Loss: 0.0004553433900036907\n",
      "Training Loss: 0.0005104182567083626\n",
      "Validation Loss: 0.002006256614127397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00807839291053824\n",
      "Training Loss: 0.007942287690239027\n",
      "Training Loss: 0.007786459646886215\n",
      "Training Loss: 0.00456850944654434\n",
      "Training Loss: 0.0005432057148209424\n",
      "Training Loss: 0.00045707840003160526\n",
      "Training Loss: 0.0005110145940852817\n",
      "Validation Loss: 0.001992914304588503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008052205354906618\n",
      "Training Loss: 0.007917508751852438\n",
      "Training Loss: 0.007754510486265644\n",
      "Training Loss: 0.004552408045055927\n",
      "Training Loss: 0.0005462822633126052\n",
      "Training Loss: 0.00045913173436929356\n",
      "Training Loss: 0.0005118401603976963\n",
      "Validation Loss: 0.0019813910229040015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008026937183458357\n",
      "Training Loss: 0.007893708067713305\n",
      "Training Loss: 0.007723955715773627\n",
      "Training Loss: 0.004537013504086644\n",
      "Training Loss: 0.0005496357792071649\n",
      "Training Loss: 0.0004614335033147654\n",
      "Training Loss: 0.0005128017711831489\n",
      "Validation Loss: 0.001971331213000108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00800227127270773\n",
      "Training Loss: 0.007870560195297003\n",
      "Training Loss: 0.007694380338070914\n",
      "Training Loss: 0.004522106127988082\n",
      "Training Loss: 0.0005532159493304789\n",
      "Training Loss: 0.00046392530866796734\n",
      "Training Loss: 0.000513816403108649\n",
      "Validation Loss: 0.001962448296489016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00797798264422454\n",
      "Training Loss: 0.007847830440150574\n",
      "Training Loss: 0.007665470167994499\n",
      "Training Loss: 0.004507514293582062\n",
      "Training Loss: 0.000556979263019457\n",
      "Training Loss: 0.00046655838965307337\n",
      "Training Loss: 0.0005148090832517482\n",
      "Validation Loss: 0.001954533541461711\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007953901458531618\n",
      "Training Loss: 0.007825329244369642\n",
      "Training Loss: 0.007636974032502622\n",
      "Training Loss: 0.004493091003823792\n",
      "Training Loss: 0.0005608963938357192\n",
      "Training Loss: 0.00046929475967772305\n",
      "Training Loss: 0.0005157102662633406\n",
      "Validation Loss: 0.0019474260862511216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007929898250149564\n",
      "Training Loss: 0.007802905631251633\n",
      "Training Loss: 0.0076086796016898006\n",
      "Training Loss: 0.0044787178852129725\n",
      "Training Loss: 0.0005649490417636116\n",
      "Training Loss: 0.0004721009340028104\n",
      "Training Loss: 0.0005164483581029344\n",
      "Validation Loss: 0.0019409991112430422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007905867288354785\n",
      "Training Loss: 0.007780427988618613\n",
      "Training Loss: 0.007580399834550917\n",
      "Training Loss: 0.004464278940358782\n",
      "Training Loss: 0.0005691186705007567\n",
      "Training Loss: 0.00047494280715909554\n",
      "Training Loss: 0.0005169444996681704\n",
      "Validation Loss: 0.0019351690401556842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007881721095182002\n",
      "Training Loss: 0.0077577736193779855\n",
      "Training Loss: 0.007551962634315714\n",
      "Training Loss: 0.0044496682311728365\n",
      "Training Loss: 0.0005734009492516634\n",
      "Training Loss: 0.00047779334208826186\n",
      "Training Loss: 0.0005171139413505443\n",
      "Validation Loss: 0.0019298790941954056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007857379679335282\n",
      "Training Loss: 0.007734818324679509\n",
      "Training Loss: 0.00752319255261682\n",
      "Training Loss: 0.004434777479473268\n",
      "Training Loss: 0.000577791348878236\n",
      "Training Loss: 0.00048061847634016885\n",
      "Training Loss: 0.0005168509167560841\n",
      "Validation Loss: 0.001925105752889067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007832773223053664\n",
      "Training Loss: 0.007711432609939947\n",
      "Training Loss: 0.007493908527540043\n",
      "Training Loss: 0.004419492575398181\n",
      "Training Loss: 0.0005822900583370938\n",
      "Training Loss: 0.0004833828734990675\n",
      "Training Loss: 0.0005160233209426224\n",
      "Validation Loss: 0.0019208460453023946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007807835579151288\n",
      "Training Loss: 0.007687473945552483\n",
      "Training Loss: 0.007463908354984596\n",
      "Training Loss: 0.004403689881582977\n",
      "Training Loss: 0.0005869011905451771\n",
      "Training Loss: 0.00048604235304082976\n",
      "Training Loss: 0.0005144644200481707\n",
      "Validation Loss: 0.001917164027603685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007782511612167582\n",
      "Training Loss: 0.007662777167279273\n",
      "Training Loss: 0.007432964576873928\n",
      "Training Loss: 0.004387224243400851\n",
      "Training Loss: 0.000591630705530406\n",
      "Training Loss: 0.000488537137680396\n",
      "Training Loss: 0.0005119465592360938\n",
      "Validation Loss: 0.0019141448218478344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007756753454450518\n",
      "Training Loss: 0.007637145010521635\n",
      "Training Loss: 0.007400798574090004\n",
      "Training Loss: 0.004369931373366854\n",
      "Training Loss: 0.0005964839736043359\n",
      "Training Loss: 0.0004907868555892492\n",
      "Training Loss: 0.0005081672122287273\n",
      "Validation Loss: 0.001911974504464899\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007730534002184868\n",
      "Training Loss: 0.007610333235934377\n",
      "Training Loss: 0.007367073132190854\n",
      "Training Loss: 0.004351608530851081\n",
      "Training Loss: 0.0006014642120135249\n",
      "Training Loss: 0.0004926749323203694\n",
      "Training Loss: 0.0005027080414947704\n",
      "Validation Loss: 0.001910959191723685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007703852419508621\n",
      "Training Loss: 0.0075820267933886494\n",
      "Training Loss: 0.0073313571512699125\n",
      "Training Loss: 0.0043320124593446965\n",
      "Training Loss: 0.0006065640164160868\n",
      "Training Loss: 0.0004940323314804118\n",
      "Training Loss: 0.0004949962333012081\n",
      "Validation Loss: 0.001911612817592926\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 40\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0076767498813569545\n",
      "Training Loss: 0.007551804281538352\n",
      "Training Loss: 0.007293094288324937\n",
      "Training Loss: 0.004310841185724712\n",
      "Training Loss: 0.0006117539363913238\n",
      "Training Loss: 0.0004946008493789122\n",
      "Training Loss: 0.0004842413648293586\n",
      "Validation Loss: 0.0019148158398173464\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 41\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007649333633016795\n",
      "Training Loss: 0.0075191026274114845\n",
      "Training Loss: 0.007251568968640641\n",
      "Training Loss: 0.0042877282504196045\n",
      "Training Loss: 0.0006169447160937125\n",
      "Training Loss: 0.0004939795341852005\n",
      "Training Loss: 0.00046938895211496857\n",
      "Validation Loss: 0.001922025578587023\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 42\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007621790006523952\n",
      "Training Loss: 0.007483142423443496\n",
      "Training Loss: 0.007205859387759119\n",
      "Training Loss: 0.004262236551949172\n",
      "Training Loss: 0.0006219259579665959\n",
      "Training Loss: 0.0004915427998275846\n",
      "Training Loss: 0.00044913928049936656\n",
      "Validation Loss: 0.0019357169261952157\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 43\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007594370520673692\n",
      "Training Loss: 0.007442865817574784\n",
      "Training Loss: 0.007154858133289963\n",
      "Training Loss: 0.004233897284575505\n",
      "Training Loss: 0.0006262436764518498\n",
      "Training Loss: 0.00048634981612849515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [05:24<12:28, 106.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00042223747721436666\n",
      "Validation Loss: 0.0019596719860155067\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 44\n",
      "Early stopping after 44 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.10427996296435595\n",
      "Training Loss: 0.08222504612058401\n",
      "Training Loss: 0.07230979274958373\n",
      "Training Loss: 0.05799570460862014\n",
      "Training Loss: 0.046368329208344224\n",
      "Training Loss: 0.044964040974155066\n",
      "Training Loss: 0.043932415517047047\n",
      "Validation Loss: 0.04860695772403188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.060654336661100386\n",
      "Training Loss: 0.05852359689772129\n",
      "Training Loss: 0.05704598294571042\n",
      "Training Loss: 0.04548072741483338\n",
      "Training Loss: 0.03383133106864989\n",
      "Training Loss: 0.031200226838700475\n",
      "Training Loss: 0.029307694649323823\n",
      "Validation Loss: 0.03334962748242228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.044662069864571094\n",
      "Training Loss: 0.04200357773341239\n",
      "Training Loss: 0.04015105935744941\n",
      "Training Loss: 0.02798793644789839\n",
      "Training Loss: 0.015876937629655002\n",
      "Training Loss: 0.013199836034327745\n",
      "Training Loss: 0.011441759166773409\n",
      "Validation Loss: 0.01628966675460869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.0282027009408921\n",
      "Training Loss: 0.02612401141319424\n",
      "Training Loss: 0.025668541486375034\n",
      "Training Loss: 0.014886861672857776\n",
      "Training Loss: 0.003389132773736492\n",
      "Training Loss: 0.002294923252193257\n",
      "Training Loss: 0.0015080573630984872\n",
      "Validation Loss: 0.008256221982765566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.02167463716119528\n",
      "Training Loss: 0.020144923711195587\n",
      "Training Loss: 0.020297461764421314\n",
      "Training Loss: 0.010874555047630565\n",
      "Training Loss: 0.0009106126878759824\n",
      "Training Loss: 0.0008345620705222245\n",
      "Training Loss: 0.0008707425424654503\n",
      "Validation Loss: 0.006615561381795998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.018279365957714618\n",
      "Training Loss: 0.01704000012949109\n",
      "Training Loss: 0.017121522652450948\n",
      "Training Loss: 0.009354525934759295\n",
      "Training Loss: 0.0009449457339360379\n",
      "Training Loss: 0.0008237014837504831\n",
      "Training Loss: 0.0009122012732404982\n",
      "Validation Loss: 0.005604431389574631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01580354565521702\n",
      "Training Loss: 0.014938702865038067\n",
      "Training Loss: 0.015105907830875367\n",
      "Training Loss: 0.008488285146595444\n",
      "Training Loss: 0.0010570267343427986\n",
      "Training Loss: 0.0008845376419776584\n",
      "Training Loss: 0.0009861255141731817\n",
      "Validation Loss: 0.0049956130038917215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014211995382793248\n",
      "Training Loss: 0.013580497454386204\n",
      "Training Loss: 0.0137634385144338\n",
      "Training Loss: 0.007852935536357108\n",
      "Training Loss: 0.0010843164230755064\n",
      "Training Loss: 0.0008967634126747726\n",
      "Training Loss: 0.001005690390302334\n",
      "Validation Loss: 0.004534295818084774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013066254681907594\n",
      "Training Loss: 0.01257846842519939\n",
      "Training Loss: 0.012741897425148635\n",
      "Training Loss: 0.00732481818384258\n",
      "Training Loss: 0.001057109378016321\n",
      "Training Loss: 0.0008697740047500702\n",
      "Training Loss: 0.0009837710404826793\n",
      "Validation Loss: 0.00414708541306817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.012170570932794363\n",
      "Training Loss: 0.011779609574005008\n",
      "Training Loss: 0.011910630713682622\n",
      "Training Loss: 0.006872615348256659\n",
      "Training Loss: 0.0010050089133437723\n",
      "Training Loss: 0.0008241572038969025\n",
      "Training Loss: 0.0009408876333327498\n",
      "Validation Loss: 0.003813750504394854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.011441672067157925\n",
      "Training Loss: 0.011119937519542872\n",
      "Training Loss: 0.011213463582098484\n",
      "Training Loss: 0.006483964799845126\n",
      "Training Loss: 0.0009462808843090898\n",
      "Training Loss: 0.0007742099819006399\n",
      "Training Loss: 0.0008912082051392645\n",
      "Validation Loss: 0.0035256474964060797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010836524225305766\n",
      "Training Loss: 0.010565884362440556\n",
      "Training Loss: 0.010619790949858725\n",
      "Training Loss: 0.006150989415327785\n",
      "Training Loss: 0.0008913584269612329\n",
      "Training Loss: 0.0007282450329512358\n",
      "Training Loss: 0.0008432033464487176\n",
      "Validation Loss: 0.0032770214600716142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.010328400391153991\n",
      "Training Loss: 0.01009546135785058\n",
      "Training Loss: 0.010108820407185703\n",
      "Training Loss: 0.005866902784327976\n",
      "Training Loss: 0.0008460914528404828\n",
      "Training Loss: 0.0006907869534188649\n",
      "Training Loss: 0.0008018926907243439\n",
      "Validation Loss: 0.0030631100360939824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009897980852983893\n",
      "Training Loss: 0.009692256113048643\n",
      "Training Loss: 0.009665269670076668\n",
      "Training Loss: 0.005625764859869378\n",
      "Training Loss: 0.0008135066997056129\n",
      "Training Loss: 0.0006639497765718261\n",
      "Training Loss: 0.0007700575530907372\n",
      "Validation Loss: 0.0028798666716512286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009530986221507191\n",
      "Training Loss: 0.009344588976819067\n",
      "Training Loss: 0.009279302406357602\n",
      "Training Loss: 0.005422932088913512\n",
      "Training Loss: 0.000794164878243464\n",
      "Training Loss: 0.0006478424109809567\n",
      "Training Loss: 0.0007484410185134038\n",
      "Validation Loss: 0.0027239767463170584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009217944212723523\n",
      "Training Loss: 0.009045137381181121\n",
      "Training Loss: 0.008945256074657664\n",
      "Training Loss: 0.005254520654707448\n",
      "Training Loss: 0.0007864854048239067\n",
      "Training Loss: 0.0006409563708439236\n",
      "Training Loss: 0.0007359318692033412\n",
      "Validation Loss: 0.0025924890310732884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008952514580450953\n",
      "Training Loss: 0.008788858993211761\n",
      "Training Loss: 0.008658629395067691\n",
      "Training Loss: 0.005116353865305428\n",
      "Training Loss: 0.0007876721691718558\n",
      "Training Loss: 0.0006409236241597682\n",
      "Training Loss: 0.0007302979117957875\n",
      "Validation Loss: 0.0024824190993504667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008729118322953582\n",
      "Training Loss: 0.008570936081232503\n",
      "Training Loss: 0.008414392272243276\n",
      "Training Loss: 0.005003798712423304\n",
      "Training Loss: 0.0007946230066590942\n",
      "Training Loss: 0.0006451979502890026\n",
      "Training Loss: 0.0007290161871060263\n",
      "Validation Loss: 0.0023906967066483894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008542027384974062\n",
      "Training Loss: 0.008386364739853889\n",
      "Training Loss: 0.00820721258642152\n",
      "Training Loss: 0.004912279507261701\n",
      "Training Loss: 0.0008044342983339447\n",
      "Training Loss: 0.0006514791944209719\n",
      "Training Loss: 0.0007298466959036887\n",
      "Validation Loss: 0.002314393147207057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008385725197149441\n",
      "Training Loss: 0.008230441462947055\n",
      "Training Loss: 0.008032161761075258\n",
      "Training Loss: 0.004837774140905821\n",
      "Training Loss: 0.0008146893844241277\n",
      "Training Loss: 0.0006579653770313598\n",
      "Training Loss: 0.0007311229718470713\n",
      "Validation Loss: 0.0022509104899463873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008255372794810683\n",
      "Training Loss: 0.00809917413513176\n",
      "Training Loss: 0.007885067939059808\n",
      "Training Loss: 0.004777017158994567\n",
      "Training Loss: 0.0008236262651189464\n",
      "Training Loss: 0.0006634632189525292\n",
      "Training Loss: 0.0007318231806129915\n",
      "Validation Loss: 0.002198048706505664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00814697492052801\n",
      "Training Loss: 0.007989360810024665\n",
      "Training Loss: 0.007762490740278735\n",
      "Training Loss: 0.00472742362821009\n",
      "Training Loss: 0.0008301754655258265\n",
      "Training Loss: 0.0006673373866942712\n",
      "Training Loss: 0.0007314424197829794\n",
      "Validation Loss: 0.0021539461310741\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008057295846519992\n",
      "Training Loss: 0.007898371169576422\n",
      "Training Loss: 0.007661399260396138\n",
      "Training Loss: 0.004686888186406577\n",
      "Training Loss: 0.0008339077894197544\n",
      "Training Loss: 0.0006693941289267969\n",
      "Training Loss: 0.0007298405808251118\n",
      "Validation Loss: 0.002117046912716116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007983583403984085\n",
      "Training Loss: 0.007823767170775682\n",
      "Training Loss: 0.007578803778160364\n",
      "Training Loss: 0.004653613297559787\n",
      "Training Loss: 0.0008349314155202592\n",
      "Training Loss: 0.0006697440399148036\n",
      "Training Loss: 0.0007271046647292678\n",
      "Validation Loss: 0.0020860319481120523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007923300603870302\n",
      "Training Loss: 0.007763050793437287\n",
      "Training Loss: 0.007511613359674811\n",
      "Training Loss: 0.004626028691782267\n",
      "Training Loss: 0.0008337008201488061\n",
      "Training Loss: 0.0006686780199379427\n",
      "Training Loss: 0.0007234524329032865\n",
      "Validation Loss: 0.0020597989505029557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007874017923604697\n",
      "Training Loss: 0.007713650896912441\n",
      "Training Loss: 0.007456751487916335\n",
      "Training Loss: 0.004602801766523044\n",
      "Training Loss: 0.0008308327288250439\n",
      "Training Loss: 0.0006665649922069861\n",
      "Training Loss: 0.0007191663060802967\n",
      "Validation Loss: 0.002037452237461676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007833442278206348\n",
      "Training Loss: 0.007673096536891535\n",
      "Training Loss: 0.0074114083009772\n",
      "Training Loss: 0.0045828609467571365\n",
      "Training Loss: 0.0008269369725894648\n",
      "Training Loss: 0.0006637640078406548\n",
      "Training Loss: 0.000714522787820897\n",
      "Validation Loss: 0.0020182587322779\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0077995600900612775\n",
      "Training Loss: 0.007639244531746954\n",
      "Training Loss: 0.007373248739168048\n",
      "Training Loss: 0.004565381033680751\n",
      "Training Loss: 0.0008225039808166911\n",
      "Training Loss: 0.0006605716764897806\n",
      "Training Loss: 0.0007097526931829634\n",
      "Validation Loss: 0.0020016311680503916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007770722752902657\n",
      "Training Loss: 0.0076103800989221785\n",
      "Training Loss: 0.007340457738609985\n",
      "Training Loss: 0.0045497615967178716\n",
      "Training Loss: 0.0008178870184201515\n",
      "Training Loss: 0.0006572049926035107\n",
      "Training Loss: 0.0007050176052871393\n",
      "Validation Loss: 0.0019870925837934144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007745666726259514\n",
      "Training Loss: 0.007585214349674061\n",
      "Training Loss: 0.007311691669747234\n",
      "Training Loss: 0.00453555839274486\n",
      "Training Loss: 0.000813309976583696\n",
      "Training Loss: 0.0006538077040022472\n",
      "Training Loss: 0.0007004212414176436\n",
      "Validation Loss: 0.001974265602127778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007723448569886386\n",
      "Training Loss: 0.007562806846108288\n",
      "Training Loss: 0.007285976678831503\n",
      "Training Loss: 0.004522455631231424\n",
      "Training Loss: 0.0008089058264886262\n",
      "Training Loss: 0.0006504718327050796\n",
      "Training Loss: 0.0006960192807673593\n",
      "Validation Loss: 0.0019628434674814343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0077033869840670375\n",
      "Training Loss: 0.007542484815930947\n",
      "Training Loss: 0.007262610530015081\n",
      "Training Loss: 0.004510224450277747\n",
      "Training Loss: 0.0008047362503566546\n",
      "Training Loss: 0.0006472424112871523\n",
      "Training Loss: 0.0006918283673803671\n",
      "Validation Loss: 0.0019525765961956945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007684999943012372\n",
      "Training Loss: 0.007523775340523571\n",
      "Training Loss: 0.007241088798036799\n",
      "Training Loss: 0.004498694520007121\n",
      "Training Loss: 0.0008008262410294265\n",
      "Training Loss: 0.0006441426835226594\n",
      "Training Loss: 0.0006878460700318101\n",
      "Validation Loss: 0.0019432632389917886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00766793078975752\n",
      "Training Loss: 0.007506336045917123\n",
      "Training Loss: 0.007221044301986695\n",
      "Training Loss: 0.004487738327588886\n",
      "Training Loss: 0.0007971711589198093\n",
      "Training Loss: 0.0006411768930411199\n",
      "Training Loss: 0.0006840585067402572\n",
      "Validation Loss: 0.0019347388040889596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007651923125376925\n",
      "Training Loss: 0.007489919760264457\n",
      "Training Loss: 0.007202206866350025\n",
      "Training Loss: 0.004477260537387337\n",
      "Training Loss: 0.0007937553619558458\n",
      "Training Loss: 0.0006383424779778579\n",
      "Training Loss: 0.000680446002043027\n",
      "Validation Loss: 0.001926876513212431\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007636785882059485\n",
      "Training Loss: 0.007474343684734776\n",
      "Training Loss: 0.007184373893542215\n",
      "Training Loss: 0.004467183625747566\n",
      "Training Loss: 0.0007905561320512789\n",
      "Training Loss: 0.0006356298940227135\n",
      "Training Loss: 0.0006769833135331282\n",
      "Validation Loss: 0.001919566292650579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007622376774670556\n",
      "Training Loss: 0.007459475392242894\n",
      "Training Loss: 0.007167392238043249\n",
      "Training Loss: 0.004457452169444878\n",
      "Training Loss: 0.0007875445447280072\n",
      "Training Loss: 0.0006330247575533577\n",
      "Training Loss: 0.0006736462781918817\n",
      "Validation Loss: 0.0019127173579094343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007608583936234936\n",
      "Training Loss: 0.0074452139611821625\n",
      "Training Loss: 0.00715114482678473\n",
      "Training Loss: 0.0044480151813331755\n",
      "Training Loss: 0.000784692516317591\n",
      "Training Loss: 0.0006305123827769422\n",
      "Training Loss: 0.0006704090156199527\n",
      "Validation Loss: 0.0019062544546314176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007595327387098223\n",
      "Training Loss: 0.007431481956737116\n",
      "Training Loss: 0.007135538830189034\n",
      "Training Loss: 0.004438834977554507\n",
      "Training Loss: 0.0007819732579810079\n",
      "Training Loss: 0.0006280778985819779\n",
      "Training Loss: 0.0006672491092831478\n",
      "Validation Loss: 0.0019001165309374584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007582536465488374\n",
      "Training Loss: 0.007418216983787715\n",
      "Training Loss: 0.0071205002663191404\n",
      "Training Loss: 0.004429877155052964\n",
      "Training Loss: 0.0007793631962704239\n",
      "Training Loss: 0.0006257093875319697\n",
      "Training Loss: 0.0006641489183311932\n",
      "Validation Loss: 0.0018942582299793314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0075701538042631\n",
      "Training Loss: 0.007405369851039722\n",
      "Training Loss: 0.007105970219708979\n",
      "Training Loss: 0.004421112849886413\n",
      "Training Loss: 0.0007768406331160804\n",
      "Training Loss: 0.0006233932392933639\n",
      "Training Loss: 0.0006610898503640783\n",
      "Validation Loss: 0.0018886369149451762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007558140675537288\n",
      "Training Loss: 0.007392901338171214\n",
      "Training Loss: 0.007091899948427453\n",
      "Training Loss: 0.004412525170046137\n",
      "Training Loss: 0.0007743873712752247\n",
      "Training Loss: 0.0006211164622072829\n",
      "Training Loss: 0.0006580535671673715\n",
      "Validation Loss: 0.001883210369420878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007546456720447168\n",
      "Training Loss: 0.007380781586980447\n",
      "Training Loss: 0.007078249561600387\n",
      "Training Loss: 0.004404087591537973\n",
      "Training Loss: 0.0007719797991012456\n",
      "Training Loss: 0.0006188647598901298\n",
      "Training Loss: 0.0006550243179299286\n",
      "Validation Loss: 0.0018779583435443714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0075350734777748585\n",
      "Training Loss: 0.007368979500606656\n",
      "Training Loss: 0.007064981433795765\n",
      "Training Loss: 0.0043957832913292805\n",
      "Training Loss: 0.0007696072482940509\n",
      "Training Loss: 0.0006166324752848595\n",
      "Training Loss: 0.0006519946666958276\n",
      "Validation Loss: 0.0018728510226486668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00752395847812295\n",
      "Training Loss: 0.007357468783156946\n",
      "Training Loss: 0.007052064395975321\n",
      "Training Loss: 0.004387597406021087\n",
      "Training Loss: 0.0007672600029763998\n",
      "Training Loss: 0.0006144123368721921\n",
      "Training Loss: 0.000648953726667969\n",
      "Validation Loss: 0.0018678728782324198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007513090287102386\n",
      "Training Loss: 0.0073462283588014545\n",
      "Training Loss: 0.007039472799515351\n",
      "Training Loss: 0.004379513406311162\n",
      "Training Loss: 0.0007649220646999311\n",
      "Training Loss: 0.000612193472479703\n",
      "Training Loss: 0.0006458899745848612\n",
      "Validation Loss: 0.0018630012206714479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007502446862636134\n",
      "Training Loss: 0.007335240026004612\n",
      "Training Loss: 0.007027182811871171\n",
      "Training Loss: 0.0043715210127265895\n",
      "Training Loss: 0.0007625879778061062\n",
      "Training Loss: 0.000609969062716118\n",
      "Training Loss: 0.0006427962258749176\n",
      "Validation Loss: 0.0018582248458630503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007492011199938134\n",
      "Training Loss: 0.007324486322468147\n",
      "Training Loss: 0.007015173239633441\n",
      "Training Loss: 0.0043636074468668086\n",
      "Training Loss: 0.0007602427207166329\n",
      "Training Loss: 0.0006077290521352552\n",
      "Training Loss: 0.0006396625298293656\n",
      "Validation Loss: 0.001853530137683701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007481771121965721\n",
      "Training Loss: 0.00731395305134356\n",
      "Training Loss: 0.0070034229708835485\n",
      "Training Loss: 0.004355761158076348\n",
      "Training Loss: 0.0007578891852972447\n",
      "Training Loss: 0.0006054757015954238\n",
      "Training Loss: 0.0006364894584476133\n",
      "Validation Loss: 0.0018489094689132625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007471697569126263\n",
      "Training Loss: 0.007303617403376848\n",
      "Training Loss: 0.006991912558441981\n",
      "Training Loss: 0.004347972726682201\n",
      "Training Loss: 0.0007555156542366603\n",
      "Training Loss: 0.0006031975978112314\n",
      "Training Loss: 0.0006332654783545876\n",
      "Validation Loss: 0.0018443481566965203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007461790207307786\n",
      "Training Loss: 0.007293471887242049\n",
      "Training Loss: 0.006980626084841787\n",
      "Training Loss: 0.004340229505032767\n",
      "Training Loss: 0.0007531197404387058\n",
      "Training Loss: 0.0006008936921716668\n",
      "Training Loss: 0.0006299892523384188\n",
      "Validation Loss: 0.0018398439595480153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007452027978142723\n",
      "Training Loss: 0.007283498098840937\n",
      "Training Loss: 0.006969546737382188\n",
      "Training Loss: 0.004332525332720252\n",
      "Training Loss: 0.0007506988591921981\n",
      "Training Loss: 0.0005985598475672305\n",
      "Training Loss: 0.0006266584274635534\n",
      "Validation Loss: 0.0018353909336371445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007442397212143987\n",
      "Training Loss: 0.007273683404782787\n",
      "Training Loss: 0.00695866032037884\n",
      "Training Loss: 0.0043248547091934595\n",
      "Training Loss: 0.0007482487641391344\n",
      "Training Loss: 0.0005961901312548434\n",
      "Training Loss: 0.0006232641575115849\n",
      "Validation Loss: 0.0018309743322328705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007432893367949873\n",
      "Training Loss: 0.007264019625727087\n",
      "Training Loss: 0.006947952719638124\n",
      "Training Loss: 0.004317203881655587\n",
      "Training Loss: 0.0007457648543640972\n",
      "Training Loss: 0.0005937823732529068\n",
      "Training Loss: 0.0006198056569337496\n",
      "Validation Loss: 0.001826595991274581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00742350134649314\n",
      "Training Loss: 0.007254489959450439\n",
      "Training Loss: 0.006937407329678536\n",
      "Training Loss: 0.004309565205767285\n",
      "Training Loss: 0.0007432494604290696\n",
      "Training Loss: 0.0005913364369916962\n",
      "Training Loss: 0.0006162818436132511\n",
      "Validation Loss: 0.0018222480302734112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0074142047599889335\n",
      "Training Loss: 0.007245080530410632\n",
      "Training Loss: 0.006927012717351317\n",
      "Training Loss: 0.0043019356168952074\n",
      "Training Loss: 0.0007406984663612093\n",
      "Training Loss: 0.0005888450978090987\n",
      "Training Loss: 0.0006126852851957665\n",
      "Validation Loss: 0.0018179280217300946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007405005119508133\n",
      "Training Loss: 0.007235785922966897\n",
      "Training Loss: 0.006916756476275623\n",
      "Training Loss: 0.004294303540664259\n",
      "Training Loss: 0.0007381083712971303\n",
      "Training Loss: 0.0005863077064714162\n",
      "Training Loss: 0.0006090163442058838\n",
      "Validation Loss: 0.0018136307885691573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007395884355064481\n",
      "Training Loss: 0.007226589090423658\n",
      "Training Loss: 0.0069066245865542445\n",
      "Training Loss: 0.004286664088795078\n",
      "Training Loss: 0.0007354846965245088\n",
      "Training Loss: 0.0005837241326662479\n",
      "Training Loss: 0.000605271787426318\n",
      "Validation Loss: 0.0018093554665866893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007386838571401313\n",
      "Training Loss: 0.007217483250424266\n",
      "Training Loss: 0.0068966077710501845\n",
      "Training Loss: 0.00427901075425325\n",
      "Training Loss: 0.0007328204717487097\n",
      "Training Loss: 0.0005810885468235938\n",
      "Training Loss: 0.0006014472686729277\n",
      "Validation Loss: 0.001805093991160323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007377859022235498\n",
      "Training Loss: 0.007208458053646609\n",
      "Training Loss: 0.00688669566414319\n",
      "Training Loss: 0.004271333657452487\n",
      "Training Loss: 0.0007301159347480279\n",
      "Training Loss: 0.0005783998617698671\n",
      "Training Loss: 0.0005975408396261628\n",
      "Validation Loss: 0.0018008472988720328\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007368936213897542\n",
      "Training Loss: 0.007199502682778984\n",
      "Training Loss: 0.006876874598674476\n",
      "Training Loss: 0.004263628923290526\n",
      "Training Loss: 0.0007273709625224001\n",
      "Training Loss: 0.0005756557475979207\n",
      "Training Loss: 0.0005935487639362691\n",
      "Validation Loss: 0.0017966093820698946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007360062948428094\n",
      "Training Loss: 0.007190605335636064\n",
      "Training Loss: 0.006867134300991892\n",
      "Training Loss: 0.0042558893717068716\n",
      "Training Loss: 0.0007245875408261782\n",
      "Training Loss: 0.000572856359067373\n",
      "Training Loss: 0.0005894699792042957\n",
      "Validation Loss: 0.0017923777778558816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007351229924242943\n",
      "Training Loss: 0.00718175804708153\n",
      "Training Loss: 0.006857464930508286\n",
      "Training Loss: 0.004248109547406784\n",
      "Training Loss: 0.000721764696027094\n",
      "Training Loss: 0.0005699986254330725\n",
      "Training Loss: 0.0005853021024449845\n",
      "Validation Loss: 0.001788155523628914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007342433232115582\n",
      "Training Loss: 0.007172951239626854\n",
      "Training Loss: 0.006847858892288059\n",
      "Training Loss: 0.004240282374375966\n",
      "Training Loss: 0.0007188977743862779\n",
      "Training Loss: 0.0005670772310259054\n",
      "Training Loss: 0.0005810371520783519\n",
      "Validation Loss: 0.001783936069964358\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.0073336706298869105\n",
      "Training Loss: 0.0071641778398770836\n",
      "Training Loss: 0.006838306440040469\n",
      "Training Loss: 0.004232401585177285\n",
      "Training Loss: 0.0007159880755352787\n",
      "Training Loss: 0.0005640927150670905\n",
      "Training Loss: 0.0005766733174823457\n",
      "Validation Loss: 0.0017797189649898203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007324929782189429\n",
      "Training Loss: 0.007155428412370384\n",
      "Training Loss: 0.006828798860078677\n",
      "Training Loss: 0.004224460646946681\n",
      "Training Loss: 0.0007130343210883438\n",
      "Training Loss: 0.000561041812034091\n",
      "Training Loss: 0.0005722085952584166\n",
      "Validation Loss: 0.0017754998970327704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007316208569100127\n",
      "Training Loss: 0.0071466934541240335\n",
      "Training Loss: 0.006819327524863183\n",
      "Training Loss: 0.004216454651832464\n",
      "Training Loss: 0.0007100350884502404\n",
      "Training Loss: 0.0005579222534288419\n",
      "Training Loss: 0.0005676362139638514\n",
      "Validation Loss: 0.001771282914904738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007307506534270942\n",
      "Training Loss: 0.007137968628667295\n",
      "Training Loss: 0.006809887001290918\n",
      "Training Loss: 0.004208378175535472\n",
      "Training Loss: 0.00070699023832276\n",
      "Training Loss: 0.0005547308503446402\n",
      "Training Loss: 0.0005629528926147032\n",
      "Validation Loss: 0.0017670608972690212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0072988115972839294\n",
      "Training Loss: 0.007129243627423421\n",
      "Training Loss: 0.0068004682299215346\n",
      "Training Loss: 0.004200224875894491\n",
      "Training Loss: 0.0007038960636418779\n",
      "Training Loss: 0.0005514649428369012\n",
      "Training Loss: 0.0005581522949432838\n",
      "Validation Loss: 0.0017628374845024952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0072901271004229785\n",
      "Training Loss: 0.007120511311804876\n",
      "Training Loss: 0.006791064838180319\n",
      "Training Loss: 0.004191986265577725\n",
      "Training Loss: 0.0007007528319445555\n",
      "Training Loss: 0.0005481231150042731\n",
      "Training Loss: 0.0005532329997004126\n",
      "Validation Loss: 0.0017586110166512947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007281443043611943\n",
      "Training Loss: 0.00711176514509134\n",
      "Training Loss: 0.006781672234646976\n",
      "Training Loss: 0.004183660116323154\n",
      "Training Loss: 0.0006975541149222409\n",
      "Training Loss: 0.0005446992270299233\n",
      "Training Loss: 0.000548185343741352\n",
      "Validation Loss: 0.0017543838560308263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007272764599183574\n",
      "Training Loss: 0.007103000310016796\n",
      "Training Loss: 0.006772283784812316\n",
      "Training Loss: 0.0041752394507057035\n",
      "Training Loss: 0.0006942993950360687\n",
      "Training Loss: 0.0005411915016156854\n",
      "Training Loss: 0.0005430042971238436\n",
      "Validation Loss: 0.0017501551580849917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007264084646012634\n",
      "Training Loss: 0.007094207280315459\n",
      "Training Loss: 0.006762893076520413\n",
      "Training Loss: 0.004166718394699274\n",
      "Training Loss: 0.0006909858611470554\n",
      "Training Loss: 0.0005375968287262367\n",
      "Training Loss: 0.0005376852785047958\n",
      "Validation Loss: 0.0017459308541090356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007255402739392593\n",
      "Training Loss: 0.007085380646167323\n",
      "Training Loss: 0.006753497559111565\n",
      "Training Loss: 0.004158091080753366\n",
      "Training Loss: 0.0006876110471785068\n",
      "Training Loss: 0.0005339124102465575\n",
      "Training Loss: 0.0005322214753869048\n",
      "Validation Loss: 0.0017417046026835107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007246717262314632\n",
      "Training Loss: 0.0070765140105504545\n",
      "Training Loss: 0.006744090230204165\n",
      "Training Loss: 0.004149349348881515\n",
      "Training Loss: 0.0006841684522078139\n",
      "Training Loss: 0.0005301337700802833\n",
      "Training Loss: 0.0005266061451038695\n",
      "Validation Loss: 0.001737488223288177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007238026740960777\n",
      "Training Loss: 0.007067599777365104\n",
      "Training Loss: 0.006734666550764814\n",
      "Training Loss: 0.004140489799319766\n",
      "Training Loss: 0.0006806568037427496\n",
      "Training Loss: 0.0005262593478983035\n",
      "Training Loss: 0.0005208347720144957\n",
      "Validation Loss: 0.001733283469347067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007229330480331555\n",
      "Training Loss: 0.007058631569379941\n",
      "Training Loss: 0.006725223526591435\n",
      "Training Loss: 0.004131505981786176\n",
      "Training Loss: 0.000677074768464081\n",
      "Training Loss: 0.0005222873338061617\n",
      "Training Loss: 0.0005149003940459806\n",
      "Validation Loss: 0.0017290940279448893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007220624338369817\n",
      "Training Loss: 0.007049601273611188\n",
      "Training Loss: 0.0067157546395901595\n",
      "Training Loss: 0.004122392877252423\n",
      "Training Loss: 0.0006734164219597005\n",
      "Training Loss: 0.0005182132737536449\n",
      "Training Loss: 0.0005087982546319836\n",
      "Validation Loss: 0.0017249320220805648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007211912760976702\n",
      "Training Loss: 0.007040502777090296\n",
      "Training Loss: 0.006706256971228868\n",
      "Training Loss: 0.004113143542708713\n",
      "Training Loss: 0.0006696774365627789\n",
      "Training Loss: 0.0005140353896422312\n",
      "Training Loss: 0.0005025218858645531\n",
      "Validation Loss: 0.0017207970652290644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007203194455942139\n",
      "Training Loss: 0.007031328963348642\n",
      "Training Loss: 0.006696727767121047\n",
      "Training Loss: 0.004103753329472965\n",
      "Training Loss: 0.0006658574875837075\n",
      "Training Loss: 0.0005097548198682489\n",
      "Training Loss: 0.0004960680250405858\n",
      "Validation Loss: 0.001716705384574419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007194468242814765\n",
      "Training Loss: 0.007022069522645324\n",
      "Training Loss: 0.006687158060958609\n",
      "Training Loss: 0.004094216405792395\n",
      "Training Loss: 0.0006619547904483624\n",
      "Training Loss: 0.0005053684481390519\n",
      "Training Loss: 0.0004894320928178785\n",
      "Validation Loss: 0.0017126635813449896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007185735747916624\n",
      "Training Loss: 0.00701271818485111\n",
      "Training Loss: 0.006677545156562701\n",
      "Training Loss: 0.004084528702369425\n",
      "Training Loss: 0.0006579687117482535\n",
      "Training Loss: 0.000500879245591932\n",
      "Training Loss: 0.00048261307836583\n",
      "Validation Loss: 0.0017086817177268938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007176995041081682\n",
      "Training Loss: 0.007003263321239501\n",
      "Training Loss: 0.006667879961896688\n",
      "Training Loss: 0.004074684796942165\n",
      "Training Loss: 0.0006538990965054836\n",
      "Training Loss: 0.0004962877666548593\n",
      "Training Loss: 0.0004756106943023042\n",
      "Validation Loss: 0.0017047754895139994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0071682471467647705\n",
      "Training Loss: 0.006993691587122157\n",
      "Training Loss: 0.006658155268523842\n",
      "Training Loss: 0.00406468112305447\n",
      "Training Loss: 0.000649744659967837\n",
      "Training Loss: 0.0004915954432362923\n",
      "Training Loss: 0.0004684228467704088\n",
      "Validation Loss: 0.0017009533468999268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007159493862418458\n",
      "Training Loss: 0.006983994272304699\n",
      "Training Loss: 0.006648360510589555\n",
      "Training Loss: 0.004054514626986929\n",
      "Training Loss: 0.0006455103688858799\n",
      "Training Loss: 0.0004868099874147447\n",
      "Training Loss: 0.00046105807839921906\n",
      "Validation Loss: 0.0016972237213297612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007150724323000759\n",
      "Training Loss: 0.006974152399925515\n",
      "Training Loss: 0.00663848300697282\n",
      "Training Loss: 0.004044183210353367\n",
      "Training Loss: 0.0006412033992091893\n",
      "Training Loss: 0.00048193496215390044\n",
      "Training Loss: 0.0004535166547066183\n",
      "Validation Loss: 0.0016936028707809118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007141945923212916\n",
      "Training Loss: 0.006964153584558517\n",
      "Training Loss: 0.00662850879249163\n",
      "Training Loss: 0.004033681191358483\n",
      "Training Loss: 0.0006368229551662807\n",
      "Training Loss: 0.0004769762263458688\n",
      "Training Loss: 0.00044580676058103563\n",
      "Validation Loss: 0.0016900963109742662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0071331483265385034\n",
      "Training Loss: 0.0069539730262476954\n",
      "Training Loss: 0.00661841592984274\n",
      "Training Loss: 0.004023011231402052\n",
      "Training Loss: 0.0006323878447437891\n",
      "Training Loss: 0.00047194698545354185\n",
      "Training Loss: 0.000437940251758846\n",
      "Validation Loss: 0.0016867080009027912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007124320967122912\n",
      "Training Loss: 0.006943588478025049\n",
      "Training Loss: 0.006608180720359087\n",
      "Training Loss: 0.004012167825567303\n",
      "Training Loss: 0.0006278979556373087\n",
      "Training Loss: 0.0004668522748397663\n",
      "Training Loss: 0.00042992888294975275\n",
      "Validation Loss: 0.0016834345448470923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007115456715691835\n",
      "Training Loss: 0.006932974219089374\n",
      "Training Loss: 0.006597776783164591\n",
      "Training Loss: 0.004001150804615463\n",
      "Training Loss: 0.000623370356624946\n",
      "Training Loss: 0.0004617067724757362\n",
      "Training Loss: 0.00042178536652500044\n",
      "Validation Loss: 0.0016802712471166814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007106538309017196\n",
      "Training Loss: 0.006922095478512347\n",
      "Training Loss: 0.006587163732619956\n",
      "Training Loss: 0.003989954923963523\n",
      "Training Loss: 0.0006188144542829832\n",
      "Training Loss: 0.000456520651896426\n",
      "Training Loss: 0.0004135267990568536\n",
      "Validation Loss: 0.001677197760754973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007097541044931859\n",
      "Training Loss: 0.006910911801969633\n",
      "Training Loss: 0.006576300222659484\n",
      "Training Loss: 0.003978579854228883\n",
      "Training Loss: 0.0006142459395050536\n",
      "Training Loss: 0.0004513074586429866\n",
      "Training Loss: 0.00040516991839467664\n",
      "Validation Loss: 0.001674185757270634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007088435726473108\n",
      "Training Loss: 0.0068993754009716215\n",
      "Training Loss: 0.006565131238894537\n",
      "Training Loss: 0.003967016278693336\n",
      "Training Loss: 0.0006096740312568727\n",
      "Training Loss: 0.0004460783946342417\n",
      "Training Loss: 0.00039673286191828084\n",
      "Validation Loss: 0.0016711989523078164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007079182681627572\n",
      "Training Loss: 0.006887432319344953\n",
      "Training Loss: 0.006553593196440488\n",
      "Training Loss: 0.003955255369364749\n",
      "Training Loss: 0.0006051136280439095\n",
      "Training Loss: 0.0004408450509072281\n",
      "Training Loss: 0.00038823009737825486\n",
      "Validation Loss: 0.0016681804996544552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00706973577849567\n",
      "Training Loss: 0.006875016883714125\n",
      "Training Loss: 0.006541611957363785\n",
      "Training Loss: 0.003943284090200905\n",
      "Training Loss: 0.0006005729990283726\n",
      "Training Loss: 0.00043561707836488496\n",
      "Training Loss: 0.0003796780363882135\n",
      "Validation Loss: 0.001665063828713006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007060031384462491\n",
      "Training Loss: 0.006862052401993423\n",
      "Training Loss: 0.0065290981729049236\n",
      "Training Loss: 0.003931082521885401\n",
      "Training Loss: 0.000596057244365511\n",
      "Training Loss: 0.00043040156775532524\n",
      "Training Loss: 0.000371088277643139\n",
      "Validation Loss: 0.0016617662182765794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007050003473414108\n",
      "Training Loss: 0.006848454519640655\n",
      "Training Loss: 0.006515954380156472\n",
      "Training Loss: 0.003918628169849399\n",
      "Training Loss: 0.000591579559550155\n",
      "Training Loss: 0.0004252124500999344\n",
      "Training Loss: 0.00036247668273063025\n",
      "Validation Loss: 0.0016581858001969412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007039557659300044\n",
      "Training Loss: 0.006834119909908623\n",
      "Training Loss: 0.006502063667867332\n",
      "Training Loss: 0.0039058941165421857\n",
      "Training Loss: 0.0005871376299182885\n",
      "Training Loss: 0.0004200495686745853\n",
      "Training Loss: 0.00035384851467824775\n",
      "Validation Loss: 0.0016542106553670611\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0070286069612484426\n",
      "Training Loss: 0.006818944743135944\n",
      "Training Loss: 0.006487302713794634\n",
      "Training Loss: 0.003892841785418568\n",
      "Training Loss: 0.0005827258102726774\n",
      "Training Loss: 0.0004149202983171563\n",
      "Training Loss: 0.00034521308090916135\n",
      "Validation Loss: 0.0016497100657854955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007017037955811247\n",
      "Training Loss: 0.0068028045643586665\n",
      "Training Loss: 0.006471530965063721\n",
      "Training Loss: 0.003879439607335371\n",
      "Training Loss: 0.0005783480107129435\n",
      "Training Loss: 0.00040983204467920587\n",
      "Training Loss: 0.0003365803043925553\n",
      "Validation Loss: 0.0016445531809030185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007004727317253128\n",
      "Training Loss: 0.006785568826599047\n",
      "Training Loss: 0.006454600034048781\n",
      "Training Loss: 0.0038656559738592475\n",
      "Training Loss: 0.000573998604377266\n",
      "Training Loss: 0.00040479020743077853\n",
      "Training Loss: 0.0003279605897114379\n",
      "Validation Loss: 0.001638581067862596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006991564108757302\n",
      "Training Loss: 0.00676711791777052\n",
      "Training Loss: 0.006436366403941065\n",
      "Training Loss: 0.0038514718975056895\n",
      "Training Loss: 0.0005696772510418669\n",
      "Training Loss: 0.00039980581848794825\n",
      "Training Loss: 0.000319373318052385\n",
      "Validation Loss: 0.0016316544302270055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006977431999985129\n",
      "Training Loss: 0.006747336266562343\n",
      "Training Loss: 0.006416700062109157\n",
      "Training Loss: 0.0038368940842337905\n",
      "Training Loss: 0.0005653810303920181\n",
      "Training Loss: 0.0003948893003325793\n",
      "Training Loss: 0.00031084397811355303\n",
      "Validation Loss: 0.0016236608969078187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006962236188119277\n",
      "Training Loss: 0.006726141702383757\n",
      "Training Loss: 0.006395502398954704\n",
      "Training Loss: 0.0038219688424578637\n",
      "Training Loss: 0.0005611131076511811\n",
      "Training Loss: 0.0003900524530399707\n",
      "Training Loss: 0.00030240512773161755\n",
      "Validation Loss: 0.001614540169128454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006945944156032055\n",
      "Training Loss: 0.006703510646475479\n",
      "Training Loss: 0.006372738326899707\n",
      "Training Loss: 0.0038067929206590636\n",
      "Training Loss: 0.000556878032948589\n",
      "Training Loss: 0.00038530839829036266\n",
      "Training Loss: 0.0002941040498626535\n",
      "Validation Loss: 0.001604339419510948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006928563654655591\n",
      "Training Loss: 0.006679475941928104\n",
      "Training Loss: 0.006348430730868131\n",
      "Training Loss: 0.0037915121632249795\n",
      "Training Loss: 0.0005526963840020472\n",
      "Training Loss: 0.00038068802077759754\n",
      "Training Loss: 0.00028601147794688587\n",
      "Validation Loss: 0.0015931955815503488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006910169904585928\n",
      "Training Loss: 0.0066541453707031906\n",
      "Training Loss: 0.006322674067923799\n",
      "Training Loss: 0.003776313579364796\n",
      "Training Loss: 0.0005486037625087192\n",
      "Training Loss: 0.00037623816577252\n",
      "Training Loss: 0.0002782216428749962\n",
      "Validation Loss: 0.0015812730024516851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006890904157189653\n",
      "Training Loss: 0.00662770449067466\n",
      "Training Loss: 0.006295630520908162\n",
      "Training Loss: 0.0037614121473598062\n",
      "Training Loss: 0.0005446487278459245\n",
      "Training Loss: 0.0003720156144663633\n",
      "Training Loss: 0.0002708524719491834\n",
      "Validation Loss: 0.0015687318426105177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.0068709664029302075\n",
      "Training Loss: 0.0066004052490461615\n",
      "Training Loss: 0.006267522664275021\n",
      "Training Loss: 0.003747024166186748\n",
      "Training Loss: 0.0005408857164002257\n",
      "Training Loss: 0.0003680925993648998\n",
      "Training Loss: 0.0002640342306403909\n",
      "Validation Loss: 0.0015557250244523772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006850582359475083\n",
      "Training Loss: 0.006572541259229184\n",
      "Training Loss: 0.006238614922622219\n",
      "Training Loss: 0.0037333507329094574\n",
      "Training Loss: 0.0005373651726040407\n",
      "Training Loss: 0.00036453490696658264\n",
      "Training Loss: 0.00025788842052861584\n",
      "Validation Loss: 0.0015423594423679178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006830003569484688\n",
      "Training Loss: 0.0065444462792947885\n",
      "Training Loss: 0.006209220672026276\n",
      "Training Loss: 0.0037205574465770043\n",
      "Training Loss: 0.0005341239758490701\n",
      "Training Loss: 0.00036139385842034246\n",
      "Training Loss: 0.0002525076338497456\n",
      "Validation Loss: 0.0015287793660340202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.00680947867105715\n",
      "Training Loss: 0.0065164553339127455\n",
      "Training Loss: 0.0061796698556281626\n",
      "Training Loss: 0.003708758596694679\n",
      "Training Loss: 0.0005311943055130541\n",
      "Training Loss: 0.00035870109088136814\n",
      "Training Loss: 0.00024794665681838524\n",
      "Validation Loss: 0.001515132475780386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006789241433143616\n",
      "Training Loss: 0.006488893759669736\n",
      "Training Loss: 0.006150300621520728\n",
      "Training Loss: 0.003698012298264075\n",
      "Training Loss: 0.000528577623408637\n",
      "Training Loss: 0.00035646073274619994\n",
      "Training Loss: 0.0002442180600883148\n",
      "Validation Loss: 0.0015016028797951587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006769495265325531\n",
      "Training Loss: 0.006462041632039473\n",
      "Training Loss: 0.006121425833553076\n",
      "Training Loss: 0.0036883157433476297\n",
      "Training Loss: 0.000526275165611878\n",
      "Training Loss: 0.0003546580542024458\n",
      "Training Loss: 0.00024129578308929923\n",
      "Validation Loss: 0.0014884039151507574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006750397160067223\n",
      "Training Loss: 0.006436123177409172\n",
      "Training Loss: 0.006093313536839559\n",
      "Training Loss: 0.003679619039321551\n",
      "Training Loss: 0.000524280980353069\n",
      "Training Loss: 0.00035326751369211705\n",
      "Training Loss: 0.00023912309661682228\n",
      "Validation Loss: 0.0014757451963543801\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.0067320619855308905\n",
      "Training Loss: 0.006411300102481619\n",
      "Training Loss: 0.0060661742265801875\n",
      "Training Loss: 0.00367182277754182\n",
      "Training Loss: 0.0005225801478081849\n",
      "Training Loss: 0.00035224735978772514\n",
      "Training Loss: 0.00023762261253068573\n",
      "Validation Loss: 0.0014638220817234354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006714545233990066\n",
      "Training Loss: 0.0063876623508986085\n",
      "Training Loss: 0.0060401500097941605\n",
      "Training Loss: 0.0036648127999796996\n",
      "Training Loss: 0.0005211719351427746\n",
      "Training Loss: 0.00035156044823452247\n",
      "Training Loss: 0.0002367040292119782\n",
      "Validation Loss: 0.0014527933739924938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006697849673219025\n",
      "Training Loss: 0.0063652352953795345\n",
      "Training Loss: 0.006015320640290156\n",
      "Training Loss: 0.003658452117233537\n",
      "Training Loss: 0.0005200509003407206\n",
      "Training Loss: 0.00035116404169457385\n",
      "Training Loss: 0.00023627444859812387\n",
      "Validation Loss: 0.001442773677996222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006681937875109725\n",
      "Training Loss: 0.006343995440984145\n",
      "Training Loss: 0.005991701524471864\n",
      "Training Loss: 0.0036526144784875215\n",
      "Training Loss: 0.000519212775870983\n",
      "Training Loss: 0.00035102838390230315\n",
      "Training Loss: 0.0002362480833653535\n",
      "Validation Loss: 0.0014338258706527668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006666734450263902\n",
      "Training Loss: 0.0063238738011568785\n",
      "Training Loss: 0.005969263372244313\n",
      "Training Loss: 0.003647185880327015\n",
      "Training Loss: 0.0005186500081617851\n",
      "Training Loss: 0.0003511120034454507\n",
      "Training Loss: 0.0002365413133156835\n",
      "Validation Loss: 0.0014259622089667482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006652171423775144\n",
      "Training Loss: 0.006304788533598184\n",
      "Training Loss: 0.005947946469532326\n",
      "Training Loss: 0.003642062754879589\n",
      "Training Loss: 0.0005183493264121353\n",
      "Training Loss: 0.00035138636001647684\n",
      "Training Loss: 0.00023708653990979654\n",
      "Validation Loss: 0.0014191514794342612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006638162524905056\n",
      "Training Loss: 0.006286634178832173\n",
      "Training Loss: 0.0059276656515430655\n",
      "Training Loss: 0.0036371676313865465\n",
      "Training Loss: 0.0005182897394115571\n",
      "Training Loss: 0.00035181468521841455\n",
      "Training Loss: 0.00023782464859323227\n",
      "Validation Loss: 0.0014133420659214772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006624633602332324\n",
      "Training Loss: 0.006269310953794047\n",
      "Training Loss: 0.005908328115474433\n",
      "Training Loss: 0.003632431325459038\n",
      "Training Loss: 0.0005184456508141012\n",
      "Training Loss: 0.00035236446716226057\n",
      "Training Loss: 0.0002387094089317543\n",
      "Validation Loss: 0.0014084552258895344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006611509793438017\n",
      "Training Loss: 0.006252717801835388\n",
      "Training Loss: 0.005889838715083897\n",
      "Training Loss: 0.003627805480500683\n",
      "Training Loss: 0.0005187824867971358\n",
      "Training Loss: 0.00035300294432090597\n",
      "Training Loss: 0.00023970243337316787\n",
      "Validation Loss: 0.0014044091923856473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006598743209033273\n",
      "Training Loss: 0.0062367641343735155\n",
      "Training Loss: 0.005872106925817206\n",
      "Training Loss: 0.003623248290386982\n",
      "Training Loss: 0.0005192692166383494\n",
      "Training Loss: 0.0003537041673916974\n",
      "Training Loss: 0.00024077415824649506\n",
      "Validation Loss: 0.0014011161325020675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.00658628205768764\n",
      "Training Loss: 0.006221364471130073\n",
      "Training Loss: 0.0058550483570434155\n",
      "Training Loss: 0.0036187301773315996\n",
      "Training Loss: 0.000519876178004779\n",
      "Training Loss: 0.000354438220620068\n",
      "Training Loss: 0.00024189936706534354\n",
      "Validation Loss: 0.0013984965779844755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006574088078341447\n",
      "Training Loss: 0.006206443542614579\n",
      "Training Loss: 0.005838584216544405\n",
      "Training Loss: 0.00361422475107247\n",
      "Training Loss: 0.000520574297697749\n",
      "Training Loss: 0.0003551856359263184\n",
      "Training Loss: 0.0002430593183999008\n",
      "Validation Loss: 0.0013964734481554304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006562132087419741\n",
      "Training Loss: 0.006191932193469256\n",
      "Training Loss: 0.005822643502615393\n",
      "Training Loss: 0.003609713330370141\n",
      "Training Loss: 0.0005213343010473182\n",
      "Training Loss: 0.0003559262674571073\n",
      "Training Loss: 0.0002442385535869107\n",
      "Validation Loss: 0.0013949761973192116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006550383989233524\n",
      "Training Loss: 0.0061777747003361584\n",
      "Training Loss: 0.005807170099578798\n",
      "Training Loss: 0.003605183192048571\n",
      "Training Loss: 0.0005221391340455739\n",
      "Training Loss: 0.00035664560413351865\n",
      "Training Loss: 0.00024542281507820005\n",
      "Validation Loss: 0.001393941268678022\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.00653881996171549\n",
      "Training Loss: 0.006163919126847759\n",
      "Training Loss: 0.0057921076915226875\n",
      "Training Loss: 0.003600619038261357\n",
      "Training Loss: 0.0005229665257866145\n",
      "Training Loss: 0.0003573323492673808\n",
      "Training Loss: 0.00024660195253090934\n",
      "Validation Loss: 0.0013933203420523302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0065274217398837205\n",
      "Training Loss: 0.006150317633291706\n",
      "Training Loss: 0.005777411470189691\n",
      "Training Loss: 0.0035960157775116386\n",
      "Training Loss: 0.0005238033203568193\n",
      "Training Loss: 0.0003579776045990002\n",
      "Training Loss: 0.0002477671430096962\n",
      "Validation Loss: 0.0013930556270996307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006516169385286048\n",
      "Training Loss: 0.006136931751389057\n",
      "Training Loss: 0.005763041030149907\n",
      "Training Loss: 0.0035913677398639265\n",
      "Training Loss: 0.0005246387546867481\n",
      "Training Loss: 0.0003585773419581528\n",
      "Training Loss: 0.0002489109024645586\n",
      "Validation Loss: 0.0013931090312387293\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 132\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006505048985127359\n",
      "Training Loss: 0.006123729157261551\n",
      "Training Loss: 0.005748963365331292\n",
      "Training Loss: 0.003586671327793738\n",
      "Training Loss: 0.0005254608991526765\n",
      "Training Loss: 0.00035912637644287316\n",
      "Training Loss: 0.000250029207290936\n",
      "Validation Loss: 0.001393439451631286\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 133\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006494042708654888\n",
      "Training Loss: 0.006110678828554228\n",
      "Training Loss: 0.005735146607039496\n",
      "Training Loss: 0.0035819228972104613\n",
      "Training Loss: 0.0005262635676990613\n",
      "Training Loss: 0.00035962272033430054\n",
      "Training Loss: 0.00025111552167800255\n",
      "Validation Loss: 0.0013940145078951002\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 134\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006483141075004823\n",
      "Training Loss: 0.00609776018303819\n",
      "Training Loss: 0.005721567402360961\n",
      "Training Loss: 0.003577123160866904\n",
      "Training Loss: 0.0005270451540854992\n",
      "Training Loss: 0.0003600678157999937\n",
      "Training Loss: 0.00025216941658072755\n",
      "Validation Loss: 0.0013948000299259025\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 135\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006472328791860491\n",
      "Training Loss: 0.006084949114592746\n",
      "Training Loss: 0.0057082042098045346\n",
      "Training Loss: 0.0035722605866612867\n",
      "Training Loss: 0.0005277860708520166\n",
      "Training Loss: 0.0003604568868831848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [08:53<14:42, 147.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002531852836364123\n",
      "Validation Loss: 0.0013957627726198184\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 136\n",
      "Early stopping after 136 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.11482223726809025\n",
      "Training Loss: 0.09457418696954846\n",
      "Training Loss: 0.0830644753947854\n",
      "Training Loss: 0.06564256371930241\n",
      "Training Loss: 0.05137628613039851\n",
      "Training Loss: 0.04738901155069471\n",
      "Training Loss: 0.0490706040058285\n",
      "Validation Loss: 0.053480799142480565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0633808172121644\n",
      "Training Loss: 0.06006226591765881\n",
      "Training Loss: 0.05814350053668022\n",
      "Training Loss: 0.04700978717613907\n",
      "Training Loss: 0.03328634154982865\n",
      "Training Loss: 0.030183017873205244\n",
      "Training Loss: 0.029718655850738285\n",
      "Validation Loss: 0.03422296903190318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04464906827546656\n",
      "Training Loss: 0.041951820505782965\n",
      "Training Loss: 0.04063164952211082\n",
      "Training Loss: 0.029382930904976092\n",
      "Training Loss: 0.01714973100926727\n",
      "Training Loss: 0.015289391288533807\n",
      "Training Loss: 0.014884657140355558\n",
      "Validation Loss: 0.019874592148611665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.03093922547530383\n",
      "Training Loss: 0.029023509239777923\n",
      "Training Loss: 0.028632389032281935\n",
      "Training Loss: 0.018526281284866854\n",
      "Training Loss: 0.007908399995649233\n",
      "Training Loss: 0.006949566215043887\n",
      "Training Loss: 0.006642871220828965\n",
      "Validation Loss: 0.011777620262916335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.02292442610487342\n",
      "Training Loss: 0.02148252535611391\n",
      "Training Loss: 0.021582381785847246\n",
      "Training Loss: 0.012578245638287626\n",
      "Training Loss: 0.003490825030603446\n",
      "Training Loss: 0.0029044574924046176\n",
      "Training Loss: 0.0026406004978343843\n",
      "Validation Loss: 0.007765312536535889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.018360624131746592\n",
      "Training Loss: 0.017205306480173023\n",
      "Training Loss: 0.017382994997315108\n",
      "Training Loss: 0.009488463592279004\n",
      "Training Loss: 0.001637224049627548\n",
      "Training Loss: 0.0012346796196652577\n",
      "Training Loss: 0.0011361874708381947\n",
      "Validation Loss: 0.005974609690935487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.015678939397912473\n",
      "Training Loss: 0.014772970038466155\n",
      "Training Loss: 0.01483442127937451\n",
      "Training Loss: 0.00798799704942212\n",
      "Training Loss: 0.0010627815414045471\n",
      "Training Loss: 0.0007949604814348277\n",
      "Training Loss: 0.0008248706590893562\n",
      "Validation Loss: 0.004937528102444607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.013682650306727738\n",
      "Training Loss: 0.012982328543439508\n",
      "Training Loss: 0.01293774964986369\n",
      "Training Loss: 0.007031736579592689\n",
      "Training Loss: 0.0008871747873490676\n",
      "Training Loss: 0.0006843791047140258\n",
      "Training Loss: 0.0007623769273777725\n",
      "Validation Loss: 0.004123040325508003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.012054284643381834\n",
      "Training Loss: 0.011548042024951428\n",
      "Training Loss: 0.011451857688371092\n",
      "Training Loss: 0.0063340602708922234\n",
      "Training Loss: 0.0008290148887317628\n",
      "Training Loss: 0.000654279574555403\n",
      "Training Loss: 0.0007596949777507689\n",
      "Validation Loss: 0.0035247646689337366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.010829760688357054\n",
      "Training Loss: 0.010468796979403124\n",
      "Training Loss: 0.010338647546013817\n",
      "Training Loss: 0.005837721230709576\n",
      "Training Loss: 0.0008247534537076717\n",
      "Training Loss: 0.0006595482357079163\n",
      "Training Loss: 0.0007833115283574444\n",
      "Validation Loss: 0.0031065902394096082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.009952958466019481\n",
      "Training Loss: 0.009689080255338923\n",
      "Training Loss: 0.009533598844427615\n",
      "Training Loss: 0.005495192920061526\n",
      "Training Loss: 0.0008439661243392038\n",
      "Training Loss: 0.0006793912698049099\n",
      "Training Loss: 0.0008155966617778177\n",
      "Validation Loss: 0.0028186914993799726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009344545892672614\n",
      "Training Loss: 0.009141914499923586\n",
      "Training Loss: 0.008965861474862322\n",
      "Training Loss: 0.005264220401149941\n",
      "Training Loss: 0.0008700079748086864\n",
      "Training Loss: 0.0007025100810278673\n",
      "Training Loss: 0.0008471453152742469\n",
      "Validation Loss: 0.002618810837276974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00893042944255285\n",
      "Training Loss: 0.008765327897854149\n",
      "Training Loss: 0.008571126599563286\n",
      "Training Loss: 0.005110596255544806\n",
      "Training Loss: 0.0008950394749990665\n",
      "Training Loss: 0.0007237594223988708\n",
      "Training Loss: 0.000873972895424231\n",
      "Validation Loss: 0.0024775799637122343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008650183529825882\n",
      "Training Loss: 0.008508193847956137\n",
      "Training Loss: 0.008297310130437836\n",
      "Training Loss: 0.005008434166593361\n",
      "Training Loss: 0.0009159196796281322\n",
      "Training Loss: 0.0007411706708080601\n",
      "Training Loss: 0.000894735821748327\n",
      "Validation Loss: 0.002376064155606138\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008458761405199767\n",
      "Training Loss: 0.008331626344006509\n",
      "Training Loss: 0.008105499062221497\n",
      "Training Loss: 0.004939129823542316\n",
      "Training Loss: 0.000931544559844042\n",
      "Training Loss: 0.0007540588876145194\n",
      "Training Loss: 0.0009090703692709212\n",
      "Validation Loss: 0.0023018064609905773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.00832483104080893\n",
      "Training Loss: 0.008207957447739318\n",
      "Training Loss: 0.007968366346322\n",
      "Training Loss: 0.0048899786977563055\n",
      "Training Loss: 0.0009415917766091297\n",
      "Training Loss: 0.0007622063663438893\n",
      "Training Loss: 0.0009169383983680746\n",
      "Validation Loss: 0.0022461690639332286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008227832894772292\n",
      "Training Loss: 0.008118642716435715\n",
      "Training Loss: 0.007867648820392788\n",
      "Training Loss: 0.0048527425384963865\n",
      "Training Loss: 0.0009460704915545648\n",
      "Training Loss: 0.0007656198406039039\n",
      "Training Loss: 0.0009184697503951611\n",
      "Validation Loss: 0.0022030067189739606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008154824818484485\n",
      "Training Loss: 0.008051784355193376\n",
      "Training Loss: 0.0077914919529575855\n",
      "Training Loss: 0.004822304020708543\n",
      "Training Loss: 0.0009451721164805349\n",
      "Training Loss: 0.0007644479272858007\n",
      "Training Loss: 0.0009139258971845265\n",
      "Validation Loss: 0.0021679470248429683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008097808122402057\n",
      "Training Loss: 0.007999901844887063\n",
      "Training Loss: 0.007732251060660928\n",
      "Training Loss: 0.004795555098826299\n",
      "Training Loss: 0.000939203964517219\n",
      "Training Loss: 0.0007589499896857887\n",
      "Training Loss: 0.0009036880603525788\n",
      "Validation Loss: 0.0021379592222177286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00805179580929689\n",
      "Training Loss: 0.00795826262095943\n",
      "Training Loss: 0.007684920174069703\n",
      "Training Loss: 0.004770624764205422\n",
      "Training Loss: 0.0009285627051212941\n",
      "Training Loss: 0.0007494736207445385\n",
      "Training Loss: 0.0008882486119546229\n",
      "Validation Loss: 0.0021109990668762126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008013555250363425\n",
      "Training Loss: 0.007923765182495117\n",
      "Training Loss: 0.007646095781819895\n",
      "Training Loss: 0.004746379971184069\n",
      "Training Loss: 0.0009137161236503744\n",
      "Training Loss: 0.0007364325525122694\n",
      "Training Loss: 0.0008682014813530259\n",
      "Validation Loss: 0.0020857361230994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007980870410101489\n",
      "Training Loss: 0.007894256489817054\n",
      "Training Loss: 0.007613334851339459\n",
      "Training Loss: 0.004722122561943252\n",
      "Training Loss: 0.0008952054429391865\n",
      "Training Loss: 0.0007203125052183168\n",
      "Training Loss: 0.0008442507233849028\n",
      "Validation Loss: 0.0020613479340245793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007952103625284508\n",
      "Training Loss: 0.007868138876510784\n",
      "Training Loss: 0.007584773384733126\n",
      "Training Loss: 0.004697429117804859\n",
      "Training Loss: 0.0008736591735578258\n",
      "Training Loss: 0.0007016718876548112\n",
      "Training Loss: 0.0008172082119563129\n",
      "Validation Loss: 0.0020373805772364033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007925955972168594\n",
      "Training Loss: 0.007844138913787902\n",
      "Training Loss: 0.0075589046673849225\n",
      "Training Loss: 0.004672062729368918\n",
      "Training Loss: 0.0008497871408690116\n",
      "Training Loss: 0.0006811310415650951\n",
      "Training Loss: 0.0007879670371039538\n",
      "Validation Loss: 0.0020136163529764673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00790135026560165\n",
      "Training Loss: 0.007821204222273082\n",
      "Training Loss: 0.0075344610470347104\n",
      "Training Loss: 0.004645917498855852\n",
      "Training Loss: 0.0008243636445695302\n",
      "Training Loss: 0.000659352044822299\n",
      "Training Loss: 0.0007574619664956117\n",
      "Validation Loss: 0.0019899921030985986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007877376397373155\n",
      "Training Loss: 0.0077984442084562035\n",
      "Training Loss: 0.0075103524082805965\n",
      "Training Loss: 0.004618985747656552\n",
      "Training Loss: 0.0007981993985595182\n",
      "Training Loss: 0.0006370077431347453\n",
      "Training Loss: 0.0007266068112221546\n",
      "Validation Loss: 0.001966540191770786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007853267507161945\n",
      "Training Loss: 0.007775116198463366\n",
      "Training Loss: 0.007485658827936277\n",
      "Training Loss: 0.004591327280213591\n",
      "Training Loss: 0.000772077987639932\n",
      "Training Loss: 0.0006147357825830113\n",
      "Training Loss: 0.0006962239662971115\n",
      "Validation Loss: 0.0019433299033320072\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007828404764877632\n",
      "Training Loss: 0.007750626505585387\n",
      "Training Loss: 0.007459628571523353\n",
      "Training Loss: 0.004563055403268663\n",
      "Training Loss: 0.0007467181232641451\n",
      "Training Loss: 0.0005931000517739449\n",
      "Training Loss: 0.0006669887570751598\n",
      "Validation Loss: 0.0019204478943284447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007802325321827084\n",
      "Training Loss: 0.007724542492069304\n",
      "Training Loss: 0.007431698964210227\n",
      "Training Loss: 0.004534312665346079\n",
      "Training Loss: 0.0007227171171689406\n",
      "Training Loss: 0.0005725561440340243\n",
      "Training Loss: 0.0006393964735616465\n",
      "Validation Loss: 0.0018979737052017272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007774734915001318\n",
      "Training Loss: 0.007696597219910473\n",
      "Training Loss: 0.007401503882138058\n",
      "Training Loss: 0.0045052620676869996\n",
      "Training Loss: 0.0007005323876001057\n",
      "Training Loss: 0.0005534326274937484\n",
      "Training Loss: 0.0006137426665372914\n",
      "Validation Loss: 0.0018759807852996785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007745517556322738\n",
      "Training Loss: 0.0076667040598113086\n",
      "Training Loss: 0.007368893654784187\n",
      "Training Loss: 0.0044760811785090485\n",
      "Training Loss: 0.0006804626988014207\n",
      "Training Loss: 0.0005359334829699947\n",
      "Training Loss: 0.0005901511521369684\n",
      "Validation Loss: 0.001854545385241055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007714711445150897\n",
      "Training Loss: 0.007634930202038958\n",
      "Training Loss: 0.007333905956475064\n",
      "Training Loss: 0.004446944013398024\n",
      "Training Loss: 0.0006626586097991094\n",
      "Training Loss: 0.0005201430099987192\n",
      "Training Loss: 0.0005685990391793894\n",
      "Validation Loss: 0.0018337408256410073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007682487283600495\n",
      "Training Loss: 0.007601476146373898\n",
      "Training Loss: 0.0072967462579254065\n",
      "Training Loss: 0.004418023882390116\n",
      "Training Loss: 0.0006471311078348663\n",
      "Training Loss: 0.0005060460995446192\n",
      "Training Loss: 0.0005489571584621444\n",
      "Validation Loss: 0.0018136487153296843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007649106176104397\n",
      "Training Loss: 0.0075666291627567266\n",
      "Training Loss: 0.007257733278675005\n",
      "Training Loss: 0.00438946581336495\n",
      "Training Loss: 0.0006337831099881441\n",
      "Training Loss: 0.0004935577196010854\n",
      "Training Loss: 0.000531037394903251\n",
      "Validation Loss: 0.0017943480950784573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007614865166833624\n",
      "Training Loss: 0.00753071645507589\n",
      "Training Loss: 0.007217239997116849\n",
      "Training Loss: 0.004361393359868088\n",
      "Training Loss: 0.000622446111010504\n",
      "Training Loss: 0.00048254716690280473\n",
      "Training Loss: 0.0005146293155121384\n",
      "Validation Loss: 0.0017759135235053023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007580059316242113\n",
      "Training Loss: 0.007494055744027719\n",
      "Training Loss: 0.007175644850358367\n",
      "Training Loss: 0.004333888528999523\n",
      "Training Loss: 0.0006129159427655395\n",
      "Training Loss: 0.0004728711254574591\n",
      "Training Loss: 0.0004995349640375935\n",
      "Validation Loss: 0.001758415516139329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007544939847430214\n",
      "Training Loss: 0.007456925772130489\n",
      "Training Loss: 0.007133289076155052\n",
      "Training Loss: 0.004307006601520697\n",
      "Training Loss: 0.0006049828256072942\n",
      "Training Loss: 0.00046438489262072834\n",
      "Training Loss: 0.0004855782834783895\n",
      "Validation Loss: 0.0017419213871972998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007509720876114443\n",
      "Training Loss: 0.007419557198882103\n",
      "Training Loss: 0.007090475492877886\n",
      "Training Loss: 0.004280771470585023\n",
      "Training Loss: 0.0005984464580978965\n",
      "Training Loss: 0.00045695813867496326\n",
      "Training Loss: 0.00047261711370083503\n",
      "Validation Loss: 0.0017264900596185382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007474555913358927\n",
      "Training Loss: 0.007382125519216061\n",
      "Training Loss: 0.007047453804407269\n",
      "Training Loss: 0.00425519276453997\n",
      "Training Loss: 0.0005931286282429937\n",
      "Training Loss: 0.00045047338273434433\n",
      "Training Loss: 0.00046053682061028664\n",
      "Validation Loss: 0.0017121913891363267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007439564242959023\n",
      "Training Loss: 0.007344767090398818\n",
      "Training Loss: 0.007004446178907529\n",
      "Training Loss: 0.004230265891092131\n",
      "Training Loss: 0.0005888632644200697\n",
      "Training Loss: 0.0004448221634083893\n",
      "Training Loss: 0.00044924473237188065\n",
      "Validation Loss: 0.001699088384889586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00740484087378718\n",
      "Training Loss: 0.007307590824784711\n",
      "Training Loss: 0.00696165437460877\n",
      "Training Loss: 0.004205980083352188\n",
      "Training Loss: 0.0005855034569685813\n",
      "Training Loss: 0.0004399084105534712\n",
      "Training Loss: 0.00043866750471352136\n",
      "Validation Loss: 0.0016872425628926305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00737046800670214\n",
      "Training Loss: 0.007270694815088063\n",
      "Training Loss: 0.006919271959923208\n",
      "Training Loss: 0.004182330369585543\n",
      "Training Loss: 0.0005829011637251824\n",
      "Training Loss: 0.00043563130879192613\n",
      "Training Loss: 0.0004287359477893915\n",
      "Validation Loss: 0.0016767180697318368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007336530752945691\n",
      "Training Loss: 0.007234177275095135\n",
      "Training Loss: 0.006877493736101315\n",
      "Training Loss: 0.004159312841220526\n",
      "Training Loss: 0.0005809213523025391\n",
      "Training Loss: 0.00043190634110942485\n",
      "Training Loss: 0.00041940021197660825\n",
      "Validation Loss: 0.0016675677186131917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007303112399531528\n",
      "Training Loss: 0.0071981404116377235\n",
      "Training Loss: 0.006836514384485781\n",
      "Training Loss: 0.004136932371620787\n",
      "Training Loss: 0.0005794330626667942\n",
      "Training Loss: 0.0004286411609064089\n",
      "Training Loss: 0.00041060808616748544\n",
      "Validation Loss: 0.0016598285917953104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007270315419882536\n",
      "Training Loss: 0.0071626968192867934\n",
      "Training Loss: 0.006796527591068298\n",
      "Training Loss: 0.00411520320463751\n",
      "Training Loss: 0.0005783075423096307\n",
      "Training Loss: 0.0004257516017241869\n",
      "Training Loss: 0.00040231670143839435\n",
      "Validation Loss: 0.0016535108594863924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007238249956863001\n",
      "Training Loss: 0.007127970777219161\n",
      "Training Loss: 0.006757723210612312\n",
      "Training Loss: 0.004094145971685066\n",
      "Training Loss: 0.0005774279741308419\n",
      "Training Loss: 0.0004231640876241727\n",
      "Training Loss: 0.0003944959109503543\n",
      "Validation Loss: 0.0016486184574072407\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007207013783045113\n",
      "Training Loss: 0.007094068945152685\n",
      "Training Loss: 0.006720252875238657\n",
      "Training Loss: 0.004073784294014331\n",
      "Training Loss: 0.0005766988146206131\n",
      "Training Loss: 0.00042081582480022915\n",
      "Training Loss: 0.00038712087596650237\n",
      "Validation Loss: 0.0016450926231256118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.0071767072263173755\n",
      "Training Loss: 0.0070611016754992305\n",
      "Training Loss: 0.006684250785037875\n",
      "Training Loss: 0.0040541421881061974\n",
      "Training Loss: 0.0005760356864630012\n",
      "Training Loss: 0.0004186578376902617\n",
      "Training Loss: 0.0003801813082827721\n",
      "Validation Loss: 0.0016428653333595106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007147404793649912\n",
      "Training Loss: 0.007029150789603591\n",
      "Training Loss: 0.006649803923210129\n",
      "Training Loss: 0.004035242839672719\n",
      "Training Loss: 0.0005753743361128727\n",
      "Training Loss: 0.00041664685453724815\n",
      "Training Loss: 0.0003736638222471811\n",
      "Validation Loss: 0.0016418355576496063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007119172002421692\n",
      "Training Loss: 0.006998278285609558\n",
      "Training Loss: 0.006616956185316667\n",
      "Training Loss: 0.004017098661570344\n",
      "Training Loss: 0.0005746736042056\n",
      "Training Loss: 0.0004147600760916248\n",
      "Training Loss: 0.00036757044726982714\n",
      "Validation Loss: 0.0016418661690475803\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 50\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0070920377061702315\n",
      "Training Loss: 0.006968514635227621\n",
      "Training Loss: 0.006585709715727717\n",
      "Training Loss: 0.00399971906306746\n",
      "Training Loss: 0.0005739097914920421\n",
      "Training Loss: 0.0004129839193774387\n",
      "Training Loss: 0.0003619008435998694\n",
      "Validation Loss: 0.0016428047382034718\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 51\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00706600834033452\n",
      "Training Loss: 0.006939864488085732\n",
      "Training Loss: 0.006556026079924777\n",
      "Training Loss: 0.003983101240301039\n",
      "Training Loss: 0.0005730730746290647\n",
      "Training Loss: 0.000411306812420662\n",
      "Training Loss: 0.0003566517603030661\n",
      "Validation Loss: 0.0016444885322483159\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 52\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007041071959538386\n",
      "Training Loss: 0.006912308820756152\n",
      "Training Loss: 0.006527842149371282\n",
      "Training Loss: 0.003967233612347627\n",
      "Training Loss: 0.00057216406428779\n",
      "Training Loss: 0.00040972614435304423\n",
      "Training Loss: 0.000351817764894804\n",
      "Validation Loss: 0.0016467399835075978\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 53\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007017197204986587\n",
      "Training Loss: 0.00688580957823433\n",
      "Training Loss: 0.00650106682209298\n",
      "Training Loss: 0.0039520975475898015\n",
      "Training Loss: 0.0005711893304396654\n",
      "Training Loss: 0.00040823944716976256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [10:16<10:19, 123.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00034738862559606786\n",
      "Validation Loss: 0.0016494051136699075\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 54\n",
      "Early stopping after 54 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.45923496663570407\n",
      "Training Loss: 0.3568067030608654\n",
      "Training Loss: 0.2779049304127693\n",
      "Training Loss: 0.18412986505776643\n",
      "Training Loss: 0.11518447738140822\n",
      "Training Loss: 0.08988504225388169\n",
      "Training Loss: 0.07252919849008321\n",
      "Validation Loss: 0.0746042128575596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.08787024872377515\n",
      "Training Loss: 0.07906594345346094\n",
      "Training Loss: 0.07607630776241421\n",
      "Training Loss: 0.06383969038492068\n",
      "Training Loss: 0.051750248204916714\n",
      "Training Loss: 0.05034894540905952\n",
      "Training Loss: 0.05162528133019805\n",
      "Validation Loss: 0.057289500103405354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06942965304479003\n",
      "Training Loss: 0.06742681125178933\n",
      "Training Loss: 0.06652122331783175\n",
      "Training Loss: 0.05562309375003679\n",
      "Training Loss: 0.042131953509524464\n",
      "Training Loss: 0.038814681489020585\n",
      "Training Loss: 0.038752829367294905\n",
      "Validation Loss: 0.0434540074025647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.052734311195090415\n",
      "Training Loss: 0.04935453608632088\n",
      "Training Loss: 0.04746690054424107\n",
      "Training Loss: 0.03506956910714507\n",
      "Training Loss: 0.0221299628354609\n",
      "Training Loss: 0.019511618977412583\n",
      "Training Loss: 0.019406003397889435\n",
      "Validation Loss: 0.025395678275191548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03397817740216851\n",
      "Training Loss: 0.03137912644073367\n",
      "Training Loss: 0.03069602033589035\n",
      "Training Loss: 0.019319548340281472\n",
      "Training Loss: 0.008746806501876562\n",
      "Training Loss: 0.007650707798311487\n",
      "Training Loss: 0.007288328014547005\n",
      "Validation Loss: 0.013689749583790309\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.023033196395263075\n",
      "Training Loss: 0.021288494891487063\n",
      "Training Loss: 0.02141614315100014\n",
      "Training Loss: 0.012432282149093225\n",
      "Training Loss: 0.003522269949899055\n",
      "Training Loss: 0.003368672267824877\n",
      "Training Loss: 0.003183346820587758\n",
      "Validation Loss: 0.009279591747304975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.018362003616057335\n",
      "Training Loss: 0.01712985285324976\n",
      "Training Loss: 0.01736344198230654\n",
      "Training Loss: 0.010142243474401767\n",
      "Training Loss: 0.002569721585314255\n",
      "Training Loss: 0.0023969847350963393\n",
      "Training Loss: 0.002321172673982801\n",
      "Validation Loss: 0.0076127600168751745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01591710751177743\n",
      "Training Loss: 0.014953930724877863\n",
      "Training Loss: 0.015101292345207185\n",
      "Training Loss: 0.008970357833022717\n",
      "Training Loss: 0.0023447230679448693\n",
      "Training Loss: 0.0020445023135107474\n",
      "Training Loss: 0.002010036272695288\n",
      "Validation Loss: 0.006444222885027026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.014219954907894135\n",
      "Training Loss: 0.013461721434723586\n",
      "Training Loss: 0.013542784493183717\n",
      "Training Loss: 0.008130677618610208\n",
      "Training Loss: 0.002139554720488377\n",
      "Training Loss: 0.0017861074741813354\n",
      "Training Loss: 0.0017996593346470036\n",
      "Validation Loss: 0.005502150958985585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.012942189478781074\n",
      "Training Loss: 0.012344767265021801\n",
      "Training Loss: 0.012373131500789896\n",
      "Training Loss: 0.0074498987963306715\n",
      "Training Loss: 0.001920955883397255\n",
      "Training Loss: 0.001569163294043392\n",
      "Training Loss: 0.0016301196404674555\n",
      "Validation Loss: 0.004761341862552293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.011921391622163355\n",
      "Training Loss: 0.011458002591971307\n",
      "Training Loss: 0.011442035833606496\n",
      "Training Loss: 0.006882095641485648\n",
      "Training Loss: 0.0017170720761350822\n",
      "Training Loss: 0.001388792896468658\n",
      "Training Loss: 0.0014847997324250173\n",
      "Validation Loss: 0.004191312451030682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011090084195602685\n",
      "Training Loss: 0.010738141559995711\n",
      "Training Loss: 0.010685469133313745\n",
      "Training Loss: 0.006412303792458261\n",
      "Training Loss: 0.0015399612066539703\n",
      "Training Loss: 0.0012402100171311759\n",
      "Training Loss: 0.0013571426369162508\n",
      "Validation Loss: 0.0037552380114327243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.01042309165932238\n",
      "Training Loss: 0.010156985048670322\n",
      "Training Loss: 0.010072973088826985\n",
      "Training Loss: 0.006032539732259466\n",
      "Training Loss: 0.0013934511713159735\n",
      "Training Loss: 0.0011196013638254954\n",
      "Training Loss: 0.0012462018434598577\n",
      "Validation Loss: 0.0034204474848164037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009902100146282464\n",
      "Training Loss: 0.009695296504069119\n",
      "Training Loss: 0.009583119555609301\n",
      "Training Loss: 0.0057337897489924215\n",
      "Training Loss: 0.0012770731704949867\n",
      "Training Loss: 0.0010237767091166462\n",
      "Training Loss: 0.0011525387241272257\n",
      "Validation Loss: 0.003160726984897201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009504660540260374\n",
      "Training Loss: 0.00933403999893926\n",
      "Training Loss: 0.009196340242633596\n",
      "Training Loss: 0.0055040783037111395\n",
      "Training Loss: 0.001187203434383264\n",
      "Training Loss: 0.0009492042596684769\n",
      "Training Loss: 0.001075879030940996\n",
      "Validation Loss: 0.0029566003500081928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009206674649612978\n",
      "Training Loss: 0.009054675751831382\n",
      "Training Loss: 0.008894519972382114\n",
      "Training Loss: 0.005330488170002355\n",
      "Training Loss: 0.0011189504668436712\n",
      "Training Loss: 0.0008920826600297005\n",
      "Training Loss: 0.001014796850977291\n",
      "Validation Loss: 0.0027945507161361983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008986397846601903\n",
      "Training Loss: 0.00884084946475923\n",
      "Training Loss: 0.008661603559739888\n",
      "Training Loss: 0.005201200107694604\n",
      "Training Loss: 0.0010676941321435152\n",
      "Training Loss: 0.0008488545490945398\n",
      "Training Loss: 0.000967235676398559\n",
      "Validation Loss: 0.002665391935050629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008825753015698865\n",
      "Training Loss: 0.008678761747432873\n",
      "Training Loss: 0.008483600654872135\n",
      "Training Loss: 0.005106159258211847\n",
      "Training Loss: 0.0010296008212753805\n",
      "Training Loss: 0.0008164836787909735\n",
      "Training Loss: 0.0009309646266410709\n",
      "Validation Loss: 0.0025625554253395177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008709891862235964\n",
      "Training Loss: 0.008556783506646752\n",
      "Training Loss: 0.008348406112054363\n",
      "Training Loss: 0.005036995417613071\n",
      "Training Loss: 0.001001565358856169\n",
      "Training Loss: 0.000792470688757021\n",
      "Training Loss: 0.0009038215616965317\n",
      "Validation Loss: 0.002480906907457916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008626621834700927\n",
      "Training Loss: 0.0084651200810913\n",
      "Training Loss: 0.008245749499183148\n",
      "Training Loss: 0.004986862364239642\n",
      "Training Loss: 0.0009810391494829674\n",
      "Training Loss: 0.0007747684584683156\n",
      "Training Loss: 0.0008838216164804181\n",
      "Validation Loss: 0.002416204238675726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008566205512033775\n",
      "Training Loss: 0.008395734768128023\n",
      "Training Loss: 0.008167201885953546\n",
      "Training Loss: 0.004950329842977226\n",
      "Training Loss: 0.0009659611418101121\n",
      "Training Loss: 0.0007617273121650214\n",
      "Training Loss: 0.0008692402145970845\n",
      "Validation Loss: 0.0023648975126006884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008521212459309027\n",
      "Training Loss: 0.008342307423008606\n",
      "Training Loss: 0.008106166217476129\n",
      "Training Loss: 0.004923259346578561\n",
      "Training Loss: 0.0009546973688702565\n",
      "Training Loss: 0.0007520386761461851\n",
      "Training Loss: 0.0008586338027816964\n",
      "Validation Loss: 0.0023240395968512646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008486259906785563\n",
      "Training Loss: 0.00830009276396595\n",
      "Training Loss: 0.00805767423240468\n",
      "Training Loss: 0.004902618198429991\n",
      "Training Loss: 0.0009459986548972665\n",
      "Training Loss: 0.0007446931178856175\n",
      "Training Loss: 0.0008508510409592418\n",
      "Validation Loss: 0.0022912557865225943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008457633618963883\n",
      "Training Loss: 0.008265659651951864\n",
      "Training Loss: 0.008018102193018422\n",
      "Training Loss: 0.004886254663178988\n",
      "Training Loss: 0.0009389494434799417\n",
      "Training Loss: 0.0007389400856482098\n",
      "Training Loss: 0.0008450095882290043\n",
      "Validation Loss: 0.0022646688236719805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008432865932118148\n",
      "Training Loss: 0.008236600416712463\n",
      "Training Loss: 0.007984873808454722\n",
      "Training Loss: 0.0048726824367622615\n",
      "Training Loss: 0.0009329021617304534\n",
      "Training Loss: 0.0007342351597253582\n",
      "Training Loss: 0.0008404511611297494\n",
      "Validation Loss: 0.002242818729400858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008410381673602387\n",
      "Training Loss: 0.00821126063237898\n",
      "Training Loss: 0.007956172339618206\n",
      "Training Loss: 0.004860894677913166\n",
      "Training Loss: 0.0009274176132021239\n",
      "Training Loss: 0.0007301946353618405\n",
      "Training Loss: 0.0008366980728169437\n",
      "Validation Loss: 0.0022245788844584614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008389201869722456\n",
      "Training Loss: 0.008188514290377497\n",
      "Training Loss: 0.007930729323998093\n",
      "Training Loss: 0.004850218766514445\n",
      "Training Loss: 0.0009222046927243355\n",
      "Training Loss: 0.0007265535392434686\n",
      "Training Loss: 0.0008334120439758408\n",
      "Validation Loss: 0.0022090985268855396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008368722629966215\n",
      "Training Loss: 0.008167597367428243\n",
      "Training Loss: 0.00790765721932985\n",
      "Training Loss: 0.004840197282574081\n",
      "Training Loss: 0.0009170739437831799\n",
      "Training Loss: 0.0007231341833539772\n",
      "Training Loss: 0.0008303566418180708\n",
      "Validation Loss: 0.00219572531327532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00834858693764545\n",
      "Training Loss: 0.008147990244906396\n",
      "Training Loss: 0.007886330324690789\n",
      "Training Loss: 0.004830532800551737\n",
      "Training Loss: 0.0009119150935657671\n",
      "Training Loss: 0.0007198179977785913\n",
      "Training Loss: 0.0008273709657805739\n",
      "Validation Loss: 0.002183959489124295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008328582574613393\n",
      "Training Loss: 0.008129337331047282\n",
      "Training Loss: 0.007866305583156645\n",
      "Training Loss: 0.0048210224183640096\n",
      "Training Loss: 0.0009066624614570174\n",
      "Training Loss: 0.0007165313562290976\n",
      "Training Loss: 0.0008243474855771638\n",
      "Validation Loss: 0.0021734294482910776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008308584414189682\n",
      "Training Loss: 0.008111393291037529\n",
      "Training Loss: 0.007847262126160786\n",
      "Training Loss: 0.004811532209569123\n",
      "Training Loss: 0.0009012892327882583\n",
      "Training Loss: 0.0007132310018641874\n",
      "Training Loss: 0.0008212168585851032\n",
      "Validation Loss: 0.0021638384411441316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.008288530003046617\n",
      "Training Loss: 0.008093993678921834\n",
      "Training Loss: 0.007828977779718116\n",
      "Training Loss: 0.00480197402255726\n",
      "Training Loss: 0.0008957776491297409\n",
      "Training Loss: 0.0007098805432906374\n",
      "Training Loss: 0.0008179244705388555\n",
      "Validation Loss: 0.0021549697784792625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.008268399973167107\n",
      "Training Loss: 0.008077034496236592\n",
      "Training Loss: 0.007811298940796405\n",
      "Training Loss: 0.0047922921802819474\n",
      "Training Loss: 0.0008901293209055438\n",
      "Training Loss: 0.0007064625556813552\n",
      "Training Loss: 0.0008144376610289328\n",
      "Validation Loss: 0.0021466513313185198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00824819716392085\n",
      "Training Loss: 0.008060446896124632\n",
      "Training Loss: 0.00779411300085485\n",
      "Training Loss: 0.004782451183382363\n",
      "Training Loss: 0.000884350245250971\n",
      "Training Loss: 0.0007029660972330021\n",
      "Training Loss: 0.000810733882135537\n",
      "Validation Loss: 0.0021387555698379316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00822794137406163\n",
      "Training Loss: 0.008044197343988344\n",
      "Training Loss: 0.007777357271406799\n",
      "Training Loss: 0.004772433851794631\n",
      "Training Loss: 0.000878445140660915\n",
      "Training Loss: 0.0006993808973493287\n",
      "Training Loss: 0.0008067967006536492\n",
      "Validation Loss: 0.0021311866467441905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.008207665666704998\n",
      "Training Loss: 0.008028265916509554\n",
      "Training Loss: 0.007760984790511429\n",
      "Training Loss: 0.004762233429210028\n",
      "Training Loss: 0.0008724236341731739\n",
      "Training Loss: 0.0006956998485111399\n",
      "Training Loss: 0.0008026112267361896\n",
      "Validation Loss: 0.0021238697846228264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.008187415243592113\n",
      "Training Loss: 0.008012657957151533\n",
      "Training Loss: 0.007744976331014186\n",
      "Training Loss: 0.004751851109613198\n",
      "Training Loss: 0.0008662882235148572\n",
      "Training Loss: 0.0006919155810464872\n",
      "Training Loss: 0.000798165421365411\n",
      "Validation Loss: 0.0021167552765294882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0081672362878453\n",
      "Training Loss: 0.007997381575405598\n",
      "Training Loss: 0.007729322614613921\n",
      "Training Loss: 0.004741295242929482\n",
      "Training Loss: 0.0008600441689850414\n",
      "Training Loss: 0.0006880230264869169\n",
      "Training Loss: 0.0007934526731332881\n",
      "Validation Loss: 0.002109805112425587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.008147178454091773\n",
      "Training Loss: 0.007982452458236367\n",
      "Training Loss: 0.0077140221919398755\n",
      "Training Loss: 0.004730575565045001\n",
      "Training Loss: 0.0008536948676919565\n",
      "Training Loss: 0.000684019317086495\n",
      "Training Loss: 0.0007884687453770311\n",
      "Validation Loss: 0.0021029978986521693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.008127286902163178\n",
      "Training Loss: 0.007967887303093448\n",
      "Training Loss: 0.007699080243473873\n",
      "Training Loss: 0.00471970633156161\n",
      "Training Loss: 0.0008472382400577772\n",
      "Training Loss: 0.0006798995809731423\n",
      "Training Loss: 0.0007832090691226768\n",
      "Validation Loss: 0.002096320657789435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00810760970809497\n",
      "Training Loss: 0.00795370116014965\n",
      "Training Loss: 0.007684496758738533\n",
      "Training Loss: 0.004708701494637353\n",
      "Training Loss: 0.0008406819716401515\n",
      "Training Loss: 0.0006756682881677989\n",
      "Training Loss: 0.0007776811361327418\n",
      "Validation Loss: 0.0020897750489192245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.008088176908204332\n",
      "Training Loss: 0.007939898625481874\n",
      "Training Loss: 0.007670262848259881\n",
      "Training Loss: 0.004697576593025587\n",
      "Training Loss: 0.0008340354369647684\n",
      "Training Loss: 0.0006713313183900027\n",
      "Training Loss: 0.0007718911796473549\n",
      "Validation Loss: 0.002083365822151828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.008069020494585856\n",
      "Training Loss: 0.007926484203198924\n",
      "Training Loss: 0.0076563750207424165\n",
      "Training Loss: 0.004686346230337222\n",
      "Training Loss: 0.0008273038224797346\n",
      "Training Loss: 0.0006668973289924906\n",
      "Training Loss: 0.0007658541728233104\n",
      "Validation Loss: 0.002077107044502139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.008050160804996266\n",
      "Training Loss: 0.007913450879277662\n",
      "Training Loss: 0.007642812863923609\n",
      "Training Loss: 0.004675022821247694\n",
      "Training Loss: 0.0008205029378586914\n",
      "Training Loss: 0.000662380015146482\n",
      "Training Loss: 0.0007595919730010791\n",
      "Validation Loss: 0.0020710191387384048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.008031607884913684\n",
      "Training Loss: 0.007900780866621063\n",
      "Training Loss: 0.007629547009710223\n",
      "Training Loss: 0.004663628614725895\n",
      "Training Loss: 0.0008136581801227294\n",
      "Training Loss: 0.0006578001500383835\n",
      "Training Loss: 0.0007531292387284339\n",
      "Validation Loss: 0.002065119687934347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.008013368259416892\n",
      "Training Loss: 0.007888456078944728\n",
      "Training Loss: 0.007616548038786277\n",
      "Training Loss: 0.004652166710729944\n",
      "Training Loss: 0.000806789945854689\n",
      "Training Loss: 0.0006531826617174374\n",
      "Training Loss: 0.0007465031941683264\n",
      "Validation Loss: 0.002059441481015823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007995434030890465\n",
      "Training Loss: 0.007876442604465411\n",
      "Training Loss: 0.007603773885639384\n",
      "Training Loss: 0.004640658713542507\n",
      "Training Loss: 0.0007999329105587094\n",
      "Training Loss: 0.0006485527036420535\n",
      "Training Loss: 0.0007397471459989902\n",
      "Validation Loss: 0.0020540018989920377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007977795650949701\n",
      "Training Loss: 0.007864706713007763\n",
      "Training Loss: 0.007591180778108537\n",
      "Training Loss: 0.004629114252966246\n",
      "Training Loss: 0.0007931175240082667\n",
      "Training Loss: 0.0006439396089263028\n",
      "Training Loss: 0.0007329033342830372\n",
      "Validation Loss: 0.0020488385207942787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007960438018199057\n",
      "Training Loss: 0.00785320669761859\n",
      "Training Loss: 0.007578720838064328\n",
      "Training Loss: 0.004617547640154953\n",
      "Training Loss: 0.0007863813568110344\n",
      "Training Loss: 0.0006393746917092357\n",
      "Training Loss: 0.0007260144029351068\n",
      "Validation Loss: 0.0020439670625727446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007943340328056365\n",
      "Training Loss: 0.007841898857150227\n",
      "Training Loss: 0.007566342941718176\n",
      "Training Loss: 0.00460597109500668\n",
      "Training Loss: 0.000779763409991574\n",
      "Training Loss: 0.0006348888750653714\n",
      "Training Loss: 0.0007191225924179889\n",
      "Validation Loss: 0.0020394173298654153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00792648184695281\n",
      "Training Loss: 0.007830734412418678\n",
      "Training Loss: 0.007553994923364371\n",
      "Training Loss: 0.004594393222359941\n",
      "Training Loss: 0.0007733001922315452\n",
      "Training Loss: 0.0006305122028788901\n",
      "Training Loss: 0.0007122714795332286\n",
      "Validation Loss: 0.00203520074224689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007909830824937672\n",
      "Training Loss: 0.007819665365386754\n",
      "Training Loss: 0.0075416261982172725\n",
      "Training Loss: 0.0045828264046576805\n",
      "Training Loss: 0.0007670263589898241\n",
      "Training Loss: 0.0006262691534720943\n",
      "Training Loss: 0.0007054952763064648\n",
      "Validation Loss: 0.0020313311833888292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007893365293275565\n",
      "Training Loss: 0.007808644071919843\n",
      "Training Loss: 0.007529188741464168\n",
      "Training Loss: 0.004571275049092946\n",
      "Training Loss: 0.0007609719801985193\n",
      "Training Loss: 0.0006221824692693189\n",
      "Training Loss: 0.0006988294183611288\n",
      "Validation Loss: 0.0020278162708645946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00787705800263211\n",
      "Training Loss: 0.0077976237086113545\n",
      "Training Loss: 0.007516635656356812\n",
      "Training Loss: 0.004559743012068793\n",
      "Training Loss: 0.0007551646178399097\n",
      "Training Loss: 0.0006182694018934854\n",
      "Training Loss: 0.0006922983814729378\n",
      "Validation Loss: 0.0020246535076581863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00786087812972255\n",
      "Training Loss: 0.007786557637155056\n",
      "Training Loss: 0.007503925117198378\n",
      "Training Loss: 0.004548237604394672\n",
      "Training Loss: 0.0007496231270124554\n",
      "Training Loss: 0.0006145416761137312\n",
      "Training Loss: 0.0006859233074283111\n",
      "Validation Loss: 0.0020218428457264826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00784480170928873\n",
      "Training Loss: 0.007775403602281585\n",
      "Training Loss: 0.007491016840795055\n",
      "Training Loss: 0.004536752711937879\n",
      "Training Loss: 0.0007443617579338024\n",
      "Training Loss: 0.0006110072885712726\n",
      "Training Loss: 0.0006797169791389024\n",
      "Validation Loss: 0.0020193744288174932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007828800480347127\n",
      "Training Loss: 0.007764121352229267\n",
      "Training Loss: 0.007477877659257501\n",
      "Training Loss: 0.00452528792717203\n",
      "Training Loss: 0.0007393871353269788\n",
      "Training Loss: 0.0006076650796603644\n",
      "Training Loss: 0.0006736820273727062\n",
      "Validation Loss: 0.0020172436813076554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007812852676725015\n",
      "Training Loss: 0.0077526758378371596\n",
      "Training Loss: 0.007464477093890309\n",
      "Training Loss: 0.0045138367277832\n",
      "Training Loss: 0.0007347028534422862\n",
      "Training Loss: 0.000604514094775368\n",
      "Training Loss: 0.0006678191789615084\n",
      "Validation Loss: 0.0020154261400649317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0077969329408369955\n",
      "Training Loss: 0.007741035539656878\n",
      "Training Loss: 0.007450789789436385\n",
      "Training Loss: 0.004502393496513832\n",
      "Training Loss: 0.0007303001257241704\n",
      "Training Loss: 0.0006015436133748153\n",
      "Training Loss: 0.0006621171621372924\n",
      "Validation Loss: 0.0020139236621753128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0077810255088843405\n",
      "Training Loss: 0.0077291739196516576\n",
      "Training Loss: 0.007436799093848094\n",
      "Training Loss: 0.0044909447028476275\n",
      "Training Loss: 0.0007261689405640936\n",
      "Training Loss: 0.0005987415970594157\n",
      "Training Loss: 0.0006565610037796432\n",
      "Validation Loss: 0.002012718453208047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0077651127590797845\n",
      "Training Loss: 0.00771706729196012\n",
      "Training Loss: 0.007422483151312918\n",
      "Training Loss: 0.004479483130271546\n",
      "Training Loss: 0.0007222975325566949\n",
      "Training Loss: 0.0005960958127616322\n",
      "Training Loss: 0.0006511345725084539\n",
      "Validation Loss: 0.0020117947353444268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007749176168581471\n",
      "Training Loss: 0.007704695045249537\n",
      "Training Loss: 0.007407829610165209\n",
      "Training Loss: 0.004467995753875584\n",
      "Training Loss: 0.0007186677211211645\n",
      "Training Loss: 0.0005935896029041032\n",
      "Training Loss: 0.0006458146283694077\n",
      "Validation Loss: 0.0020111526855510005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007733205392723903\n",
      "Training Loss: 0.007692043066490442\n",
      "Training Loss: 0.007392827154835686\n",
      "Training Loss: 0.004456471012963448\n",
      "Training Loss: 0.0007152599929759162\n",
      "Training Loss: 0.0005912035152141471\n",
      "Training Loss: 0.0006405766552416025\n",
      "Validation Loss: 0.0020107685530855587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007717190540861338\n",
      "Training Loss: 0.007679097594227642\n",
      "Training Loss: 0.007377464590827003\n",
      "Training Loss: 0.0044448952895618276\n",
      "Training Loss: 0.0007120526793733006\n",
      "Training Loss: 0.0005889198537988705\n",
      "Training Loss: 0.0006353944690272328\n",
      "Validation Loss: 0.002010654412822149\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007701123264851049\n",
      "Training Loss: 0.007665847223834134\n",
      "Training Loss: 0.007361733872676269\n",
      "Training Loss: 0.004433259025900043\n",
      "Training Loss: 0.0007090247135056416\n",
      "Training Loss: 0.0005867205538379495\n",
      "Training Loss: 0.000630241608741926\n",
      "Validation Loss: 0.0020108056628674598\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 65\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007684995390009135\n",
      "Training Loss: 0.007652282314375043\n",
      "Training Loss: 0.007345625897869468\n",
      "Training Loss: 0.004421549231628887\n",
      "Training Loss: 0.0007061585733026732\n",
      "Training Loss: 0.0005845897071776562\n",
      "Training Loss: 0.0006250927632936509\n",
      "Validation Loss: 0.0020112049959801408\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 66\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007668801294639707\n",
      "Training Loss: 0.007638396064867266\n",
      "Training Loss: 0.007329131047008559\n",
      "Training Loss: 0.00440975383593468\n",
      "Training Loss: 0.0007034293843753404\n",
      "Training Loss: 0.0005825072427978739\n",
      "Training Loss: 0.0006199199924230925\n",
      "Validation Loss: 0.0020118461111263974\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 67\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0076525364653207365\n",
      "Training Loss: 0.007624180798302405\n",
      "Training Loss: 0.007312240399187431\n",
      "Training Loss: 0.0043978647913172604\n",
      "Training Loss: 0.000700819510166184\n",
      "Training Loss: 0.0005804588871251326\n",
      "Training Loss: 0.0006146983489452396\n",
      "Validation Loss: 0.002012745637166722\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 68\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007636200572596863\n",
      "Training Loss: 0.007609631313243881\n",
      "Training Loss: 0.007294947424670681\n",
      "Training Loss: 0.004385870114710997\n",
      "Training Loss: 0.0006983074908202979\n",
      "Training Loss: 0.0005784259391293745\n",
      "Training Loss: 0.0006094030251551885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [12:02<07:51, 117.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0020138736556359125\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 69\n",
      "Early stopping after 69 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.11472930856049061\n",
      "Training Loss: 0.0955673299357295\n",
      "Training Loss: 0.08684668812900781\n",
      "Training Loss: 0.07109529384644703\n",
      "Training Loss: 0.05581011473201215\n",
      "Training Loss: 0.05384132738225162\n",
      "Training Loss: 0.05400000149384141\n",
      "Validation Loss: 0.059838249023710745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.07223746359348297\n",
      "Training Loss: 0.06985520707443356\n",
      "Training Loss: 0.06838515544310213\n",
      "Training Loss: 0.0576778111961903\n",
      "Training Loss: 0.04375949839130044\n",
      "Training Loss: 0.04123261542990804\n",
      "Training Loss: 0.04123219047673046\n",
      "Validation Loss: 0.046410149109832356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05734261527657509\n",
      "Training Loss: 0.05463496496900916\n",
      "Training Loss: 0.05261893917806446\n",
      "Training Loss: 0.041303792716935274\n",
      "Training Loss: 0.02747229063883424\n",
      "Training Loss: 0.0252435197820887\n",
      "Training Loss: 0.02507824375294149\n",
      "Validation Loss: 0.030723500975899484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.041103217657655476\n",
      "Training Loss: 0.038874036399647593\n",
      "Training Loss: 0.03754078323021531\n",
      "Training Loss: 0.027065568843390793\n",
      "Training Loss: 0.015115831284783781\n",
      "Training Loss: 0.014024947651196272\n",
      "Training Loss: 0.01416690175421536\n",
      "Validation Loss: 0.02025660178676415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.030425456804223358\n",
      "Training Loss: 0.028859129599295555\n",
      "Training Loss: 0.028422221597284077\n",
      "Training Loss: 0.019150323315989225\n",
      "Training Loss: 0.008965362766757608\n",
      "Training Loss: 0.008457871516002342\n",
      "Training Loss: 0.00873083389014937\n",
      "Validation Loss: 0.014554598813437009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.024383164816536008\n",
      "Training Loss: 0.023210769067518414\n",
      "Training Loss: 0.023221697765402494\n",
      "Training Loss: 0.014901236514560878\n",
      "Training Loss: 0.0059266662574373186\n",
      "Training Loss: 0.005641970998840407\n",
      "Training Loss: 0.00582811345695518\n",
      "Validation Loss: 0.01097207122886979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.020472786175087094\n",
      "Training Loss: 0.019513058825396\n",
      "Training Loss: 0.01970492782071233\n",
      "Training Loss: 0.012114782451535576\n",
      "Training Loss: 0.003868051139288582\n",
      "Training Loss: 0.0037700906238751484\n",
      "Training Loss: 0.0037927814945578576\n",
      "Validation Loss: 0.008291097282875009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01757790890755132\n",
      "Training Loss: 0.01677859863964841\n",
      "Training Loss: 0.017055470552295445\n",
      "Training Loss: 0.010057970700545411\n",
      "Training Loss: 0.002305989721789956\n",
      "Training Loss: 0.0022593488718848677\n",
      "Training Loss: 0.0021569994700257667\n",
      "Validation Loss: 0.00616261276960624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.015282952033448965\n",
      "Training Loss: 0.014619185307528823\n",
      "Training Loss: 0.014879606168251484\n",
      "Training Loss: 0.008301988634502776\n",
      "Training Loss: 0.0010007429552206305\n",
      "Training Loss: 0.0008493742041900987\n",
      "Training Loss: 0.0007314274596865288\n",
      "Validation Loss: 0.004610953221351784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013644731086678803\n",
      "Training Loss: 0.013079902502940968\n",
      "Training Loss: 0.013249707065988332\n",
      "Training Loss: 0.007124939336208626\n",
      "Training Loss: 0.00046529400948202237\n",
      "Training Loss: 0.0003448660013236804\n",
      "Training Loss: 0.0003184945796601824\n",
      "Validation Loss: 0.003926553003261501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0125057218875736\n",
      "Training Loss: 0.01201999197830446\n",
      "Training Loss: 0.012104780012741685\n",
      "Training Loss: 0.0064927306894242065\n",
      "Training Loss: 0.00036116054743615675\n",
      "Training Loss: 0.0002437863553132047\n",
      "Training Loss: 0.00022864556587592232\n",
      "Validation Loss: 0.00346900130801835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011623455523513258\n",
      "Training Loss: 0.01121919937315397\n",
      "Training Loss: 0.011250360929407179\n",
      "Training Loss: 0.006075801812985446\n",
      "Training Loss: 0.0003453595352402772\n",
      "Training Loss: 0.00022814723497504018\n",
      "Training Loss: 0.00021557614891207778\n",
      "Validation Loss: 0.0031359097798547204\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.010953372798394412\n",
      "Training Loss: 0.010610791830113158\n",
      "Training Loss: 0.010603873583022505\n",
      "Training Loss: 0.005779381039574218\n",
      "Training Loss: 0.0003524459148866299\n",
      "Training Loss: 0.00023613836730874028\n",
      "Training Loss: 0.00022628775237535593\n",
      "Validation Loss: 0.002889938485549897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010449080364778637\n",
      "Training Loss: 0.010150600454071537\n",
      "Training Loss: 0.010114821812603623\n",
      "Training Loss: 0.005564028773878817\n",
      "Training Loss: 0.00036494574005700996\n",
      "Training Loss: 0.00025017084168212024\n",
      "Training Loss: 0.00024372087247684249\n",
      "Validation Loss: 0.0027055783750583534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010071891789557412\n",
      "Training Loss: 0.009804121986962854\n",
      "Training Loss: 0.009745303269010037\n",
      "Training Loss: 0.00540578894338978\n",
      "Training Loss: 0.000377235146224848\n",
      "Training Loss: 0.00026454482485860353\n",
      "Training Loss: 0.0002619237887483905\n",
      "Validation Loss: 0.0025651420378091324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009789331394713371\n",
      "Training Loss: 0.009542641149600968\n",
      "Training Loss: 0.009464669524459169\n",
      "Training Loss: 0.005287710402408266\n",
      "Training Loss: 0.0003879279321699869\n",
      "Training Loss: 0.0002777798037277535\n",
      "Training Loss: 0.00027920480346438125\n",
      "Validation Loss: 0.0024565183876131573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009574562014313415\n",
      "Training Loss: 0.009342441943008453\n",
      "Training Loss: 0.009248155642999335\n",
      "Training Loss: 0.005197335776174441\n",
      "Training Loss: 0.0003972409915877506\n",
      "Training Loss: 0.00028993292075028875\n",
      "Training Loss: 0.00029549938526542976\n",
      "Validation Loss: 0.0023713518482206077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009406525288941339\n",
      "Training Loss: 0.0091848925082013\n",
      "Training Loss: 0.00907662664190866\n",
      "Training Loss: 0.005125745660152461\n",
      "Training Loss: 0.00040584727630630366\n",
      "Training Loss: 0.0003014963996429287\n",
      "Training Loss: 0.0003112317228442407\n",
      "Validation Loss: 0.0023037662451335992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009269803622737527\n",
      "Training Loss: 0.009056295697810128\n",
      "Training Loss: 0.008936136777047068\n",
      "Training Loss: 0.005066868548528874\n",
      "Training Loss: 0.00041438263087911764\n",
      "Training Loss: 0.000312952627427876\n",
      "Training Loss: 0.0003268322827534576\n",
      "Validation Loss: 0.002249586288469507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009153950239997356\n",
      "Training Loss: 0.00894728086073883\n",
      "Training Loss: 0.008817110126838088\n",
      "Training Loss: 0.0050168055813992396\n",
      "Training Loss: 0.0004232728584247525\n",
      "Training Loss: 0.00032462230446981264\n",
      "Training Loss: 0.00034257336441442023\n",
      "Validation Loss: 0.0022057852258056416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00905236484366469\n",
      "Training Loss: 0.008851837043184787\n",
      "Training Loss: 0.008713299036026\n",
      "Training Loss: 0.004973157808162796\n",
      "Training Loss: 0.0004327257093973458\n",
      "Training Loss: 0.0003366583815841295\n",
      "Training Loss: 0.00035855219502991533\n",
      "Validation Loss: 0.0021701166432707094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008961119035957381\n",
      "Training Loss: 0.008766300968127326\n",
      "Training Loss: 0.00862075261771679\n",
      "Training Loss: 0.004934472530985659\n",
      "Training Loss: 0.0004427856696565868\n",
      "Training Loss: 0.0003490736599633237\n",
      "Training Loss: 0.00037472048363270007\n",
      "Validation Loss: 0.002140853242724759\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008877956747310236\n",
      "Training Loss: 0.008688499260460957\n",
      "Training Loss: 0.008536996152251959\n",
      "Training Loss: 0.0048998500678135316\n",
      "Training Loss: 0.00045339110380155035\n",
      "Training Loss: 0.00036177664613205705\n",
      "Training Loss: 0.0003909311712777708\n",
      "Validation Loss: 0.0021166156463792427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008801587880589068\n",
      "Training Loss: 0.008617129222257063\n",
      "Training Loss: 0.008460444419179113\n",
      "Training Loss: 0.004868672006232373\n",
      "Training Loss: 0.0004644087473934633\n",
      "Training Loss: 0.0003746154025975557\n",
      "Training Loss: 0.000406987578026019\n",
      "Validation Loss: 0.0020962984406392346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008731227632379159\n",
      "Training Loss: 0.008551365727325901\n",
      "Training Loss: 0.008390027622226626\n",
      "Training Loss: 0.004840471421666734\n",
      "Training Loss: 0.00047567657431500264\n",
      "Training Loss: 0.0003874084362905705\n",
      "Training Loss: 0.0004226806199767452\n",
      "Validation Loss: 0.0020790126967740468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008666328847175464\n",
      "Training Loss: 0.008490621120436116\n",
      "Training Loss: 0.008324970119865611\n",
      "Training Loss: 0.004814853743664571\n",
      "Training Loss: 0.0004870181142177898\n",
      "Training Loss: 0.0003999722813023254\n",
      "Training Loss: 0.0004378167835238855\n",
      "Validation Loss: 0.002064047440143532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008606455808039754\n",
      "Training Loss: 0.008434428465552628\n",
      "Training Loss: 0.008264659750275315\n",
      "Training Loss: 0.004791471597163763\n",
      "Training Loss: 0.0004982686558287242\n",
      "Training Loss: 0.00041214746433979597\n",
      "Training Loss: 0.0004522426356561482\n",
      "Validation Loss: 0.0020508520796052214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008551199390785769\n",
      "Training Loss: 0.008382377011002973\n",
      "Training Loss: 0.00820858459570445\n",
      "Training Loss: 0.004770014829045976\n",
      "Training Loss: 0.0005092852280722582\n",
      "Training Loss: 0.0004238058952614665\n",
      "Training Loss: 0.0004658474600000773\n",
      "Validation Loss: 0.002039010003282146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008500169402686879\n",
      "Training Loss: 0.008334087954135611\n",
      "Training Loss: 0.008156303571304306\n",
      "Training Loss: 0.004750207055039936\n",
      "Training Loss: 0.000519954909432272\n",
      "Training Loss: 0.00043485783917276424\n",
      "Training Loss: 0.00047856533139565725\n",
      "Validation Loss: 0.002028208760625756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008452981977025048\n",
      "Training Loss: 0.008289213902316987\n",
      "Training Loss: 0.008107434017583728\n",
      "Training Loss: 0.0047318126626487355\n",
      "Training Loss: 0.00053019116865471\n",
      "Training Loss: 0.00044524394877953454\n",
      "Training Loss: 0.0004903619213291677\n",
      "Validation Loss: 0.0020182102304174346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008409277355531231\n",
      "Training Loss: 0.008247435205848887\n",
      "Training Loss: 0.008061636574566364\n",
      "Training Loss: 0.00471462873108976\n",
      "Training Loss: 0.0005399348671926419\n",
      "Training Loss: 0.0004549365892671631\n",
      "Training Loss: 0.0005012379641630105\n",
      "Validation Loss: 0.002008852357215297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00836871002218686\n",
      "Training Loss: 0.008208455492276698\n",
      "Training Loss: 0.008018612227169796\n",
      "Training Loss: 0.004698482413077727\n",
      "Training Loss: 0.0005491510167485103\n",
      "Training Loss: 0.00046393093522056005\n",
      "Training Loss: 0.0005112130906491075\n",
      "Validation Loss: 0.002000007135941811\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.008330964266788215\n",
      "Training Loss: 0.008172012544237077\n",
      "Training Loss: 0.007978104711510241\n",
      "Training Loss: 0.004683238074576366\n",
      "Training Loss: 0.0005578211235842901\n",
      "Training Loss: 0.0004722373317417805\n",
      "Training Loss: 0.0005203224151409813\n",
      "Validation Loss: 0.001991586008982049\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.008295751824043691\n",
      "Training Loss: 0.008137869498459622\n",
      "Training Loss: 0.00793988807592541\n",
      "Training Loss: 0.0046687751187710095\n",
      "Training Loss: 0.0005659395213297103\n",
      "Training Loss: 0.000479877315046906\n",
      "Training Loss: 0.0005286072849776247\n",
      "Validation Loss: 0.001983518470617182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.008262816759524868\n",
      "Training Loss: 0.008105818304466083\n",
      "Training Loss: 0.007903768037213012\n",
      "Training Loss: 0.004655000748243765\n",
      "Training Loss: 0.0005735135210852604\n",
      "Training Loss: 0.00048688070426578634\n",
      "Training Loss: 0.0005361167797309463\n",
      "Validation Loss: 0.0019757574666570523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.008231930579058825\n",
      "Training Loss: 0.008075674903811886\n",
      "Training Loss: 0.007869573731441051\n",
      "Training Loss: 0.004641835379370605\n",
      "Training Loss: 0.0005805522244918393\n",
      "Training Loss: 0.0004932785949495155\n",
      "Training Loss: 0.0005428976369148586\n",
      "Validation Loss: 0.0019682600489496654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.008202889029635117\n",
      "Training Loss: 0.008047276593279093\n",
      "Training Loss: 0.007837157458998262\n",
      "Training Loss: 0.004629211096907965\n",
      "Training Loss: 0.0005870716465142322\n",
      "Training Loss: 0.0004991047405201243\n",
      "Training Loss: 0.0005489987906548777\n",
      "Validation Loss: 0.001960989463226765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00817551022511907\n",
      "Training Loss: 0.008020476787351072\n",
      "Training Loss: 0.007806383257266134\n",
      "Training Loss: 0.0046170710928709014\n",
      "Training Loss: 0.0005930925951543032\n",
      "Training Loss: 0.0005043944715362159\n",
      "Training Loss: 0.0005544657185964752\n",
      "Validation Loss: 0.0019539223560079764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.008149636698653921\n",
      "Training Loss: 0.007995148975169286\n",
      "Training Loss: 0.007777137537486851\n",
      "Training Loss: 0.004605363952287007\n",
      "Training Loss: 0.0005986302990640979\n",
      "Training Loss: 0.0005091786349294125\n",
      "Training Loss: 0.000559342583437683\n",
      "Validation Loss: 0.0019470367300296236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.008125119094038381\n",
      "Training Loss: 0.007971171924145893\n",
      "Training Loss: 0.007749305496690795\n",
      "Training Loss: 0.0045940446359600175\n",
      "Training Loss: 0.0006037097248190548\n",
      "Training Loss: 0.0005134913053552737\n",
      "Training Loss: 0.0005636710680846591\n",
      "Validation Loss: 0.0019403080048178208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.008101828531362116\n",
      "Training Loss: 0.007948438207386062\n",
      "Training Loss: 0.007722789775580168\n",
      "Training Loss: 0.00458307542030525\n",
      "Training Loss: 0.0006083506302093155\n",
      "Training Loss: 0.0005173623182054143\n",
      "Training Loss: 0.0005674903686667676\n",
      "Validation Loss: 0.0019337198342661433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.008079644396202639\n",
      "Training Loss: 0.00792684749700129\n",
      "Training Loss: 0.007697492997394874\n",
      "Training Loss: 0.004572415080401697\n",
      "Training Loss: 0.0006125768837955547\n",
      "Training Loss: 0.0005208203366419184\n",
      "Training Loss: 0.0005708354536182014\n",
      "Validation Loss: 0.0019272586671079156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.008058462772751226\n",
      "Training Loss: 0.007906308044912293\n",
      "Training Loss: 0.007673326497897506\n",
      "Training Loss: 0.004562031001551076\n",
      "Training Loss: 0.0006164104916388169\n",
      "Training Loss: 0.0005238962056318997\n",
      "Training Loss: 0.0005737432790920139\n",
      "Validation Loss: 0.0019209064940127548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.008038178227143361\n",
      "Training Loss: 0.007886728906305507\n",
      "Training Loss: 0.007650201014475897\n",
      "Training Loss: 0.0045518926746444775\n",
      "Training Loss: 0.0006198752944328589\n",
      "Training Loss: 0.0005266146827489137\n",
      "Training Loss: 0.0005762436362419976\n",
      "Validation Loss: 0.001914654007314073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00801870457478799\n",
      "Training Loss: 0.007868029699893668\n",
      "Training Loss: 0.007628034396329895\n",
      "Training Loss: 0.004541967386612669\n",
      "Training Loss: 0.000622994799123262\n",
      "Training Loss: 0.0005290053003773209\n",
      "Training Loss: 0.0005783700355459587\n",
      "Validation Loss: 0.0019084882074644378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007999954435508699\n",
      "Training Loss: 0.00785012892447412\n",
      "Training Loss: 0.007606745735974982\n",
      "Training Loss: 0.004532229949327302\n",
      "Training Loss: 0.0006257941642252262\n",
      "Training Loss: 0.000531089871074073\n",
      "Training Loss: 0.0005801487701319275\n",
      "Validation Loss: 0.0019024048003408193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00798185813240707\n",
      "Training Loss: 0.007832955708727241\n",
      "Training Loss: 0.007586259879171848\n",
      "Training Loss: 0.004522655714390566\n",
      "Training Loss: 0.0006282943124824669\n",
      "Training Loss: 0.0005328946747613372\n",
      "Training Loss: 0.00058160952416074\n",
      "Validation Loss: 0.0018963903093436726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00796433798968792\n",
      "Training Loss: 0.007816436473513022\n",
      "Training Loss: 0.007566497337538749\n",
      "Training Loss: 0.004513222665700596\n",
      "Training Loss: 0.0006305239283392438\n",
      "Training Loss: 0.0005344450744814821\n",
      "Training Loss: 0.0005827792812124244\n",
      "Validation Loss: 0.0018904459012422906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00794733350747265\n",
      "Training Loss: 0.007800507167121396\n",
      "Training Loss: 0.007547391313128173\n",
      "Training Loss: 0.004503909089544322\n",
      "Training Loss: 0.0006325038961222162\n",
      "Training Loss: 0.000535761497922067\n",
      "Training Loss: 0.0005836806160004926\n",
      "Validation Loss: 0.0018845606105962825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007930784188210964\n",
      "Training Loss: 0.0077851036400534215\n",
      "Training Loss: 0.007528874020790681\n",
      "Training Loss: 0.0044946968824660875\n",
      "Training Loss: 0.0006342599355411948\n",
      "Training Loss: 0.0005368668340452132\n",
      "Training Loss: 0.0005843378214922268\n",
      "Validation Loss: 0.0018787357882811943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007914639870868996\n",
      "Training Loss: 0.007770170950097963\n",
      "Training Loss: 0.0075108853727579115\n",
      "Training Loss: 0.004485569864045829\n",
      "Training Loss: 0.0006358087958506076\n",
      "Training Loss: 0.0005377769617916783\n",
      "Training Loss: 0.0005847692166207708\n",
      "Validation Loss: 0.0018729653995033276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007898854382801801\n",
      "Training Loss: 0.007755654678912833\n",
      "Training Loss: 0.0074933618924114855\n",
      "Training Loss: 0.004476513437693939\n",
      "Training Loss: 0.0006371791382116499\n",
      "Training Loss: 0.0005385177235439186\n",
      "Training Loss: 0.0005850000923965127\n",
      "Validation Loss: 0.0018672464599755283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00788337723002769\n",
      "Training Loss: 0.007741502717835829\n",
      "Training Loss: 0.0074762498890049755\n",
      "Training Loss: 0.004467513306153705\n",
      "Training Loss: 0.0006383864701638231\n",
      "Training Loss: 0.000539102330658352\n",
      "Training Loss: 0.0005850456011830829\n",
      "Validation Loss: 0.0018615810173212234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007868172305170446\n",
      "Training Loss: 0.007727669196901843\n",
      "Training Loss: 0.00745949522126466\n",
      "Training Loss: 0.004458561456995085\n",
      "Training Loss: 0.0006394536091102054\n",
      "Training Loss: 0.0005395483644315391\n",
      "Training Loss: 0.0005849229980594828\n",
      "Validation Loss: 0.0018559581479572164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00785320603987202\n",
      "Training Loss: 0.007714110411470756\n",
      "Training Loss: 0.007443045626860112\n",
      "Training Loss: 0.004449640937382355\n",
      "Training Loss: 0.0006403994813445024\n",
      "Training Loss: 0.000539872261833807\n",
      "Training Loss: 0.0005846491306874668\n",
      "Validation Loss: 0.001850384492298487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00783844107412733\n",
      "Training Loss: 0.0077007865358609704\n",
      "Training Loss: 0.007426861613057553\n",
      "Training Loss: 0.004440744574312702\n",
      "Training Loss: 0.0006412397565145511\n",
      "Training Loss: 0.0005400862364695058\n",
      "Training Loss: 0.0005842356629727874\n",
      "Validation Loss: 0.0018448512710710248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00782385257538408\n",
      "Training Loss: 0.007687660289229825\n",
      "Training Loss: 0.007410896308720112\n",
      "Training Loss: 0.004431864297221182\n",
      "Training Loss: 0.0006419890140386997\n",
      "Training Loss: 0.0005402044480433688\n",
      "Training Loss: 0.0005836984790948918\n",
      "Validation Loss: 0.0018393668741352284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0078094074386172\n",
      "Training Loss: 0.00767469335347414\n",
      "Training Loss: 0.007395106347976252\n",
      "Training Loss: 0.004422987873113016\n",
      "Training Loss: 0.0006426682700111996\n",
      "Training Loss: 0.0005402372810567612\n",
      "Training Loss: 0.0005830450259600183\n",
      "Validation Loss: 0.0018339174723209924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007795085266698152\n",
      "Training Loss: 0.007661856494378299\n",
      "Training Loss: 0.0073794555582571775\n",
      "Training Loss: 0.0044141093549114885\n",
      "Training Loss: 0.0006432857942854752\n",
      "Training Loss: 0.0005401954297121847\n",
      "Training Loss: 0.0005822862508648541\n",
      "Validation Loss: 0.0018285054457657325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0077808623050805185\n",
      "Training Loss: 0.0076491177047137175\n",
      "Training Loss: 0.007363905332749709\n",
      "Training Loss: 0.004405215539954952\n",
      "Training Loss: 0.0006438569154124707\n",
      "Training Loss: 0.0005400887063296977\n",
      "Training Loss: 0.0005814328276028391\n",
      "Validation Loss: 0.0018231341391753873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007766708752606064\n",
      "Training Loss: 0.007636442228686064\n",
      "Training Loss: 0.007348420063499362\n",
      "Training Loss: 0.004396300607768353\n",
      "Training Loss: 0.0006443959287571487\n",
      "Training Loss: 0.0005399262006540084\n",
      "Training Loss: 0.0005804913054817007\n",
      "Validation Loss: 0.0018177954894263815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007752605772111565\n",
      "Training Loss: 0.0076238057774025945\n",
      "Training Loss: 0.0073329622438177465\n",
      "Training Loss: 0.004387348790114629\n",
      "Training Loss: 0.000644914158328902\n",
      "Training Loss: 0.0005397165999966091\n",
      "Training Loss: 0.0005794690452603391\n",
      "Validation Loss: 0.0018124866303909318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0077385325753130015\n",
      "Training Loss: 0.007611176694044843\n",
      "Training Loss: 0.007317502471851185\n",
      "Training Loss: 0.004378357143577887\n",
      "Training Loss: 0.0006454183477035258\n",
      "Training Loss: 0.0005394623785105068\n",
      "Training Loss: 0.0005783676971623208\n",
      "Validation Loss: 0.0018072112144362565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007724470264511183\n",
      "Training Loss: 0.007598527097143233\n",
      "Training Loss: 0.007302002309588715\n",
      "Training Loss: 0.0043693083057587505\n",
      "Training Loss: 0.0006459222430567024\n",
      "Training Loss: 0.0005391711878110073\n",
      "Training Loss: 0.0005771930854825769\n",
      "Validation Loss: 0.0018019608644553205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007710395719623193\n",
      "Training Loss: 0.007585832489421591\n",
      "Training Loss: 0.007286431539105251\n",
      "Training Loss: 0.004360194180626422\n",
      "Training Loss: 0.0006464313917240361\n",
      "Training Loss: 0.0005388461606344209\n",
      "Training Loss: 0.0005759456751184189\n",
      "Validation Loss: 0.0017967289517509788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007696291790343821\n",
      "Training Loss: 0.007573065700707957\n",
      "Training Loss: 0.007270754824858159\n",
      "Training Loss: 0.004350998554073158\n",
      "Training Loss: 0.0006469575588562293\n",
      "Training Loss: 0.0005384933244204148\n",
      "Training Loss: 0.0005746304833155591\n",
      "Validation Loss: 0.0017915223325643695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007682133569614962\n",
      "Training Loss: 0.0075601938215550035\n",
      "Training Loss: 0.007254937888355926\n",
      "Training Loss: 0.004341709640721092\n",
      "Training Loss: 0.0006475082323595415\n",
      "Training Loss: 0.0005381132379625342\n",
      "Training Loss: 0.0005732432743025129\n",
      "Validation Loss: 0.001786329636835556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0076679035974666476\n",
      "Training Loss: 0.00754719217075035\n",
      "Training Loss: 0.007238943575648591\n",
      "Training Loss: 0.004332307604199741\n",
      "Training Loss: 0.0006480915987776825\n",
      "Training Loss: 0.0005377115954979672\n",
      "Training Loss: 0.0005717878288123756\n",
      "Validation Loss: 0.0017811511883037757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0076535748015157876\n",
      "Training Loss: 0.007534024985507131\n",
      "Training Loss: 0.007222732530208304\n",
      "Training Loss: 0.004322778840360115\n",
      "Training Loss: 0.0006487173923233058\n",
      "Training Loss: 0.000537286007493094\n",
      "Training Loss: 0.000570257820218103\n",
      "Validation Loss: 0.0017759805245016272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007639127637958154\n",
      "Training Loss: 0.007520665015326813\n",
      "Training Loss: 0.007206269402522594\n",
      "Training Loss: 0.004313100543513428\n",
      "Training Loss: 0.0006493879974004813\n",
      "Training Loss: 0.0005368364386595203\n",
      "Training Loss: 0.0005686482220335165\n",
      "Validation Loss: 0.0017708126833895221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007624543817946687\n",
      "Training Loss: 0.007507082360098139\n",
      "Training Loss: 0.007189513630000874\n",
      "Training Loss: 0.004303253745456459\n",
      "Training Loss: 0.0006501166084490251\n",
      "Training Loss: 0.0005363689630758017\n",
      "Training Loss: 0.0005669619403852267\n",
      "Validation Loss: 0.0017656475656111254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0076097849244251845\n",
      "Training Loss: 0.00749323089257814\n",
      "Training Loss: 0.007172416066750884\n",
      "Training Loss: 0.004293213690616539\n",
      "Training Loss: 0.0006509094915236346\n",
      "Training Loss: 0.0005358765197888715\n",
      "Training Loss: 0.0005651849896094063\n",
      "Validation Loss: 0.0017604780557159028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.0075948356802109625\n",
      "Training Loss: 0.007479080087505281\n",
      "Training Loss: 0.0071549343585502355\n",
      "Training Loss: 0.004282953160800389\n",
      "Training Loss: 0.0006517749021440977\n",
      "Training Loss: 0.0005353622326947515\n",
      "Training Loss: 0.000563314522660221\n",
      "Validation Loss: 0.001755303169405768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0075796610384713855\n",
      "Training Loss: 0.007464585934067145\n",
      "Training Loss: 0.007137019218644128\n",
      "Training Loss: 0.004272447013572673\n",
      "Training Loss: 0.0006527195790113182\n",
      "Training Loss: 0.0005348188572679647\n",
      "Training Loss: 0.0005613370622086222\n",
      "Validation Loss: 0.0017501171322954533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007564236882608384\n",
      "Training Loss: 0.0074497039837297056\n",
      "Training Loss: 0.007118616953957826\n",
      "Training Loss: 0.004261663414654322\n",
      "Training Loss: 0.0006537550530629232\n",
      "Training Loss: 0.0005342461971304147\n",
      "Training Loss: 0.000559243484694889\n",
      "Validation Loss: 0.0017449132307743905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007548531781649217\n",
      "Training Loss: 0.007434391295537353\n",
      "Training Loss: 0.007099671167088673\n",
      "Training Loss: 0.0042505667130899386\n",
      "Training Loss: 0.0006548881594790146\n",
      "Training Loss: 0.0005336378634092398\n",
      "Training Loss: 0.0005570204446121352\n",
      "Validation Loss: 0.0017396916027860158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007532512000761926\n",
      "Training Loss: 0.0074185944371856745\n",
      "Training Loss: 0.007080124118365347\n",
      "Training Loss: 0.004239124396845\n",
      "Training Loss: 0.0006561297530424781\n",
      "Training Loss: 0.0005329908043131582\n",
      "Training Loss: 0.000554655394225847\n",
      "Validation Loss: 0.0017344514641619536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007516141451196745\n",
      "Training Loss: 0.007402257649227977\n",
      "Training Loss: 0.007059914777055382\n",
      "Training Loss: 0.004227296167664462\n",
      "Training Loss: 0.0006574898032704369\n",
      "Training Loss: 0.0005322979813354322\n",
      "Training Loss: 0.0005521288001727954\n",
      "Validation Loss: 0.0017291839991121515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007499392980244011\n",
      "Training Loss: 0.007385326204821467\n",
      "Training Loss: 0.007038980005308986\n",
      "Training Loss: 0.0042150458092510236\n",
      "Training Loss: 0.0006589798442291795\n",
      "Training Loss: 0.0005315557186622755\n",
      "Training Loss: 0.0005494314717361704\n",
      "Validation Loss: 0.0017238988195853796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007482216517673806\n",
      "Training Loss: 0.007367734314175323\n",
      "Training Loss: 0.007017249851487577\n",
      "Training Loss: 0.0042023319034342425\n",
      "Training Loss: 0.0006606125896360027\n",
      "Training Loss: 0.0005307563661699533\n",
      "Training Loss: 0.0005465401384390134\n",
      "Validation Loss: 0.0017185888380359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007464589135488495\n",
      "Training Loss: 0.007349426972214132\n",
      "Training Loss: 0.006994667849503458\n",
      "Training Loss: 0.004189115190602024\n",
      "Training Loss: 0.0006623999219300458\n",
      "Training Loss: 0.0005298939070416963\n",
      "Training Loss: 0.0005434395592237706\n",
      "Validation Loss: 0.0017132601929193692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0074464713595807554\n",
      "Training Loss: 0.007330342214554548\n",
      "Training Loss: 0.006971179193351417\n",
      "Training Loss: 0.004175361854286166\n",
      "Training Loss: 0.0006643492659350158\n",
      "Training Loss: 0.0005289616830850719\n",
      "Training Loss: 0.0005401117132714716\n",
      "Validation Loss: 0.0017079212379071526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007427833911497146\n",
      "Training Loss: 0.007310422930167988\n",
      "Training Loss: 0.0069467336277011784\n",
      "Training Loss: 0.004161041816769284\n",
      "Training Loss: 0.0006664769677445292\n",
      "Training Loss: 0.0005279595406682347\n",
      "Training Loss: 0.0005365467587398598\n",
      "Validation Loss: 0.001702579100113118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007408641240326688\n",
      "Training Loss: 0.0072896139952354135\n",
      "Training Loss: 0.0069212938752025365\n",
      "Training Loss: 0.004146137227653526\n",
      "Training Loss: 0.000668789472329081\n",
      "Training Loss: 0.0005268801147758495\n",
      "Training Loss: 0.0005327270437192055\n",
      "Validation Loss: 0.0016972360928557736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007388883309904486\n",
      "Training Loss: 0.007267883084714413\n",
      "Training Loss: 0.006894850350217894\n",
      "Training Loss: 0.0041306434138823536\n",
      "Training Loss: 0.0006712933771632379\n",
      "Training Loss: 0.0005257289213113836\n",
      "Training Loss: 0.0005286522120513837\n",
      "Validation Loss: 0.0016919127165680849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007368538806913421\n",
      "Training Loss: 0.00724520621355623\n",
      "Training Loss: 0.006867420694325119\n",
      "Training Loss: 0.004114571995160077\n",
      "Training Loss: 0.0006739863845723448\n",
      "Training Loss: 0.0005245064266637201\n",
      "Training Loss: 0.0005243203416466713\n",
      "Validation Loss: 0.001686625365372346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007347615818725899\n",
      "Training Loss: 0.007221595509909093\n",
      "Training Loss: 0.006839065180392936\n",
      "Training Loss: 0.004097959229111439\n",
      "Training Loss: 0.0006768579070921988\n",
      "Training Loss: 0.0005232203075138386\n",
      "Training Loss: 0.0005197375601710518\n",
      "Validation Loss: 0.0016813782389948932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0073261356423608955\n",
      "Training Loss: 0.007197093917056918\n",
      "Training Loss: 0.0068098863807972525\n",
      "Training Loss: 0.0040808771255251486\n",
      "Training Loss: 0.0006798917661944869\n",
      "Training Loss: 0.0005218830193553004\n",
      "Training Loss: 0.0005149238799640444\n",
      "Validation Loss: 0.0016761870529864084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00730413700453937\n",
      "Training Loss: 0.007171778273768723\n",
      "Training Loss: 0.006780036073178053\n",
      "Training Loss: 0.004063417682336876\n",
      "Training Loss: 0.0006830565976270009\n",
      "Training Loss: 0.0005205127240333241\n",
      "Training Loss: 0.0005099084587709512\n",
      "Validation Loss: 0.0016710732795425852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00728168289642781\n",
      "Training Loss: 0.007145784044405445\n",
      "Training Loss: 0.006749734677141532\n",
      "Training Loss: 0.004045714227031567\n",
      "Training Loss: 0.0006863026227074443\n",
      "Training Loss: 0.000519121975194139\n",
      "Training Loss: 0.000504725002374471\n",
      "Validation Loss: 0.0016660344827709168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007258873146492988\n",
      "Training Loss: 0.0071192940324544905\n",
      "Training Loss: 0.006719242352992296\n",
      "Training Loss: 0.0040279253743210576\n",
      "Training Loss: 0.0006895665323827416\n",
      "Training Loss: 0.0005177280049247202\n",
      "Training Loss: 0.0004994173549675906\n",
      "Validation Loss: 0.0016610816755281475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007235827700933442\n",
      "Training Loss: 0.007092531980015337\n",
      "Training Loss: 0.006688865205505863\n",
      "Training Loss: 0.0040102350350207415\n",
      "Training Loss: 0.0006927719835221069\n",
      "Training Loss: 0.0005163437908049672\n",
      "Training Loss: 0.0004940312138205627\n",
      "Validation Loss: 0.0016562134638280009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00721270831534639\n",
      "Training Loss: 0.007065770926419646\n",
      "Training Loss: 0.006658931792480871\n",
      "Training Loss: 0.0039928370591223936\n",
      "Training Loss: 0.0006958250270690769\n",
      "Training Loss: 0.0005149685522337677\n",
      "Training Loss: 0.0004886116016132292\n",
      "Validation Loss: 0.001651436371343125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0071896884648595\n",
      "Training Loss: 0.007039286630460992\n",
      "Training Loss: 0.006629762621596456\n",
      "Training Loss: 0.003975921771270805\n",
      "Training Loss: 0.0006986391927785008\n",
      "Training Loss: 0.0005136052421585191\n",
      "Training Loss: 0.00048320445846911753\n",
      "Validation Loss: 0.0016467570633412084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007166957837762311\n",
      "Training Loss: 0.007013364979065954\n",
      "Training Loss: 0.0066016540245618675\n",
      "Training Loss: 0.0039596666155557615\n",
      "Training Loss: 0.0007011138659436256\n",
      "Training Loss: 0.0005122335041960469\n",
      "Training Loss: 0.0004778408945639967\n",
      "Validation Loss: 0.0016421899115825892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007144716230686754\n",
      "Training Loss: 0.006988263617968187\n",
      "Training Loss: 0.006574849577154964\n",
      "Training Loss: 0.003944218489705236\n",
      "Training Loss: 0.0007031737385113957\n",
      "Training Loss: 0.0005108370600282796\n",
      "Training Loss: 0.00047255506382498424\n",
      "Validation Loss: 0.001637755441134935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007123132972046733\n",
      "Training Loss: 0.006964192710584029\n",
      "Training Loss: 0.006549515051301569\n",
      "Training Loss: 0.003929685246694134\n",
      "Training Loss: 0.000704749965807423\n",
      "Training Loss: 0.0005093857418978587\n",
      "Training Loss: 0.0004673625843133777\n",
      "Validation Loss: 0.0016334878864961027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007102366976905614\n",
      "Training Loss: 0.006941311506088823\n",
      "Training Loss: 0.006525755197508261\n",
      "Training Loss: 0.003916135209874483\n",
      "Training Loss: 0.000705799559582374\n",
      "Training Loss: 0.0005078549419704359\n",
      "Training Loss: 0.0004622796005423879\n",
      "Validation Loss: 0.0016294086960173555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007082524766447023\n",
      "Training Loss: 0.006919712574454024\n",
      "Training Loss: 0.0065035917016211895\n",
      "Training Loss: 0.00390359254568466\n",
      "Training Loss: 0.0007063034176826477\n",
      "Training Loss: 0.0005062200083193602\n",
      "Training Loss: 0.00045731173806416335\n",
      "Validation Loss: 0.001625547935645103\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007063679881393909\n",
      "Training Loss: 0.006899432889185846\n",
      "Training Loss: 0.006482992076780647\n",
      "Training Loss: 0.0038920469654112823\n",
      "Training Loss: 0.0007062606430554297\n",
      "Training Loss: 0.000504462221833819\n",
      "Training Loss: 0.00045246321798913413\n",
      "Validation Loss: 0.0016219252045745944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007045856546610594\n",
      "Training Loss: 0.0068804565933533015\n",
      "Training Loss: 0.006463882743846625\n",
      "Training Loss: 0.0038814566317887512\n",
      "Training Loss: 0.0007056906102661742\n",
      "Training Loss: 0.0005025693632705952\n",
      "Training Loss: 0.0004477361444878625\n",
      "Validation Loss: 0.0016185585167960957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007029045403469354\n",
      "Training Loss: 0.006862727546831593\n",
      "Training Loss: 0.006446150380652398\n",
      "Training Loss: 0.0038717575545888392\n",
      "Training Loss: 0.0007046348053700058\n",
      "Training Loss: 0.0005005380565125961\n",
      "Training Loss: 0.0004431289049534826\n",
      "Validation Loss: 0.0016154456367648176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007013206972042099\n",
      "Training Loss: 0.006846161888679489\n",
      "Training Loss: 0.006429672950180248\n",
      "Training Loss: 0.0038628783145395573\n",
      "Training Loss: 0.0007031394396472024\n",
      "Training Loss: 0.0004983766785881016\n",
      "Training Loss: 0.0004386487977899378\n",
      "Validation Loss: 0.001612583558501986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006998261811677366\n",
      "Training Loss: 0.006830650079064071\n",
      "Training Loss: 0.0064143111638259144\n",
      "Training Loss: 0.0038547342459787615\n",
      "Training Loss: 0.0007012599092558958\n",
      "Training Loss: 0.0004960895908152452\n",
      "Training Loss: 0.0004342890375846764\n",
      "Validation Loss: 0.0016099631904669311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006984143771696836\n",
      "Training Loss: 0.006816092209191993\n",
      "Training Loss: 0.006399945640005171\n",
      "Training Loss: 0.003847243768250337\n",
      "Training Loss: 0.0006990474194753915\n",
      "Training Loss: 0.0004936900777101983\n",
      "Training Loss: 0.0004300505352875916\n",
      "Validation Loss: 0.0016075735663744876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006970768686151132\n",
      "Training Loss: 0.006802377180429175\n",
      "Training Loss: 0.006386454541934654\n",
      "Training Loss: 0.003840332419349579\n",
      "Training Loss: 0.0006965574810601538\n",
      "Training Loss: 0.0004911929826630512\n",
      "Training Loss: 0.000425935097882757\n",
      "Validation Loss: 0.0016054008954508956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006958048987435177\n",
      "Training Loss: 0.0067894009908195585\n",
      "Training Loss: 0.00637373183737509\n",
      "Training Loss: 0.003833920705219498\n",
      "Training Loss: 0.0006938368830742548\n",
      "Training Loss: 0.0004886145407363074\n",
      "Training Loss: 0.00042194150722934864\n",
      "Validation Loss: 0.0016034341351905653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006945903553860262\n",
      "Training Loss: 0.006777065714122728\n",
      "Training Loss: 0.006361677178647369\n",
      "Training Loss: 0.0038279475615127013\n",
      "Training Loss: 0.0006909342829749221\n",
      "Training Loss: 0.00048596993568935433\n",
      "Training Loss: 0.00041807041940046476\n",
      "Validation Loss: 0.0016016610133693177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006934257999528199\n",
      "Training Loss: 0.0067652918072417375\n",
      "Training Loss: 0.006350212711840868\n",
      "Training Loss: 0.003822353201394435\n",
      "Training Loss: 0.0006878885321202687\n",
      "Training Loss: 0.00048327123986382505\n",
      "Training Loss: 0.00041431864105106797\n",
      "Validation Loss: 0.0016000623366104836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006923044075956568\n",
      "Training Loss: 0.006754001182271168\n",
      "Training Loss: 0.006339259099913761\n",
      "Training Loss: 0.0038170875213108958\n",
      "Training Loss: 0.0006847326531715226\n",
      "Training Loss: 0.00048053417303890457\n",
      "Training Loss: 0.0004106871779367793\n",
      "Validation Loss: 0.0015986269290431678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006912197837373242\n",
      "Training Loss: 0.0067431232496164735\n",
      "Training Loss: 0.006328749246895313\n",
      "Training Loss: 0.0038121029346075376\n",
      "Training Loss: 0.0006815018154884456\n",
      "Training Loss: 0.0004777727529290132\n",
      "Training Loss: 0.0004071748840942746\n",
      "Validation Loss: 0.0015973359490982395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006901664692559279\n",
      "Training Loss: 0.006732602837728336\n",
      "Training Loss: 0.006318631783360615\n",
      "Training Loss: 0.0038073627489211503\n",
      "Training Loss: 0.000678216238738969\n",
      "Training Loss: 0.0004749961586639984\n",
      "Training Loss: 0.0004037793828319991\n",
      "Validation Loss: 0.0015961882239567335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006891395643469878\n",
      "Training Loss: 0.006722388183698058\n",
      "Training Loss: 0.00630885885679163\n",
      "Training Loss: 0.0038028320191369857\n",
      "Training Loss: 0.0006748972958303057\n",
      "Training Loss: 0.00047220978332916273\n",
      "Training Loss: 0.0004004954608535627\n",
      "Validation Loss: 0.0015951701624023341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006881356343510561\n",
      "Training Loss: 0.006712443178985268\n",
      "Training Loss: 0.006299394676461816\n",
      "Training Loss: 0.003798485413135495\n",
      "Training Loss: 0.0006715618633461417\n",
      "Training Loss: 0.0004694247524457751\n",
      "Training Loss: 0.00039732212942908515\n",
      "Validation Loss: 0.0015942724427343033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006871509735938162\n",
      "Training Loss: 0.006702728695236146\n",
      "Training Loss: 0.006290204231627286\n",
      "Training Loss: 0.0037942972108430694\n",
      "Training Loss: 0.0006682252557948232\n",
      "Training Loss: 0.0004666494689445244\n",
      "Training Loss: 0.0003942567779449746\n",
      "Validation Loss: 0.0015934851030766362\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006861825517844409\n",
      "Training Loss: 0.006693214440019801\n",
      "Training Loss: 0.00628125702845864\n",
      "Training Loss: 0.003790248041623272\n",
      "Training Loss: 0.0006648945329652634\n",
      "Training Loss: 0.0004638812462508213\n",
      "Training Loss: 0.0003912897341797361\n",
      "Validation Loss: 0.0015927909320289676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006852287879446521\n",
      "Training Loss: 0.0066838841279968616\n",
      "Training Loss: 0.006272536731557921\n",
      "Training Loss: 0.003786321090592537\n",
      "Training Loss: 0.0006615789088391466\n",
      "Training Loss: 0.00046112834446830674\n",
      "Training Loss: 0.0003884208951785695\n",
      "Validation Loss: 0.0015921936611492755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006842875703587197\n",
      "Training Loss: 0.006674711316591129\n",
      "Training Loss: 0.006264018284855411\n",
      "Training Loss: 0.0037825015321141108\n",
      "Training Loss: 0.000658282635777141\n",
      "Training Loss: 0.0004583947384526255\n",
      "Training Loss: 0.00038564498630876186\n",
      "Validation Loss: 0.0015916657232784505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0068335750355618076\n",
      "Training Loss: 0.006665685705374926\n",
      "Training Loss: 0.0062556908605620265\n",
      "Training Loss: 0.003778779715357814\n",
      "Training Loss: 0.0006550124229397625\n",
      "Training Loss: 0.0004556772331125103\n",
      "Training Loss: 0.00038295448539429346\n",
      "Validation Loss: 0.0015912138656545205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006824377881130204\n",
      "Training Loss: 0.0066567932313773785\n",
      "Training Loss: 0.006247540471376851\n",
      "Training Loss: 0.003775142628874164\n",
      "Training Loss: 0.0006517645192070632\n",
      "Training Loss: 0.0004529795336566167\n",
      "Training Loss: 0.00038034607729059644\n",
      "Validation Loss: 0.0015908233393663854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0068152774870395665\n",
      "Training Loss: 0.006648025112226606\n",
      "Training Loss: 0.006239556575892493\n",
      "Training Loss: 0.003771584585920209\n",
      "Training Loss: 0.0006485461480042431\n",
      "Training Loss: 0.00045030484376184176\n",
      "Training Loss: 0.00037781665472721217\n",
      "Validation Loss: 0.0015904848972441844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006806265281047672\n",
      "Training Loss: 0.0066393723920919\n",
      "Training Loss: 0.006231729098362848\n",
      "Training Loss: 0.003768099087756127\n",
      "Training Loss: 0.000645360719790915\n",
      "Training Loss: 0.00044765181046386716\n",
      "Training Loss: 0.00037535958472290076\n",
      "Validation Loss: 0.001590192407208943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006797341128112748\n",
      "Training Loss: 0.006630831251386553\n",
      "Training Loss: 0.006224052873440087\n",
      "Training Loss: 0.0037646795068576465\n",
      "Training Loss: 0.0006422000707971165\n",
      "Training Loss: 0.00044502001546788963\n",
      "Training Loss: 0.000372974210040411\n",
      "Validation Loss: 0.0015899420487016443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006788498916430399\n",
      "Training Loss: 0.0066223921591881665\n",
      "Training Loss: 0.006216518023284152\n",
      "Training Loss: 0.00376132233403041\n",
      "Training Loss: 0.0006390720704803243\n",
      "Training Loss: 0.00044241320807486773\n",
      "Training Loss: 0.0003706553398660617\n",
      "Validation Loss: 0.001589719964947145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006779739243793301\n",
      "Training Loss: 0.006614056179532781\n",
      "Training Loss: 0.006209120770217851\n",
      "Training Loss: 0.00375802553302492\n",
      "Training Loss: 0.0006359732930286554\n",
      "Training Loss: 0.00043982944916933777\n",
      "Training Loss: 0.000368400794104673\n",
      "Validation Loss: 0.0015895271746885146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006771058295271359\n",
      "Training Loss: 0.006605816193623468\n",
      "Training Loss: 0.006201853792881593\n",
      "Training Loss: 0.0037547824361536188\n",
      "Training Loss: 0.0006329008809552761\n",
      "Training Loss: 0.0004372687673458131\n",
      "Training Loss: 0.00036620646438677794\n",
      "Validation Loss: 0.0015893554971060692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006762459480087273\n",
      "Training Loss: 0.006597673670621589\n",
      "Training Loss: 0.006194716161116958\n",
      "Training Loss: 0.003751592797052581\n",
      "Training Loss: 0.0006298560673167231\n",
      "Training Loss: 0.0004347329054871807\n",
      "Training Loss: 0.0003640728225582279\n",
      "Validation Loss: 0.0015892053944547486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006753941965289414\n",
      "Training Loss: 0.006589623674517498\n",
      "Training Loss: 0.006187699142610654\n",
      "Training Loss: 0.0037484547807252965\n",
      "Training Loss: 0.0006268411437486066\n",
      "Training Loss: 0.0004322240422334289\n",
      "Training Loss: 0.00036199851601850244\n",
      "Validation Loss: 0.0015890595632810616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006745501141413115\n",
      "Training Loss: 0.006581665676785633\n",
      "Training Loss: 0.00618080216110684\n",
      "Training Loss: 0.003745365312934155\n",
      "Training Loss: 0.0006238482307526282\n",
      "Training Loss: 0.00042973810093826614\n",
      "Training Loss: 0.0003599805047269911\n",
      "Validation Loss: 0.0015889378629161798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.00673714277218096\n",
      "Training Loss: 0.006573798768222332\n",
      "Training Loss: 0.006174020929029212\n",
      "Training Loss: 0.003742323439655593\n",
      "Training Loss: 0.0006208837731537642\n",
      "Training Loss: 0.0004272824511281215\n",
      "Training Loss: 0.0003580199328280287\n",
      "Validation Loss: 0.00158882015500822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006728861330193467\n",
      "Training Loss: 0.006566022341139614\n",
      "Training Loss: 0.0061673525383230295\n",
      "Training Loss: 0.0037393282739503777\n",
      "Training Loss: 0.0006179408643220086\n",
      "Training Loss: 0.0004248526832088828\n",
      "Training Loss: 0.00035611579245596657\n",
      "Validation Loss: 0.0015887132279711342\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006720658839913085\n",
      "Training Loss: 0.006558332169661298\n",
      "Training Loss: 0.006160788737470284\n",
      "Training Loss: 0.003736378009925829\n",
      "Training Loss: 0.0006150260029971832\n",
      "Training Loss: 0.0004224550962680951\n",
      "Training Loss: 0.0003542693717463408\n",
      "Validation Loss: 0.0015886103383275028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006712527833878994\n",
      "Training Loss: 0.0065507303166668866\n",
      "Training Loss: 0.0061543305451050405\n",
      "Training Loss: 0.0037334711708535907\n",
      "Training Loss: 0.0006121309606533032\n",
      "Training Loss: 0.0004200860901619308\n",
      "Training Loss: 0.00035247953841462733\n",
      "Validation Loss: 0.0015885069500218923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00670447429525666\n",
      "Training Loss: 0.006543216223362834\n",
      "Training Loss: 0.006147972223116085\n",
      "Training Loss: 0.0037306078332767357\n",
      "Training Loss: 0.0006092593040375505\n",
      "Training Loss: 0.0004177499000070384\n",
      "Training Loss: 0.0003507463057758287\n",
      "Validation Loss: 0.0015884191471717516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0066964938887394965\n",
      "Training Loss: 0.006535786221502349\n",
      "Training Loss: 0.006141711048549041\n",
      "Training Loss: 0.0037277872623235455\n",
      "Training Loss: 0.0006064117733330932\n",
      "Training Loss: 0.0004154491184453946\n",
      "Training Loss: 0.000349070732772816\n",
      "Validation Loss: 0.0015883235872787692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.00668858211429324\n",
      "Training Loss: 0.006528444428695366\n",
      "Training Loss: 0.006135544420685619\n",
      "Training Loss: 0.003725004212319618\n",
      "Training Loss: 0.0006035833730129525\n",
      "Training Loss: 0.0004131828927347669\n",
      "Training Loss: 0.00034745301920338536\n",
      "Validation Loss: 0.0015882421459318993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0066807390825124454\n",
      "Training Loss: 0.0065211835422087465\n",
      "Training Loss: 0.006129467957653106\n",
      "Training Loss: 0.0037222629752068316\n",
      "Training Loss: 0.000600776764404145\n",
      "Training Loss: 0.0004109541096840985\n",
      "Training Loss: 0.0003458928904001368\n",
      "Validation Loss: 0.0015881577314161921\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006672962674638256\n",
      "Training Loss: 0.006514010523678735\n",
      "Training Loss: 0.0061234798887744545\n",
      "Training Loss: 0.0037195593296200967\n",
      "Training Loss: 0.0005979890243179397\n",
      "Training Loss: 0.00040876197344914545\n",
      "Training Loss: 0.0003443911653448595\n",
      "Validation Loss: 0.0015880838388072202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006665250289952383\n",
      "Training Loss: 0.006506917735096067\n",
      "Training Loss: 0.006117574529489502\n",
      "Training Loss: 0.003716891585208941\n",
      "Training Loss: 0.0005952229555259692\n",
      "Training Loss: 0.0004066120836068876\n",
      "Training Loss: 0.00034294815573957747\n",
      "Validation Loss: 0.0015880110354118278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006657598884194158\n",
      "Training Loss: 0.006499908784171567\n",
      "Training Loss: 0.006111752504948526\n",
      "Training Loss: 0.0037142629412119277\n",
      "Training Loss: 0.0005924775198218413\n",
      "Training Loss: 0.00040450431013596246\n",
      "Training Loss: 0.00034156389556301293\n",
      "Validation Loss: 0.0015879381178356777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006650006010313518\n",
      "Training Loss: 0.006492984115611762\n",
      "Training Loss: 0.006106011722004041\n",
      "Training Loss: 0.0037116644870548044\n",
      "Training Loss: 0.0005897481823922135\n",
      "Training Loss: 0.00040243803065095565\n",
      "Training Loss: 0.0003402360251493519\n",
      "Validation Loss: 0.001587873349359306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006642475583357736\n",
      "Training Loss: 0.006486143110087141\n",
      "Training Loss: 0.006100346531020477\n",
      "Training Loss: 0.003709102000502753\n",
      "Training Loss: 0.000587042580373236\n",
      "Training Loss: 0.00040041907552222254\n",
      "Training Loss: 0.00033897060595336373\n",
      "Validation Loss: 0.0015878139885817392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006634994050837122\n",
      "Training Loss: 0.006479379930533468\n",
      "Training Loss: 0.006094753512879834\n",
      "Training Loss: 0.0037065721608814783\n",
      "Training Loss: 0.0005843593855388463\n",
      "Training Loss: 0.00039844816463300957\n",
      "Training Loss: 0.0003377624144923175\n",
      "Validation Loss: 0.0015877587960013589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0066275680891703815\n",
      "Training Loss: 0.006472699652658775\n",
      "Training Loss: 0.006089232624508441\n",
      "Training Loss: 0.0037040731418528593\n",
      "Training Loss: 0.0005816945120022865\n",
      "Training Loss: 0.00039652502673561687\n",
      "Training Loss: 0.00033661268826108427\n",
      "Validation Loss: 0.0015877073648458081\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006620191867114045\n",
      "Training Loss: 0.006466098873643205\n",
      "Training Loss: 0.006083780038170517\n",
      "Training Loss: 0.0037016048568330007\n",
      "Training Loss: 0.0005790519230504288\n",
      "Training Loss: 0.000394651564056403\n",
      "Training Loss: 0.00033551954962604216\n",
      "Validation Loss: 0.001587657513009072\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.0066128638380905614\n",
      "Training Loss: 0.006459578752983361\n",
      "Training Loss: 0.006078391696792096\n",
      "Training Loss: 0.0036991662497166543\n",
      "Training Loss: 0.0005764316697604954\n",
      "Training Loss: 0.0003928291494230507\n",
      "Training Loss: 0.000334483082551742\n",
      "Validation Loss: 0.0015876046771031878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006605585526558571\n",
      "Training Loss: 0.006453137211501599\n",
      "Training Loss: 0.006073067880934104\n",
      "Training Loss: 0.003696754489646992\n",
      "Training Loss: 0.0005738339209347032\n",
      "Training Loss: 0.00039105862146243453\n",
      "Training Loss: 0.0003335016028722748\n",
      "Validation Loss: 0.0015875608928700865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006598353175795637\n",
      "Training Loss: 0.006446775718359277\n",
      "Training Loss: 0.0060678085288964215\n",
      "Training Loss: 0.0036943695093941643\n",
      "Training Loss: 0.0005712575293000554\n",
      "Training Loss: 0.00038934078649617733\n",
      "Training Loss: 0.0003325744208996184\n",
      "Validation Loss: 0.0015875184495387467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006591168558225035\n",
      "Training Loss: 0.006440490857930854\n",
      "Training Loss: 0.00606260787579231\n",
      "Training Loss: 0.00369200848719629\n",
      "Training Loss: 0.0005687037139432505\n",
      "Training Loss: 0.0003876763094740454\n",
      "Training Loss: 0.0003317000630340772\n",
      "Validation Loss: 0.0015874802747147057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006584026273922064\n",
      "Training Loss: 0.00643428630544804\n",
      "Training Loss: 0.006057466630591079\n",
      "Training Loss: 0.003689672638502088\n",
      "Training Loss: 0.0005661727465485455\n",
      "Training Loss: 0.0003860638041078346\n",
      "Training Loss: 0.0003308764728353708\n",
      "Validation Loss: 0.001587444417569298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006576930568553507\n",
      "Training Loss: 0.006428157663904131\n",
      "Training Loss: 0.006052380895707757\n",
      "Training Loss: 0.003687361237825826\n",
      "Training Loss: 0.0005636672249238472\n",
      "Training Loss: 0.00038450598352937957\n",
      "Training Loss: 0.00033010293842380636\n",
      "Validation Loss: 0.0015874172322753353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006569880358874798\n",
      "Training Loss: 0.006422105772653595\n",
      "Training Loss: 0.006047349316067993\n",
      "Training Loss: 0.003685072496518842\n",
      "Training Loss: 0.0005611885304824682\n",
      "Training Loss: 0.00038300259759125764\n",
      "Training Loss: 0.00032937780601059784\n",
      "Validation Loss: 0.0015873838391452365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006562874227529392\n",
      "Training Loss: 0.006416129891294986\n",
      "Training Loss: 0.0060423712071497\n",
      "Training Loss: 0.0036828053489443846\n",
      "Training Loss: 0.0005587315255252179\n",
      "Training Loss: 0.000381551693790243\n",
      "Training Loss: 0.0003286984079386457\n",
      "Validation Loss: 0.001587352478323628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006555910013848916\n",
      "Training Loss: 0.006410226547159254\n",
      "Training Loss: 0.006037442411761731\n",
      "Training Loss: 0.0036805590888252483\n",
      "Training Loss: 0.0005563026879826793\n",
      "Training Loss: 0.0003801551805372583\n",
      "Training Loss: 0.00032806434199301294\n",
      "Validation Loss: 0.0015873248777550659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006548989968723618\n",
      "Training Loss: 0.006404398813610896\n",
      "Training Loss: 0.006032565210480243\n",
      "Training Loss: 0.0036783345581352478\n",
      "Training Loss: 0.000553900925515336\n",
      "Training Loss: 0.0003788105978310341\n",
      "Training Loss: 0.00032747236095019615\n",
      "Validation Loss: 0.0015873015520704843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006542115699267015\n",
      "Training Loss: 0.00639864393742755\n",
      "Training Loss: 0.006027736319229007\n",
      "Training Loss: 0.003676129605300957\n",
      "Training Loss: 0.0005515247955190716\n",
      "Training Loss: 0.00037751619245682375\n",
      "Training Loss: 0.0003269193979576812\n",
      "Validation Loss: 0.0015872789198091892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006535288597806357\n",
      "Training Loss: 0.006392963023390621\n",
      "Training Loss: 0.006022956246742979\n",
      "Training Loss: 0.0036739403798856075\n",
      "Training Loss: 0.0005491731897200225\n",
      "Training Loss: 0.0003762741918762913\n",
      "Training Loss: 0.00032640676352457376\n",
      "Validation Loss: 0.001587254657297376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006528503663139418\n",
      "Training Loss: 0.006387351887533441\n",
      "Training Loss: 0.006018221927806735\n",
      "Training Loss: 0.0036717715341364966\n",
      "Training Loss: 0.0005468518393172417\n",
      "Training Loss: 0.0003750820869754534\n",
      "Training Loss: 0.0003259310741850641\n",
      "Validation Loss: 0.0015872347998192571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006521764261997305\n",
      "Training Loss: 0.0063818124332465235\n",
      "Training Loss: 0.0060135330853518095\n",
      "Training Loss: 0.0036696222741738893\n",
      "Training Loss: 0.0005445565957052168\n",
      "Training Loss: 0.0003739370539551601\n",
      "Training Loss: 0.00032548834547924344\n",
      "Validation Loss: 0.0015872204623131468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006515072392649018\n",
      "Training Loss: 0.006376341854920611\n",
      "Training Loss: 0.006008887244388461\n",
      "Training Loss: 0.003667489653234952\n",
      "Training Loss: 0.0005422900915436912\n",
      "Training Loss: 0.0003728405653964728\n",
      "Training Loss: 0.00032507901334611234\n",
      "Validation Loss: 0.0015872032094098477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006508426805958152\n",
      "Training Loss: 0.006370939847547561\n",
      "Training Loss: 0.006004285049857572\n",
      "Training Loss: 0.003665373980184086\n",
      "Training Loss: 0.000540049253613688\n",
      "Training Loss: 0.0003717889669496799\n",
      "Training Loss: 0.0003247011878556805\n",
      "Validation Loss: 0.0015871940097925933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006501827614265494\n",
      "Training Loss: 0.0063656046043615785\n",
      "Training Loss: 0.005999724668217823\n",
      "Training Loss: 0.003663275288490695\n",
      "Training Loss: 0.0005378373628627742\n",
      "Training Loss: 0.00037078244735312183\n",
      "Training Loss: 0.0003243524912613793\n",
      "Validation Loss: 0.0015871829899869012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006495276141213253\n",
      "Training Loss: 0.006360336823854595\n",
      "Training Loss: 0.00599520587711595\n",
      "Training Loss: 0.003661193170337356\n",
      "Training Loss: 0.0005356522358488291\n",
      "Training Loss: 0.00036981731034757103\n",
      "Training Loss: 0.0003240292685222812\n",
      "Validation Loss: 0.0015871783075402908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006488775679608807\n",
      "Training Loss: 0.00635513408575207\n",
      "Training Loss: 0.005990727544995025\n",
      "Training Loss: 0.0036591262135334548\n",
      "Training Loss: 0.0005334939323802246\n",
      "Training Loss: 0.0003688950881769415\n",
      "Training Loss: 0.00032373398847994393\n",
      "Validation Loss: 0.0015871768358347968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006482320002978667\n",
      "Training Loss: 0.0063499937055166815\n",
      "Training Loss: 0.005986288231797516\n",
      "Training Loss: 0.003657076891468023\n",
      "Training Loss: 0.0005313658444356406\n",
      "Training Loss: 0.0003680127211555373\n",
      "Training Loss: 0.00032346183816116535\n",
      "Validation Loss: 0.0015871751645991094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0064759134734049435\n",
      "Training Loss: 0.006344916599337011\n",
      "Training Loss: 0.005981887975940481\n",
      "Training Loss: 0.0036550441845975\n",
      "Training Loss: 0.000529262838390423\n",
      "Training Loss: 0.00036716669717861805\n",
      "Training Loss: 0.0003232105143251829\n",
      "Validation Loss: 0.0015871764350848618\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 166\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.0064695588615722955\n",
      "Training Loss: 0.006339903410989791\n",
      "Training Loss: 0.005977527158102021\n",
      "Training Loss: 0.0036530259284336354\n",
      "Training Loss: 0.0005271880567306652\n",
      "Training Loss: 0.00036635881042457186\n",
      "Training Loss: 0.00032298238522344036\n",
      "Validation Loss: 0.0015871875426653086\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 167\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006463251438690349\n",
      "Training Loss: 0.006334948712028563\n",
      "Training Loss: 0.005973203621106222\n",
      "Training Loss: 0.0036510236217509374\n",
      "Training Loss: 0.0005251390457851812\n",
      "Training Loss: 0.000365584083046997\n",
      "Training Loss: 0.0003227713036176283\n",
      "Validation Loss: 0.001587198857569671\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 168\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006456998529029079\n",
      "Training Loss: 0.0063300542894285175\n",
      "Training Loss: 0.0059689163137227295\n",
      "Training Loss: 0.003649038176918111\n",
      "Training Loss: 0.0005231197066314052\n",
      "Training Loss: 0.00036484450298303274\n",
      "Training Loss: 0.00032257933577056974\n",
      "Validation Loss: 0.0015872079153466283\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 169\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00645079311740119\n",
      "Training Loss: 0.006325219391146675\n",
      "Training Loss: 0.005964666238287464\n",
      "Training Loss: 0.0036470689950147063\n",
      "Training Loss: 0.0005211239744676278\n",
      "Training Loss: 0.00036413525565876626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [16:27<08:18, 166.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0003224047102048644\n",
      "Validation Loss: 0.001587227663303872\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 170\n",
      "Early stopping after 170 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.07171495635062457\n",
      "Training Loss: 0.06793875560164452\n",
      "Training Loss: 0.06624594485387206\n",
      "Training Loss: 0.05620231258217245\n",
      "Training Loss: 0.042472919886931776\n",
      "Training Loss: 0.03876827876083553\n",
      "Training Loss: 0.03918800844345242\n",
      "Validation Loss: 0.043187459752884474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.05277119412086904\n",
      "Training Loss: 0.04875996720977128\n",
      "Training Loss: 0.04628666571341455\n",
      "Training Loss: 0.03519502347560774\n",
      "Training Loss: 0.022044640290550886\n",
      "Training Loss: 0.01923144667875022\n",
      "Training Loss: 0.018725303118117154\n",
      "Validation Loss: 0.02347972531792488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.03263209708966315\n",
      "Training Loss: 0.030030744923278688\n",
      "Training Loss: 0.02914668705780059\n",
      "Training Loss: 0.019628174850950017\n",
      "Training Loss: 0.009584484482184052\n",
      "Training Loss: 0.008481493548024445\n",
      "Training Loss: 0.008413737565279007\n",
      "Validation Loss: 0.013032638263794478\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.022436444237828253\n",
      "Training Loss: 0.0208632453950122\n",
      "Training Loss: 0.020861838560085742\n",
      "Training Loss: 0.012860907486174255\n",
      "Training Loss: 0.0045989951392402875\n",
      "Training Loss: 0.003997911799815484\n",
      "Training Loss: 0.0038964515074621886\n",
      "Validation Loss: 0.00787183800616305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.017214305533561857\n",
      "Training Loss: 0.016031330784317108\n",
      "Training Loss: 0.016142257356550546\n",
      "Training Loss: 0.009093404141021893\n",
      "Training Loss: 0.0018154439993668349\n",
      "Training Loss: 0.0013882573910814244\n",
      "Training Loss: 0.0012134261312894523\n",
      "Validation Loss: 0.005934650384823614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.014376813198905438\n",
      "Training Loss: 0.013422311902977525\n",
      "Training Loss: 0.013464007747825236\n",
      "Training Loss: 0.007303853096382227\n",
      "Training Loss: 0.000897638761161943\n",
      "Training Loss: 0.0007367488057207083\n",
      "Training Loss: 0.0007497739912651014\n",
      "Validation Loss: 0.004973126811015486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.012577502180356533\n",
      "Training Loss: 0.01180258356500417\n",
      "Training Loss: 0.011763140640687198\n",
      "Training Loss: 0.006409451846120646\n",
      "Training Loss: 0.0007336116346777999\n",
      "Training Loss: 0.0006032574537675828\n",
      "Training Loss: 0.0006680164612043882\n",
      "Validation Loss: 0.0039778674529971775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.011134818801656366\n",
      "Training Loss: 0.010590192617382855\n",
      "Training Loss: 0.010535588192287832\n",
      "Training Loss: 0.0058188458288350375\n",
      "Training Loss: 0.0006732278904382837\n",
      "Training Loss: 0.0005489776873582741\n",
      "Training Loss: 0.0006364610137097771\n",
      "Validation Loss: 0.0033119921496749267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.010148606938309967\n",
      "Training Loss: 0.009767355376388877\n",
      "Training Loss: 0.009709371167700738\n",
      "Training Loss: 0.0054431858405587265\n",
      "Training Loss: 0.0006484620173432632\n",
      "Training Loss: 0.0005272298765339656\n",
      "Training Loss: 0.0006237735130707734\n",
      "Validation Loss: 0.0028777954332994417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.009522047174395993\n",
      "Training Loss: 0.009243593955179676\n",
      "Training Loss: 0.009180030213901774\n",
      "Training Loss: 0.0052142113426089055\n",
      "Training Loss: 0.0006406753384362673\n",
      "Training Loss: 0.0005211561272153631\n",
      "Training Loss: 0.0006204528398666298\n",
      "Validation Loss: 0.0025996842227238737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.009141029014717788\n",
      "Training Loss: 0.00892031533527188\n",
      "Training Loss: 0.008845284731360153\n",
      "Training Loss: 0.005075688206707127\n",
      "Training Loss: 0.0006422997820482124\n",
      "Training Loss: 0.0005231538502994226\n",
      "Training Loss: 0.0006226827696809778\n",
      "Validation Loss: 0.002423526312303921\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008907333619426937\n",
      "Training Loss: 0.008715058986563235\n",
      "Training Loss: 0.008624252921435982\n",
      "Training Loss: 0.004986905787009163\n",
      "Training Loss: 0.0006492407847690629\n",
      "Training Loss: 0.0005292208179889712\n",
      "Training Loss: 0.0006280832306947559\n",
      "Validation Loss: 0.0023109920298151343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008751757551217453\n",
      "Training Loss: 0.008571989155607298\n",
      "Training Loss: 0.00846440895809792\n",
      "Training Loss: 0.00492311075431644\n",
      "Training Loss: 0.0006586131351650693\n",
      "Training Loss: 0.0005368115822784603\n",
      "Training Loss: 0.0006346435364685022\n",
      "Validation Loss: 0.0022362448726471144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008634978234767913\n",
      "Training Loss: 0.00846072654123418\n",
      "Training Loss: 0.008337580478983\n",
      "Training Loss: 0.004871728590878774\n",
      "Training Loss: 0.0006684126267646206\n",
      "Training Loss: 0.0005442543948447565\n",
      "Training Loss: 0.0006408038547670004\n",
      "Validation Loss: 0.002183081547525617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008538773369509726\n",
      "Training Loss: 0.00836755805881694\n",
      "Training Loss: 0.008230600658571348\n",
      "Training Loss: 0.00482717597624287\n",
      "Training Loss: 0.0006774671438324731\n",
      "Training Loss: 0.0005505665802775184\n",
      "Training Loss: 0.0006455822468706174\n",
      "Validation Loss: 0.002142118894434464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008455816049827264\n",
      "Training Loss: 0.008286852990277111\n",
      "Training Loss: 0.00813755913870409\n",
      "Training Loss: 0.0047870981723826846\n",
      "Training Loss: 0.0006852088797313627\n",
      "Training Loss: 0.000555264430004172\n",
      "Training Loss: 0.0006484856646420667\n",
      "Validation Loss: 0.002108336747931369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008383191898465156\n",
      "Training Loss: 0.008216146719641984\n",
      "Training Loss: 0.008055599358631298\n",
      "Training Loss: 0.0047504506654513536\n",
      "Training Loss: 0.0006914089644851629\n",
      "Training Loss: 0.0005581849820737261\n",
      "Training Loss: 0.0006493444295483642\n",
      "Validation Loss: 0.002079159749681845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00831946867518127\n",
      "Training Loss: 0.008154048105934635\n",
      "Training Loss: 0.007983079826226458\n",
      "Training Loss: 0.004716709195563453\n",
      "Training Loss: 0.0006960066915053176\n",
      "Training Loss: 0.0005593623697495786\n",
      "Training Loss: 0.0006481827575771604\n",
      "Validation Loss: 0.002053234488236777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00826364418840967\n",
      "Training Loss: 0.008099513298366218\n",
      "Training Loss: 0.00791885482147336\n",
      "Training Loss: 0.004685551544171176\n",
      "Training Loss: 0.0006990153703372925\n",
      "Training Loss: 0.0005589414938731352\n",
      "Training Loss: 0.0006451251362159382\n",
      "Validation Loss: 0.0020297688141762546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008214837990235537\n",
      "Training Loss: 0.008051614471478388\n",
      "Training Loss: 0.007861980553716421\n",
      "Training Loss: 0.004656745962347486\n",
      "Training Loss: 0.0007004954565491061\n",
      "Training Loss: 0.0005571262251032749\n",
      "Training Loss: 0.0006403518312436063\n",
      "Validation Loss: 0.002008232983393413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008172204181319103\n",
      "Training Loss: 0.008009489671094343\n",
      "Training Loss: 0.007811613087542355\n",
      "Training Loss: 0.004630087288896903\n",
      "Training Loss: 0.0007005182607099414\n",
      "Training Loss: 0.0005541282677586423\n",
      "Training Loss: 0.0006340591667685657\n",
      "Validation Loss: 0.0019882518544353626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008134942918550223\n",
      "Training Loss: 0.007972333877114579\n",
      "Training Loss: 0.0077669688791502265\n",
      "Training Loss: 0.004605374711900367\n",
      "Training Loss: 0.0006991851123166271\n",
      "Training Loss: 0.0005501562905556056\n",
      "Training Loss: 0.0006264552118227584\n",
      "Validation Loss: 0.0019695534305328726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008102287107612937\n",
      "Training Loss: 0.007939396459842102\n",
      "Training Loss: 0.007727300026454031\n",
      "Training Loss: 0.004582405608452973\n",
      "Training Loss: 0.000696618229339947\n",
      "Training Loss: 0.0005454034276044695\n",
      "Training Loss: 0.000617748772710911\n",
      "Validation Loss: 0.001951972511259068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008073543546488508\n",
      "Training Loss: 0.007910007735481485\n",
      "Training Loss: 0.007691918248310685\n",
      "Training Loss: 0.004560987299410044\n",
      "Training Loss: 0.0006929609530197923\n",
      "Training Loss: 0.0005400398368510651\n",
      "Training Loss: 0.000608144207217265\n",
      "Validation Loss: 0.0019353906713292692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008048088909126817\n",
      "Training Loss: 0.007883570404956117\n",
      "Training Loss: 0.00766018402762711\n",
      "Training Loss: 0.004540946201741463\n",
      "Training Loss: 0.0006883862722315826\n",
      "Training Loss: 0.0005342273879796267\n",
      "Training Loss: 0.0005978505752864294\n",
      "Validation Loss: 0.0019197603091942008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008025369265815242\n",
      "Training Loss: 0.007859571542358026\n",
      "Training Loss: 0.007631521323928609\n",
      "Training Loss: 0.004522122437338112\n",
      "Training Loss: 0.0006830783167970367\n",
      "Training Loss: 0.0005281152811949141\n",
      "Training Loss: 0.0005870747216249583\n",
      "Validation Loss: 0.0019050793178237396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008004918777151033\n",
      "Training Loss: 0.007837578122271226\n",
      "Training Loss: 0.007605423126369715\n",
      "Training Loss: 0.00450437972212967\n",
      "Training Loss: 0.0006772288156207651\n",
      "Training Loss: 0.0005218433212576201\n",
      "Training Loss: 0.0005760203430691035\n",
      "Validation Loss: 0.0018913667728711959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007986317704198881\n",
      "Training Loss: 0.007817217201227323\n",
      "Training Loss: 0.007581441046204418\n",
      "Training Loss: 0.004487601624350646\n",
      "Training Loss: 0.000671027097341721\n",
      "Training Loss: 0.0005155399389332161\n",
      "Training Loss: 0.000564883312836173\n",
      "Validation Loss: 0.0018786491123869604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007969216901110486\n",
      "Training Loss: 0.007798176393844187\n",
      "Training Loss: 0.007559183122357354\n",
      "Training Loss: 0.004471688344128779\n",
      "Training Loss: 0.0006646628925955156\n",
      "Training Loss: 0.0005093308624054771\n",
      "Training Loss: 0.0005538515794614795\n",
      "Validation Loss: 0.0018669689456323572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007953302436508238\n",
      "Training Loss: 0.007780184231232851\n",
      "Training Loss: 0.007538303077453747\n",
      "Training Loss: 0.004456550077811698\n",
      "Training Loss: 0.0006583093156950781\n",
      "Training Loss: 0.0005033258612820645\n",
      "Training Loss: 0.0005430937429628102\n",
      "Validation Loss: 0.0018563247084127537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007938300512032584\n",
      "Training Loss: 0.007763007124885916\n",
      "Training Loss: 0.007518498200224713\n",
      "Training Loss: 0.004442108359871782\n",
      "Training Loss: 0.0006521208769117948\n",
      "Training Loss: 0.0004976247616286855\n",
      "Training Loss: 0.0005327610680978978\n",
      "Validation Loss: 0.0018467155032510405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007923962876666336\n",
      "Training Loss: 0.007746436634333804\n",
      "Training Loss: 0.007499497301178053\n",
      "Training Loss: 0.0044282884144195124\n",
      "Training Loss: 0.0006462338547862601\n",
      "Training Loss: 0.0004923091082309839\n",
      "Training Loss: 0.0005229716296162223\n",
      "Validation Loss: 0.0018380980493722322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007910083719762042\n",
      "Training Loss: 0.007730293098138646\n",
      "Training Loss: 0.007481060608988628\n",
      "Training Loss: 0.004415018112340476\n",
      "Training Loss: 0.0006407566519192187\n",
      "Training Loss: 0.0004874430772179039\n",
      "Training Loss: 0.0005138176794571336\n",
      "Validation Loss: 0.0018304153855114805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007896467492682859\n",
      "Training Loss: 0.007714413159992546\n",
      "Training Loss: 0.007462968279141933\n",
      "Training Loss: 0.004402223833094468\n",
      "Training Loss: 0.0006357696979102912\n",
      "Training Loss: 0.00048306674529158044\n",
      "Training Loss: 0.0005053528118151007\n",
      "Validation Loss: 0.0018235679075696543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007882949752965942\n",
      "Training Loss: 0.007698651447426528\n",
      "Training Loss: 0.007445030375383794\n",
      "Training Loss: 0.004389836108821328\n",
      "Training Loss: 0.0006313247735670303\n",
      "Training Loss: 0.00047920109289407265\n",
      "Training Loss: 0.0004976040956535144\n",
      "Validation Loss: 0.001817463692351792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00786938686389476\n",
      "Training Loss: 0.007682878514751792\n",
      "Training Loss: 0.007427071100100875\n",
      "Training Loss: 0.0043777842460258395\n",
      "Training Loss: 0.0006274509659124305\n",
      "Training Loss: 0.0004758466601197142\n",
      "Training Loss: 0.0004905667339335195\n",
      "Validation Loss: 0.00181197416594763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007855656961910427\n",
      "Training Loss: 0.007666980287758633\n",
      "Training Loss: 0.0074089375545736405\n",
      "Training Loss: 0.004365992307502893\n",
      "Training Loss: 0.0006241494569985662\n",
      "Training Loss: 0.0004729867026617285\n",
      "Training Loss: 0.0004842157705570571\n",
      "Validation Loss: 0.001806979310264539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00784164918703027\n",
      "Training Loss: 0.007650855567771941\n",
      "Training Loss: 0.007390498258173466\n",
      "Training Loss: 0.004354391062806826\n",
      "Training Loss: 0.00062139308967744\n",
      "Training Loss: 0.00047058603289769964\n",
      "Training Loss: 0.0004784992997883819\n",
      "Validation Loss: 0.0018023705282832812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007827280634082855\n",
      "Training Loss: 0.007634417910594493\n",
      "Training Loss: 0.007371636667521671\n",
      "Training Loss: 0.004342909446568228\n",
      "Training Loss: 0.0006191514720558189\n",
      "Training Loss: 0.0004686034933547489\n",
      "Training Loss: 0.0004733626599045238\n",
      "Validation Loss: 0.0017980410623576052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007812471934594214\n",
      "Training Loss: 0.007617588528664783\n",
      "Training Loss: 0.00735225215787068\n",
      "Training Loss: 0.004331477259838721\n",
      "Training Loss: 0.0006173713017051341\n",
      "Training Loss: 0.0004669894397375174\n",
      "Training Loss: 0.0004687404436117504\n",
      "Validation Loss: 0.0017938813149832253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007797150091500953\n",
      "Training Loss: 0.0076002929790411145\n",
      "Training Loss: 0.007332251836778596\n",
      "Training Loss: 0.0043200296527356845\n",
      "Training Loss: 0.0006159980890515726\n",
      "Training Loss: 0.00046569073776481674\n",
      "Training Loss: 0.00046456469128315804\n",
      "Validation Loss: 0.0017898114725567178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007781254656147212\n",
      "Training Loss: 0.007582461906131357\n",
      "Training Loss: 0.007311553456820548\n",
      "Training Loss: 0.004308500298720901\n",
      "Training Loss: 0.0006149700968671823\n",
      "Training Loss: 0.00046465514686133246\n",
      "Training Loss: 0.00046076909988187255\n",
      "Validation Loss: 0.0017857555397991125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007764724070439115\n",
      "Training Loss: 0.0075640286202542486\n",
      "Training Loss: 0.007290081436512992\n",
      "Training Loss: 0.004296832482214086\n",
      "Training Loss: 0.0006142313531017862\n",
      "Training Loss: 0.0004638346096180612\n",
      "Training Loss: 0.00045729283570835835\n",
      "Validation Loss: 0.0017816287431384572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007747495966032148\n",
      "Training Loss: 0.0075449292617850005\n",
      "Training Loss: 0.007267764111747965\n",
      "Training Loss: 0.004284964551552548\n",
      "Training Loss: 0.0006137163039966253\n",
      "Training Loss: 0.00046317862725118173\n",
      "Training Loss: 0.0004540749068837613\n",
      "Validation Loss: 0.00177737477058693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007729516414692625\n",
      "Training Loss: 0.007525095496093854\n",
      "Training Loss: 0.007244531670585275\n",
      "Training Loss: 0.004272842326681712\n",
      "Training Loss: 0.0006133693275478436\n",
      "Training Loss: 0.00046264660639280916\n",
      "Training Loss: 0.00045106480713002383\n",
      "Validation Loss: 0.0017729448187269606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007710724434582516\n",
      "Training Loss: 0.007504463219083846\n",
      "Training Loss: 0.007220317216124385\n",
      "Training Loss: 0.004260416311735753\n",
      "Training Loss: 0.0006131392170937033\n",
      "Training Loss: 0.0004622018913505599\n",
      "Training Loss: 0.00044821464551205283\n",
      "Validation Loss: 0.0017682516850157876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007691056004259736\n",
      "Training Loss: 0.007482960331253707\n",
      "Training Loss: 0.007195056168129667\n",
      "Training Loss: 0.004247639849490952\n",
      "Training Loss: 0.000612972478629672\n",
      "Training Loss: 0.00046180711964552754\n",
      "Training Loss: 0.00044547852252435405\n",
      "Validation Loss: 0.0017632619393440068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007670463252579794\n",
      "Training Loss: 0.007460529509698972\n",
      "Training Loss: 0.007168691462138668\n",
      "Training Loss: 0.004234465524859843\n",
      "Training Loss: 0.0006128147381241433\n",
      "Training Loss: 0.0004614307568408549\n",
      "Training Loss: 0.0004428182788979029\n",
      "Validation Loss: 0.0017579060806199552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007648878504987806\n",
      "Training Loss: 0.007437098227674141\n",
      "Training Loss: 0.007141165172215551\n",
      "Training Loss: 0.004220861185531249\n",
      "Training Loss: 0.0006126245324412594\n",
      "Training Loss: 0.0004610467049496947\n",
      "Training Loss: 0.0004401946664438583\n",
      "Validation Loss: 0.0017521200719143853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007626258633099497\n",
      "Training Loss: 0.007412615749053657\n",
      "Training Loss: 0.007112434409791603\n",
      "Training Loss: 0.004206794031852042\n",
      "Training Loss: 0.000612350317023811\n",
      "Training Loss: 0.0004606253952806583\n",
      "Training Loss: 0.0004375734857603675\n",
      "Validation Loss: 0.0017458371875183273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007602561453823\n",
      "Training Loss: 0.0073870323947630824\n",
      "Training Loss: 0.0070824694051407275\n",
      "Training Loss: 0.004192242452336359\n",
      "Training Loss: 0.0006119508827396203\n",
      "Training Loss: 0.00046014392617507835\n",
      "Training Loss: 0.00043491879107023125\n",
      "Validation Loss: 0.0017389977817473348\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007577761129941791\n",
      "Training Loss: 0.0073603151505813\n",
      "Training Loss: 0.007051253519020975\n",
      "Training Loss: 0.004177195518641383\n",
      "Training Loss: 0.0006113757974526379\n",
      "Training Loss: 0.00045957011399877957\n",
      "Training Loss: 0.0004321933833853109\n",
      "Validation Loss: 0.0017315433429308195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00755185563932173\n",
      "Training Loss: 0.007332451783586293\n",
      "Training Loss: 0.007018797725904733\n",
      "Training Loss: 0.004161655492644059\n",
      "Training Loss: 0.0006105887441663072\n",
      "Training Loss: 0.0004588816043906263\n",
      "Training Loss: 0.0004293596524075838\n",
      "Validation Loss: 0.0017234078188355286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007524869398912415\n",
      "Training Loss: 0.0073034570703748615\n",
      "Training Loss: 0.006985136411385611\n",
      "Training Loss: 0.004145638509653509\n",
      "Training Loss: 0.0006095461321820039\n",
      "Training Loss: 0.0004580511327367276\n",
      "Training Loss: 0.0004263856277248124\n",
      "Validation Loss: 0.001714525244430698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007496857858495787\n",
      "Training Loss: 0.007273370164912194\n",
      "Training Loss: 0.006950332430424169\n",
      "Training Loss: 0.0041291819576872515\n",
      "Training Loss: 0.0006082171500747791\n",
      "Training Loss: 0.0004570531501667574\n",
      "Training Loss: 0.0004232342770410469\n",
      "Validation Loss: 0.0017048495624686177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007467918967595324\n",
      "Training Loss: 0.007242271098075435\n",
      "Training Loss: 0.006914489214541391\n",
      "Training Loss: 0.0041123436770431\n",
      "Training Loss: 0.0006065865341952304\n",
      "Training Loss: 0.00045587098800751845\n",
      "Training Loss: 0.0004198826359061059\n",
      "Validation Loss: 0.001694359055060583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0074381978111341595\n",
      "Training Loss: 0.0072102800256107005\n",
      "Training Loss: 0.006877740803174675\n",
      "Training Loss: 0.00409520435037848\n",
      "Training Loss: 0.0006046456240437693\n",
      "Training Loss: 0.00045448998684150866\n",
      "Training Loss: 0.0004163175651774509\n",
      "Validation Loss: 0.0016830527497898467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007407876470824704\n",
      "Training Loss: 0.007177550672786311\n",
      "Training Loss: 0.006840261552715674\n",
      "Training Loss: 0.0040778693240281425\n",
      "Training Loss: 0.00060241062703426\n",
      "Training Loss: 0.0004529112041200278\n",
      "Training Loss: 0.0004125375516741769\n",
      "Validation Loss: 0.0016709670221933587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007377189041581005\n",
      "Training Loss: 0.007144286538241431\n",
      "Training Loss: 0.006802261464763433\n",
      "Training Loss: 0.004060466512019047\n",
      "Training Loss: 0.0005999131807038794\n",
      "Training Loss: 0.00045114615288184724\n",
      "Training Loss: 0.0004085668105108198\n",
      "Validation Loss: 0.001658176873169215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007346386729041115\n",
      "Training Loss: 0.007110709534026682\n",
      "Training Loss: 0.006763977111550048\n",
      "Training Loss: 0.0040431410625024\n",
      "Training Loss: 0.0005972116338671185\n",
      "Training Loss: 0.00044922609398781785\n",
      "Training Loss: 0.00040444431666401213\n",
      "Validation Loss: 0.0016448119587560571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007315747219836339\n",
      "Training Loss: 0.00707708067027852\n",
      "Training Loss: 0.006725677233189345\n",
      "Training Loss: 0.004026047082079458\n",
      "Training Loss: 0.0005943831682088784\n",
      "Training Loss: 0.0004472011752659455\n",
      "Training Loss: 0.0004002383609622484\n",
      "Validation Loss: 0.0016310181256605151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007285546727944165\n",
      "Training Loss: 0.007043661479838192\n",
      "Training Loss: 0.006687632410321384\n",
      "Training Loss: 0.0040093414769944505\n",
      "Training Loss: 0.0005915137533884263\n",
      "Training Loss: 0.0004451258360859356\n",
      "Training Loss: 0.00039602723911229986\n",
      "Validation Loss: 0.0016170068304333486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007256040333304554\n",
      "Training Loss: 0.007010709205642343\n",
      "Training Loss: 0.00665010983706452\n",
      "Training Loss: 0.0039931738263112495\n",
      "Training Loss: 0.0005887102541601053\n",
      "Training Loss: 0.0004430799596229917\n",
      "Training Loss: 0.0003919099181803176\n",
      "Validation Loss: 0.0016030022750864999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007227435341337696\n",
      "Training Loss: 0.006978459404781461\n",
      "Training Loss: 0.006613362984498963\n",
      "Training Loss: 0.003977667431463487\n",
      "Training Loss: 0.000586066530449898\n",
      "Training Loss: 0.00044113189083873296\n",
      "Training Loss: 0.00038797284752945416\n",
      "Validation Loss: 0.001589221538769165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007199914152733982\n",
      "Training Loss: 0.006947121167322621\n",
      "Training Loss: 0.006577616763534025\n",
      "Training Loss: 0.003962923490107641\n",
      "Training Loss: 0.0005836711178562837\n",
      "Training Loss: 0.00043934980931226164\n",
      "Training Loss: 0.00038429793385148515\n",
      "Validation Loss: 0.0015758582164554366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007173588437726721\n",
      "Training Loss: 0.00691684591001831\n",
      "Training Loss: 0.006543041239492595\n",
      "Training Loss: 0.00394900667895854\n",
      "Training Loss: 0.0005815969782270258\n",
      "Training Loss: 0.000437789263050945\n",
      "Training Loss: 0.0003809491398715181\n",
      "Validation Loss: 0.001563094174493739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007148529505357147\n",
      "Training Loss: 0.006887748736189679\n",
      "Training Loss: 0.006509764567017556\n",
      "Training Loss: 0.003935948878643103\n",
      "Training Loss: 0.000579897342613549\n",
      "Training Loss: 0.0004364949368391535\n",
      "Training Loss: 0.0003779739813762717\n",
      "Validation Loss: 0.0015510497111691972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007124743977328762\n",
      "Training Loss: 0.0068598839815240354\n",
      "Training Loss: 0.006477863955078647\n",
      "Training Loss: 0.003923752327536932\n",
      "Training Loss: 0.0005786077481752727\n",
      "Training Loss: 0.00043549106627324366\n",
      "Training Loss: 0.00037539428543823303\n",
      "Validation Loss: 0.0015398149362465276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007102213009493426\n",
      "Training Loss: 0.0068332673038821665\n",
      "Training Loss: 0.006447362534236163\n",
      "Training Loss: 0.003912390181576484\n",
      "Training Loss: 0.0005777387526177336\n",
      "Training Loss: 0.0004347832612984348\n",
      "Training Loss: 0.0003732066825614311\n",
      "Validation Loss: 0.0015294320217755794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007080888256896287\n",
      "Training Loss: 0.006807882179273293\n",
      "Training Loss: 0.006418255561729893\n",
      "Training Loss: 0.003901817835358088\n",
      "Training Loss: 0.00057728694358957\n",
      "Training Loss: 0.00043436983331048397\n",
      "Training Loss: 0.0003714030205446761\n",
      "Validation Loss: 0.0015199080342644903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00706068888423033\n",
      "Training Loss: 0.006783674813341349\n",
      "Training Loss: 0.006390496654203162\n",
      "Training Loss: 0.0038919761832949006\n",
      "Training Loss: 0.0005772352094209055\n",
      "Training Loss: 0.0004342316502879839\n",
      "Training Loss: 0.000369950232343399\n",
      "Validation Loss: 0.0015112119309899784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007041537933982909\n",
      "Training Loss: 0.0067605850799009205\n",
      "Training Loss: 0.006364024269860238\n",
      "Training Loss: 0.0038828014289174462\n",
      "Training Loss: 0.000577555458075949\n",
      "Training Loss: 0.0004343461861571996\n",
      "Training Loss: 0.0003688166837673634\n",
      "Validation Loss: 0.0015032968953341656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007023349805967883\n",
      "Training Loss: 0.006738535689655691\n",
      "Training Loss: 0.006338756724726408\n",
      "Training Loss: 0.0038742245957109843\n",
      "Training Loss: 0.0005782219476532191\n",
      "Training Loss: 0.00043468902826134583\n",
      "Training Loss: 0.00036796535168832635\n",
      "Validation Loss: 0.0014961147853103554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007006030660122633\n",
      "Training Loss: 0.006717442087829113\n",
      "Training Loss: 0.006314608714310452\n",
      "Training Loss: 0.00386618477612501\n",
      "Training Loss: 0.0005791947354737203\n",
      "Training Loss: 0.00043522788226255213\n",
      "Training Loss: 0.00036736009635205845\n",
      "Validation Loss: 0.0014895931440985445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006989499075571075\n",
      "Training Loss: 0.006697226245887577\n",
      "Training Loss: 0.006291495027253405\n",
      "Training Loss: 0.003858618524973281\n",
      "Training Loss: 0.000580445729647181\n",
      "Training Loss: 0.00043593541078735143\n",
      "Training Loss: 0.0003669584984163521\n",
      "Validation Loss: 0.001483673064619362\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006973688169964589\n",
      "Training Loss: 0.006677817850140854\n",
      "Training Loss: 0.006269336928380653\n",
      "Training Loss: 0.0038514735663920875\n",
      "Training Loss: 0.0005819319316651673\n",
      "Training Loss: 0.000436780641466612\n",
      "Training Loss: 0.00036672740869107655\n",
      "Validation Loss: 0.001478286701756397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006958518641768024\n",
      "Training Loss: 0.006659146910533309\n",
      "Training Loss: 0.0062480574857909236\n",
      "Training Loss: 0.0038447004518820903\n",
      "Training Loss: 0.0005836190238187555\n",
      "Training Loss: 0.000437731694401009\n",
      "Training Loss: 0.0003666315800364828\n",
      "Validation Loss: 0.0014733740398141448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006943954367307015\n",
      "Training Loss: 0.006641165578039363\n",
      "Training Loss: 0.006227594128577038\n",
      "Training Loss: 0.0038382584576902444\n",
      "Training Loss: 0.0005854776090563974\n",
      "Training Loss: 0.0004387698667414952\n",
      "Training Loss: 0.0003666437954234425\n",
      "Validation Loss: 0.0014688853629099986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006929929499747232\n",
      "Training Loss: 0.006623814279446378\n",
      "Training Loss: 0.006207886452320963\n",
      "Training Loss: 0.003832111300507677\n",
      "Training Loss: 0.0005874667190801119\n",
      "Training Loss: 0.00043985919503029434\n",
      "Training Loss: 0.00036672894035291395\n",
      "Validation Loss: 0.0014647692604354942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006916418285109103\n",
      "Training Loss: 0.006607059130910784\n",
      "Training Loss: 0.006188888781471178\n",
      "Training Loss: 0.0038262278301408516\n",
      "Training Loss: 0.000589558189312811\n",
      "Training Loss: 0.0004409774461237248\n",
      "Training Loss: 0.0003668661489064107\n",
      "Validation Loss: 0.0014609785872918802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006903385139303282\n",
      "Training Loss: 0.006590869658393786\n",
      "Training Loss: 0.006170561813050881\n",
      "Training Loss: 0.003820582072075922\n",
      "Training Loss: 0.0005917179039533948\n",
      "Training Loss: 0.00044210482083144597\n",
      "Training Loss: 0.0003670307383436011\n",
      "Validation Loss: 0.0014574826280377136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006890805661678314\n",
      "Training Loss: 0.006575215884950012\n",
      "Training Loss: 0.006152871825033799\n",
      "Training Loss: 0.003815151414601132\n",
      "Training Loss: 0.0005939157740795053\n",
      "Training Loss: 0.0004432183337485185\n",
      "Training Loss: 0.0003672021580132423\n",
      "Validation Loss: 0.0014542443346958573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00687865972169675\n",
      "Training Loss: 0.006560081082861871\n",
      "Training Loss: 0.006135792289860546\n",
      "Training Loss: 0.003809917009639321\n",
      "Training Loss: 0.0005961272009881213\n",
      "Training Loss: 0.00044429691828554494\n",
      "Training Loss: 0.0003673613342834869\n",
      "Validation Loss: 0.0014512348140843653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006866932471166365\n",
      "Training Loss: 0.006545448452234268\n",
      "Training Loss: 0.00611930440296419\n",
      "Training Loss: 0.0038048621530469974\n",
      "Training Loss: 0.000598321495563141\n",
      "Training Loss: 0.00044532631116453556\n",
      "Training Loss: 0.0003674957378825638\n",
      "Validation Loss: 0.0014484252758112245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006855594748631119\n",
      "Training Loss: 0.006531296868342906\n",
      "Training Loss: 0.006103382618166506\n",
      "Training Loss: 0.0037999696695624153\n",
      "Training Loss: 0.0006004717888572486\n",
      "Training Loss: 0.00044628833733440843\n",
      "Training Loss: 0.0003675903971452499\n",
      "Validation Loss: 0.0014458032375487607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006844643511576578\n",
      "Training Loss: 0.006517617079662159\n",
      "Training Loss: 0.006088013102998957\n",
      "Training Loss: 0.003795232004267746\n",
      "Training Loss: 0.000602565202570986\n",
      "Training Loss: 0.00044717172437231057\n",
      "Training Loss: 0.00036763444710231853\n",
      "Validation Loss: 0.0014433429168457905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.00683406627329532\n",
      "Training Loss: 0.006504397234530188\n",
      "Training Loss: 0.006073180394014344\n",
      "Training Loss: 0.0037906316318549217\n",
      "Training Loss: 0.0006045780853310135\n",
      "Training Loss: 0.0004479657299816608\n",
      "Training Loss: 0.0003676238812477095\n",
      "Validation Loss: 0.0014410295491765186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006823836661642418\n",
      "Training Loss: 0.006491622781613842\n",
      "Training Loss: 0.006058871238492429\n",
      "Training Loss: 0.0037861635550507345\n",
      "Training Loss: 0.0006064944638637826\n",
      "Training Loss: 0.00044865934723929967\n",
      "Training Loss: 0.00036754426735569724\n",
      "Validation Loss: 0.0014388483204732367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006813964432803914\n",
      "Training Loss: 0.006479287662077695\n",
      "Training Loss: 0.0060450709325959905\n",
      "Training Loss: 0.003781814675676287\n",
      "Training Loss: 0.0006082956177851884\n",
      "Training Loss: 0.0004492451360420091\n",
      "Training Loss: 0.0003673973124386976\n",
      "Validation Loss: 0.0014367913540076875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006804403099813498\n",
      "Training Loss: 0.006467365431599319\n",
      "Training Loss: 0.006031760227051564\n",
      "Training Loss: 0.003777569637823035\n",
      "Training Loss: 0.000609970963705564\n",
      "Training Loss: 0.00044971721210458783\n",
      "Training Loss: 0.0003671774705435382\n",
      "Validation Loss: 0.0014348417159286764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006795163992210291\n",
      "Training Loss: 0.006455849661724642\n",
      "Training Loss: 0.00601892173755914\n",
      "Training Loss: 0.0037734280491713433\n",
      "Training Loss: 0.0006115165030496427\n",
      "Training Loss: 0.00045007247928879223\n",
      "Training Loss: 0.00036688374471850695\n",
      "Validation Loss: 0.001432992739278966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006786216613836587\n",
      "Training Loss: 0.006444720255676657\n",
      "Training Loss: 0.006006538461660966\n",
      "Training Loss: 0.003769378026772756\n",
      "Training Loss: 0.0006129263855109457\n",
      "Training Loss: 0.0004503169044619426\n",
      "Training Loss: 0.00036651911374065095\n",
      "Validation Loss: 0.0014312400509627738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006777535402798094\n",
      "Training Loss: 0.006433953268569894\n",
      "Training Loss: 0.005994588389876298\n",
      "Training Loss: 0.0037654068597475997\n",
      "Training Loss: 0.0006141832395951496\n",
      "Training Loss: 0.00045043707737931984\n",
      "Training Loss: 0.00036607947629818227\n",
      "Validation Loss: 0.0014295649235372253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006769124417915009\n",
      "Training Loss: 0.006423541161348112\n",
      "Training Loss: 0.0059830532607156785\n",
      "Training Loss: 0.0037615098336027586\n",
      "Training Loss: 0.0006152988656685921\n",
      "Training Loss: 0.00045044193167996125\n",
      "Training Loss: 0.0003655677738424856\n",
      "Validation Loss: 0.0014279677923607435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006760952856275253\n",
      "Training Loss: 0.00641345708980225\n",
      "Training Loss: 0.005971908423816785\n",
      "Training Loss: 0.0037576765191261073\n",
      "Training Loss: 0.000616267211662489\n",
      "Training Loss: 0.0004503331518935738\n",
      "Training Loss: 0.000364988553483272\n",
      "Validation Loss: 0.0014264422859290218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006753004648489877\n",
      "Training Loss: 0.00640368101070635\n",
      "Training Loss: 0.005961133528035134\n",
      "Training Loss: 0.0037539003377605696\n",
      "Training Loss: 0.0006170927617495181\n",
      "Training Loss: 0.00045011439302470533\n",
      "Training Loss: 0.00036434816480323206\n",
      "Validation Loss: 0.001424982237091335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006745253255940042\n",
      "Training Loss: 0.006394184778910131\n",
      "Training Loss: 0.005950698919477872\n",
      "Training Loss: 0.0037501751029776643\n",
      "Training Loss: 0.0006177783345628996\n",
      "Training Loss: 0.00044979212958423887\n",
      "Training Loss: 0.000363649661449017\n",
      "Validation Loss: 0.001423583789099634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006737682019011117\n",
      "Training Loss: 0.006384953053784556\n",
      "Training Loss: 0.00594058456888888\n",
      "Training Loss: 0.0037464911853385273\n",
      "Training Loss: 0.0006183275025250623\n",
      "Training Loss: 0.00044936656588106416\n",
      "Training Loss: 0.0003628947307151975\n",
      "Validation Loss: 0.0014222391483132825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006730280490592122\n",
      "Training Loss: 0.00637596127926372\n",
      "Training Loss: 0.005930768804391846\n",
      "Training Loss: 0.003742848221336317\n",
      "Training Loss: 0.0006187484238034813\n",
      "Training Loss: 0.00044884733528306243\n",
      "Training Loss: 0.000362091465794947\n",
      "Validation Loss: 0.0014209480565039124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006723028479027562\n",
      "Training Loss: 0.006367192036123015\n",
      "Training Loss: 0.0059212240006309\n",
      "Training Loss: 0.0037392289476338193\n",
      "Training Loss: 0.0006190418962796684\n",
      "Training Loss: 0.00044823941731010565\n",
      "Training Loss: 0.0003612413648806978\n",
      "Validation Loss: 0.0014197059906419622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00671590359939728\n",
      "Training Loss: 0.006358618989470415\n",
      "Training Loss: 0.005911929979920388\n",
      "Training Loss: 0.0037356344299405465\n",
      "Training Loss: 0.0006192182271479396\n",
      "Training Loss: 0.0004475497407838702\n",
      "Training Loss: 0.00036035152959811966\n",
      "Validation Loss: 0.001418506392310042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006708890241570771\n",
      "Training Loss: 0.006350219959858805\n",
      "Training Loss: 0.00590285932761617\n",
      "Training Loss: 0.003732063020506757\n",
      "Training Loss: 0.0006192909570381744\n",
      "Training Loss: 0.0004467862482124474\n",
      "Training Loss: 0.00035942975453508554\n",
      "Validation Loss: 0.0014173522590936864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.0067019795707892625\n",
      "Training Loss: 0.006341982629382983\n",
      "Training Loss: 0.005893998220562935\n",
      "Training Loss: 0.003728505522922205\n",
      "Training Loss: 0.0006192640349036082\n",
      "Training Loss: 0.0004459562424017349\n",
      "Training Loss: 0.00035848040446580855\n",
      "Validation Loss: 0.001416237088793859\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006695151283638552\n",
      "Training Loss: 0.006333882226026617\n",
      "Training Loss: 0.005885323692345992\n",
      "Training Loss: 0.003724953369492141\n",
      "Training Loss: 0.0006191371686873026\n",
      "Training Loss: 0.000445056574899354\n",
      "Training Loss: 0.000357499274177826\n",
      "Validation Loss: 0.0014151596580414024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006688398558180779\n",
      "Training Loss: 0.006325906094862149\n",
      "Training Loss: 0.005876816367963329\n",
      "Training Loss: 0.0037214070478148644\n",
      "Training Loss: 0.0006189215274935122\n",
      "Training Loss: 0.00044409881593310274\n",
      "Training Loss: 0.0003564989144797437\n",
      "Validation Loss: 0.0014141153109047129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006681709301192313\n",
      "Training Loss: 0.0063180406123865395\n",
      "Training Loss: 0.005868462823564187\n",
      "Training Loss: 0.0037178638547993616\n",
      "Training Loss: 0.00061862897942774\n",
      "Training Loss: 0.0004430926347413333\n",
      "Training Loss: 0.0003554853084642673\n",
      "Validation Loss: 0.0014131063517367935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006675059671979397\n",
      "Training Loss: 0.006310263515915722\n",
      "Training Loss: 0.0058602430520113555\n",
      "Training Loss: 0.0037143175241726566\n",
      "Training Loss: 0.000618258860486094\n",
      "Training Loss: 0.00044203686440596356\n",
      "Training Loss: 0.00035445376888674216\n",
      "Validation Loss: 0.0014121289258606537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006668458519270643\n",
      "Training Loss: 0.0063025698153069245\n",
      "Training Loss: 0.0058521460392512385\n",
      "Training Loss: 0.0037107659778484957\n",
      "Training Loss: 0.0006178194448875729\n",
      "Training Loss: 0.0004409387111081742\n",
      "Training Loss: 0.0003534127944294596\n",
      "Validation Loss: 0.0014111796668242343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006661887224181555\n",
      "Training Loss: 0.006294940581428818\n",
      "Training Loss: 0.005844154074438847\n",
      "Training Loss: 0.003707207202569407\n",
      "Training Loss: 0.000617327751169796\n",
      "Training Loss: 0.0004398060210223775\n",
      "Training Loss: 0.00035236769683251625\n",
      "Validation Loss: 0.0014102622778719546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0066553355584619564\n",
      "Training Loss: 0.006287364297313616\n",
      "Training Loss: 0.005836258953204379\n",
      "Training Loss: 0.003703637965081725\n",
      "Training Loss: 0.0006167746841674671\n",
      "Training Loss: 0.00043863900602445936\n",
      "Training Loss: 0.0003513182538881665\n",
      "Validation Loss: 0.0014093695576860804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006648802531999536\n",
      "Training Loss: 0.006279838870395907\n",
      "Training Loss: 0.005828449095133692\n",
      "Training Loss: 0.0037000529263241334\n",
      "Training Loss: 0.0006161716573842568\n",
      "Training Loss: 0.000437441576650599\n",
      "Training Loss: 0.0003502665364794666\n",
      "Validation Loss: 0.0014085055513447847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006642274524201639\n",
      "Training Loss: 0.006272343699820339\n",
      "Training Loss: 0.005820711120031774\n",
      "Training Loss: 0.003696456753386883\n",
      "Training Loss: 0.0006155204048991437\n",
      "Training Loss: 0.00043622077435429674\n",
      "Training Loss: 0.00034922058628580996\n",
      "Validation Loss: 0.0014076694497179802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006635748952976428\n",
      "Training Loss: 0.006264876401401125\n",
      "Training Loss: 0.0058130375813925635\n",
      "Training Loss: 0.003692840074909327\n",
      "Training Loss: 0.0006148322630906477\n",
      "Training Loss: 0.00043497895807377064\n",
      "Training Loss: 0.00034817874409782235\n",
      "Validation Loss: 0.001406857891613007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006629224520293064\n",
      "Training Loss: 0.006257429457036778\n",
      "Training Loss: 0.005805424107820727\n",
      "Training Loss: 0.0036892053637711795\n",
      "Training Loss: 0.0006141060408845078\n",
      "Training Loss: 0.0004337197529093828\n",
      "Training Loss: 0.00034714264667854875\n",
      "Validation Loss: 0.0014060711190440214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006622697119601071\n",
      "Training Loss: 0.006249999165884219\n",
      "Training Loss: 0.005797862383769825\n",
      "Training Loss: 0.003685553242175956\n",
      "Training Loss: 0.0006133503354067215\n",
      "Training Loss: 0.00043244519765721633\n",
      "Training Loss: 0.000346118405686866\n",
      "Validation Loss: 0.0014053065358839445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006616151617490687\n",
      "Training Loss: 0.006242575610522181\n",
      "Training Loss: 0.005790341775864362\n",
      "Training Loss: 0.0036818786588628427\n",
      "Training Loss: 0.0006125622135732555\n",
      "Training Loss: 0.0004311567971672048\n",
      "Training Loss: 0.00034510144912928807\n",
      "Validation Loss: 0.0014045699695480573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006609601607779041\n",
      "Training Loss: 0.006235155841568485\n",
      "Training Loss: 0.005782865570508875\n",
      "Training Loss: 0.003678180322276603\n",
      "Training Loss: 0.0006117449368321104\n",
      "Training Loss: 0.00042985813513951143\n",
      "Training Loss: 0.00034409933930874104\n",
      "Validation Loss: 0.0014038539835989166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006603029504767619\n",
      "Training Loss: 0.0062277294538216664\n",
      "Training Loss: 0.005775418075500056\n",
      "Training Loss: 0.0036744594526680885\n",
      "Training Loss: 0.0006108864205452846\n",
      "Training Loss: 0.00042855306597630263\n",
      "Training Loss: 0.0003431039499992039\n",
      "Validation Loss: 0.001403163073324792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006596434109378606\n",
      "Training Loss: 0.006220295520033687\n",
      "Training Loss: 0.005767997652292252\n",
      "Training Loss: 0.0036707210903114173\n",
      "Training Loss: 0.0006099983281455934\n",
      "Training Loss: 0.0004272394120198442\n",
      "Training Loss: 0.0003421188306674594\n",
      "Validation Loss: 0.0014024958095041518\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006589812648599036\n",
      "Training Loss: 0.006212845820700749\n",
      "Training Loss: 0.00576059743296355\n",
      "Training Loss: 0.0036669605105998926\n",
      "Training Loss: 0.0006090849234169582\n",
      "Training Loss: 0.0004259246772926417\n",
      "Training Loss: 0.00034115268088498853\n",
      "Validation Loss: 0.0014018492354276287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006583161494927481\n",
      "Training Loss: 0.006205379914608784\n",
      "Training Loss: 0.005753220127662644\n",
      "Training Loss: 0.0036631738526557455\n",
      "Training Loss: 0.0006081599042954622\n",
      "Training Loss: 0.00042460682099772386\n",
      "Training Loss: 0.0003402032826488721\n",
      "Validation Loss: 0.0014012263596900705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006576493772445247\n",
      "Training Loss: 0.006197905216831714\n",
      "Training Loss: 0.005745865452918224\n",
      "Training Loss: 0.0036593617026665017\n",
      "Training Loss: 0.0006072140442120144\n",
      "Training Loss: 0.00042328573788836366\n",
      "Training Loss: 0.00033927131411473963\n",
      "Validation Loss: 0.0014006259527091418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006569805076578632\n",
      "Training Loss: 0.006190416411263868\n",
      "Training Loss: 0.005738532660179771\n",
      "Training Loss: 0.003655528112431057\n",
      "Training Loss: 0.0006062626390485093\n",
      "Training Loss: 0.0004219689013189054\n",
      "Training Loss: 0.0003383625990318251\n",
      "Validation Loss: 0.001400049817096529\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006563083162764088\n",
      "Training Loss: 0.00618290770391468\n",
      "Training Loss: 0.005731215508421883\n",
      "Training Loss: 0.003651671539482777\n",
      "Training Loss: 0.0006053065331070684\n",
      "Training Loss: 0.0004206618023090414\n",
      "Training Loss: 0.0003374750385410152\n",
      "Validation Loss: 0.001399496629200213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006556334869237616\n",
      "Training Loss: 0.006175379308406264\n",
      "Training Loss: 0.0057239141152240335\n",
      "Training Loss: 0.0036477904346975264\n",
      "Training Loss: 0.0006043416733882622\n",
      "Training Loss: 0.00041935590455977946\n",
      "Training Loss: 0.000336612664104905\n",
      "Validation Loss: 0.001398969442388069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006549561257706955\n",
      "Training Loss: 0.006167835695669055\n",
      "Training Loss: 0.005716628661612049\n",
      "Training Loss: 0.0036438868231198286\n",
      "Training Loss: 0.0006033769412897527\n",
      "Training Loss: 0.0004180630319751799\n",
      "Training Loss: 0.0003357748518101289\n",
      "Validation Loss: 0.0013984700640134184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006542764005134813\n",
      "Training Loss: 0.006160272678243928\n",
      "Training Loss: 0.0057093603175599125\n",
      "Training Loss: 0.00363995654595783\n",
      "Training Loss: 0.000602404475066578\n",
      "Training Loss: 0.00041677280329167844\n",
      "Training Loss: 0.00033495705272798657\n",
      "Validation Loss: 0.0013979967004028307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006535948567325249\n",
      "Training Loss: 0.006152692589676007\n",
      "Training Loss: 0.005702105865930207\n",
      "Training Loss: 0.0036360101841273716\n",
      "Training Loss: 0.0006014422181760893\n",
      "Training Loss: 0.0004154985521381604\n",
      "Training Loss: 0.0003341677857679315\n",
      "Validation Loss: 0.0013975447277533683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.0065291011927183715\n",
      "Training Loss: 0.006145088127232157\n",
      "Training Loss: 0.005694863473763689\n",
      "Training Loss: 0.0036320412081840914\n",
      "Training Loss: 0.0006004799928632565\n",
      "Training Loss: 0.0004142355756266625\n",
      "Training Loss: 0.0003334054046717938\n",
      "Validation Loss: 0.0013971281432906821\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.0065222389466362074\n",
      "Training Loss: 0.00613746912102215\n",
      "Training Loss: 0.0056876362359616905\n",
      "Training Loss: 0.0036280475676903736\n",
      "Training Loss: 0.0005995201946643647\n",
      "Training Loss: 0.0004129842672409723\n",
      "Training Loss: 0.00033266652117163175\n",
      "Validation Loss: 0.0013967351221393582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006515358125907369\n",
      "Training Loss: 0.006129833069862798\n",
      "Training Loss: 0.00568042220082134\n",
      "Training Loss: 0.003624045568576548\n",
      "Training Loss: 0.0005985773845895892\n",
      "Training Loss: 0.00041174838737788376\n",
      "Training Loss: 0.0003319560112140607\n",
      "Validation Loss: 0.0013963725118475358\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006508457398158498\n",
      "Training Loss: 0.006122180612292141\n",
      "Training Loss: 0.0056732243887381625\n",
      "Training Loss: 0.0036200188194561635\n",
      "Training Loss: 0.000597634988007485\n",
      "Training Loss: 0.00041052598131500415\n",
      "Training Loss: 0.0003312695234126295\n",
      "Validation Loss: 0.0013960400678394867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006501542717451229\n",
      "Training Loss: 0.0061145149084040895\n",
      "Training Loss: 0.005666043210076168\n",
      "Training Loss: 0.003615978373745747\n",
      "Training Loss: 0.0005967037646769313\n",
      "Training Loss: 0.00040932199528469936\n",
      "Training Loss: 0.0003306130315468181\n",
      "Validation Loss: 0.001395737131055155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006494610220543109\n",
      "Training Loss: 0.006106833948288113\n",
      "Training Loss: 0.005658876395900733\n",
      "Training Loss: 0.0036119262388092464\n",
      "Training Loss: 0.0005957890611171024\n",
      "Training Loss: 0.000408134241879452\n",
      "Training Loss: 0.00032998002439853734\n",
      "Validation Loss: 0.001395467592905579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006487673082156107\n",
      "Training Loss: 0.006099141633021645\n",
      "Training Loss: 0.005651727583026514\n",
      "Training Loss: 0.0036078613076460896\n",
      "Training Loss: 0.0005948841373901814\n",
      "Training Loss: 0.00040695959000004223\n",
      "Training Loss: 0.0003293721864611143\n",
      "Validation Loss: 0.0013952304082144355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006480734230717644\n",
      "Training Loss: 0.0060914444562513385\n",
      "Training Loss: 0.005644597956561483\n",
      "Training Loss: 0.003603781806777988\n",
      "Training Loss: 0.0005939878652861807\n",
      "Training Loss: 0.0004058018231808092\n",
      "Training Loss: 0.0003287890087813139\n",
      "Validation Loss: 0.0013950227367149296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006473788438015617\n",
      "Training Loss: 0.006083736426080577\n",
      "Training Loss: 0.005637486076448112\n",
      "Training Loss: 0.0035997000286442926\n",
      "Training Loss: 0.0005931180296465755\n",
      "Training Loss: 0.0004046648407529574\n",
      "Training Loss: 0.0003282327806664398\n",
      "Validation Loss: 0.0013948520293146675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006466835898463614\n",
      "Training Loss: 0.006076023952336982\n",
      "Training Loss: 0.005630394493346102\n",
      "Training Loss: 0.003595611052842287\n",
      "Training Loss: 0.000592257016687654\n",
      "Training Loss: 0.00040354150802158985\n",
      "Training Loss: 0.00032769894325610947\n",
      "Validation Loss: 0.0013947156415436911\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006459889282705262\n",
      "Training Loss: 0.0060683110554236915\n",
      "Training Loss: 0.005623326255008578\n",
      "Training Loss: 0.003591513783467235\n",
      "Training Loss: 0.0005914106993441237\n",
      "Training Loss: 0.00040243414281576406\n",
      "Training Loss: 0.00032718628706788876\n",
      "Validation Loss: 0.0013946101473524908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006452951051760465\n",
      "Training Loss: 0.006060596548486501\n",
      "Training Loss: 0.005616279198438861\n",
      "Training Loss: 0.0035874165428685955\n",
      "Training Loss: 0.0005905842615175061\n",
      "Training Loss: 0.0004013450784259476\n",
      "Training Loss: 0.000326696424272086\n",
      "Validation Loss: 0.0013945425226676194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.0064460167003562675\n",
      "Training Loss: 0.006052884655073285\n",
      "Training Loss: 0.005609258612967096\n",
      "Training Loss: 0.0035833199149783467\n",
      "Training Loss: 0.0005897743401146727\n",
      "Training Loss: 0.00040027294970059303\n",
      "Training Loss: 0.000326231234066654\n",
      "Validation Loss: 0.001394510639939119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006439092440414243\n",
      "Training Loss: 0.006045178063213825\n",
      "Training Loss: 0.005602262903703376\n",
      "Training Loss: 0.0035792198496346827\n",
      "Training Loss: 0.0005889812901295954\n",
      "Training Loss: 0.0003992126970842946\n",
      "Training Loss: 0.00032578291567915586\n",
      "Validation Loss: 0.0013945139594108375\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 142\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006432192634092644\n",
      "Training Loss: 0.006037483693799004\n",
      "Training Loss: 0.005595295441453345\n",
      "Training Loss: 0.0035751258063464776\n",
      "Training Loss: 0.0005882013474911218\n",
      "Training Loss: 0.00039816770895413357\n",
      "Training Loss: 0.00032535400314372966\n",
      "Validation Loss: 0.0013945566342647836\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 143\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006425304661388509\n",
      "Training Loss: 0.006029793278430589\n",
      "Training Loss: 0.005588356938678771\n",
      "Training Loss: 0.003571041128016077\n",
      "Training Loss: 0.0005874431433767313\n",
      "Training Loss: 0.00039714069633191686\n",
      "Training Loss: 0.00032494327322638125\n",
      "Validation Loss: 0.0013946352367346481\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 144\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006418445791350678\n",
      "Training Loss: 0.006022118095424958\n",
      "Training Loss: 0.00558144700829871\n",
      "Training Loss: 0.0035669632905410255\n",
      "Training Loss: 0.0005867059619049542\n",
      "Training Loss: 0.0003961276747577358\n",
      "Training Loss: 0.0003245523358054925\n",
      "Validation Loss: 0.001394750959232706\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 145\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006411603713640943\n",
      "Training Loss: 0.0060144582873908805\n",
      "Training Loss: 0.005574570610770024\n",
      "Training Loss: 0.0035628937853471143\n",
      "Training Loss: 0.0005859806213265983\n",
      "Training Loss: 0.0003951258005326963\n",
      "Training Loss: 0.0003241768184670946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [20:10<06:08, 184.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0013949083711965924\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 146\n",
      "Early stopping after 146 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.10937363110482692\n",
      "Training Loss: 0.08665973082184791\n",
      "Training Loss: 0.07175491973757744\n",
      "Training Loss: 0.05348023339727661\n",
      "Training Loss: 0.04110849160701036\n",
      "Training Loss: 0.037932619592174886\n",
      "Training Loss: 0.038441222249530255\n",
      "Validation Loss: 0.04290564234058062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.05368460228666663\n",
      "Training Loss: 0.05113187726587057\n",
      "Training Loss: 0.04932602042332292\n",
      "Training Loss: 0.038229196095489894\n",
      "Training Loss: 0.02537280277349055\n",
      "Training Loss: 0.022526019071228802\n",
      "Training Loss: 0.02157270697876811\n",
      "Validation Loss: 0.02643883196909106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.03644685602746904\n",
      "Training Loss: 0.03334439183585346\n",
      "Training Loss: 0.031195006859488787\n",
      "Training Loss: 0.019653738387278283\n",
      "Training Loss: 0.0058177444018656385\n",
      "Training Loss: 0.004512134520628024\n",
      "Training Loss: 0.0035907892166869714\n",
      "Validation Loss: 0.012508728474287896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.022985836579464375\n",
      "Training Loss: 0.021046615703962743\n",
      "Training Loss: 0.020848296284675598\n",
      "Training Loss: 0.011831038344826083\n",
      "Training Loss: 0.002177230689849239\n",
      "Training Loss: 0.0019705398610676637\n",
      "Training Loss: 0.0018938391818664967\n",
      "Validation Loss: 0.008829120241152646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.019370588897727428\n",
      "Training Loss: 0.018024971028789877\n",
      "Training Loss: 0.01805248448625207\n",
      "Training Loss: 0.010257683434174396\n",
      "Training Loss: 0.0021774351966450923\n",
      "Training Loss: 0.0017748007507179865\n",
      "Training Loss: 0.0018009388330392539\n",
      "Validation Loss: 0.007217446860747433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.017023246057797224\n",
      "Training Loss: 0.016099550421349706\n",
      "Training Loss: 0.016202238202095032\n",
      "Training Loss: 0.00928120654367376\n",
      "Training Loss: 0.002120771596673876\n",
      "Training Loss: 0.0016658239587559365\n",
      "Training Loss: 0.0017895541441976092\n",
      "Validation Loss: 0.006273835444210746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.015299641038291156\n",
      "Training Loss: 0.014631702669430525\n",
      "Training Loss: 0.014744649059139192\n",
      "Training Loss: 0.00851608468394261\n",
      "Training Loss: 0.0020323397958418353\n",
      "Training Loss: 0.001583630526147317\n",
      "Training Loss: 0.0017763597855810075\n",
      "Validation Loss: 0.005622473251936113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.013925026578363031\n",
      "Training Loss: 0.013412660313770175\n",
      "Training Loss: 0.013501416631042958\n",
      "Training Loss: 0.007867934085661546\n",
      "Training Loss: 0.001951466719910968\n",
      "Training Loss: 0.0015251517936121673\n",
      "Training Loss: 0.0017588200446334668\n",
      "Validation Loss: 0.005118366846228751\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.012765704111661762\n",
      "Training Loss: 0.012354941586963833\n",
      "Training Loss: 0.012406282902229577\n",
      "Training Loss: 0.007302250391803682\n",
      "Training Loss: 0.0018815802919561974\n",
      "Training Loss: 0.0014800219779135659\n",
      "Training Loss: 0.0017337277106707915\n",
      "Validation Loss: 0.004693876114571014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011763872664887457\n",
      "Training Loss: 0.01142583244247362\n",
      "Training Loss: 0.011438491451554001\n",
      "Training Loss: 0.006806243050959893\n",
      "Training Loss: 0.0018167339364299551\n",
      "Training Loss: 0.0014389055944047868\n",
      "Training Loss: 0.0016983988470747136\n",
      "Validation Loss: 0.00431837670266112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010899419425986706\n",
      "Training Loss: 0.010617845701053738\n",
      "Training Loss: 0.010596054171910509\n",
      "Training Loss: 0.0063766553066670895\n",
      "Training Loss: 0.0017521095703705214\n",
      "Training Loss: 0.0013966930223978124\n",
      "Training Loss: 0.0016528697361354715\n",
      "Validation Loss: 0.00398110363053416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010167333881836384\n",
      "Training Loss: 0.00993152140174061\n",
      "Training Loss: 0.00988074077758938\n",
      "Training Loss: 0.006012888553377707\n",
      "Training Loss: 0.0016862223035423085\n",
      "Training Loss: 0.0013521433155983687\n",
      "Training Loss: 0.001599710259179119\n",
      "Validation Loss: 0.003680367360008385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009564962411532178\n",
      "Training Loss: 0.009366144931409508\n",
      "Training Loss: 0.00929092188598588\n",
      "Training Loss: 0.005713487534376327\n",
      "Training Loss: 0.0016204114136053249\n",
      "Training Loss: 0.0013065304003248457\n",
      "Training Loss: 0.0015429330544429831\n",
      "Validation Loss: 0.0034171162794033685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.0090862927865237\n",
      "Training Loss: 0.008916231147013605\n",
      "Training Loss: 0.00881969713489525\n",
      "Training Loss: 0.005474900074477773\n",
      "Training Loss: 0.0015573899913579226\n",
      "Training Loss: 0.0012621501662943046\n",
      "Training Loss: 0.0014867072345805354\n",
      "Validation Loss: 0.0031918201866744556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.00872047317097895\n",
      "Training Loss: 0.008571268589003011\n",
      "Training Loss: 0.008455350579461084\n",
      "Training Loss: 0.005291222452360671\n",
      "Training Loss: 0.0014998011938587297\n",
      "Training Loss: 0.0012211635573476088\n",
      "Training Loss: 0.0014343818926136009\n",
      "Validation Loss: 0.0030033746867245306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008452317916089669\n",
      "Training Loss: 0.00831675443216227\n",
      "Training Loss: 0.00818250784999691\n",
      "Training Loss: 0.005154515037138481\n",
      "Training Loss: 0.0014493756969750392\n",
      "Training Loss: 0.001185013195645297\n",
      "Training Loss: 0.0013880594029615167\n",
      "Validation Loss: 0.002849004568212948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008263731847982854\n",
      "Training Loss: 0.008135747443884612\n",
      "Training Loss: 0.007983710406115278\n",
      "Training Loss: 0.0050556200742721555\n",
      "Training Loss: 0.0014067906704440247\n",
      "Training Loss: 0.0011543604255712125\n",
      "Training Loss: 0.0013486831155023538\n",
      "Validation Loss: 0.0027247810272381322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008135748378699646\n",
      "Training Loss: 0.008010752440895885\n",
      "Training Loss: 0.007841317171696574\n",
      "Training Loss: 0.004985275933577214\n",
      "Training Loss: 0.00137189463886898\n",
      "Training Loss: 0.0011292352741293144\n",
      "Training Loss: 0.0013163133920170366\n",
      "Validation Loss: 0.0026261736468799163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00805062918458134\n",
      "Training Loss: 0.007925578814465553\n",
      "Training Loss: 0.007739343789871782\n",
      "Training Loss: 0.004935185877548065\n",
      "Training Loss: 0.0013440197333693504\n",
      "Training Loss: 0.0011092543622362428\n",
      "Training Loss: 0.0012904505894402974\n",
      "Validation Loss: 0.0025486034512945386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007993534029228613\n",
      "Training Loss: 0.00786677047261037\n",
      "Training Loss: 0.007664743158966303\n",
      "Training Loss: 0.004898679417965468\n",
      "Training Loss: 0.0013222300553752575\n",
      "Training Loss: 0.0010937938153801952\n",
      "Training Loss: 0.0012702855630777777\n",
      "Validation Loss: 0.002487815275381944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007953330067684873\n",
      "Training Loss: 0.00782426132587716\n",
      "Training Loss: 0.007607858307892457\n",
      "Training Loss: 0.004870901747781317\n",
      "Training Loss: 0.0013055100406927523\n",
      "Training Loss: 0.0010821341788687278\n",
      "Training Loss: 0.00125489473255584\n",
      "Validation Loss: 0.002440110585946164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007922507070470602\n",
      "Training Loss: 0.007791248235153034\n",
      "Training Loss: 0.007562129319412633\n",
      "Training Loss: 0.004848596914380323\n",
      "Training Loss: 0.0012928849959280343\n",
      "Training Loss: 0.001073552731249947\n",
      "Training Loss: 0.0012433562334626914\n",
      "Validation Loss: 0.0024024323209961493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007896499565104022\n",
      "Training Loss: 0.0077635486086364836\n",
      "Training Loss: 0.007523416086332873\n",
      "Training Loss: 0.004829724757000804\n",
      "Training Loss: 0.0012834813876543194\n",
      "Training Loss: 0.001067391655087704\n",
      "Training Loss: 0.001234834444912849\n",
      "Validation Loss: 0.0023723422128476956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007872815943555907\n",
      "Training Loss: 0.007738812696188689\n",
      "Training Loss: 0.007489250446669757\n",
      "Training Loss: 0.004813070257660002\n",
      "Training Loss: 0.0012765595319797285\n",
      "Training Loss: 0.0010630824753025082\n",
      "Training Loss: 0.001228612932463875\n",
      "Validation Loss: 0.0023479569285422604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00785024975775741\n",
      "Training Loss: 0.007715837029973045\n",
      "Training Loss: 0.007458217764506117\n",
      "Training Loss: 0.004797924394079018\n",
      "Training Loss: 0.0012715108040720225\n",
      "Training Loss: 0.001060156201274367\n",
      "Training Loss: 0.0012241052942408715\n",
      "Validation Loss: 0.0023278442552846887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007828316799132153\n",
      "Training Loss: 0.007694066939875483\n",
      "Training Loss: 0.007429526154883206\n",
      "Training Loss: 0.004783882305200677\n",
      "Training Loss: 0.0012678540727938524\n",
      "Training Loss: 0.0010582383515429683\n",
      "Training Loss: 0.0012208412241307086\n",
      "Validation Loss: 0.002310919330463211\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007806897456757725\n",
      "Training Loss: 0.007673287956276908\n",
      "Training Loss: 0.007402732295449823\n",
      "Training Loss: 0.00477070761990035\n",
      "Training Loss: 0.0012652109494956675\n",
      "Training Loss: 0.0010570341508719138\n",
      "Training Loss: 0.0012184535036794842\n",
      "Validation Loss: 0.002296382511075593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0077860337670426815\n",
      "Training Loss: 0.007653440146241337\n",
      "Training Loss: 0.007377581724431366\n",
      "Training Loss: 0.004758255080378149\n",
      "Training Loss: 0.0012632855703122914\n",
      "Training Loss: 0.0010563134995754807\n",
      "Training Loss: 0.001216660460777348\n",
      "Validation Loss: 0.0022836311847627276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0077658086118754\n",
      "Training Loss: 0.0076345214410685\n",
      "Training Loss: 0.0073539105767849835\n",
      "Training Loss: 0.0047464313535601835\n",
      "Training Loss: 0.0012618554005166516\n",
      "Training Loss: 0.0010559020479558967\n",
      "Training Loss: 0.0012152450322173536\n",
      "Validation Loss: 0.002272222632339943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007746311301598325\n",
      "Training Loss: 0.007616542740724981\n",
      "Training Loss: 0.007331602362683043\n",
      "Training Loss: 0.004735166435420979\n",
      "Training Loss: 0.0012607492900860962\n",
      "Training Loss: 0.0010556714971608017\n",
      "Training Loss: 0.0012140531998011284\n",
      "Validation Loss: 0.0022618344730753383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0077276017190888524\n",
      "Training Loss: 0.0075995043502189216\n",
      "Training Loss: 0.007310561751946807\n",
      "Training Loss: 0.0047244072530884295\n",
      "Training Loss: 0.0012598477916617413\n",
      "Training Loss: 0.0010555276024388149\n",
      "Training Loss: 0.0012129697364434832\n",
      "Validation Loss: 0.002252227225064471\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007709711724892258\n",
      "Training Loss: 0.007583388349739834\n",
      "Training Loss: 0.00729069986846298\n",
      "Training Loss: 0.004714107109757606\n",
      "Training Loss: 0.001259057275892701\n",
      "Training Loss: 0.0010554027995385695\n",
      "Training Loss: 0.0012119123410229804\n",
      "Validation Loss: 0.0022432243899260873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007692648280644789\n",
      "Training Loss: 0.007568166543496773\n",
      "Training Loss: 0.00727193683385849\n",
      "Training Loss: 0.0047042277851141985\n",
      "Training Loss: 0.0012583150425052737\n",
      "Training Loss: 0.0010552502451173496\n",
      "Training Loss: 0.001210825988164288\n",
      "Validation Loss: 0.002234701911438333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007676397756440565\n",
      "Training Loss: 0.007553791718091816\n",
      "Training Loss: 0.007254185256315395\n",
      "Training Loss: 0.00469473145523807\n",
      "Training Loss: 0.001257581252575619\n",
      "Training Loss: 0.0010550434964534362\n",
      "Training Loss: 0.0012096760090935276\n",
      "Validation Loss: 0.0022265600786790293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007660925625823438\n",
      "Training Loss: 0.007540210688021034\n",
      "Training Loss: 0.007237366673070938\n",
      "Training Loss: 0.004685584872786422\n",
      "Training Loss: 0.0012568224118149373\n",
      "Training Loss: 0.001054759849794209\n",
      "Training Loss: 0.0012084374751430004\n",
      "Validation Loss: 0.002218733600638144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007646194740664214\n",
      "Training Loss: 0.007527364630950615\n",
      "Training Loss: 0.007221400904236361\n",
      "Training Loss: 0.004676757759298198\n",
      "Training Loss: 0.0012560266430955381\n",
      "Training Loss: 0.001054392323276261\n",
      "Training Loss: 0.0012071012001251802\n",
      "Validation Loss: 0.002211172602070523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007632153118029237\n",
      "Training Loss: 0.007515189175028354\n",
      "Training Loss: 0.007206210895674303\n",
      "Training Loss: 0.004668218572624028\n",
      "Training Loss: 0.001255182692402741\n",
      "Training Loss: 0.0010539378273824696\n",
      "Training Loss: 0.0012056616937479703\n",
      "Validation Loss: 0.0022038392341531786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0076187486585695295\n",
      "Training Loss: 0.007503624602686614\n",
      "Training Loss: 0.007191727892495692\n",
      "Training Loss: 0.004659942042198963\n",
      "Training Loss: 0.001254284182941774\n",
      "Training Loss: 0.0010533933897386306\n",
      "Training Loss: 0.0012041153138852678\n",
      "Validation Loss: 0.0021966958315153555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007605927609838545\n",
      "Training Loss: 0.007492609889013692\n",
      "Training Loss: 0.007177883289987221\n",
      "Training Loss: 0.0046519043322769\n",
      "Training Loss: 0.001253332664637128\n",
      "Training Loss: 0.00105276276692166\n",
      "Training Loss: 0.0012024660729366588\n",
      "Validation Loss: 0.0021897281818955175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007593642441788688\n",
      "Training Loss: 0.007482088780961931\n",
      "Training Loss: 0.007164616194786504\n",
      "Training Loss: 0.004644081017759163\n",
      "Training Loss: 0.0012523278572916753\n",
      "Training Loss: 0.0010520504959276877\n",
      "Training Loss: 0.0012007192921009845\n",
      "Validation Loss: 0.002182914746061058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007581837358884513\n",
      "Training Loss: 0.007472003954462707\n",
      "Training Loss: 0.0071518662536982445\n",
      "Training Loss: 0.004636452090344392\n",
      "Training Loss: 0.0012512751206668327\n",
      "Training Loss: 0.0010512611642479897\n",
      "Training Loss: 0.0011988784129789564\n",
      "Validation Loss: 0.0021762389073598336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007570466189645231\n",
      "Training Loss: 0.007462309065740556\n",
      "Training Loss: 0.007139584842370823\n",
      "Training Loss: 0.004628996986575658\n",
      "Training Loss: 0.0012501702515146462\n",
      "Training Loss: 0.0010503937372413929\n",
      "Training Loss: 0.0011969430652970913\n",
      "Validation Loss: 0.002169686908945302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007559487674152479\n",
      "Training Loss: 0.0074529578851070255\n",
      "Training Loss: 0.007127723493613303\n",
      "Training Loss: 0.004621696320245974\n",
      "Training Loss: 0.001249018293528934\n",
      "Training Loss: 0.0010494552794261835\n",
      "Training Loss: 0.0011949202676623826\n",
      "Validation Loss: 0.00216325002261141\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007548857859801501\n",
      "Training Loss: 0.007443907294655219\n",
      "Training Loss: 0.007116238775197416\n",
      "Training Loss: 0.004614533416752237\n",
      "Training Loss: 0.0012478166566143045\n",
      "Training Loss: 0.0010484431499207859\n",
      "Training Loss: 0.0011928088451531949\n",
      "Validation Loss: 0.0021569157398152357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007538544202689081\n",
      "Training Loss: 0.0074351234652567655\n",
      "Training Loss: 0.007105094520375133\n",
      "Training Loss: 0.004607491478382144\n",
      "Training Loss: 0.0012465656633139587\n",
      "Training Loss: 0.0010473596754309255\n",
      "Training Loss: 0.0011906094789446797\n",
      "Validation Loss: 0.002150668984227587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007528507638489827\n",
      "Training Loss: 0.007426572514232248\n",
      "Training Loss: 0.007094259328441694\n",
      "Training Loss: 0.004600556570512709\n",
      "Training Loss: 0.0012452613993082196\n",
      "Training Loss: 0.0010462021405692212\n",
      "Training Loss: 0.0011883207805658458\n",
      "Validation Loss: 0.002144503432687037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0075187223055399955\n",
      "Training Loss: 0.007418225973378867\n",
      "Training Loss: 0.007083701299270615\n",
      "Training Loss: 0.004593711232882924\n",
      "Training Loss: 0.0012438985212793342\n",
      "Training Loss: 0.001044967298512347\n",
      "Training Loss: 0.001185938821727177\n",
      "Validation Loss: 0.002138406159931773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007509161352645606\n",
      "Training Loss: 0.007410057523520664\n",
      "Training Loss: 0.0070733949891291555\n",
      "Training Loss: 0.004586945665651001\n",
      "Training Loss: 0.001242472843005089\n",
      "Training Loss: 0.0010436501663934905\n",
      "Training Loss: 0.0011834584576718044\n",
      "Validation Loss: 0.00213236655963215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007499799454817549\n",
      "Training Loss: 0.00740204424597323\n",
      "Training Loss: 0.007063317683059722\n",
      "Training Loss: 0.0045802424012799745\n",
      "Training Loss: 0.0012409745250624837\n",
      "Training Loss: 0.001042243552801665\n",
      "Training Loss: 0.001180872276163427\n",
      "Validation Loss: 0.0021263742147969284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007490611451212317\n",
      "Training Loss: 0.007394163596909493\n",
      "Training Loss: 0.0070534490852151065\n",
      "Training Loss: 0.004573587870108895\n",
      "Training Loss: 0.0012393941939808429\n",
      "Training Loss: 0.0010407398350071161\n",
      "Training Loss: 0.0011781729284848553\n",
      "Validation Loss: 0.0021204194457319038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007481580997118726\n",
      "Training Loss: 0.007386399171082303\n",
      "Training Loss: 0.007043772244360298\n",
      "Training Loss: 0.004566968774888665\n",
      "Training Loss: 0.0012377195262524765\n",
      "Training Loss: 0.0010391282926138956\n",
      "Training Loss: 0.0011753481744381134\n",
      "Validation Loss: 0.002114485222554141\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007472681645303965\n",
      "Training Loss: 0.00737872980767861\n",
      "Training Loss: 0.007034268869319931\n",
      "Training Loss: 0.004560371856787242\n",
      "Training Loss: 0.0012359364549047313\n",
      "Training Loss: 0.0010373957789852283\n",
      "Training Loss: 0.0011723835574957776\n",
      "Validation Loss: 0.002108559064625515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.0074639014340937134\n",
      "Training Loss: 0.007371142377378419\n",
      "Training Loss: 0.007024925792356953\n",
      "Training Loss: 0.004553779123525601\n",
      "Training Loss: 0.0012340263003716245\n",
      "Training Loss: 0.0010355247736151796\n",
      "Training Loss: 0.0011692607849545312\n",
      "Validation Loss: 0.0021026248726226417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007455219315597787\n",
      "Training Loss: 0.007363618579693139\n",
      "Training Loss: 0.007015728732803836\n",
      "Training Loss: 0.004547176392079564\n",
      "Training Loss: 0.0012319689781725173\n",
      "Training Loss: 0.0010334991218405776\n",
      "Training Loss: 0.001165961462611449\n",
      "Validation Loss: 0.0020966685020839203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007446620791452006\n",
      "Training Loss: 0.007356145191006362\n",
      "Training Loss: 0.00700666612945497\n",
      "Training Loss: 0.004540542283211835\n",
      "Training Loss: 0.0012297398917144164\n",
      "Training Loss: 0.0010312944995530416\n",
      "Training Loss: 0.0011624593961460051\n",
      "Validation Loss: 0.002090665974614144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007438082421431318\n",
      "Training Loss: 0.007348702496383339\n",
      "Training Loss: 0.006997724305838346\n",
      "Training Loss: 0.004533860742521938\n",
      "Training Loss: 0.001227310766116716\n",
      "Training Loss: 0.0010288854500686284\n",
      "Training Loss: 0.0011587234333273954\n",
      "Validation Loss: 0.0020845948316484744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007429591525578871\n",
      "Training Loss: 0.007341275288490578\n",
      "Training Loss: 0.006988889789208769\n",
      "Training Loss: 0.004527104680746561\n",
      "Training Loss: 0.0012246490781399188\n",
      "Training Loss: 0.0010262396193866153\n",
      "Training Loss: 0.0011547194109152769\n",
      "Validation Loss: 0.002078433078430307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007421118362108245\n",
      "Training Loss: 0.0073338383005466315\n",
      "Training Loss: 0.006980147638823837\n",
      "Training Loss: 0.004520248714688932\n",
      "Training Loss: 0.001221713614067994\n",
      "Training Loss: 0.0010233192051236984\n",
      "Training Loss: 0.0011504009533382486\n",
      "Validation Loss: 0.0020721421449720746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007412647166056559\n",
      "Training Loss: 0.007326374966651201\n",
      "Training Loss: 0.006971485777758062\n",
      "Training Loss: 0.004513257673679618\n",
      "Training Loss: 0.0012184517800051253\n",
      "Training Loss: 0.0010200744977919385\n",
      "Training Loss: 0.0011457117249665317\n",
      "Validation Loss: 0.0020656840373676493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007404147918568924\n",
      "Training Loss: 0.007318854546174407\n",
      "Training Loss: 0.0069628824677783994\n",
      "Training Loss: 0.004506094856187701\n",
      "Training Loss: 0.0012148054318095092\n",
      "Training Loss: 0.0010164474885095843\n",
      "Training Loss: 0.0011405824813118671\n",
      "Validation Loss: 0.0020590112959898046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007395590954693034\n",
      "Training Loss: 0.007311242436990142\n",
      "Training Loss: 0.006954316521296277\n",
      "Training Loss: 0.004498708905593958\n",
      "Training Loss: 0.0012106984121783172\n",
      "Training Loss: 0.0010123658474185504\n",
      "Training Loss: 0.0011349238651018822\n",
      "Validation Loss: 0.0020520584915035616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007386936757247895\n",
      "Training Loss: 0.007303498190594837\n",
      "Training Loss: 0.006945760839153081\n",
      "Training Loss: 0.00449103754654061\n",
      "Training Loss: 0.0012060358182498022\n",
      "Training Loss: 0.001007736368046608\n",
      "Training Loss: 0.0011286250857665437\n",
      "Validation Loss: 0.002044753260777091\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007378140180371702\n",
      "Training Loss: 0.007295565566746518\n",
      "Training Loss: 0.006937178659718483\n",
      "Training Loss: 0.00448300528107211\n",
      "Training Loss: 0.001200699812034145\n",
      "Training Loss: 0.001002441100717988\n",
      "Training Loss: 0.0011215385689865797\n",
      "Validation Loss: 0.002036991435860036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007369141905801371\n",
      "Training Loss: 0.007287372832652181\n",
      "Training Loss: 0.006928519883658737\n",
      "Training Loss: 0.004474506969709182\n",
      "Training Loss: 0.0011945327708963304\n",
      "Training Loss: 0.0009963266940030734\n",
      "Training Loss: 0.0011134726413729369\n",
      "Validation Loss: 0.002028644554079807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007359866845654324\n",
      "Training Loss: 0.0072788256942294535\n",
      "Training Loss: 0.006919722550082952\n",
      "Training Loss: 0.004465409538825043\n",
      "Training Loss: 0.0011873298451246228\n",
      "Training Loss: 0.0009891883190721274\n",
      "Training Loss: 0.0011041692831349791\n",
      "Validation Loss: 0.002019538686912479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0073502173111774025\n",
      "Training Loss: 0.007269793192390353\n",
      "Training Loss: 0.006910693005193025\n",
      "Training Loss: 0.004455531303246971\n",
      "Training Loss: 0.001178825020979275\n",
      "Training Loss: 0.0009807590112905018\n",
      "Training Loss: 0.0010932800834416413\n",
      "Validation Loss: 0.0020094430826217186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007340056567918509\n",
      "Training Loss: 0.007260094439843669\n",
      "Training Loss: 0.006901306314393878\n",
      "Training Loss: 0.004444623747840524\n",
      "Training Loss: 0.0011686485767859267\n",
      "Training Loss: 0.000970668318332173\n",
      "Training Loss: 0.0010803192688763374\n",
      "Validation Loss: 0.001998040223104377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007329209215240553\n",
      "Training Loss: 0.007249478279845789\n",
      "Training Loss: 0.006891384111950174\n",
      "Training Loss: 0.004432337376347278\n",
      "Training Loss: 0.0011562991295795656\n",
      "Training Loss: 0.0009584101672226097\n",
      "Training Loss: 0.0010646125084895176\n",
      "Validation Loss: 0.001984892706456507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007317425914807245\n",
      "Training Loss: 0.007237581922672689\n",
      "Training Loss: 0.00688066860078834\n",
      "Training Loss: 0.0044181757667683995\n",
      "Training Loss: 0.0011410801779129542\n",
      "Training Loss: 0.0009432811284204945\n",
      "Training Loss: 0.0010451961139187915\n",
      "Validation Loss: 0.001969394853952505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007304365349700675\n",
      "Training Loss: 0.0072238917055074126\n",
      "Training Loss: 0.006868795535992831\n",
      "Training Loss: 0.004401426750118845\n",
      "Training Loss: 0.0011220264451549155\n",
      "Training Loss: 0.0009243064410111401\n",
      "Training Loss: 0.0010207147696928588\n",
      "Validation Loss: 0.001950706683591092\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007289547665277496\n",
      "Training Loss: 0.007207671198993921\n",
      "Training Loss: 0.00685525088571012\n",
      "Training Loss: 0.004381044268520782\n",
      "Training Loss: 0.0010978114367753732\n",
      "Training Loss: 0.000900159518350847\n",
      "Training Loss: 0.0009892866553855128\n",
      "Validation Loss: 0.0019276809592187153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007272319763433188\n",
      "Training Loss: 0.007187912568915635\n",
      "Training Loss: 0.006839355999836698\n",
      "Training Loss: 0.0043555302766617385\n",
      "Training Loss: 0.0010667032501805807\n",
      "Training Loss: 0.0008691356264171191\n",
      "Training Loss: 0.0009484803546365583\n",
      "Validation Loss: 0.001898812775828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007251811882015318\n",
      "Training Loss: 0.00716334096272476\n",
      "Training Loss: 0.00682029431220144\n",
      "Training Loss: 0.0043228029213787525\n",
      "Training Loss: 0.0010266968477662885\n",
      "Training Loss: 0.0008293224162480329\n",
      "Training Loss: 0.0008956273658986902\n",
      "Validation Loss: 0.0018621819351724792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007226933419005945\n",
      "Training Loss: 0.0071325597865507006\n",
      "Training Loss: 0.006797190235229209\n",
      "Training Loss: 0.004280183767987182\n",
      "Training Loss: 0.0009760792855377077\n",
      "Training Loss: 0.000779151201568311\n",
      "Training Loss: 0.0008288020057807444\n",
      "Validation Loss: 0.0018154711099358952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007196291772415862\n",
      "Training Loss: 0.007094054926419631\n",
      "Training Loss: 0.006768930408870801\n",
      "Training Loss: 0.004224652991397306\n",
      "Training Loss: 0.0009143570796004497\n",
      "Training Loss: 0.0007179750574869103\n",
      "Training Loss: 0.0007478260150674032\n",
      "Validation Loss: 0.001756939567426701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007157911744434387\n",
      "Training Loss: 0.007045154308434576\n",
      "Training Loss: 0.006733660605968908\n",
      "Training Loss: 0.004153762246132829\n",
      "Training Loss: 0.0008418600480945316\n",
      "Training Loss: 0.0006453196048096288\n",
      "Training Loss: 0.0006533974795456743\n",
      "Validation Loss: 0.0016929658083157956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007110544352326542\n",
      "Training Loss: 0.006981973631773144\n",
      "Training Loss: 0.006690463727572933\n",
      "Training Loss: 0.004070079502562294\n",
      "Training Loss: 0.000758431719004875\n",
      "Training Loss: 0.0005632062742370181\n",
      "Training Loss: 0.0005517352339666104\n",
      "Validation Loss: 0.0016525440322006757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.00705963769229129\n",
      "Training Loss: 0.006908627189695835\n",
      "Training Loss: 0.006640521865338087\n",
      "Training Loss: 0.003987909863935784\n",
      "Training Loss: 0.0006760505404236028\n",
      "Training Loss: 0.000491595838975627\n",
      "Training Loss: 0.00046845206750731447\n",
      "Validation Loss: 0.0016431833046975926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007005201930878684\n",
      "Training Loss: 0.006831532967044041\n",
      "Training Loss: 0.006578211291925981\n",
      "Training Loss: 0.003919902505440404\n",
      "Training Loss: 0.0006161156044981908\n",
      "Training Loss: 0.000447633735529962\n",
      "Training Loss: 0.00041660756116471023\n",
      "Validation Loss: 0.0016307885860932698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006939442690927535\n",
      "Training Loss: 0.00675288341823034\n",
      "Training Loss: 0.006507999122841284\n",
      "Training Loss: 0.0038680224724521395\n",
      "Training Loss: 0.000578110026253853\n",
      "Training Loss: 0.00042375936289317905\n",
      "Training Loss: 0.00038536867174116196\n",
      "Validation Loss: 0.0016102022524368915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006873561522224918\n",
      "Training Loss: 0.006682852408848703\n",
      "Training Loss: 0.006443286394933238\n",
      "Training Loss: 0.0038300514631555414\n",
      "Training Loss: 0.0005531399449682794\n",
      "Training Loss: 0.0004101726063890965\n",
      "Training Loss: 0.00036525157531286823\n",
      "Validation Loss: 0.0015891196301262755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006817861492745578\n",
      "Training Loss: 0.0066266944934614\n",
      "Training Loss: 0.00638960340176709\n",
      "Training Loss: 0.0038020348282589113\n",
      "Training Loss: 0.0005357161516440101\n",
      "Training Loss: 0.0004017835409467807\n",
      "Training Loss: 0.0003517718120565405\n",
      "Validation Loss: 0.001571563131337042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006773564979666844\n",
      "Training Loss: 0.006582582186674699\n",
      "Training Loss: 0.006345660081133246\n",
      "Training Loss: 0.003780278817212093\n",
      "Training Loss: 0.0005232009859537357\n",
      "Training Loss: 0.0003963255605412996\n",
      "Training Loss: 0.0003426570181181887\n",
      "Validation Loss: 0.0015585417156458714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006737960402388126\n",
      "Training Loss: 0.006546754611190408\n",
      "Training Loss: 0.006308601945638656\n",
      "Training Loss: 0.0037622443703003226\n",
      "Training Loss: 0.0005141220313089434\n",
      "Training Loss: 0.0003926771607802948\n",
      "Training Loss: 0.00033647731546807333\n",
      "Validation Loss: 0.001549737554345252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00670816729660146\n",
      "Training Loss: 0.006516169506357983\n",
      "Training Loss: 0.006276163989678025\n",
      "Training Loss: 0.003746413586413837\n",
      "Training Loss: 0.0005074974687158828\n",
      "Training Loss: 0.00039019272317091235\n",
      "Training Loss: 0.00033226454390387515\n",
      "Validation Loss: 0.0015444226060417998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006682170558487997\n",
      "Training Loss: 0.0064889116631820795\n",
      "Training Loss: 0.006246889936737716\n",
      "Training Loss: 0.0037319466391636524\n",
      "Training Loss: 0.000502638634025061\n",
      "Training Loss: 0.00038847103634907397\n",
      "Training Loss: 0.00032936551735474496\n",
      "Validation Loss: 0.0015419267054973345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006658748637419194\n",
      "Training Loss: 0.006463873999891802\n",
      "Training Loss: 0.006219855054514483\n",
      "Training Loss: 0.0037184159603930312\n",
      "Training Loss: 0.0004990730442295899\n",
      "Training Loss: 0.00038726217280782294\n",
      "Training Loss: 0.0003273557865031762\n",
      "Validation Loss: 0.0015417034088107252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0066371668875217435\n",
      "Training Loss: 0.006440402659354732\n",
      "Training Loss: 0.006194443751592189\n",
      "Training Loss: 0.0037055968123240746\n",
      "Training Loss: 0.0004964656953234225\n",
      "Training Loss: 0.00038641435552563055\n",
      "Training Loss: 0.0003259601976242266\n",
      "Validation Loss: 0.0015433591750493162\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 88\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00661694941460155\n",
      "Training Loss: 0.006418050405336544\n",
      "Training Loss: 0.0061702299246098845\n",
      "Training Loss: 0.003693369101492863\n",
      "Training Loss: 0.0004945804622184369\n",
      "Training Loss: 0.0003858265055168886\n",
      "Training Loss: 0.00032499635006388416\n",
      "Validation Loss: 0.001546574508657283\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 89\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006597734508104623\n",
      "Training Loss: 0.006396483660209924\n",
      "Training Loss: 0.006146906809881329\n",
      "Training Loss: 0.003681646196691872\n",
      "Training Loss: 0.0004932466155150905\n",
      "Training Loss: 0.00038542817819688937\n",
      "Training Loss: 0.00032434267111966617\n",
      "Validation Loss: 0.0015511067390621969\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 90\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006579243451124057\n",
      "Training Loss: 0.006375454093795269\n",
      "Training Loss: 0.006124264375539496\n",
      "Training Loss: 0.0036703533159015934\n",
      "Training Loss: 0.0004923329601660953\n",
      "Training Loss: 0.0003851672527162009\n",
      "Training Loss: 0.00032391294229455525\n",
      "Validation Loss: 0.00155676248875117\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 91\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006561274372506887\n",
      "Training Loss: 0.006354797675739974\n",
      "Training Loss: 0.006102166982600465\n",
      "Training Loss: 0.003659431409814715\n",
      "Training Loss: 0.0004917463891615625\n",
      "Training Loss: 0.00038500474711327114\n",
      "Training Loss: 0.00032364700215111955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [22:32<02:50, 170.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0015633878648984821\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 92\n",
      "Early stopping after 92 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.08765851907432079\n",
      "Training Loss: 0.07848652105778456\n",
      "Training Loss: 0.07522734712809324\n",
      "Training Loss: 0.06399551593000069\n",
      "Training Loss: 0.05157847401686013\n",
      "Training Loss: 0.04977309999987483\n",
      "Training Loss: 0.05186019850894809\n",
      "Validation Loss: 0.0573357804591178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06936112930998206\n",
      "Training Loss: 0.06780701661482454\n",
      "Training Loss: 0.06731115475296974\n",
      "Training Loss: 0.057649512332864104\n",
      "Training Loss: 0.045820904020220043\n",
      "Training Loss: 0.04354526371695101\n",
      "Training Loss: 0.04438008341938257\n",
      "Validation Loss: 0.049333533572123736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06125489231199026\n",
      "Training Loss: 0.05925880488008261\n",
      "Training Loss: 0.058146673832088706\n",
      "Training Loss: 0.04700055142617202\n",
      "Training Loss: 0.03493941595777869\n",
      "Training Loss: 0.03192602620460093\n",
      "Training Loss: 0.03133296987041831\n",
      "Validation Loss: 0.035606570538370574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04678928673267364\n",
      "Training Loss: 0.04371885433793068\n",
      "Training Loss: 0.04156384686008096\n",
      "Training Loss: 0.02948981139197713\n",
      "Training Loss: 0.017557368697598576\n",
      "Training Loss: 0.01492832847405225\n",
      "Training Loss: 0.0141245162114501\n",
      "Validation Loss: 0.01853072688232912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.029664409896358847\n",
      "Training Loss: 0.027945271860808134\n",
      "Training Loss: 0.027710688542574646\n",
      "Training Loss: 0.01823988287476823\n",
      "Training Loss: 0.008424014402553439\n",
      "Training Loss: 0.007616177723975852\n",
      "Training Loss: 0.007725388300605119\n",
      "Validation Loss: 0.01238577247663551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.023353713513351977\n",
      "Training Loss: 0.02221183553338051\n",
      "Training Loss: 0.022452646251767874\n",
      "Training Loss: 0.014206165284849703\n",
      "Training Loss: 0.005512330811470747\n",
      "Training Loss: 0.004982666841242462\n",
      "Training Loss: 0.005133661414729432\n",
      "Validation Loss: 0.009461530349095271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01973994911648333\n",
      "Training Loss: 0.018795061171986163\n",
      "Training Loss: 0.01910597609821707\n",
      "Training Loss: 0.011740448609925807\n",
      "Training Loss: 0.0039307523926254365\n",
      "Training Loss: 0.0034804760641418396\n",
      "Training Loss: 0.0036123536369996145\n",
      "Validation Loss: 0.007611456338476655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.017172819862607866\n",
      "Training Loss: 0.016374030667357146\n",
      "Training Loss: 0.01667052718112245\n",
      "Training Loss: 0.010003756396472455\n",
      "Training Loss: 0.0028940451802918687\n",
      "Training Loss: 0.0024791261833161118\n",
      "Training Loss: 0.0025807044852990658\n",
      "Validation Loss: 0.006307206917135568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.015232760503422468\n",
      "Training Loss: 0.014552811332978309\n",
      "Training Loss: 0.014798158460762352\n",
      "Training Loss: 0.00869877663149964\n",
      "Training Loss: 0.0021473137696739284\n",
      "Training Loss: 0.001768640991358552\n",
      "Training Loss: 0.0018468313166522421\n",
      "Validation Loss: 0.005368671840194557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013750138436444103\n",
      "Training Loss: 0.013150699452962726\n",
      "Training Loss: 0.013320837912615388\n",
      "Training Loss: 0.007730067023076117\n",
      "Training Loss: 0.0016463036253117026\n",
      "Training Loss: 0.001316449603473302\n",
      "Training Loss: 0.0013900531112449243\n",
      "Validation Loss: 0.004730082403699264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012625184943899512\n",
      "Training Loss: 0.012060457267798483\n",
      "Training Loss: 0.012155145017895847\n",
      "Training Loss: 0.007061956268589711\n",
      "Training Loss: 0.0013841253076680004\n",
      "Training Loss: 0.001103873012762051\n",
      "Training Loss: 0.001180792088416638\n",
      "Validation Loss: 0.004301253409401342\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011749739553779363\n",
      "Training Loss: 0.01122166817309335\n",
      "Training Loss: 0.011276568443281575\n",
      "Training Loss: 0.006619491267629201\n",
      "Training Loss: 0.0012819768734334503\n",
      "Training Loss: 0.0010387408621318173\n",
      "Training Loss: 0.0011146928217203823\n",
      "Validation Loss: 0.00398591896240017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.011063844631426036\n",
      "Training Loss: 0.010603480595164002\n",
      "Training Loss: 0.010643473238451407\n",
      "Training Loss: 0.006309544437390287\n",
      "Training Loss: 0.0012410844388796249\n",
      "Training Loss: 0.001021028570976341\n",
      "Training Loss: 0.0010954860971833114\n",
      "Validation Loss: 0.003733654798305862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010535979017149658\n",
      "Training Loss: 0.010150672462768852\n",
      "Training Loss: 0.010178034552372992\n",
      "Training Loss: 0.006070143492543138\n",
      "Training Loss: 0.0012090618921502027\n",
      "Training Loss: 0.0010034919103782158\n",
      "Training Loss: 0.0010800398889841746\n",
      "Validation Loss: 0.0035241193656154737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010128759392537177\n",
      "Training Loss: 0.009805421275086702\n",
      "Training Loss: 0.009816393584478646\n",
      "Training Loss: 0.005872633943072287\n",
      "Training Loss: 0.0011734238411008845\n",
      "Training Loss: 0.0009775704211642732\n",
      "Training Loss: 0.0010587736056186258\n",
      "Validation Loss: 0.003345859760611688\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009807696181815118\n",
      "Training Loss: 0.00952981700305827\n",
      "Training Loss: 0.0095219297404401\n",
      "Training Loss: 0.0057053610458388\n",
      "Training Loss: 0.0011352971350424923\n",
      "Training Loss: 0.0009463293969020015\n",
      "Training Loss: 0.001032802230110974\n",
      "Validation Loss: 0.003191343931156849\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009548946083523333\n",
      "Training Loss: 0.009303018425125629\n",
      "Training Loss: 0.009275724375620485\n",
      "Training Loss: 0.005563062152505154\n",
      "Training Loss: 0.0010975239407707705\n",
      "Training Loss: 0.0009135890164179727\n",
      "Training Loss: 0.0010048237831506413\n",
      "Validation Loss: 0.003055844440751479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009337713714921847\n",
      "Training Loss: 0.00911374323652126\n",
      "Training Loss: 0.00906769574736245\n",
      "Training Loss: 0.005442567512218375\n",
      "Training Loss: 0.0010620015025779139\n",
      "Training Loss: 0.0008818242896813899\n",
      "Training Loss: 0.0009769219040026656\n",
      "Validation Loss: 0.002936392466239858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009164573110174387\n",
      "Training Loss: 0.008955304131377488\n",
      "Training Loss: 0.008891728938324376\n",
      "Training Loss: 0.0053413303737761455\n",
      "Training Loss: 0.00102966760743584\n",
      "Training Loss: 0.0008523434075323167\n",
      "Training Loss: 0.0009503992234385806\n",
      "Validation Loss: 0.0028309864853704974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00902290400932543\n",
      "Training Loss: 0.008823099960573018\n",
      "Training Loss: 0.008743422657717019\n",
      "Training Loss: 0.00525697048062284\n",
      "Training Loss: 0.0010008208360522985\n",
      "Training Loss: 0.000825697298932937\n",
      "Training Loss: 0.0009259572683367878\n",
      "Validation Loss: 0.0027381451859872278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008907502066576853\n",
      "Training Loss: 0.008713414639933035\n",
      "Training Loss: 0.008619064848171548\n",
      "Training Loss: 0.005187166853720555\n",
      "Training Loss: 0.0009754090027854545\n",
      "Training Loss: 0.0008020096079417271\n",
      "Training Loss: 0.0009038986701852992\n",
      "Validation Loss: 0.002656601779178144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008813930896576495\n",
      "Training Loss: 0.008622941430658101\n",
      "Training Loss: 0.008515275530517102\n",
      "Training Loss: 0.0051296805765014145\n",
      "Training Loss: 0.000953170151260565\n",
      "Training Loss: 0.0007811515602224972\n",
      "Training Loss: 0.0008842558085234486\n",
      "Validation Loss: 0.002585185941276908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008738264791900293\n",
      "Training Loss: 0.008548609229037538\n",
      "Training Loss: 0.008428871498908848\n",
      "Training Loss: 0.005082407258014427\n",
      "Training Loss: 0.0009337553096702323\n",
      "Training Loss: 0.0007628670934354886\n",
      "Training Loss: 0.0008668905432568864\n",
      "Validation Loss: 0.0025227579257336764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00867704111034982\n",
      "Training Loss: 0.008487596571212635\n",
      "Training Loss: 0.008356934090843425\n",
      "Training Loss: 0.005043429208890302\n",
      "Training Loss: 0.0009167530580452876\n",
      "Training Loss: 0.0007468229437654372\n",
      "Training Loss: 0.0008515506146795815\n",
      "Validation Loss: 0.0024682056272253288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008627265298273415\n",
      "Training Loss: 0.008437368905870244\n",
      "Training Loss: 0.008296829207101836\n",
      "Training Loss: 0.0050110585116635775\n",
      "Training Loss: 0.0009017436708381865\n",
      "Training Loss: 0.0007326591757737333\n",
      "Training Loss: 0.0008379143603087869\n",
      "Validation Loss: 0.0024204635649831435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008586423663655297\n",
      "Training Loss: 0.00839572973549366\n",
      "Training Loss: 0.008246260776650161\n",
      "Training Loss: 0.004983856815306354\n",
      "Training Loss: 0.0008883249427162809\n",
      "Training Loss: 0.0007200244061459671\n",
      "Training Loss: 0.0008256545807125803\n",
      "Validation Loss: 0.002378529146438367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008552434067241847\n",
      "Training Loss: 0.008360815489431843\n",
      "Training Loss: 0.008203274777624756\n",
      "Training Loss: 0.004960629357447033\n",
      "Training Loss: 0.0008761277858138783\n",
      "Training Loss: 0.000708587420740514\n",
      "Training Loss: 0.0008144362028724572\n",
      "Validation Loss: 0.002341489864370266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008523650316055864\n",
      "Training Loss: 0.008331101851072163\n",
      "Training Loss: 0.008166253068484366\n",
      "Training Loss: 0.004940401583735365\n",
      "Training Loss: 0.0008648262870701728\n",
      "Training Loss: 0.0006980538515199441\n",
      "Training Loss: 0.0008039633318549022\n",
      "Validation Loss: 0.0023085374586447227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00849875564686954\n",
      "Training Loss: 0.008305349858710542\n",
      "Training Loss: 0.008133860504021867\n",
      "Training Loss: 0.004922390096253366\n",
      "Training Loss: 0.0008541438918473432\n",
      "Training Loss: 0.0006881717782380293\n",
      "Training Loss: 0.000793968228281301\n",
      "Validation Loss: 0.0022789702478180156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008476731773698702\n",
      "Training Loss: 0.008282575274351984\n",
      "Training Loss: 0.008105010879226028\n",
      "Training Loss: 0.004905967806516856\n",
      "Training Loss: 0.0008438508517429\n",
      "Training Loss: 0.0006787292350054486\n",
      "Training Loss: 0.0007842257365700788\n",
      "Validation Loss: 0.0022521848477345145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008456778494874015\n",
      "Training Loss: 0.008261992170009762\n",
      "Training Loss: 0.008078817420173436\n",
      "Training Loss: 0.004890632453680155\n",
      "Training Loss: 0.0008337603764084633\n",
      "Training Loss: 0.0006695542879242566\n",
      "Training Loss: 0.0007745520384196424\n",
      "Validation Loss: 0.0022276864576324376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.008438245651777834\n",
      "Training Loss: 0.008242953887674957\n",
      "Training Loss: 0.00805452888365835\n",
      "Training Loss: 0.004875966098043136\n",
      "Training Loss: 0.0008237255089625251\n",
      "Training Loss: 0.0006605128665978555\n",
      "Training Loss: 0.0007647940172137168\n",
      "Validation Loss: 0.0022050577110335344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.008420607515145093\n",
      "Training Loss: 0.00822493563289754\n",
      "Training Loss: 0.00803151250933297\n",
      "Training Loss: 0.004861619263792818\n",
      "Training Loss: 0.0008136345240927767\n",
      "Training Loss: 0.0006515008863425464\n",
      "Training Loss: 0.0007548327297627111\n",
      "Validation Loss: 0.0021839737146297097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.008403400015085936\n",
      "Training Loss: 0.008207477822434157\n",
      "Training Loss: 0.008009196830680593\n",
      "Training Loss: 0.0048472782390672365\n",
      "Training Loss: 0.0008034098587813787\n",
      "Training Loss: 0.0006424469105331809\n",
      "Training Loss: 0.0007445751037084846\n",
      "Validation Loss: 0.0021641781026705024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.008386196584906429\n",
      "Training Loss: 0.008190162783721462\n",
      "Training Loss: 0.007987043854082004\n",
      "Training Loss: 0.004832644908892689\n",
      "Training Loss: 0.0007930003336514346\n",
      "Training Loss: 0.000633302837213705\n",
      "Training Loss: 0.0007339447505728458\n",
      "Validation Loss: 0.002145479296930117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.008368582642870024\n",
      "Training Loss: 0.008172600548714399\n",
      "Training Loss: 0.00796453600283712\n",
      "Training Loss: 0.004817416935620713\n",
      "Training Loss: 0.0007823696488048882\n",
      "Training Loss: 0.0006240283883562369\n",
      "Training Loss: 0.0007228620994465018\n",
      "Validation Loss: 0.0021277608695241174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.008350141864502803\n",
      "Training Loss: 0.008154399709310383\n",
      "Training Loss: 0.00794113659998402\n",
      "Training Loss: 0.004801270255629788\n",
      "Training Loss: 0.0007715083639777731\n",
      "Training Loss: 0.0006146001397064537\n",
      "Training Loss: 0.0007112498109927401\n",
      "Validation Loss: 0.0021109708406297973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.008330419175326825\n",
      "Training Loss: 0.008135158483637496\n",
      "Training Loss: 0.007916280168574303\n",
      "Training Loss: 0.004783835324305982\n",
      "Training Loss: 0.0007604173327126773\n",
      "Training Loss: 0.0006049946808707318\n",
      "Training Loss: 0.0006990140362722741\n",
      "Validation Loss: 0.002095144614348387\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.008308917360845953\n",
      "Training Loss: 0.008114458959316834\n",
      "Training Loss: 0.007889373934594913\n",
      "Training Loss: 0.004764684492074594\n",
      "Training Loss: 0.0007491145855601644\n",
      "Training Loss: 0.0005951922492931772\n",
      "Training Loss: 0.0006860655489253987\n",
      "Validation Loss: 0.0020804335574402776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.008285058076726273\n",
      "Training Loss: 0.008091877558035776\n",
      "Training Loss: 0.0078598164988216\n",
      "Training Loss: 0.0047433514785734585\n",
      "Training Loss: 0.0007376689307420747\n",
      "Training Loss: 0.0005852162938754191\n",
      "Training Loss: 0.0006724039014625305\n",
      "Validation Loss: 0.0020671706403167884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.008258166606537998\n",
      "Training Loss: 0.008067031804239377\n",
      "Training Loss: 0.00782713013351895\n",
      "Training Loss: 0.004719430332261254\n",
      "Training Loss: 0.0007262672937213211\n",
      "Training Loss: 0.0005752381154161412\n",
      "Training Loss: 0.0006583558561214886\n",
      "Validation Loss: 0.002055818791707131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.008227504425449297\n",
      "Training Loss: 0.008039690965088084\n",
      "Training Loss: 0.0077912938059307634\n",
      "Training Loss: 0.0046928880794075666\n",
      "Training Loss: 0.0007153382371689076\n",
      "Training Loss: 0.0005657066653657239\n",
      "Training Loss: 0.0006448321817151736\n",
      "Validation Loss: 0.0020464587336602755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.008192643587244674\n",
      "Training Loss: 0.008009906265651807\n",
      "Training Loss: 0.007753128707408905\n",
      "Training Loss: 0.004664502087543951\n",
      "Training Loss: 0.0007054415321908891\n",
      "Training Loss: 0.0005571842454810394\n",
      "Training Loss: 0.0006329707206350577\n",
      "Validation Loss: 0.0020376268722031273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.008154312110273168\n",
      "Training Loss: 0.007978083275957034\n",
      "Training Loss: 0.007714052352821454\n",
      "Training Loss: 0.004635698524434701\n",
      "Training Loss: 0.0006968543647235492\n",
      "Training Loss: 0.0005499653221704648\n",
      "Training Loss: 0.0006231749905600736\n",
      "Validation Loss: 0.002026901190162179\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.008114612472709268\n",
      "Training Loss: 0.007945253915386275\n",
      "Training Loss: 0.0076754690054804085\n",
      "Training Loss: 0.004607713233635877\n",
      "Training Loss: 0.0006895253813490854\n",
      "Training Loss: 0.0005440217083014431\n",
      "Training Loss: 0.000615058291805326\n",
      "Validation Loss: 0.0020132931930358323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.008075674545252695\n",
      "Training Loss: 0.00791285140789114\n",
      "Training Loss: 0.0076385230419691655\n",
      "Training Loss: 0.004581191352081078\n",
      "Training Loss: 0.0006833099074356142\n",
      "Training Loss: 0.0005391373348538764\n",
      "Training Loss: 0.0006080720078534796\n",
      "Validation Loss: 0.001997492485745088\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.008038727294187992\n",
      "Training Loss: 0.007881872084690258\n",
      "Training Loss: 0.007603829351719469\n",
      "Training Loss: 0.004556354121705226\n",
      "Training Loss: 0.000678042388499307\n",
      "Training Loss: 0.0005350699418704607\n",
      "Training Loss: 0.0006018048331679893\n",
      "Validation Loss: 0.001980574969456257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.008004272946855052\n",
      "Training Loss: 0.007852746793068945\n",
      "Training Loss: 0.007571548722917214\n",
      "Training Loss: 0.004533228216314455\n",
      "Training Loss: 0.0006735579546148074\n",
      "Training Loss: 0.0005316238632985914\n",
      "Training Loss: 0.0005960169091667922\n",
      "Validation Loss: 0.0019633372622807617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00797241676482372\n",
      "Training Loss: 0.007825562005164101\n",
      "Training Loss: 0.007541603544959799\n",
      "Training Loss: 0.004511754039558582\n",
      "Training Loss: 0.0006697176052330178\n",
      "Training Loss: 0.0005286624719155952\n",
      "Training Loss: 0.0005905805178917944\n",
      "Validation Loss: 0.0019463150677298873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007943058257224038\n",
      "Training Loss: 0.00780024349107407\n",
      "Training Loss: 0.007513825648929924\n",
      "Training Loss: 0.004491834050459147\n",
      "Training Loss: 0.000666402182650927\n",
      "Training Loss: 0.0005260901829751675\n",
      "Training Loss: 0.0005854332751914626\n",
      "Validation Loss: 0.0019298574262846275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007915998527314514\n",
      "Training Loss: 0.007776643831748515\n",
      "Training Loss: 0.007488012028625235\n",
      "Training Loss: 0.004473346567610861\n",
      "Training Loss: 0.0006635152075978113\n",
      "Training Loss: 0.0005238337756964029\n",
      "Training Loss: 0.000580533946686046\n",
      "Validation Loss: 0.0019141525091014345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007891004660632462\n",
      "Training Loss: 0.007754589138785377\n",
      "Training Loss: 0.007463947236537934\n",
      "Training Loss: 0.004456165037190658\n",
      "Training Loss: 0.0006609805933112512\n",
      "Training Loss: 0.00052184183812642\n",
      "Training Loss: 0.0005758569690806326\n",
      "Validation Loss: 0.0018993245205510152\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007867838449310511\n",
      "Training Loss: 0.007733906989451498\n",
      "Training Loss: 0.007441424671560526\n",
      "Training Loss: 0.004440157166500285\n",
      "Training Loss: 0.0006587333357674652\n",
      "Training Loss: 0.000520066743301868\n",
      "Training Loss: 0.0005713802461468731\n",
      "Validation Loss: 0.0018853978476539857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007846272692549974\n",
      "Training Loss: 0.007714426290476695\n",
      "Training Loss: 0.007420245211105794\n",
      "Training Loss: 0.004425196909360238\n",
      "Training Loss: 0.0006567299999369425\n",
      "Training Loss: 0.0005184793869921123\n",
      "Training Loss: 0.0005670935333364469\n",
      "Validation Loss: 0.001872375622641972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007826089554000645\n",
      "Training Loss: 0.0076959866832476105\n",
      "Training Loss: 0.007400225347373635\n",
      "Training Loss: 0.00441116691006755\n",
      "Training Loss: 0.0006549310967966449\n",
      "Training Loss: 0.0005170508711307776\n",
      "Training Loss: 0.0005629799040798389\n",
      "Validation Loss: 0.0018602446662759136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0078070954384747895\n",
      "Training Loss: 0.007678443229524419\n",
      "Training Loss: 0.007381196711212397\n",
      "Training Loss: 0.004397956406137382\n",
      "Training Loss: 0.0006533065407711547\n",
      "Training Loss: 0.000515755974483909\n",
      "Training Loss: 0.0005590265718637966\n",
      "Validation Loss: 0.0018489447226992038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007789119378430769\n",
      "Training Loss: 0.0076616692473180596\n",
      "Training Loss: 0.00736300912918523\n",
      "Training Loss: 0.004385463468497619\n",
      "Training Loss: 0.0006518348867393797\n",
      "Training Loss: 0.0005145782958061318\n",
      "Training Loss: 0.0005552219216042431\n",
      "Validation Loss: 0.0018384080880634618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007772001435514539\n",
      "Training Loss: 0.007645544401602819\n",
      "Training Loss: 0.0073455253487918525\n",
      "Training Loss: 0.004373593721247744\n",
      "Training Loss: 0.0006504930366645567\n",
      "Training Loss: 0.0005134980998263927\n",
      "Training Loss: 0.0005515513345017098\n",
      "Validation Loss: 0.0018285914483205032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007755607684375718\n",
      "Training Loss: 0.007629969108384102\n",
      "Training Loss: 0.007328627215465531\n",
      "Training Loss: 0.0043622688276809644\n",
      "Training Loss: 0.0006492723630435648\n",
      "Training Loss: 0.0005125054699237808\n",
      "Training Loss: 0.0005480096792598488\n",
      "Validation Loss: 0.0018194424720308377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007739816477987915\n",
      "Training Loss: 0.0076148457394447176\n",
      "Training Loss: 0.007312204448971897\n",
      "Training Loss: 0.004351411142270081\n",
      "Training Loss: 0.0006481618711040938\n",
      "Training Loss: 0.0005115922908225912\n",
      "Training Loss: 0.0005445876256999326\n",
      "Validation Loss: 0.0018109039614201184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007724515456939116\n",
      "Training Loss: 0.007600093765649945\n",
      "Training Loss: 0.007296166802989319\n",
      "Training Loss: 0.004340954673389206\n",
      "Training Loss: 0.0006471504557703156\n",
      "Training Loss: 0.0005107440199935808\n",
      "Training Loss: 0.0005412719449668657\n",
      "Validation Loss: 0.0018029012005788812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007709617363288999\n",
      "Training Loss: 0.007585643688216805\n",
      "Training Loss: 0.007280436768196523\n",
      "Training Loss: 0.004330842075796681\n",
      "Training Loss: 0.0006462323151208693\n",
      "Training Loss: 0.0005099557877110783\n",
      "Training Loss: 0.0005380508946473128\n",
      "Validation Loss: 0.001795411008169913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007695044159190729\n",
      "Training Loss: 0.00757143336115405\n",
      "Training Loss: 0.007264946462819353\n",
      "Training Loss: 0.004321020544593921\n",
      "Training Loss: 0.0006453978721037856\n",
      "Training Loss: 0.0005092190766299609\n",
      "Training Loss: 0.0005349153533461504\n",
      "Validation Loss: 0.0017883825004785339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007680726983817294\n",
      "Training Loss: 0.007557407830609009\n",
      "Training Loss: 0.007249633412575349\n",
      "Training Loss: 0.004311441209647455\n",
      "Training Loss: 0.0006446415791288018\n",
      "Training Loss: 0.000508529169819667\n",
      "Training Loss: 0.000531852976164373\n",
      "Validation Loss: 0.001781790035149808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007666606000857428\n",
      "Training Loss: 0.007543514725985006\n",
      "Training Loss: 0.00723444701754488\n",
      "Training Loss: 0.004302064261501073\n",
      "Training Loss: 0.0006439558111742371\n",
      "Training Loss: 0.000507878139251261\n",
      "Training Loss: 0.0005288545396251721\n",
      "Validation Loss: 0.0017755864970608395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007652631629025563\n",
      "Training Loss: 0.0075297133019194004\n",
      "Training Loss: 0.007219345227349549\n",
      "Training Loss: 0.00429285350292048\n",
      "Training Loss: 0.0006433393992847414\n",
      "Training Loss: 0.0005072639352147235\n",
      "Training Loss: 0.0005259071103500901\n",
      "Validation Loss: 0.0017697379529983683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0076387659227475525\n",
      "Training Loss: 0.007515971143729985\n",
      "Training Loss: 0.007204294513212517\n",
      "Training Loss: 0.0042837754720676455\n",
      "Training Loss: 0.0006427803933183895\n",
      "Training Loss: 0.0005066800577333197\n",
      "Training Loss: 0.0005229987363418331\n",
      "Validation Loss: 0.0017642440379109785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007624963754788041\n",
      "Training Loss: 0.007502247798256576\n",
      "Training Loss: 0.007189257332356647\n",
      "Training Loss: 0.004274802516229101\n",
      "Training Loss: 0.0006422808899878874\n",
      "Training Loss: 0.0005061204064259072\n",
      "Training Loss: 0.0005201179964569746\n",
      "Validation Loss: 0.0017590531174613213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007611203434644267\n",
      "Training Loss: 0.007488521963823587\n",
      "Training Loss: 0.007174213995458558\n",
      "Training Loss: 0.0042659073599497785\n",
      "Training Loss: 0.0006418285337713314\n",
      "Training Loss: 0.0005055818316759542\n",
      "Training Loss: 0.0005172552516160067\n",
      "Validation Loss: 0.0017541722670412878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007597454533679411\n",
      "Training Loss: 0.007474762367783114\n",
      "Training Loss: 0.0071591354289557785\n",
      "Training Loss: 0.0042570691955188525\n",
      "Training Loss: 0.0006414227548521012\n",
      "Training Loss: 0.0005050609330646694\n",
      "Training Loss: 0.0005143970287099364\n",
      "Validation Loss: 0.0017495708739448668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007583696226356551\n",
      "Training Loss: 0.00746095136157237\n",
      "Training Loss: 0.007144005791051313\n",
      "Training Loss: 0.0042482673809718105\n",
      "Training Loss: 0.0006410580671945354\n",
      "Training Loss: 0.0005045537314435932\n",
      "Training Loss: 0.0005115353548535495\n",
      "Validation Loss: 0.0017452377775070966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0075699089746922256\n",
      "Training Loss: 0.007447067823959514\n",
      "Training Loss: 0.007128807202680037\n",
      "Training Loss: 0.004239483602432302\n",
      "Training Loss: 0.0006407324520114343\n",
      "Training Loss: 0.0005040581164939794\n",
      "Training Loss: 0.0005086598100751871\n",
      "Validation Loss: 0.001741176487355622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007556077147601172\n",
      "Training Loss: 0.007433094425359741\n",
      "Training Loss: 0.0071135255461558695\n",
      "Training Loss: 0.0042307033209363\n",
      "Training Loss: 0.0006404400344763416\n",
      "Training Loss: 0.0005035714021505556\n",
      "Training Loss: 0.0005057614403995103\n",
      "Validation Loss: 0.0017373714643340447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007542188605293631\n",
      "Training Loss: 0.0074190191319212315\n",
      "Training Loss: 0.007098150112433359\n",
      "Training Loss: 0.004221914878798998\n",
      "Training Loss: 0.0006401821972394828\n",
      "Training Loss: 0.0005030920699937269\n",
      "Training Loss: 0.0005028355217655189\n",
      "Validation Loss: 0.0017338169093678918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00752823299379088\n",
      "Training Loss: 0.007404825142584741\n",
      "Training Loss: 0.007082672205287963\n",
      "Training Loss: 0.004213105868620915\n",
      "Training Loss: 0.0006399513498035959\n",
      "Training Loss: 0.0005026162147260038\n",
      "Training Loss: 0.0004998719451759826\n",
      "Validation Loss: 0.0017304993914209188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007514204171020538\n",
      "Training Loss: 0.007390506834490225\n",
      "Training Loss: 0.00706708496902138\n",
      "Training Loss: 0.004204266911328886\n",
      "Training Loss: 0.0006397474628465716\n",
      "Training Loss: 0.0005021442913857755\n",
      "Training Loss: 0.0004968668375659036\n",
      "Validation Loss: 0.0017274362887500015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007500090795801952\n",
      "Training Loss: 0.007376052722102031\n",
      "Training Loss: 0.007051382637582719\n",
      "Training Loss: 0.004195390183595009\n",
      "Training Loss: 0.0006395710481592687\n",
      "Training Loss: 0.0005016763650928624\n",
      "Training Loss: 0.0004938154673800455\n",
      "Validation Loss: 0.0017245963517984564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007485892059048638\n",
      "Training Loss: 0.0073614610463846476\n",
      "Training Loss: 0.007035565370460972\n",
      "Training Loss: 0.004186471025022911\n",
      "Training Loss: 0.000639417124693864\n",
      "Training Loss: 0.0005012087475915905\n",
      "Training Loss: 0.0004907137346890523\n",
      "Validation Loss: 0.0017219997060830506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007471605567261576\n",
      "Training Loss: 0.007346727949334308\n",
      "Training Loss: 0.007019633406307548\n",
      "Training Loss: 0.0041775065843103225\n",
      "Training Loss: 0.000639287197845988\n",
      "Training Loss: 0.0005007438596658176\n",
      "Training Loss: 0.00048756165899249026\n",
      "Validation Loss: 0.0017196268950391053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007457231892039999\n",
      "Training Loss: 0.007331849456531927\n",
      "Training Loss: 0.007003584227059037\n",
      "Training Loss: 0.004168494456826011\n",
      "Training Loss: 0.0006391864731995156\n",
      "Training Loss: 0.0005002845441777026\n",
      "Training Loss: 0.00048436171229695904\n",
      "Validation Loss: 0.0017174773589901501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.00744276805780828\n",
      "Training Loss: 0.00731682555982843\n",
      "Training Loss: 0.006987422667443752\n",
      "Training Loss: 0.004159432550732162\n",
      "Training Loss: 0.0006391098781023174\n",
      "Training Loss: 0.0004998294507095125\n",
      "Training Loss: 0.00048111415871971986\n",
      "Validation Loss: 0.0017155528271615276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007428220034344121\n",
      "Training Loss: 0.0073016572068445385\n",
      "Training Loss: 0.006971151381731033\n",
      "Training Loss: 0.00415032745055214\n",
      "Training Loss: 0.0006390646897489205\n",
      "Training Loss: 0.0004993841247778618\n",
      "Training Loss: 0.0004778261666797334\n",
      "Validation Loss: 0.00171384563587156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0074135924223810434\n",
      "Training Loss: 0.007286351963412017\n",
      "Training Loss: 0.006954779127845541\n",
      "Training Loss: 0.004141178830832359\n",
      "Training Loss: 0.0006390498278051382\n",
      "Training Loss: 0.000498948932508938\n",
      "Training Loss: 0.00047450329693674573\n",
      "Validation Loss: 0.0017123288088124978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0073988891125191004\n",
      "Training Loss: 0.007270913567626849\n",
      "Training Loss: 0.006938314035069198\n",
      "Training Loss: 0.004131993435585173\n",
      "Training Loss: 0.0006390673079295084\n",
      "Training Loss: 0.0004985274297359865\n",
      "Training Loss: 0.00047115376870351613\n",
      "Validation Loss: 0.001711003936557727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0073841183469630775\n",
      "Training Loss: 0.007255350440973416\n",
      "Training Loss: 0.006921761990524828\n",
      "Training Loss: 0.0041227772228012325\n",
      "Training Loss: 0.0006391227534186328\n",
      "Training Loss: 0.0004981222722562961\n",
      "Training Loss: 0.000467787722373032\n",
      "Validation Loss: 0.001709831934297991\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007369292112998665\n",
      "Training Loss: 0.0072396715020295235\n",
      "Training Loss: 0.006905137446010485\n",
      "Training Loss: 0.004113534239004366\n",
      "Training Loss: 0.0006392123094701674\n",
      "Training Loss: 0.0004977365917147835\n",
      "Training Loss: 0.0004644159866438713\n",
      "Validation Loss: 0.001708814439696019\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0073544142337050285\n",
      "Training Loss: 0.00722388599999249\n",
      "Training Loss: 0.006888448434183374\n",
      "Training Loss: 0.0041042750576161776\n",
      "Training Loss: 0.0006393442026455887\n",
      "Training Loss: 0.0004973779236752307\n",
      "Training Loss: 0.0004610557786145364\n",
      "Validation Loss: 0.0017079203616856503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00733949174056761\n",
      "Training Loss: 0.007207996031502262\n",
      "Training Loss: 0.006871696857269853\n",
      "Training Loss: 0.004095008794029127\n",
      "Training Loss: 0.0006395251939829904\n",
      "Training Loss: 0.0004970506933750585\n",
      "Training Loss: 0.0004577200935091241\n",
      "Validation Loss: 0.0017071003142276897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007324533405480906\n",
      "Training Loss: 0.0071920176688581704\n",
      "Training Loss: 0.006854896851582453\n",
      "Training Loss: 0.00408574579309061\n",
      "Training Loss: 0.0006397517913137563\n",
      "Training Loss: 0.0004967550537548959\n",
      "Training Loss: 0.0004544255959262955\n",
      "Validation Loss: 0.001706328212332821\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007309548836201429\n",
      "Training Loss: 0.007175958334701135\n",
      "Training Loss: 0.006838057726854458\n",
      "Training Loss: 0.0040764922910966565\n",
      "Training Loss: 0.0006400280292291427\n",
      "Training Loss: 0.0004964990900407428\n",
      "Training Loss: 0.00045118776924937267\n",
      "Validation Loss: 0.0017055773415732675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.0072945428604725745\n",
      "Training Loss: 0.007159823027905077\n",
      "Training Loss: 0.006821180767146871\n",
      "Training Loss: 0.004067258450486406\n",
      "Training Loss: 0.0006403569530812092\n",
      "Training Loss: 0.0004962821154549602\n",
      "Training Loss: 0.00044802283198805523\n",
      "Validation Loss: 0.0017047935258771541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0072795260278508064\n",
      "Training Loss: 0.007143623345764354\n",
      "Training Loss: 0.006804271790897474\n",
      "Training Loss: 0.004058054333436303\n",
      "Training Loss: 0.0006407384496560553\n",
      "Training Loss: 0.0004961115570404217\n",
      "Training Loss: 0.0004449470194595051\n",
      "Validation Loss: 0.0017039337940383285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007264494491973892\n",
      "Training Loss: 0.0071273601346183565\n",
      "Training Loss: 0.006787330387160182\n",
      "Training Loss: 0.004048884702169744\n",
      "Training Loss: 0.0006411738459428306\n",
      "Training Loss: 0.0004959871025857865\n",
      "Training Loss: 0.0004419735547890014\n",
      "Validation Loss: 0.0017029437731797999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0072494594508316365\n",
      "Training Loss: 0.007111039356095717\n",
      "Training Loss: 0.006770358267240226\n",
      "Training Loss: 0.004039758739600075\n",
      "Training Loss: 0.0006416626158170402\n",
      "Training Loss: 0.0004959130629140418\n",
      "Training Loss: 0.00043911825963732553\n",
      "Validation Loss: 0.0017017976955113032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007234417429426685\n",
      "Training Loss: 0.007094662724994123\n",
      "Training Loss: 0.006753351090010256\n",
      "Training Loss: 0.004030681113181345\n",
      "Training Loss: 0.0006422042822669027\n",
      "Training Loss: 0.0004958862478815718\n",
      "Training Loss: 0.00043638858278427506\n",
      "Validation Loss: 0.0017004414403345436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007219371016835794\n",
      "Training Loss: 0.007078233365900815\n",
      "Training Loss: 0.006736308368854225\n",
      "Training Loss: 0.004021654067728377\n",
      "Training Loss: 0.0006427924984745915\n",
      "Training Loss: 0.0004959085434893495\n",
      "Training Loss: 0.0004337973058864009\n",
      "Validation Loss: 0.0016988303022038834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007204319419106469\n",
      "Training Loss: 0.007061744858510792\n",
      "Training Loss: 0.00671922103036195\n",
      "Training Loss: 0.004012678822982707\n",
      "Training Loss: 0.0006434235342749161\n",
      "Training Loss: 0.0004959768043408985\n",
      "Training Loss: 0.0004313488742991467\n",
      "Validation Loss: 0.0016969595136502862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007189254249678925\n",
      "Training Loss: 0.00704519470105879\n",
      "Training Loss: 0.006702077115187421\n",
      "Training Loss: 0.004003761171152292\n",
      "Training Loss: 0.0006441063581587514\n",
      "Training Loss: 0.0004960932650283212\n",
      "Training Loss: 0.0004290518827474443\n",
      "Validation Loss: 0.0016947753315077298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007174175975378603\n",
      "Training Loss: 0.007028578742174432\n",
      "Training Loss: 0.006684868151787668\n",
      "Training Loss: 0.003994897599550313\n",
      "Training Loss: 0.0006448284011275974\n",
      "Training Loss: 0.0004962595085817157\n",
      "Training Loss: 0.000426911363574618\n",
      "Validation Loss: 0.0016922567240620896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007159067053580656\n",
      "Training Loss: 0.007011883570812643\n",
      "Training Loss: 0.006667578056221828\n",
      "Training Loss: 0.0039860880310880024\n",
      "Training Loss: 0.0006455916365666781\n",
      "Training Loss: 0.0004964695741000468\n",
      "Training Loss: 0.00042492919150390664\n",
      "Validation Loss: 0.0016893998166343043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007143928398145363\n",
      "Training Loss: 0.006995104675879702\n",
      "Training Loss: 0.006650193452369422\n",
      "Training Loss: 0.003977328938999563\n",
      "Training Loss: 0.0006463904972042655\n",
      "Training Loss: 0.0004967214975113165\n",
      "Training Loss: 0.0004231050105590839\n",
      "Validation Loss: 0.0016861683327985023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007128746045054868\n",
      "Training Loss: 0.006978232507826761\n",
      "Training Loss: 0.006632705767406151\n",
      "Training Loss: 0.003968616099264181\n",
      "Training Loss: 0.0006472209414641838\n",
      "Training Loss: 0.0004970142182719428\n",
      "Training Loss: 0.000421437722943665\n",
      "Validation Loss: 0.0016825981307083703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007113517875550315\n",
      "Training Loss: 0.006961257882649079\n",
      "Training Loss: 0.00661509720608592\n",
      "Training Loss: 0.00395994699181756\n",
      "Training Loss: 0.0006480776460375637\n",
      "Training Loss: 0.0004973426561991801\n",
      "Training Loss: 0.000419926524937182\n",
      "Validation Loss: 0.001678661511365537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.007098230089759454\n",
      "Training Loss: 0.006944164976011961\n",
      "Training Loss: 0.006597352967364713\n",
      "Training Loss: 0.003951314592377457\n",
      "Training Loss: 0.000648963021376403\n",
      "Training Loss: 0.0004977097879600478\n",
      "Training Loss: 0.0004185700027846906\n",
      "Validation Loss: 0.0016743816954573382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.007082862988463603\n",
      "Training Loss: 0.006926937642274425\n",
      "Training Loss: 0.006579451226862147\n",
      "Training Loss: 0.003942713078104134\n",
      "Training Loss: 0.0006498736265348271\n",
      "Training Loss: 0.0004981122333992971\n",
      "Training Loss: 0.0004173679198720492\n",
      "Validation Loss: 0.0016697703346804967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007067406956339255\n",
      "Training Loss: 0.006909567887196317\n",
      "Training Loss: 0.006561384912347421\n",
      "Training Loss: 0.003934136907773791\n",
      "Training Loss: 0.0006508059010957367\n",
      "Training Loss: 0.000498548518444295\n",
      "Training Loss: 0.00041631166903243865\n",
      "Validation Loss: 0.0016648315767668648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0070518551394343374\n",
      "Training Loss: 0.006892045742133633\n",
      "Training Loss: 0.006543140307767317\n",
      "Training Loss: 0.003925580564318807\n",
      "Training Loss: 0.0006517522667854791\n",
      "Training Loss: 0.0004990138013818068\n",
      "Training Loss: 0.00041539870580891146\n",
      "Validation Loss: 0.0016596123389986932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.007036198099376634\n",
      "Training Loss: 0.00687435363070108\n",
      "Training Loss: 0.006524702683091164\n",
      "Training Loss: 0.003917036809798447\n",
      "Training Loss: 0.0006527155739604496\n",
      "Training Loss: 0.0004995117510770797\n",
      "Training Loss: 0.00041462630357273154\n",
      "Validation Loss: 0.0016541076252456714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.00702041374228429\n",
      "Training Loss: 0.006856481254799291\n",
      "Training Loss: 0.006506057170918211\n",
      "Training Loss: 0.003908495524628961\n",
      "Training Loss: 0.000653687441481452\n",
      "Training Loss: 0.0005000362710052286\n",
      "Training Loss: 0.0004139894091349561\n",
      "Validation Loss: 0.0016483577230301239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.007004495916189626\n",
      "Training Loss: 0.006838415305828675\n",
      "Training Loss: 0.006487194166984409\n",
      "Training Loss: 0.003899953481195553\n",
      "Training Loss: 0.0006546633226389531\n",
      "Training Loss: 0.0005005855400668224\n",
      "Training Loss: 0.0004134795766367461\n",
      "Validation Loss: 0.0016423984764715872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006988431304926053\n",
      "Training Loss: 0.006820146930404007\n",
      "Training Loss: 0.006468109135748818\n",
      "Training Loss: 0.003891400703869294\n",
      "Training Loss: 0.000655641033736174\n",
      "Training Loss: 0.0005011609412395046\n",
      "Training Loss: 0.0004130974743384286\n",
      "Validation Loss: 0.0016362397894836623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.0069722034747246656\n",
      "Training Loss: 0.0068016641668509695\n",
      "Training Loss: 0.006448791156290099\n",
      "Training Loss: 0.0038828359481703958\n",
      "Training Loss: 0.000656615583175153\n",
      "Training Loss: 0.0005017568562470842\n",
      "Training Loss: 0.00041283172784460474\n",
      "Validation Loss: 0.0016299346187749306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006955810688086785\n",
      "Training Loss: 0.006782965415623039\n",
      "Training Loss: 0.0064292396814562384\n",
      "Training Loss: 0.003874249271611916\n",
      "Training Loss: 0.0006575772014912218\n",
      "Training Loss: 0.0005023733044436085\n",
      "Training Loss: 0.0004126789702604583\n",
      "Validation Loss: 0.0016234944189372402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006939244467066601\n",
      "Training Loss: 0.006764049192424864\n",
      "Training Loss: 0.0064094540372025225\n",
      "Training Loss: 0.00386563848300284\n",
      "Training Loss: 0.0006585183112838422\n",
      "Training Loss: 0.0005030038636687095\n",
      "Training Loss: 0.00041263202010668467\n",
      "Validation Loss: 0.0016169500559725805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006922491147415713\n",
      "Training Loss: 0.0067449070827569815\n",
      "Training Loss: 0.006389441012870521\n",
      "Training Loss: 0.0038569969314994523\n",
      "Training Loss: 0.0006594312076049391\n",
      "Training Loss: 0.0005036480604758253\n",
      "Training Loss: 0.0004126830120185332\n",
      "Validation Loss: 0.0016103431237783031\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.0069055580772692336\n",
      "Training Loss: 0.0067255504918284715\n",
      "Training Loss: 0.006369205224327743\n",
      "Training Loss: 0.0038483259608983644\n",
      "Training Loss: 0.0006603094686579425\n",
      "Training Loss: 0.0005043020262746722\n",
      "Training Loss: 0.00041282603380750517\n",
      "Validation Loss: 0.001603710514293593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006888432411360554\n",
      "Training Loss: 0.0067059802683070305\n",
      "Training Loss: 0.006348761762492359\n",
      "Training Loss: 0.0038396204833043156\n",
      "Training Loss: 0.0006611373019404709\n",
      "Training Loss: 0.0005049568843605812\n",
      "Training Loss: 0.0004130517917838006\n",
      "Validation Loss: 0.0015970560048304827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006871126355254092\n",
      "Training Loss: 0.00668621665914543\n",
      "Training Loss: 0.0063281322794500735\n",
      "Training Loss: 0.003830881912217592\n",
      "Training Loss: 0.0006619102491822559\n",
      "Training Loss: 0.0005056109818178811\n",
      "Training Loss: 0.00041334712028401555\n",
      "Validation Loss: 0.0015904060900937295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006853644744260237\n",
      "Training Loss: 0.006666273600421846\n",
      "Training Loss: 0.0063073374738451095\n",
      "Training Loss: 0.003822112428388209\n",
      "Training Loss: 0.0006626109455464758\n",
      "Training Loss: 0.0005062560539226979\n",
      "Training Loss: 0.0004137080594955478\n",
      "Validation Loss: 0.0015838169925251003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006836001391639002\n",
      "Training Loss: 0.006646178538212553\n",
      "Training Loss: 0.00628641111543402\n",
      "Training Loss: 0.0038133170356741174\n",
      "Training Loss: 0.0006632321233337279\n",
      "Training Loss: 0.000506888031050039\n",
      "Training Loss: 0.00041412127680814595\n",
      "Validation Loss: 0.0015772776123378705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0068182077549863605\n",
      "Training Loss: 0.0066259602247737345\n",
      "Training Loss: 0.006265393217327073\n",
      "Training Loss: 0.00380450540666061\n",
      "Training Loss: 0.0006637584352938575\n",
      "Training Loss: 0.0005074933277865056\n",
      "Training Loss: 0.0004145724670343043\n",
      "Validation Loss: 0.001570823777137605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0068002981442259625\n",
      "Training Loss: 0.0066056607209611685\n",
      "Training Loss: 0.006244324109284207\n",
      "Training Loss: 0.003795681819901802\n",
      "Training Loss: 0.000664176071404654\n",
      "Training Loss: 0.0005080646926217014\n",
      "Training Loss: 0.00041505018478346753\n",
      "Validation Loss: 0.0015644680105641568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0067823039554059505\n",
      "Training Loss: 0.0065853259176947175\n",
      "Training Loss: 0.006223261535633355\n",
      "Training Loss: 0.0037868618349602913\n",
      "Training Loss: 0.0006644782296280027\n",
      "Training Loss: 0.0005086004109034547\n",
      "Training Loss: 0.00041554429288225947\n",
      "Validation Loss: 0.0015582226154988296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.00676425465149805\n",
      "Training Loss: 0.006565007081953809\n",
      "Training Loss: 0.006202258480479941\n",
      "Training Loss: 0.0037780627472238848\n",
      "Training Loss: 0.0006646540656583966\n",
      "Training Loss: 0.0005090828688480542\n",
      "Training Loss: 0.00041603799187214465\n",
      "Validation Loss: 0.001552108448242493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.00674620914447587\n",
      "Training Loss: 0.0065447675716131925\n",
      "Training Loss: 0.00618138779187575\n",
      "Training Loss: 0.0037692953440273415\n",
      "Training Loss: 0.0006646888097748161\n",
      "Training Loss: 0.0005095055827769101\n",
      "Training Loss: 0.00041651785861176907\n",
      "Validation Loss: 0.0015461380077730464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006728211353183724\n",
      "Training Loss: 0.006524666136829183\n",
      "Training Loss: 0.006160708997631445\n",
      "Training Loss: 0.00376058981881215\n",
      "Training Loss: 0.000664589135121787\n",
      "Training Loss: 0.0005098666148114717\n",
      "Training Loss: 0.000416972715738666\n",
      "Validation Loss: 0.0015403022354142566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006710314872907475\n",
      "Training Loss: 0.006504774009808898\n",
      "Training Loss: 0.006140298238024116\n",
      "Training Loss: 0.0037519592764147093\n",
      "Training Loss: 0.0006643343839095906\n",
      "Training Loss: 0.0005101448916684603\n",
      "Training Loss: 0.0004173862018797081\n",
      "Validation Loss: 0.0015346346135425193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006692594577325508\n",
      "Training Loss: 0.006485161720775068\n",
      "Training Loss: 0.00612022389890626\n",
      "Training Loss: 0.0037434402589860837\n",
      "Training Loss: 0.0006639445941254963\n",
      "Training Loss: 0.0005103508351385244\n",
      "Training Loss: 0.00041775479676289253\n",
      "Validation Loss: 0.001529115558713535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006675108024501242\n",
      "Training Loss: 0.006465900440234691\n",
      "Training Loss: 0.006100560902850703\n",
      "Training Loss: 0.003735046767978929\n",
      "Training Loss: 0.000663403409635066\n",
      "Training Loss: 0.0005104662353915046\n",
      "Training Loss: 0.0004180615279983613\n",
      "Validation Loss: 0.0015237901483188044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006657920659636147\n",
      "Training Loss: 0.006447059313068167\n",
      "Training Loss: 0.006081375700887293\n",
      "Training Loss: 0.003726808590363362\n",
      "Training Loss: 0.0006627250160090625\n",
      "Training Loss: 0.000510495195085241\n",
      "Training Loss: 0.0004183007511892356\n",
      "Validation Loss: 0.0015185990284207061\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006641102510038763\n",
      "Training Loss: 0.006428703065030277\n",
      "Training Loss: 0.00606273427605629\n",
      "Training Loss: 0.0037187503873064996\n",
      "Training Loss: 0.0006619139010217623\n",
      "Training Loss: 0.0005104352454509353\n",
      "Training Loss: 0.0004184683931816835\n",
      "Validation Loss: 0.0015136021720672773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0066247065429342914\n",
      "Training Loss: 0.0064108890085481105\n",
      "Training Loss: 0.00604468847042881\n",
      "Training Loss: 0.0037108965602965327\n",
      "Training Loss: 0.0006609851124449051\n",
      "Training Loss: 0.0005102904076193227\n",
      "Training Loss: 0.00041856204406940376\n",
      "Validation Loss: 0.0015087723161090838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006608794622588903\n",
      "Training Loss: 0.006393670326797291\n",
      "Training Loss: 0.006027289162157104\n",
      "Training Loss: 0.003703264117721119\n",
      "Training Loss: 0.0006599451423244318\n",
      "Training Loss: 0.000510059456792078\n",
      "Training Loss: 0.00041857707330564156\n",
      "Validation Loss: 0.0015040985760677952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006593416029354557\n",
      "Training Loss: 0.00637708876398392\n",
      "Training Loss: 0.006010573599487543\n",
      "Training Loss: 0.0036958765324015984\n",
      "Training Loss: 0.0006588138055667514\n",
      "Training Loss: 0.0005097522416326683\n",
      "Training Loss: 0.0004185193601733772\n",
      "Validation Loss: 0.0014996161591850242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006578604739625007\n",
      "Training Loss: 0.006361171944299713\n",
      "Training Loss: 0.005994563532294705\n",
      "Training Loss: 0.003688749605244084\n",
      "Training Loss: 0.0006576092849718407\n",
      "Training Loss: 0.0005093781566029065\n",
      "Training Loss: 0.0004183941435258021\n",
      "Validation Loss: 0.0014953029452415866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006564389267587103\n",
      "Training Loss: 0.006345938248559832\n",
      "Training Loss: 0.005979272903641686\n",
      "Training Loss: 0.0036818863498046996\n",
      "Training Loss: 0.0006563388998620212\n",
      "Training Loss: 0.0005089419812793494\n",
      "Training Loss: 0.0004182029531148146\n",
      "Validation Loss: 0.0014911423056494979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006550787624437362\n",
      "Training Loss: 0.00633139749057591\n",
      "Training Loss: 0.0059647074725944545\n",
      "Training Loss: 0.003675303504933254\n",
      "Training Loss: 0.0006550268114369828\n",
      "Training Loss: 0.0005084544157216442\n",
      "Training Loss: 0.0004179558049145271\n",
      "Validation Loss: 0.001487170184729403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0065378122573019936\n",
      "Training Loss: 0.006317548662191257\n",
      "Training Loss: 0.0059508611913770436\n",
      "Training Loss: 0.0036689966772974003\n",
      "Training Loss: 0.0006536888612390612\n",
      "Training Loss: 0.0005079277846016339\n",
      "Training Loss: 0.0004176592270778201\n",
      "Validation Loss: 0.0014833521383159623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.0065254606364760544\n",
      "Training Loss: 0.006304379992652685\n",
      "Training Loss: 0.005937714601168409\n",
      "Training Loss: 0.0036629698489196016\n",
      "Training Loss: 0.000652337380015524\n",
      "Training Loss: 0.0005073698928390513\n",
      "Training Loss: 0.0004173244360026729\n",
      "Validation Loss: 0.0014797261743222047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006513714921311475\n",
      "Training Loss: 0.006291868956759572\n",
      "Training Loss: 0.005925240482902154\n",
      "Training Loss: 0.0036572198708017824\n",
      "Training Loss: 0.0006509879258737783\n",
      "Training Loss: 0.0005067913785023847\n",
      "Training Loss: 0.00041695782763781605\n",
      "Validation Loss: 0.0014762342602279636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006502563012763858\n",
      "Training Loss: 0.006279988109599799\n",
      "Training Loss: 0.005913413605885581\n",
      "Training Loss: 0.0036517342417209876\n",
      "Training Loss: 0.0006496512694138801\n",
      "Training Loss: 0.0005062045584054431\n",
      "Training Loss: 0.00041656844132376136\n",
      "Validation Loss: 0.0014729176750206056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006491980096325278\n",
      "Training Loss: 0.006268710526637733\n",
      "Training Loss: 0.00590219818521291\n",
      "Training Loss: 0.0036465097787004197\n",
      "Training Loss: 0.0006483333841242711\n",
      "Training Loss: 0.0005056094175597537\n",
      "Training Loss: 0.00041616411244831396\n",
      "Validation Loss: 0.0014697655721003808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006481933705508709\n",
      "Training Loss: 0.006258001612732187\n",
      "Training Loss: 0.00589155966299586\n",
      "Training Loss: 0.003641535805654712\n",
      "Training Loss: 0.0006470480019561364\n",
      "Training Loss: 0.0005050180030593765\n",
      "Training Loss: 0.00041575065662982527\n",
      "Validation Loss: 0.0014667671387402553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0064723979105474425\n",
      "Training Loss: 0.006247819346608594\n",
      "Training Loss: 0.005881450496381149\n",
      "Training Loss: 0.0036368016390770207\n",
      "Training Loss: 0.0006457645331465756\n",
      "Training Loss: 0.000504430883047462\n",
      "Training Loss: 0.0004153301217411354\n",
      "Validation Loss: 0.001463926118761057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0064633358089486136\n",
      "Training Loss: 0.006238133239094168\n",
      "Training Loss: 0.005871840102481656\n",
      "Training Loss: 0.003632286159408977\n",
      "Training Loss: 0.0006444597470908774\n",
      "Training Loss: 0.0005038496584529639\n",
      "Training Loss: 0.0004149022310048167\n",
      "Validation Loss: 0.0014612591956883376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006454707648372277\n",
      "Training Loss: 0.006228900529677049\n",
      "Training Loss: 0.005862679263227619\n",
      "Training Loss: 0.003627986982974107\n",
      "Training Loss: 0.0006431982510184753\n",
      "Training Loss: 0.000503278111864347\n",
      "Training Loss: 0.0004144770308084844\n",
      "Validation Loss: 0.001458731510381917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0064464937848970295\n",
      "Training Loss: 0.00622008608886972\n",
      "Training Loss: 0.005853940155357122\n",
      "Training Loss: 0.0036238810231589012\n",
      "Training Loss: 0.0006419789586652769\n",
      "Training Loss: 0.0005027217746101087\n",
      "Training Loss: 0.0004140591787654557\n",
      "Validation Loss: 0.0014563494546206803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006438641845597885\n",
      "Training Loss: 0.0062116596288979056\n",
      "Training Loss: 0.005845587294315919\n",
      "Training Loss: 0.0036199624822620536\n",
      "Training Loss: 0.0006408060067042243\n",
      "Training Loss: 0.0005021787576333736\n",
      "Training Loss: 0.00041364891152625207\n",
      "Validation Loss: 0.0014540805824843064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006431155011523515\n",
      "Training Loss: 0.006203597671119496\n",
      "Training Loss: 0.005837599288206548\n",
      "Training Loss: 0.0036162167946167754\n",
      "Training Loss: 0.000639675742968393\n",
      "Training Loss: 0.000501648940044106\n",
      "Training Loss: 0.0004132473643767298\n",
      "Validation Loss: 0.001451941462145806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006423988178139553\n",
      "Training Loss: 0.006195864524925127\n",
      "Training Loss: 0.00582993736024946\n",
      "Training Loss: 0.0036126278318988625\n",
      "Training Loss: 0.0006385872446844587\n",
      "Training Loss: 0.0005011287370507489\n",
      "Training Loss: 0.0004128537189353665\n",
      "Validation Loss: 0.0014499199203285738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006417118310928345\n",
      "Training Loss: 0.006188437317032367\n",
      "Training Loss: 0.0058225820469669995\n",
      "Training Loss: 0.003609191431387444\n",
      "Training Loss: 0.0006375333223695634\n",
      "Training Loss: 0.0005006184636658872\n",
      "Training Loss: 0.00041246878117817687\n",
      "Validation Loss: 0.0014480099032723698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006410517548210919\n",
      "Training Loss: 0.006181287266081199\n",
      "Training Loss: 0.005815501901088283\n",
      "Training Loss: 0.003605892497507739\n",
      "Training Loss: 0.0006365146239841125\n",
      "Training Loss: 0.0005001157172955572\n",
      "Training Loss: 0.00041209027120203245\n",
      "Validation Loss: 0.0014461908303451906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006404176165815443\n",
      "Training Loss: 0.006174403680488467\n",
      "Training Loss: 0.005808686399832368\n",
      "Training Loss: 0.0036027200306125453\n",
      "Training Loss: 0.0006355253539368277\n",
      "Training Loss: 0.0004996194571867818\n",
      "Training Loss: 0.0004117166603100486\n",
      "Validation Loss: 0.0014444909447706863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.0063980684650596234\n",
      "Training Loss: 0.006167759555391967\n",
      "Training Loss: 0.005802108419593424\n",
      "Training Loss: 0.0035996688612067373\n",
      "Training Loss: 0.0006345663328102091\n",
      "Training Loss: 0.0004991285084543051\n",
      "Training Loss: 0.0004113519028760493\n",
      "Validation Loss: 0.0014428694525435793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0063921736477641385\n",
      "Training Loss: 0.006161340734688565\n",
      "Training Loss: 0.005795750146498904\n",
      "Training Loss: 0.0035967281298508167\n",
      "Training Loss: 0.0006336268116501742\n",
      "Training Loss: 0.0004986336073488928\n",
      "Training Loss: 0.000410986387214507\n",
      "Validation Loss: 0.001441332759231648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006386488464777358\n",
      "Training Loss: 0.006155131373088807\n",
      "Training Loss: 0.005789603417506442\n",
      "Training Loss: 0.0035938881065521854\n",
      "Training Loss: 0.0006327049804531271\n",
      "Training Loss: 0.0004981378639422473\n",
      "Training Loss: 0.00041062102225623674\n",
      "Validation Loss: 0.0014398918992742523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.00638098921335768\n",
      "Training Loss: 0.006149117033928632\n",
      "Training Loss: 0.005783643377944827\n",
      "Training Loss: 0.0035911466224933975\n",
      "Training Loss: 0.0006318039970210521\n",
      "Training Loss: 0.0004976405544221052\n",
      "Training Loss: 0.00041025778475159316\n",
      "Validation Loss: 0.0014385066815895684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006375662221107632\n",
      "Training Loss: 0.006143285515718162\n",
      "Training Loss: 0.0057778672873973844\n",
      "Training Loss: 0.0035884934143541616\n",
      "Training Loss: 0.0006309136278287042\n",
      "Training Loss: 0.0004971347907849121\n",
      "Training Loss: 0.00040989279050336337\n",
      "Validation Loss: 0.0014372023347839766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006370502341305837\n",
      "Training Loss: 0.006137628629803657\n",
      "Training Loss: 0.005772261755773798\n",
      "Training Loss: 0.0035859241696743994\n",
      "Training Loss: 0.0006300363832269795\n",
      "Training Loss: 0.0004966255253020791\n",
      "Training Loss: 0.000409526170224126\n",
      "Validation Loss: 0.0014359633746113948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006365497792139649\n",
      "Training Loss: 0.006132128426106647\n",
      "Training Loss: 0.005766808826010674\n",
      "Training Loss: 0.003583434338652296\n",
      "Training Loss: 0.0006291686752956594\n",
      "Training Loss: 0.0004961062235815917\n",
      "Training Loss: 0.0004091552089084871\n",
      "Validation Loss: 0.0014347743621710356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006360636822646484\n",
      "Training Loss: 0.006126782167702913\n",
      "Training Loss: 0.005761507005081512\n",
      "Training Loss: 0.00358101672893099\n",
      "Training Loss: 0.0006283086372422986\n",
      "Training Loss: 0.0004955815827270272\n",
      "Training Loss: 0.00040878435405829807\n",
      "Validation Loss: 0.0014336507315675499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006355906841927208\n",
      "Training Loss: 0.006121577135054394\n",
      "Training Loss: 0.0057563423336250705\n",
      "Training Loss: 0.003578665257373359\n",
      "Training Loss: 0.0006274541095262976\n",
      "Training Loss: 0.0004950428970187204\n",
      "Training Loss: 0.0004084066187533608\n",
      "Validation Loss: 0.0014325676818137591\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.0063513038691598925\n",
      "Training Loss: 0.006116509929997846\n",
      "Training Loss: 0.005751312805805355\n",
      "Training Loss: 0.0035763794954982585\n",
      "Training Loss: 0.0006265984968922566\n",
      "Training Loss: 0.0004944907835670165\n",
      "Training Loss: 0.00040802045577947865\n",
      "Validation Loss: 0.0014315239844991117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006346827516099438\n",
      "Training Loss: 0.0061115714046172795\n",
      "Training Loss: 0.005746407604310662\n",
      "Training Loss: 0.003574149912892608\n",
      "Training Loss: 0.0006257445739902323\n",
      "Training Loss: 0.0004939265163920936\n",
      "Training Loss: 0.0004076277177227894\n",
      "Validation Loss: 0.0014305403521221239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006342464146437124\n",
      "Training Loss: 0.006106756235240028\n",
      "Training Loss: 0.005741621520719491\n",
      "Training Loss: 0.0035719816947676008\n",
      "Training Loss: 0.0006248940560180927\n",
      "Training Loss: 0.0004933521369093796\n",
      "Training Loss: 0.00040723100455579696\n",
      "Validation Loss: 0.0014295983723406627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006338209321838804\n",
      "Training Loss: 0.006102056580130011\n",
      "Training Loss: 0.005736945171374828\n",
      "Training Loss: 0.0035698663169750943\n",
      "Training Loss: 0.0006240418826564565\n",
      "Training Loss: 0.0004927619892987423\n",
      "Training Loss: 0.00040682564473172535\n",
      "Validation Loss: 0.0014286783130301865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006334057009662501\n",
      "Training Loss: 0.00609746367088519\n",
      "Training Loss: 0.005732376826927066\n",
      "Training Loss: 0.0035677963533089496\n",
      "Training Loss: 0.0006231904864034732\n",
      "Training Loss: 0.0004921610745077487\n",
      "Training Loss: 0.0004064129876496736\n",
      "Validation Loss: 0.0014277982354065585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006330004571937025\n",
      "Training Loss: 0.0060929789254441855\n",
      "Training Loss: 0.005727909021079541\n",
      "Training Loss: 0.0035657758122397353\n",
      "Training Loss: 0.0006223353388850228\n",
      "Training Loss: 0.0004915448278916302\n",
      "Training Loss: 0.00040599150921480034\n",
      "Validation Loss: 0.0014269514020147807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006326041892752983\n",
      "Training Loss: 0.0060885910002980385\n",
      "Training Loss: 0.0057235358678735795\n",
      "Training Loss: 0.003563800992196775\n",
      "Training Loss: 0.0006214826256109518\n",
      "Training Loss: 0.0004909176467117505\n",
      "Training Loss: 0.00040556552125053713\n",
      "Validation Loss: 0.0014261225134780463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006322162188589573\n",
      "Training Loss: 0.006084298829082399\n",
      "Training Loss: 0.005719255444710143\n",
      "Training Loss: 0.003561867774478742\n",
      "Training Loss: 0.0006206185321207158\n",
      "Training Loss: 0.0004902740059696953\n",
      "Training Loss: 0.0004051304436325154\n",
      "Validation Loss: 0.001425337165416208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006318376236595214\n",
      "Training Loss: 0.006080097528174519\n",
      "Training Loss: 0.005715059555368498\n",
      "Training Loss: 0.003559973364099278\n",
      "Training Loss: 0.000619761120469775\n",
      "Training Loss: 0.0004896197744528763\n",
      "Training Loss: 0.0004046880543319276\n",
      "Validation Loss: 0.001424563819005578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006314662343356758\n",
      "Training Loss: 0.006075980867026373\n",
      "Training Loss: 0.005710946582257748\n",
      "Training Loss: 0.0035581206792994636\n",
      "Training Loss: 0.0006189025018829852\n",
      "Training Loss: 0.0004889574133630959\n",
      "Training Loss: 0.0004042410580404976\n",
      "Validation Loss: 0.0014238223436601157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006311028010095469\n",
      "Training Loss: 0.0060719505755696445\n",
      "Training Loss: 0.005706913927569985\n",
      "Training Loss: 0.0035562982869305417\n",
      "Training Loss: 0.0006180365196269122\n",
      "Training Loss: 0.0004882770852782414\n",
      "Training Loss: 0.00040378404668445\n",
      "Validation Loss: 0.0014230964006583576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006307466606376693\n",
      "Training Loss: 0.006067998259095475\n",
      "Training Loss: 0.005702956456225365\n",
      "Training Loss: 0.003554513510171091\n",
      "Training Loss: 0.000617171612502716\n",
      "Training Loss: 0.0004875888479000423\n",
      "Training Loss: 0.00040332334279810314\n",
      "Validation Loss: 0.0014223970634355263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006303976253839209\n",
      "Training Loss: 0.0060641187336295845\n",
      "Training Loss: 0.00569907253026031\n",
      "Training Loss: 0.0035527619249478446\n",
      "Training Loss: 0.0006163035549980123\n",
      "Training Loss: 0.0004868880934009212\n",
      "Training Loss: 0.00040285621036673547\n",
      "Validation Loss: 0.0014217147690397496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006300551633466966\n",
      "Training Loss: 0.006060312050394714\n",
      "Training Loss: 0.005695255587925203\n",
      "Training Loss: 0.0035510357737803134\n",
      "Training Loss: 0.0006154316050378839\n",
      "Training Loss: 0.0004861763705412159\n",
      "Training Loss: 0.0004023803267955373\n",
      "Validation Loss: 0.001421044435282761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006297187804011628\n",
      "Training Loss: 0.00605657396838069\n",
      "Training Loss: 0.005691504806163721\n",
      "Training Loss: 0.0035493426235916558\n",
      "Training Loss: 0.0006145599243973266\n",
      "Training Loss: 0.000485453430810594\n",
      "Training Loss: 0.00040190095342040877\n",
      "Validation Loss: 0.0014203915470920691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.00629388406756334\n",
      "Training Loss: 0.00605289880069904\n",
      "Training Loss: 0.0056878158455947415\n",
      "Training Loss: 0.0035476768719672693\n",
      "Training Loss: 0.0006136876521486556\n",
      "Training Loss: 0.0004847227342543192\n",
      "Training Loss: 0.0004014163995816489\n",
      "Validation Loss: 0.0014197562691441229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006290641750092618\n",
      "Training Loss: 0.006049293001415208\n",
      "Training Loss: 0.0056841908843489365\n",
      "Training Loss: 0.003546037795895245\n",
      "Training Loss: 0.0006128145163893351\n",
      "Training Loss: 0.0004839841157445335\n",
      "Training Loss: 0.0004009266356297303\n",
      "Validation Loss: 0.0014191403486225266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006287448196671903\n",
      "Training Loss: 0.006045741699635982\n",
      "Training Loss: 0.005680619074264541\n",
      "Training Loss: 0.003544426454900531\n",
      "Training Loss: 0.0006119398552982602\n",
      "Training Loss: 0.0004832363178866217\n",
      "Training Loss: 0.00040043309098109604\n",
      "Validation Loss: 0.001418532511144824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.00628431475663092\n",
      "Training Loss: 0.006042251897742972\n",
      "Training Loss: 0.005677104954374954\n",
      "Training Loss: 0.0035428390051674796\n",
      "Training Loss: 0.0006110677868491621\n",
      "Training Loss: 0.00048248099195916436\n",
      "Training Loss: 0.0003999352526079747\n",
      "Validation Loss: 0.0014179480118325595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006281230409513228\n",
      "Training Loss: 0.006038815621286631\n",
      "Training Loss: 0.005673644975759089\n",
      "Training Loss: 0.0035412756988807814\n",
      "Training Loss: 0.0006101933884201571\n",
      "Training Loss: 0.0004817186892250902\n",
      "Training Loss: 0.0003994334816161427\n",
      "Validation Loss: 0.0014173700849173332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006278198668733239\n",
      "Training Loss: 0.006035438003018498\n",
      "Training Loss: 0.005670237132580951\n",
      "Training Loss: 0.0035397351548454026\n",
      "Training Loss: 0.0006093181194592035\n",
      "Training Loss: 0.0004809450567699969\n",
      "Training Loss: 0.0003989251966413576\n",
      "Validation Loss: 0.0014168070082860992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006275213939952664\n",
      "Training Loss: 0.006032105276826769\n",
      "Training Loss: 0.005666876783943735\n",
      "Training Loss: 0.0035382163066242354\n",
      "Training Loss: 0.0006084445061424049\n",
      "Training Loss: 0.00048017098637501474\n",
      "Training Loss: 0.00039842049631261034\n",
      "Validation Loss: 0.0014162573170188068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006272264575818554\n",
      "Training Loss: 0.006028822623193264\n",
      "Training Loss: 0.0056635616812855\n",
      "Training Loss: 0.0035367172671976733\n",
      "Training Loss: 0.0006075703741589678\n",
      "Training Loss: 0.00047938857514964186\n",
      "Training Loss: 0.00039790885595721194\n",
      "Validation Loss: 0.001415722890955846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006269366730120965\n",
      "Training Loss: 0.006025587299373001\n",
      "Training Loss: 0.005660296472487971\n",
      "Training Loss: 0.0035352375610818855\n",
      "Training Loss: 0.0006067009511389188\n",
      "Training Loss: 0.00047860290345852263\n",
      "Training Loss: 0.0003973961050724029\n",
      "Validation Loss: 0.0014151947527918057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006266513085574843\n",
      "Training Loss: 0.006022396003827452\n",
      "Training Loss: 0.005657071259338409\n",
      "Training Loss: 0.0035337803268339486\n",
      "Training Loss: 0.0006058324843252194\n",
      "Training Loss: 0.0004778114701548475\n",
      "Training Loss: 0.00039688117438345215\n",
      "Validation Loss: 0.0014146737478458067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.0062636996910441665\n",
      "Training Loss: 0.006019250450190156\n",
      "Training Loss: 0.0056538917846046385\n",
      "Training Loss: 0.0035323408334807026\n",
      "Training Loss: 0.0006049613661161857\n",
      "Training Loss: 0.00047701393523311706\n",
      "Training Loss: 0.0003963636867047171\n",
      "Validation Loss: 0.0014141746823918353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006260924435337074\n",
      "Training Loss: 0.006016144510358572\n",
      "Training Loss: 0.005650748512125574\n",
      "Training Loss: 0.003530921276396839\n",
      "Training Loss: 0.0006040985850268043\n",
      "Training Loss: 0.00047621788831747836\n",
      "Training Loss: 0.00039584780199220404\n",
      "Validation Loss: 0.0014136700946767902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006258183951140381\n",
      "Training Loss: 0.006013079546391964\n",
      "Training Loss: 0.005647646390716545\n",
      "Training Loss: 0.0035295218382088932\n",
      "Training Loss: 0.0006032382692501415\n",
      "Training Loss: 0.00047541599906253396\n",
      "Training Loss: 0.0003953308742529771\n",
      "Validation Loss: 0.00141318658214086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006255476846708916\n",
      "Training Loss: 0.0060100516001693905\n",
      "Training Loss: 0.0056445789389545096\n",
      "Training Loss: 0.0035281333549210103\n",
      "Training Loss: 0.0006023776208530763\n",
      "Training Loss: 0.00047461356392886956\n",
      "Training Loss: 0.00039481140758653056\n",
      "Validation Loss: 0.0014127100126670451\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006252817110507749\n",
      "Training Loss: 0.006007062948774546\n",
      "Training Loss: 0.005641549906576984\n",
      "Training Loss: 0.00352676521637477\n",
      "Training Loss: 0.0006015249636402586\n",
      "Training Loss: 0.0004738101332623046\n",
      "Training Loss: 0.00039429419028238046\n",
      "Validation Loss: 0.0014122425674348337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006250178290647454\n",
      "Training Loss: 0.006004107326734811\n",
      "Training Loss: 0.005638555952464231\n",
      "Training Loss: 0.0035254138677555604\n",
      "Training Loss: 0.0006006715937837726\n",
      "Training Loss: 0.0004730002438009251\n",
      "Training Loss: 0.0003937741982008447\n",
      "Validation Loss: 0.001411789989436598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0062475764041300865\n",
      "Training Loss: 0.0060011894692434\n",
      "Training Loss: 0.005635597430518828\n",
      "Training Loss: 0.0035240776275895767\n",
      "Training Loss: 0.0005998229123724741\n",
      "Training Loss: 0.0004721905518817948\n",
      "Training Loss: 0.0003932559601889807\n",
      "Validation Loss: 0.0014113356985089854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00624501099344343\n",
      "Training Loss: 0.005998305386747234\n",
      "Training Loss: 0.005632673481595702\n",
      "Training Loss: 0.0035227583376399706\n",
      "Training Loss: 0.0005989757797578932\n",
      "Training Loss: 0.00047138030211499424\n",
      "Training Loss: 0.000392737569163728\n",
      "Validation Loss: 0.0014108941704285513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006242469298886135\n",
      "Training Loss: 0.005995451469789259\n",
      "Training Loss: 0.005629779158625752\n",
      "Training Loss: 0.00352145368247875\n",
      "Training Loss: 0.0005981378583237529\n",
      "Training Loss: 0.0004705695391749032\n",
      "Training Loss: 0.0003922200153101585\n",
      "Validation Loss: 0.001410465345979356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006239960440434515\n",
      "Training Loss: 0.0059926262788940225\n",
      "Training Loss: 0.005626912645529955\n",
      "Training Loss: 0.003520165313384496\n",
      "Training Loss: 0.0005973027781146812\n",
      "Training Loss: 0.0004697606026820722\n",
      "Training Loss: 0.00039170595207906446\n",
      "Validation Loss: 0.0014100441379317392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006237474670051597\n",
      "Training Loss: 0.005989832570194266\n",
      "Training Loss: 0.005624077025568113\n",
      "Training Loss: 0.0035188881855719957\n",
      "Training Loss: 0.0005964712046261411\n",
      "Training Loss: 0.00046894979434000564\n",
      "Training Loss: 0.00039119104802011863\n",
      "Validation Loss: 0.001409623477870009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006235018535517156\n",
      "Training Loss: 0.005987066458328627\n",
      "Training Loss: 0.005621272561256774\n",
      "Training Loss: 0.003517628785339184\n",
      "Training Loss: 0.0005956457060892717\n",
      "Training Loss: 0.0004681423974398058\n",
      "Training Loss: 0.0003906794079557585\n",
      "Validation Loss: 0.00140922161454988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006232592072337866\n",
      "Training Loss: 0.00598433187988121\n",
      "Training Loss: 0.005618495357921347\n",
      "Training Loss: 0.0035163763670425395\n",
      "Training Loss: 0.0005948219618949224\n",
      "Training Loss: 0.00046733235903957394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [27:37<00:00, 165.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00039016850061670996\n",
      "Validation Loss: 0.0014088216279635522\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = predictive_evaluation(data_real_numpy, data_syn_numpy, hyperparameters, include_baseline=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(DATA_FOLDER / f\"results/results_{syn_data_type}_{hyperparameters['num_epochs']}_{hyperparameters['num_evaluation_runs']}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_results = results.loc[results['Metric'] == 'MSE']\n",
    "mae_results = results.loc[results['Metric'] == 'MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28906876690>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Model', y='Error', hue='Model', data=mse_results)\n",
    "sns.stripplot(x='Model', y='Error', hue='Metric', data=mse_results, dodge=True, jitter=True, palette='dark:black', alpha=0.7)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Metric')\n",
    "plt.title(f'MSE | {syn_data_type} | {hyperparameters[\"num_evaluation_runs\"]} Training Runs {\" | jitter factor = \" + str(jitter_factor) if syn_data_type == \"jitter\" else \"\"}')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Model', y='Error', hue='Model', data=mae_results)\n",
    "sns.stripplot(x='Model', y='Error', hue='Metric', data=mae_results, dodge=True, jitter=True, palette='dark:black', alpha=0.7)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel('Metric')\n",
    "plt.title(f'MAE | {syn_data_type} | {hyperparameters[\"num_evaluation_runs\"]} Training Runs {\" | jitter factor = \" + str(jitter_factor) if syn_data_type == \"jitter\" else \"\"}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Evaluate Similarity of Synthetic vs Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Visualize Synthetic vs Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (28500, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "# split data before feeding into visual evaluation\n",
    "data_real_seq = split_data_into_sequences(data_real_numpy, seq_len=hyperparameters['seq_len'], shuffle_data=True)\n",
    "\n",
    "if data_syn_numpy.ndim == 3:\n",
    "    data_syn_seq = data_syn_numpy\n",
    "else:\n",
    "    data_syn_seq = split_data_into_sequences(data_syn_numpy, seq_len=hyperparameters['seq_len'], shuffle_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data. Shape: (28500, 12, 5)\n",
      "Data has been preprocessed. Shape: (1000, 60)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data. Shape: (28500, 12, 5)\n",
      "Data has been preprocessed. Shape: (1000, 60)\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 2000 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 2000 samples in 0.087s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fanny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1162: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2000\n",
      "[t-SNE] Mean sigma: 946.454922\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 58.231922\n",
      "[t-SNE] KL divergence after 300 iterations: 1.035306\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(data_real_seq, data_syn_seq, metric='pca')\n",
    "visualize(data_real_seq, data_syn_seq, metric='tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispielaussage:\n",
    "PCA-Analyse von Realen und Synthetischen Daten\n",
    "Um die Ähnlichkeit zwischen den realen und synthetischen Daten zu bewerten, wurde eine Principal Component Analysis (PCA) durchgeführt. Die PCA reduziert die Dimensionalität der Daten und projiziert sie auf eine zweidimensionale Ebene, wobei die Hauptkomponenten beibehalten werden, die den größten Teil der Varianz erklären.\n",
    "\n",
    "Abbildung X zeigt den PCA-Plot der realen (rote Punkte) und synthetischen Daten (blaue Punkte). Die folgenden Beobachtungen können gemacht werden:\n",
    "\n",
    "Verteilung und Clusterbildung:\n",
    "\n",
    "Die roten Punkte, die die realen Daten repräsentieren, sind in einem spezifischen Bereich konzentriert.\n",
    "Die blauen Punkte, die die synthetischen Daten darstellen, zeigen eine größere Verteilung und decken einen breiteren Bereich ab.\n",
    "Ähnlichkeit und Unterschiede:\n",
    "\n",
    "Die Tatsache, dass die synthetischen Daten eine größere Variabilität aufweisen, könnte darauf hinweisen, dass sie eine breitere Vielfalt an Mustern generieren.\n",
    "Die Cluster der realen und synthetischen Daten überlappen sich teilweise, was darauf hindeutet, dass die synthetischen Daten einige der Eigenschaften der realen Daten gut nachahmen. Allerdings gibt es auch Bereiche, in denen die synthetischen Daten stark von den realen Daten abweichen, was auf Unterschiede in den zugrunde liegenden Verteilungen hinweist.\n",
    "Schlussfolgerung:\n",
    "\n",
    "Die PCA-Analyse zeigt, dass die synthetischen Daten in gewissem Maße die Struktur der realen Daten einfangen, jedoch eine größere Variabilität aufweisen.\n",
    "Weitere Untersuchungen und Anpassungen am Generierungsprozess der synthetischen Daten könnten notwendig sein, um deren Genauigkeit und Übereinstimmung mit den realen Daten zu verbessern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series_data_augmentation_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
