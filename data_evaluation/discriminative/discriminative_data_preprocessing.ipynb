{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0 Imports and Constants\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from utilities import split_data_into_sequences, load_sequential_time_series\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "DATA_FOLDER = Path(\"../../data\")\n",
    "REAL_DATA_FOLDER = DATA_FOLDER / \"real\"\n",
    "SYNTHETIC_DATA_FOLDER = DATA_FOLDER / \"synthetic\" / \"usable\" / \"1y\"\n",
    "no_discriminative_data = int(os.getenv('NO_DISCRIMINATIVE_DATA', 1459))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    print(f'Shape of data before splitting: {data.shape}')\n",
    "    split_index = len(data) // 2\n",
    "    data_1 = data[:split_index]\n",
    "    data_2 = data[split_index:]\n",
    "\n",
    "    return data_1, data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df = pd.read_csv(REAL_DATA_FOLDER / 'mitv_prep_1y.csv') # not sequential, not shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pd.read_csv(REAL_DATA_FOLDER / 'mitv_prep_1y.csv').to_numpy() # not sequential, not shuffled\n",
    "jitter = pd.read_csv(SYNTHETIC_DATA_FOLDER / 'jittered_01.csv').to_numpy() # not sequential, not shuffled\n",
    "timewarp = pd.read_csv(SYNTHETIC_DATA_FOLDER / 'time_warped.csv').to_numpy() # not sequential, not shuffled\n",
    "\n",
    "timegan_gru_seq_shuffled = load_sequential_time_series(SYNTHETIC_DATA_FOLDER / '8747_12_5_timegan_gru.csv', shape=(8747, 12, 5)) # sequential, shuffled\n",
    "timegan_lstm_seq_shuffled = load_sequential_time_series(SYNTHETIC_DATA_FOLDER / '8747_12_5_timegan_lstm.csv', shape=(8747, 12, 5)) # sequential, shuffled\n",
    "vae_seq_shuffled = load_sequential_time_series(SYNTHETIC_DATA_FOLDER / '8759_12_5_fc_vae.csv', shape=(8759, 12, 5)) # sequential, shuffled\n",
    "\n",
    "autoencoder_seq = load_sequential_time_series(SYNTHETIC_DATA_FOLDER / '8726_12_5_lstm_autoencoder.csv', shape=(8726, 12, 5)) # sequential, not shuffled, ordered by train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data before splitting: (8759, 5)\n",
      "Shape of data before splitting: (8759, 5)\n",
      "Shape of data before splitting: (8747, 12, 5)\n",
      "Shape of data before splitting: (8747, 12, 5)\n",
      "Shape of data before splitting: (8759, 12, 5)\n",
      "Shape of data before splitting: (8726, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "jitter_train, jitter_test = split_dataset(jitter)\n",
    "timewarp_train, timewarp_test = split_dataset(timewarp)\n",
    "\n",
    "# split sequential data\n",
    "timegan_gru_train_seq_shuffled, timegan_gru_test_seq_shuffled = split_dataset(timegan_gru_seq_shuffled)\n",
    "timegan_lstm_train_seq_shuffled, timegan_lstm_test_seq_shuffled = split_dataset(timegan_lstm_seq_shuffled)\n",
    "vae_train_seq_shuffled, vae_test_seq_shuffled = split_dataset(vae_seq_shuffled)\n",
    "autoencoder_train_seq, autoencoder_test_seq = split_dataset(autoencoder_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn into Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (8748, 12, 5)\n",
      "Shape of the data after splitting into sequences: (4368, 12, 5)\n",
      "Shape of the data after splitting into sequences: (4369, 12, 5)\n",
      "Shape of the data after splitting into sequences: (4368, 12, 5)\n",
      "Shape of the data after splitting into sequences: (4369, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "real_data_seq_shuffled = split_data_into_sequences(real_data, seq_len=12, shuffle_data=True)\n",
    "\n",
    "jitter_train_seq_shuffled = split_data_into_sequences(jitter_train, seq_len=12, shuffle_data=True)\n",
    "jitter_test_seq_shuffled = split_data_into_sequences(jitter_test, seq_len=12, shuffle_data=True)\n",
    "\n",
    "timewarp_train_seq_shuffled = split_data_into_sequences(timewarp_train, seq_len=12, shuffle_data=True)\n",
    "timewarp_test_seq_shuffled = split_data_into_sequences(timewarp_test, seq_len=12, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Autoencoder Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train_indices = np.random.permutation(len(autoencoder_train_seq))\n",
    "autoencoder_test_indices = np.random.permutation(len(autoencoder_test_seq))\n",
    "\n",
    "autoencoder_train_seq_shuffled = autoencoder_train_seq[autoencoder_train_indices]\n",
    "autoencoder_test_seq_shuffled = autoencoder_test_seq[autoencoder_test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 12, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_seq_shuffled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only keep required amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real = real_data_seq_shuffled[:6*no_discriminative_data]\n",
    "\n",
    "train_jitter = jitter_train_seq_shuffled[:no_discriminative_data]\n",
    "test_jitter = jitter_test_seq_shuffled[:no_discriminative_data]\n",
    "\n",
    "train_timewarp = timewarp_train_seq_shuffled[:no_discriminative_data]\n",
    "test_timewarp = timewarp_test_seq_shuffled[:no_discriminative_data]\n",
    "\n",
    "train_timegan_gru = timegan_gru_train_seq_shuffled[:no_discriminative_data]\n",
    "test_timegan_gru = timegan_gru_test_seq_shuffled[:no_discriminative_data]\n",
    "\n",
    "train_timegan_lstm = timegan_lstm_train_seq_shuffled[:no_discriminative_data]\n",
    "test_timegan_lstm = timegan_lstm_test_seq_shuffled[:no_discriminative_data]\n",
    "\n",
    "train_vae = vae_train_seq_shuffled[:no_discriminative_data]\n",
    "test_vae = vae_test_seq_shuffled[:no_discriminative_data]\n",
    "\n",
    "train_autoencoder = autoencoder_train_seq_shuffled[:no_discriminative_data]\n",
    "test_autoencoder = autoencoder_test_seq_shuffled[:no_discriminative_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding Ones -> Real Data ###\n",
    "train_real_labeled = np.concatenate((train_real, np.ones((train_real.shape[0], 1, 5))), axis=1)\n",
    "\n",
    "### Adding Zeros -> Synthetic Data ###\n",
    "train_jitter_labeled = np.concatenate((train_jitter, np.zeros((train_jitter.shape[0], 1, 5))), axis=1)\n",
    "test_jitter_labeled = np.concatenate((test_jitter, np.zeros((test_jitter.shape[0], 1, 5))), axis=1)\n",
    "\n",
    "train_timewarp_labeled = np.concatenate((train_timewarp, np.zeros((train_timewarp.shape[0], 1, 5))), axis=1)\n",
    "test_timewarp_labeled = np.concatenate((test_timewarp, np.zeros((test_timewarp.shape[0], 1, 5))), axis=1)\n",
    "\n",
    "train_timegan_gru_labeled = np.concatenate((train_timegan_gru, np.zeros((train_timegan_gru.shape[0], 1, 5))), axis=1)\n",
    "test_timegan_gru_labeled = np.concatenate((test_timegan_gru, np.zeros((test_timegan_gru.shape[0], 1, 5))), axis=1)\n",
    "\n",
    "train_timegan_lstm_labeled = np.concatenate((train_timegan_lstm, np.zeros((train_timegan_lstm.shape[0], 1, 5))), axis=1)\n",
    "test_timegan_lstm_labeled = np.concatenate((test_timegan_lstm, np.zeros((test_timegan_lstm.shape[0], 1, 5))), axis=1)\n",
    "\n",
    "train_vae_labeled = np.concatenate((train_vae, np.zeros((train_vae.shape[0], 1, 5))), axis=1)\n",
    "test_vae_labeled = np.concatenate((test_vae, np.zeros((test_vae.shape[0], 1, 5))), axis=1)\n",
    "\n",
    "train_autoencoder_labeled = np.concatenate((train_autoencoder, np.zeros((train_autoencoder.shape[0], 1, 5))), axis=1)\n",
    "test_autoencoder_labeled = np.concatenate((test_autoencoder, np.zeros((test_autoencoder.shape[0], 1, 5))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17502, 13, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all train data and shuffle again\n",
    "train = np.concatenate((train_real_labeled, train_jitter_labeled, train_timewarp_labeled, train_timegan_gru_labeled, train_timegan_lstm_labeled, train_vae_labeled, train_autoencoder_labeled), axis=0)\n",
    "permutated_train_indices = np.random.permutation(len(train))\n",
    "train = train[permutated_train_indices]\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save combined training data and individual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # save combined train data\n",
    "    train_to_save = train.reshape(train.shape[0], train.shape[1] * train.shape[2])\n",
    "    np.savetxt(f'discriminative_train_{train.shape[0]}_{train.shape[1]}_{train.shape[2]}.csv', train_to_save, delimiter=',')\n",
    "\n",
    "    # save single test data\n",
    "    test_jitter_to_save = test_jitter_labeled.reshape(test_jitter_labeled.shape[0], test_jitter_labeled.shape[1] * test_jitter_labeled.shape[2])\n",
    "    np.savetxt(f'discriminative_test_jitter_{test_jitter_labeled.shape[0]}_{test_jitter_labeled.shape[1]}_{test_jitter_labeled.shape[2]}.csv', test_jitter_to_save, delimiter=',')\n",
    "\n",
    "    test_timewarp_to_save = test_timewarp_labeled.reshape(test_timewarp_labeled.shape[0], test_timewarp_labeled.shape[1] * test_timewarp_labeled.shape[2])\n",
    "    np.savetxt(f'discriminative_test_timewarp_{test_timewarp_labeled.shape[0]}_{test_timewarp_labeled.shape[1]}_{test_timewarp_labeled.shape[2]}.csv', test_timewarp_to_save, delimiter=',')\n",
    "\n",
    "    test_timegan_gru_to_save = test_timegan_gru_labeled.reshape(test_timegan_gru_labeled.shape[0], test_timegan_gru_labeled.shape[1] * test_timegan_gru_labeled.shape[2])\n",
    "    np.savetxt(f'discriminative_test_timegan_gru_{test_timegan_gru_labeled.shape[0]}_{test_timegan_gru_labeled.shape[1]}_{test_timegan_gru_labeled.shape[2]}.csv', test_timegan_gru_to_save, delimiter=',')\n",
    "\n",
    "    test_timegan_lstm_to_save = test_timegan_lstm_labeled.reshape(test_timegan_lstm_labeled.shape[0], test_timegan_lstm_labeled.shape[1] * test_timegan_lstm_labeled.shape[2])\n",
    "    np.savetxt(f'discriminative_test_timegan_lstm_{test_timegan_lstm_labeled.shape[0]}_{test_timegan_lstm_labeled.shape[1]}_{test_timegan_lstm_labeled.shape[2]}.csv', test_timegan_lstm_to_save, delimiter=',')\n",
    "\n",
    "    test_vae_to_save = test_vae_labeled.reshape(test_vae_labeled.shape[0], test_vae_labeled.shape[1] * test_vae_labeled.shape[2])\n",
    "    np.savetxt(f'discriminative_test_vae_{test_vae_labeled.shape[0]}_{test_vae_labeled.shape[1]}_{test_vae_labeled.shape[2]}.csv', test_vae_to_save, delimiter=',')\n",
    "\n",
    "    test_autoencoder_to_save = test_autoencoder_labeled.reshape(test_autoencoder_labeled.shape[0], test_autoencoder_labeled.shape[1] * test_autoencoder_labeled.shape[2])\n",
    "    np.savetxt(f'discriminative_test_autoencoder_{test_autoencoder_labeled.shape[0]}_{test_autoencoder_labeled.shape[1]}_{test_autoencoder_labeled.shape[2]}.csv', test_autoencoder_to_save, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series_data_augmentation_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
