{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Imports and Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "from utilities import split_data_into_sequences, load_sequential_time_series, reconstruct_sequential_data, Scaler, extract_features_and_targets_reg, get_discriminative_test_performance\n",
    "from data_evaluation.visual.visual_evaluation import visual_evaluation\n",
    "from predictive_evaluation import predictive_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../../data\")\n",
    "REAL_DATA_FOLDER = DATA_FOLDER / \"real\"\n",
    "SYNTHETIC_DATA_FOLDER = DATA_FOLDER / \"synthetic\" / \"usable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load and Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways of loading data\n",
    "- Laden der Originaldaten: als pd dataframe \n",
    "- Laden der synthetischen, sequentiellen Daten: als np array (GAN, (V)AE)\n",
    "- Laden der synthetischen, sequentiellen Daten: als pd dataframe (brownian, algorithmit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible types: 'timegan_lstm', 'timegan_gru', 'jitter', 'timewarp', 'autoencoder', 'vae'\n",
    "syn_data_type = 'timegan_lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " syn data:\n",
      "\n",
      "       traffic_volume           temp        rain_1h        snow_1h  \\\n",
      "count   341988.000000  341988.000000  341988.000000  341988.000000   \n",
      "mean      3223.797936     282.704303       0.086439       0.000249   \n",
      "std       1943.974204      12.922822       0.321004       0.000466   \n",
      "min         41.627638     250.083873       0.000008       0.000000   \n",
      "25%       1152.987320     270.511312       0.000130       0.000002   \n",
      "50%       3608.409516     285.328962       0.000575       0.000006   \n",
      "75%       5010.047921     293.711888       0.037928       0.000324   \n",
      "max       7076.619110     305.881726      12.279954       0.004205   \n",
      "\n",
      "          clouds_all  \n",
      "count  341988.000000  \n",
      "mean       39.871618  \n",
      "std        39.339560  \n",
      "min         0.016394  \n",
      "25%         4.172619  \n",
      "50%        15.465574  \n",
      "75%        87.893841  \n",
      "max        97.951007  \n",
      "\n",
      "\n",
      "real data:\n",
      "\n",
      "       traffic_volume          temp       rain_1h       snow_1h    clouds_all\n",
      "count     28511.00000  28511.000000  28511.000000  28511.000000  28511.000000\n",
      "mean       3313.74238    282.688768      0.061611      0.000250     42.122795\n",
      "std        1971.53206     12.367361      0.678185      0.008298     39.316195\n",
      "min           0.00000    243.390000      0.000000      0.000000      0.000000\n",
      "25%        1289.00000    273.480000      0.000000      0.000000      1.000000\n",
      "50%        3507.00000    284.550000      0.000000      0.000000     40.000000\n",
      "75%        4948.00000    292.790000      0.000000      0.000000     90.000000\n",
      "max        7280.00000    310.070000     42.000000      0.510000    100.000000\n"
     ]
    }
   ],
   "source": [
    "# Load real time series\n",
    "data_real_df = pd.read_csv(REAL_DATA_FOLDER/'metro_interstate_traffic_volume_label_encoded_no_categorical.csv')\n",
    "data_real_numpy = dc(data_real_df).to_numpy()\n",
    "\n",
    "if syn_data_type == 'timegan_lstm':\n",
    "    # load sequential data (which should already be scaled)\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28499_12_5_lstm_unscaled.csv', shape=(28499, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'timegan_gru':\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28499_12_5_gru_unscaled.csv', shape=(28499, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'autoencoder':\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28478_12_5_lstm_autoencoder_unscaled_15.csv', shape=(28478, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'vae':\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28511_12_5_lstm_vae_unscaled.csv', shape=(28511, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'jitter':\n",
    "    jitter_factor = 0.1\n",
    "    data_syn_df = pd.read_csv(SYNTHETIC_DATA_FOLDER/f'mitv_jittered_{str(jitter_factor).replace(\".\", \"\")}.csv')\n",
    "    data_syn_numpy = dc(data_syn_df).to_numpy()\n",
    "\n",
    "elif syn_data_type == 'timewarp':\n",
    "    data_syn_df = pd.read_csv(SYNTHETIC_DATA_FOLDER/f'mitv_time_warped.csv')\n",
    "    data_syn_numpy = dc(data_syn_df).to_numpy()\n",
    "\n",
    "# Loot at real and syn data\n",
    "df = pd.DataFrame(data_syn_numpy.reshape(-1, data_syn_numpy.shape[-1]), columns=data_real_df.columns)\n",
    "\n",
    "print('\\n\\n syn data:\\n')\n",
    "print(df.describe())\n",
    "\n",
    "print('\\n\\nreal data:\\n')\n",
    "print(data_real_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>341988.000000</td>\n",
       "      <td>341988.000000</td>\n",
       "      <td>341988.000000</td>\n",
       "      <td>341988.000000</td>\n",
       "      <td>341988.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3223.797936</td>\n",
       "      <td>282.704303</td>\n",
       "      <td>0.086439</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>39.871618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1943.974204</td>\n",
       "      <td>12.922822</td>\n",
       "      <td>0.321004</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>39.339560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.627638</td>\n",
       "      <td>250.083873</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1152.987320</td>\n",
       "      <td>270.511312</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.172619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3608.409516</td>\n",
       "      <td>285.328962</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>15.465574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5010.047921</td>\n",
       "      <td>293.711888</td>\n",
       "      <td>0.037928</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>87.893841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7076.619110</td>\n",
       "      <td>305.881726</td>\n",
       "      <td>12.279954</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>97.951007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       traffic_volume           temp        rain_1h        snow_1h  \\\n",
       "count   341988.000000  341988.000000  341988.000000  341988.000000   \n",
       "mean      3223.797936     282.704303       0.086439       0.000249   \n",
       "std       1943.974204      12.922822       0.321004       0.000466   \n",
       "min         41.627638     250.083873       0.000008       0.000000   \n",
       "25%       1152.987320     270.511312       0.000130       0.000002   \n",
       "50%       3608.409516     285.328962       0.000575       0.000006   \n",
       "75%       5010.047921     293.711888       0.037928       0.000324   \n",
       "max       7076.619110     305.881726      12.279954       0.004205   \n",
       "\n",
       "          clouds_all  \n",
       "count  341988.000000  \n",
       "mean       39.871618  \n",
       "std        39.339560  \n",
       "min         0.016394  \n",
       "25%         4.172619  \n",
       "50%        15.465574  \n",
       "75%        87.893841  \n",
       "max        97.951007  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28511.00000</td>\n",
       "      <td>28511.000000</td>\n",
       "      <td>28511.000000</td>\n",
       "      <td>28511.000000</td>\n",
       "      <td>28511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3313.74238</td>\n",
       "      <td>282.688768</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>42.122795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1971.53206</td>\n",
       "      <td>12.367361</td>\n",
       "      <td>0.678185</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>39.316195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>243.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1289.00000</td>\n",
       "      <td>273.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3507.00000</td>\n",
       "      <td>284.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4948.00000</td>\n",
       "      <td>292.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7280.00000</td>\n",
       "      <td>310.070000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       traffic_volume          temp       rain_1h       snow_1h    clouds_all\n",
       "count     28511.00000  28511.000000  28511.000000  28511.000000  28511.000000\n",
       "mean       3313.74238    282.688768      0.061611      0.000250     42.122795\n",
       "std        1971.53206     12.367361      0.678185      0.008298     39.316195\n",
       "min           0.00000    243.390000      0.000000      0.000000      0.000000\n",
       "25%        1289.00000    273.480000      0.000000      0.000000      1.000000\n",
       "50%        3507.00000    284.550000      0.000000      0.000000     40.000000\n",
       "75%        4948.00000    292.790000      0.000000      0.000000     90.000000\n",
       "max        7280.00000    310.070000     42.000000      0.510000    100.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_real_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Predictive Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"seq_len\": 12,\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 32,\n",
    "    \"hidden_size\": 4,\n",
    "    \"num_layers\": 1,\n",
    "    \"bidirectional\": True,\n",
    "    \"num_evaluation_runs\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"device\": 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETERS:\n",
      "seq_len :  12\n",
      "lr :  0.0001\n",
      "batch_size :  32\n",
      "hidden_size :  4\n",
      "num_layers :  1\n",
      "bidirectional :  True\n",
      "num_evaluation_runs :  10\n",
      "num_epochs :  200\n",
      "device :  cpu\n",
      "Synthetic Data is sequential: True\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2841, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.5443368302070409 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.16472036098496298 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.014966908006355438 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.012216368083203777 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.008142099321296054 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00521239361809462 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.00753815488584162 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004539211659974764 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007319685624883645 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.004319564303320446 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007211941005048168 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.004226537860846252 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.00713610866167132 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.004169695843220427 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0070742767184664495 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.004122030530177224 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.007019060781763718 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.004074617706270617 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006967175100455883 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.004025913179810211 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006917577760351553 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.003977952565568803 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0068702063907583105 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.003933582945433812 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006825064097336516 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.003894431256228702 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006781861305381805 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.0038603114427245232 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006740117465344429 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.003829884125715059 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.00669936664261415 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.003801667523894752 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006659250700229787 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.0037745186951785776 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006619522029332827 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.0037476541108211105 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006579987246276704 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.003720480547119141 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0065404285987327076 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.003692428114447282 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fanny\\Documents\\ArnesShit\\time_series_data_augmentation\\data_evaluation\\predictive\\predictive_evaluation.py:273: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([{'Model': evaluation_method, 'Metric': 'MAE', 'Error': mae}])], ignore_index=True)\n",
      " 10%|█         | 1/10 [03:35<32:17, 215.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.46782051793823404 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.2479787974545125 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.01576117673878353 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.013454122976347637 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.009463628701445076 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006727460654075729 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.008443922722035545 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005375561150042027 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007779031072391868 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004612437318591924 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007243788112438222 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004123430815525353 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.00688649575568234 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038205080644719384 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.006617538477320271 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0035952599849970487 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0064099817291858275 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003431589006488159 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006239123575664994 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003288859178395837 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006094431925041217 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0031580272107123494 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.005973594606237494 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0030435634661842596 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.005871228920426455 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0029446380696876834 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.005781914617247138 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0028579396083218494 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.005701477709258966 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0027802395359665323 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.005626997096838918 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002709027132532151 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0055566577297644516 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0026425310787273927 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0054895910991193805 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0025797287326599105 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.005425837789113577 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002520535010425897 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0053663681477417995 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0024660326608488066 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [07:10<28:42, 215.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.17223015503349176 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.07341266009077597 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.013419253493007403 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.011129874150069911 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.009082455749703155 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006507138794894968 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.00782111813777961 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005175942340551802 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007543657519390903 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004797820498894775 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.00738167200485038 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004558874806912428 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007264732016311883 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0043712454910777255 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007174434596026084 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004217087225779221 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.007100268940116066 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004090394797274487 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.007036858756842319 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003985835184353624 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006982128646258698 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038995658037032973 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006935315197013674 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.003829865779183554 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006895426367370341 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.0037749302743546914 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006860770206757381 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.003731046744433933 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0068294773564698775 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.003693690480339979 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006799973540274533 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.0036591637128796637 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006770976508711563 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.0036249340216242027 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006741234445212955 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.003589061803048414 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0067090774348481114 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.0035492712187088944 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006671411233959357 // Train Acc: 0.013148667601683029\n",
      "Val Loss: 0.0035013134743013745 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [10:45<25:07, 215.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.36389886095680996 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.15306977994656296 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.013373668306882051 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.010700326266416003 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0076454849348783615 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004844828880276908 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007332994828756956 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004355793824063593 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007226267893867878 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004219850818260333 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0071406747365689105 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004135776494284359 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007073037799997686 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0040687639004645055 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007018767476870795 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004015914855127254 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0069741298417465404 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003970699587554326 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006936330236736189 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003930170536355189 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006903437169028386 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038933567061831945 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0068739027313582425 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003859565281989367 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006846333546452955 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038278948206956803 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006819488203772154 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003797235698543824 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.00679228466910638 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0037664076970011164 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0067637522270913445 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0037342818582095623 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006732902313265192 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00369974455581664 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006698436103761196 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0036614637670180435 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006658019707799428 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0036170404885759516 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006606322507959167 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0035605678528421716 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [14:20<21:29, 214.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.3154649840665231 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.14744746015312965 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.014919772844756386 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.012445220247622622 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.00884896804197191 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005589283267663938 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007479953560011584 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004383412413456048 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007264092566868679 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004219313367960577 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007169734379981983 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00411766964492252 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007092914372933363 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004044136486351072 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007025867547914334 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003988215884225171 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.006964512700659091 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003941577458963468 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0069054879344801244 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038989379797967965 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.00684642833987379 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038571871157861157 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006785938969838105 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003814427498623394 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.00672303954140005 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003768984006006229 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006656208374376865 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003718282421789226 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006582080500055402 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00365759257038825 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006493693189551795 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0035786447455332187 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006378666988735938 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0034692371146376718 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006224432701851028 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0033218397267079087 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.00605038520168163 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0031643672192239024 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.005908169578251444 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0030412716317524233 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [17:49<17:44, 212.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.1575339981792351 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.08958310035339902 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.011780535957030169 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.009385275638798315 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.008042741797114677 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005328445580233349 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.00768035029153879 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004915117927083976 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007495403295346283 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004671545960846242 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007367468236254588 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004493743788157956 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0072674024046815375 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004354963364247023 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007183005227700795 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00424290265301975 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.007107679113330317 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004149105938758408 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.007035536991319976 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004064816627075917 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006961560278783485 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0039828143597925815 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006883867429164441 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038985275830864235 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006803301091829699 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038109946370731744 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0067198049945843006 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003720638701911974 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006632558707713423 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003627991144220983 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006541444829548873 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003534542401896769 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.00644784375697343 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003442377104486726 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006354394791873765 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003353098793258744 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.00626424017204246 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003267500336344741 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0061792891404328955 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0031848651843584992 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [21:18<14:05, 211.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.4750310824596196 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.22524350463004594 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.011508289921825012 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00903373321235766 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.008290729604643178 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005422262396412284 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0074109164348099416 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004481737146133117 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.00705425988759997 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004109018844594196 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.006858981792458437 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003941903666467563 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.006714984684461548 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038409424459122203 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.00658096947630823 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0037455311204631176 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0064402582407321616 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003624124651293406 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006292832457247552 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003467661758958038 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0061493798824899725 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003297150206982336 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0060170129752034765 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0031377527028259434 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.005901023297509254 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0029968348569812233 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.005803978166785901 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0028750485324646148 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0057258433730930595 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0027752844132796933 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.005664931354047613 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002699858000177597 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.005617472790194699 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002646862246682135 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.005578798963263798 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002609845640640078 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.005545498605531498 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0025821302774142515 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.005515656781776026 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002559558772272692 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [24:47<10:32, 210.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.5336886892019448 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.29774640919117445 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.014133132345971832 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.011998209605265535 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.012203814071925752 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.009640286679201748 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.008534016171901332 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005980739657756653 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.00790139350048717 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005194955518511072 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007702441695688337 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0049521354487521594 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007579238922041312 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004801649424990409 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.00749193160888722 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004692309556968427 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0074244772425629355 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004606793909281325 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0073690006942429475 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00453637624185616 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.007321412462988009 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004475924410082902 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.007279415068583665 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00442200583102328 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0072414484684881954 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004372014025791308 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.007206196814441079 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004323812389976523 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.007172572535565867 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004275719721519043 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.007139823350828104 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004226545661980851 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.007107512093753898 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004175501545953951 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.007075377000818423 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0041220354497056 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.007043132882566566 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004065644540143817 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.007010280006881255 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004005650100245905 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [28:17<07:01, 210.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.30341463715757594 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.14548011986392267 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.016006175769547843 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.014032971710385232 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.01027367691846426 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.007750300779478268 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.008201313483937635 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005410063198212994 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0077458691966444315 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004879051911006315 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007610051403361599 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004696687016364062 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007532028222083 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004586940411520139 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007459549232827549 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00449615365072164 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.007377212992862786 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0044096459822959445 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.007284488855680871 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004322559993944309 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.007184672815631161 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004229970500030125 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.007078266508621262 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004135667052109506 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006972303296613074 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00404242071155668 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006875954018637987 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003954566608371443 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006791740858687028 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.0038769092774437216 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006716402289509867 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.0038085308480547385 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006645704021508875 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.0037449138131767008 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006576240340444987 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.0036815013278673372 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006505530382092483 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.0036149472285982934 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006431742737671885 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.003543113294224977 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [31:46<03:30, 210.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.22264377645322686 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.10442083680562758 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.013957120248914642 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.01157669180983238 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.008105525467414174 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005401782322612204 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007371380890400879 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004527366856175862 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0071050111324556416 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0042227775805493755 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.006783008345221215 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003931892362130241 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.006527792750550813 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00365005065870126 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.006288324446002019 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0033466755438679723 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.00609580235722962 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0031183664124521814 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.005943517843300547 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002957078289460349 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.005819875701738138 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0028370699081360622 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.005717924908378265 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0027442624978197927 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.005632243533736306 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002669572242891437 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.005559515394956176 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002608021283051355 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.005498092329301996 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002557329460062882 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.005446682368348997 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0025159708535549847 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.005403616111483921 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0024821702541333486 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.005366935846160674 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002454009026765112 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.005334789818022165 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0024298008445001553 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.005305680621194628 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.002408306542103796 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [35:16<00:00, 211.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (5692, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.08426985918409693 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.06790068379362647 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.011364002924328893 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.009664478154559985 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.00851436935235886 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006785970305490276 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007788486212170663 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005898791997107479 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0074496425082188665 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005422796142350338 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007230002681240126 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005102484946118228 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007060182506811568 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004859107505305137 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.006919958285019481 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004666226600124134 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.006799063632731047 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004510991934561327 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006698460119768591 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004391147679220257 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.00661764134552335 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0043027448497995145 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006547255821488171 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004231694635145073 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006481563797002452 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0041695351573753725 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006416677115589568 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004111084478169554 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006349055280844939 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004052115429004424 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006275057254018207 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003988325541572164 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006191194201963281 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003915000812208092 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006097095714964307 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038285119428948153 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.005999306439216997 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0037298985584272764 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.00590400269067602 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003627145271800626 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:31<31:44, 211.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.23802866804482725 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.15903156924616085 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.012571676402727631 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.01119727209430146 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.00854896024904027 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006711615206349348 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007747910888721908 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005538912100215139 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.00737538052132408 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0050524898145473405 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007154899346609541 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0047912342131158775 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.006902726234046567 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00453222497023663 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.006577203514447585 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004197498336774454 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.006319124257481993 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0039324920187610085 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0061509468000666935 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0037843189130306997 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0060335090235306725 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0036945134248281045 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.00594301343399791 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003627494401350785 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.005868322681472343 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003571215954222036 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.005803524671961014 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003521062383360198 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.005745071439048978 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003474539653345775 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0056907863145221295 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0034301057601807995 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.005639397206769794 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0033868369221258282 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.00559020332657689 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0033442466271245913 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0055428218760372235 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003302123983589451 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.005497032138231625 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0032604351329742773 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [07:03<28:13, 211.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.14100372085418306 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.06977201112954134 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.011678048792565543 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.009841680293902755 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.00857526905211616 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006420506406418477 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0077574637951655905 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005432782889594942 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007476747037286427 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00507488126115706 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007315299437619056 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004887588031124324 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007205732814970244 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004774249983517181 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007125891449725383 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004699949867725163 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0070592709480645065 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004643805084352413 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006996878488759966 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004594165436777003 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006933748140979459 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0045449565101959065 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006866106005394662 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004491968566991305 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006790354208358489 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004431103447745188 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006703476267729639 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004358346930448636 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0066043230989715415 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004271275892309593 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006494868089390075 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004170919026855086 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006380351501135586 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00406242563818278 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006267886893427964 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003953696193900796 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006163913582067618 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038521176255098804 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006071498310898769 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0037610119867944316 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [10:35<24:44, 212.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.10507136298053563 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.07692541052283866 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.01195457707770524 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0103607926062528 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.008036692760660095 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006073094143145038 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007394516049018247 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00511128893331363 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007162586859979917 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004755999170259436 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007052101117792588 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0046244373393318295 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0069683703060325905 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0045536677470807444 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.006888415186854045 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004492975007533357 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.006805704722081691 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004428351089342634 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006714674415586707 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004353858949093336 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006613111918267035 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004267404569454198 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006510001136516424 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004176515346168007 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0064230587207392215 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004097040568012744 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006358094283524603 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004035532800873135 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006307389128360203 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003986830553013748 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0062634598011174466 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0039450719892413595 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006222486740884699 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003906715646898897 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006182458060519276 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003869505674353267 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006141807706987415 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038317150424569428 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006098774896097352 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003791505964656015 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [14:08<21:13, 212.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.09794463919473062 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.06993502575192559 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.013462576695141835 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.011900397582670277 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.009034356971951868 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.007025785958708337 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.008074843016457006 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005883075324347599 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007656794186710245 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005322250071913004 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007449957565306509 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005019894099972221 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.00731123262280951 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004819445715552677 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007190175511878177 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004667196826344837 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.007086218400371129 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0045561847287449945 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.007002315709797135 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004473408027499747 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0069305981974069125 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004401540390890761 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0068639253539152095 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004331959215950304 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006796963748830366 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004259590750162521 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006722007320702682 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004175387736896493 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006617832985715771 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00405329484374817 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006436099641992963 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003859839357011899 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006255248021386658 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003748662408776163 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006123601907320832 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0036877040670180087 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006015021241626599 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0036254051544316363 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.005917056915768243 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003556950758158993 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [17:40<17:41, 212.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.1963502330206554 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.11794149323125903 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.01491185736504147 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.013374529663850082 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.010196413753389644 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00799205053330849 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.008663709690143859 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006213847944104856 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.008025326630718442 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00547676314495169 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007558103785020669 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005036810029748032 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007382771853869585 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004899332312908903 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007296562339159624 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004823810835578217 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.007228956525808339 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004760930617470713 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0071680898150183565 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004704779508429464 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.007111576448167252 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004653193330617224 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.007058345034802111 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00460500726698678 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.007007568727997178 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00455959147140593 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0069585198743548375 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004516505104557643 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006910548113393604 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0044753417808279985 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0068630769275400535 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004435663551008434 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006815608460384291 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004396993713976627 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0067677295515000254 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0043588617464705385 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006719122232763465 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004320823715664865 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006669625228624869 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004282598538073093 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [21:13<14:09, 212.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.07092467704879285 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.06357075742791209 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.010409463398474652 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.008580733332626019 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.007760652077422173 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005670877266413627 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007312825521412417 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004987673423242535 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007137546421918198 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004683249192495485 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007051425263335273 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004545725345104053 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.006994997078375199 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004476399079169241 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.006951088279578443 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004435006634389793 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.006914274605398614 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004406470212211644 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006882099905292939 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00438492473154695 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006853110900019436 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004367647018921928 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006826291944430606 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0043530109982016715 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006800816493986637 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004339834666690591 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006775908794046378 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004327212977013812 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006750750974236059 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004314376867318714 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006724378747015219 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004300538598941744 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006695468355881946 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004284631008324161 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006661845579956296 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004264905968984442 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006619620382972584 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0042384966273969985 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006562853528044303 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004200657471894088 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [24:45<10:37, 212.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.08271359081208957 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.07570028217153603 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.010238390674861606 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.008296073418309432 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.008004633929883488 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005731884280240603 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.007530012874319356 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005077230356884807 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0073300618652207316 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004785486309281602 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007181151736420572 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004587126619135438 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007067282940979478 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004465428557707353 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.00697947864363239 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0043952432107912855 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.006908458619519577 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0043467469330291065 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006848881995569272 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004306326123880579 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.006796650113381163 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004268884894260195 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.00674842185174934 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004232055166856584 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.00670178219980363 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004194411545275093 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006655152983438396 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004155027948246662 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.006607516836420716 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004113241497772547 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006558179394583653 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00406856828675281 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006506622968134463 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004020672055416521 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006452474160398112 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003969400075363686 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006395531648627599 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003914875300794715 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0063358431410627 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038575290426287505 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [28:19<07:05, 212.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.8636636978947932 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.5956535113326619 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.017591667385722234 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.015310300375450026 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.00903143358157574 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006951114480001747 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.008089824057828118 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005756948397003031 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.007580248698419767 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0051954837079065735 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.007305335994747168 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0049135470357357285 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.00713929067235858 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004737579779113444 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007016338321783934 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004602915685875028 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.00691816292988557 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004495917076475165 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.006840041209649697 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004411900867289455 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.00677609108917436 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0043442799360491335 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.006720158131238005 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004286916636118895 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.006668465636666671 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004235547156271975 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.006619006009193772 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00418722434584156 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.00657056822594344 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004139968979543891 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.006522316742965333 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004092459404694565 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006473638124660776 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004043800414937517 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0064240782087352675 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0039933694087052616 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006373307230747808 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.003940728275900644 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006321097535719941 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0038855887061309364 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [31:51<03:32, 212.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.4730267705706694 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.253670667748103 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.014508722365675769 // Train Acc: 0.00876577840112202\n",
      "Val Loss: 0.013042778545844087 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.010362430459977784 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.008512618060726045 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.008913314910109193 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00700062904585404 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.00834495945817949 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0063763557805083275 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.008111459186736907 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.006103975774218025 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.007991966163493996 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0059393979556691115 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.007901810269625165 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005798974988741402 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.007818926731679656 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005663432298604859 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.007734626667282765 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005524597456417141 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.007641970760908714 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.005374386100872849 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0075339009122580795 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.0052043822321915225 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0074065093427496806 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.00501235002348346 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.00726843025792667 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004815618748242935 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.007140882820711271 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004648513965742934 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.007035744208470248 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004525960863860889 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.006949667694428505 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004436422223120593 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.006870470798200814 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004361724333178377 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.006784616753839082 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004286818199770085 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.006682193149854318 // Train Acc: 0.00438288920056101\n",
      "Val Loss: 0.004201345495602346 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [35:24<00:00, 212.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (28500, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.044344251667153285 // Train Acc: 0.0\n",
      "Val Loss: 0.034458460026113684 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.0030152752739475287 // Train Acc: 0.0\n",
      "Val Loss: 0.0031002305477972054 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.002287654847339015 // Train Acc: 0.0\n",
      "Val Loss: 0.0023672713354417232 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.001879619755516048 // Train Acc: 0.0\n",
      "Val Loss: 0.0019683230574978985 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0016324150904707432 // Train Acc: 0.0\n",
      "Val Loss: 0.0017434769760760057 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.001536901977014771 // Train Acc: 0.0\n",
      "Val Loss: 0.0016641867529651588 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0014958142299746485 // Train Acc: 0.0\n",
      "Val Loss: 0.0016275951406312327 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0014640076808540967 // Train Acc: 0.0\n",
      "Val Loss: 0.0015986424368544738 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.001432821678238866 // Train Acc: 0.0\n",
      "Val Loss: 0.0015702080591282594 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.001400727072078702 // Train Acc: 0.0\n",
      "Val Loss: 0.0015417461962485945 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0013708772681386382 // Train Acc: 0.0\n",
      "Val Loss: 0.0015161273610458173 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0013450052993325386 // Train Acc: 0.0\n",
      "Val Loss: 0.0014936245250120217 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0013225632204357757 // Train Acc: 0.0\n",
      "Val Loss: 0.001473366745045882 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0013028163102079577 // Train Acc: 0.0\n",
      "Val Loss: 0.0014549055390057346 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0012851530118598205 // Train Acc: 0.0\n",
      "Val Loss: 0.0014378387626005577 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0012690985996487091 // Train Acc: 0.0\n",
      "Val Loss: 0.001421825340480736 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0012543200894866628 // Train Acc: 0.0\n",
      "Val Loss: 0.0014066189886350444 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0012405948618273114 // Train Acc: 0.0\n",
      "Val Loss: 0.001392052108103243 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0012277733207166621 // Train Acc: 0.0\n",
      "Val Loss: 0.001378006382059051 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0012157461693318402 // Train Acc: 0.0\n",
      "Val Loss: 0.0013643994736524205 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:31<31:43, 211.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.2859216224386515 // Train Acc: 0.0\n",
      "Val Loss: 0.11951763979965747 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.005894174047440113 // Train Acc: 0.0\n",
      "Val Loss: 0.005775765976322263 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.002603026880388936 // Train Acc: 0.0\n",
      "Val Loss: 0.0026873605925454526 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0021709766064468136 // Train Acc: 0.0\n",
      "Val Loss: 0.0022485702381177947 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0018977749189260699 // Train Acc: 0.0\n",
      "Val Loss: 0.0019800755975432384 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0016902947915847927 // Train Acc: 0.0\n",
      "Val Loss: 0.0017818771224656252 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.00155911273248301 // Train Acc: 0.0\n",
      "Val Loss: 0.0016621629895795886 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0014919813844502014 // Train Acc: 0.0\n",
      "Val Loss: 0.001600483669957937 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0014553982097502709 // Train Acc: 0.0\n",
      "Val Loss: 0.0015640709615525837 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0014315926639505547 // Train Acc: 0.0\n",
      "Val Loss: 0.0015391600888948263 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0014139112548765152 // Train Acc: 0.0\n",
      "Val Loss: 0.0015203273424608166 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.001399254180467459 // Train Acc: 0.0\n",
      "Val Loss: 0.0015045986162868 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.001386121097138363 // Train Acc: 0.0\n",
      "Val Loss: 0.0014904558350652061 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0013738070719091348 // Train Acc: 0.0\n",
      "Val Loss: 0.00147717567690773 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0013619966758937584 // Train Acc: 0.0\n",
      "Val Loss: 0.0014644349798724034 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0013505687490500756 // Train Acc: 0.0\n",
      "Val Loss: 0.0014521031652339187 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.00133950468645853 // Train Acc: 0.0\n",
      "Val Loss: 0.0014401570274839282 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.001328842158578395 // Train Acc: 0.0\n",
      "Val Loss: 0.0014286305067290723 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0013186456155768944 // Train Acc: 0.0\n",
      "Val Loss: 0.0014175856046153587 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0013089830158982063 // Train Acc: 0.0\n",
      "Val Loss: 0.0014070936091869872 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [07:02<28:11, 211.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.08259652570140813 // Train Acc: 0.0\n",
      "Val Loss: 0.0643580965073415 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.0042864140430086545 // Train Acc: 0.0\n",
      "Val Loss: 0.004337844379667671 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0025959703555333245 // Train Acc: 0.0\n",
      "Val Loss: 0.002630264579914198 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.00200901380118027 // Train Acc: 0.0\n",
      "Val Loss: 0.0020600003980531995 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0017282611109283041 // Train Acc: 0.0\n",
      "Val Loss: 0.0018201258167489197 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0016518080049308034 // Train Acc: 0.0\n",
      "Val Loss: 0.001755989381527091 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0016092057592923875 // Train Acc: 0.0\n",
      "Val Loss: 0.0017154493479561528 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.001574985960512004 // Train Acc: 0.0\n",
      "Val Loss: 0.0016823562018849038 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0015451987452777612 // Train Acc: 0.0\n",
      "Val Loss: 0.0016534580304755637 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.001518337427818727 // Train Acc: 0.0\n",
      "Val Loss: 0.001627345494477224 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.001493195751164341 // Train Acc: 0.0\n",
      "Val Loss: 0.0016025830034716783 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0014683443255824407 // Train Acc: 0.0\n",
      "Val Loss: 0.0015773107622088032 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0014423764169176644 // Train Acc: 0.0\n",
      "Val Loss: 0.0015497343395524477 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0014148468670210257 // Train Acc: 0.0\n",
      "Val Loss: 0.0015193779296605904 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0013869521048097632 // Train Acc: 0.0\n",
      "Val Loss: 0.00148768269820477 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0013594515362258433 // Train Acc: 0.0\n",
      "Val Loss: 0.0014555587627737674 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0013318901731484722 // Train Acc: 0.0\n",
      "Val Loss: 0.001422783937084088 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0013047914899097688 // Train Acc: 0.0\n",
      "Val Loss: 0.0013902399642783212 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0012795918197913139 // Train Acc: 0.0\n",
      "Val Loss: 0.0013598060211317624 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0012569540260638193 // Train Acc: 0.0\n",
      "Val Loss: 0.001332439262063539 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [10:34<24:41, 211.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.06347824402184842 // Train Acc: 0.0\n",
      "Val Loss: 0.0534099161458415 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.003942365332543824 // Train Acc: 0.0\n",
      "Val Loss: 0.004016809081580677 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.002135267749714154 // Train Acc: 0.0\n",
      "Val Loss: 0.0022061967953334576 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.001760052174994615 // Train Acc: 0.0\n",
      "Val Loss: 0.0018762833661238492 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0016698790020632673 // Train Acc: 0.0\n",
      "Val Loss: 0.0018002643353499566 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0016208809279107852 // Train Acc: 0.0\n",
      "Val Loss: 0.0017533138124129148 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0015868967397205092 // Train Acc: 0.0\n",
      "Val Loss: 0.0017190226585397435 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.001561466942736905 // Train Acc: 0.0\n",
      "Val Loss: 0.0016923805021722515 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.001540936933457133 // Train Acc: 0.0\n",
      "Val Loss: 0.0016702464369532793 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.001523018879137527 // Train Acc: 0.0\n",
      "Val Loss: 0.0016506036007633777 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0015063780279469913 // Train Acc: 0.0\n",
      "Val Loss: 0.0016322700027847927 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0014902807516511203 // Train Acc: 0.0\n",
      "Val Loss: 0.0016145721055481417 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0014743209997302074 // Train Acc: 0.0\n",
      "Val Loss: 0.001597092965667854 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0014583010490667623 // Train Acc: 0.0\n",
      "Val Loss: 0.0015796073933532617 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0014422516132228803 // Train Acc: 0.0\n",
      "Val Loss: 0.0015621792027767742 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0014263619517752063 // Train Acc: 0.0\n",
      "Val Loss: 0.001545108579341114 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0014106993227779112 // Train Acc: 0.0\n",
      "Val Loss: 0.0015285503606678782 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.001395014796189201 // Train Acc: 0.0\n",
      "Val Loss: 0.001512216867058923 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0013787584354579161 // Train Acc: 0.0\n",
      "Val Loss: 0.0014953798592980305 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0013613621587946693 // Train Acc: 0.0\n",
      "Val Loss: 0.0014772064325025086 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [14:06<21:09, 211.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.08888720087759291 // Train Acc: 0.0\n",
      "Val Loss: 0.06280643397203371 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.0037464831572360403 // Train Acc: 0.0\n",
      "Val Loss: 0.0037783706735028733 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0023673896609298067 // Train Acc: 0.0\n",
      "Val Loss: 0.0024264027399021363 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0018700815554460717 // Train Acc: 0.0\n",
      "Val Loss: 0.0019589388684835285 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0016465060063311243 // Train Acc: 0.0\n",
      "Val Loss: 0.0017690771403585889 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0015740424244720776 // Train Acc: 0.0\n",
      "Val Loss: 0.0017079822573577985 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0015353665153723247 // Train Acc: 0.0\n",
      "Val Loss: 0.001670598763778712 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0015073967613864346 // Train Acc: 0.0\n",
      "Val Loss: 0.001641731841265947 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0014862958732473194 // Train Acc: 0.0\n",
      "Val Loss: 0.0016189283281128968 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0014700624094342062 // Train Acc: 0.0\n",
      "Val Loss: 0.001600761082507579 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0014571589424694806 // Train Acc: 0.0\n",
      "Val Loss: 0.0015859439630547861 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0014463888617512622 // Train Acc: 0.0\n",
      "Val Loss: 0.0015733803993295203 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0014368725571705311 // Train Acc: 0.0\n",
      "Val Loss: 0.0015621901956918863 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0014279493459375956 // Train Acc: 0.0\n",
      "Val Loss: 0.0015516298247160462 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0014190453596827528 // Train Acc: 0.0\n",
      "Val Loss: 0.0015409678438946335 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0014095592736336762 // Train Acc: 0.0\n",
      "Val Loss: 0.0015293823828427745 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0013988318610698022 // Train Acc: 0.0\n",
      "Val Loss: 0.0015160008354760269 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0013863313103096003 // Train Acc: 0.0\n",
      "Val Loss: 0.0015003376077163402 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0013721728050481426 // Train Acc: 0.0\n",
      "Val Loss: 0.0014830759297467784 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.001357167470836287 // Train Acc: 0.0\n",
      "Val Loss: 0.0014655375214197345 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [17:38<17:38, 211.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.06718119999281487 // Train Acc: 0.0\n",
      "Val Loss: 0.05827670057392653 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.003651159367870884 // Train Acc: 0.0\n",
      "Val Loss: 0.003861118435167692 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0024751422416221555 // Train Acc: 0.0\n",
      "Val Loss: 0.0026280117720656887 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0020880998583882133 // Train Acc: 0.0\n",
      "Val Loss: 0.002203359604681785 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.001801733334932795 // Train Acc: 0.0\n",
      "Val Loss: 0.0019128926258661664 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0015731967895134674 // Train Acc: 0.0\n",
      "Val Loss: 0.0017120945740519767 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0015069346127028775 // Train Acc: 0.0\n",
      "Val Loss: 0.0016516662064898113 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0014663940754544046 // Train Acc: 0.0\n",
      "Val Loss: 0.0016131719989590243 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0014376500173451296 // Train Acc: 0.0\n",
      "Val Loss: 0.0015860213215239138 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0014156903562966739 // Train Acc: 0.0\n",
      "Val Loss: 0.0015650539904151258 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0013970188114804845 // Train Acc: 0.0\n",
      "Val Loss: 0.0015464878544164562 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0013799491164706867 // Train Acc: 0.0\n",
      "Val Loss: 0.0015287072265744417 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0013636066407093591 // Train Acc: 0.0\n",
      "Val Loss: 0.001511020166896981 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.00134749485388856 // Train Acc: 0.0\n",
      "Val Loss: 0.0014931090693470798 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.001331376972488914 // Train Acc: 0.0\n",
      "Val Loss: 0.0014748759862027708 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0013152189748469468 // Train Acc: 0.0\n",
      "Val Loss: 0.0014563829211424516 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0012991524355431827 // Train Acc: 0.0\n",
      "Val Loss: 0.0014378263591658636 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0012834270818725224 // Train Acc: 0.0\n",
      "Val Loss: 0.001419499838255169 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0012683305120096263 // Train Acc: 0.0\n",
      "Val Loss: 0.0014017277742559141 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0012540836149862893 // Train Acc: 0.0\n",
      "Val Loss: 0.0013847607950479646 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [21:10<14:07, 211.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.1285584927817381 // Train Acc: 0.0\n",
      "Val Loss: 0.08815351197256723 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.004384034505110041 // Train Acc: 0.0\n",
      "Val Loss: 0.004297251868394708 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0023682775887951964 // Train Acc: 0.0\n",
      "Val Loss: 0.0024284216134377117 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0018718770964689642 // Train Acc: 0.0\n",
      "Val Loss: 0.001966651563868239 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0016988645574511623 // Train Acc: 0.0\n",
      "Val Loss: 0.0018144235134094839 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0016155402724442383 // Train Acc: 0.0\n",
      "Val Loss: 0.0017331123322621767 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0015583378171179572 // Train Acc: 0.0\n",
      "Val Loss: 0.0016766889207780508 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0015143369079837223 // Train Acc: 0.0\n",
      "Val Loss: 0.0016342812320529665 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.001480081291919245 // Train Acc: 0.0\n",
      "Val Loss: 0.0016022193277782798 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0014543789328692472 // Train Acc: 0.0\n",
      "Val Loss: 0.0015782701498184967 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.001434369325079579 // Train Acc: 0.0\n",
      "Val Loss: 0.001559030846611326 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0014172546313231456 // Train Acc: 0.0\n",
      "Val Loss: 0.0015418765531994621 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0014013755046049013 // Train Acc: 0.0\n",
      "Val Loss: 0.0015254856458625772 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.001385891503897864 // Train Acc: 0.0\n",
      "Val Loss: 0.0015092636115508226 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.001370403686303059 // Train Acc: 0.0\n",
      "Val Loss: 0.0014929533177595222 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0013547509943453795 // Train Acc: 0.0\n",
      "Val Loss: 0.0014764593056319853 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0013388695064615354 // Train Acc: 0.0\n",
      "Val Loss: 0.0014597290594198392 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.001322700138508145 // Train Acc: 0.0\n",
      "Val Loss: 0.001442675485260077 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0013061690820282427 // Train Acc: 0.0\n",
      "Val Loss: 0.001425196060438656 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0012892344676104777 // Train Acc: 0.0\n",
      "Val Loss: 0.0014072631540390866 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [24:41<10:35, 211.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.5727524693851551 // Train Acc: 0.0\n",
      "Val Loss: 0.4211711099360908 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.006254926559007184 // Train Acc: 0.0\n",
      "Val Loss: 0.0061330537067195556 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.003124614819367697 // Train Acc: 0.0\n",
      "Val Loss: 0.0031647390924009113 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.002121250809912882 // Train Acc: 0.0\n",
      "Val Loss: 0.0021704177023561975 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0017785784310604437 // Train Acc: 0.0\n",
      "Val Loss: 0.0018627331502717405 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0016281873068446032 // Train Acc: 0.0\n",
      "Val Loss: 0.001737258580770843 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0015615856371376518 // Train Acc: 0.0\n",
      "Val Loss: 0.0016800754306208364 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0015230216149588183 // Train Acc: 0.0\n",
      "Val Loss: 0.001645218792004646 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0014956806139420616 // Train Acc: 0.0\n",
      "Val Loss: 0.001619511117684582 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.001473502692003012 // Train Acc: 0.0\n",
      "Val Loss: 0.001598271978017484 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0014536541616488614 // Train Acc: 0.0\n",
      "Val Loss: 0.001579283786236501 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0014346635891947514 // Train Acc: 0.0\n",
      "Val Loss: 0.0015613471260931676 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0014158889609173484 // Train Acc: 0.0\n",
      "Val Loss: 0.00154392675448836 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0013974602130719437 // Train Acc: 0.0\n",
      "Val Loss: 0.0015271213495851542 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0013800193289106092 // Train Acc: 0.0\n",
      "Val Loss: 0.0015114071144359499 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.001364098818810901 // Train Acc: 0.0\n",
      "Val Loss: 0.0014971247449024274 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0013499445635760901 // Train Acc: 0.0\n",
      "Val Loss: 0.0014843907853225558 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0013376638961225737 // Train Acc: 0.0\n",
      "Val Loss: 0.0014732048298686212 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0013271970599799138 // Train Acc: 0.0\n",
      "Val Loss: 0.0014634154876498973 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.001318282780132918 // Train Acc: 0.0\n",
      "Val Loss: 0.0014547150393957064 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [28:13<07:03, 211.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.07294985634205552 // Train Acc: 0.0\n",
      "Val Loss: 0.06220812402540745 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.00391902288322064 // Train Acc: 0.0\n",
      "Val Loss: 0.0038774533921790274 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0021528757666221324 // Train Acc: 0.0\n",
      "Val Loss: 0.0022117027758579056 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0017290920382886433 // Train Acc: 0.0\n",
      "Val Loss: 0.0018268048643933182 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.001598723183600245 // Train Acc: 0.0\n",
      "Val Loss: 0.001714067469551306 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0015458383969782993 // Train Acc: 0.0\n",
      "Val Loss: 0.0016684148107153265 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0015115866963994894 // Train Acc: 0.0\n",
      "Val Loss: 0.0016395475820432724 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.0014853842961726003 // Train Acc: 0.0\n",
      "Val Loss: 0.0016176892524486272 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0014635021847295268 // Train Acc: 0.0\n",
      "Val Loss: 0.0015990872532142294 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0014439690981398574 // Train Acc: 0.0\n",
      "Val Loss: 0.0015817574537866463 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0014256300610558067 // Train Acc: 0.0\n",
      "Val Loss: 0.0015646702004791702 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.0014078573429996872 // Train Acc: 0.0\n",
      "Val Loss: 0.0015474016359986415 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.0013903791511564896 // Train Acc: 0.0\n",
      "Val Loss: 0.0015299176641508374 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.001373095521869087 // Train Acc: 0.0\n",
      "Val Loss: 0.001512273318328057 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.001356025130204206 // Train Acc: 0.0\n",
      "Val Loss: 0.0014945079943857172 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0013393573321525837 // Train Acc: 0.0\n",
      "Val Loss: 0.0014767829319345114 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0013233899516809462 // Train Acc: 0.0\n",
      "Val Loss: 0.0014594088081860987 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.001308348027300736 // Train Acc: 0.0\n",
      "Val Loss: 0.0014426968934849508 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0012942647063155393 // Train Acc: 0.0\n",
      "Val Loss: 0.0014267983810921517 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.00128103163149087 // Train Acc: 0.0\n",
      "Val Loss: 0.0014117141114417776 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [31:45<03:31, 211.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.06973617501964409 // Train Acc: 0.0\n",
      "Val Loss: 0.06121800057381891 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.004644754964487332 // Train Acc: 0.0\n",
      "Val Loss: 0.004781188576627918 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.002947079404639302 // Train Acc: 0.0\n",
      "Val Loss: 0.0029374094141449507 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.002100832617508906 // Train Acc: 0.0\n",
      "Val Loss: 0.0021689041132658886 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0018141436891262596 // Train Acc: 0.0\n",
      "Val Loss: 0.001889912425553395 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0016486944417790203 // Train Acc: 0.0\n",
      "Val Loss: 0.0017307753459740347 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0015380977642394898 // Train Acc: 0.0\n",
      "Val Loss: 0.0016319716540126223 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.001476559279814557 // Train Acc: 0.0\n",
      "Val Loss: 0.0015825679048609026 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0014422391774581854 // Train Acc: 0.0\n",
      "Val Loss: 0.0015557238479049268 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.0014181332603718387 // Train Acc: 0.0\n",
      "Val Loss: 0.0015345421357860127 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0013977923298616754 // Train Acc: 0.0\n",
      "Val Loss: 0.00151435902929805 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.001379367910547745 // Train Acc: 0.0\n",
      "Val Loss: 0.001494661526277781 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.001362289761671167 // Train Acc: 0.0\n",
      "Val Loss: 0.001475614655971678 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0013462831981166307 // Train Acc: 0.0\n",
      "Val Loss: 0.00145731596722477 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0013311397949861282 // Train Acc: 0.0\n",
      "Val Loss: 0.0014397456102897856 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0013166750210345832 // Train Acc: 0.0\n",
      "Val Loss: 0.001422815618310748 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0013027224261287552 // Train Acc: 0.0\n",
      "Val Loss: 0.0014064123297328722 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0012891382086301368 // Train Acc: 0.0\n",
      "Val Loss: 0.001390426136807255 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0012758021980676236 // Train Acc: 0.0\n",
      "Val Loss: 0.0013747595803579316 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0012626210323328853 // Train Acc: 0.0\n",
      "Val Loss: 0.0013593427078244303 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [35:16<00:00, 211.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2841, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.13658790774348153 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.06550388739266422 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.0051994526245455345 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004295591552731361 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.004762809369121764 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0037603120769510107 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004637681053892329 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036405001647948298 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.0045579458800286896 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035891204927210813 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.00449395410626108 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035690906156100374 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0044422998808015535 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035580673766468936 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.00440122785284756 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035464395873583436 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.004368285510233509 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035331449654539314 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.00434099706818683 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003519057509753581 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.004317433772149743 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035048694522486308 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.004296268702906346 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003490761633023222 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.004276626998621077 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034765266235185304 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.004257926622630482 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003461884909238813 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.00423978706545755 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003446723972813467 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.004221996434607766 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003431230715117574 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.0042044818731974635 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034159273448729826 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.004187260280248538 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034015018498169238 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.004170393396202088 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003388595000155312 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.004153932438532577 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0033775777918982498 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [07:13<1:04:57, 433.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.25124366545269716 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.0666524652140529 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.00621413948713947 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.005390260808413137 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.005103581578607943 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004116323365165402 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004926435348168422 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0038614568138348585 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004841065889853699 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0037435338347810163 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.004785857314771088 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036817992114582298 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.004742833640789484 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003639169400322429 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.004706377177619956 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003604073111122223 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.004673547133596681 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035733894315506383 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.004642787076619883 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035449701840099828 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.004613688032820549 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035171053919083113 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.004586479485248243 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034897924005838758 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.004561360786510404 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003464207254295248 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.004538207696814581 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003441148995110514 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.004516639420566582 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034205690865062198 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.00449613157880912 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034018147258046134 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.004476094680914872 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.00338399757384558 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.004455867978180433 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003366299068556544 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.004434445164626362 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003348286197425306 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.004409306227423151 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003330441684922559 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [14:25<57:40, 432.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.1403765632663921 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.04968264906175351 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.006380675476206813 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.005657342473160099 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0052003626061693856 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004412492207418918 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004861957111679321 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003995997199116358 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004740695330290348 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0038207380321489 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.004680978597513655 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003727514829141287 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.004642063518121064 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036799414534634503 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.004610826582540979 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003657632230079911 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.004585238434135197 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036462576915326874 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.004564511116432295 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036382061243580466 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0045467125915433495 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003631530304405357 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.004530291895793789 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003625791291464277 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.004514429900760466 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036206087919954063 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0044987467143751065 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003615564259561825 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.004483090253245261 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036102419814259715 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.004467423571096216 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003604429672940456 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.004451768996794228 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035981098479353248 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.004436148422455865 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035914991191899654 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.0044205734953994755 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003584794494129843 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.004405048298734841 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035781384791702744 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [21:37<50:26, 432.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.0793420695890445 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.05338449719665426 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.005790337071487375 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004517742211922605 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0049651272008930615 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003545290782650033 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0048054049268146225 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003422468195975434 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 41\n",
      "Epoch: 41\n",
      "Train Loss: 0.004724675401244952 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034131283572288963 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 42\n",
      "INFO: Validation loss did not improve in epoch 43\n",
      "INFO: Validation loss did not improve in epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [23:14<30:00, 300.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Validation loss did not improve in epoch 45\n",
      "Early stopping after 45 epochs\n",
      "Epoch: 1\n",
      "Train Loss: 0.05247540287968741 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.03285270740979173 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.005054544325100745 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004083370940963832 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.00474542437529264 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036529998203119513 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.0046476622046467565 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003541496485698016 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004570905169026276 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034639356661786773 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0045014458129156625 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0033888669069424755 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.0044375924147516945 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003312329505962644 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.004382500369829935 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0032412600538397752 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0043363406247657115 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0031828882940848663 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.004294017063744601 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0031373633916772317 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.004251653018411061 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003101117765888038 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.004208874101492194 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0030694720047536525 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.004168371302843841 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0030386552636137527 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.004132513285919352 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003008036852488556 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.0041013108970089284 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0029790358645043575 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.004073592802533349 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0029533669462733577 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.00404784684721888 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.002934171249364042 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 171\n",
      "Epoch: 171\n",
      "Train Loss: 0.00402255461650748 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.002927294627860126 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 172\n",
      "INFO: Validation loss did not improve in epoch 173\n",
      "INFO: Validation loss did not improve in epoch 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [29:33<27:21, 328.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Validation loss did not improve in epoch 175\n",
      "Early stopping after 175 epochs\n",
      "Epoch: 1\n",
      "Train Loss: 0.19074838435894945 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.04755104474430339 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.005627627308724037 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.005212040928066865 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.004873622996174968 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004024754773453924 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004740371585758544 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003692420898659385 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004692380516726033 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036195911515472727 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.00465822108150669 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035913564804993738 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.004628423574957117 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035734849048679003 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.004598150992569332 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035584185248256524 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.004563769342626452 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035415274127689974 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.004523015191783616 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035189269411409004 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.0044769895552286 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034919877899902236 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.004430496787854293 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003466834084770454 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.004387811447228145 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003444259850409018 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.004347990681602598 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034207108571505424 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.004308196389899651 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0033928251397217822 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.004268043601298056 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003359371083206497 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.004230244735098131 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.0033241812237198307 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.004197002718040733 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.0032919330716661564 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.004168643064416614 // Train Acc: 0.00619220607661823\n",
      "Val Loss: 0.0032644880243270983 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.0041443786077580294 // Train Acc: 0.00619220607661823\n",
      "Val Loss: 0.0032417806386332852 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [36:45<24:15, 363.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.09403583182137622 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.042368601149555006 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.006096460372151111 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.005262912100957958 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.004993266358880401 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003787920414110426 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004812670643494435 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003670042360415996 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004712202483485945 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035839991798046244 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.0046331441783299485 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003544234484793838 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 58\n",
      "INFO: Validation loss did not improve in epoch 59\n",
      "INFO: Validation loss did not improve in epoch 60\n",
      "INFO: Validation loss did not improve in epoch 61\n",
      "Epoch: 61\n",
      "Train Loss: 0.0045631069818514985 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035413980916969142 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [39:00<14:26, 288.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Validation loss did not improve in epoch 62\n",
      "Early stopping after 62 epochs\n",
      "Epoch: 1\n",
      "Train Loss: 0.19238662134605009 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.06312016343300263 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.0058636600182799545 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0049192592239378835 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.005028121636544085 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0038854674597367583 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004825951831333482 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036763101124552633 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004712339743686246 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003596926584945772 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.004635728133043897 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003553353670397198 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.004578884167592391 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035129297965172195 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.004517882890354035 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034617025971221686 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.004452814111443632 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034264164922492095 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 88\n",
      "INFO: Validation loss did not improve in epoch 90\n",
      "Epoch: 91\n",
      "Train Loss: 0.00438310932151972 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034074898108740577 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 98\n",
      "INFO: Validation loss did not improve in epoch 100\n",
      "INFO: Validation loss did not improve in epoch 101\n",
      "Epoch: 101\n",
      "Train Loss: 0.004365194406779606 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034708360843151136 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 102\n",
      "INFO: Validation loss did not improve in epoch 109\n",
      "Epoch: 111\n",
      "Train Loss: 0.004289071902828328 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003363218243178922 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 113\n",
      "INFO: Validation loss did not improve in epoch 118\n",
      "INFO: Validation loss did not improve in epoch 120\n",
      "INFO: Validation loss did not improve in epoch 121\n",
      "Epoch: 121\n",
      "Train Loss: 0.004245775329533324 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003338425381964575 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 122\n",
      "INFO: Validation loss did not improve in epoch 123\n",
      "INFO: Validation loss did not improve in epoch 128\n",
      "INFO: Validation loss did not improve in epoch 129\n",
      "Epoch: 131\n",
      "Train Loss: 0.004214687258142934 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0032963342497025856 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 132\n",
      "INFO: Validation loss did not improve in epoch 134\n",
      "INFO: Validation loss did not improve in epoch 135\n",
      "INFO: Validation loss did not improve in epoch 138\n",
      "INFO: Validation loss did not improve in epoch 139\n",
      "INFO: Validation loss did not improve in epoch 141\n",
      "Epoch: 141\n",
      "Train Loss: 0.0041850343610491 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0032657458117621523 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 142\n",
      "INFO: Validation loss did not improve in epoch 145\n",
      "INFO: Validation loss did not improve in epoch 147\n",
      "INFO: Validation loss did not improve in epoch 150\n",
      "INFO: Validation loss did not improve in epoch 151\n",
      "Epoch: 151\n",
      "Train Loss: 0.004148528367081654 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003240595617641569 // Val Acc: 0.0\n",
      "**************************************************\n",
      "INFO: Validation loss did not improve in epoch 154\n",
      "INFO: Validation loss did not improve in epoch 157\n",
      "INFO: Validation loss did not improve in epoch 158\n",
      "INFO: Validation loss did not improve in epoch 159\n",
      "INFO: Validation loss did not improve in epoch 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [44:49<10:16, 308.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Validation loss did not improve in epoch 161\n",
      "Early stopping after 161 epochs\n",
      "Epoch: 1\n",
      "Train Loss: 0.08345506431306055 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.05824228292435742 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.0054646812905612815 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004240151807035351 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.0049692450703192155 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003555869530255938 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004869754890189414 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034687591044969984 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004804339145773578 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034491641890372704 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.004749892830844542 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003435761845027086 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.004701815892363556 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034201180547988566 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.00465910343375319 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003401842102862298 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.004621583727054461 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0033827342064868073 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.004588309929181288 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003364687253462067 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.004557748514420877 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0033483071073829563 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.004528462032956973 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0033331242899457517 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.004499284995505568 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003318287973394199 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.004468969544348131 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003303087650329984 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.004434626399772549 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003287351413419355 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.00438859986032598 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003271361892902962 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.004329320307951138 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003250094065887414 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.0042676554737588615 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0032189002751406765 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.004209933411679077 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0031828843313857933 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.004159592497491621 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0031465984123243604 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [52:08<05:48, 348.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.17576842900990575 // Train Acc: 0.004128137384412154\n",
      "Val Loss: 0.047928934226210196 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Train Loss: 0.0057303445648846105 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.004730348776126009 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Train Loss: 0.005037950094225029 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0038755395216867328 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Train Loss: 0.004874083435208576 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0036402271875426214 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Train Loss: 0.004806853895442551 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035767079794680008 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Train Loss: 0.004755556337444494 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035530227456199988 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Train Loss: 0.004704367201249367 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035374678057890512 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Train Loss: 0.00464989463130121 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003521771528274135 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Train Loss: 0.0045935473677754845 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0035030200826972097 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Train Loss: 0.00453788896367788 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003480627879387898 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Train Loss: 0.004485135798533527 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034550484505304125 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Train Loss: 0.004436762221336711 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0034272051059897318 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Train Loss: 0.004393419580772621 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003398082670010103 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Train Loss: 0.0043550825485888294 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003368521583059886 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Train Loss: 0.004321303201359979 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0033392293893423435 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Train Loss: 0.0042914348863058475 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.003310753646525136 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Train Loss: 0.004264832371485984 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0032834459934645236 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Train Loss: 0.004240936961162945 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.00325744368447896 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Train Loss: 0.004219302774273638 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0032327757853023143 // Val Acc: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Train Loss: 0.004199588352741576 // Train Acc: 0.002064068692206077\n",
      "Val Loss: 0.0032093782807514596 // Val Acc: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [59:27<00:00, 356.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictive performance\n",
    "predictive_results = predictive_evaluation(data_real_numpy, data_syn_numpy, hyperparameters, include_baseline=True, verbose=True)\n",
    "\n",
    "# save results\n",
    "bidirectionality = \"bi\" if hyperparameters[\"bidirectional\"] else 'no_bi'\n",
    "predictive_results.to_csv(DATA_FOLDER / f\"results_{syn_data_type}_{hyperparameters['num_epochs']}_{hyperparameters['num_evaluation_runs']}_{bidirectionality}.csv\", index=False)\n",
    "\n",
    "# split in mse and mae results\n",
    "mse_results = predictive_results.loc[predictive_results['Metric'] == 'MSE']\n",
    "mae_results = predictive_results.loc[predictive_results['Metric'] == 'MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e81ebfcad0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Model', y='Error', hue='Model', data=mse_results)\n",
    "sns.stripplot(x='Model', y='Error', hue='Metric', data=mse_results, dodge=True, jitter=True, palette='dark:black', alpha=0.7)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Metric')\n",
    "plt.title(f'MSE | {syn_data_type} | {hyperparameters[\"num_evaluation_runs\"]} Training Runs {\" | jitter factor = \" + str(jitter_factor) if syn_data_type == \"jitter\" else \"\"}')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Model', y='Error', hue='Model', data=mae_results)\n",
    "sns.stripplot(x='Model', y='Error', hue='Metric', data=mae_results, dodge=True, jitter=True, palette='dark:black', alpha=0.7)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel('Metric')\n",
    "plt.title(f'MAE | {syn_data_type} | {hyperparameters[\"num_evaluation_runs\"]} Training Runs {\" | jitter factor = \" + str(jitter_factor) if syn_data_type == \"jitter\" else \"\"}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2*1e06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series_data_augmentation_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
