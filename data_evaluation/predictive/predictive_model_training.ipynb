{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Imports and Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "from utilities import split_data_into_sequences, load_sequential_time_series, reconstruct_sequential_data, Scaler, extract_features_and_targets_reg, get_discriminative_test_performance\n",
    "from data_evaluation.visual.visual_evaluation import visual_evaluation\n",
    "from predictive_evaluation import predictive_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../../data\")\n",
    "REAL_DATA_FOLDER = DATA_FOLDER / \"real\"\n",
    "SYNTHETIC_DATA_FOLDER = DATA_FOLDER / \"synthetic\" / \"usable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load and Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways of loading data\n",
    "- Laden der Originaldaten: als pd dataframe \n",
    "- Laden der synthetischen, sequentiellen Daten: als np array (GAN, (V)AE)\n",
    "- Laden der synthetischen, sequentiellen Daten: als pd dataframe (brownian, algorithmit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible types: 'timegan_lstm', 'timegan_gru', 'jitter', 'timewarp', 'autoencoder'\n",
    "syn_data_type = 'timewarp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " syn data:\n",
      "\n",
      "       traffic_volume          temp       rain_1h       snow_1h    clouds_all\n",
      "count    28511.000000  28511.000000  28511.000000  28511.000000  28511.000000\n",
      "mean      3299.968450    283.470261      0.074592      0.000267     42.295143\n",
      "std       1933.184262     12.065327      0.714961      0.008246     37.772630\n",
      "min          0.091959    243.521770      0.000000      0.000000      0.000000\n",
      "25%       1398.199030    274.298446      0.000000      0.000000      1.000000\n",
      "50%       3557.701883    285.584000      0.000000      0.000000     39.347654\n",
      "75%       4922.942623    293.171000      0.000000      0.000000     88.303943\n",
      "max       7131.318552    309.429771     41.664261      0.510000    100.000000\n",
      "\n",
      "\n",
      "real data:\n",
      "\n",
      "       traffic_volume          temp       rain_1h       snow_1h    clouds_all\n",
      "count     28511.00000  28511.000000  28511.000000  28511.000000  28511.000000\n",
      "mean       3313.74238    282.688768      0.061611      0.000250     42.122795\n",
      "std        1971.53206     12.367361      0.678185      0.008298     39.316195\n",
      "min           0.00000    243.390000      0.000000      0.000000      0.000000\n",
      "25%        1289.00000    273.480000      0.000000      0.000000      1.000000\n",
      "50%        3507.00000    284.550000      0.000000      0.000000     40.000000\n",
      "75%        4948.00000    292.790000      0.000000      0.000000     90.000000\n",
      "max        7280.00000    310.070000     42.000000      0.510000    100.000000\n"
     ]
    }
   ],
   "source": [
    "# Load real time series\n",
    "data_real_df = pd.read_csv(REAL_DATA_FOLDER/'metro_interstate_traffic_volume_label_encoded_no_categorical.csv')\n",
    "data_real_numpy = dc(data_real_df).to_numpy()\n",
    "\n",
    "if syn_data_type == 'timegan_lstm':\n",
    "    # load sequential data (which should already be scaled)\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28499_12_5_lstm_unscaled.csv', shape=(28499, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'timegan_gru':\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28499_12_5_gru_unscaled.csv', shape=(28499, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'autoencoder':\n",
    "    data_syn_numpy = load_sequential_time_series(SYNTHETIC_DATA_FOLDER/'mitv_28478_12_5_autoencoder_unscaled.csv', shape=(28478, 12, 5))\n",
    "\n",
    "elif syn_data_type == 'jitter':\n",
    "    jitter_factor = 0.1\n",
    "    data_syn_df = pd.read_csv(SYNTHETIC_DATA_FOLDER/f'mitv_jittered_{str(jitter_factor).replace(\".\", \"\")}.csv')\n",
    "    data_syn_numpy = dc(data_syn_df).to_numpy()\n",
    "\n",
    "elif syn_data_type == 'timewarp':\n",
    "    data_syn_df = pd.read_csv(SYNTHETIC_DATA_FOLDER/f'mitv_time_warped.csv')\n",
    "    data_syn_numpy = dc(data_syn_df).to_numpy()\n",
    "\n",
    "# Loot at real and syn data\n",
    "df = pd.DataFrame(data_syn_numpy.reshape(-1, data_syn_numpy.shape[-1]), columns=data_real_df.columns)\n",
    "\n",
    "print('\\n\\n syn data:\\n')\n",
    "print(df.describe())\n",
    "\n",
    "print('\\n\\nreal data:\\n')\n",
    "print(data_real_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Predictive Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"seq_len\": 12,\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 32,\n",
    "    \"hidden_size\": 4,\n",
    "    \"num_layers\": 1,\n",
    "    \"bidirectional\": True,\n",
    "    \"num_evaluation_runs\": 10,\n",
    "    \"num_epochs\": 200,\n",
    "    \"device\": 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETERS:\n",
      "seq_len :  12\n",
      "lr :  0.0001\n",
      "batch_size :  32\n",
      "hidden_size :  4\n",
      "num_layers :  1\n",
      "bidirectional :  True\n",
      "num_evaluation_runs :  10\n",
      "num_epochs :  200\n",
      "device :  cpu\n",
      "Synthetic Data is sequential: False\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2841, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.16356404960155488\n",
      "Training Loss: 0.11791826590895653\n",
      "Training Loss: 0.0930770741775632\n",
      "Validation Loss: 0.07376920645324032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.07278344415128231\n",
      "Training Loss: 0.06760959178209305\n",
      "Training Loss: 0.06572964731603861\n",
      "Validation Loss: 0.06035171089212546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06315679116174579\n",
      "Training Loss: 0.06158516261726618\n",
      "Training Loss: 0.0604852687753737\n",
      "Validation Loss: 0.05553730418173115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.058031433206051586\n",
      "Training Loss: 0.0564726185426116\n",
      "Training Loss: 0.05502623919397592\n",
      "Validation Loss: 0.04976148840584112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.05198590019717812\n",
      "Training Loss: 0.050168855022639035\n",
      "Training Loss: 0.04807432641275227\n",
      "Validation Loss: 0.04221409052777826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04405510004609823\n",
      "Training Loss: 0.041827231384813784\n",
      "Training Loss: 0.03894686710089445\n",
      "Validation Loss: 0.03272194714609827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03401145589537918\n",
      "Training Loss: 0.032011252082884314\n",
      "Training Loss: 0.029099086401984095\n",
      "Validation Loss: 0.023718863924483906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.02475867002736777\n",
      "Training Loss: 0.02382366717327386\n",
      "Training Loss: 0.021484023593366146\n",
      "Validation Loss: 0.017237553357282717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.018210266723763198\n",
      "Training Loss: 0.018122182800434528\n",
      "Training Loss: 0.016538860488217323\n",
      "Validation Loss: 0.013199569254569459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.014341612190473824\n",
      "Training Loss: 0.014829979871865361\n",
      "Training Loss: 0.013944900708738715\n",
      "Validation Loss: 0.011153319552331493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01250455794041045\n",
      "Training Loss: 0.013238167951349168\n",
      "Training Loss: 0.012764209643937647\n",
      "Validation Loss: 0.010172554129588136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011655630867462605\n",
      "Training Loss: 0.012399607633706183\n",
      "Training Loss: 0.012075187023729086\n",
      "Validation Loss: 0.009515867236311013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.011090620278846473\n",
      "Training Loss: 0.01179485564935021\n",
      "Training Loss: 0.011535206660628319\n",
      "Validation Loss: 0.008972029264472174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010628902550088241\n",
      "Training Loss: 0.011293011148227379\n",
      "Training Loss: 0.011073712008073926\n",
      "Validation Loss: 0.008495350323847673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010229599331505596\n",
      "Training Loss: 0.010856325031490997\n",
      "Training Loss: 0.010667814998887479\n",
      "Validation Loss: 0.008068730131189307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009876875553745777\n",
      "Training Loss: 0.010469239839585498\n",
      "Training Loss: 0.010306345028802753\n",
      "Validation Loss: 0.007683441100453728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009562747279414908\n",
      "Training Loss: 0.010123771176440642\n",
      "Training Loss: 0.009982680506072938\n",
      "Validation Loss: 0.007334201617605901\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009282247131923214\n",
      "Training Loss: 0.009814728697529062\n",
      "Training Loss: 0.009692095617065206\n",
      "Validation Loss: 0.007017174610093738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009031614761333913\n",
      "Training Loss: 0.009538050066912546\n",
      "Training Loss: 0.009430849608033896\n",
      "Validation Loss: 0.00672930505733644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008807747145183384\n",
      "Training Loss: 0.00929035351262428\n",
      "Training Loss: 0.009195964985992759\n",
      "Validation Loss: 0.006468170092263249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008608087853062898\n",
      "Training Loss: 0.009068860751576723\n",
      "Training Loss: 0.008985128970816731\n",
      "Validation Loss: 0.006231927723634277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008430556781822815\n",
      "Training Loss: 0.008871319980826228\n",
      "Training Loss: 0.008796537406742572\n",
      "Validation Loss: 0.006019165624309791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008273407111410051\n",
      "Training Loss: 0.008695851219817996\n",
      "Training Loss: 0.008628678261302411\n",
      "Validation Loss: 0.005828659897774793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008135059133637696\n",
      "Training Loss: 0.008540757138980552\n",
      "Training Loss: 0.008480118630686775\n",
      "Validation Loss: 0.005659135556884445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008013953792396934\n",
      "Training Loss: 0.008404376088874415\n",
      "Training Loss: 0.00834937094943598\n",
      "Validation Loss: 0.005509161929275547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007908484766958282\n",
      "Training Loss: 0.008285000293981284\n",
      "Training Loss: 0.008234828823478892\n",
      "Validation Loss: 0.005377065504147681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007816983597585932\n",
      "Training Loss: 0.008180863223969936\n",
      "Training Loss: 0.00813478764379397\n",
      "Validation Loss: 0.005261010491665913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007737762404140085\n",
      "Training Loss: 0.008090183570748194\n",
      "Training Loss: 0.008047511305194347\n",
      "Validation Loss: 0.005159076403962511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007669172086752951\n",
      "Training Loss: 0.008011217248858884\n",
      "Training Loss: 0.007971296113682911\n",
      "Validation Loss: 0.005069353931656714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007609659341396764\n",
      "Training Loss: 0.00794231886859052\n",
      "Training Loss: 0.007904544689226896\n",
      "Validation Loss: 0.004990043618266334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007557805844116956\n",
      "Training Loss: 0.007881976807257161\n",
      "Training Loss: 0.007845800585346296\n",
      "Validation Loss: 0.004919501763161565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007512352133635432\n",
      "Training Loss: 0.007828843871830032\n",
      "Training Loss: 0.007793776042526588\n",
      "Validation Loss: 0.004856274043356351\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007472206376260147\n",
      "Training Loss: 0.007781743961386383\n",
      "Training Loss: 0.0077473609591834245\n",
      "Validation Loss: 0.004799113894048869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007436441667377949\n",
      "Training Loss: 0.007739670228911564\n",
      "Training Loss: 0.007705614309525117\n",
      "Validation Loss: 0.00474697518361251\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007404284813674167\n",
      "Training Loss: 0.0077017788914963605\n",
      "Training Loss: 0.0076677517883945254\n",
      "Validation Loss: 0.004698995925915124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007375101340003311\n",
      "Training Loss: 0.007667367729591206\n",
      "Training Loss: 0.007633132559712976\n",
      "Validation Loss: 0.004654487696989031\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007348380013136193\n",
      "Training Loss: 0.007635867410572246\n",
      "Training Loss: 0.007601235583424568\n",
      "Validation Loss: 0.004612896909278011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007323712196666748\n",
      "Training Loss: 0.007606815530452877\n",
      "Training Loss: 0.0075716442498378455\n",
      "Validation Loss: 0.004573801354494657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007300776412012056\n",
      "Training Loss: 0.007579842328559607\n",
      "Training Loss: 0.0075440245680511\n",
      "Validation Loss: 0.004536871091996351\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007279319907538593\n",
      "Training Loss: 0.0075546505081001665\n",
      "Training Loss: 0.00751811244059354\n",
      "Validation Loss: 0.0045018556640284615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007259144693380222\n",
      "Training Loss: 0.0075310039450414475\n",
      "Training Loss: 0.007493694657459855\n",
      "Validation Loss: 0.004468562417621776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0072400963853579015\n",
      "Training Loss: 0.007508711265400052\n",
      "Training Loss: 0.007470603375695646\n",
      "Validation Loss: 0.0044368472397641355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007222052577417344\n",
      "Training Loss: 0.007487619143212214\n",
      "Training Loss: 0.007448700164677575\n",
      "Validation Loss: 0.004406593551629045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0072049142874311654\n",
      "Training Loss: 0.00746759979869239\n",
      "Training Loss: 0.007427870572428219\n",
      "Validation Loss: 0.004377711653248982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007188600336667151\n",
      "Training Loss: 0.007448547902749851\n",
      "Training Loss: 0.007408020031871274\n",
      "Validation Loss: 0.004350127984528963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007173044933006167\n",
      "Training Loss: 0.007430375388357788\n",
      "Training Loss: 0.007389067824115045\n",
      "Validation Loss: 0.004323778798270008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007158189638284966\n",
      "Training Loss: 0.0074130042584147305\n",
      "Training Loss: 0.007370943823480048\n",
      "Validation Loss: 0.004298608642845844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007143984261201695\n",
      "Training Loss: 0.007396369249327108\n",
      "Training Loss: 0.007353585922974162\n",
      "Validation Loss: 0.004274565200687626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007130384118063375\n",
      "Training Loss: 0.0073804123664740475\n",
      "Training Loss: 0.007336939624510705\n",
      "Validation Loss: 0.004251602279765301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007117348943138495\n",
      "Training Loss: 0.007365080034360289\n",
      "Training Loss: 0.007320954516180791\n",
      "Validation Loss: 0.004229675618711901\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007104842255357653\n",
      "Training Loss: 0.007350328309694305\n",
      "Training Loss: 0.007305587423034012\n",
      "Validation Loss: 0.004208737393066789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007092830130131915\n",
      "Training Loss: 0.007336114331847057\n",
      "Training Loss: 0.0072907966939965265\n",
      "Validation Loss: 0.004188747427771601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.0070812818594276905\n",
      "Training Loss: 0.007322401028359309\n",
      "Training Loss: 0.007276544361957349\n",
      "Validation Loss: 0.004169660757735288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00707016747794114\n",
      "Training Loss: 0.007309154331451282\n",
      "Training Loss: 0.007262796988943592\n",
      "Validation Loss: 0.004151436661139884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00705945972702466\n",
      "Training Loss: 0.007296344020869583\n",
      "Training Loss: 0.007249523077043705\n",
      "Validation Loss: 0.0041340359688077245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007049134634435177\n",
      "Training Loss: 0.007283941669156775\n",
      "Training Loss: 0.007236693781451322\n",
      "Validation Loss: 0.004117419026279299\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007039168417686596\n",
      "Training Loss: 0.007271922759246081\n",
      "Training Loss: 0.007224282856332138\n",
      "Validation Loss: 0.0041015493471614935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007029538776259869\n",
      "Training Loss: 0.007260262819472701\n",
      "Training Loss: 0.007212264413246885\n",
      "Validation Loss: 0.004086382772114253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0070202257507480685\n",
      "Training Loss: 0.007248941693687811\n",
      "Training Loss: 0.007200616832124069\n",
      "Validation Loss: 0.004071891415089871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007011210899800062\n",
      "Training Loss: 0.007237940055783838\n",
      "Training Loss: 0.00718931887880899\n",
      "Validation Loss: 0.004058038733449628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007002476558554917\n",
      "Training Loss: 0.007227240290958435\n",
      "Training Loss: 0.0071783510717796165\n",
      "Validation Loss: 0.004044790646281052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006994005849119276\n",
      "Training Loss: 0.007216825793730095\n",
      "Training Loss: 0.007167696161777712\n",
      "Validation Loss: 0.004032118565120389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006985784384887665\n",
      "Training Loss: 0.007206681115785613\n",
      "Training Loss: 0.00715733653283678\n",
      "Validation Loss: 0.004019989209574009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006977797409053892\n",
      "Training Loss: 0.007196794365299865\n",
      "Training Loss: 0.0071472580218687656\n",
      "Validation Loss: 0.004008375999015453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00697003269684501\n",
      "Training Loss: 0.0071871513593941925\n",
      "Training Loss: 0.007137445289408788\n",
      "Validation Loss: 0.0039972532671363505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006962477613706141\n",
      "Training Loss: 0.007177740273764357\n",
      "Training Loss: 0.007127885117079132\n",
      "Validation Loss: 0.003986593866930082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006955120135098696\n",
      "Training Loss: 0.007168550710193813\n",
      "Training Loss: 0.007118564554257318\n",
      "Validation Loss: 0.003976373328942429\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006947949164314195\n",
      "Training Loss: 0.007159571188967675\n",
      "Training Loss: 0.0071094724955037235\n",
      "Validation Loss: 0.003966571179773198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00694095647893846\n",
      "Training Loss: 0.007150793486507609\n",
      "Training Loss: 0.007100596908712759\n",
      "Validation Loss: 0.003957162112824284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006934130742447451\n",
      "Training Loss: 0.007142206972930581\n",
      "Training Loss: 0.007091927755973302\n",
      "Validation Loss: 0.003948126380656208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006927463790634647\n",
      "Training Loss: 0.007133803609758615\n",
      "Training Loss: 0.007083454966777936\n",
      "Validation Loss: 0.003939445486313172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00692094708327204\n",
      "Training Loss: 0.007125574399251491\n",
      "Training Loss: 0.007075169315212407\n",
      "Validation Loss: 0.00393109950969477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.0069145723909605295\n",
      "Training Loss: 0.00711751312832348\n",
      "Training Loss: 0.00706706091936212\n",
      "Validation Loss: 0.003923072555531444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006908332123421132\n",
      "Training Loss: 0.0071096107084304095\n",
      "Training Loss: 0.007059122181963176\n",
      "Validation Loss: 0.0039153483518388835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006902219966286793\n",
      "Training Loss: 0.00710186067270115\n",
      "Training Loss: 0.007051344119245187\n",
      "Validation Loss: 0.003907909221800693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00689622821402736\n",
      "Training Loss: 0.007094255408737808\n",
      "Training Loss: 0.007043719532084651\n",
      "Validation Loss: 0.0039007396324736514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0068903497920837255\n",
      "Training Loss: 0.007086789124878123\n",
      "Training Loss: 0.007036240306915715\n",
      "Validation Loss: 0.003893826885431419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006884579724865034\n",
      "Training Loss: 0.007079454910708592\n",
      "Training Loss: 0.007028899768483825\n",
      "Validation Loss: 0.003887157755108613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006878910803934559\n",
      "Training Loss: 0.007072246603202075\n",
      "Training Loss: 0.007021690905676223\n",
      "Validation Loss: 0.0038807168184371477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006873338598525152\n",
      "Training Loss: 0.007065158035838976\n",
      "Training Loss: 0.007014606752200052\n",
      "Validation Loss: 0.003874492542451938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006867856624303385\n",
      "Training Loss: 0.0070581845159176735\n",
      "Training Loss: 0.007007641962845809\n",
      "Validation Loss: 0.003868476202544034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006862460477277637\n",
      "Training Loss: 0.007051319314632565\n",
      "Training Loss: 0.0070007891248678785\n",
      "Validation Loss: 0.0038626530819855045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006857144888490438\n",
      "Training Loss: 0.0070445581653621045\n",
      "Training Loss: 0.0069940433668671175\n",
      "Validation Loss: 0.003857013108888955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0068519051535986366\n",
      "Training Loss: 0.007037895584944636\n",
      "Training Loss: 0.006987399120698683\n",
      "Validation Loss: 0.0038515479458244833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00684673753916286\n",
      "Training Loss: 0.007031325756106526\n",
      "Training Loss: 0.006980850415420719\n",
      "Validation Loss: 0.003846247424109933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006841636101016775\n",
      "Training Loss: 0.00702484511421062\n",
      "Training Loss: 0.006974392463453114\n",
      "Validation Loss: 0.0038411005980889786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0068365979182999585\n",
      "Training Loss: 0.007018448787275702\n",
      "Training Loss: 0.006968020146596246\n",
      "Validation Loss: 0.0038361010439903215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006831619214499369\n",
      "Training Loss: 0.00701213231193833\n",
      "Training Loss: 0.006961728778551332\n",
      "Validation Loss: 0.0038312414773541054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006826696465723216\n",
      "Training Loss: 0.007005891930311918\n",
      "Training Loss: 0.006955514607834629\n",
      "Validation Loss: 0.0038265109355195186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00682182491174899\n",
      "Training Loss: 0.00699972317321226\n",
      "Training Loss: 0.006949372839881107\n",
      "Validation Loss: 0.0038219027213354626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006817002941388637\n",
      "Training Loss: 0.00699362198705785\n",
      "Training Loss: 0.0069432992895599455\n",
      "Validation Loss: 0.0038174098184897325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006812225434696301\n",
      "Training Loss: 0.006987585499882698\n",
      "Training Loss: 0.0069372898171423\n",
      "Validation Loss: 0.0038130243434413764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0068074902845546605\n",
      "Training Loss: 0.006981609014328569\n",
      "Training Loss: 0.006931340543087572\n",
      "Validation Loss: 0.003808743787374808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006802795451367274\n",
      "Training Loss: 0.006975690315011889\n",
      "Training Loss: 0.0069254485744750125\n",
      "Validation Loss: 0.003804560499579719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006798137039877475\n",
      "Training Loss: 0.006969825981650501\n",
      "Training Loss: 0.006919609945034608\n",
      "Validation Loss: 0.0038004644827268432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006793512589065358\n",
      "Training Loss: 0.006964012068929151\n",
      "Training Loss: 0.006913821507478133\n",
      "Validation Loss: 0.003796458359431015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006788921008119359\n",
      "Training Loss: 0.006958246512804181\n",
      "Training Loss: 0.006908080694265664\n",
      "Validation Loss: 0.00379253005389166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.00678435915382579\n",
      "Training Loss: 0.006952526933746412\n",
      "Training Loss: 0.006902383944252506\n",
      "Validation Loss: 0.0037886763627253722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006779824638506397\n",
      "Training Loss: 0.006946849139640107\n",
      "Training Loss: 0.006896728779538535\n",
      "Validation Loss: 0.003784895654809609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006775316126877442\n",
      "Training Loss: 0.0069412117940373715\n",
      "Training Loss: 0.006891112400335259\n",
      "Validation Loss: 0.003781177427912696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006770831884350628\n",
      "Training Loss: 0.00693561326013878\n",
      "Training Loss: 0.006885532700107433\n",
      "Validation Loss: 0.00377752234390152\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006766368995886296\n",
      "Training Loss: 0.0069300496019423004\n",
      "Training Loss: 0.00687998664972838\n",
      "Validation Loss: 0.0037739267141108264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006761927739717066\n",
      "Training Loss: 0.0069245201861485835\n",
      "Training Loss: 0.00687447285046801\n",
      "Validation Loss: 0.0037703846994620025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006757505047135055\n",
      "Training Loss: 0.006919021734502167\n",
      "Training Loss: 0.00686898828484118\n",
      "Validation Loss: 0.00376689435359551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006753100371570326\n",
      "Training Loss: 0.006913553281920031\n",
      "Training Loss: 0.006863530807895586\n",
      "Validation Loss: 0.00376345323178959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006748711750260554\n",
      "Training Loss: 0.0069081113045103846\n",
      "Training Loss: 0.00685809945804067\n",
      "Validation Loss: 0.0037600553249207773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006744338340940886\n",
      "Training Loss: 0.006902696394827217\n",
      "Training Loss: 0.006852692156098783\n",
      "Validation Loss: 0.0037566995499341677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006739978585974313\n",
      "Training Loss: 0.00689730471232906\n",
      "Training Loss: 0.00684730596782174\n",
      "Validation Loss: 0.003753381051395214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006735632026102394\n",
      "Training Loss: 0.006891936711035669\n",
      "Training Loss: 0.00684194075409323\n",
      "Validation Loss: 0.0037500995768527134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0067312980233691635\n",
      "Training Loss: 0.006886589175555855\n",
      "Training Loss: 0.00683659367961809\n",
      "Validation Loss: 0.0037468498823850344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006726975318742916\n",
      "Training Loss: 0.006881261615781113\n",
      "Training Loss: 0.006831264449865557\n",
      "Validation Loss: 0.003743630839155966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006722662142710761\n",
      "Training Loss: 0.0068759520864114165\n",
      "Training Loss: 0.006825950004858896\n",
      "Validation Loss: 0.0037404409651592206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006718358562793582\n",
      "Training Loss: 0.006870659366250038\n",
      "Training Loss: 0.006820650605950504\n",
      "Validation Loss: 0.003737278684209823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00671406397363171\n",
      "Training Loss: 0.006865382331889123\n",
      "Training Loss: 0.006815363770583644\n",
      "Validation Loss: 0.003734136384838585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.00670977734029293\n",
      "Training Loss: 0.006860120160272345\n",
      "Training Loss: 0.0068100884521845725\n",
      "Validation Loss: 0.0037310160670345756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006705497974762693\n",
      "Training Loss: 0.006854870019014925\n",
      "Training Loss: 0.006804823235725053\n",
      "Validation Loss: 0.003727918365195896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006701225186116062\n",
      "Training Loss: 0.006849632671801374\n",
      "Training Loss: 0.006799567784182728\n",
      "Validation Loss: 0.0037248341845390336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.0066969591093948115\n",
      "Training Loss: 0.0068444050359539686\n",
      "Training Loss: 0.0067943195009138434\n",
      "Validation Loss: 0.00372176703845224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006692698133992963\n",
      "Training Loss: 0.0068391875631641594\n",
      "Training Loss: 0.006789078087895178\n",
      "Validation Loss: 0.003718712322644136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006688441774458625\n",
      "Training Loss: 0.006833979524672031\n",
      "Training Loss: 0.006783843046287074\n",
      "Validation Loss: 0.00371567087818272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0066841905808541924\n",
      "Training Loss: 0.006828778143972159\n",
      "Training Loss: 0.006778611117042601\n",
      "Validation Loss: 0.0037126371537575895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.00667994300078135\n",
      "Training Loss: 0.006823583262739703\n",
      "Training Loss: 0.006773383693071082\n",
      "Validation Loss: 0.003709613112732768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006675699358456768\n",
      "Training Loss: 0.0068183935468550776\n",
      "Training Loss: 0.006768158368067816\n",
      "Validation Loss: 0.003706593197257666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006671457779011689\n",
      "Training Loss: 0.006813207836821675\n",
      "Training Loss: 0.006762933553545736\n",
      "Validation Loss: 0.003703581116926134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0066672186745563525\n",
      "Training Loss: 0.00680802580085583\n",
      "Training Loss: 0.006757709442754276\n",
      "Validation Loss: 0.0037005703014666947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006662981689441949\n",
      "Training Loss: 0.006802845910424366\n",
      "Training Loss: 0.006752484251046553\n",
      "Validation Loss: 0.0036975595239403373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00665874648024328\n",
      "Training Loss: 0.006797666739439592\n",
      "Training Loss: 0.006747256763046608\n",
      "Validation Loss: 0.003694549418745165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006654512137174606\n",
      "Training Loss: 0.006792486754711717\n",
      "Training Loss: 0.006742026304709725\n",
      "Validation Loss: 0.0036915383364461113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006650277985609136\n",
      "Training Loss: 0.006787306135520339\n",
      "Training Loss: 0.006736792160081677\n",
      "Validation Loss: 0.003688522805512119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006646044470253401\n",
      "Training Loss: 0.006782124170567841\n",
      "Training Loss: 0.006731552038691007\n",
      "Validation Loss: 0.0036855006140520735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006641809516586363\n",
      "Training Loss: 0.006776938021648676\n",
      "Training Loss: 0.006726306439377367\n",
      "Validation Loss: 0.003682471708436444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0066375730250729245\n",
      "Training Loss: 0.006771747862221673\n",
      "Training Loss: 0.006721053463988938\n",
      "Validation Loss: 0.0036794336871087048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006633335470687598\n",
      "Training Loss: 0.006766552114859223\n",
      "Training Loss: 0.0067157914605923\n",
      "Validation Loss: 0.003676387392444892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0066290954645955935\n",
      "Training Loss: 0.006761349500156939\n",
      "Training Loss: 0.006710519923362881\n",
      "Validation Loss: 0.0036733308663131313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006624852126115002\n",
      "Training Loss: 0.006756138948258012\n",
      "Training Loss: 0.00670523735228926\n",
      "Validation Loss: 0.0036702573736292427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0066206057544332\n",
      "Training Loss: 0.006750919100595638\n",
      "Training Loss: 0.006699942941777408\n",
      "Validation Loss: 0.0036671711118849977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006616354818688706\n",
      "Training Loss: 0.006745689711533487\n",
      "Training Loss: 0.006694636156316847\n",
      "Validation Loss: 0.0036640706043062584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0066120989707997065\n",
      "Training Loss: 0.006740448618074879\n",
      "Training Loss: 0.0066893145337235185\n",
      "Validation Loss: 0.0036609497109658263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006607837082119658\n",
      "Training Loss: 0.006735194800421595\n",
      "Training Loss: 0.006683977127540857\n",
      "Validation Loss: 0.0036578094233559928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006603568742284551\n",
      "Training Loss: 0.006729927036212757\n",
      "Training Loss: 0.006678623464540579\n",
      "Validation Loss: 0.003654647368697052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006599293346516788\n",
      "Training Loss: 0.006724644338246435\n",
      "Training Loss: 0.00667325145099312\n",
      "Validation Loss: 0.003651465430562751\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006595009636948816\n",
      "Training Loss: 0.006719344010343775\n",
      "Training Loss: 0.006667861230089329\n",
      "Validation Loss: 0.003648257075306656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006590716237551533\n",
      "Training Loss: 0.006714026133995504\n",
      "Training Loss: 0.006662449332070537\n",
      "Validation Loss: 0.003645023943207572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0065864133788272735\n",
      "Training Loss: 0.006708688598591834\n",
      "Training Loss: 0.006657015342498198\n",
      "Validation Loss: 0.0036417662997970755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006582100127125159\n",
      "Training Loss: 0.006703329770825803\n",
      "Training Loss: 0.006651558640296571\n",
      "Validation Loss: 0.0036384755054886422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006577773698954843\n",
      "Training Loss: 0.006697949495865032\n",
      "Training Loss: 0.0066460770816775035\n",
      "Validation Loss: 0.003635157330034908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006573435026803054\n",
      "Training Loss: 0.006692545266123489\n",
      "Training Loss: 0.006640569707378745\n",
      "Validation Loss: 0.003631808288824441\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006569082296337001\n",
      "Training Loss: 0.006687116061802953\n",
      "Training Loss: 0.006635035282815806\n",
      "Validation Loss: 0.0036284238338114673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006564713686821051\n",
      "Training Loss: 0.006681660792091862\n",
      "Training Loss: 0.006629472114727832\n",
      "Validation Loss: 0.0036250064293383046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006560329042840749\n",
      "Training Loss: 0.006676178087946028\n",
      "Training Loss: 0.006623879497055896\n",
      "Validation Loss: 0.003621554262465222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006555926186265424\n",
      "Training Loss: 0.006670665332349017\n",
      "Training Loss: 0.006618254873319529\n",
      "Validation Loss: 0.0036180595791469633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006551505259121768\n",
      "Training Loss: 0.006665122541598976\n",
      "Training Loss: 0.006612598524661735\n",
      "Validation Loss: 0.003614531798560298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006547062889439985\n",
      "Training Loss: 0.006659548520110548\n",
      "Training Loss: 0.006606907433597371\n",
      "Validation Loss: 0.003610962653909339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.0065425994183169675\n",
      "Training Loss: 0.006653940916294232\n",
      "Training Loss: 0.006601181366131641\n",
      "Validation Loss: 0.003607351509487947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0065381128829903904\n",
      "Training Loss: 0.006648298052605242\n",
      "Training Loss: 0.0065954193752259015\n",
      "Validation Loss: 0.0036037010729333824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00653360046679154\n",
      "Training Loss: 0.0066426220745779575\n",
      "Training Loss: 0.006589620031300001\n",
      "Validation Loss: 0.0036000041160313937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.0065290627209469675\n",
      "Training Loss: 0.0066369084105826915\n",
      "Training Loss: 0.006583782733068802\n",
      "Validation Loss: 0.003596266578579468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006524496857891791\n",
      "Training Loss: 0.006631158710224554\n",
      "Training Loss: 0.006577906519523822\n",
      "Validation Loss: 0.0035924850387519663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006519901975989342\n",
      "Training Loss: 0.006625371164409444\n",
      "Training Loss: 0.006571990089141764\n",
      "Validation Loss: 0.003588658413493985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006515276613063179\n",
      "Training Loss: 0.006619545402936637\n",
      "Training Loss: 0.006566032983828336\n",
      "Validation Loss: 0.003584786428117685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006510619006003253\n",
      "Training Loss: 0.0066136827133595946\n",
      "Training Loss: 0.0065600348281441255\n",
      "Validation Loss: 0.0035808706339553334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0065059276384999976\n",
      "Training Loss: 0.006607781056081876\n",
      "Training Loss: 0.0065539955702843145\n",
      "Validation Loss: 0.003576909433893357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006501200961647555\n",
      "Training Loss: 0.006601840370567515\n",
      "Training Loss: 0.006547915663686581\n",
      "Validation Loss: 0.0035729042811612232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.0064964368077926335\n",
      "Training Loss: 0.006595862314570695\n",
      "Training Loss: 0.006541794458753429\n",
      "Validation Loss: 0.0035688546813208233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006491635518032126\n",
      "Training Loss: 0.006589847289724275\n",
      "Training Loss: 0.006535632246523164\n",
      "Validation Loss: 0.0035647613158596033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006486794529482722\n",
      "Training Loss: 0.006583796648774296\n",
      "Training Loss: 0.006529429804650135\n",
      "Validation Loss: 0.0035606243875233477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006481912592425943\n",
      "Training Loss: 0.006577712097205222\n",
      "Training Loss: 0.006523188062710687\n",
      "Validation Loss: 0.003556449250108824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.00647699034656398\n",
      "Training Loss: 0.006571593895787373\n",
      "Training Loss: 0.006516907543991693\n",
      "Validation Loss: 0.0035522342332523693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006472025996772573\n",
      "Training Loss: 0.006565445654559881\n",
      "Training Loss: 0.006510589994722977\n",
      "Validation Loss: 0.00354798040431244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006467018021503464\n",
      "Training Loss: 0.006559269254794344\n",
      "Training Loss: 0.0065042376093333585\n",
      "Validation Loss: 0.003543693394389715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006461967894574627\n",
      "Training Loss: 0.006553064406616614\n",
      "Training Loss: 0.006497850004816428\n",
      "Validation Loss: 0.0035393665704269257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006456873917486518\n",
      "Training Loss: 0.006546837065834552\n",
      "Training Loss: 0.00649143097398337\n",
      "Validation Loss: 0.0035350120422336156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006451736598974094\n",
      "Training Loss: 0.0065405892406124625\n",
      "Training Loss: 0.006484981143730692\n",
      "Validation Loss: 0.003530620890303274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.00644655583309941\n",
      "Training Loss: 0.006534323482774198\n",
      "Training Loss: 0.006478503037942574\n",
      "Validation Loss: 0.0035262078025870107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006441333232214674\n",
      "Training Loss: 0.006528043786529452\n",
      "Training Loss: 0.006471998078632168\n",
      "Validation Loss: 0.0035217641473465253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006436068400507793\n",
      "Training Loss: 0.006521750426618383\n",
      "Training Loss: 0.006465469647664577\n",
      "Validation Loss: 0.003517296262022652\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006430762466043234\n",
      "Training Loss: 0.006515449052676559\n",
      "Training Loss: 0.006458918197313324\n",
      "Validation Loss: 0.0035128066240380823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006425416033016518\n",
      "Training Loss: 0.0065091412188485265\n",
      "Training Loss: 0.006452345533762127\n",
      "Validation Loss: 0.0035082909914277744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.00642003090120852\n",
      "Training Loss: 0.006502829225501046\n",
      "Training Loss: 0.006445753825246357\n",
      "Validation Loss: 0.0035037565623211226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006414607667829841\n",
      "Training Loss: 0.0064965162961743775\n",
      "Training Loss: 0.006439144322648645\n",
      "Validation Loss: 0.0034991968396967383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.00640914753312245\n",
      "Training Loss: 0.006490203459979966\n",
      "Training Loss: 0.006432517538778484\n",
      "Validation Loss: 0.0034946190059875672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.0064036523806862535\n",
      "Training Loss: 0.006483892954420299\n",
      "Training Loss: 0.006425875857821665\n",
      "Validation Loss: 0.003490020337859901\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006398122487589717\n",
      "Training Loss: 0.0064775865490082655\n",
      "Training Loss: 0.006419218687224202\n",
      "Validation Loss: 0.003485402671798143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006392559593077749\n",
      "Training Loss: 0.0064712853461969646\n",
      "Training Loss: 0.006412547153304331\n",
      "Validation Loss: 0.0034807650594752323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006386965283891186\n",
      "Training Loss: 0.006464990370441228\n",
      "Training Loss: 0.006405861130915582\n",
      "Validation Loss: 0.0034761064950104676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.00638134044711478\n",
      "Training Loss: 0.006458701108349487\n",
      "Training Loss: 0.006399160996661522\n",
      "Validation Loss: 0.0034714233786851336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006375684967497364\n",
      "Training Loss: 0.0064524191559758035\n",
      "Training Loss: 0.0063924467936158184\n",
      "Validation Loss: 0.0034667211257737507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006370001819450408\n",
      "Training Loss: 0.006446144267683849\n",
      "Training Loss: 0.00638571830058936\n",
      "Validation Loss: 0.0034619955335523974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006364290445344522\n",
      "Training Loss: 0.006439877640223131\n",
      "Training Loss: 0.006378974374965765\n",
      "Validation Loss: 0.003457244303799496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006358551848679781\n",
      "Training Loss: 0.006433617508737371\n",
      "Training Loss: 0.006372214846778661\n",
      "Validation Loss: 0.003452469258611038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006352786512579769\n",
      "Training Loss: 0.00642736348323524\n",
      "Training Loss: 0.006365438209031709\n",
      "Validation Loss: 0.003447663015424368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006346995125059038\n",
      "Training Loss: 0.006421115478733554\n",
      "Training Loss: 0.0063586438971105965\n",
      "Validation Loss: 0.003442834828603552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0063411782192997635\n",
      "Training Loss: 0.006414872258901596\n",
      "Training Loss: 0.006351831055944786\n",
      "Validation Loss: 0.0034379694045761997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006335336040938273\n",
      "Training Loss: 0.0064086356270127\n",
      "Training Loss: 0.006344998708809726\n",
      "Validation Loss: 0.0034330772403418346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006329469893826172\n",
      "Training Loss: 0.006402402020758018\n",
      "Training Loss: 0.006338146518100984\n",
      "Validation Loss: 0.0034281533692827387\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.0063235793984495105\n",
      "Training Loss: 0.006396172270178795\n",
      "Training Loss: 0.006331272880197502\n",
      "Validation Loss: 0.0034231928182410056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006317664466332644\n",
      "Training Loss: 0.00638994378503412\n",
      "Training Loss: 0.0063243764184881006\n",
      "Validation Loss: 0.0034181948076263905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006311724920524284\n",
      "Training Loss: 0.0063837171893101185\n",
      "Training Loss: 0.0063174563751090314\n",
      "Validation Loss: 0.003413161898575974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006305762246483937\n",
      "Training Loss: 0.006377491768216714\n",
      "Training Loss: 0.006310512493364513\n",
      "Validation Loss: 0.0034080887621456986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.0062997759354766454\n",
      "Training Loss: 0.0063712659932207314\n",
      "Training Loss: 0.006303542336099781\n",
      "Validation Loss: 0.003402972651457184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fanny\\Documents\\ArnesShit\\time_series_data_augmentation\\data_evaluation\\predictive\\predictive_evaluation.py:272: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([{'Model': evaluation_method, 'Metric': 'MAE', 'Error': mae}])], ignore_index=True)\n",
      " 10%|█         | 1/10 [03:27<31:08, 207.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.1583011532574892\n",
      "Training Loss: 0.1251966630294919\n",
      "Training Loss: 0.10208195379003883\n",
      "Validation Loss: 0.0759114520519637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.07647400125861167\n",
      "Training Loss: 0.06941117335110902\n",
      "Training Loss: 0.0662662960216403\n",
      "Validation Loss: 0.05902656577946095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06153253445401788\n",
      "Training Loss: 0.059261093698441986\n",
      "Training Loss: 0.05687672033905983\n",
      "Validation Loss: 0.05057214953926172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05218515352346003\n",
      "Training Loss: 0.050076246233657\n",
      "Training Loss: 0.04741249815560877\n",
      "Validation Loss: 0.04150502616016383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04250325375236571\n",
      "Training Loss: 0.040618915781378745\n",
      "Training Loss: 0.037768596727401016\n",
      "Validation Loss: 0.03223690068286456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.032783874860033396\n",
      "Training Loss: 0.03127530260942876\n",
      "Training Loss: 0.028484215610660613\n",
      "Validation Loss: 0.02365362699656339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.024065597844310106\n",
      "Training Loss: 0.02351336678955704\n",
      "Training Loss: 0.021460879035294055\n",
      "Validation Loss: 0.017899412745505237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.0184515246655792\n",
      "Training Loss: 0.019012602581642567\n",
      "Training Loss: 0.017746315463446082\n",
      "Validation Loss: 0.01500627003463634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01570136553607881\n",
      "Training Loss: 0.016775298225693406\n",
      "Training Loss: 0.015890342763159423\n",
      "Validation Loss: 0.013417345011251027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.014263541474938392\n",
      "Training Loss: 0.015467501876410097\n",
      "Training Loss: 0.014736592504195869\n",
      "Validation Loss: 0.012269886262882291\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.013273625586880371\n",
      "Training Loss: 0.014415168375708163\n",
      "Training Loss: 0.013722204610239715\n",
      "Validation Loss: 0.011105383474254207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.012290925880661234\n",
      "Training Loss: 0.013246962206903846\n",
      "Training Loss: 0.012584981344407425\n",
      "Validation Loss: 0.009794943843015961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.011207077043363824\n",
      "Training Loss: 0.01196580528980121\n",
      "Training Loss: 0.011430128290085122\n",
      "Validation Loss: 0.008544461555737123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010234149565221742\n",
      "Training Loss: 0.010864224338438361\n",
      "Training Loss: 0.01051431786851026\n",
      "Validation Loss: 0.00755416988028904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009533597093541174\n",
      "Training Loss: 0.010075953151099383\n",
      "Training Loss: 0.009846391788451002\n",
      "Validation Loss: 0.006790942025862718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.00901879316312261\n",
      "Training Loss: 0.009496655779657885\n",
      "Training Loss: 0.00932821374037303\n",
      "Validation Loss: 0.006191282043903229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008617150261998177\n",
      "Training Loss: 0.009046943039866164\n",
      "Training Loss: 0.008912010109052062\n",
      "Validation Loss: 0.005713120694115256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008294685744913296\n",
      "Training Loss: 0.008686498894821853\n",
      "Training Loss: 0.0085715925891418\n",
      "Validation Loss: 0.005328069331145354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008032081967685371\n",
      "Training Loss: 0.008392980264034122\n",
      "Training Loss: 0.008291778294369579\n",
      "Validation Loss: 0.0050184582713258905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00781778572127223\n",
      "Training Loss: 0.008153013456612825\n",
      "Training Loss: 0.008062718022847548\n",
      "Validation Loss: 0.004771802363802124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007643674100982025\n",
      "Training Loss: 0.007957176114432514\n",
      "Training Loss: 0.00787652047118172\n",
      "Validation Loss: 0.004577616427166994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007502997509436682\n",
      "Training Loss: 0.007797729461453855\n",
      "Training Loss: 0.0077260684757493436\n",
      "Validation Loss: 0.00442641374414389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007389790451852605\n",
      "Training Loss: 0.007667961525730789\n",
      "Training Loss: 0.007604892756789923\n",
      "Validation Loss: 0.004309643437991735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007298821692820638\n",
      "Training Loss: 0.007562101684743539\n",
      "Training Loss: 0.007507310543442145\n",
      "Validation Loss: 0.004219859474851342\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007225634002825245\n",
      "Training Loss: 0.007475327526917681\n",
      "Training Loss: 0.007428505939315073\n",
      "Validation Loss: 0.004150801763367536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007166508826194331\n",
      "Training Loss: 0.007403690468054265\n",
      "Training Loss: 0.0073644877754850315\n",
      "Validation Loss: 0.004097354468847677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007118388297967613\n",
      "Training Loss: 0.007344004608457908\n",
      "Training Loss: 0.007312011350295506\n",
      "Validation Loss: 0.004055456277977131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007078797125723213\n",
      "Training Loss: 0.00729371799970977\n",
      "Training Loss: 0.007268471291754394\n",
      "Validation Loss: 0.00402195867820737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007045761543558911\n",
      "Training Loss: 0.007250805592630059\n",
      "Training Loss: 0.007231819131411612\n",
      "Validation Loss: 0.003994475635490642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007017732133390382\n",
      "Training Loss: 0.0072136687464080754\n",
      "Training Loss: 0.007200460997410119\n",
      "Validation Loss: 0.003971253630307535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.006993513596244156\n",
      "Training Loss: 0.007181059361901134\n",
      "Training Loss: 0.007173175050411373\n",
      "Validation Loss: 0.003951024179074788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00697219708468765\n",
      "Training Loss: 0.007152007102267817\n",
      "Training Loss: 0.007149034551111981\n",
      "Validation Loss: 0.003932891272301419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00695309562725015\n",
      "Training Loss: 0.0071257620747201145\n",
      "Training Loss: 0.007127339958096854\n",
      "Validation Loss: 0.003916227496804648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.006935695646097884\n",
      "Training Loss: 0.007101745693944395\n",
      "Training Loss: 0.0071075629681581634\n",
      "Validation Loss: 0.003900602015174842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.006919611170887947\n",
      "Training Loss: 0.007079508905299008\n",
      "Training Loss: 0.0070893010427244005\n",
      "Validation Loss: 0.0038857169820811976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00690455125994049\n",
      "Training Loss: 0.007058701261412352\n",
      "Training Loss: 0.007072247414034791\n",
      "Validation Loss: 0.0038713584706354678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.006890291054733097\n",
      "Training Loss: 0.007039045705460012\n",
      "Training Loss: 0.007056158529012464\n",
      "Validation Loss: 0.0038573774953864597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.006876656118547544\n",
      "Training Loss: 0.0070203171588946135\n",
      "Training Loss: 0.007040840277913958\n",
      "Validation Loss: 0.0038436602479307337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0068635048868600276\n",
      "Training Loss: 0.007002333048731089\n",
      "Training Loss: 0.0070261323382146655\n",
      "Validation Loss: 0.0038301165443269556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.006850720160873607\n",
      "Training Loss: 0.00698493558447808\n",
      "Training Loss: 0.007011897919583134\n",
      "Validation Loss: 0.003816663266651416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.006838201562641188\n",
      "Training Loss: 0.006967990400735289\n",
      "Training Loss: 0.006998017448931932\n",
      "Validation Loss: 0.0038032259601116013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006825858497759327\n",
      "Training Loss: 0.006951374970376492\n",
      "Training Loss: 0.006984381416696123\n",
      "Validation Loss: 0.0037897315577425984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.0068136086722370235\n",
      "Training Loss: 0.006934980003861711\n",
      "Training Loss: 0.006970886740018614\n",
      "Validation Loss: 0.0037760958794943907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006801373355556279\n",
      "Training Loss: 0.0069186986319255085\n",
      "Training Loss: 0.006957435923395678\n",
      "Validation Loss: 0.0037622346864552812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006789073875406757\n",
      "Training Loss: 0.006902425811858848\n",
      "Training Loss: 0.006943928151740692\n",
      "Validation Loss: 0.0037480484186723996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006776630703825504\n",
      "Training Loss: 0.006886055914219469\n",
      "Training Loss: 0.006930261483648792\n",
      "Validation Loss: 0.003733427100291664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006763957436196506\n",
      "Training Loss: 0.0068694778578355905\n",
      "Training Loss: 0.006916325453785248\n",
      "Validation Loss: 0.0037182369674922207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006750962099176832\n",
      "Training Loss: 0.00685256903176196\n",
      "Training Loss: 0.006902000069385394\n",
      "Validation Loss: 0.0037023189446229615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00673753758892417\n",
      "Training Loss: 0.0068351927457842975\n",
      "Training Loss: 0.0068871457723435016\n",
      "Validation Loss: 0.0036854810235770735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006723559178644791\n",
      "Training Loss: 0.006817187940469011\n",
      "Training Loss: 0.006871599610312842\n",
      "Validation Loss: 0.003667480657609661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006708875558106228\n",
      "Training Loss: 0.006798359273816459\n",
      "Training Loss: 0.0068551598460180685\n",
      "Validation Loss: 0.0036480167744618454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006693297835881822\n",
      "Training Loss: 0.006778465380193666\n",
      "Training Loss: 0.006837575759273022\n",
      "Validation Loss: 0.0036266953671309217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006676582508953288\n",
      "Training Loss: 0.006757199335843325\n",
      "Training Loss: 0.006818521313834936\n",
      "Validation Loss: 0.0036029951775111676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006658407284412533\n",
      "Training Loss: 0.006734151529381052\n",
      "Training Loss: 0.0067975627444684505\n",
      "Validation Loss: 0.003576217658734054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006638336108298972\n",
      "Training Loss: 0.006708776297746227\n",
      "Training Loss: 0.006774107452947646\n",
      "Validation Loss: 0.0035454015877997773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0066157599887810645\n",
      "Training Loss: 0.006680315077537671\n",
      "Training Loss: 0.006747326503391378\n",
      "Validation Loss: 0.0035092192584272016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006589809685829095\n",
      "Training Loss: 0.006647700104513206\n",
      "Training Loss: 0.006716034075943753\n",
      "Validation Loss: 0.003465788049121084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00655922457575798\n",
      "Training Loss: 0.006609398481668904\n",
      "Training Loss: 0.006678518714033998\n",
      "Validation Loss: 0.0034124971723204917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006522164965281263\n",
      "Training Loss: 0.0065632402035407725\n",
      "Training Loss: 0.0066323467437177895\n",
      "Validation Loss: 0.003345897565124912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006476028672768735\n",
      "Training Loss: 0.006506302356137894\n",
      "Training Loss: 0.006574309574207291\n",
      "Validation Loss: 0.0032622191055646436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006417557565146126\n",
      "Training Loss: 0.0064353755302727226\n",
      "Training Loss: 0.006501182568026707\n",
      "Validation Loss: 0.0031599494984394377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0063441749248886485\n",
      "Training Loss: 0.00634924593497999\n",
      "Training Loss: 0.0064128298207651825\n",
      "Validation Loss: 0.003046454359473807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0062580452836118634\n",
      "Training Loss: 0.006253862631274388\n",
      "Training Loss: 0.0063178186642471705\n",
      "Validation Loss: 0.0029438043515501396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006170285604894161\n",
      "Training Loss: 0.006164290796150453\n",
      "Training Loss: 0.006232402034802362\n",
      "Validation Loss: 0.00287490701198243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006094221092062071\n",
      "Training Loss: 0.006092364923097194\n",
      "Training Loss: 0.006165623611886986\n",
      "Validation Loss: 0.002839304820707675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006032883293228224\n",
      "Training Loss: 0.006036636565695517\n",
      "Training Loss: 0.006114032414043322\n",
      "Validation Loss: 0.0028218582273837637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00598228961287532\n",
      "Training Loss: 0.005991155963856727\n",
      "Training Loss: 0.006071957328822463\n",
      "Validation Loss: 0.0028118288001893195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.005939081649994477\n",
      "Training Loss: 0.0059523237135726955\n",
      "Training Loss: 0.006036161636002362\n",
      "Validation Loss: 0.0028047891427877914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.005901428232318722\n",
      "Training Loss: 0.005918371754232794\n",
      "Training Loss: 0.0060049745766446\n",
      "Validation Loss: 0.002799116341224505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.005868178882519714\n",
      "Training Loss: 0.005888222304638475\n",
      "Training Loss: 0.005977375269285403\n",
      "Validation Loss: 0.002794144380173196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.00583848750742618\n",
      "Training Loss: 0.005861092628329061\n",
      "Training Loss: 0.005952646959922276\n",
      "Validation Loss: 0.002789539716002437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.005811700568301603\n",
      "Training Loss: 0.0058363926073070616\n",
      "Training Loss: 0.005930256880237721\n",
      "Validation Loss: 0.002785110241848599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.0057873068237677214\n",
      "Training Loss: 0.005813665858004242\n",
      "Training Loss: 0.005909787847776897\n",
      "Validation Loss: 0.002780739742519564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.005764898373745382\n",
      "Training Loss: 0.005792556215892546\n",
      "Training Loss: 0.005890916216885671\n",
      "Validation Loss: 0.00277634873839744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00574415216804482\n",
      "Training Loss: 0.005772786989691667\n",
      "Training Loss: 0.00587338071432896\n",
      "Validation Loss: 0.0027718855273449437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.005724806907819584\n",
      "Training Loss: 0.005754138160846196\n",
      "Training Loss: 0.005856971071334555\n",
      "Validation Loss: 0.0027673202599503436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0057066503202077\n",
      "Training Loss: 0.005736434279824607\n",
      "Training Loss: 0.00584151697694324\n",
      "Validation Loss: 0.0027626340841257085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0056895090086618435\n",
      "Training Loss: 0.0057195355830481276\n",
      "Training Loss: 0.005826878366060555\n",
      "Validation Loss: 0.0027578207866937507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0056732414488215\n",
      "Training Loss: 0.0057033287739614025\n",
      "Training Loss: 0.0058129400631878525\n",
      "Validation Loss: 0.002752871374897868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.005657729336526245\n",
      "Training Loss: 0.00568772122496739\n",
      "Training Loss: 0.005799607383669354\n",
      "Validation Loss: 0.00274778661655597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.005642877063364722\n",
      "Training Loss: 0.005672639571712352\n",
      "Training Loss: 0.0057868012803373855\n",
      "Validation Loss: 0.0027425744305260144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.005628602619981393\n",
      "Training Loss: 0.005658021097769961\n",
      "Training Loss: 0.005774456569924951\n",
      "Validation Loss: 0.002737237208554249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0056148399756057185\n",
      "Training Loss: 0.005643816935480573\n",
      "Training Loss: 0.005762518891715445\n",
      "Validation Loss: 0.002731781206329175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.005601531273568981\n",
      "Training Loss: 0.005629985082778149\n",
      "Training Loss: 0.005750942819868214\n",
      "Validation Loss: 0.002726215377366275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0055886307946639135\n",
      "Training Loss: 0.005616491945111193\n",
      "Training Loss: 0.005739690054906532\n",
      "Validation Loss: 0.0027205482938881505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005576098009478301\n",
      "Training Loss: 0.005603309070575051\n",
      "Training Loss: 0.005728728548856452\n",
      "Validation Loss: 0.0027147897727149172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.005563898132531903\n",
      "Training Loss: 0.005590411022421904\n",
      "Training Loss: 0.005718031075084582\n",
      "Validation Loss: 0.0027089495789992175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005552002796321176\n",
      "Training Loss: 0.005577779071754776\n",
      "Training Loss: 0.00570757612993475\n",
      "Validation Loss: 0.002703033188185288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005540387252694927\n",
      "Training Loss: 0.005565394420409575\n",
      "Training Loss: 0.00569734274118673\n",
      "Validation Loss: 0.0026970514412864707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.0055290298321051526\n",
      "Training Loss: 0.005553241763263941\n",
      "Training Loss: 0.0056873146409634505\n",
      "Validation Loss: 0.0026910122708951154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005517912692157552\n",
      "Training Loss: 0.0055413087387569246\n",
      "Training Loss: 0.0056774785462766885\n",
      "Validation Loss: 0.0026849244676760576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005507020469522104\n",
      "Training Loss: 0.005529583504539914\n",
      "Training Loss: 0.005667822289979085\n",
      "Validation Loss: 0.0026787959125541736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0054963380109984425\n",
      "Training Loss: 0.005518057423178107\n",
      "Training Loss: 0.005658335717744194\n",
      "Validation Loss: 0.0026726349161446013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.005485854604048654\n",
      "Training Loss: 0.005506720218691043\n",
      "Training Loss: 0.005649010357446968\n",
      "Validation Loss: 0.002666448019287978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.005475560750346631\n",
      "Training Loss: 0.005495565778110176\n",
      "Training Loss: 0.0056398386094952\n",
      "Validation Loss: 0.002660243228480764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.0054654460144229235\n",
      "Training Loss: 0.005484586649690755\n",
      "Training Loss: 0.005630813254392706\n",
      "Validation Loss: 0.0026540260701806524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.005455502611584962\n",
      "Training Loss: 0.00547377583803609\n",
      "Training Loss: 0.005621930386405438\n",
      "Validation Loss: 0.0026478057150373215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005445723991142586\n",
      "Training Loss: 0.005463129657437093\n",
      "Training Loss: 0.0056131830776575955\n",
      "Validation Loss: 0.0026415879229931267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005436104030814022\n",
      "Training Loss: 0.005452641459414736\n",
      "Training Loss: 0.005604568784474395\n",
      "Validation Loss: 0.0026353736580715754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005426637147320434\n",
      "Training Loss: 0.00544230847270228\n",
      "Training Loss: 0.005596084129065275\n",
      "Validation Loss: 0.0026291762432868308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.0054173195839393885\n",
      "Training Loss: 0.005432125569786877\n",
      "Training Loss: 0.005587724533397704\n",
      "Validation Loss: 0.00262299719530817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00540814618114382\n",
      "Training Loss: 0.005422091563814319\n",
      "Training Loss: 0.005579488569055684\n",
      "Validation Loss: 0.002616844172694124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005399113749153912\n",
      "Training Loss: 0.005412202883162536\n",
      "Training Loss: 0.005571373534621671\n",
      "Validation Loss: 0.002610721280065815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0053902185568586\n",
      "Training Loss: 0.005402455395669676\n",
      "Training Loss: 0.005563376426580362\n",
      "Validation Loss: 0.002604631012504439\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005381457670591771\n",
      "Training Loss: 0.005392846922040917\n",
      "Training Loss: 0.005555496074375697\n",
      "Validation Loss: 0.0025985817094019543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005372828667168506\n",
      "Training Loss: 0.005383375722449273\n",
      "Training Loss: 0.005547730381367728\n",
      "Validation Loss: 0.0025925742255607513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.005364329080912285\n",
      "Training Loss: 0.0053740408667363225\n",
      "Training Loss: 0.00554007769736927\n",
      "Validation Loss: 0.002586615750607982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00535595718130935\n",
      "Training Loss: 0.005364839379908517\n",
      "Training Loss: 0.005532537128310651\n",
      "Validation Loss: 0.0025807063937647624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005347710111527704\n",
      "Training Loss: 0.005355770979076624\n",
      "Training Loss: 0.005525106289424002\n",
      "Validation Loss: 0.002574852773699951\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.005339587565977126\n",
      "Training Loss: 0.005346832619397901\n",
      "Training Loss: 0.0055177838512463495\n",
      "Validation Loss: 0.002569055153329051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005331586301908828\n",
      "Training Loss: 0.005338023756630719\n",
      "Training Loss: 0.0055105695151723925\n",
      "Validation Loss: 0.002563318390702682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.005323706338531338\n",
      "Training Loss: 0.005329343067714944\n",
      "Training Loss: 0.005503460754407569\n",
      "Validation Loss: 0.002557644815435319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005315944770700298\n",
      "Training Loss: 0.005320790975238196\n",
      "Training Loss: 0.005496457146364264\n",
      "Validation Loss: 0.0025520366426881698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.005308301107143052\n",
      "Training Loss: 0.005312362500699237\n",
      "Training Loss: 0.005489556764950975\n",
      "Validation Loss: 0.002546494321772054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005300773439230398\n",
      "Training Loss: 0.005304061943315901\n",
      "Training Loss: 0.005482759381993674\n",
      "Validation Loss: 0.0025410213425305535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005293360794894397\n",
      "Training Loss: 0.005295884819934145\n",
      "Training Loss: 0.00547606382984668\n",
      "Validation Loss: 0.0025356227114765244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005286062510567718\n",
      "Training Loss: 0.00528783087967895\n",
      "Training Loss: 0.0054694677796214815\n",
      "Validation Loss: 0.0025302944835693983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005278875988442451\n",
      "Training Loss: 0.005279899624874815\n",
      "Training Loss: 0.005462969364016317\n",
      "Validation Loss: 0.002525042274867425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0052718001592438665\n",
      "Training Loss: 0.005272088983329013\n",
      "Training Loss: 0.005456568759400398\n",
      "Validation Loss: 0.002519864032406025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.00526483392866794\n",
      "Training Loss: 0.005264399393927306\n",
      "Training Loss: 0.0054502638668054715\n",
      "Validation Loss: 0.00251475832323031\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005257976143038832\n",
      "Training Loss: 0.0052568292448995635\n",
      "Training Loss: 0.005444054217077792\n",
      "Validation Loss: 0.0025097325416752712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005251225102692842\n",
      "Training Loss: 0.005249377209693194\n",
      "Training Loss: 0.005437937999959104\n",
      "Validation Loss: 0.0025047801331658797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005244579864665866\n",
      "Training Loss: 0.005242043594480492\n",
      "Training Loss: 0.005431914596119896\n",
      "Validation Loss: 0.002499907264444098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005238039345131256\n",
      "Training Loss: 0.005234824506915175\n",
      "Training Loss: 0.005425981500302442\n",
      "Validation Loss: 0.0024951127020307303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.005231600985280238\n",
      "Training Loss: 0.005227722203126177\n",
      "Training Loss: 0.005420137900509872\n",
      "Validation Loss: 0.0024903920528824243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005225264457985759\n",
      "Training Loss: 0.005220733286696486\n",
      "Training Loss: 0.005414383573224768\n",
      "Validation Loss: 0.002485750073676908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00521902791399043\n",
      "Training Loss: 0.005213858420029282\n",
      "Training Loss: 0.005408716722158715\n",
      "Validation Loss: 0.002481186655193065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005212891334667802\n",
      "Training Loss: 0.0052070959110278635\n",
      "Training Loss: 0.005403135240194388\n",
      "Validation Loss: 0.0024766988118357035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005206851856783033\n",
      "Training Loss: 0.005200444284710102\n",
      "Training Loss: 0.005397639667498879\n",
      "Validation Loss: 0.0024722862447182953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005200908804545179\n",
      "Training Loss: 0.005193902162718586\n",
      "Training Loss: 0.005392228147247807\n",
      "Validation Loss: 0.002467951849835475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005195060606347397\n",
      "Training Loss: 0.005187469293596223\n",
      "Training Loss: 0.005386899231234565\n",
      "Validation Loss: 0.002463691472860702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005189305589883588\n",
      "Training Loss: 0.005181142560904846\n",
      "Training Loss: 0.005381652067881077\n",
      "Validation Loss: 0.0024595060666991668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005183643896598369\n",
      "Training Loss: 0.005174923324375413\n",
      "Training Loss: 0.005376485596061684\n",
      "Validation Loss: 0.002455391610444136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005178073261049576\n",
      "Training Loss: 0.005168808471644297\n",
      "Training Loss: 0.005371399418800138\n",
      "Validation Loss: 0.002451351318597333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0051725929835811256\n",
      "Training Loss: 0.0051627990760607645\n",
      "Training Loss: 0.0053663928597234185\n",
      "Validation Loss: 0.0024473837156926566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.005167201560689136\n",
      "Training Loss: 0.0051568919129204\n",
      "Training Loss: 0.005361463415902108\n",
      "Validation Loss: 0.0024434874577217557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.005161898140213453\n",
      "Training Loss: 0.0051510864577721804\n",
      "Training Loss: 0.005356611797469668\n",
      "Validation Loss: 0.0024396605165727604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.005156680747750215\n",
      "Training Loss: 0.005145381038892083\n",
      "Training Loss: 0.005351836263434962\n",
      "Validation Loss: 0.0024359038510370287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.0051515495456988\n",
      "Training Loss: 0.00513977553229779\n",
      "Training Loss: 0.0053471368795726445\n",
      "Validation Loss: 0.002432214421889839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.00514650356315542\n",
      "Training Loss: 0.005134268588153646\n",
      "Training Loss: 0.00534251224657055\n",
      "Validation Loss: 0.002428590947908632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005141541626653634\n",
      "Training Loss: 0.005128858862444758\n",
      "Training Loss: 0.005337961874902248\n",
      "Validation Loss: 0.002425030990911836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005136661904398352\n",
      "Training Loss: 0.005123543661902659\n",
      "Training Loss: 0.005333484191214666\n",
      "Validation Loss: 0.0024215381009127486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.005131864079739899\n",
      "Training Loss: 0.005118323616334237\n",
      "Training Loss: 0.0053290804149582986\n",
      "Validation Loss: 0.0024181068521725497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005127147130551748\n",
      "Training Loss: 0.005113196820602752\n",
      "Training Loss: 0.00532474746752996\n",
      "Validation Loss: 0.0024147387809810763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.005122510599903762\n",
      "Training Loss: 0.005108162448741496\n",
      "Training Loss: 0.005320486252312549\n",
      "Validation Loss: 0.0024114296100562795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005117953132721596\n",
      "Training Loss: 0.005103218894801103\n",
      "Training Loss: 0.005316295131342486\n",
      "Validation Loss: 0.0024081775604673987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005113473134697415\n",
      "Training Loss: 0.005098363379947841\n",
      "Training Loss: 0.005312172732083127\n",
      "Validation Loss: 0.0024049839696825975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005109069796744734\n",
      "Training Loss: 0.005093595936195925\n",
      "Training Loss: 0.005308119190740399\n",
      "Validation Loss: 0.002401845378597173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005104742984403856\n",
      "Training Loss: 0.005088914774823934\n",
      "Training Loss: 0.005304132765741087\n",
      "Validation Loss: 0.002398761196632273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005100490897893906\n",
      "Training Loss: 0.005084318674635142\n",
      "Training Loss: 0.005300212586880662\n",
      "Validation Loss: 0.002395727778941895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005096311907400377\n",
      "Training Loss: 0.005079804006381892\n",
      "Training Loss: 0.005296358791529201\n",
      "Validation Loss: 0.002392747884830774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005092206600820646\n",
      "Training Loss: 0.005075372632127255\n",
      "Training Loss: 0.005292569604353048\n",
      "Validation Loss: 0.002389816525444556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005088171442039311\n",
      "Training Loss: 0.005071020604809746\n",
      "Training Loss: 0.005288843442685902\n",
      "Validation Loss: 0.0023869336726604386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005084207386826165\n",
      "Training Loss: 0.005066747458768077\n",
      "Training Loss: 0.005285179940983653\n",
      "Validation Loss: 0.002384094037429503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005080313141806982\n",
      "Training Loss: 0.005062549785943702\n",
      "Training Loss: 0.0052815781673416495\n",
      "Validation Loss: 0.0023813001455718213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005076485906611197\n",
      "Training Loss: 0.005058428811607883\n",
      "Training Loss: 0.005278036178206094\n",
      "Validation Loss: 0.0023785492397447147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005072724826168269\n",
      "Training Loss: 0.005054379555513151\n",
      "Training Loss: 0.005274553035269492\n",
      "Validation Loss: 0.002375839463843221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0050690299668349325\n",
      "Training Loss: 0.005050402139313519\n",
      "Training Loss: 0.0052711275091860445\n",
      "Validation Loss: 0.0023731679728861603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005065397317521274\n",
      "Training Loss: 0.005046493579284288\n",
      "Training Loss: 0.005267758218105882\n",
      "Validation Loss: 0.002370535061181931\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005061829120968468\n",
      "Training Loss: 0.005042653153650462\n",
      "Training Loss: 0.005264444615459069\n",
      "Validation Loss: 0.0023679391185365867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005058321147807874\n",
      "Training Loss: 0.005038879156927578\n",
      "Training Loss: 0.005261184123810381\n",
      "Validation Loss: 0.002365377643982765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0050548731937306\n",
      "Training Loss: 0.0050351688161026685\n",
      "Training Loss: 0.005257976126740687\n",
      "Validation Loss: 0.0023628504805559857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005051483162096701\n",
      "Training Loss: 0.005031521304044872\n",
      "Training Loss: 0.005254819231922738\n",
      "Validation Loss: 0.002360356155406223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005048149584326893\n",
      "Training Loss: 0.005027933697565459\n",
      "Training Loss: 0.005251711603486911\n",
      "Validation Loss: 0.0023578921531777035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.0050448708812473346\n",
      "Training Loss: 0.005024404271389358\n",
      "Training Loss: 0.005248652945156209\n",
      "Validation Loss: 0.0023554577963070924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.00504164629150182\n",
      "Training Loss: 0.005020932699553668\n",
      "Training Loss: 0.005245640492648818\n",
      "Validation Loss: 0.002353053229986533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005038474059547298\n",
      "Training Loss: 0.0050175165885593745\n",
      "Training Loss: 0.005242674358887598\n",
      "Validation Loss: 0.002350675160578044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.00503535293857567\n",
      "Training Loss: 0.00501415254198946\n",
      "Training Loss: 0.005239752177149057\n",
      "Validation Loss: 0.002348325068125857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0050322799995774405\n",
      "Training Loss: 0.005010840632021427\n",
      "Training Loss: 0.005236872897949069\n",
      "Validation Loss: 0.0023459978977197343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005029255239642225\n",
      "Training Loss: 0.005007578372024\n",
      "Training Loss: 0.005234035192406736\n",
      "Validation Loss: 0.002343695574790616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005026277635479346\n",
      "Training Loss: 0.005004365100176073\n",
      "Training Loss: 0.0052312378515489396\n",
      "Validation Loss: 0.002341416079074856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005023345272638835\n",
      "Training Loss: 0.0050011993624502794\n",
      "Training Loss: 0.005228479719371535\n",
      "Validation Loss: 0.0023391611241013483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005020456400234252\n",
      "Training Loss: 0.004998078724020161\n",
      "Training Loss: 0.005225759380264208\n",
      "Validation Loss: 0.0023369261552841306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0050176106934668495\n",
      "Training Loss: 0.004995002027135343\n",
      "Training Loss: 0.005223075448884629\n",
      "Validation Loss: 0.0023347116945300964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005014805716346018\n",
      "Training Loss: 0.004991967104724608\n",
      "Training Loss: 0.0052204269182402644\n",
      "Validation Loss: 0.0023325177627678416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005012040932197124\n",
      "Training Loss: 0.004988973602303303\n",
      "Training Loss: 0.005217812720220536\n",
      "Validation Loss: 0.0023303450728777084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005009314436465502\n",
      "Training Loss: 0.004986019375501201\n",
      "Training Loss: 0.00521523172094021\n",
      "Validation Loss: 0.0023281898681765025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0050066251482348886\n",
      "Training Loss: 0.0049831043340964245\n",
      "Training Loss: 0.005212682803394273\n",
      "Validation Loss: 0.002326054173506001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005003973604179919\n",
      "Training Loss: 0.0049802269681822504\n",
      "Training Loss: 0.005210165866301395\n",
      "Validation Loss: 0.002323936315886467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005001356962020509\n",
      "Training Loss: 0.004977384396479465\n",
      "Training Loss: 0.0052076783031225204\n",
      "Validation Loss: 0.0023218351710598203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.004998775045969524\n",
      "Training Loss: 0.004974577934481203\n",
      "Training Loss: 0.005205220477073454\n",
      "Validation Loss: 0.0023197534224646313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.004996225971262902\n",
      "Training Loss: 0.004971805768436752\n",
      "Training Loss: 0.005202791159972548\n",
      "Validation Loss: 0.002317685669868808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.00499371001846157\n",
      "Training Loss: 0.004969065205077641\n",
      "Training Loss: 0.005200388320954517\n",
      "Validation Loss: 0.002315635931563009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.004991224577534013\n",
      "Training Loss: 0.004966356796794571\n",
      "Training Loss: 0.005198012940236367\n",
      "Validation Loss: 0.0023136035718410958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.004988769687479362\n",
      "Training Loss: 0.004963679497595876\n",
      "Training Loss: 0.005195663428166881\n",
      "Validation Loss: 0.0023115855083131135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.004986344978678971\n",
      "Training Loss: 0.0049610327841946855\n",
      "Training Loss: 0.005193338759709149\n",
      "Validation Loss: 0.002309583368177494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00498394854075741\n",
      "Training Loss: 0.004958415291621349\n",
      "Training Loss: 0.005191037735785358\n",
      "Validation Loss: 0.0023075946478507995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.004981581642641686\n",
      "Training Loss: 0.004955826443037949\n",
      "Training Loss: 0.005188761226600036\n",
      "Validation Loss: 0.0023056232760231316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.004979241046239622\n",
      "Training Loss: 0.004953263882780448\n",
      "Training Loss: 0.005186507319449447\n",
      "Validation Loss: 0.002303665471158587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.004976926831295714\n",
      "Training Loss: 0.004950729489792138\n",
      "Training Loss: 0.00518427568138577\n",
      "Validation Loss: 0.002301724028532927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.004974639079882763\n",
      "Training Loss: 0.00494822042179294\n",
      "Training Loss: 0.005182065558619798\n",
      "Validation Loss: 0.0022997963216072055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.004972376438672654\n",
      "Training Loss: 0.004945737150264904\n",
      "Training Loss: 0.00517987689410802\n",
      "Validation Loss: 0.002297882806232429\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.004970138730132021\n",
      "Training Loss: 0.0049432786507532\n",
      "Training Loss: 0.0051777088490780445\n",
      "Validation Loss: 0.002295981942848669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.004967923889635131\n",
      "Training Loss: 0.0049408442666754124\n",
      "Training Loss: 0.0051755601004697385\n",
      "Validation Loss: 0.0022940990231209175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.004965733008575625\n",
      "Training Loss: 0.004938435130170547\n",
      "Training Loss: 0.005173431375296787\n",
      "Validation Loss: 0.002292229580755733\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.00496356567949988\n",
      "Training Loss: 0.0049360482796328145\n",
      "Training Loss: 0.005171321799862199\n",
      "Validation Loss: 0.0022903712325091107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.004961420790059492\n",
      "Training Loss: 0.004933682845439762\n",
      "Training Loss: 0.005169230801984667\n",
      "Validation Loss: 0.0022885286833913055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.004959297332679853\n",
      "Training Loss: 0.004931341530173086\n",
      "Training Loss: 0.005167157386895269\n",
      "Validation Loss: 0.002286700155125575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.0049571960227331145\n",
      "Training Loss: 0.004929021243005991\n",
      "Training Loss: 0.005165102243772708\n",
      "Validation Loss: 0.0022848826836993435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.004955115425400436\n",
      "Training Loss: 0.00492672102409415\n",
      "Training Loss: 0.005163064015796408\n",
      "Validation Loss: 0.0022830769002406197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [06:54<27:37, 207.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.10839949861168861\n",
      "Training Loss: 0.08884037058800459\n",
      "Training Loss: 0.08165888143703341\n",
      "Validation Loss: 0.07272992718420672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.07369550917297601\n",
      "Training Loss: 0.07026312161237001\n",
      "Training Loss: 0.06828055512160063\n",
      "Validation Loss: 0.06163546279742477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06292957222089171\n",
      "Training Loss: 0.05982377965003252\n",
      "Training Loss: 0.05733102699741721\n",
      "Validation Loss: 0.050576768438802676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05180625477805734\n",
      "Training Loss: 0.048711511762812736\n",
      "Training Loss: 0.04572227369062602\n",
      "Validation Loss: 0.03911110668788465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.040156705044209956\n",
      "Training Loss: 0.03746006730943918\n",
      "Training Loss: 0.03440466600470245\n",
      "Validation Loss: 0.028593054313338206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.029478701795451343\n",
      "Training Loss: 0.027819254398345948\n",
      "Training Loss: 0.02531171228736639\n",
      "Validation Loss: 0.020883932741086804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.02177813772112131\n",
      "Training Loss: 0.021484278892166912\n",
      "Training Loss: 0.01979879753664136\n",
      "Validation Loss: 0.016627364164071807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.017590160097461192\n",
      "Training Loss: 0.01824744762852788\n",
      "Training Loss: 0.017119863883126526\n",
      "Validation Loss: 0.014610051334406553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.015624905785080046\n",
      "Training Loss: 0.016691767231095583\n",
      "Training Loss: 0.01583039286546409\n",
      "Validation Loss: 0.01356623616864842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.014635876526590437\n",
      "Training Loss: 0.01583163829287514\n",
      "Training Loss: 0.015096057932823896\n",
      "Validation Loss: 0.01290237069590373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.014034831774188206\n",
      "Training Loss: 0.015259492287877947\n",
      "Training Loss: 0.014594551983755082\n",
      "Validation Loss: 0.012409872412053722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.013604852694552392\n",
      "Training Loss: 0.014825432300567628\n",
      "Training Loss: 0.014205161178251728\n",
      "Validation Loss: 0.0120047904613815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013257611104054377\n",
      "Training Loss: 0.014458329549524933\n",
      "Training Loss: 0.013866094547556712\n",
      "Validation Loss: 0.011632691977252618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.012940231884131207\n",
      "Training Loss: 0.014104055296629668\n",
      "Training Loss: 0.013525356855243444\n",
      "Validation Loss: 0.011234377424515198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.012599427772220223\n",
      "Training Loss: 0.013695907177170738\n",
      "Training Loss: 0.013113088821992278\n",
      "Validation Loss: 0.010716460085358847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.012153684715740383\n",
      "Training Loss: 0.01312327166670002\n",
      "Training Loss: 0.012510504012461753\n",
      "Validation Loss: 0.009913090425491166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.01146162411547266\n",
      "Training Loss: 0.012201038119383157\n",
      "Training Loss: 0.01153671661275439\n",
      "Validation Loss: 0.00861852512475145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.010374565471429377\n",
      "Training Loss: 0.010843438153387978\n",
      "Training Loss: 0.010290365259861574\n",
      "Validation Loss: 0.00726845396258816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009321019174531103\n",
      "Training Loss: 0.009804309712490068\n",
      "Training Loss: 0.009572446611709893\n",
      "Validation Loss: 0.0066824659464483184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008858035096200183\n",
      "Training Loss: 0.009400667654117569\n",
      "Training Loss: 0.009296910465927795\n",
      "Validation Loss: 0.006432720258559906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008661032996606081\n",
      "Training Loss: 0.00921249193022959\n",
      "Training Loss: 0.009143143475521356\n",
      "Validation Loss: 0.006267603208164402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008541103313909844\n",
      "Training Loss: 0.009087174418382346\n",
      "Training Loss: 0.009029442705214023\n",
      "Validation Loss: 0.006135572569465704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008449584108311682\n",
      "Training Loss: 0.008985941145801916\n",
      "Training Loss: 0.008933391267200932\n",
      "Validation Loss: 0.006020630278174629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008371527269482613\n",
      "Training Loss: 0.008896905625006184\n",
      "Training Loss: 0.00884736934211105\n",
      "Validation Loss: 0.005916660437046477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00830157476128079\n",
      "Training Loss: 0.008815733793890104\n",
      "Training Loss: 0.008768321187235415\n",
      "Validation Loss: 0.005820910314234037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008237424180842936\n",
      "Training Loss: 0.008740495975362137\n",
      "Training Loss: 0.008694764814572408\n",
      "Validation Loss: 0.00573188288848889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008177871825173497\n",
      "Training Loss: 0.00867014447809197\n",
      "Training Loss: 0.00862583084614016\n",
      "Validation Loss: 0.005648598135082742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008122178472112863\n",
      "Training Loss: 0.008604017805773766\n",
      "Training Loss: 0.008560944092459976\n",
      "Validation Loss: 0.005570355657582286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00806983864866197\n",
      "Training Loss: 0.008541655441513285\n",
      "Training Loss: 0.008499688630690798\n",
      "Validation Loss: 0.005496617935053753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008020489974878729\n",
      "Training Loss: 0.008482723059132695\n",
      "Training Loss: 0.00844175013829954\n",
      "Validation Loss: 0.00542696299073234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007973857391625642\n",
      "Training Loss: 0.008426959863863886\n",
      "Training Loss: 0.008386884154751896\n",
      "Validation Loss: 0.005361048897121395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007929729988100008\n",
      "Training Loss: 0.008374157910002395\n",
      "Training Loss: 0.008334887744858861\n",
      "Validation Loss: 0.005298580237915426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007887937314808368\n",
      "Training Loss: 0.008324141050688922\n",
      "Training Loss: 0.008285587049322203\n",
      "Validation Loss: 0.005239311692022373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007848334953887388\n",
      "Training Loss: 0.008276752965757623\n",
      "Training Loss: 0.008238829883048311\n",
      "Validation Loss: 0.005183015163893696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007810794190736488\n",
      "Training Loss: 0.00823184902081266\n",
      "Training Loss: 0.008194471170427278\n",
      "Validation Loss: 0.005129484928035167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007775198540184647\n",
      "Training Loss: 0.008189294795738534\n",
      "Training Loss: 0.008152377819642424\n",
      "Validation Loss: 0.005078526419127004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007741438822122291\n",
      "Training Loss: 0.008148957258090377\n",
      "Training Loss: 0.008112418866949156\n",
      "Validation Loss: 0.005029958997214778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007709407121874392\n",
      "Training Loss: 0.008110705985454842\n",
      "Training Loss: 0.008074465586105362\n",
      "Validation Loss: 0.004983606171438449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0076790002011694015\n",
      "Training Loss: 0.008074413196882234\n",
      "Training Loss: 0.008038394467439503\n",
      "Validation Loss: 0.00493930273668401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007650116806617007\n",
      "Training Loss: 0.008039961574831977\n",
      "Training Loss: 0.00800408745300956\n",
      "Validation Loss: 0.004896897854011381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007622661981731654\n",
      "Training Loss: 0.008007229862269014\n",
      "Training Loss: 0.007971427900483831\n",
      "Validation Loss: 0.004856242898987669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0075965395907405765\n",
      "Training Loss: 0.007976104681147263\n",
      "Training Loss: 0.007940304945223034\n",
      "Validation Loss: 0.004817206488419952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007571661407127977\n",
      "Training Loss: 0.007946480442769825\n",
      "Training Loss: 0.007910616613226012\n",
      "Validation Loss: 0.0047796666242831045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0075479455513414\n",
      "Training Loss: 0.0079182572173886\n",
      "Training Loss: 0.007882264944491908\n",
      "Validation Loss: 0.004743519105707829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007525313518708571\n",
      "Training Loss: 0.007891343865776435\n",
      "Training Loss: 0.007855162596097216\n",
      "Validation Loss: 0.004708667633678304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007503695200430229\n",
      "Training Loss: 0.007865654285997153\n",
      "Training Loss: 0.007829227258916945\n",
      "Validation Loss: 0.004675027231549781\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007483025663532317\n",
      "Training Loss: 0.00784111509216018\n",
      "Training Loss: 0.007804384304909036\n",
      "Validation Loss: 0.004642527895780762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007463246585102752\n",
      "Training Loss: 0.007817654262762517\n",
      "Training Loss: 0.007780567154986784\n",
      "Validation Loss: 0.004611109697333212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007444305416429415\n",
      "Training Loss: 0.007795209462055936\n",
      "Training Loss: 0.007757716057822109\n",
      "Validation Loss: 0.004580721043290968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007426156050059945\n",
      "Training Loss: 0.007773726596496999\n",
      "Training Loss: 0.007735777301713824\n",
      "Validation Loss: 0.004551325978324069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007408756748773158\n",
      "Training Loss: 0.007753154198871926\n",
      "Training Loss: 0.007714703257661313\n",
      "Validation Loss: 0.004522885936260056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007392069889465347\n",
      "Training Loss: 0.007733447924256325\n",
      "Training Loss: 0.007694449931150303\n",
      "Validation Loss: 0.004495376791658528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007376062511466444\n",
      "Training Loss: 0.00771456710412167\n",
      "Training Loss: 0.007674979441799223\n",
      "Validation Loss: 0.004468778632267305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007360704086022451\n",
      "Training Loss: 0.007696474451804534\n",
      "Training Loss: 0.007656256348127499\n",
      "Validation Loss: 0.0044430725229380845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007345967007568106\n",
      "Training Loss: 0.007679134419886395\n",
      "Training Loss: 0.007638248755829409\n",
      "Validation Loss: 0.004418245367601179\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007331825594883412\n",
      "Training Loss: 0.00766251724679023\n",
      "Training Loss: 0.007620926834642887\n",
      "Validation Loss: 0.004394284266392502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007318255779100582\n",
      "Training Loss: 0.0076465906901285055\n",
      "Training Loss: 0.007604263583198189\n",
      "Validation Loss: 0.004371179652327065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007305234102532267\n",
      "Training Loss: 0.0076313277904409916\n",
      "Training Loss: 0.00758823147858493\n",
      "Validation Loss: 0.004348919628805408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007292738797841594\n",
      "Training Loss: 0.007616698248311877\n",
      "Training Loss: 0.007572805642848834\n",
      "Validation Loss: 0.004327493373126713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007280747902113944\n",
      "Training Loss: 0.007602675578091293\n",
      "Training Loss: 0.007557961078127846\n",
      "Validation Loss: 0.004306889311776737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007269238737644628\n",
      "Training Loss: 0.007589232317404822\n",
      "Training Loss: 0.007543673156760633\n",
      "Validation Loss: 0.004287092535746064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007258189661661163\n",
      "Training Loss: 0.007576341229723766\n",
      "Training Loss: 0.007529918215004728\n",
      "Validation Loss: 0.00426808864223572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007247580186231062\n",
      "Training Loss: 0.007563975845696405\n",
      "Training Loss: 0.007516672925557941\n",
      "Validation Loss: 0.00424986136187747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00723738688393496\n",
      "Training Loss: 0.007552109448006376\n",
      "Training Loss: 0.007503914212575183\n",
      "Validation Loss: 0.004232391329178733\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007227589308749885\n",
      "Training Loss: 0.007540715920040384\n",
      "Training Loss: 0.007491617691703141\n",
      "Validation Loss: 0.004215658444837992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007218165111262351\n",
      "Training Loss: 0.0075297672534361485\n",
      "Training Loss: 0.00747975995298475\n",
      "Validation Loss: 0.0041996379385524415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007209092731354758\n",
      "Training Loss: 0.007519240437541157\n",
      "Training Loss: 0.007468319598119706\n",
      "Validation Loss: 0.0041843086685148185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007200351841747761\n",
      "Training Loss: 0.007509107757359743\n",
      "Training Loss: 0.007457273287000135\n",
      "Validation Loss: 0.004169647557022615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007191921022022143\n",
      "Training Loss: 0.007499347158009186\n",
      "Training Loss: 0.007446600323310122\n",
      "Validation Loss: 0.004155625939745916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007183780848281458\n",
      "Training Loss: 0.007489933199249208\n",
      "Training Loss: 0.007436277838423848\n",
      "Validation Loss: 0.00414221997508842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007175911371596158\n",
      "Training Loss: 0.00748084292630665\n",
      "Training Loss: 0.007426286924164742\n",
      "Validation Loss: 0.00412939931658421\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00716829446493648\n",
      "Training Loss: 0.007472055195830762\n",
      "Training Loss: 0.007416606650222093\n",
      "Validation Loss: 0.0041171421160858665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007160910979146138\n",
      "Training Loss: 0.007463548429077491\n",
      "Training Loss: 0.007407217600848526\n",
      "Validation Loss: 0.004105416712549965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007153744761599228\n",
      "Training Loss: 0.007455302479211241\n",
      "Training Loss: 0.007398102920269593\n",
      "Validation Loss: 0.004094199257840016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007146778914611787\n",
      "Training Loss: 0.007447299542836845\n",
      "Training Loss: 0.007389244103105739\n",
      "Validation Loss: 0.004083462357730343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00713999907951802\n",
      "Training Loss: 0.0074395203846506774\n",
      "Training Loss: 0.0073806246020831166\n",
      "Validation Loss: 0.0040731803629170645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007133388798683882\n",
      "Training Loss: 0.007431949458550662\n",
      "Training Loss: 0.007372229542816058\n",
      "Validation Loss: 0.004063327870007311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007126936540007591\n",
      "Training Loss: 0.007424571050796658\n",
      "Training Loss: 0.007364042834378779\n",
      "Validation Loss: 0.0040538819412585725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007120628713164478\n",
      "Training Loss: 0.0074173688376322384\n",
      "Training Loss: 0.007356050661765039\n",
      "Validation Loss: 0.004044816377991287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007114452944369987\n",
      "Training Loss: 0.007410330799175426\n",
      "Training Loss: 0.007348240617429838\n",
      "Validation Loss: 0.0040361110076538465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007108398654963821\n",
      "Training Loss: 0.007403443980729207\n",
      "Training Loss: 0.007340599210001528\n",
      "Validation Loss: 0.004027742526253287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007102455436252058\n",
      "Training Loss: 0.007396695584757254\n",
      "Training Loss: 0.007333115083165467\n",
      "Validation Loss: 0.004019689370794327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0070966130844317375\n",
      "Training Loss: 0.007390075236326083\n",
      "Training Loss: 0.007325777171645314\n",
      "Validation Loss: 0.004011933821295336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007090862892800942\n",
      "Training Loss: 0.0073835724079981445\n",
      "Training Loss: 0.0073185742308851335\n",
      "Validation Loss: 0.004004455638494803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007085197629639879\n",
      "Training Loss: 0.007377177934395149\n",
      "Training Loss: 0.007311498391209171\n",
      "Validation Loss: 0.0039972382992652525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007079607635969296\n",
      "Training Loss: 0.007370883795665577\n",
      "Training Loss: 0.007304538949392736\n",
      "Validation Loss: 0.003990263512012747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007074086605571211\n",
      "Training Loss: 0.007364679366583004\n",
      "Training Loss: 0.007297687785467133\n",
      "Validation Loss: 0.003983513657474534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007068628310225904\n",
      "Training Loss: 0.007358558455016464\n",
      "Training Loss: 0.0072909361158963295\n",
      "Validation Loss: 0.003976974803745077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007063226376194507\n",
      "Training Loss: 0.007352514013182372\n",
      "Training Loss: 0.007284276970895007\n",
      "Validation Loss: 0.0039706334152541465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007057874373858794\n",
      "Training Loss: 0.007346539387945086\n",
      "Training Loss: 0.007277703988365829\n",
      "Validation Loss: 0.003964474804050634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00705256751854904\n",
      "Training Loss: 0.00734062742209062\n",
      "Training Loss: 0.007271208515157923\n",
      "Validation Loss: 0.003958485530051036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007047299767145887\n",
      "Training Loss: 0.0073347731586545705\n",
      "Training Loss: 0.007264785342267714\n",
      "Validation Loss: 0.003952654873889484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007042067657457665\n",
      "Training Loss: 0.007328970867674798\n",
      "Training Loss: 0.0072584282397292555\n",
      "Validation Loss: 0.003946969921313478\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007036865495610983\n",
      "Training Loss: 0.007323215043870732\n",
      "Training Loss: 0.007252130651613698\n",
      "Validation Loss: 0.003941416770502339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007031690258299932\n",
      "Training Loss: 0.00731750127277337\n",
      "Training Loss: 0.007245888400939293\n",
      "Validation Loss: 0.003935990974129167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007026537305209786\n",
      "Training Loss: 0.0073118257010355596\n",
      "Training Loss: 0.007239695596508682\n",
      "Validation Loss: 0.00393068052833544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007021403670078144\n",
      "Training Loss: 0.007306182425236329\n",
      "Training Loss: 0.007233547244686634\n",
      "Validation Loss: 0.003925473942013269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007016284561250359\n",
      "Training Loss: 0.007300568945938721\n",
      "Training Loss: 0.007227439392590895\n",
      "Validation Loss: 0.003920363610233651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007011177331442013\n",
      "Training Loss: 0.007294979948783293\n",
      "Training Loss: 0.00722136659489479\n",
      "Validation Loss: 0.003915339204733878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007006079510319978\n",
      "Training Loss: 0.007289412940153852\n",
      "Training Loss: 0.007215325655997731\n",
      "Validation Loss: 0.0039103953167796135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007000988420331851\n",
      "Training Loss: 0.007283863467164337\n",
      "Training Loss: 0.007209312013583258\n",
      "Validation Loss: 0.003905523136739483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006995899183675647\n",
      "Training Loss: 0.007278329774271697\n",
      "Training Loss: 0.007203322302666492\n",
      "Validation Loss: 0.0039007158510470656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006990811842260882\n",
      "Training Loss: 0.007272807360859588\n",
      "Training Loss: 0.007197352779330686\n",
      "Validation Loss: 0.0038959647220130384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006985722024692223\n",
      "Training Loss: 0.007267293797340244\n",
      "Training Loss: 0.007191398953436874\n",
      "Validation Loss: 0.003891264777787532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006980629343306646\n",
      "Training Loss: 0.007261785473674536\n",
      "Training Loss: 0.007185458535095677\n",
      "Validation Loss: 0.003886609642996631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006975529558258131\n",
      "Training Loss: 0.007256280296714977\n",
      "Training Loss: 0.0071795277704950426\n",
      "Validation Loss: 0.003881992517154287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0069704207184258845\n",
      "Training Loss: 0.0072507756296545265\n",
      "Training Loss: 0.00717360382899642\n",
      "Validation Loss: 0.0038774073191949828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006965302784228697\n",
      "Training Loss: 0.007245269777486101\n",
      "Training Loss: 0.007167684308951721\n",
      "Validation Loss: 0.003872850754172698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006960171824321151\n",
      "Training Loss: 0.007239759484073147\n",
      "Training Loss: 0.00716176574176643\n",
      "Validation Loss: 0.0038683158057752284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006955028366064653\n",
      "Training Loss: 0.00723424190771766\n",
      "Training Loss: 0.007155845579109155\n",
      "Validation Loss: 0.003863795969132962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006949867840157822\n",
      "Training Loss: 0.0072287163557484746\n",
      "Training Loss: 0.007149921795353294\n",
      "Validation Loss: 0.003859289212863934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006944690376985818\n",
      "Training Loss: 0.007223179122665897\n",
      "Training Loss: 0.007143990614567883\n",
      "Validation Loss: 0.0038547884487138873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006939494580728933\n",
      "Training Loss: 0.007217629016377031\n",
      "Training Loss: 0.007138050719513558\n",
      "Validation Loss: 0.0038502890907039637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006934278067201376\n",
      "Training Loss: 0.0072120629565324635\n",
      "Training Loss: 0.007132099190494045\n",
      "Validation Loss: 0.003845786433823909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006929039051756263\n",
      "Training Loss: 0.007206480706809088\n",
      "Training Loss: 0.007126134666614234\n",
      "Validation Loss: 0.0038412783616693334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006923777615884319\n",
      "Training Loss: 0.007200878729345277\n",
      "Training Loss: 0.007120153087889776\n",
      "Validation Loss: 0.003836759264068155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.0069184917164966464\n",
      "Training Loss: 0.007195255979895592\n",
      "Training Loss: 0.0071141542901750655\n",
      "Validation Loss: 0.0038322260004227584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006913179850671441\n",
      "Training Loss: 0.007189609631896019\n",
      "Training Loss: 0.007108134842710569\n",
      "Validation Loss: 0.0038276747735007926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.00690783925470896\n",
      "Training Loss: 0.007183938833186403\n",
      "Training Loss: 0.007102093099383637\n",
      "Validation Loss: 0.0038231031137277906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006902469830820337\n",
      "Training Loss: 0.007178240488283336\n",
      "Training Loss: 0.007096026077051647\n",
      "Validation Loss: 0.003818506592089373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006897070343839005\n",
      "Training Loss: 0.00717251259018667\n",
      "Training Loss: 0.0070899328251834955\n",
      "Validation Loss: 0.0038138812648530088\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0068916371546220035\n",
      "Training Loss: 0.007166753247147426\n",
      "Training Loss: 0.007083809707546606\n",
      "Validation Loss: 0.0038092237363538044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0068861704086884854\n",
      "Training Loss: 0.007160959527827799\n",
      "Training Loss: 0.007077654666500166\n",
      "Validation Loss: 0.003804532617456123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006880666038487106\n",
      "Training Loss: 0.007155130213359371\n",
      "Training Loss: 0.007071465003537014\n",
      "Validation Loss: 0.00379980325154709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006875123529462144\n",
      "Training Loss: 0.007149260714650154\n",
      "Training Loss: 0.0070652377227088435\n",
      "Validation Loss: 0.0037950337288922137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.00686953887110576\n",
      "Training Loss: 0.007143349498510361\n",
      "Training Loss: 0.007058970020152628\n",
      "Validation Loss: 0.0037902167310226668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0068639103474561125\n",
      "Training Loss: 0.007137391365831718\n",
      "Training Loss: 0.0070526571187656375\n",
      "Validation Loss: 0.003785354448900966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006858233517268672\n",
      "Training Loss: 0.007131385058164597\n",
      "Training Loss: 0.007046296320040711\n",
      "Validation Loss: 0.003780442125195365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006852506006835029\n",
      "Training Loss: 0.007125325641827658\n",
      "Training Loss: 0.007039883762481622\n",
      "Validation Loss: 0.0037754740647113556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006846722910413518\n",
      "Training Loss: 0.007119207700015977\n",
      "Training Loss: 0.007033413872122764\n",
      "Validation Loss: 0.003770445757336245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006840880805393681\n",
      "Training Loss: 0.007113028807798401\n",
      "Training Loss: 0.007026882885838859\n",
      "Validation Loss: 0.003765356658926506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006834973864024505\n",
      "Training Loss: 0.007106781414477154\n",
      "Training Loss: 0.007020283654564991\n",
      "Validation Loss: 0.0037601995046428415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0068289964529685675\n",
      "Training Loss: 0.00710046055377461\n",
      "Training Loss: 0.007013610749854706\n",
      "Validation Loss: 0.003754968587518408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00682294225669466\n",
      "Training Loss: 0.007094059695955366\n",
      "Training Loss: 0.0070068565738620235\n",
      "Validation Loss: 0.0037496593124180864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006816802816465497\n",
      "Training Loss: 0.007087572201853618\n",
      "Training Loss: 0.0070000115071889015\n",
      "Validation Loss: 0.0037442671142916164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006810571638634428\n",
      "Training Loss: 0.007080987001536414\n",
      "Training Loss: 0.006993066995637492\n",
      "Validation Loss: 0.0037387795053066665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.00680423769284971\n",
      "Training Loss: 0.007074296619975939\n",
      "Training Loss: 0.0069860125135164704\n",
      "Validation Loss: 0.0037331929668428356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006797789942938834\n",
      "Training Loss: 0.00706749051110819\n",
      "Training Loss: 0.006978834916371852\n",
      "Validation Loss: 0.0037274948305586414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.0067912157892715186\n",
      "Training Loss: 0.007060554341878742\n",
      "Training Loss: 0.006971519960206934\n",
      "Validation Loss: 0.003721672371866998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006784500408684835\n",
      "Training Loss: 0.00705347525770776\n",
      "Training Loss: 0.006964051062823273\n",
      "Validation Loss: 0.0037157137399497493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006777626111870632\n",
      "Training Loss: 0.0070462362968828525\n",
      "Training Loss: 0.006956408935948275\n",
      "Validation Loss: 0.003709600188015971\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006770574152469635\n",
      "Training Loss: 0.007038818288128823\n",
      "Training Loss: 0.006948570871027186\n",
      "Validation Loss: 0.0037033136023648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006763320222962648\n",
      "Training Loss: 0.007031200397759676\n",
      "Training Loss: 0.006940511982538738\n",
      "Validation Loss: 0.003696833675716784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006755837620003149\n",
      "Training Loss: 0.007023357207654044\n",
      "Training Loss: 0.0069322024588473145\n",
      "Validation Loss: 0.003690134644968791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006748095948714763\n",
      "Training Loss: 0.0070152603590395305\n",
      "Training Loss: 0.00692360779910814\n",
      "Validation Loss: 0.0036831848621577696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006740059650037438\n",
      "Training Loss: 0.007006876625819131\n",
      "Training Loss: 0.006914689336554147\n",
      "Validation Loss: 0.003675950180969379\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006731686217244714\n",
      "Training Loss: 0.006998168303398416\n",
      "Training Loss: 0.006905402195989154\n",
      "Validation Loss: 0.0036683868763319563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006722930106334389\n",
      "Training Loss: 0.006989093390293419\n",
      "Training Loss: 0.006895694889244623\n",
      "Validation Loss: 0.003660449841886424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006713737535756081\n",
      "Training Loss: 0.006979603470535949\n",
      "Training Loss: 0.006885511663858779\n",
      "Validation Loss: 0.0036520881125745312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006704049981199205\n",
      "Training Loss: 0.00696964657632634\n",
      "Training Loss: 0.0068747901520691814\n",
      "Validation Loss: 0.0036432380353759847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006693804074311629\n",
      "Training Loss: 0.006959168156608939\n",
      "Training Loss: 0.006863463345216587\n",
      "Validation Loss: 0.003633841262669878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.00668293188791722\n",
      "Training Loss: 0.006948108330834657\n",
      "Training Loss: 0.006851463947095908\n",
      "Validation Loss: 0.0036238289537598913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006671366317896173\n",
      "Training Loss: 0.006936409346526489\n",
      "Training Loss: 0.006838724322151392\n",
      "Validation Loss: 0.00361314169889881\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006659043183317408\n",
      "Training Loss: 0.006924017259152606\n",
      "Training Loss: 0.006825183897744864\n",
      "Validation Loss: 0.0036017171413313303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006645909090293571\n",
      "Training Loss: 0.006910887637641281\n",
      "Training Loss: 0.006810794264310971\n",
      "Validation Loss: 0.0035895130118313297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006631927757989615\n",
      "Training Loss: 0.006896994283888489\n",
      "Training Loss: 0.006795529604423791\n",
      "Validation Loss: 0.003576508797757495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006617089848732576\n",
      "Training Loss: 0.006882331582019106\n",
      "Training Loss: 0.006779392141615972\n",
      "Validation Loss: 0.003562710790769354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006601420950610191\n",
      "Training Loss: 0.006866927139926701\n",
      "Training Loss: 0.006762423729524017\n",
      "Validation Loss: 0.0035481670638546348\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006584987598471343\n",
      "Training Loss: 0.006850843338761479\n",
      "Training Loss: 0.006744709190097637\n",
      "Validation Loss: 0.0035329681959819425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006567901355447247\n",
      "Training Loss: 0.006834180207224563\n",
      "Training Loss: 0.00672637463954743\n",
      "Validation Loss: 0.0035172374369681217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.0065503138257190585\n",
      "Training Loss: 0.006817070309771225\n",
      "Training Loss: 0.006707585034891963\n",
      "Validation Loss: 0.0035011375890626165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006532407235354185\n",
      "Training Loss: 0.006799672439228743\n",
      "Training Loss: 0.0066885291878134015\n",
      "Validation Loss: 0.00348484253097493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006514375134720467\n",
      "Training Loss: 0.006782151845982298\n",
      "Training Loss: 0.006669404737185687\n",
      "Validation Loss: 0.0034685342721745708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006496408052043989\n",
      "Training Loss: 0.0067646703205537055\n",
      "Training Loss: 0.006650398733909242\n",
      "Validation Loss: 0.0034523679681247874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006478672859957442\n",
      "Training Loss: 0.006747373327380046\n",
      "Training Loss: 0.006631673703668639\n",
      "Validation Loss: 0.0034364790844029925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006461304062395356\n",
      "Training Loss: 0.006730372470337897\n",
      "Training Loss: 0.006613357054884545\n",
      "Validation Loss: 0.003420958107107141\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006444394392892718\n",
      "Training Loss: 0.006713750759372488\n",
      "Training Loss: 0.006595538611873053\n",
      "Validation Loss: 0.003405868685333414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006428002419415862\n",
      "Training Loss: 0.006697559403255582\n",
      "Training Loss: 0.006578271965263411\n",
      "Validation Loss: 0.0033912320746883246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006412153355777264\n",
      "Training Loss: 0.006681823377730325\n",
      "Training Loss: 0.006561581841669977\n",
      "Validation Loss: 0.003377052913472224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006396847963915206\n",
      "Training Loss: 0.006666544749168679\n",
      "Training Loss: 0.006545468607801013\n",
      "Validation Loss: 0.0033633196661039515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.0063820721488446\n",
      "Training Loss: 0.006651713607134298\n",
      "Training Loss: 0.006529917077859864\n",
      "Validation Loss: 0.0033500053516976286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006367801314918324\n",
      "Training Loss: 0.006637309718644247\n",
      "Training Loss: 0.006514902762137354\n",
      "Validation Loss: 0.003337083360849974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006354005872271955\n",
      "Training Loss: 0.006623307793634012\n",
      "Training Loss: 0.0065003954514395446\n",
      "Validation Loss: 0.0033245209128376137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006340653626248241\n",
      "Training Loss: 0.006609681074041873\n",
      "Training Loss: 0.0064863613591296596\n",
      "Validation Loss: 0.003312290388452454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006327714568469673\n",
      "Training Loss: 0.006596401745919138\n",
      "Training Loss: 0.006472769202664494\n",
      "Validation Loss: 0.0033003649990901015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006315160455415025\n",
      "Training Loss: 0.006583443657727912\n",
      "Training Loss: 0.006459586673881859\n",
      "Validation Loss: 0.003288721054886583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006302964547066949\n",
      "Training Loss: 0.006570784343639388\n",
      "Training Loss: 0.006446787019958719\n",
      "Validation Loss: 0.0032773408384763458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006291104466072284\n",
      "Training Loss: 0.006558401064248756\n",
      "Training Loss: 0.006434342279098928\n",
      "Validation Loss: 0.0032662019405639573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006279556539375335\n",
      "Training Loss: 0.006546274492284283\n",
      "Training Loss: 0.006422228083247319\n",
      "Validation Loss: 0.003255290337681268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.00626830336987041\n",
      "Training Loss: 0.006534387683495879\n",
      "Training Loss: 0.006410422250628472\n",
      "Validation Loss: 0.003244594791171591\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006257327332277783\n",
      "Training Loss: 0.006522724512033165\n",
      "Training Loss: 0.0063989047124050555\n",
      "Validation Loss: 0.003234102781809699\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006246612194809131\n",
      "Training Loss: 0.0065112698264420035\n",
      "Training Loss: 0.006387655949220061\n",
      "Validation Loss: 0.0032238023606746386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.00623614211101085\n",
      "Training Loss: 0.006500010055024177\n",
      "Training Loss: 0.006376657033688389\n",
      "Validation Loss: 0.00321368590714096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006225903918384575\n",
      "Training Loss: 0.006488932782085613\n",
      "Training Loss: 0.006365892244502902\n",
      "Validation Loss: 0.003203743206745202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.0062158842955250294\n",
      "Training Loss: 0.006478024809621274\n",
      "Training Loss: 0.006355345717747696\n",
      "Validation Loss: 0.0031939659796111036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006206068298197352\n",
      "Training Loss: 0.006467276636976748\n",
      "Training Loss: 0.006345002491725609\n",
      "Validation Loss: 0.003184348767298912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006196444062516094\n",
      "Training Loss: 0.0064566751255188135\n",
      "Training Loss: 0.006334846916724928\n",
      "Validation Loss: 0.003174881329184419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006186998617486097\n",
      "Training Loss: 0.006446209100540727\n",
      "Training Loss: 0.006324865437345579\n",
      "Validation Loss: 0.0031655518183735815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006177720085834153\n",
      "Training Loss: 0.006435868358239532\n",
      "Training Loss: 0.006315044371294789\n",
      "Validation Loss: 0.003156358346060504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006168595672934316\n",
      "Training Loss: 0.006425644678529352\n",
      "Training Loss: 0.006305371433845721\n",
      "Validation Loss: 0.0031472887134891044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006159613541094586\n",
      "Training Loss: 0.006415524990297854\n",
      "Training Loss: 0.006295833745389246\n",
      "Validation Loss: 0.0031383380534525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006150761640165001\n",
      "Training Loss: 0.006405500156106427\n",
      "Training Loss: 0.006286418999661691\n",
      "Validation Loss: 0.00312949414626601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006142028964241035\n",
      "Training Loss: 0.006395561636891216\n",
      "Training Loss: 0.006277117177378386\n",
      "Validation Loss: 0.0031207499259120123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0061334049026481804\n",
      "Training Loss: 0.006385698539670557\n",
      "Training Loss: 0.006267916258075275\n",
      "Validation Loss: 0.003112097327032367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00612487658218015\n",
      "Training Loss: 0.006375900965649634\n",
      "Training Loss: 0.006258807295816951\n",
      "Validation Loss: 0.003103524806197691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006116435276344419\n",
      "Training Loss: 0.0063661604048684236\n",
      "Training Loss: 0.006249778482597322\n",
      "Validation Loss: 0.003095026020735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006108068203902803\n",
      "Training Loss: 0.006356467859586701\n",
      "Training Loss: 0.006240821361425333\n",
      "Validation Loss: 0.0030865911891411863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006099765440449118\n",
      "Training Loss: 0.006346812082920223\n",
      "Training Loss: 0.0062319274130277335\n",
      "Validation Loss: 0.0030782074900344014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.00609151761222165\n",
      "Training Loss: 0.006337184646399692\n",
      "Training Loss: 0.00622308706631884\n",
      "Validation Loss: 0.0030698701974757937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006083311963011511\n",
      "Training Loss: 0.006327570977155119\n",
      "Training Loss: 0.0062142899155151095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [10:21<24:08, 206.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0030615618373947533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5548192612826824\n",
      "Training Loss: 0.4538154189288616\n",
      "Training Loss: 0.3726331006735563\n",
      "Validation Loss: 0.27485843002796173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.23542774137109518\n",
      "Training Loss: 0.15677558820694684\n",
      "Training Loss: 0.10488349709659815\n",
      "Validation Loss: 0.06585245864110047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06716355921700597\n",
      "Training Loss: 0.06086020313203335\n",
      "Training Loss: 0.05797160070389509\n",
      "Validation Loss: 0.05307081684972463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05504037672653794\n",
      "Training Loss: 0.05398005042225122\n",
      "Training Loss: 0.05178896651603281\n",
      "Validation Loss: 0.04748258963645844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.048384246900677684\n",
      "Training Loss: 0.04716189258731902\n",
      "Training Loss: 0.04451346651650965\n",
      "Validation Loss: 0.04019688264456358\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04039709687232971\n",
      "Training Loss: 0.03924068184569478\n",
      "Training Loss: 0.03638579715974629\n",
      "Validation Loss: 0.032287033839841904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03204963331110775\n",
      "Training Loss: 0.03130560490302742\n",
      "Training Loss: 0.02863208162598312\n",
      "Validation Loss: 0.025065710747175004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.02472984609659761\n",
      "Training Loss: 0.02469534657429904\n",
      "Training Loss: 0.022553659016266464\n",
      "Validation Loss: 0.0196831404241953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.019540447662584483\n",
      "Training Loss: 0.020247652479447424\n",
      "Training Loss: 0.01872289427323267\n",
      "Validation Loss: 0.016393611840694475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.016569491566624493\n",
      "Training Loss: 0.01774654454551637\n",
      "Training Loss: 0.01664746240247041\n",
      "Validation Loss: 0.014541613932154822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.015012707670684904\n",
      "Training Loss: 0.016346065283287317\n",
      "Training Loss: 0.01545914038317278\n",
      "Validation Loss: 0.013372011974537641\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.014065417158417404\n",
      "Training Loss: 0.015378097160719336\n",
      "Training Loss: 0.014579414145555348\n",
      "Validation Loss: 0.012410607277886586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013242650044849142\n",
      "Training Loss: 0.014383945760782809\n",
      "Training Loss: 0.013537611637730151\n",
      "Validation Loss: 0.011082087455087163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.011954298405908049\n",
      "Training Loss: 0.012653211546130479\n",
      "Training Loss: 0.011847304217517375\n",
      "Validation Loss: 0.009226479138551133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010521830298239365\n",
      "Training Loss: 0.011257997809443622\n",
      "Training Loss: 0.010895190320443362\n",
      "Validation Loss: 0.008319772905513141\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009927874826826156\n",
      "Training Loss: 0.010634757766965777\n",
      "Training Loss: 0.010380390426144004\n",
      "Validation Loss: 0.007765287517705995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009559697703225538\n",
      "Training Loss: 0.010214951873058454\n",
      "Training Loss: 0.010004932743031532\n",
      "Validation Loss: 0.007351415059162995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009282400367083029\n",
      "Training Loss: 0.009892181800678372\n",
      "Training Loss: 0.009707425750093535\n",
      "Validation Loss: 0.007017215551661976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009058050317689777\n",
      "Training Loss: 0.009629149201791733\n",
      "Training Loss: 0.009460638815071434\n",
      "Validation Loss: 0.006735097195722916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008869060473516583\n",
      "Training Loss: 0.009407288705697283\n",
      "Training Loss: 0.009250137779163196\n",
      "Validation Loss: 0.006490836116181833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008706162605667487\n",
      "Training Loss: 0.00921618047170341\n",
      "Training Loss: 0.009067521961405874\n",
      "Validation Loss: 0.00627628592460343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00856394571484998\n",
      "Training Loss: 0.009049396603368223\n",
      "Training Loss: 0.008907430490944534\n",
      "Validation Loss: 0.00608624176781499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008438865098869429\n",
      "Training Loss: 0.008902593249222263\n",
      "Training Loss: 0.008766115461476147\n",
      "Validation Loss: 0.005917012980574051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008328340663574636\n",
      "Training Loss: 0.00877258931635879\n",
      "Training Loss: 0.008640759128611534\n",
      "Validation Loss: 0.005765759773301274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008230339973233641\n",
      "Training Loss: 0.008656918880296871\n",
      "Training Loss: 0.008529127553338185\n",
      "Validation Loss: 0.005630178387496579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008143186382949353\n",
      "Training Loss: 0.008553591434611008\n",
      "Training Loss: 0.008429390508681536\n",
      "Validation Loss: 0.005508335615937295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008065461938967929\n",
      "Training Loss: 0.008460962414974347\n",
      "Training Loss: 0.008340014686109499\n",
      "Validation Loss: 0.005398587506850449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007995951735647395\n",
      "Training Loss: 0.008377646965673193\n",
      "Training Loss: 0.008259703004732728\n",
      "Validation Loss: 0.005299511888807409\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007933609945466743\n",
      "Training Loss: 0.008302470305934548\n",
      "Training Loss: 0.008187342868186533\n",
      "Validation Loss: 0.005209879313982772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00787753200973384\n",
      "Training Loss: 0.00823442277032882\n",
      "Training Loss: 0.008121971118962392\n",
      "Validation Loss: 0.00512860952798026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00782692907610908\n",
      "Training Loss: 0.008172629174077883\n",
      "Training Loss: 0.008062750363023952\n",
      "Validation Loss: 0.005054757481681581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0077811147097963836\n",
      "Training Loss: 0.008116329240147024\n",
      "Training Loss: 0.008008950484218076\n",
      "Validation Loss: 0.004987489935690851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007739490618696436\n",
      "Training Loss: 0.008064858998404817\n",
      "Training Loss: 0.00795992742991075\n",
      "Validation Loss: 0.004926068033353331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007701530208578333\n",
      "Training Loss: 0.00801763216033578\n",
      "Training Loss: 0.007915113234193995\n",
      "Validation Loss: 0.0048698374839353095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007666770062642172\n",
      "Training Loss: 0.007974133008392528\n",
      "Training Loss: 0.007874004574259743\n",
      "Validation Loss: 0.004818214816459863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007634803100954741\n",
      "Training Loss: 0.007933902243385091\n",
      "Training Loss: 0.007836155253462493\n",
      "Validation Loss: 0.004770682519040165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00760526817641221\n",
      "Training Loss: 0.007896533479215578\n",
      "Training Loss: 0.007801167106954381\n",
      "Validation Loss: 0.0047267728911587195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007577845118939877\n",
      "Training Loss: 0.00786166401929222\n",
      "Training Loss: 0.007768685941118747\n",
      "Validation Loss: 0.00468607210643129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007552252043969929\n",
      "Training Loss: 0.007828971348935738\n",
      "Training Loss: 0.007738394361222162\n",
      "Validation Loss: 0.004648205703856905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007528235564241186\n",
      "Training Loss: 0.007798167369328439\n",
      "Training Loss: 0.0077100113284541295\n",
      "Validation Loss: 0.00461283976635948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007505574920214713\n",
      "Training Loss: 0.007768998714163899\n",
      "Training Loss: 0.007683289055712521\n",
      "Validation Loss: 0.004579676082357764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007484072410734371\n",
      "Training Loss: 0.0077412383293267335\n",
      "Training Loss: 0.0076580041757551955\n",
      "Validation Loss: 0.004548446239976819\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.0074635571509134024\n",
      "Training Loss: 0.007714688285486773\n",
      "Training Loss: 0.007633961197570898\n",
      "Validation Loss: 0.004518910096644351\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007443875294411555\n",
      "Training Loss: 0.007689174365950748\n",
      "Training Loss: 0.0076109904784243555\n",
      "Validation Loss: 0.004490854535147213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007424896729644388\n",
      "Training Loss: 0.007664546216838062\n",
      "Training Loss: 0.007588941215653904\n",
      "Validation Loss: 0.004464089382554959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00740650885971263\n",
      "Training Loss: 0.007640675717266276\n",
      "Training Loss: 0.00756768855615519\n",
      "Validation Loss: 0.004438448958936032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0073886174021754415\n",
      "Training Loss: 0.007617455944418907\n",
      "Training Loss: 0.007547123885015026\n",
      "Validation Loss: 0.0044137854129076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007371144687058404\n",
      "Training Loss: 0.007594798606587574\n",
      "Training Loss: 0.007527157654985786\n",
      "Validation Loss: 0.004389970610441452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007354028023546562\n",
      "Training Loss: 0.007572633981471882\n",
      "Training Loss: 0.007507718619890511\n",
      "Validation Loss: 0.004366897936031389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007337219547480345\n",
      "Training Loss: 0.007550908628618344\n",
      "Training Loss: 0.007488750982447528\n",
      "Validation Loss: 0.004344476457538732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0073206856020260605\n",
      "Training Loss: 0.007529586059972644\n",
      "Training Loss: 0.007470213394844905\n",
      "Validation Loss: 0.004322634631862048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.0073044050356838855\n",
      "Training Loss: 0.00750864161294885\n",
      "Training Loss: 0.0074520766804926095\n",
      "Validation Loss: 0.004301312642454515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007288365232525394\n",
      "Training Loss: 0.007488064615754411\n",
      "Training Loss: 0.007434324556379579\n",
      "Validation Loss: 0.00428047271319822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007272566471947357\n",
      "Training Loss: 0.007467852737754584\n",
      "Training Loss: 0.007416947488090955\n",
      "Validation Loss: 0.004260082946294982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007257013355847448\n",
      "Training Loss: 0.007448013216489926\n",
      "Training Loss: 0.007399947144440375\n",
      "Validation Loss: 0.004240133123357226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007241718654986471\n",
      "Training Loss: 0.007428559709805996\n",
      "Training Loss: 0.007383328177966177\n",
      "Validation Loss: 0.004220620569448625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0072267003159504385\n",
      "Training Loss: 0.007409512765007093\n",
      "Training Loss: 0.007367102428688667\n",
      "Validation Loss: 0.004201550501022028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007211977321421727\n",
      "Training Loss: 0.007390893192496151\n",
      "Training Loss: 0.007351281372248195\n",
      "Validation Loss: 0.0041829367335676475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007197570719290525\n",
      "Training Loss: 0.007372723723528906\n",
      "Training Loss: 0.007335877566947602\n",
      "Validation Loss: 0.004164796487396855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007183501031249762\n",
      "Training Loss: 0.0073550265724770724\n",
      "Training Loss: 0.007320902949431911\n",
      "Validation Loss: 0.004147149635520712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0071697863668669015\n",
      "Training Loss: 0.0073378226708155124\n",
      "Training Loss: 0.007306368262507021\n",
      "Validation Loss: 0.004130017774943472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007156442030100152\n",
      "Training Loss: 0.007321128575131297\n",
      "Training Loss: 0.007292279157554731\n",
      "Validation Loss: 0.004113419829041101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007143480246886611\n",
      "Training Loss: 0.007304956862935796\n",
      "Training Loss: 0.007278638093266636\n",
      "Validation Loss: 0.004097370496229007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007130908239632845\n",
      "Training Loss: 0.007289314913796261\n",
      "Training Loss: 0.007265443209907971\n",
      "Validation Loss: 0.004081881540994882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007118727779015899\n",
      "Training Loss: 0.007274204039713367\n",
      "Training Loss: 0.007252687568543479\n",
      "Validation Loss: 0.0040669603969148375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00710693676606752\n",
      "Training Loss: 0.007259621848352254\n",
      "Training Loss: 0.00724036120052915\n",
      "Validation Loss: 0.004052607389690166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007095529065700248\n",
      "Training Loss: 0.007245558182476088\n",
      "Training Loss: 0.007228448446840048\n",
      "Validation Loss: 0.004038822511472645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007084492625435815\n",
      "Training Loss: 0.00723200042033568\n",
      "Training Loss: 0.007216932120500132\n",
      "Validation Loss: 0.004025594717195111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0070738154789432885\n",
      "Training Loss: 0.007218930933158845\n",
      "Training Loss: 0.007205792113090866\n",
      "Validation Loss: 0.004012913798934288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007063480057986453\n",
      "Training Loss: 0.00720632902928628\n",
      "Training Loss: 0.007195006932015531\n",
      "Validation Loss: 0.00400076507658729\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007053469368256629\n",
      "Training Loss: 0.007194172925082966\n",
      "Training Loss: 0.007184554362902417\n",
      "Validation Loss: 0.003989129625470116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007043763241963461\n",
      "Training Loss: 0.007182438441086561\n",
      "Training Loss: 0.007174411548767239\n",
      "Validation Loss: 0.003977990774647071\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.00703434276743792\n",
      "Training Loss: 0.007171099309343845\n",
      "Training Loss: 0.0071645554457791145\n",
      "Validation Loss: 0.003967326376430188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007025188129628077\n",
      "Training Loss: 0.007160131772980094\n",
      "Training Loss: 0.007154966331436299\n",
      "Validation Loss: 0.003957119780812371\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007016282032709569\n",
      "Training Loss: 0.007149512100731954\n",
      "Training Loss: 0.007145623383694328\n",
      "Validation Loss: 0.0039473469735363895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007007605464896188\n",
      "Training Loss: 0.007139215262141079\n",
      "Training Loss: 0.007136506086098961\n",
      "Validation Loss: 0.003937989128021042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006999140211846679\n",
      "Training Loss: 0.007129218506161123\n",
      "Training Loss: 0.007127598863444291\n",
      "Validation Loss: 0.003929022432754884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0069908719358500095\n",
      "Training Loss: 0.007119499883847311\n",
      "Training Loss: 0.007118884337251075\n",
      "Validation Loss: 0.003920429241006378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0069827851629816\n",
      "Training Loss: 0.007110041494015605\n",
      "Training Loss: 0.007110347879352048\n",
      "Validation Loss: 0.003912189482250826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.0069748664216604086\n",
      "Training Loss: 0.007100822199136019\n",
      "Training Loss: 0.007101975548430346\n",
      "Validation Loss: 0.0039042842802016085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006967102742055431\n",
      "Training Loss: 0.0070918260270264\n",
      "Training Loss: 0.007093755236128345\n",
      "Validation Loss: 0.003896692869766207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00695948263630271\n",
      "Training Loss: 0.007083035516552627\n",
      "Training Loss: 0.007085675908601843\n",
      "Validation Loss: 0.0038893987853707893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006951995741110295\n",
      "Training Loss: 0.007074436347465962\n",
      "Training Loss: 0.0070777257886948065\n",
      "Validation Loss: 0.0038823817131957146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0069446307828184214\n",
      "Training Loss: 0.0070660142449196425\n",
      "Training Loss: 0.0070698958565481\n",
      "Validation Loss: 0.0038756245179520396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006937379511073232\n",
      "Training Loss: 0.007057756701251492\n",
      "Training Loss: 0.007062176823383197\n",
      "Validation Loss: 0.003869109636622617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006930233500897884\n",
      "Training Loss: 0.007049651682609692\n",
      "Training Loss: 0.007054560331744142\n",
      "Validation Loss: 0.0038628206075577254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006923183617182076\n",
      "Training Loss: 0.007041687428718433\n",
      "Training Loss: 0.007047037817537785\n",
      "Validation Loss: 0.003856738734979894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006916222961153835\n",
      "Training Loss: 0.0070338542538229375\n",
      "Training Loss: 0.007039602916338481\n",
      "Validation Loss: 0.0038508478175388293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006909344906453043\n",
      "Training Loss: 0.007026142053073272\n",
      "Training Loss: 0.007032247018651105\n",
      "Validation Loss: 0.0038451326715372752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006902542533352971\n",
      "Training Loss: 0.007018542455043643\n",
      "Training Loss: 0.007024965854361654\n",
      "Validation Loss: 0.0038395775652103376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00689581019920297\n",
      "Training Loss: 0.007011047195410356\n",
      "Training Loss: 0.007017750895465724\n",
      "Validation Loss: 0.0038341661010021237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006889141011051834\n",
      "Training Loss: 0.007003646934172139\n",
      "Training Loss: 0.007010597133194097\n",
      "Validation Loss: 0.0038288844895831655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006882530546281487\n",
      "Training Loss: 0.006996336575830355\n",
      "Training Loss: 0.007003498738631606\n",
      "Validation Loss: 0.003823716878849134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006875973482383415\n",
      "Training Loss: 0.006989106595283374\n",
      "Training Loss: 0.006996449662838131\n",
      "Validation Loss: 0.0038186502577527686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006869463855400682\n",
      "Training Loss: 0.006981951334746554\n",
      "Training Loss: 0.0069894451141590255\n",
      "Validation Loss: 0.0038136718729301616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006862997736316174\n",
      "Training Loss: 0.00697486428776756\n",
      "Training Loss: 0.006982480591977947\n",
      "Validation Loss: 0.003808767453694109\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006856570297386498\n",
      "Training Loss: 0.006967838600976392\n",
      "Training Loss: 0.006975549513590522\n",
      "Validation Loss: 0.0038039243735603235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006850176400039345\n",
      "Training Loss: 0.006960869488539174\n",
      "Training Loss: 0.006968647977919318\n",
      "Validation Loss: 0.003799132941280272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0068438127101399\n",
      "Training Loss: 0.006953949767630547\n",
      "Training Loss: 0.006961771083297208\n",
      "Validation Loss: 0.0037943809345532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006837474973872304\n",
      "Training Loss: 0.006947075261268765\n",
      "Training Loss: 0.006954914659727365\n",
      "Validation Loss: 0.0037896549590769107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006831159375142306\n",
      "Training Loss: 0.006940240882104262\n",
      "Training Loss: 0.006948074419633485\n",
      "Validation Loss: 0.0037849484262674044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006824861621716991\n",
      "Training Loss: 0.00693343932623975\n",
      "Training Loss: 0.006941244903136976\n",
      "Validation Loss: 0.0037802516252555874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006818577940575779\n",
      "Training Loss: 0.006926667966181413\n",
      "Training Loss: 0.006934422657941468\n",
      "Validation Loss: 0.0037755540407294137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006812305209459737\n",
      "Training Loss: 0.006919919779757038\n",
      "Training Loss: 0.006927603529184125\n",
      "Validation Loss: 0.0037708470592631048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006806039288640022\n",
      "Training Loss: 0.006913192386273295\n",
      "Training Loss: 0.006920783660607412\n",
      "Validation Loss: 0.0037661235468210968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006799778026761487\n",
      "Training Loss: 0.006906481293262914\n",
      "Training Loss: 0.0069139590725535525\n",
      "Validation Loss: 0.0037613794838046925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00679351702448912\n",
      "Training Loss: 0.006899778972147033\n",
      "Training Loss: 0.006907125759171322\n",
      "Validation Loss: 0.003756603181592367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006787253925576806\n",
      "Training Loss: 0.006893084560288116\n",
      "Training Loss: 0.00690027981530875\n",
      "Validation Loss: 0.00375179056303178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006780984621727839\n",
      "Training Loss: 0.006886392432497814\n",
      "Training Loss: 0.006893417835817673\n",
      "Validation Loss: 0.0037469348773423038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006774706983705982\n",
      "Training Loss: 0.006879698665579781\n",
      "Training Loss: 0.006886536104138941\n",
      "Validation Loss: 0.003742031839393665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006768417714629322\n",
      "Training Loss: 0.006873000403866172\n",
      "Training Loss: 0.006879631414194592\n",
      "Validation Loss: 0.00373707694953747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.0067621140589471905\n",
      "Training Loss: 0.006866292890626937\n",
      "Training Loss: 0.006872700190288014\n",
      "Validation Loss: 0.003732065145669275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.0067557929968461395\n",
      "Training Loss: 0.006859572903485969\n",
      "Training Loss: 0.006865739609347657\n",
      "Validation Loss: 0.003726991849658446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006749452409567311\n",
      "Training Loss: 0.006852837954647839\n",
      "Training Loss: 0.006858745251083747\n",
      "Validation Loss: 0.0037218553597484242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006743089338997379\n",
      "Training Loss: 0.006846083991695196\n",
      "Training Loss: 0.006851715010707266\n",
      "Validation Loss: 0.003716650277669175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006736701397458091\n",
      "Training Loss: 0.006839307916816324\n",
      "Training Loss: 0.006844646091922186\n",
      "Validation Loss: 0.003711374995842827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006730285860830918\n",
      "Training Loss: 0.0068325075262691826\n",
      "Training Loss: 0.006837534616934136\n",
      "Validation Loss: 0.0037060273507756466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.0067238412972074005\n",
      "Training Loss: 0.006825679570902139\n",
      "Training Loss: 0.00683037900715135\n",
      "Validation Loss: 0.003700602988011382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0067173654865473505\n",
      "Training Loss: 0.006818822644418105\n",
      "Training Loss: 0.006823176622274332\n",
      "Validation Loss: 0.003695102493550754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0067108568479307\n",
      "Training Loss: 0.00681193257914856\n",
      "Training Loss: 0.006815923184040003\n",
      "Validation Loss: 0.003689523422672005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006704311796929687\n",
      "Training Loss: 0.006805007574148476\n",
      "Training Loss: 0.0068086188769666475\n",
      "Validation Loss: 0.003683864535355752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006697729739244096\n",
      "Training Loss: 0.006798046343028545\n",
      "Training Loss: 0.006801260160282254\n",
      "Validation Loss: 0.003678126277642722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006691108737722971\n",
      "Training Loss: 0.006791047242004424\n",
      "Training Loss: 0.006793844941421412\n",
      "Validation Loss: 0.003672305889574162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006684447446605191\n",
      "Training Loss: 0.006784008089452982\n",
      "Training Loss: 0.006786372203496285\n",
      "Validation Loss: 0.0036664045850087084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006677743908949196\n",
      "Training Loss: 0.006776928795734421\n",
      "Training Loss: 0.006778839579201303\n",
      "Validation Loss: 0.003660421754400968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006670997445471585\n",
      "Training Loss: 0.006769804946379736\n",
      "Training Loss: 0.006771246056887321\n",
      "Validation Loss: 0.0036543564075666867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00666420656372793\n",
      "Training Loss: 0.006762638587970287\n",
      "Training Loss: 0.006763590275659226\n",
      "Validation Loss: 0.003648211529447038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006657370401662774\n",
      "Training Loss: 0.006755428009200841\n",
      "Training Loss: 0.006755870737251825\n",
      "Validation Loss: 0.0036419856498080693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006650488111772574\n",
      "Training Loss: 0.006748172567458823\n",
      "Training Loss: 0.006748086922452785\n",
      "Validation Loss: 0.003635681444894146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006643559618387371\n",
      "Training Loss: 0.006740870730718598\n",
      "Training Loss: 0.006740238761412911\n",
      "Validation Loss: 0.0036293002044300686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006636583370273001\n",
      "Training Loss: 0.006733523549046367\n",
      "Training Loss: 0.0067323245719308035\n",
      "Validation Loss: 0.0036228425706621636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006629558568820357\n",
      "Training Loss: 0.006726130839670077\n",
      "Training Loss: 0.006724345400580205\n",
      "Validation Loss: 0.003616308971318636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006622486251872033\n",
      "Training Loss: 0.006718692963477224\n",
      "Training Loss: 0.0067163007351337\n",
      "Validation Loss: 0.0036097042095125393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006615365830948576\n",
      "Training Loss: 0.0067112099460791795\n",
      "Training Loss: 0.006708191450452432\n",
      "Validation Loss: 0.0036030280170962214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006608196229790337\n",
      "Training Loss: 0.006703682265942916\n",
      "Training Loss: 0.006700016626273282\n",
      "Validation Loss: 0.0035962846648115456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006600978901260533\n",
      "Training Loss: 0.0066961112862918525\n",
      "Training Loss: 0.006691778339445591\n",
      "Validation Loss: 0.0035894739263680545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006593714656191878\n",
      "Training Loss: 0.006688498024595901\n",
      "Training Loss: 0.00668347793223802\n",
      "Validation Loss: 0.0035826028193859908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0065864032320678235\n",
      "Training Loss: 0.006680844577495008\n",
      "Training Loss: 0.006675116714905016\n",
      "Validation Loss: 0.0035756730783228457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.0065790456079412255\n",
      "Training Loss: 0.006673151449067518\n",
      "Training Loss: 0.006666695307940245\n",
      "Validation Loss: 0.0035686870903467362\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006571642690105363\n",
      "Training Loss: 0.006665419767377898\n",
      "Training Loss: 0.006658215814968571\n",
      "Validation Loss: 0.0035616452478688587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006564194621751085\n",
      "Training Loss: 0.006657652074936777\n",
      "Training Loss: 0.006649680137634277\n",
      "Validation Loss: 0.0035545550707957885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006556704086833633\n",
      "Training Loss: 0.006649851652327925\n",
      "Training Loss: 0.006641092101344839\n",
      "Validation Loss: 0.003547417525767108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006549171386868693\n",
      "Training Loss: 0.006642018461134285\n",
      "Training Loss: 0.006632451515179128\n",
      "Validation Loss: 0.003540237425052132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006541597312898375\n",
      "Training Loss: 0.006634156284853816\n",
      "Training Loss: 0.0066237626323709265\n",
      "Validation Loss: 0.003533017344176351\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006533984381239861\n",
      "Training Loss: 0.006626265440136194\n",
      "Training Loss: 0.006615027601365\n",
      "Validation Loss: 0.003525759154941175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.00652633290621452\n",
      "Training Loss: 0.006618350557982921\n",
      "Training Loss: 0.006606249754549935\n",
      "Validation Loss: 0.0035184701810475815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006518645378528163\n",
      "Training Loss: 0.006610413545276969\n",
      "Training Loss: 0.006597431420814246\n",
      "Validation Loss: 0.0035111516873676625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006510923003079369\n",
      "Training Loss: 0.006602455379907042\n",
      "Training Loss: 0.006588576714275405\n",
      "Validation Loss: 0.003503807379571156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006503167822374962\n",
      "Training Loss: 0.006594480341300368\n",
      "Training Loss: 0.0065796874603256585\n",
      "Validation Loss: 0.0034964388181465897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006495381515123882\n",
      "Training Loss: 0.006586490544723347\n",
      "Training Loss: 0.006570768472738564\n",
      "Validation Loss: 0.0034890517401456665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006487565680290572\n",
      "Training Loss: 0.00657848910195753\n",
      "Training Loss: 0.006561822370858863\n",
      "Validation Loss: 0.00348164830906212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006479722064686939\n",
      "Training Loss: 0.006570476931519806\n",
      "Training Loss: 0.006552850989392027\n",
      "Validation Loss: 0.003474228650467533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006471851281821728\n",
      "Training Loss: 0.006562456749379635\n",
      "Training Loss: 0.00654385945701506\n",
      "Validation Loss: 0.0034667981129265233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006463956581428647\n",
      "Training Loss: 0.006554430642863735\n",
      "Training Loss: 0.006534849933814257\n",
      "Validation Loss: 0.0034593574668730746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006456038624746725\n",
      "Training Loss: 0.006546402286039666\n",
      "Training Loss: 0.006525825842400082\n",
      "Validation Loss: 0.0034519116030587407\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006448099192348309\n",
      "Training Loss: 0.006538371323840692\n",
      "Training Loss: 0.006516790120513178\n",
      "Validation Loss: 0.00344445700809527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006440139435580932\n",
      "Training Loss: 0.006530340788885951\n",
      "Training Loss: 0.006507745262351819\n",
      "Validation Loss: 0.0034370016204611806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006432161423144862\n",
      "Training Loss: 0.006522312508895994\n",
      "Training Loss: 0.006498694946640171\n",
      "Validation Loss: 0.003429542018330834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006424165389616974\n",
      "Training Loss: 0.0065142861462663855\n",
      "Training Loss: 0.006489639872452244\n",
      "Validation Loss: 0.0034220797922776152\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006416153321624734\n",
      "Training Loss: 0.006506265649804845\n",
      "Training Loss: 0.0064805843133945015\n",
      "Validation Loss: 0.003414617683947756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006408126465976239\n",
      "Training Loss: 0.00649824931868352\n",
      "Training Loss: 0.006471529142581858\n",
      "Validation Loss: 0.0034071538058433977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0064000849012518304\n",
      "Training Loss: 0.0064902392320800575\n",
      "Training Loss: 0.006462476952583529\n",
      "Validation Loss: 0.0033996905006593867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006392029795679263\n",
      "Training Loss: 0.006482236963929609\n",
      "Training Loss: 0.006453429569955915\n",
      "Validation Loss: 0.003392227438770318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006383962102700025\n",
      "Training Loss: 0.006474241234827787\n",
      "Training Loss: 0.006444388285162858\n",
      "Validation Loss: 0.0033847644710599373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006375882512656972\n",
      "Training Loss: 0.006466252647805959\n",
      "Training Loss: 0.006435355404391885\n",
      "Validation Loss: 0.003377300816629961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006367790775839239\n",
      "Training Loss: 0.006458272981690243\n",
      "Training Loss: 0.006426331639522687\n",
      "Validation Loss: 0.0033698359901985424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006359688222291879\n",
      "Training Loss: 0.006450300373835489\n",
      "Training Loss: 0.006417317350860685\n",
      "Validation Loss: 0.003362369103608339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.0063515755283879115\n",
      "Training Loss: 0.006442334124585614\n",
      "Training Loss: 0.006408314289874397\n",
      "Validation Loss: 0.0033549016637183476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006343452351284213\n",
      "Training Loss: 0.006434375401586295\n",
      "Training Loss: 0.0063993226189631965\n",
      "Validation Loss: 0.003347429682322767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0063353190821362655\n",
      "Training Loss: 0.0064264234353322534\n",
      "Training Loss: 0.006390344924875535\n",
      "Validation Loss: 0.0033399549265800232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006327175930491649\n",
      "Training Loss: 0.006418477324768901\n",
      "Training Loss: 0.006381378735532053\n",
      "Validation Loss: 0.003332474790879766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.00631902277295012\n",
      "Training Loss: 0.006410536682233214\n",
      "Training Loss: 0.006372426465386525\n",
      "Validation Loss: 0.0033249883949128763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006310860376688651\n",
      "Training Loss: 0.006402599215507507\n",
      "Training Loss: 0.006363487474736758\n",
      "Validation Loss: 0.003317495671969451\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006302688276045956\n",
      "Training Loss: 0.0063946658105123785\n",
      "Training Loss: 0.006354562115157023\n",
      "Validation Loss: 0.0033099958908566264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.00629450595472008\n",
      "Training Loss: 0.006386736030108296\n",
      "Training Loss: 0.0063456499692983925\n",
      "Validation Loss: 0.003302484283778356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006286314550088719\n",
      "Training Loss: 0.006378806207794696\n",
      "Training Loss: 0.006336750189657323\n",
      "Validation Loss: 0.003294963780738246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.0062781127099879085\n",
      "Training Loss: 0.0063708770903758705\n",
      "Training Loss: 0.006327863938058727\n",
      "Validation Loss: 0.003287431042317008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.00626990090822801\n",
      "Training Loss: 0.006362945735454559\n",
      "Training Loss: 0.006318990025902167\n",
      "Validation Loss: 0.003279888228084264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.0062616793491179126\n",
      "Training Loss: 0.006355014520231635\n",
      "Training Loss: 0.00631012775877025\n",
      "Validation Loss: 0.0032723310934588985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006253446937771514\n",
      "Training Loss: 0.006347077974351123\n",
      "Training Loss: 0.006301276082522236\n",
      "Validation Loss: 0.003264758381417042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006245203798171133\n",
      "Training Loss: 0.006339137654867955\n",
      "Training Loss: 0.0062924360384931785\n",
      "Validation Loss: 0.0032571713202057427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006236950068268925\n",
      "Training Loss: 0.006331191388890147\n",
      "Training Loss: 0.006283605473581702\n",
      "Validation Loss: 0.003249566642347765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006228685061214492\n",
      "Training Loss: 0.006323238690383732\n",
      "Training Loss: 0.006274784692213871\n",
      "Validation Loss: 0.0032419463308276924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006220409258385189\n",
      "Training Loss: 0.006315276501118206\n",
      "Training Loss: 0.006265971940592863\n",
      "Validation Loss: 0.0032343092358807163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006212121826829389\n",
      "Training Loss: 0.006307306218659505\n",
      "Training Loss: 0.006257167373551056\n",
      "Validation Loss: 0.0032266521999047377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.00620382197725121\n",
      "Training Loss: 0.006299325150903315\n",
      "Training Loss: 0.006248369223321788\n",
      "Validation Loss: 0.0032189749168190225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006195510335383006\n",
      "Training Loss: 0.0062913319969084116\n",
      "Training Loss: 0.0062395776645280425\n",
      "Validation Loss: 0.0032112792885098398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006187186009483412\n",
      "Training Loss: 0.006283325449912809\n",
      "Training Loss: 0.006230791105772369\n",
      "Validation Loss: 0.0032035620370356554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006178849371499382\n",
      "Training Loss: 0.006275304505252279\n",
      "Training Loss: 0.0062220071320189165\n",
      "Validation Loss: 0.0031958219197610123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.0061704989051213485\n",
      "Training Loss: 0.006267267658258789\n",
      "Training Loss: 0.006213226870750077\n",
      "Validation Loss: 0.0031880610870992704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006162135312333703\n",
      "Training Loss: 0.0062592145707458255\n",
      "Training Loss: 0.006204448112403043\n",
      "Validation Loss: 0.003180275522067808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006153757891152054\n",
      "Training Loss: 0.006251141662360169\n",
      "Training Loss: 0.006195669697481207\n",
      "Validation Loss: 0.0031724652691398946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006145365915144794\n",
      "Training Loss: 0.00624304981844034\n",
      "Training Loss: 0.006186890111421235\n",
      "Validation Loss: 0.0031646312557139927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006136958873830736\n",
      "Training Loss: 0.0062349362822715195\n",
      "Training Loss: 0.006178108389140107\n",
      "Validation Loss: 0.0031567727767579843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006128535580355674\n",
      "Training Loss: 0.006226801395532675\n",
      "Training Loss: 0.006169324245420284\n",
      "Validation Loss: 0.003148886831634249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006120096804806963\n",
      "Training Loss: 0.006218642980093137\n",
      "Training Loss: 0.0061605359852546825\n",
      "Validation Loss: 0.0031409756793232446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0061116422561462965\n",
      "Training Loss: 0.006210460495203733\n",
      "Training Loss: 0.006151741521898657\n",
      "Validation Loss: 0.0031330382053771717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006103170771384611\n",
      "Training Loss: 0.006202251721406355\n",
      "Training Loss: 0.006142940816935152\n",
      "Validation Loss: 0.0031250722567665945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006094681653194129\n",
      "Training Loss: 0.00619401391420979\n",
      "Training Loss: 0.006134131076396443\n",
      "Validation Loss: 0.0031170772566470537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.0060861739318352195\n",
      "Training Loss: 0.006185749382711947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [13:45<20:36, 206.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006125311107025482\n",
      "Validation Loss: 0.003109052267155788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5368938940763474\n",
      "Training Loss: 0.4050438951700926\n",
      "Training Loss: 0.2938531631976366\n",
      "Validation Loss: 0.16777303773030805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.14279031090438365\n",
      "Training Loss: 0.08994586810469628\n",
      "Training Loss: 0.0685381823219359\n",
      "Validation Loss: 0.058269427105616986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05970649963244796\n",
      "Training Loss: 0.05905788464471698\n",
      "Training Loss: 0.05771952027454972\n",
      "Validation Loss: 0.05510459944940685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05460166754201055\n",
      "Training Loss: 0.05403636272996664\n",
      "Training Loss: 0.05234083712100983\n",
      "Validation Loss: 0.04986825083078963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04865445770323276\n",
      "Training Loss: 0.04805792331695557\n",
      "Training Loss: 0.04603573780506849\n",
      "Validation Loss: 0.04368884597768944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.04185788088478148\n",
      "Training Loss: 0.04135416628792882\n",
      "Training Loss: 0.0391024209279567\n",
      "Validation Loss: 0.036864468262771545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03468672395683825\n",
      "Training Loss: 0.03442852236330509\n",
      "Training Loss: 0.03213760046754032\n",
      "Validation Loss: 0.02997096399828959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.02789088634774089\n",
      "Training Loss: 0.027978990436531605\n",
      "Training Loss: 0.025883176517672836\n",
      "Validation Loss: 0.023739637430296855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.02219410696066916\n",
      "Training Loss: 0.022617858089506625\n",
      "Training Loss: 0.020888612070120872\n",
      "Validation Loss: 0.018727969597983226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.017939099138602616\n",
      "Training Loss: 0.018570248475298284\n",
      "Training Loss: 0.017226936114020645\n",
      "Validation Loss: 0.014977161505709538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01497285663150251\n",
      "Training Loss: 0.015638635861687362\n",
      "Training Loss: 0.014665091009810567\n",
      "Validation Loss: 0.012332992099769664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.01305931072216481\n",
      "Training Loss: 0.013707178174518048\n",
      "Training Loss: 0.013102939375676215\n",
      "Validation Loss: 0.01075612560301768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.01195869394345209\n",
      "Training Loss: 0.012565754076931626\n",
      "Training Loss: 0.012164103763643653\n",
      "Validation Loss: 0.009781459623717525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.011207946992944926\n",
      "Training Loss: 0.01177683908957988\n",
      "Training Loss: 0.011463652551174163\n",
      "Validation Loss: 0.009035306663534949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010600899916607887\n",
      "Training Loss: 0.011140352248912678\n",
      "Training Loss: 0.010877918133046479\n",
      "Validation Loss: 0.008395777832130703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010079192711273208\n",
      "Training Loss: 0.010590028573060408\n",
      "Training Loss: 0.010364146464271471\n",
      "Validation Loss: 0.0078239849522668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009619000966195017\n",
      "Training Loss: 0.010101899903966115\n",
      "Training Loss: 0.009906250342028215\n",
      "Validation Loss: 0.007309400476515293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009213417955907062\n",
      "Training Loss: 0.009670703862793744\n",
      "Training Loss: 0.009502154553774744\n",
      "Validation Loss: 0.00685362523589074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008863817552337424\n",
      "Training Loss: 0.009298924139002337\n",
      "Training Loss: 0.009154960880987346\n",
      "Validation Loss: 0.006460805282289727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008572154840221629\n",
      "Training Loss: 0.008988397545181215\n",
      "Training Loss: 0.008865765559021384\n",
      "Validation Loss: 0.006131159615169248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008336123968474567\n",
      "Training Loss: 0.008735878570005297\n",
      "Training Loss: 0.008630651551065967\n",
      "Validation Loss: 0.005859269148387601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008148824353702367\n",
      "Training Loss: 0.008533510238630698\n",
      "Training Loss: 0.0084418944013305\n",
      "Validation Loss: 0.0056362465426869944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008001205975888296\n",
      "Training Loss: 0.008371629727771506\n",
      "Training Loss: 0.00829058073577471\n",
      "Validation Loss: 0.005452611660218557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007884413794381545\n",
      "Training Loss: 0.008241077209822834\n",
      "Training Loss: 0.008168442134046928\n",
      "Validation Loss: 0.005299980859429146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0077909379242919385\n",
      "Training Loss: 0.008134231597650796\n",
      "Training Loss: 0.008068594981450588\n",
      "Validation Loss: 0.005171584984381798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007714849300682545\n",
      "Training Loss: 0.008045159911271185\n",
      "Training Loss: 0.007985610890900717\n",
      "Validation Loss: 0.00506217960723456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007651637019589544\n",
      "Training Loss: 0.007969401852460579\n",
      "Training Loss: 0.007915341035695746\n",
      "Validation Loss: 0.004967766123290142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007597939950646833\n",
      "Training Loss: 0.007903670036466793\n",
      "Training Loss: 0.007854668505024165\n",
      "Validation Loss: 0.004885304945500128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007551296993624419\n",
      "Training Loss: 0.007845566951436922\n",
      "Training Loss: 0.007801287295296788\n",
      "Validation Loss: 0.004812478948531024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007509923853212967\n",
      "Training Loss: 0.007793354119639844\n",
      "Training Loss: 0.007753503535641357\n",
      "Validation Loss: 0.004747504200995638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007472536232089624\n",
      "Training Loss: 0.00774576383526437\n",
      "Training Loss: 0.007710071720648557\n",
      "Validation Loss: 0.004688987501875989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007438208591192961\n",
      "Training Loss: 0.007701872990000993\n",
      "Training Loss: 0.007670075764181093\n",
      "Validation Loss: 0.004635842133763383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007406271081417799\n",
      "Training Loss: 0.007660995170008391\n",
      "Training Loss: 0.007632833903189748\n",
      "Validation Loss: 0.004587195676311934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007376233711838722\n",
      "Training Loss: 0.007622613892890513\n",
      "Training Loss: 0.007597833587788046\n",
      "Validation Loss: 0.004542348595084936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0073477318801451474\n",
      "Training Loss: 0.0075863373745232825\n",
      "Training Loss: 0.007564685547258705\n",
      "Validation Loss: 0.004500737693683987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007320490878773853\n",
      "Training Loss: 0.007551857953658327\n",
      "Training Loss: 0.007533088247291744\n",
      "Validation Loss: 0.004461905754202705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00729430397041142\n",
      "Training Loss: 0.00751893813489005\n",
      "Training Loss: 0.007502811761805788\n",
      "Validation Loss: 0.004425483959821168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007269012023461982\n",
      "Training Loss: 0.007487388807348907\n",
      "Training Loss: 0.00747367552598007\n",
      "Validation Loss: 0.004391169588845433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0072444929287303235\n",
      "Training Loss: 0.007457060622982681\n",
      "Training Loss: 0.007445537718012929\n",
      "Validation Loss: 0.004358717015410742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007220654134871438\n",
      "Training Loss: 0.007427833307301626\n",
      "Training Loss: 0.007418290534988045\n",
      "Validation Loss: 0.004327924727211089\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007197425155900419\n",
      "Training Loss: 0.0073996150936000045\n",
      "Training Loss: 0.0073918508796487\n",
      "Validation Loss: 0.00429863316723763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007174755047308281\n",
      "Training Loss: 0.007372330280486494\n",
      "Training Loss: 0.007366154529154301\n",
      "Validation Loss: 0.004270704833298838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007152605894953012\n",
      "Training Loss: 0.007345920284278691\n",
      "Training Loss: 0.0073411533783655615\n",
      "Validation Loss: 0.004244034275349774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007130952170118689\n",
      "Training Loss: 0.007320339030120522\n",
      "Training Loss: 0.007316811663331464\n",
      "Validation Loss: 0.0042185266201352975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007109777068253606\n",
      "Training Loss: 0.007295548608526587\n",
      "Training Loss: 0.007293101864634082\n",
      "Validation Loss: 0.004194115013867784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007089069349458441\n",
      "Training Loss: 0.007271519501227885\n",
      "Training Loss: 0.007270004836609587\n",
      "Validation Loss: 0.004170728537379607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007068824603920803\n",
      "Training Loss: 0.00724822765099816\n",
      "Training Loss: 0.007247505048289895\n",
      "Validation Loss: 0.004148317252421815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.00704903964069672\n",
      "Training Loss: 0.007225650933105498\n",
      "Training Loss: 0.00722558991634287\n",
      "Validation Loss: 0.0041268341402847615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007029714558739215\n",
      "Training Loss: 0.0072037700784858315\n",
      "Training Loss: 0.007204250441864133\n",
      "Validation Loss: 0.004106231884026293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007010850473307073\n",
      "Training Loss: 0.007182567957788706\n",
      "Training Loss: 0.007183477248763666\n",
      "Validation Loss: 0.0040864796518986475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006992447538068518\n",
      "Training Loss: 0.007162028452148661\n",
      "Training Loss: 0.007163262465037405\n",
      "Validation Loss: 0.004067539536980179\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.0069745073362719266\n",
      "Training Loss: 0.007142132790759206\n",
      "Training Loss: 0.007143595373490825\n",
      "Validation Loss: 0.004049380990059188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006957028732867912\n",
      "Training Loss: 0.0071228643390350045\n",
      "Training Loss: 0.007124468294205144\n",
      "Validation Loss: 0.004031970016553663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006940010117832571\n",
      "Training Loss: 0.007104204688221216\n",
      "Training Loss: 0.00710586896748282\n",
      "Validation Loss: 0.004015276403417497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0069234474701806905\n",
      "Training Loss: 0.007086134881246835\n",
      "Training Loss: 0.0070877873012796045\n",
      "Validation Loss: 0.003999271097833689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006907336245058104\n",
      "Training Loss: 0.00706863623461686\n",
      "Training Loss: 0.007070209126686678\n",
      "Validation Loss: 0.003983926183669671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006891669970937073\n",
      "Training Loss: 0.007051686737686396\n",
      "Training Loss: 0.007053121192147955\n",
      "Validation Loss: 0.003969212012951461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006876439850311726\n",
      "Training Loss: 0.007035266580060124\n",
      "Training Loss: 0.007036508116871118\n",
      "Validation Loss: 0.003955098020770912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006861636504763738\n",
      "Training Loss: 0.007019353043287993\n",
      "Training Loss: 0.0070203544409014286\n",
      "Validation Loss: 0.003941559346570644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006847247414989397\n",
      "Training Loss: 0.007003924753516913\n",
      "Training Loss: 0.007004642623942345\n",
      "Validation Loss: 0.003928566318832003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006833260246785358\n",
      "Training Loss: 0.006988956688437611\n",
      "Training Loss: 0.006989354741526768\n",
      "Validation Loss: 0.0039160875158823945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0068196614505723115\n",
      "Training Loss: 0.006974428516114131\n",
      "Training Loss: 0.0069744731072569266\n",
      "Validation Loss: 0.0039040982432851797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006806435977341607\n",
      "Training Loss: 0.006960315721808001\n",
      "Training Loss: 0.006959979348466732\n",
      "Validation Loss: 0.003892572451477054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006793567908462137\n",
      "Training Loss: 0.006946594519540668\n",
      "Training Loss: 0.006945852584321983\n",
      "Validation Loss: 0.003881479805764439\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.0067810403904877605\n",
      "Training Loss: 0.0069332425494212655\n",
      "Training Loss: 0.006932073860662058\n",
      "Validation Loss: 0.0038707938249317115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006768837128765881\n",
      "Training Loss: 0.006920235877623781\n",
      "Training Loss: 0.006918623814708553\n",
      "Validation Loss: 0.0038604875830305593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006756940244231373\n",
      "Training Loss: 0.006907553399214521\n",
      "Training Loss: 0.006905482829315588\n",
      "Validation Loss: 0.0038505352201630896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0067453325306996706\n",
      "Training Loss: 0.006895171097712591\n",
      "Training Loss: 0.006892630773363635\n",
      "Validation Loss: 0.0038409105088729203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0067339969903696326\n",
      "Training Loss: 0.006883068394381553\n",
      "Training Loss: 0.006880049241590314\n",
      "Validation Loss: 0.0038315888227413546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00672291568480432\n",
      "Training Loss: 0.006871223017806187\n",
      "Training Loss: 0.0068677183863474055\n",
      "Validation Loss: 0.003822545793033048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006712071473011747\n",
      "Training Loss: 0.006859617454465478\n",
      "Training Loss: 0.006855620459537022\n",
      "Validation Loss: 0.003813756628516601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006701448000967503\n",
      "Training Loss: 0.0068482293689157816\n",
      "Training Loss: 0.006843737256713211\n",
      "Validation Loss: 0.0038052016131454305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006691028152126819\n",
      "Training Loss: 0.006837040971731767\n",
      "Training Loss: 0.006832051180535928\n",
      "Validation Loss: 0.0037968574795516187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0066807972418610004\n",
      "Training Loss: 0.00682603387045674\n",
      "Training Loss: 0.0068205448245862495\n",
      "Validation Loss: 0.0037887007942465083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00667073906515725\n",
      "Training Loss: 0.006815191194182262\n",
      "Training Loss: 0.006809203167795204\n",
      "Validation Loss: 0.0037807135050069917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00666083860443905\n",
      "Training Loss: 0.0068044968403410165\n",
      "Training Loss: 0.006798008694895543\n",
      "Validation Loss: 0.0037728755086074385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0066510825278237465\n",
      "Training Loss: 0.006793935206951573\n",
      "Training Loss: 0.0067869487113785\n",
      "Validation Loss: 0.003765168610248673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006641456610523165\n",
      "Training Loss: 0.00678349184221588\n",
      "Training Loss: 0.006776007821317762\n",
      "Validation Loss: 0.0037575738930949168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00663194834953174\n",
      "Training Loss: 0.006773152821697295\n",
      "Training Loss: 0.006765172421582974\n",
      "Validation Loss: 0.0037500779876966824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006622545655118301\n",
      "Training Loss: 0.006762904716888443\n",
      "Training Loss: 0.006754430418950506\n",
      "Validation Loss: 0.0037426607594354434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006613236515549943\n",
      "Training Loss: 0.0067527364729903635\n",
      "Training Loss: 0.006743768918677233\n",
      "Validation Loss: 0.003735309755795876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006604010357987136\n",
      "Training Loss: 0.00674263630528003\n",
      "Training Loss: 0.00673317723965738\n",
      "Validation Loss: 0.003728009145602249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006594856329029426\n",
      "Training Loss: 0.006732593299821019\n",
      "Training Loss: 0.00672264385910239\n",
      "Validation Loss: 0.0037207453880521856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0065857648313976825\n",
      "Training Loss: 0.006722596003673971\n",
      "Training Loss: 0.006712158612790517\n",
      "Validation Loss: 0.003713506793216122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006576726854545995\n",
      "Training Loss: 0.0067126363539136945\n",
      "Training Loss: 0.006701712050125934\n",
      "Validation Loss: 0.0037062817444145847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006567732994444669\n",
      "Training Loss: 0.006702705272473395\n",
      "Training Loss: 0.006691294847405516\n",
      "Validation Loss: 0.003699054900985839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006558775558369234\n",
      "Training Loss: 0.006692793483380228\n",
      "Training Loss: 0.006680897332844324\n",
      "Validation Loss: 0.0036918189326887218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0065498459443915635\n",
      "Training Loss: 0.006682893065735698\n",
      "Training Loss: 0.006670512084965594\n",
      "Validation Loss: 0.0036845604661496336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006540939046535641\n",
      "Training Loss: 0.006672997790155932\n",
      "Training Loss: 0.0066601317125605415\n",
      "Validation Loss: 0.0036772706825809365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006532045666826889\n",
      "Training Loss: 0.006663098594872281\n",
      "Training Loss: 0.0066497487935703245\n",
      "Validation Loss: 0.0036699423001388485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006523160778451711\n",
      "Training Loss: 0.006653190371580422\n",
      "Training Loss: 0.006639356318628415\n",
      "Validation Loss: 0.003662563723072493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006514277706155553\n",
      "Training Loss: 0.006643266116734594\n",
      "Training Loss: 0.00662894815672189\n",
      "Validation Loss: 0.003655126705514581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00650539064896293\n",
      "Training Loss: 0.006633319618413225\n",
      "Training Loss: 0.006618517701863311\n",
      "Validation Loss: 0.0036476238335095596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006496494573075324\n",
      "Training Loss: 0.006623346317792311\n",
      "Training Loss: 0.006608059343416244\n",
      "Validation Loss: 0.0036400461470017607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.0064875838300213215\n",
      "Training Loss: 0.00661333939875476\n",
      "Training Loss: 0.006597568692523054\n",
      "Validation Loss: 0.0036323882882703055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006478654618840665\n",
      "Training Loss: 0.006603295566746965\n",
      "Training Loss: 0.00658703959255945\n",
      "Validation Loss: 0.0036246427374086185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006469703355105594\n",
      "Training Loss: 0.006593209956772626\n",
      "Training Loss: 0.006576469125575386\n",
      "Validation Loss: 0.003616805612161923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006460724436910823\n",
      "Training Loss: 0.00658307762700133\n",
      "Training Loss: 0.006565851454506628\n",
      "Validation Loss: 0.0036088673533934555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006451713683782145\n",
      "Training Loss: 0.006572894166456535\n",
      "Training Loss: 0.00655518242972903\n",
      "Validation Loss: 0.0036008223234623503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.0064426689432002604\n",
      "Training Loss: 0.006562656231690198\n",
      "Training Loss: 0.006544459411525167\n",
      "Validation Loss: 0.003592666014871989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00643358611385338\n",
      "Training Loss: 0.006552360521163791\n",
      "Training Loss: 0.006533678198466077\n",
      "Validation Loss: 0.0035843935734958627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006424461634596809\n",
      "Training Loss: 0.0065420034481212495\n",
      "Training Loss: 0.006522835636860691\n",
      "Validation Loss: 0.003576001895361402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006415293522877619\n",
      "Training Loss: 0.006531581615563482\n",
      "Training Loss: 0.0065119291219161825\n",
      "Validation Loss: 0.0035674833271422245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006406078869476914\n",
      "Training Loss: 0.0065210930036846545\n",
      "Training Loss: 0.0065009564202046025\n",
      "Validation Loss: 0.0035588351546608833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0063968162285164\n",
      "Training Loss: 0.0065105343784671275\n",
      "Training Loss: 0.006489914131816476\n",
      "Validation Loss: 0.0035500542216233156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006387501829303801\n",
      "Training Loss: 0.006499903401127085\n",
      "Training Loss: 0.006478800398763269\n",
      "Validation Loss: 0.0035411389047552027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006378134022234008\n",
      "Training Loss: 0.006489199022762477\n",
      "Training Loss: 0.006467613467830233\n",
      "Validation Loss: 0.0035320837809337995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00636871227179654\n",
      "Training Loss: 0.006478418203769252\n",
      "Training Loss: 0.006456351590459235\n",
      "Validation Loss: 0.0035228847533862076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006359233356779442\n",
      "Training Loss: 0.006467560305027291\n",
      "Training Loss: 0.006445013681659475\n",
      "Validation Loss: 0.003513541172017877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006349695603130385\n",
      "Training Loss: 0.006456622624536976\n",
      "Training Loss: 0.006433597502764315\n",
      "Validation Loss: 0.0035040503501201446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006340099509106949\n",
      "Training Loss: 0.006445605324115604\n",
      "Training Loss: 0.00642210211546626\n",
      "Validation Loss: 0.0034944084472954273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006330442527541891\n",
      "Training Loss: 0.006434506498044357\n",
      "Training Loss: 0.006410527520347387\n",
      "Validation Loss: 0.003484617990671835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006320724905235693\n",
      "Training Loss: 0.006423324738861993\n",
      "Training Loss: 0.006398872382706031\n",
      "Validation Loss: 0.003474674341949017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006310944295255467\n",
      "Training Loss: 0.006412059469148516\n",
      "Training Loss: 0.006387135733966716\n",
      "Validation Loss: 0.003464577391251838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006301100708078593\n",
      "Training Loss: 0.006400710152229294\n",
      "Training Loss: 0.006375316146877594\n",
      "Validation Loss: 0.0034543243158357533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006291192641947418\n",
      "Training Loss: 0.006389276339905337\n",
      "Training Loss: 0.006363414622610435\n",
      "Validation Loss: 0.003443915039834598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006281221391400322\n",
      "Training Loss: 0.006377756863366812\n",
      "Training Loss: 0.006351429884671233\n",
      "Validation Loss: 0.003433345444238839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006271184239303693\n",
      "Training Loss: 0.006366151121328585\n",
      "Training Loss: 0.006339361896389164\n",
      "Validation Loss: 0.003422619042436728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0062610809493344275\n",
      "Training Loss: 0.006354458865243942\n",
      "Training Loss: 0.006327209518058225\n",
      "Validation Loss: 0.0034117300136621747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006250911940587685\n",
      "Training Loss: 0.006342678962973878\n",
      "Training Loss: 0.0063149736024206505\n",
      "Validation Loss: 0.0034006802558773355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006240676242159679\n",
      "Training Loss: 0.006330811204388737\n",
      "Training Loss: 0.006302652873564511\n",
      "Validation Loss: 0.0033894684492725502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0062303720950149\n",
      "Training Loss: 0.006318853314733133\n",
      "Training Loss: 0.0062902466097148136\n",
      "Validation Loss: 0.0033780901033556862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006220000577159226\n",
      "Training Loss: 0.00630680684640538\n",
      "Training Loss: 0.006277756042545661\n",
      "Validation Loss: 0.003366546281561088\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006209559648996219\n",
      "Training Loss: 0.006294668276095763\n",
      "Training Loss: 0.006265179404290393\n",
      "Validation Loss: 0.0033548350663060384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0061990495712962\n",
      "Training Loss: 0.006282437579939142\n",
      "Training Loss: 0.006252516492386348\n",
      "Validation Loss: 0.0033429549284949064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.00618846828234382\n",
      "Training Loss: 0.006270112654892728\n",
      "Training Loss: 0.006239766505314037\n",
      "Validation Loss: 0.003330903211503886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006177816587733104\n",
      "Training Loss: 0.006257692991057411\n",
      "Training Loss: 0.006226929928525351\n",
      "Validation Loss: 0.0033186779205760593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.00616709184483625\n",
      "Training Loss: 0.006245175617514178\n",
      "Training Loss: 0.00621400480857119\n",
      "Validation Loss: 0.0033062738405666156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006156292293453589\n",
      "Training Loss: 0.006232558107585646\n",
      "Training Loss: 0.006200988880591467\n",
      "Validation Loss: 0.0032936894541522595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006145416840445251\n",
      "Training Loss: 0.006219837200478651\n",
      "Training Loss: 0.006187882316298783\n",
      "Validation Loss: 0.0032809210033417583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006134463128400967\n",
      "Training Loss: 0.006207010165089741\n",
      "Training Loss: 0.006174683063291013\n",
      "Validation Loss: 0.003267961576465894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006123428805731237\n",
      "Training Loss: 0.006194073809310794\n",
      "Training Loss: 0.00616138941491954\n",
      "Validation Loss: 0.0032548094809243685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006112311175093055\n",
      "Training Loss: 0.006181022529490292\n",
      "Training Loss: 0.006147998061496764\n",
      "Validation Loss: 0.0032414565624125052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0061011059791781005\n",
      "Training Loss: 0.006167852173093707\n",
      "Training Loss: 0.006134506598464214\n",
      "Validation Loss: 0.0032278960178281817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006089809754630551\n",
      "Training Loss: 0.006154555651592091\n",
      "Training Loss: 0.006120911993202753\n",
      "Validation Loss: 0.0032141224776781846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0060784180893097076\n",
      "Training Loss: 0.006141127075534314\n",
      "Training Loss: 0.006107209660694934\n",
      "Validation Loss: 0.003200122971464409\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006066925643244759\n",
      "Training Loss: 0.006127560858731158\n",
      "Training Loss: 0.006093395728967153\n",
      "Validation Loss: 0.0031858920485953266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006055326114874333\n",
      "Training Loss: 0.006113845139043406\n",
      "Training Loss: 0.00607946494477801\n",
      "Validation Loss: 0.0031714182480479056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006043612675275653\n",
      "Training Loss: 0.006099973203381523\n",
      "Training Loss: 0.006065412529278546\n",
      "Validation Loss: 0.003156690820371418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.0060317766806110736\n",
      "Training Loss: 0.006085934384609573\n",
      "Training Loss: 0.006051231009187177\n",
      "Validation Loss: 0.003141699159999242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006019811399746686\n",
      "Training Loss: 0.006071716762380675\n",
      "Training Loss: 0.006036915250006132\n",
      "Validation Loss: 0.0031264303382904676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006007705468218774\n",
      "Training Loss: 0.006057310224277899\n",
      "Training Loss: 0.006022456566570327\n",
      "Validation Loss: 0.00311087217741761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.005995450225891545\n",
      "Training Loss: 0.006042700965772383\n",
      "Training Loss: 0.006007847712608054\n",
      "Validation Loss: 0.0030950099384161028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005983033981174231\n",
      "Training Loss: 0.0060278768191346895\n",
      "Training Loss: 0.005993081278284081\n",
      "Validation Loss: 0.0030788353479498727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0059704457083716985\n",
      "Training Loss: 0.00601282388321124\n",
      "Training Loss: 0.005978151738527231\n",
      "Validation Loss: 0.0030623401509953683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005957675165846012\n",
      "Training Loss: 0.005997531803441234\n",
      "Training Loss: 0.005963052501901984\n",
      "Validation Loss: 0.0030455156791892447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005944711365154945\n",
      "Training Loss: 0.005981989098363556\n",
      "Training Loss: 0.005947780134156346\n",
      "Validation Loss: 0.0030283623484873706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005931545624625869\n",
      "Training Loss: 0.0059661882778164\n",
      "Training Loss: 0.005932333588134497\n",
      "Validation Loss: 0.0030108833086436217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005918171312077902\n",
      "Training Loss: 0.005950124429073184\n",
      "Training Loss: 0.005916716793435626\n",
      "Validation Loss: 0.002993094188087944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005904586401884444\n",
      "Training Loss: 0.005933800101047382\n",
      "Training Loss: 0.0059009380079805855\n",
      "Validation Loss: 0.0029750220422643456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005890791335841641\n",
      "Training Loss: 0.005917223728029057\n",
      "Training Loss: 0.005885014425148256\n",
      "Validation Loss: 0.0029567080952771258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005876796786906197\n",
      "Training Loss: 0.0059004153055138885\n",
      "Training Loss: 0.005868973642936908\n",
      "Validation Loss: 0.0029382096143083626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005862620576517656\n",
      "Training Loss: 0.005883405995555222\n",
      "Training Loss: 0.005852850960218347\n",
      "Validation Loss: 0.0029196067728897495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005848289459827356\n",
      "Training Loss: 0.005866238515009173\n",
      "Training Loss: 0.005836696412879974\n",
      "Validation Loss: 0.0029009971636860224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005833843279979192\n",
      "Training Loss: 0.005848971161758527\n",
      "Training Loss: 0.005820570132927969\n",
      "Validation Loss: 0.0028824955682803907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005819330718368292\n",
      "Training Loss: 0.005831677755340933\n",
      "Training Loss: 0.00580454581649974\n",
      "Validation Loss: 0.0028642418799566085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005804813716677018\n",
      "Training Loss: 0.005814444164279849\n",
      "Training Loss: 0.005788707145838999\n",
      "Validation Loss: 0.0028463816087106976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0057903614238603044\n",
      "Training Loss: 0.005797367313061841\n",
      "Training Loss: 0.005773141934769228\n",
      "Validation Loss: 0.0028290634836185347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005776047856197692\n",
      "Training Loss: 0.0057805474317865445\n",
      "Training Loss: 0.005757937418529764\n",
      "Validation Loss: 0.0028124292436045376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005761947839055211\n",
      "Training Loss: 0.005764080174849369\n",
      "Training Loss: 0.005743175652460195\n",
      "Validation Loss: 0.0027965989324860692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005748129582498223\n",
      "Training Loss: 0.005748057957971469\n",
      "Training Loss: 0.005728928055032156\n",
      "Validation Loss: 0.002781668309059538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.00573465445835609\n",
      "Training Loss: 0.0057325525954365734\n",
      "Training Loss: 0.005715248967171647\n",
      "Validation Loss: 0.0027676946025739393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005721568801091053\n",
      "Training Loss: 0.005717621804797091\n",
      "Training Loss: 0.00570217396307271\n",
      "Validation Loss: 0.002754699325011101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005708904537023045\n",
      "Training Loss: 0.005703300375025719\n",
      "Training Loss: 0.0056897170940646905\n",
      "Validation Loss: 0.0027426675660535693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005696676170919091\n",
      "Training Loss: 0.0056896018091356386\n",
      "Training Loss: 0.005677876900299452\n",
      "Validation Loss: 0.0027315583043428285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005684886499075219\n",
      "Training Loss: 0.005676523237489164\n",
      "Training Loss: 0.005666634207009338\n",
      "Validation Loss: 0.0027213016619089614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005673525737365708\n",
      "Training Loss: 0.005664042713469826\n",
      "Training Loss: 0.0056559589313110335\n",
      "Validation Loss: 0.0027118136496754007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.0056625762610929085\n",
      "Training Loss: 0.00565212937479373\n",
      "Training Loss: 0.005645811603171751\n",
      "Validation Loss: 0.002703007234762726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005652012839564122\n",
      "Training Loss: 0.005640747004072182\n",
      "Training Loss: 0.00563615073915571\n",
      "Validation Loss: 0.0026947942698437176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005641809621592984\n",
      "Training Loss: 0.005629853098653257\n",
      "Training Loss: 0.0056269324250752106\n",
      "Validation Loss: 0.002687090650734523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005631937618018128\n",
      "Training Loss: 0.0056194046046584845\n",
      "Training Loss: 0.005618112679221667\n",
      "Validation Loss: 0.002679816665640624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.0056223712494829665\n",
      "Training Loss: 0.005609363412368111\n",
      "Training Loss: 0.005609652645071037\n",
      "Validation Loss: 0.0026729068433698475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005613083854550496\n",
      "Training Loss: 0.005599688111688011\n",
      "Training Loss: 0.005601513955043629\n",
      "Validation Loss: 0.0026662993843907887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0056040535017382355\n",
      "Training Loss: 0.005590345623204485\n",
      "Training Loss: 0.005593663433101029\n",
      "Validation Loss: 0.002659948767696539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005595258694957011\n",
      "Training Loss: 0.005581304560764693\n",
      "Training Loss: 0.005586072745500132\n",
      "Validation Loss: 0.002653808998770677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005586681673303246\n",
      "Training Loss: 0.005572536262334325\n",
      "Training Loss: 0.005578715741867199\n",
      "Validation Loss: 0.0026478526533026707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005578306645620614\n",
      "Training Loss: 0.005564019244047813\n",
      "Training Loss: 0.005571569232852198\n",
      "Validation Loss: 0.0026420479263649897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005570119281182997\n",
      "Training Loss: 0.005555729157640599\n",
      "Training Loss: 0.0055646145646460355\n",
      "Validation Loss: 0.002636376222899037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.0055621087871259075\n",
      "Training Loss: 0.0055476481502410024\n",
      "Training Loss: 0.005557835251674987\n",
      "Validation Loss: 0.002630818470412593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0055542636301834135\n",
      "Training Loss: 0.005539759463281371\n",
      "Training Loss: 0.005551215715240687\n",
      "Validation Loss: 0.002625360699067039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005546574270701967\n",
      "Training Loss: 0.00553205055941362\n",
      "Training Loss: 0.005544743348145857\n",
      "Validation Loss: 0.0026199918637952106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005539033495588228\n",
      "Training Loss: 0.00552450701885391\n",
      "Training Loss: 0.005538408195716329\n",
      "Validation Loss: 0.00261470412422139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005531633116188459\n",
      "Training Loss: 0.005517119339783676\n",
      "Training Loss: 0.005532198988366872\n",
      "Validation Loss: 0.002609487633440602\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.00552436632278841\n",
      "Training Loss: 0.005509875811403617\n",
      "Training Loss: 0.005526107663754374\n",
      "Validation Loss: 0.0026043378211704367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005517227241070941\n",
      "Training Loss: 0.005502768239239231\n",
      "Training Loss: 0.005520125604816712\n",
      "Validation Loss: 0.002599248793394713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005510209498461336\n",
      "Training Loss: 0.005495787305990234\n",
      "Training Loss: 0.005514246862148866\n",
      "Validation Loss: 0.0025942185854413704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005503307589096948\n",
      "Training Loss: 0.005488927609403618\n",
      "Training Loss: 0.005508464555605315\n",
      "Validation Loss: 0.00258924055902099\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005496516748680733\n",
      "Training Loss: 0.005482181078405119\n",
      "Training Loss: 0.005502772441250272\n",
      "Validation Loss: 0.002584313094783365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005489831316517666\n",
      "Training Loss: 0.0054755422251764685\n",
      "Training Loss: 0.005497166062705219\n",
      "Validation Loss: 0.002579436721175574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005483247672673315\n",
      "Training Loss: 0.005469004582846537\n",
      "Training Loss: 0.005491640293621458\n",
      "Validation Loss: 0.0025746021498245803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005476760934107006\n",
      "Training Loss: 0.005462562514585443\n",
      "Training Loss: 0.0054861900146352125\n",
      "Validation Loss: 0.0025698111269602114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005470365633955226\n",
      "Training Loss: 0.005456211520940997\n",
      "Training Loss: 0.005480811371235177\n",
      "Validation Loss: 0.0025650614315350906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005464059234363958\n",
      "Training Loss: 0.005449946334119886\n",
      "Training Loss: 0.0054755000211298465\n",
      "Validation Loss: 0.0025603476744354443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005457836841815151\n",
      "Training Loss: 0.005443762486102059\n",
      "Training Loss: 0.005470252264058217\n",
      "Validation Loss: 0.0025556713769086794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005451694865478203\n",
      "Training Loss: 0.005437656242283992\n",
      "Training Loss: 0.00546506516286172\n",
      "Validation Loss: 0.0025510291537542023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005445628769812174\n",
      "Training Loss: 0.005431623010663316\n",
      "Training Loss: 0.005459934531245381\n",
      "Validation Loss: 0.0025464194497156344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005439636139781215\n",
      "Training Loss: 0.0054256600956432526\n",
      "Training Loss: 0.005454857799340971\n",
      "Validation Loss: 0.0025418408364162185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005433712977683172\n",
      "Training Loss: 0.005419762691017241\n",
      "Training Loss: 0.005449832102749496\n",
      "Validation Loss: 0.0025372924270066484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005427855717134662\n",
      "Training Loss: 0.005413928821217269\n",
      "Training Loss: 0.005444854904781095\n",
      "Validation Loss: 0.0025327712653225726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005422061266726814\n",
      "Training Loss: 0.005408154388424009\n",
      "Training Loss: 0.005439922995865345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [17:10<17:08, 205.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0025282779125120032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5228372783958912\n",
      "Training Loss: 0.4148260417580605\n",
      "Training Loss: 0.32563879929482936\n",
      "Validation Loss: 0.23658035427666782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.1956882069259882\n",
      "Training Loss: 0.1338166533783078\n",
      "Training Loss: 0.09279951483011245\n",
      "Validation Loss: 0.061206144060981404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.057128015141934156\n",
      "Training Loss: 0.04989870982244611\n",
      "Training Loss: 0.046540599251165986\n",
      "Validation Loss: 0.040758801477678706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.043054770678281784\n",
      "Training Loss: 0.0416535463090986\n",
      "Training Loss: 0.03872377648949623\n",
      "Validation Loss: 0.032959717692116676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03448385677300394\n",
      "Training Loss: 0.033112453036010264\n",
      "Training Loss: 0.030003022328019144\n",
      "Validation Loss: 0.025065354877308512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.025953360181301833\n",
      "Training Loss: 0.02548116958234459\n",
      "Training Loss: 0.023044584752060473\n",
      "Validation Loss: 0.019499776152412544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.02010522290598601\n",
      "Training Loss: 0.02064882474951446\n",
      "Training Loss: 0.01900281566660851\n",
      "Validation Loss: 0.016422253217171418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.0169998094975017\n",
      "Training Loss: 0.018104403091128915\n",
      "Training Loss: 0.016956965648569168\n",
      "Validation Loss: 0.014766691268285673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.015432336006779224\n",
      "Training Loss: 0.01673372587421909\n",
      "Training Loss: 0.01584513724781573\n",
      "Validation Loss: 0.013745627648542437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.014531017313711345\n",
      "Training Loss: 0.01586551850894466\n",
      "Training Loss: 0.01511641249526292\n",
      "Validation Loss: 0.013002243662106523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.013902233116095886\n",
      "Training Loss: 0.015206353408284485\n",
      "Training Loss: 0.014540455730166286\n",
      "Validation Loss: 0.012376764736902178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.013377668677130715\n",
      "Training Loss: 0.014619894973002374\n",
      "Training Loss: 0.014006352492142469\n",
      "Validation Loss: 0.011773793759305826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.012866889402503148\n",
      "Training Loss: 0.014023242121329531\n",
      "Training Loss: 0.013443810439202935\n",
      "Validation Loss: 0.011123243776893013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.012311885738745332\n",
      "Training Loss: 0.013364576594904065\n",
      "Training Loss: 0.012814954726491124\n",
      "Validation Loss: 0.010389571227237916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.011697536687133834\n",
      "Training Loss: 0.012646451032487675\n",
      "Training Loss: 0.012142629122827202\n",
      "Validation Loss: 0.009602741657473733\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.011072716652415692\n",
      "Training Loss: 0.011935050974134356\n",
      "Training Loss: 0.011500973565271124\n",
      "Validation Loss: 0.008840411511678876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.010507319865282624\n",
      "Training Loss: 0.011300646482268348\n",
      "Training Loss: 0.010946791406022385\n",
      "Validation Loss: 0.008165772447069541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.010035979228559882\n",
      "Training Loss: 0.010773289203643798\n",
      "Training Loss: 0.010492270961403847\n",
      "Validation Loss: 0.007602263862015993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009659100415883587\n",
      "Training Loss: 0.010351448835572229\n",
      "Training Loss: 0.010126675048377365\n",
      "Validation Loss: 0.00714610921208527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009363330237101763\n",
      "Training Loss: 0.010018860219279304\n",
      "Training Loss: 0.00983292676275596\n",
      "Validation Loss: 0.006780223805834068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00912875255336985\n",
      "Training Loss: 0.009751390472520143\n",
      "Training Loss: 0.009590145561378449\n",
      "Validation Loss: 0.006481249494938536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008933797496138141\n",
      "Training Loss: 0.009525397442048415\n",
      "Training Loss: 0.009379269847413526\n",
      "Validation Loss: 0.006227814073130237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008762160864425822\n",
      "Training Loss: 0.009324121206300334\n",
      "Training Loss: 0.009187097192043438\n",
      "Validation Loss: 0.006004519059500667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008603974867146463\n",
      "Training Loss: 0.009137334669940173\n",
      "Training Loss: 0.009005441007902846\n",
      "Validation Loss: 0.005801057210192084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008453611540608108\n",
      "Training Loss: 0.008958992297993972\n",
      "Training Loss: 0.008829421593109146\n",
      "Validation Loss: 0.005610634980911619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008308097529225051\n",
      "Training Loss: 0.008785921515664086\n",
      "Training Loss: 0.008656803090125322\n",
      "Validation Loss: 0.005429395512426586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008166774085257202\n",
      "Training Loss: 0.008617653847904876\n",
      "Training Loss: 0.008488173055229708\n",
      "Validation Loss: 0.005256616523531214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00803143808967434\n",
      "Training Loss: 0.008456494958372786\n",
      "Training Loss: 0.0083269845333416\n",
      "Validation Loss: 0.00509476945657032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007905954997986554\n",
      "Training Loss: 0.008306871709646658\n",
      "Training Loss: 0.008178519713692368\n",
      "Validation Loss: 0.004948268191930786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007794729120796547\n",
      "Training Loss: 0.00817345671239309\n",
      "Training Loss: 0.008047631052322686\n",
      "Validation Loss: 0.004821003464395913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0077006099431309845\n",
      "Training Loss: 0.00805902722175233\n",
      "Training Loss: 0.007936701261205598\n",
      "Validation Loss: 0.004714410052258061\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007623829975491389\n",
      "Training Loss: 0.007963651383761317\n",
      "Training Loss: 0.007845272865379229\n",
      "Validation Loss: 0.004627354732149521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007562532438896596\n",
      "Training Loss: 0.007885415608761832\n",
      "Training Loss: 0.007771058368962258\n",
      "Validation Loss: 0.004557232539891527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007513979785144329\n",
      "Training Loss: 0.007821606792276725\n",
      "Training Loss: 0.007711126042413525\n",
      "Validation Loss: 0.004501019116606187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00747542439494282\n",
      "Training Loss: 0.00776948343263939\n",
      "Training Loss: 0.007662607064121403\n",
      "Validation Loss: 0.004455851193444197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007444484203588218\n",
      "Training Loss: 0.007726601354079321\n",
      "Training Loss: 0.007622983045876026\n",
      "Validation Loss: 0.004419241010295122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007419228560756892\n",
      "Training Loss: 0.007690915034618229\n",
      "Training Loss: 0.007590178400278091\n",
      "Validation Loss: 0.004389143390633333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0073981464770622556\n",
      "Training Loss: 0.007660769952926785\n",
      "Training Loss: 0.007562546268454753\n",
      "Validation Loss: 0.004363937384522195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007380100549198687\n",
      "Training Loss: 0.007634869713801891\n",
      "Training Loss: 0.0075388175679836425\n",
      "Validation Loss: 0.004342381718170861\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007364249004749582\n",
      "Training Loss: 0.007612221231684088\n",
      "Training Loss: 0.0075180435832589865\n",
      "Validation Loss: 0.0043235505666855845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007349989013746381\n",
      "Training Loss: 0.007592075486900285\n",
      "Training Loss: 0.0074995218822732565\n",
      "Validation Loss: 0.0043067656054548665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007336892086314038\n",
      "Training Loss: 0.007573876478709281\n",
      "Training Loss: 0.007482738534454256\n",
      "Validation Loss: 0.004291535942459458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007324660156155005\n",
      "Training Loss: 0.007557208477519453\n",
      "Training Loss: 0.007467319606803358\n",
      "Validation Loss: 0.004277506894222722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007313086166977883\n",
      "Training Loss: 0.007541765370406211\n",
      "Training Loss: 0.007452989108278416\n",
      "Validation Loss: 0.004264425696920227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007302026029210537\n",
      "Training Loss: 0.0075273157504852865\n",
      "Training Loss: 0.007439548263791948\n",
      "Validation Loss: 0.004252109706684361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007291381013346836\n",
      "Training Loss: 0.007513690053019673\n",
      "Training Loss: 0.007426848072791472\n",
      "Validation Loss: 0.00424042555602958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007281081851106137\n",
      "Training Loss: 0.007500755806686357\n",
      "Training Loss: 0.007414776103105396\n",
      "Validation Loss: 0.0042292766777924104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007271080041537061\n",
      "Training Loss: 0.007488413183018565\n",
      "Training Loss: 0.007403245949535631\n",
      "Validation Loss: 0.004218589748632623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007261341082630679\n",
      "Training Loss: 0.007476582701783628\n",
      "Training Loss: 0.007392192678526044\n",
      "Validation Loss: 0.004208312265240074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007251840464305132\n",
      "Training Loss: 0.00746520436834544\n",
      "Training Loss: 0.007381564361858182\n",
      "Validation Loss: 0.004198402090500412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007242560628801584\n",
      "Training Loss: 0.007454228543210774\n",
      "Training Loss: 0.007371318779187277\n",
      "Validation Loss: 0.0041888269080435124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00723348674015142\n",
      "Training Loss: 0.007443616689415649\n",
      "Training Loss: 0.0073614247259683905\n",
      "Validation Loss: 0.004179560844891108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007224609928671271\n",
      "Training Loss: 0.007433335882378742\n",
      "Training Loss: 0.007351853345171549\n",
      "Validation Loss: 0.004170585269359558\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0072159228578675535\n",
      "Training Loss: 0.00742335913120769\n",
      "Training Loss: 0.007342581977136433\n",
      "Validation Loss: 0.004161883139030568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007207417777972296\n",
      "Training Loss: 0.00741366341826506\n",
      "Training Loss: 0.007333590626367368\n",
      "Validation Loss: 0.00415344121264231\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007199091367656365\n",
      "Training Loss: 0.007404229688690975\n",
      "Training Loss: 0.007324863512767479\n",
      "Validation Loss: 0.0041452478552027865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007190936771221459\n",
      "Training Loss: 0.007395041107665748\n",
      "Training Loss: 0.007316384902223944\n",
      "Validation Loss: 0.00413729267435546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007182952580042184\n",
      "Training Loss: 0.007386080889264121\n",
      "Training Loss: 0.0073081417521461845\n",
      "Validation Loss: 0.004129567137772866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007175131492549554\n",
      "Training Loss: 0.007377338146325201\n",
      "Training Loss: 0.0073001208517234776\n",
      "Validation Loss: 0.0041220637791779605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007167472400469705\n",
      "Training Loss: 0.007368797970702872\n",
      "Training Loss: 0.007292312897625379\n",
      "Validation Loss: 0.004114773702608903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00715997010585852\n",
      "Training Loss: 0.007360450025880709\n",
      "Training Loss: 0.007284705792553723\n",
      "Validation Loss: 0.0041076916419074275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007152619687840343\n",
      "Training Loss: 0.007352282434003428\n",
      "Training Loss: 0.007277289767516777\n",
      "Validation Loss: 0.00410081015957331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007145418488653377\n",
      "Training Loss: 0.0073442855081520975\n",
      "Training Loss: 0.007270055823028088\n",
      "Validation Loss: 0.004094122753353015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0071383608423639085\n",
      "Training Loss: 0.0073364511411637065\n",
      "Training Loss: 0.0072629952075658364\n",
      "Validation Loss: 0.004087624052445289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007131443008547649\n",
      "Training Loss: 0.0073287686973344535\n",
      "Training Loss: 0.007256099200458266\n",
      "Validation Loss: 0.004081306249175346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0071246600174345075\n",
      "Training Loss: 0.007321229386143387\n",
      "Training Loss: 0.007249359992565587\n",
      "Validation Loss: 0.0040751645195015365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007118007607059554\n",
      "Training Loss: 0.007313825525343418\n",
      "Training Loss: 0.007242769221193157\n",
      "Validation Loss: 0.004069192864764691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0071114813885651525\n",
      "Training Loss: 0.00730654955492355\n",
      "Training Loss: 0.007236319826333783\n",
      "Validation Loss: 0.004063384633595019\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007105074470164254\n",
      "Training Loss: 0.007299393732100725\n",
      "Training Loss: 0.00723000448429957\n",
      "Validation Loss: 0.004057734749499667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007098784329136834\n",
      "Training Loss: 0.007292350591160357\n",
      "Training Loss: 0.0072238161775749175\n",
      "Validation Loss: 0.004052236872421724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007092604649951682\n",
      "Training Loss: 0.007285414565121755\n",
      "Training Loss: 0.007217748674447648\n",
      "Validation Loss: 0.004046883732289746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007086532306857407\n",
      "Training Loss: 0.007278577926335857\n",
      "Training Loss: 0.0072117950685787946\n",
      "Validation Loss: 0.004041671195705788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007080560791073367\n",
      "Training Loss: 0.007271835096180439\n",
      "Training Loss: 0.007205950507777743\n",
      "Validation Loss: 0.004036591392209272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007074686243431643\n",
      "Training Loss: 0.007265181543771177\n",
      "Training Loss: 0.007200208721333184\n",
      "Validation Loss: 0.004031638328373181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007068904120242223\n",
      "Training Loss: 0.007258610493736341\n",
      "Training Loss: 0.007194564515957609\n",
      "Validation Loss: 0.004026807516321456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007063209352781996\n",
      "Training Loss: 0.007252118968171999\n",
      "Training Loss: 0.007189013239694759\n",
      "Validation Loss: 0.0040220942772045895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007057599003892392\n",
      "Training Loss: 0.007245701807551086\n",
      "Training Loss: 0.007183549609035254\n",
      "Validation Loss: 0.004017490711785183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007052068423945457\n",
      "Training Loss: 0.007239354436751455\n",
      "Training Loss: 0.007178169615799561\n",
      "Validation Loss: 0.004012992185686998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007046613884158432\n",
      "Training Loss: 0.007233073302777484\n",
      "Training Loss: 0.007172869628411718\n",
      "Validation Loss: 0.004008593665582411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007041231972398237\n",
      "Training Loss: 0.007226855321787298\n",
      "Training Loss: 0.0071676451247185465\n",
      "Validation Loss: 0.004004291150185248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007035918434849009\n",
      "Training Loss: 0.007220697526354343\n",
      "Training Loss: 0.007162492588395253\n",
      "Validation Loss: 0.004000079165359311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007030671173706651\n",
      "Training Loss: 0.0072145963262300935\n",
      "Training Loss: 0.007157409370993264\n",
      "Validation Loss: 0.0039959504580376354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007025486568454653\n",
      "Training Loss: 0.007208549352362752\n",
      "Training Loss: 0.007152391647687182\n",
      "Validation Loss: 0.003991903476887958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.0070203613070771095\n",
      "Training Loss: 0.007202554636169225\n",
      "Training Loss: 0.007147436888189986\n",
      "Validation Loss: 0.003987932425996895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007015293537406251\n",
      "Training Loss: 0.007196610739920288\n",
      "Training Loss: 0.007142543169902637\n",
      "Validation Loss: 0.003984033141881646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007010280732065439\n",
      "Training Loss: 0.007190714546013623\n",
      "Training Loss: 0.007137706517823972\n",
      "Validation Loss: 0.003980202116386107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007005319716408848\n",
      "Training Loss: 0.007184865913586691\n",
      "Training Loss: 0.007132926672347821\n",
      "Validation Loss: 0.003976434439138164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007000409153988585\n",
      "Training Loss: 0.007179062213981524\n",
      "Training Loss: 0.00712820012588054\n",
      "Validation Loss: 0.003972727028401882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006995547683909535\n",
      "Training Loss: 0.007173303151503206\n",
      "Training Loss: 0.007123525596689433\n",
      "Validation Loss: 0.003969077464308213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.00699073197087273\n",
      "Training Loss: 0.0071675866248551755\n",
      "Training Loss: 0.007118900871137157\n",
      "Validation Loss: 0.003965481659240519\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006985960764577612\n",
      "Training Loss: 0.007161912565352395\n",
      "Training Loss: 0.007114324648864567\n",
      "Validation Loss: 0.0039619360134800835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006981233318801969\n",
      "Training Loss: 0.00715628043632023\n",
      "Training Loss: 0.007109795368160121\n",
      "Validation Loss: 0.00395843775006367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006976547508966178\n",
      "Training Loss: 0.0071506881399545814\n",
      "Training Loss: 0.007105311884079129\n",
      "Validation Loss: 0.003954983681304317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006971902567893267\n",
      "Training Loss: 0.007145136499311775\n",
      "Training Loss: 0.007100872814189643\n",
      "Validation Loss: 0.003951572486084331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006967296913499013\n",
      "Training Loss: 0.007139624825213104\n",
      "Training Loss: 0.007096476096776314\n",
      "Validation Loss: 0.003948202483575749\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006962729081278667\n",
      "Training Loss: 0.0071341518871486185\n",
      "Training Loss: 0.007092121376190335\n",
      "Validation Loss: 0.003944867607101463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006958198867505416\n",
      "Training Loss: 0.007128718569874764\n",
      "Training Loss: 0.007087807709467597\n",
      "Validation Loss: 0.003941569082292445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006953703834442422\n",
      "Training Loss: 0.007123324068961665\n",
      "Training Loss: 0.00708353438123595\n",
      "Validation Loss: 0.0039383031982468085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00694924525800161\n",
      "Training Loss: 0.007117967564845458\n",
      "Training Loss: 0.007079299200559035\n",
      "Validation Loss: 0.003935068404940323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006944820525823161\n",
      "Training Loss: 0.007112648756010458\n",
      "Training Loss: 0.007075101807131432\n",
      "Validation Loss: 0.003931864275952822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006940428800880909\n",
      "Training Loss: 0.007107368430588394\n",
      "Training Loss: 0.007070941893034615\n",
      "Validation Loss: 0.003928685368541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006936071038944646\n",
      "Training Loss: 0.007102125990204513\n",
      "Training Loss: 0.00706681840994861\n",
      "Validation Loss: 0.003925533003822555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006931745064212009\n",
      "Training Loss: 0.007096921784104779\n",
      "Training Loss: 0.007062729937024415\n",
      "Validation Loss: 0.0039224048521830125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00692745071137324\n",
      "Training Loss: 0.007091754231369123\n",
      "Training Loss: 0.0070586758852005\n",
      "Validation Loss: 0.003919300438804824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006923187786014751\n",
      "Training Loss: 0.0070866247627418485\n",
      "Training Loss: 0.007054656419204548\n",
      "Validation Loss: 0.003916216419036552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006918955084402114\n",
      "Training Loss: 0.007081532190786674\n",
      "Training Loss: 0.007050669387099333\n",
      "Validation Loss: 0.003913152431859896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00691475207102485\n",
      "Training Loss: 0.007076476832153276\n",
      "Training Loss: 0.007046715413453058\n",
      "Validation Loss: 0.0039101072241751\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.0069105780660174785\n",
      "Training Loss: 0.0070714574761223045\n",
      "Training Loss: 0.007042792818974703\n",
      "Validation Loss: 0.003907080680874878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006906432764371857\n",
      "Training Loss: 0.007066476026084274\n",
      "Training Loss: 0.00703890091215726\n",
      "Validation Loss: 0.0039040696613616152\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006902315079933032\n",
      "Training Loss: 0.007061529811471701\n",
      "Training Loss: 0.00703503914468456\n",
      "Validation Loss: 0.0039010743526846506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006898225779877976\n",
      "Training Loss: 0.007056619914947077\n",
      "Training Loss: 0.007031206479296088\n",
      "Validation Loss: 0.0038980941021333586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006894162731477991\n",
      "Training Loss: 0.007051745738135651\n",
      "Training Loss: 0.0070274034072645005\n",
      "Validation Loss: 0.0038951266938925125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.0068901263771113\n",
      "Training Loss: 0.007046907180920243\n",
      "Training Loss: 0.00702362738433294\n",
      "Validation Loss: 0.003892171726394654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006886116353562102\n",
      "Training Loss: 0.007042103618150577\n",
      "Training Loss: 0.007019879191648215\n",
      "Validation Loss: 0.0038892273069097757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006882131202146411\n",
      "Training Loss: 0.0070373348123393955\n",
      "Training Loss: 0.0070161573315272105\n",
      "Validation Loss: 0.0038862940528314937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006878170495619998\n",
      "Training Loss: 0.00703259976580739\n",
      "Training Loss: 0.007012461378471926\n",
      "Validation Loss: 0.003883370034804756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006874234089627862\n",
      "Training Loss: 0.007027899055974558\n",
      "Training Loss: 0.0070087901270017025\n",
      "Validation Loss: 0.0038804552240527413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.0068703219678718595\n",
      "Training Loss: 0.007023232264909893\n",
      "Training Loss: 0.0070051433279877525\n",
      "Validation Loss: 0.0038775490960524825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006866432452807203\n",
      "Training Loss: 0.00701859790366143\n",
      "Training Loss: 0.007001519852201455\n",
      "Validation Loss: 0.0038746502551281555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006862565657356754\n",
      "Training Loss: 0.007013996053719893\n",
      "Training Loss: 0.006997919481364079\n",
      "Validation Loss: 0.0038717567758488184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006858720756135881\n",
      "Training Loss: 0.007009425045689568\n",
      "Training Loss: 0.006994341317331418\n",
      "Validation Loss: 0.003868867860311705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0068548973160795865\n",
      "Training Loss: 0.007004885647911578\n",
      "Training Loss: 0.006990783893852495\n",
      "Validation Loss: 0.003865985237742157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006851094401208684\n",
      "Training Loss: 0.007000376980286092\n",
      "Training Loss: 0.006987247424549423\n",
      "Validation Loss: 0.003863105770158634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006847311274614185\n",
      "Training Loss: 0.006995897493325174\n",
      "Training Loss: 0.006983730022329837\n",
      "Validation Loss: 0.003860229065149939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006843548030592501\n",
      "Training Loss: 0.006991447121836245\n",
      "Training Loss: 0.006980231441557408\n",
      "Validation Loss: 0.0038573568048520706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.0068398036144208165\n",
      "Training Loss: 0.0069870248599909245\n",
      "Training Loss: 0.006976751032634638\n",
      "Validation Loss: 0.003854484587719434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006836076830513776\n",
      "Training Loss: 0.006982631093123927\n",
      "Training Loss: 0.006973287973669358\n",
      "Validation Loss: 0.0038516148676300483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006832367952447385\n",
      "Training Loss: 0.006978263576747849\n",
      "Training Loss: 0.006969841681420803\n",
      "Validation Loss: 0.0038487458564968927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006828675739234314\n",
      "Training Loss: 0.006973921761382371\n",
      "Training Loss: 0.006966410566237755\n",
      "Validation Loss: 0.0038458756275809884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006824999251402914\n",
      "Training Loss: 0.006969604721525684\n",
      "Training Loss: 0.006962994610075839\n",
      "Validation Loss: 0.00384300357264498\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006821338346926495\n",
      "Training Loss: 0.006965313048567623\n",
      "Training Loss: 0.006959592615603469\n",
      "Validation Loss: 0.003840129800255965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.00681769186980091\n",
      "Training Loss: 0.0069610449788160625\n",
      "Training Loss: 0.006956203323788941\n",
      "Validation Loss: 0.0038372537178730363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006814060499891639\n",
      "Training Loss: 0.006956798433093354\n",
      "Training Loss: 0.006952825871994719\n",
      "Validation Loss: 0.003834373840873831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0068104416760616\n",
      "Training Loss: 0.0069525740190874786\n",
      "Training Loss: 0.006949460455216467\n",
      "Validation Loss: 0.003831489888030324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006806835168972612\n",
      "Training Loss: 0.0069483698369003834\n",
      "Training Loss: 0.006946105740498751\n",
      "Validation Loss: 0.0038286022543697878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006803240233566612\n",
      "Training Loss: 0.006944186090258882\n",
      "Training Loss: 0.006942760541569441\n",
      "Validation Loss: 0.0038257085187151357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0067996570852119475\n",
      "Training Loss: 0.0069400197418872265\n",
      "Training Loss: 0.006939423925359733\n",
      "Validation Loss: 0.0038228075666185677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006796083601657301\n",
      "Training Loss: 0.006935872432077304\n",
      "Training Loss: 0.006936095954151824\n",
      "Validation Loss: 0.0038198984811459195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006792519699083641\n",
      "Training Loss: 0.006931741605512798\n",
      "Training Loss: 0.006932774431770667\n",
      "Validation Loss: 0.0038169819804096824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006788964109728113\n",
      "Training Loss: 0.00692762529826723\n",
      "Training Loss: 0.006929459220846184\n",
      "Validation Loss: 0.00381405575049183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006785416344646364\n",
      "Training Loss: 0.006923524782760069\n",
      "Training Loss: 0.006926148668862879\n",
      "Validation Loss: 0.0038111204781119574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006781875580782071\n",
      "Training Loss: 0.006919436589814722\n",
      "Training Loss: 0.006922842898638919\n",
      "Validation Loss: 0.0038081765687616354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006778340969467536\n",
      "Training Loss: 0.006915361266583204\n",
      "Training Loss: 0.006919540646485985\n",
      "Validation Loss: 0.003805219058439219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006774811000796035\n",
      "Training Loss: 0.0069112974836025385\n",
      "Training Loss: 0.006916240748250857\n",
      "Validation Loss: 0.003802248984418307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006771285568829626\n",
      "Training Loss: 0.006907243857858703\n",
      "Training Loss: 0.0069129424612037835\n",
      "Validation Loss: 0.0037992666553957073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006767763609532267\n",
      "Training Loss: 0.006903199502266944\n",
      "Training Loss: 0.0069096451328368854\n",
      "Validation Loss: 0.0037962716423351776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006764244184596464\n",
      "Training Loss: 0.006899163759080693\n",
      "Training Loss: 0.006906347722979263\n",
      "Validation Loss: 0.0037932604920181833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006760726479114965\n",
      "Training Loss: 0.006895134183578193\n",
      "Training Loss: 0.006903048880049028\n",
      "Validation Loss: 0.0037902332306054705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.0067572092602495104\n",
      "Training Loss: 0.006891109994612634\n",
      "Training Loss: 0.006899748091236688\n",
      "Validation Loss: 0.0037871910798038992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0067536919040139766\n",
      "Training Loss: 0.006887091138632968\n",
      "Training Loss: 0.006896444163285196\n",
      "Validation Loss: 0.0037841287315980104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006750173284672201\n",
      "Training Loss: 0.006883076167432591\n",
      "Training Loss: 0.006893136611906812\n",
      "Validation Loss: 0.0037810506280825545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006746652924921364\n",
      "Training Loss: 0.006879063817905262\n",
      "Training Loss: 0.006889824246172793\n",
      "Validation Loss: 0.0037779500564099865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006743129083188251\n",
      "Training Loss: 0.006875051509123296\n",
      "Training Loss: 0.006886505305301398\n",
      "Validation Loss: 0.0037748299675125084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006739600885193795\n",
      "Training Loss: 0.006871039360994473\n",
      "Training Loss: 0.006883179205469787\n",
      "Validation Loss: 0.003771689362049605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006736067575402558\n",
      "Training Loss: 0.0068670262559317055\n",
      "Training Loss: 0.006879845702205785\n",
      "Validation Loss: 0.0037685251962184235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006732528156135231\n",
      "Training Loss: 0.00686300999019295\n",
      "Training Loss: 0.006876503500971012\n",
      "Validation Loss: 0.0037653369716567435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006728980741463601\n",
      "Training Loss: 0.006858991537010297\n",
      "Training Loss: 0.006873151946929283\n",
      "Validation Loss: 0.003762123759658065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006725425658514723\n",
      "Training Loss: 0.0068549668288324025\n",
      "Training Loss: 0.006869788747280836\n",
      "Validation Loss: 0.0037588857080306064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006721861173864454\n",
      "Training Loss: 0.006850936816772446\n",
      "Training Loss: 0.006866414329851978\n",
      "Validation Loss: 0.00375561998487356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.00671828611753881\n",
      "Training Loss: 0.006846898749936372\n",
      "Training Loss: 0.006863026267965324\n",
      "Validation Loss: 0.003752326009418355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006714698658324778\n",
      "Training Loss: 0.006842852694680914\n",
      "Training Loss: 0.006859624800272286\n",
      "Validation Loss: 0.003749002239488986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006711098974337801\n",
      "Training Loss: 0.006838796630036086\n",
      "Training Loss: 0.006856208496610634\n",
      "Validation Loss: 0.0037456466319311537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006707485114457085\n",
      "Training Loss: 0.006834729223046451\n",
      "Training Loss: 0.006852775690495036\n",
      "Validation Loss: 0.003742260607273391\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006703856185777113\n",
      "Training Loss: 0.006830649398034438\n",
      "Training Loss: 0.006849326360388659\n",
      "Validation Loss: 0.0037388405984979164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006700210444396362\n",
      "Training Loss: 0.00682655482320115\n",
      "Training Loss: 0.006845858283340931\n",
      "Validation Loss: 0.0037353860222200832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006696546552702785\n",
      "Training Loss: 0.006822444723220542\n",
      "Training Loss: 0.0068423705140594395\n",
      "Validation Loss: 0.003731894794736434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006692863656207919\n",
      "Training Loss: 0.006818317386787385\n",
      "Training Loss: 0.006838862015283667\n",
      "Validation Loss: 0.0037283649487588346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006689159636152908\n",
      "Training Loss: 0.0068141717498656365\n",
      "Training Loss: 0.006835331217735075\n",
      "Validation Loss: 0.0037247956942327402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006685433385428041\n",
      "Training Loss: 0.006810007060412317\n",
      "Training Loss: 0.006831778306514024\n",
      "Validation Loss: 0.0037211858709290456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0066816842160187665\n",
      "Training Loss: 0.0068058201659005136\n",
      "Training Loss: 0.006828200165764429\n",
      "Validation Loss: 0.003717533112608231\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006677909384015948\n",
      "Training Loss: 0.0068016106472350655\n",
      "Training Loss: 0.0068245970067800955\n",
      "Validation Loss: 0.0037138341020876435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006674108651932329\n",
      "Training Loss: 0.006797376477625221\n",
      "Training Loss: 0.006820966157247313\n",
      "Validation Loss: 0.00371008929064016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006670279563404619\n",
      "Training Loss: 0.0067931152484379705\n",
      "Training Loss: 0.00681730660609901\n",
      "Validation Loss: 0.003706296485995225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006666420404799283\n",
      "Training Loss: 0.006788825393887237\n",
      "Training Loss: 0.006813616949366406\n",
      "Validation Loss: 0.0037024518739160023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006662529103923589\n",
      "Training Loss: 0.006784506347030401\n",
      "Training Loss: 0.006809896497870795\n",
      "Validation Loss: 0.0036985534361009013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006658604383701459\n",
      "Training Loss: 0.006780155540909618\n",
      "Training Loss: 0.006806142603163607\n",
      "Validation Loss: 0.0036946010286658167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006654644234804437\n",
      "Training Loss: 0.006775770615786314\n",
      "Training Loss: 0.006802354447427206\n",
      "Validation Loss: 0.0036905884410495336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0066506463882979\n",
      "Training Loss: 0.006771349632181227\n",
      "Training Loss: 0.006798529674415477\n",
      "Validation Loss: 0.003686518994358818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006646609336603433\n",
      "Training Loss: 0.00676689084735699\n",
      "Training Loss: 0.006794666201458312\n",
      "Validation Loss: 0.0036823857272190326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006642530341632664\n",
      "Training Loss: 0.006762391834054142\n",
      "Training Loss: 0.006790763310273178\n",
      "Validation Loss: 0.003678184616107368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.0066384077444672585\n",
      "Training Loss: 0.006757850341964513\n",
      "Training Loss: 0.00678681802819483\n",
      "Validation Loss: 0.0036739162352522102\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006634238482220099\n",
      "Training Loss: 0.006753263685386628\n",
      "Training Loss: 0.006782828490249812\n",
      "Validation Loss: 0.00366957500718241\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006630019540898502\n",
      "Training Loss: 0.006748629305511713\n",
      "Training Loss: 0.006778792869881727\n",
      "Validation Loss: 0.0036651599469458623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006625749438535422\n",
      "Training Loss: 0.006743943961337209\n",
      "Training Loss: 0.006774708409793675\n",
      "Validation Loss: 0.0036606638642613975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.00662142519140616\n",
      "Training Loss: 0.0067392061487771574\n",
      "Training Loss: 0.006770573430112563\n",
      "Validation Loss: 0.003656087388294969\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.0066170427307952195\n",
      "Training Loss: 0.006734413212398067\n",
      "Training Loss: 0.00676638457167428\n",
      "Validation Loss: 0.0036514239383107993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006612599801737815\n",
      "Training Loss: 0.006729559879750014\n",
      "Training Loss: 0.00676213902363088\n",
      "Validation Loss: 0.0036466680166280167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006608093729009851\n",
      "Training Loss: 0.006724643689813093\n",
      "Training Loss: 0.006757835044991225\n",
      "Validation Loss: 0.003641818151704632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.0066035197058226915\n",
      "Training Loss: 0.006719662511022762\n",
      "Training Loss: 0.006753468841197901\n",
      "Validation Loss: 0.003636866301727178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006598874281626195\n",
      "Training Loss: 0.006714611612260342\n",
      "Training Loss: 0.006749037125264295\n",
      "Validation Loss: 0.0036318101606258517\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006594154193298891\n",
      "Training Loss: 0.006709487456828356\n",
      "Training Loss: 0.006744536526384764\n",
      "Validation Loss: 0.0036266428991377857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006589354650350288\n",
      "Training Loss: 0.006704285048181191\n",
      "Training Loss: 0.006739964028238319\n",
      "Validation Loss: 0.0036213589397918306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006584471644600853\n",
      "Training Loss: 0.0066990004037506875\n",
      "Training Loss: 0.006735315350233577\n",
      "Validation Loss: 0.0036159510792264445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0065794996486511085\n",
      "Training Loss: 0.006693629623623565\n",
      "Training Loss: 0.006730585813056677\n",
      "Validation Loss: 0.0036104141062209276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00657443467178382\n",
      "Training Loss: 0.006688167256070301\n",
      "Training Loss: 0.006725770939956419\n",
      "Validation Loss: 0.003604737237315583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006569270190084353\n",
      "Training Loss: 0.006682607415132225\n",
      "Training Loss: 0.006720866945688613\n",
      "Validation Loss: 0.003598918310324714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006564002283848822\n",
      "Training Loss: 0.00667694523697719\n",
      "Training Loss: 0.006715867798193358\n",
      "Validation Loss: 0.0035929463089579778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006558622487355024\n",
      "Training Loss: 0.006671176292002201\n",
      "Training Loss: 0.006710769553901628\n",
      "Validation Loss: 0.003586811926529816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006553126665530726\n",
      "Training Loss: 0.00666529172565788\n",
      "Training Loss: 0.006705565403681248\n",
      "Validation Loss: 0.003580506573159122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006547506700735539\n",
      "Training Loss: 0.006659286895301193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [20:35<13:41, 205.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.006700249961577356\n",
      "Validation Loss: 0.0035740225131131627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5441212683916092\n",
      "Training Loss: 0.4199144119024277\n",
      "Training Loss: 0.30742365546524525\n",
      "Validation Loss: 0.16852028165640456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.14921418219804763\n",
      "Training Loss: 0.09297890612855554\n",
      "Training Loss: 0.06759082488715648\n",
      "Validation Loss: 0.05107325403375572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05234296740964055\n",
      "Training Loss: 0.050604946296662096\n",
      "Training Loss: 0.04919361537322402\n",
      "Validation Loss: 0.047058958518371156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04511154565960169\n",
      "Training Loss: 0.04417287334799767\n",
      "Training Loss: 0.042087010834366084\n",
      "Validation Loss: 0.03958883155346586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03701109733432531\n",
      "Training Loss: 0.03598704089410603\n",
      "Training Loss: 0.0335129055660218\n",
      "Validation Loss: 0.03083738402118174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.028454497316852213\n",
      "Training Loss: 0.02803389137610793\n",
      "Training Loss: 0.02586849262472242\n",
      "Validation Loss: 0.023296763754209106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.021723537901416422\n",
      "Training Loss: 0.02213182156905532\n",
      "Training Loss: 0.020542090865783392\n",
      "Validation Loss: 0.018112051551847645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.017442448930814862\n",
      "Training Loss: 0.0184096309915185\n",
      "Training Loss: 0.01723678851732984\n",
      "Validation Loss: 0.014802842233539297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.014834857356036082\n",
      "Training Loss: 0.015917042626533658\n",
      "Training Loss: 0.014889229069231078\n",
      "Validation Loss: 0.012285387645779031\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.012820750526152551\n",
      "Training Loss: 0.013639290344435721\n",
      "Training Loss: 0.012645634438376874\n",
      "Validation Loss: 0.009784075944276337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010928416677052155\n",
      "Training Loss: 0.011462326640030369\n",
      "Training Loss: 0.010808965682517737\n",
      "Validation Loss: 0.007947691901995058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009647394201019779\n",
      "Training Loss: 0.010111309943022206\n",
      "Training Loss: 0.009792832428356633\n",
      "Validation Loss: 0.007031723804604472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008975658935960383\n",
      "Training Loss: 0.00942293984349817\n",
      "Training Loss: 0.009257972222985699\n",
      "Validation Loss: 0.006545588468316566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008592876557959244\n",
      "Training Loss: 0.009027416037861257\n",
      "Training Loss: 0.00892140565556474\n",
      "Validation Loss: 0.006221083662566844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.00833417495363392\n",
      "Training Loss: 0.008757878263713792\n",
      "Training Loss: 0.00867902624187991\n",
      "Validation Loss: 0.005973200138469928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.00814256734563969\n",
      "Training Loss: 0.008555797801818699\n",
      "Training Loss: 0.008493155217729509\n",
      "Validation Loss: 0.005773235426357623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.007994357903953642\n",
      "Training Loss: 0.008397048006299883\n",
      "Training Loss: 0.008345927039626985\n",
      "Validation Loss: 0.005608195548856191\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.007876810644520447\n",
      "Training Loss: 0.00826890545198694\n",
      "Training Loss: 0.008226644441019743\n",
      "Validation Loss: 0.005470030912292305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007781634032726288\n",
      "Training Loss: 0.008163187656318769\n",
      "Training Loss: 0.008127920269034803\n",
      "Validation Loss: 0.005352583535936441\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007702876242110506\n",
      "Training Loss: 0.008074071033624931\n",
      "Training Loss: 0.008044382255757227\n",
      "Validation Loss: 0.005250881900853907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007636186314048245\n",
      "Training Loss: 0.007997330793878064\n",
      "Training Loss: 0.007972159007331357\n",
      "Validation Loss: 0.005161023183380452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007578453023452312\n",
      "Training Loss: 0.007929959424072876\n",
      "Training Loss: 0.007908523104852065\n",
      "Validation Loss: 0.005080114519014285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007527515206020325\n",
      "Training Loss: 0.00786986818886362\n",
      "Training Loss: 0.007851590203354136\n",
      "Validation Loss: 0.005006111581454032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007481904064770788\n",
      "Training Loss: 0.007815628305543214\n",
      "Training Loss: 0.007800068415235728\n",
      "Validation Loss: 0.004937626747152863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0074406262906268235\n",
      "Training Loss: 0.007766259914496913\n",
      "Training Loss: 0.007753067462472245\n",
      "Validation Loss: 0.004873747293826904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007403008157853037\n",
      "Training Loss: 0.007721082156058401\n",
      "Training Loss: 0.0077099653123877945\n",
      "Validation Loss: 0.004813882009534354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007368581630289555\n",
      "Training Loss: 0.007679606574820355\n",
      "Training Loss: 0.007670312176924199\n",
      "Validation Loss: 0.004757662060450804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0073370138043537736\n",
      "Training Loss: 0.007641469984082505\n",
      "Training Loss: 0.007633775970898569\n",
      "Validation Loss: 0.004704843753990665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007308055043686181\n",
      "Training Loss: 0.007606388631975278\n",
      "Training Loss: 0.007600100606214255\n",
      "Validation Loss: 0.004655279334257828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.0072815109114162625\n",
      "Training Loss: 0.007574132081354037\n",
      "Training Loss: 0.007569078017259017\n",
      "Validation Loss: 0.004608861844348355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007257215981371701\n",
      "Training Loss: 0.007544497409835458\n",
      "Training Loss: 0.007540525697404519\n",
      "Validation Loss: 0.004565498061750209\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007235018878709525\n",
      "Training Loss: 0.0075172971992287785\n",
      "Training Loss: 0.007514275106368587\n",
      "Validation Loss: 0.004525101240044146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007214774687308818\n",
      "Training Loss: 0.007492355869617313\n",
      "Training Loss: 0.00749016686109826\n",
      "Validation Loss: 0.00448757759295404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007196340401424095\n",
      "Training Loss: 0.0074694979400374\n",
      "Training Loss: 0.007468040084931999\n",
      "Validation Loss: 0.004452808621454607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007179569251602516\n",
      "Training Loss: 0.0074485533300321545\n",
      "Training Loss: 0.0074477347894571725\n",
      "Validation Loss: 0.004420666377258937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007164313404355198\n",
      "Training Loss: 0.007429350977763534\n",
      "Training Loss: 0.007429091173689812\n",
      "Validation Loss: 0.00439100486508916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007150423100683838\n",
      "Training Loss: 0.007411723996046931\n",
      "Training Loss: 0.007411950000096113\n",
      "Validation Loss: 0.004363660943914163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0071377532742917535\n",
      "Training Loss: 0.007395509068155661\n",
      "Training Loss: 0.007396155894966796\n",
      "Validation Loss: 0.004338468545315306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007126161139458418\n",
      "Training Loss: 0.007380550088128075\n",
      "Training Loss: 0.007381558490451425\n",
      "Validation Loss: 0.004315252432840343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00711551038781181\n",
      "Training Loss: 0.0073667002853471785\n",
      "Training Loss: 0.007368017985718325\n",
      "Validation Loss: 0.004293841979560557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0071056757494807245\n",
      "Training Loss: 0.007353824229212478\n",
      "Training Loss: 0.007355402585817501\n",
      "Validation Loss: 0.004274069266184495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007096541519276797\n",
      "Training Loss: 0.007341795699903742\n",
      "Training Loss: 0.00734359250520356\n",
      "Validation Loss: 0.004255774621904063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007088003919925541\n",
      "Training Loss: 0.007330503339180723\n",
      "Training Loss: 0.007332479307660833\n",
      "Validation Loss: 0.004238806655787433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007079970539780334\n",
      "Training Loss: 0.0073198453022632745\n",
      "Training Loss: 0.007321966078598053\n",
      "Validation Loss: 0.004223024243687729\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007072360541205853\n",
      "Training Loss: 0.007309732357971371\n",
      "Training Loss: 0.007311967299319804\n",
      "Validation Loss: 0.004208298954652266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0070651035639457405\n",
      "Training Loss: 0.0073000874160788955\n",
      "Training Loss: 0.007302408463438041\n",
      "Validation Loss: 0.004194512587888271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007058138723950833\n",
      "Training Loss: 0.0072908402187749745\n",
      "Training Loss: 0.00729322342958767\n",
      "Validation Loss: 0.004181560254498814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.0070514149405062196\n",
      "Training Loss: 0.007281932951882481\n",
      "Training Loss: 0.0072843545983778315\n",
      "Validation Loss: 0.004169348172131884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0070448870968539265\n",
      "Training Loss: 0.007273311861790716\n",
      "Training Loss: 0.0072757514013210315\n",
      "Validation Loss: 0.004157787424334315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007038517293985933\n",
      "Training Loss: 0.00726493063615635\n",
      "Training Loss: 0.007267370029003359\n",
      "Validation Loss: 0.00414680446147542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0070322711672633886\n",
      "Training Loss: 0.007256750242086127\n",
      "Training Loss: 0.0072591686464147645\n",
      "Validation Loss: 0.004136329634491814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007026119962101802\n",
      "Training Loss: 0.007248731531435623\n",
      "Training Loss: 0.007251111376099288\n",
      "Validation Loss: 0.0041262972772937645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.00702003687969409\n",
      "Training Loss: 0.007240844463231042\n",
      "Training Loss: 0.007243165218969807\n",
      "Validation Loss: 0.00411665356937754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007013997094472871\n",
      "Training Loss: 0.0072330556239467115\n",
      "Training Loss: 0.0072352988523198295\n",
      "Validation Loss: 0.004107343424059284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00700797816622071\n",
      "Training Loss: 0.007225337325362489\n",
      "Training Loss: 0.0072274811763782055\n",
      "Validation Loss: 0.00409831819412288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007001956063322723\n",
      "Training Loss: 0.007217658987501636\n",
      "Training Loss: 0.00721968175668735\n",
      "Validation Loss: 0.0040895325822358055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00699590926291421\n",
      "Training Loss: 0.007209994322620332\n",
      "Training Loss: 0.007211869524908252\n",
      "Validation Loss: 0.004080941259672635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006989813490072265\n",
      "Training Loss: 0.007202312659937888\n",
      "Training Loss: 0.007204013274167665\n",
      "Validation Loss: 0.004072498187443681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006983643914572894\n",
      "Training Loss: 0.007194583385717124\n",
      "Training Loss: 0.007196078694541939\n",
      "Validation Loss: 0.004064158900128154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006977372595574707\n",
      "Training Loss: 0.0071867722820024935\n",
      "Training Loss: 0.0071880272647831586\n",
      "Validation Loss: 0.004055877557558039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006970968117238954\n",
      "Training Loss: 0.007178843873552978\n",
      "Training Loss: 0.007179818277363665\n",
      "Validation Loss: 0.004047600531511092\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006964395591057837\n",
      "Training Loss: 0.007170754572143778\n",
      "Training Loss: 0.0071714035485638305\n",
      "Validation Loss: 0.00403927153583323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006957611655816436\n",
      "Training Loss: 0.007162453029304743\n",
      "Training Loss: 0.007162726403330453\n",
      "Validation Loss: 0.004030824389068012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006950567949097604\n",
      "Training Loss: 0.007153882677666843\n",
      "Training Loss: 0.0071537211257964375\n",
      "Validation Loss: 0.004022183951011367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00694320225622505\n",
      "Training Loss: 0.007144970478257164\n",
      "Training Loss: 0.007144308194401674\n",
      "Validation Loss: 0.004013257112950505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006935441842069849\n",
      "Training Loss: 0.007135629978729412\n",
      "Training Loss: 0.007134389426792041\n",
      "Validation Loss: 0.00400392350013462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006927192063303664\n",
      "Training Loss: 0.00712574883014895\n",
      "Training Loss: 0.00712384361831937\n",
      "Validation Loss: 0.003994041550224333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006918335148366168\n",
      "Training Loss: 0.0071151888754684475\n",
      "Training Loss: 0.007112515673507005\n",
      "Validation Loss: 0.003983420442810722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0069087177037727085\n",
      "Training Loss: 0.007103767187800258\n",
      "Training Loss: 0.00710020971018821\n",
      "Validation Loss: 0.003971817451947777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00689814038341865\n",
      "Training Loss: 0.00709124795277603\n",
      "Training Loss: 0.007086668360279873\n",
      "Validation Loss: 0.0039589057161127416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006886338479816913\n",
      "Training Loss: 0.007077312718611211\n",
      "Training Loss: 0.0070715502317762\n",
      "Validation Loss: 0.003944243766168614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006872950674733147\n",
      "Training Loss: 0.007061530741630122\n",
      "Training Loss: 0.007054397047031671\n",
      "Validation Loss: 0.003927226273834789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006857482911436818\n",
      "Training Loss: 0.00704330894164741\n",
      "Training Loss: 0.007034578374586999\n",
      "Validation Loss: 0.003907003044935592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006839243074064143\n",
      "Training Loss: 0.007021815542830154\n",
      "Training Loss: 0.007011219842825085\n",
      "Validation Loss: 0.003882392065003096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006817245304118842\n",
      "Training Loss: 0.006995875227730721\n",
      "Training Loss: 0.0069830854330211875\n",
      "Validation Loss: 0.003851710139836572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006790073000011034\n",
      "Training Loss: 0.006963799963705242\n",
      "Training Loss: 0.006948420477565378\n",
      "Validation Loss: 0.003812586769639525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006755684960517101\n",
      "Training Loss: 0.006923204585909844\n",
      "Training Loss: 0.006904759666649624\n",
      "Validation Loss: 0.0037618108875944875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006711213897215202\n",
      "Training Loss: 0.00687085457961075\n",
      "Training Loss: 0.006848849497619085\n",
      "Validation Loss: 0.0036955516539472206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00665302166598849\n",
      "Training Loss: 0.006803002874366939\n",
      "Training Loss: 0.006777203188976273\n",
      "Validation Loss: 0.003610956014311883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00657786496100016\n",
      "Training Loss: 0.006717324986821041\n",
      "Training Loss: 0.006688568833051249\n",
      "Validation Loss: 0.0035108868686712525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006486710892058909\n",
      "Training Loss: 0.006617696423199959\n",
      "Training Loss: 0.006588910380960442\n",
      "Validation Loss: 0.003409730570045499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006389705599285662\n",
      "Training Loss: 0.006517471837578341\n",
      "Training Loss: 0.006492317252559587\n",
      "Validation Loss: 0.003326611160405315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006301665215287358\n",
      "Training Loss: 0.006430036620004103\n",
      "Training Loss: 0.006409532792167738\n",
      "Validation Loss: 0.0032664949919379662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006228516263072379\n",
      "Training Loss: 0.006357271819142625\n",
      "Training Loss: 0.006340686362818815\n",
      "Validation Loss: 0.0032216516621620134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0061671478644711895\n",
      "Training Loss: 0.006294744802289642\n",
      "Training Loss: 0.006281953231664374\n",
      "Validation Loss: 0.003184996664346185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006113498980412259\n",
      "Training Loss: 0.006238809002679773\n",
      "Training Loss: 0.006230357291642576\n",
      "Validation Loss: 0.003153063857854668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006065092710778117\n",
      "Training Loss: 0.006187484017573297\n",
      "Training Loss: 0.006184094965574332\n",
      "Validation Loss: 0.003124343189463187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006020587812527083\n",
      "Training Loss: 0.006139740752987563\n",
      "Training Loss: 0.006142072988441214\n",
      "Validation Loss: 0.003098122698380455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.005979231538367458\n",
      "Training Loss: 0.006095005112583749\n",
      "Training Loss: 0.006103600569767878\n",
      "Validation Loss: 0.0030740240034176393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005940577230649069\n",
      "Training Loss: 0.0060529392468743025\n",
      "Training Loss: 0.006068233120022342\n",
      "Validation Loss: 0.0030518267133660365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.005904360325075686\n",
      "Training Loss: 0.006013349032145925\n",
      "Training Loss: 0.006035686277900822\n",
      "Validation Loss: 0.0030314057759333697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005870436099357903\n",
      "Training Loss: 0.00597613341815304\n",
      "Training Loss: 0.006005783950677142\n",
      "Validation Loss: 0.0030126902575636012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0058387464983388785\n",
      "Training Loss: 0.005941262116539292\n",
      "Training Loss: 0.005978422785992734\n",
      "Validation Loss: 0.0029956492454106553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0058092902827775105\n",
      "Training Loss: 0.0059087513131089505\n",
      "Training Loss: 0.005953538119210861\n",
      "Validation Loss: 0.002980263712763619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.0057820991711923855\n",
      "Training Loss: 0.005878632174571976\n",
      "Training Loss: 0.005931072594830766\n",
      "Validation Loss: 0.002966492043106995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.0057572037738282235\n",
      "Training Loss: 0.005850926884450019\n",
      "Training Loss: 0.005910945569630712\n",
      "Validation Loss: 0.0029542666017548756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0057346007518935945\n",
      "Training Loss: 0.0058256100007565694\n",
      "Training Loss: 0.005893027432030067\n",
      "Validation Loss: 0.0029434629472684156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005714227226562798\n",
      "Training Loss: 0.005802595281274989\n",
      "Training Loss: 0.005877132648602128\n",
      "Validation Loss: 0.00293391543764914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005695948921493254\n",
      "Training Loss: 0.005781725018750876\n",
      "Training Loss: 0.005863028624444269\n",
      "Validation Loss: 0.002925430818230667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.0056795719446381555\n",
      "Training Loss: 0.005762797869974748\n",
      "Training Loss: 0.005850465195835568\n",
      "Validation Loss: 0.002917813082236085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005664872672059573\n",
      "Training Loss: 0.005745587255805731\n",
      "Training Loss: 0.005839196853921749\n",
      "Validation Loss: 0.0029108807381786656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.005651624146848917\n",
      "Training Loss: 0.005729872199008241\n",
      "Training Loss: 0.005829004297265783\n",
      "Validation Loss: 0.0029044795815382947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005639613337698393\n",
      "Training Loss: 0.005715449392446317\n",
      "Training Loss: 0.005819699787534774\n",
      "Validation Loss: 0.0028984860289486105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0056286521401489155\n",
      "Training Loss: 0.00570213770493865\n",
      "Training Loss: 0.0058111279574222865\n",
      "Validation Loss: 0.0028928038677242533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.005618579973233864\n",
      "Training Loss: 0.005689785533468239\n",
      "Training Loss: 0.005803163775708526\n",
      "Validation Loss: 0.0028873574959239765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.005609264643862843\n",
      "Training Loss: 0.005678262133151293\n",
      "Training Loss: 0.005795706767821684\n",
      "Validation Loss: 0.0028821002506242877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0056005926488433035\n",
      "Training Loss: 0.00566745773947332\n",
      "Training Loss: 0.005788676261436194\n",
      "Validation Loss: 0.002876986576809307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005592473191791214\n",
      "Training Loss: 0.005657281570020132\n",
      "Training Loss: 0.00578200928575825\n",
      "Validation Loss: 0.002871992534779933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005584830255247653\n",
      "Training Loss: 0.005647656500805169\n",
      "Training Loss: 0.005775655801990069\n",
      "Validation Loss: 0.0028670998015493322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0055776030983543026\n",
      "Training Loss: 0.00563852101971861\n",
      "Training Loss: 0.0057695742195937785\n",
      "Validation Loss: 0.002862294846779426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005570738963433542\n",
      "Training Loss: 0.005629820331814699\n",
      "Training Loss: 0.005763732679188251\n",
      "Validation Loss: 0.002857570202885133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.005564195931074209\n",
      "Training Loss: 0.005621508968179114\n",
      "Training Loss: 0.005758104897104203\n",
      "Validation Loss: 0.002852915813675506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005557937055709772\n",
      "Training Loss: 0.005613549208501354\n",
      "Training Loss: 0.005752669085632078\n",
      "Validation Loss: 0.0028483302363853775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.005551933951210231\n",
      "Training Loss: 0.005605907627614215\n",
      "Training Loss: 0.0057474073191406206\n",
      "Validation Loss: 0.002843811723476883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005546160081285052\n",
      "Training Loss: 0.005598557147895917\n",
      "Training Loss: 0.00574230620986782\n",
      "Validation Loss: 0.002839356178177123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005540594013873488\n",
      "Training Loss: 0.00559147370106075\n",
      "Training Loss: 0.00573735072335694\n",
      "Validation Loss: 0.002834965004010147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005535217641154304\n",
      "Training Loss: 0.005584634344559163\n",
      "Training Loss: 0.005732531875255517\n",
      "Validation Loss: 0.0028306333743182296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005530013745301403\n",
      "Training Loss: 0.005578021393739618\n",
      "Training Loss: 0.005727839705068618\n",
      "Validation Loss: 0.0028263621890310493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005524968933896162\n",
      "Training Loss: 0.005571618738467805\n",
      "Training Loss: 0.005723265694105067\n",
      "Validation Loss: 0.002822150947170311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005520070264465176\n",
      "Training Loss: 0.005565411805873737\n",
      "Training Loss: 0.005718802812043578\n",
      "Validation Loss: 0.002817996869156702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005515307424939237\n",
      "Training Loss: 0.005559387532412074\n",
      "Training Loss: 0.005714444534969516\n",
      "Validation Loss: 0.0028139017221486466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0055106702778721225\n",
      "Training Loss: 0.005553532997728325\n",
      "Training Loss: 0.00571018471615389\n",
      "Validation Loss: 0.0028098597246211734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005506149075808935\n",
      "Training Loss: 0.005547839654609561\n",
      "Training Loss: 0.005706018656492233\n",
      "Validation Loss: 0.002805872516853086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005501737549784593\n",
      "Training Loss: 0.00554229658911936\n",
      "Training Loss: 0.00570194105093833\n",
      "Validation Loss: 0.002801937558635902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.005497427857480943\n",
      "Training Loss: 0.005536896585253998\n",
      "Training Loss: 0.00569794736627955\n",
      "Validation Loss: 0.002798053522311737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005493212842266075\n",
      "Training Loss: 0.0055316291900817305\n",
      "Training Loss: 0.005694033142644912\n",
      "Validation Loss: 0.0027942217695474457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0054890880332095545\n",
      "Training Loss: 0.005526490118354559\n",
      "Training Loss: 0.005690194665803574\n",
      "Validation Loss: 0.002790438560664319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005485046837711707\n",
      "Training Loss: 0.005521471042884514\n",
      "Training Loss: 0.005686428162734955\n",
      "Validation Loss: 0.002786701368534247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005481084744678811\n",
      "Training Loss: 0.005516565520665608\n",
      "Training Loss: 0.0056827309844084085\n",
      "Validation Loss: 0.0027830088851199058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.0054771972948219625\n",
      "Training Loss: 0.005511768703581765\n",
      "Training Loss: 0.005679098966065794\n",
      "Validation Loss: 0.0027793630149236387\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005473380096955225\n",
      "Training Loss: 0.005507074488559738\n",
      "Training Loss: 0.005675529882428237\n",
      "Validation Loss: 0.0027757575029109635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0054696286976104605\n",
      "Training Loss: 0.005502478546113707\n",
      "Training Loss: 0.0056720194168156015\n",
      "Validation Loss: 0.0027721928435199884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005465940064168535\n",
      "Training Loss: 0.0054979758436093104\n",
      "Training Loss: 0.005668566196691245\n",
      "Validation Loss: 0.0027686693663761188\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00546231098473072\n",
      "Training Loss: 0.00549356168252416\n",
      "Training Loss: 0.005665167213301174\n",
      "Validation Loss: 0.0027651857542857696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.00545873838244006\n",
      "Training Loss: 0.005489233975531534\n",
      "Training Loss: 0.0056618203147081655\n",
      "Validation Loss: 0.002761739081169447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0054552188498200845\n",
      "Training Loss: 0.005484986527008005\n",
      "Training Loss: 0.005658523036981933\n",
      "Validation Loss: 0.002758327955275439\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.005451751060900278\n",
      "Training Loss: 0.005480817116913386\n",
      "Training Loss: 0.00565527307393495\n",
      "Validation Loss: 0.0027549553380002466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.005448329864884726\n",
      "Training Loss: 0.005476721876184456\n",
      "Training Loss: 0.00565206756873522\n",
      "Validation Loss: 0.0027516138337008405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005444956637220457\n",
      "Training Loss: 0.005472698562662117\n",
      "Training Loss: 0.005648906358983368\n",
      "Validation Loss: 0.002748307995655145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005441625319072045\n",
      "Training Loss: 0.005468743500532582\n",
      "Training Loss: 0.005645786992972717\n",
      "Validation Loss: 0.0027450319337710906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005438336867373436\n",
      "Training Loss: 0.005464854411548004\n",
      "Training Loss: 0.005642707096994854\n",
      "Validation Loss: 0.002741789042405533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005435088090598584\n",
      "Training Loss: 0.005461029091384262\n",
      "Training Loss: 0.0056396647670771925\n",
      "Validation Loss: 0.0027385804857116905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.005431877642404288\n",
      "Training Loss: 0.005457263845019042\n",
      "Training Loss: 0.005636659372248687\n",
      "Validation Loss: 0.0027353961067797428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005428703457582742\n",
      "Training Loss: 0.005453557258588262\n",
      "Training Loss: 0.005633689103997312\n",
      "Validation Loss: 0.0027322464823994913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00542556444532238\n",
      "Training Loss: 0.005449906936264597\n",
      "Training Loss: 0.005630752416327596\n",
      "Validation Loss: 0.0027291252123443095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005422458509565331\n",
      "Training Loss: 0.005446312467101961\n",
      "Training Loss: 0.0056278472521808\n",
      "Validation Loss: 0.00272603072173726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005419386144494638\n",
      "Training Loss: 0.0054427692911121995\n",
      "Training Loss: 0.005624974216916598\n",
      "Validation Loss: 0.0027229649111565747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005416344227269292\n",
      "Training Loss: 0.005439276350662112\n",
      "Training Loss: 0.005622130403062329\n",
      "Validation Loss: 0.0027199269016011714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005413331540767103\n",
      "Training Loss: 0.005435831364593469\n",
      "Training Loss: 0.005619314957875758\n",
      "Validation Loss: 0.002716915489676712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.00541034723224584\n",
      "Training Loss: 0.005432435371330939\n",
      "Training Loss: 0.005616526470403187\n",
      "Validation Loss: 0.0027139319180186543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005407391851767898\n",
      "Training Loss: 0.005429084331262856\n",
      "Training Loss: 0.005613765699090436\n",
      "Validation Loss: 0.002710973965579623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005404462872538715\n",
      "Training Loss: 0.005425776782794855\n",
      "Training Loss: 0.005611029037390835\n",
      "Validation Loss: 0.0027080432778705706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.00540155955706723\n",
      "Training Loss: 0.005422512700315565\n",
      "Training Loss: 0.0056083171273348855\n",
      "Validation Loss: 0.0027051378941435494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.00539868154854048\n",
      "Training Loss: 0.005419289777055383\n",
      "Training Loss: 0.005605628443881869\n",
      "Validation Loss: 0.002702258200269569\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005395827903412282\n",
      "Training Loss: 0.0054161063738865775\n",
      "Training Loss: 0.005602962785051204\n",
      "Validation Loss: 0.0026994023296793694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005392998058814555\n",
      "Training Loss: 0.005412961939582601\n",
      "Training Loss: 0.005600318597862497\n",
      "Validation Loss: 0.002696571564249527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005390189798199572\n",
      "Training Loss: 0.005409855566686019\n",
      "Training Loss: 0.005597696143086068\n",
      "Validation Loss: 0.002693769274792226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005387404509820044\n",
      "Training Loss: 0.005406785157974809\n",
      "Training Loss: 0.00559509358543437\n",
      "Validation Loss: 0.002690990005483788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.0053846408112440255\n",
      "Training Loss: 0.005403750617406331\n",
      "Training Loss: 0.005592510536080226\n",
      "Validation Loss: 0.0026882356608265573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005381898461491801\n",
      "Training Loss: 0.005400750808184966\n",
      "Training Loss: 0.005589946527616121\n",
      "Validation Loss: 0.0026855064474904304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005379176534479484\n",
      "Training Loss: 0.0053977837227284905\n",
      "Training Loss: 0.005587401372031309\n",
      "Validation Loss: 0.002682799141163404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005376474667573347\n",
      "Training Loss: 0.005394849331350997\n",
      "Training Loss: 0.005584873353946022\n",
      "Validation Loss: 0.0026801176986583834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005373792316531762\n",
      "Training Loss: 0.005391946513555013\n",
      "Training Loss: 0.005582362641580403\n",
      "Validation Loss: 0.0026774605359421687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005371128811966628\n",
      "Training Loss: 0.005389074101112783\n",
      "Training Loss: 0.005579869041685015\n",
      "Validation Loss: 0.0026748258531554027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005368483933852986\n",
      "Training Loss: 0.0053862316464073955\n",
      "Training Loss: 0.005577391440747306\n",
      "Validation Loss: 0.002672215910586581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005365857214783319\n",
      "Training Loss: 0.005383418281562627\n",
      "Training Loss: 0.0055749299505259845\n",
      "Validation Loss: 0.002669629789993502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005363249095971696\n",
      "Training Loss: 0.005380632685846649\n",
      "Training Loss: 0.005572483026771807\n",
      "Validation Loss: 0.002667066112704826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005360657869023271\n",
      "Training Loss: 0.005377874458790757\n",
      "Training Loss: 0.005570051134563983\n",
      "Validation Loss: 0.0026645292148642827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005358084034523927\n",
      "Training Loss: 0.0053751437546452506\n",
      "Training Loss: 0.005567633431055583\n",
      "Validation Loss: 0.002662013904871733\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00535552655113861\n",
      "Training Loss: 0.0053724376804893835\n",
      "Training Loss: 0.005565229630446993\n",
      "Validation Loss: 0.0026595228471992054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005352986479992978\n",
      "Training Loss: 0.005369757129810751\n",
      "Training Loss: 0.005562839484773576\n",
      "Validation Loss: 0.0026570567978922736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005350462169153616\n",
      "Training Loss: 0.005367102298187092\n",
      "Training Loss: 0.005560462652938441\n",
      "Validation Loss: 0.0026546110964139526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005347953930031508\n",
      "Training Loss: 0.005364470197819173\n",
      "Training Loss: 0.005558098907349631\n",
      "Validation Loss: 0.0026521890978799777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005345461788820103\n",
      "Training Loss: 0.00536186317447573\n",
      "Training Loss: 0.005555746784666553\n",
      "Validation Loss: 0.0026497892156410754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005342984948656522\n",
      "Training Loss: 0.0053592775890138\n",
      "Training Loss: 0.005553407872794196\n",
      "Validation Loss: 0.0026474142855221635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005340523269260302\n",
      "Training Loss: 0.005356713614892214\n",
      "Training Loss: 0.0055510809214320035\n",
      "Validation Loss: 0.002645060264379874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005338076351908967\n",
      "Training Loss: 0.005354173029190861\n",
      "Training Loss: 0.005548765334533527\n",
      "Validation Loss: 0.0026427310933306645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005335644088336267\n",
      "Training Loss: 0.005351652600220405\n",
      "Training Loss: 0.0055464610928902406\n",
      "Validation Loss: 0.002640423731187756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005333226632210426\n",
      "Training Loss: 0.005349153339047916\n",
      "Training Loss: 0.005544167665648274\n",
      "Validation Loss: 0.0026381358901938694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0053308240440674125\n",
      "Training Loss: 0.005346672620507888\n",
      "Training Loss: 0.0055418856604956095\n",
      "Validation Loss: 0.0026358740346694594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005328434313414618\n",
      "Training Loss: 0.005344212673371658\n",
      "Training Loss: 0.005539614591980353\n",
      "Validation Loss: 0.002633633204536994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005326058937353082\n",
      "Training Loss: 0.0053417723625898365\n",
      "Training Loss: 0.005537352653336711\n",
      "Validation Loss: 0.0026314133461669423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005323697438579984\n",
      "Training Loss: 0.005339347951230593\n",
      "Training Loss: 0.005535101959249005\n",
      "Validation Loss: 0.002629214640068455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005321348769357428\n",
      "Training Loss: 0.005336943597067148\n",
      "Training Loss: 0.005532859979430213\n",
      "Validation Loss: 0.0026270406728798753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005319013592670671\n",
      "Training Loss: 0.005334556796005927\n",
      "Training Loss: 0.005530628330889158\n",
      "Validation Loss: 0.0026248840646546207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005316690977779217\n",
      "Training Loss: 0.0053321862389566375\n",
      "Training Loss: 0.005528405836666934\n",
      "Validation Loss: 0.0026227518657138678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005314381680218503\n",
      "Training Loss: 0.005329833601135761\n",
      "Training Loss: 0.005526193225523457\n",
      "Validation Loss: 0.002620639360583063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005312084759934805\n",
      "Training Loss: 0.005327496923273429\n",
      "Training Loss: 0.005523989197681658\n",
      "Validation Loss: 0.002618549174493116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.00530980066745542\n",
      "Training Loss: 0.0053251761238789184\n",
      "Training Loss: 0.005521794294472784\n",
      "Validation Loss: 0.0026164773702516816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005307528510456905\n",
      "Training Loss: 0.005322869858937338\n",
      "Training Loss: 0.005519608235917985\n",
      "Validation Loss: 0.002614426151901651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005305268458323553\n",
      "Training Loss: 0.005320579945691861\n",
      "Training Loss: 0.005517431015032343\n",
      "Validation Loss: 0.002612396921659035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005303019598941318\n",
      "Training Loss: 0.005318304618122056\n",
      "Training Loss: 0.0055152614985127\n",
      "Validation Loss: 0.0026103864473636064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005300782510894351\n",
      "Training Loss: 0.005316043423954397\n",
      "Training Loss: 0.005513099907548166\n",
      "Validation Loss: 0.002608396331361087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005298556594061666\n",
      "Training Loss: 0.005313796577975154\n",
      "Training Loss: 0.005510946023277939\n",
      "Validation Loss: 0.0026064259444855235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0052963423717301335\n",
      "Training Loss: 0.005311562715214677\n",
      "Training Loss: 0.005508800358511507\n",
      "Validation Loss: 0.002604474293936588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005294138407916762\n",
      "Training Loss: 0.005309342705877498\n",
      "Training Loss: 0.00550666228227783\n",
      "Validation Loss: 0.0026025422260144288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005291945172939449\n",
      "Training Loss: 0.005307135117473081\n",
      "Training Loss: 0.005504532473278232\n",
      "Validation Loss: 0.0026006285098559233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005289763170876541\n",
      "Training Loss: 0.005304940404603258\n",
      "Training Loss: 0.005502409464097582\n",
      "Validation Loss: 0.002598732804063331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005287590898224153\n",
      "Training Loss: 0.005302758024190553\n",
      "Training Loss: 0.005500293039367534\n",
      "Validation Loss: 0.002596857257741974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005285428914357908\n",
      "Training Loss: 0.005300587594974786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [24:00<10:15, 205.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005498184132156894\n",
      "Validation Loss: 0.002594998213619496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.18486561737954615\n",
      "Training Loss: 0.12700491454452276\n",
      "Training Loss: 0.09336452035233378\n",
      "Validation Loss: 0.071770807330528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0668552266433835\n",
      "Training Loss: 0.061618268992751836\n",
      "Training Loss: 0.06016616640612483\n",
      "Validation Loss: 0.055897335281197946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05658294150605798\n",
      "Training Loss: 0.05426382306031883\n",
      "Training Loss: 0.052184926094487306\n",
      "Validation Loss: 0.04707868956029415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04689210135489702\n",
      "Training Loss: 0.04381046013906598\n",
      "Training Loss: 0.0405768514610827\n",
      "Validation Loss: 0.034883367672060316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03440839434042573\n",
      "Training Loss: 0.03193762496113777\n",
      "Training Loss: 0.028869577115401626\n",
      "Validation Loss: 0.02397450322306223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.024095098674297332\n",
      "Training Loss: 0.023246348570100963\n",
      "Training Loss: 0.021073480886407196\n",
      "Validation Loss: 0.01734499412515525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01808095700573176\n",
      "Training Loss: 0.018352006594650448\n",
      "Training Loss: 0.016834442522376775\n",
      "Validation Loss: 0.013724235043431936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014851868031546473\n",
      "Training Loss: 0.015490675019100309\n",
      "Training Loss: 0.014329018569551408\n",
      "Validation Loss: 0.011491122472445282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.012914101488422602\n",
      "Training Loss: 0.01365475882543251\n",
      "Training Loss: 0.012801423525670543\n",
      "Validation Loss: 0.010128919992679626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011742591595975682\n",
      "Training Loss: 0.012497155105229467\n",
      "Training Loss: 0.011844089698279277\n",
      "Validation Loss: 0.009193278401776145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010942638578126208\n",
      "Training Loss: 0.011657943499740213\n",
      "Training Loss: 0.011142647843807935\n",
      "Validation Loss: 0.008457318955530108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010327963249292225\n",
      "Training Loss: 0.010986981105525047\n",
      "Training Loss: 0.010568684479221702\n",
      "Validation Loss: 0.007831778709536021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009806771213188768\n",
      "Training Loss: 0.010401982176117599\n",
      "Training Loss: 0.010051056452794001\n",
      "Validation Loss: 0.007263288056226761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009334373358869925\n",
      "Training Loss: 0.009868456398835405\n",
      "Training Loss: 0.009574526636861265\n",
      "Validation Loss: 0.006747964152208205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008912780702812597\n",
      "Training Loss: 0.009392724835779518\n",
      "Training Loss: 0.009153634823160246\n",
      "Validation Loss: 0.006304774145606194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008555668060434982\n",
      "Training Loss: 0.008988875029608608\n",
      "Training Loss: 0.008801513558719307\n",
      "Validation Loss: 0.005946005398951722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008269048341317102\n",
      "Training Loss: 0.008662997415522114\n",
      "Training Loss: 0.008520491435192526\n",
      "Validation Loss: 0.005667746030422074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008047717966837809\n",
      "Training Loss: 0.008409159571165219\n",
      "Training Loss: 0.008301738045411185\n",
      "Validation Loss: 0.005452796011074876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007878282109741121\n",
      "Training Loss: 0.008212987075094134\n",
      "Training Loss: 0.008130783039378002\n",
      "Validation Loss: 0.005281360694364215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007746108913561329\n",
      "Training Loss: 0.008059043261455371\n",
      "Training Loss: 0.007994173226179555\n",
      "Validation Loss: 0.005138618608654132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007639944095863029\n",
      "Training Loss: 0.007935269854497164\n",
      "Training Loss: 0.007882212072145194\n",
      "Validation Loss: 0.005015625995112939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007552411704091355\n",
      "Training Loss: 0.007833471649792045\n",
      "Training Loss: 0.007788571441778913\n",
      "Validation Loss: 0.004907390882334347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007478866870515049\n",
      "Training Loss: 0.007748264307156205\n",
      "Training Loss: 0.007709122602827847\n",
      "Validation Loss: 0.004811074538941212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007416277270531282\n",
      "Training Loss: 0.007676019702339545\n",
      "Training Loss: 0.0076410302182193844\n",
      "Validation Loss: 0.00472489918916999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00736253302777186\n",
      "Training Loss: 0.007614168244181201\n",
      "Training Loss: 0.0075822232977952805\n",
      "Validation Loss: 0.00464761155406327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007316064855549484\n",
      "Training Loss: 0.0075607981835491955\n",
      "Training Loss: 0.007531101530184969\n",
      "Validation Loss: 0.004578214880403424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007275642327731475\n",
      "Training Loss: 0.007514422344975173\n",
      "Training Loss: 0.007486383450450376\n",
      "Validation Loss: 0.004515852632649829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007240267002489417\n",
      "Training Loss: 0.007473853019764647\n",
      "Training Loss: 0.007447018882958218\n",
      "Validation Loss: 0.004459770187065842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007209114668658003\n",
      "Training Loss: 0.00743812078027986\n",
      "Training Loss: 0.007412135958438739\n",
      "Validation Loss: 0.004409278460432974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007181496171979234\n",
      "Training Loss: 0.007406427129171789\n",
      "Training Loss: 0.007381007020594552\n",
      "Validation Loss: 0.004363754212207506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007156833544140682\n",
      "Training Loss: 0.007378110098652541\n",
      "Training Loss: 0.007353024397743866\n",
      "Validation Loss: 0.004322637373508279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007134642989840358\n",
      "Training Loss: 0.007352618544828147\n",
      "Training Loss: 0.0073276799148879945\n",
      "Validation Loss: 0.0042854187855748144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007114519817987457\n",
      "Training Loss: 0.007329495227895677\n",
      "Training Loss: 0.007304549072869122\n",
      "Validation Loss: 0.004251648862898517\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007096125544048846\n",
      "Training Loss: 0.007308359673479572\n",
      "Training Loss: 0.007283278590766713\n",
      "Validation Loss: 0.004220920813719878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0070791796001140024\n",
      "Training Loss: 0.0072888934472575785\n",
      "Training Loss: 0.0072635732393246145\n",
      "Validation Loss: 0.0041928782449574785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007063448022818193\n",
      "Training Loss: 0.00727083463105373\n",
      "Training Loss: 0.007245188363594934\n",
      "Validation Loss: 0.0041672033401666565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007048736994620413\n",
      "Training Loss: 0.007253964733099565\n",
      "Training Loss: 0.007227920577861369\n",
      "Validation Loss: 0.004143618059009732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007034887499175965\n",
      "Training Loss: 0.0072381031082477424\n",
      "Training Loss: 0.007211601301096379\n",
      "Validation Loss: 0.004121879413933232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007021768154809252\n",
      "Training Loss: 0.007223098581889644\n",
      "Training Loss: 0.007196091091027483\n",
      "Validation Loss: 0.0041017699908214005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007009269638219848\n",
      "Training Loss: 0.007208828093716875\n",
      "Training Loss: 0.00718127484433353\n",
      "Validation Loss: 0.004083101321116425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.006997303475509397\n",
      "Training Loss: 0.007195187842007726\n",
      "Training Loss: 0.007167055883910507\n",
      "Validation Loss: 0.004065710504466061\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.006985796357039362\n",
      "Training Loss: 0.007182093783048913\n",
      "Training Loss: 0.007153354696929455\n",
      "Validation Loss: 0.004049453497184127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.006974687855690717\n",
      "Training Loss: 0.007169472347013653\n",
      "Training Loss: 0.0071401050908025355\n",
      "Validation Loss: 0.004034202630903697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006963927570031956\n",
      "Training Loss: 0.00715726564405486\n",
      "Training Loss: 0.0071272526786196975\n",
      "Validation Loss: 0.004019849770179207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006953475557966157\n",
      "Training Loss: 0.0071454251767136155\n",
      "Training Loss: 0.007114751387853176\n",
      "Validation Loss: 0.004006294544074643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006943296680692584\n",
      "Training Loss: 0.007133909136755392\n",
      "Training Loss: 0.0071025627246126535\n",
      "Validation Loss: 0.003993454885020266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006933363461284898\n",
      "Training Loss: 0.007122682628687471\n",
      "Training Loss: 0.007090654744533822\n",
      "Validation Loss: 0.003981252147271978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006923652662080713\n",
      "Training Loss: 0.0071117167256306854\n",
      "Training Loss: 0.007079000305384398\n",
      "Validation Loss: 0.0039696222749339895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00691414347209502\n",
      "Training Loss: 0.007100986059522256\n",
      "Training Loss: 0.007067575701512396\n",
      "Validation Loss: 0.003958504871998945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006904819220653735\n",
      "Training Loss: 0.0070904697861988095\n",
      "Training Loss: 0.0070563620189204816\n",
      "Validation Loss: 0.003947852737940011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006895665265037678\n",
      "Training Loss: 0.007080149800749495\n",
      "Training Loss: 0.007045340888435021\n",
      "Validation Loss: 0.003937615848177772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006886669616797007\n",
      "Training Loss: 0.00707000907859765\n",
      "Training Loss: 0.007034497963613831\n",
      "Validation Loss: 0.003927756146674327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006877821145462803\n",
      "Training Loss: 0.0070600337535142894\n",
      "Training Loss: 0.007023820186732337\n",
      "Validation Loss: 0.0039182362196381005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006869109199033119\n",
      "Training Loss: 0.007050211630994454\n",
      "Training Loss: 0.007013295178767294\n",
      "Validation Loss: 0.003909028353682311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0068605253228452056\n",
      "Training Loss: 0.007040530913509428\n",
      "Training Loss: 0.007002912569441832\n",
      "Validation Loss: 0.003900098921783436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006852061245008372\n",
      "Training Loss: 0.007030981450807303\n",
      "Training Loss: 0.006992662756820209\n",
      "Validation Loss: 0.0038914221699946046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006843708996311762\n",
      "Training Loss: 0.007021553522208706\n",
      "Training Loss: 0.006982536116265692\n",
      "Validation Loss: 0.0038829775019601155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006835461313021369\n",
      "Training Loss: 0.007012237906455994\n",
      "Training Loss: 0.006972524725133553\n",
      "Validation Loss: 0.0038747388144871327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006827311008237302\n",
      "Training Loss: 0.007003027190221473\n",
      "Training Loss: 0.006962621168931946\n",
      "Validation Loss: 0.003866694144266291\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006819252303685062\n",
      "Training Loss: 0.0069939139985945075\n",
      "Training Loss: 0.006952819097787142\n",
      "Validation Loss: 0.003858822052565853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0068112794461194425\n",
      "Training Loss: 0.006984890766907483\n",
      "Training Loss: 0.006943109735730104\n",
      "Validation Loss: 0.0038511080751090906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0068033845216268676\n",
      "Training Loss: 0.006975949674379081\n",
      "Training Loss: 0.006933487430214882\n",
      "Validation Loss: 0.0038435364042649443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006795562484767288\n",
      "Training Loss: 0.006967084918869659\n",
      "Training Loss: 0.006923945160815492\n",
      "Validation Loss: 0.0038360925325914546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.00678780676680617\n",
      "Training Loss: 0.006958289085887372\n",
      "Training Loss: 0.0069144776632310825\n",
      "Validation Loss: 0.003828768386882259\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006780111939297058\n",
      "Training Loss: 0.006949556337203831\n",
      "Training Loss: 0.00690507783961948\n",
      "Validation Loss: 0.0038215474152330604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006772472108714282\n",
      "Training Loss: 0.006940882245544344\n",
      "Training Loss: 0.006895741409971378\n",
      "Validation Loss: 0.0038144232043368594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006764881524140946\n",
      "Training Loss: 0.0069322586781345305\n",
      "Training Loss: 0.006886461865506135\n",
      "Validation Loss: 0.0038073822160073546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006757335183210671\n",
      "Training Loss: 0.006923681908519938\n",
      "Training Loss: 0.0068772354710381475\n",
      "Validation Loss: 0.003800414645196765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0067498280620202425\n",
      "Training Loss: 0.006915146026294679\n",
      "Training Loss: 0.006868055838276632\n",
      "Validation Loss: 0.003793513178668414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006742353801382705\n",
      "Training Loss: 0.006906645734561607\n",
      "Training Loss: 0.006858918501529842\n",
      "Validation Loss: 0.00378666823635694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0067349077470134945\n",
      "Training Loss: 0.006898176571121439\n",
      "Training Loss: 0.006849819403723814\n",
      "Validation Loss: 0.0037798696914373825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006727484348230064\n",
      "Training Loss: 0.006889733364805579\n",
      "Training Loss: 0.006840753588476218\n",
      "Validation Loss: 0.0037731127865779936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006720080062514171\n",
      "Training Loss: 0.006881311913020909\n",
      "Training Loss: 0.0068317178421420975\n",
      "Validation Loss: 0.0037663885224819855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006712689193082042\n",
      "Training Loss: 0.006872907201759517\n",
      "Training Loss: 0.0068227062450023366\n",
      "Validation Loss: 0.003759693992690424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006705307143274695\n",
      "Training Loss: 0.006864517112262547\n",
      "Training Loss: 0.00681371706945356\n",
      "Validation Loss: 0.0037530173568494536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006697930164518766\n",
      "Training Loss: 0.0068561353825498375\n",
      "Training Loss: 0.006804744664113968\n",
      "Validation Loss: 0.003746351201003522\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006690552626969293\n",
      "Training Loss: 0.006847757984651252\n",
      "Training Loss: 0.006795786618604325\n",
      "Validation Loss: 0.003739692804434996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006683171208715066\n",
      "Training Loss: 0.006839381891768426\n",
      "Training Loss: 0.006786838059779257\n",
      "Validation Loss: 0.003733031884662472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006675780297373421\n",
      "Training Loss: 0.006831003243569285\n",
      "Training Loss: 0.0067778969090431926\n",
      "Validation Loss: 0.003726368450842212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006668377760797739\n",
      "Training Loss: 0.006822618918959051\n",
      "Training Loss: 0.006768958728061989\n",
      "Validation Loss: 0.003719689168841735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006660957799758762\n",
      "Training Loss: 0.0068142247456125914\n",
      "Training Loss: 0.006760021732188762\n",
      "Validation Loss: 0.0037129961459091707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006653518176171928\n",
      "Training Loss: 0.006805818255525082\n",
      "Training Loss: 0.00675108177762013\n",
      "Validation Loss: 0.0037062819746291535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006646053653676063\n",
      "Training Loss: 0.0067973939410876484\n",
      "Training Loss: 0.006742136297980324\n",
      "Validation Loss: 0.0036995376727093805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006638561297440901\n",
      "Training Loss: 0.006788950487971306\n",
      "Training Loss: 0.0067331820714753125\n",
      "Validation Loss: 0.0036927617568355262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0066310370701830835\n",
      "Training Loss: 0.006780484752962366\n",
      "Training Loss: 0.00672421571565792\n",
      "Validation Loss: 0.0036859511491957675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006623476933455095\n",
      "Training Loss: 0.006771993322763592\n",
      "Training Loss: 0.006715235219453461\n",
      "Validation Loss: 0.0036790970100738694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.00661587776907254\n",
      "Training Loss: 0.006763471701415256\n",
      "Training Loss: 0.006706237203907221\n",
      "Validation Loss: 0.0036721975893158924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00660823677899316\n",
      "Training Loss: 0.00675491833826527\n",
      "Training Loss: 0.006697219297639095\n",
      "Validation Loss: 0.0036652500419406576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.0066005500801838935\n",
      "Training Loss: 0.006746330292662606\n",
      "Training Loss: 0.006688178843469359\n",
      "Validation Loss: 0.003658249466732312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006592814474133775\n",
      "Training Loss: 0.006737706300336868\n",
      "Training Loss: 0.006679112981073558\n",
      "Validation Loss: 0.0036511918427841214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006585026948014275\n",
      "Training Loss: 0.006729041730286553\n",
      "Training Loss: 0.006670020221499726\n",
      "Validation Loss: 0.003644075871215024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006577185990754515\n",
      "Training Loss: 0.0067203348444309086\n",
      "Training Loss: 0.006660897273686715\n",
      "Validation Loss: 0.0036368964022820754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006569286422454752\n",
      "Training Loss: 0.006711582123534754\n",
      "Training Loss: 0.0066517418250441555\n",
      "Validation Loss: 0.003629651432072095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006561326382216066\n",
      "Training Loss: 0.006702783830696717\n",
      "Training Loss: 0.006642551735858433\n",
      "Validation Loss: 0.0036223393608554363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006553304556873627\n",
      "Training Loss: 0.006693934595678002\n",
      "Training Loss: 0.006633324627764523\n",
      "Validation Loss: 0.0036149535856596876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006545216629165225\n",
      "Training Loss: 0.006685034831753001\n",
      "Training Loss: 0.006624058189918287\n",
      "Validation Loss: 0.0036074981901773745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006537060585105792\n",
      "Training Loss: 0.006676080280449241\n",
      "Training Loss: 0.0066147501108935105\n",
      "Validation Loss: 0.0035999654242873528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006528834787895903\n",
      "Training Loss: 0.006667070566909388\n",
      "Training Loss: 0.006605398673564196\n",
      "Validation Loss: 0.003592356269017615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006520536612952128\n",
      "Training Loss: 0.006658003152115271\n",
      "Training Loss: 0.006596001830766909\n",
      "Validation Loss: 0.0035846670487832822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.00651216447702609\n",
      "Training Loss: 0.0066488773364108055\n",
      "Training Loss: 0.00658655853534583\n",
      "Validation Loss: 0.0035768977714325774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006503717490122653\n",
      "Training Loss: 0.006639690621523186\n",
      "Training Loss: 0.006577066068421118\n",
      "Validation Loss: 0.0035690462878601773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.0064951925945933905\n",
      "Training Loss: 0.006630441335728392\n",
      "Training Loss: 0.006567523144185543\n",
      "Validation Loss: 0.0035611120343019957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006486588788102381\n",
      "Training Loss: 0.006621129282284528\n",
      "Training Loss: 0.0065579285495914515\n",
      "Validation Loss: 0.003553093705336783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006477906046784483\n",
      "Training Loss: 0.006611752646276728\n",
      "Training Loss: 0.006548280395800248\n",
      "Validation Loss: 0.0035449905292225187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006469142435817048\n",
      "Training Loss: 0.006602312602335587\n",
      "Training Loss: 0.006538579571642913\n",
      "Validation Loss: 0.0035368027701827413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006460298989550211\n",
      "Training Loss: 0.0065928085730411114\n",
      "Training Loss: 0.006528825340792537\n",
      "Validation Loss: 0.003528532670193425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0064513741270639\n",
      "Training Loss: 0.0065832381963264195\n",
      "Training Loss: 0.006519014384830371\n",
      "Validation Loss: 0.003520178111542142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006442367750569247\n",
      "Training Loss: 0.006573603336000815\n",
      "Training Loss: 0.00650914846395608\n",
      "Validation Loss: 0.0035117374304054158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.0064332791353808715\n",
      "Training Loss: 0.0065639027627184985\n",
      "Training Loss: 0.0064992276713019236\n",
      "Validation Loss: 0.0035032147235561457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006424110612133518\n",
      "Training Loss: 0.006554138063220308\n",
      "Training Loss: 0.006489250526065007\n",
      "Validation Loss: 0.00349460977647621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006414861578959972\n",
      "Training Loss: 0.006544310247991234\n",
      "Training Loss: 0.006479218993335962\n",
      "Validation Loss: 0.0034859250535079268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006405534176738001\n",
      "Training Loss: 0.006534418318187818\n",
      "Training Loss: 0.006469131503254175\n",
      "Validation Loss: 0.0034771580549919708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.0063961276132613425\n",
      "Training Loss: 0.0065244653343688695\n",
      "Training Loss: 0.006458991377730854\n",
      "Validation Loss: 0.0034683146919490078\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.0063866456830874085\n",
      "Training Loss: 0.006514452832052484\n",
      "Training Loss: 0.0064487983006984\n",
      "Validation Loss: 0.0034593960565902043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.00637708897003904\n",
      "Training Loss: 0.006504382544662803\n",
      "Training Loss: 0.0064385546586709095\n",
      "Validation Loss: 0.003450402292799665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.00636746060103178\n",
      "Training Loss: 0.006494255933212116\n",
      "Training Loss: 0.006428262274712324\n",
      "Validation Loss: 0.003441336456152579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006357762324041687\n",
      "Training Loss: 0.0064840763388201595\n",
      "Training Loss: 0.006417922039399854\n",
      "Validation Loss: 0.003432204874933519\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006347996512195095\n",
      "Training Loss: 0.006473847120068967\n",
      "Training Loss: 0.006407537186169066\n",
      "Validation Loss: 0.0034230079428617206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006338167368085124\n",
      "Training Loss: 0.006463568840408698\n",
      "Training Loss: 0.00639711048163008\n",
      "Validation Loss: 0.0034137492832005695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006328277994180098\n",
      "Training Loss: 0.006453248296165839\n",
      "Training Loss: 0.006386644820449874\n",
      "Validation Loss: 0.0034044342432066462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006318332679220475\n",
      "Training Loss: 0.0064428863429930065\n",
      "Training Loss: 0.006376143186935223\n",
      "Validation Loss: 0.003395066162299239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006308334071654827\n",
      "Training Loss: 0.006432488647988066\n",
      "Training Loss: 0.006365609930944629\n",
      "Validation Loss: 0.0033856472353649774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006298288208199665\n",
      "Training Loss: 0.006422060040058568\n",
      "Training Loss: 0.006355049048434012\n",
      "Validation Loss: 0.0033761848658951147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.0062881990207824855\n",
      "Training Loss: 0.006411603260785341\n",
      "Training Loss: 0.006344462892157026\n",
      "Validation Loss: 0.0033666825842823874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006278071345877834\n",
      "Training Loss: 0.0064011246513109655\n",
      "Training Loss: 0.006333858193247579\n",
      "Validation Loss: 0.0033571458424263624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006267910527531058\n",
      "Training Loss: 0.0063906291278544814\n",
      "Training Loss: 0.0063232388778124\n",
      "Validation Loss: 0.003347580245266972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006257722040172667\n",
      "Training Loss: 0.006380121657857671\n",
      "Training Loss: 0.006312610078603029\n",
      "Validation Loss: 0.0033379931151971557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006247512711561285\n",
      "Training Loss: 0.006369611016707495\n",
      "Training Loss: 0.0063019773329142485\n",
      "Validation Loss: 0.0033283884234182287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006237286867690273\n",
      "Training Loss: 0.006359098519897089\n",
      "Training Loss: 0.006291346239158883\n",
      "Validation Loss: 0.003318767774891987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.0062270512420218435\n",
      "Training Loss: 0.006348592449212447\n",
      "Training Loss: 0.0062807213253108785\n",
      "Validation Loss: 0.00330914358550871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006216811141348444\n",
      "Training Loss: 0.006338099523563869\n",
      "Training Loss: 0.006270110855693929\n",
      "Validation Loss: 0.003299524507935295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006206576973199845\n",
      "Training Loss: 0.006327625693520531\n",
      "Training Loss: 0.006259518882725388\n",
      "Validation Loss: 0.0032899099574790576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0061963514686794955\n",
      "Training Loss: 0.006317178445169702\n",
      "Training Loss: 0.006248952883761376\n",
      "Validation Loss: 0.003280307474975171\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006186142809456214\n",
      "Training Loss: 0.006306761531159282\n",
      "Training Loss: 0.006238417928107083\n",
      "Validation Loss: 0.0032707227477699182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006175956606166437\n",
      "Training Loss: 0.006296385658206418\n",
      "Training Loss: 0.006227921463432722\n",
      "Validation Loss: 0.0032611661093581595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006165801336755976\n",
      "Training Loss: 0.006286053716903553\n",
      "Training Loss: 0.006217468439717777\n",
      "Validation Loss: 0.003251638517223215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006155682469252497\n",
      "Training Loss: 0.00627577441628091\n",
      "Training Loss: 0.006207065196940675\n",
      "Validation Loss: 0.0032421477646514606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0061456058651674535\n",
      "Training Loss: 0.006265552253462374\n",
      "Training Loss: 0.006196717944112607\n",
      "Validation Loss: 0.003232699869922624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.00613557880744338\n",
      "Training Loss: 0.006255395510233939\n",
      "Training Loss: 0.006186433458933607\n",
      "Validation Loss: 0.00322330307628792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006125607917783782\n",
      "Training Loss: 0.006245310163358227\n",
      "Training Loss: 0.006176216836902313\n",
      "Validation Loss: 0.00321395999328181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006115698858629912\n",
      "Training Loss: 0.006235300189582631\n",
      "Training Loss: 0.006166073717176914\n",
      "Validation Loss: 0.0032046761970674054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006105857923976146\n",
      "Training Loss: 0.00622537252609618\n",
      "Training Loss: 0.006156009856495075\n",
      "Validation Loss: 0.0031954542186969285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006096090764622204\n",
      "Training Loss: 0.006215532735805027\n",
      "Training Loss: 0.006146030543604865\n",
      "Validation Loss: 0.003186306068569087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006086402524961159\n",
      "Training Loss: 0.006205785506172106\n",
      "Training Loss: 0.006136140010203235\n",
      "Validation Loss: 0.003177232034452092\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006076799620059319\n",
      "Training Loss: 0.006196136921062134\n",
      "Training Loss: 0.006126345286611467\n",
      "Validation Loss: 0.0031682341974333264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.0060672863910440356\n",
      "Training Loss: 0.006186591304722242\n",
      "Training Loss: 0.006116648734896444\n",
      "Validation Loss: 0.003159320252696366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006057866330374964\n",
      "Training Loss: 0.0061771510826656596\n",
      "Training Loss: 0.0061070551100419835\n",
      "Validation Loss: 0.0031504902002412113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006048546545207501\n",
      "Training Loss: 0.006167821175185963\n",
      "Training Loss: 0.006097567518008873\n",
      "Validation Loss: 0.003141749883070588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.0060393286042381075\n",
      "Training Loss: 0.006158604817464948\n",
      "Training Loss: 0.006088190291775391\n",
      "Validation Loss: 0.003133099949971009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0060302154161036015\n",
      "Training Loss: 0.006149505628272891\n",
      "Training Loss: 0.006078925128094852\n",
      "Validation Loss: 0.003124544712233493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006021212538471445\n",
      "Training Loss: 0.00614052520133555\n",
      "Training Loss: 0.006069776475778781\n",
      "Validation Loss: 0.0031160871391027662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006012320783920586\n",
      "Training Loss: 0.006131666557048447\n",
      "Training Loss: 0.006060744537389837\n",
      "Validation Loss: 0.0031077267963104368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0060035440657520665\n",
      "Training Loss: 0.006122930137207732\n",
      "Training Loss: 0.006051833558594808\n",
      "Validation Loss: 0.0030994682018174215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.0059948850475484506\n",
      "Training Loss: 0.006114320503547788\n",
      "Training Loss: 0.006043044222169555\n",
      "Validation Loss: 0.003091310105794057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005986344299744814\n",
      "Training Loss: 0.006105836475035176\n",
      "Training Loss: 0.006034377782489173\n",
      "Validation Loss: 0.003083253563826464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005977924129110761\n",
      "Training Loss: 0.006097480181488209\n",
      "Training Loss: 0.006025835533509962\n",
      "Validation Loss: 0.0030753019807357967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005969625403522514\n",
      "Training Loss: 0.006089250778313726\n",
      "Training Loss: 0.006017418865230866\n",
      "Validation Loss: 0.003067458935966192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0059614499716553835\n",
      "Training Loss: 0.006081150990794413\n",
      "Training Loss: 0.0060091270395787435\n",
      "Validation Loss: 0.003059716461608291\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005953396701952443\n",
      "Training Loss: 0.006073177128564566\n",
      "Training Loss: 0.006000959537923336\n",
      "Validation Loss: 0.003052077242408701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005945467043784447\n",
      "Training Loss: 0.006065332182915881\n",
      "Training Loss: 0.005992918766569346\n",
      "Validation Loss: 0.003044547673361899\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005937661483185366\n",
      "Training Loss: 0.006057613292359747\n",
      "Training Loss: 0.005985002728411928\n",
      "Validation Loss: 0.003037120093293279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0059299795236438515\n",
      "Training Loss: 0.006050021136761643\n",
      "Training Loss: 0.0059772111318307\n",
      "Validation Loss: 0.0030298002987702408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005922420789720491\n",
      "Training Loss: 0.006042556748143397\n",
      "Training Loss: 0.005969545042607933\n",
      "Validation Loss: 0.003022582424553425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.0059149851708207276\n",
      "Training Loss: 0.006035215150332078\n",
      "Training Loss: 0.0059620009793434296\n",
      "Validation Loss: 0.003015470801554411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005907671724562533\n",
      "Training Loss: 0.00602799704996869\n",
      "Training Loss: 0.00595458046591375\n",
      "Validation Loss: 0.0030084629046071448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005900479668052867\n",
      "Training Loss: 0.006020900658331812\n",
      "Training Loss: 0.005947279628016986\n",
      "Validation Loss: 0.003001556104556605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005893406416289508\n",
      "Training Loss: 0.006013923665159382\n",
      "Training Loss: 0.005940099156578072\n",
      "Validation Loss: 0.0029947529612318353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.0058864526468096305\n",
      "Training Loss: 0.006007065364392474\n",
      "Training Loss: 0.005933036564383656\n",
      "Validation Loss: 0.0029880493602014325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005879616585443728\n",
      "Training Loss: 0.006000324063934386\n",
      "Training Loss: 0.00592609153536614\n",
      "Validation Loss: 0.002981446201395076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0058728967909701165\n",
      "Training Loss: 0.0059936988051049415\n",
      "Training Loss: 0.005919261772651225\n",
      "Validation Loss: 0.0029749429354370897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.00586629202356562\n",
      "Training Loss: 0.005987185583217069\n",
      "Training Loss: 0.0059125457552727315\n",
      "Validation Loss: 0.0029685367552793763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005859800283215009\n",
      "Training Loss: 0.005980782511178404\n",
      "Training Loss: 0.0059059405350126324\n",
      "Validation Loss: 0.0029622302678403226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005853419270715676\n",
      "Training Loss: 0.005974490059306845\n",
      "Training Loss: 0.0058994468598393725\n",
      "Validation Loss: 0.0029560177772714013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005847148765460588\n",
      "Training Loss: 0.005968304177513346\n",
      "Training Loss: 0.005893060862435959\n",
      "Validation Loss: 0.0029498991455746753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.00584098540188279\n",
      "Training Loss: 0.0059622231940738854\n",
      "Training Loss: 0.005886781529989093\n",
      "Validation Loss: 0.0029438762949109912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005834928681724705\n",
      "Training Loss: 0.005956245721317827\n",
      "Training Loss: 0.005880606702412479\n",
      "Validation Loss: 0.002937945694233594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005828976753400638\n",
      "Training Loss: 0.0059503693587612365\n",
      "Training Loss: 0.005874535178299993\n",
      "Validation Loss: 0.002932105615625179\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005823127164039761\n",
      "Training Loss: 0.0059445924637839195\n",
      "Training Loss: 0.005868565441342071\n",
      "Validation Loss: 0.002926355539140909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005817378197680228\n",
      "Training Loss: 0.005938912024721504\n",
      "Training Loss: 0.0058626950444886465\n",
      "Validation Loss: 0.002920695069099494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005811729381675832\n",
      "Training Loss: 0.005933326660306193\n",
      "Training Loss: 0.005856921803206206\n",
      "Validation Loss: 0.0029151217548930076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005806176284095272\n",
      "Training Loss: 0.005927834811154753\n",
      "Training Loss: 0.0058512445806991305\n",
      "Validation Loss: 0.002909635017714934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.0058007190155331045\n",
      "Training Loss: 0.005922434313106351\n",
      "Training Loss: 0.005845660597551614\n",
      "Validation Loss: 0.0029042329203619968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005795354774454609\n",
      "Training Loss: 0.005917123003164306\n",
      "Training Loss: 0.005840169132570736\n",
      "Validation Loss: 0.0028989147506078726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.00579008194967173\n",
      "Training Loss: 0.005911898674094118\n",
      "Training Loss: 0.0058347681973828\n",
      "Validation Loss: 0.0028936801271596817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005784899157006294\n",
      "Training Loss: 0.005906760325306095\n",
      "Training Loss: 0.005829455209313892\n",
      "Validation Loss: 0.0028885260951611097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005779803531477228\n",
      "Training Loss: 0.005901705356081948\n",
      "Training Loss: 0.005824229014688171\n",
      "Validation Loss: 0.0028834509365051313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005774794336175546\n",
      "Training Loss: 0.005896733291447163\n",
      "Training Loss: 0.005819088347489014\n",
      "Validation Loss: 0.002878455239154524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005769870029762387\n",
      "Training Loss: 0.005891840562107973\n",
      "Training Loss: 0.005814030828769318\n",
      "Validation Loss: 0.002873536310514456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005765027650631964\n",
      "Training Loss: 0.005887026306590997\n",
      "Training Loss: 0.005809054692508653\n",
      "Validation Loss: 0.002868694068832595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005760265620774589\n",
      "Training Loss: 0.005882289253058844\n",
      "Training Loss: 0.005804159733233973\n",
      "Validation Loss: 0.002863926648847717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.0057555833319202065\n",
      "Training Loss: 0.005877626973669976\n",
      "Training Loss: 0.005799342495156452\n",
      "Validation Loss: 0.0028592355659210617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0057509790430776775\n",
      "Training Loss: 0.005873039016732946\n",
      "Training Loss: 0.005794602337409742\n",
      "Validation Loss: 0.002854613076471671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0057464504725066945\n",
      "Training Loss: 0.005868521790835075\n",
      "Training Loss: 0.005789938118541613\n",
      "Validation Loss: 0.002850062543463506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0057419961679261175\n",
      "Training Loss: 0.00586407589376904\n",
      "Training Loss: 0.005785347222117707\n",
      "Validation Loss: 0.0028455832500921124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005737614665413275\n",
      "Training Loss: 0.005859698124113493\n",
      "Training Loss: 0.005780828662682325\n",
      "Validation Loss: 0.002841170272250984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005733304253662936\n",
      "Training Loss: 0.005855387503397651\n",
      "Training Loss: 0.005776380128809251\n",
      "Validation Loss: 0.0028368254425004125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0057290628884220495\n",
      "Training Loss: 0.005851143030449748\n",
      "Training Loss: 0.00577200160943903\n",
      "Validation Loss: 0.0028325481722236015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005724889664561488\n",
      "Training Loss: 0.005846963393269107\n",
      "Training Loss: 0.005767692237277515\n",
      "Validation Loss: 0.0028283369369030502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005720784710138105\n",
      "Training Loss: 0.005842846750747413\n",
      "Training Loss: 0.005763448938960209\n",
      "Validation Loss: 0.0028241884285123663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005716744482051581\n",
      "Training Loss: 0.005838792524882592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [27:25<06:50, 205.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005759271210408769\n",
      "Validation Loss: 0.0028201040898167182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.11232005413621664\n",
      "Training Loss: 0.08758618043735623\n",
      "Training Loss: 0.07547678032889962\n",
      "Validation Loss: 0.06422580753484469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0664778776653111\n",
      "Training Loss: 0.06451383735984564\n",
      "Training Loss: 0.06324747920036317\n",
      "Validation Loss: 0.05818397455503432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.060777401085942984\n",
      "Training Loss: 0.059197534043341875\n",
      "Training Loss: 0.05720915671437979\n",
      "Validation Loss: 0.05170649532856566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.053659900277853015\n",
      "Training Loss: 0.05158673951402307\n",
      "Training Loss: 0.0486476234998554\n",
      "Validation Loss: 0.042841318304116804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04396767245605588\n",
      "Training Loss: 0.041838171612471345\n",
      "Training Loss: 0.038437905749306084\n",
      "Validation Loss: 0.03309301584121886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.03357349670492113\n",
      "Training Loss: 0.032209626836702226\n",
      "Training Loss: 0.029181220321916043\n",
      "Validation Loss: 0.02485305799192257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.02510984650347382\n",
      "Training Loss: 0.024842693405225873\n",
      "Training Loss: 0.022582512595690787\n",
      "Validation Loss: 0.01913577141344882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.019527592814993115\n",
      "Training Loss: 0.020060300659388304\n",
      "Training Loss: 0.018459320024121553\n",
      "Validation Loss: 0.015465410023383546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01615301610669121\n",
      "Training Loss: 0.017032278913538902\n",
      "Training Loss: 0.015840248421300204\n",
      "Validation Loss: 0.012959073486036799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013991693719290196\n",
      "Training Loss: 0.014918376018758863\n",
      "Training Loss: 0.013980739023536444\n",
      "Validation Loss: 0.011071755252569244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012452803684864193\n",
      "Training Loss: 0.013306795284152031\n",
      "Training Loss: 0.012573932213708758\n",
      "Validation Loss: 0.009647468246226565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.01132969937636517\n",
      "Training Loss: 0.012088808909757063\n",
      "Training Loss: 0.011534284995868803\n",
      "Validation Loss: 0.008642179166814416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.010527663364773615\n",
      "Training Loss: 0.011196703035384416\n",
      "Training Loss: 0.010773912069853396\n",
      "Validation Loss: 0.007939004064589906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009937350992113353\n",
      "Training Loss: 0.01052519031916745\n",
      "Training Loss: 0.010194110327865928\n",
      "Validation Loss: 0.007410524104292808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009479004691820591\n",
      "Training Loss: 0.009996453116182238\n",
      "Training Loss: 0.009736111699603499\n",
      "Validation Loss: 0.006990163602730196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.00911510209320113\n",
      "Training Loss: 0.009577436364488677\n",
      "Training Loss: 0.00937435106257908\n",
      "Validation Loss: 0.006654982256253114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008828431485453621\n",
      "Training Loss: 0.009251304236240685\n",
      "Training Loss: 0.009092219826998189\n",
      "Validation Loss: 0.006391073951204674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008604776329593732\n",
      "Training Loss: 0.009000518595566973\n",
      "Training Loss: 0.008872786078136415\n",
      "Validation Loss: 0.0061835725948716815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008429847006918862\n",
      "Training Loss: 0.00880695094470866\n",
      "Training Loss: 0.008700247792294249\n",
      "Validation Loss: 0.006018179680712605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008291157911298797\n",
      "Training Loss: 0.008655073792906478\n",
      "Training Loss: 0.008561905708629637\n",
      "Validation Loss: 0.005883187228248695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008179014060879126\n",
      "Training Loss: 0.008533102663932368\n",
      "Training Loss: 0.008448377709137277\n",
      "Validation Loss: 0.005769895277184884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008086322679882869\n",
      "Training Loss: 0.0084326223062817\n",
      "Training Loss: 0.008353000736096874\n",
      "Validation Loss: 0.0056721910996509065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008008020458510146\n",
      "Training Loss: 0.00834776091040112\n",
      "Training Loss: 0.00827109863050282\n",
      "Validation Loss: 0.005585874446531695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007940511620836333\n",
      "Training Loss: 0.008274440047098324\n",
      "Training Loss: 0.008199382880702615\n",
      "Validation Loss: 0.005508090824600351\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007881235372042283\n",
      "Training Loss: 0.008209817303577439\n",
      "Training Loss: 0.00813553255284205\n",
      "Validation Loss: 0.005436894303355156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007828359520062804\n",
      "Training Loss: 0.008151895172195509\n",
      "Training Loss: 0.008077891402645037\n",
      "Validation Loss: 0.005370960565639681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00778056443319656\n",
      "Training Loss: 0.00809926463989541\n",
      "Training Loss: 0.008025275720283389\n",
      "Validation Loss: 0.005309384151393276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007736894724657759\n",
      "Training Loss: 0.008050925356801599\n",
      "Training Loss: 0.007976833913708105\n",
      "Validation Loss: 0.005251546207229408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007696657810593024\n",
      "Training Loss: 0.008006165445549414\n",
      "Training Loss: 0.007931947684846818\n",
      "Validation Loss: 0.005197020195257128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007659345695283264\n",
      "Training Loss: 0.007964474175823853\n",
      "Training Loss: 0.007890162509866058\n",
      "Validation Loss: 0.005145499406884728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007624577493406832\n",
      "Training Loss: 0.00792547410586849\n",
      "Training Loss: 0.007851135396631435\n",
      "Validation Loss: 0.0050967564071225145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007592059546150267\n",
      "Training Loss: 0.00788887550123036\n",
      "Training Loss: 0.007814595056697727\n",
      "Validation Loss: 0.005050603699284407\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007561557047301904\n",
      "Training Loss: 0.007854445056291298\n",
      "Training Loss: 0.0077803195384331045\n",
      "Validation Loss: 0.005006878812054402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007532871912699193\n",
      "Training Loss: 0.007821979171130805\n",
      "Training Loss: 0.0077481143618933854\n",
      "Validation Loss: 0.004965428015729936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007505832449533045\n",
      "Training Loss: 0.00779130237409845\n",
      "Training Loss: 0.007717809876194224\n",
      "Validation Loss: 0.004926113524275382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007480288100196048\n",
      "Training Loss: 0.007762255198322236\n",
      "Training Loss: 0.007689251193078235\n",
      "Validation Loss: 0.004888792121992185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007456103580771014\n",
      "Training Loss: 0.007734692343510687\n",
      "Training Loss: 0.007662295476766303\n",
      "Validation Loss: 0.004853333864528476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007433157378109172\n",
      "Training Loss: 0.0077084818598814305\n",
      "Training Loss: 0.007636812565615401\n",
      "Validation Loss: 0.004819606067194195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.00741133970906958\n",
      "Training Loss: 0.007683503528824076\n",
      "Training Loss: 0.007612681530881673\n",
      "Validation Loss: 0.004787483982469761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007390550564741716\n",
      "Training Loss: 0.007659649032866582\n",
      "Training Loss: 0.007589790020138026\n",
      "Validation Loss: 0.004756845671191728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007370699575403705\n",
      "Training Loss: 0.0076368184329476205\n",
      "Training Loss: 0.007568034949945286\n",
      "Validation Loss: 0.004727578236658671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0073517033085227015\n",
      "Training Loss: 0.007614920869236812\n",
      "Training Loss: 0.007547320275334641\n",
      "Validation Loss: 0.004699569586612117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007333485292037949\n",
      "Training Loss: 0.007593871045392006\n",
      "Training Loss: 0.007527555880369618\n",
      "Validation Loss: 0.004672715123847462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007315977587131784\n",
      "Training Loss: 0.007573595701251179\n",
      "Training Loss: 0.007508661373285577\n",
      "Validation Loss: 0.0046469169967085795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007299114519264549\n",
      "Training Loss: 0.0075540232530329375\n",
      "Training Loss: 0.007490559360012412\n",
      "Validation Loss: 0.004622082802822835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00728283851640299\n",
      "Training Loss: 0.0075350902241189035\n",
      "Training Loss: 0.0074731798726134\n",
      "Validation Loss: 0.0045981248997654135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007267095486167818\n",
      "Training Loss: 0.007516738368431106\n",
      "Training Loss: 0.0074564571725204585\n",
      "Validation Loss: 0.0045749646339439945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007251836875220761\n",
      "Training Loss: 0.007498916531912983\n",
      "Training Loss: 0.007440334435086697\n",
      "Validation Loss: 0.004552529268019068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007237018800806254\n",
      "Training Loss: 0.0074815746315289285\n",
      "Training Loss: 0.007424754978856072\n",
      "Validation Loss: 0.004530746764451098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007222600320819766\n",
      "Training Loss: 0.00746467100456357\n",
      "Training Loss: 0.007409669981570915\n",
      "Validation Loss: 0.004509557202050274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007208545494358986\n",
      "Training Loss: 0.007448165619280189\n",
      "Training Loss: 0.007395033022621646\n",
      "Validation Loss: 0.004488899675982721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007194820101140067\n",
      "Training Loss: 0.007432021435815841\n",
      "Training Loss: 0.007380803014384583\n",
      "Validation Loss: 0.004468723297056355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007181396636879072\n",
      "Training Loss: 0.007416209172224626\n",
      "Training Loss: 0.007366942378575913\n",
      "Validation Loss: 0.004448980804574624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007168246764922515\n",
      "Training Loss: 0.007400697643170133\n",
      "Training Loss: 0.007353415712714195\n",
      "Validation Loss: 0.0044296249038320076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007155346996150911\n",
      "Training Loss: 0.007385463108075783\n",
      "Training Loss: 0.007340192475239747\n",
      "Validation Loss: 0.004410618224202164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007142675862414762\n",
      "Training Loss: 0.007370479863602668\n",
      "Training Loss: 0.007327242769533769\n",
      "Validation Loss: 0.004391921197556043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0071302147593814875\n",
      "Training Loss: 0.007355727292597294\n",
      "Training Loss: 0.007314541824162007\n",
      "Validation Loss: 0.00437350319489167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007117946255020797\n",
      "Training Loss: 0.007341186925768853\n",
      "Training Loss: 0.007302064139512367\n",
      "Validation Loss: 0.004355334181056013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007105856067501009\n",
      "Training Loss: 0.007326842377660796\n",
      "Training Loss: 0.007289791104267351\n",
      "Validation Loss: 0.004337388963250213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007093930165283382\n",
      "Training Loss: 0.007312678702874109\n",
      "Training Loss: 0.007277700386475771\n",
      "Validation Loss: 0.004319640721476982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007082158609991893\n",
      "Training Loss: 0.007298682796536013\n",
      "Training Loss: 0.007265775988344103\n",
      "Validation Loss: 0.004302070421177182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007070530402706936\n",
      "Training Loss: 0.00728484260616824\n",
      "Training Loss: 0.007254001661785878\n",
      "Validation Loss: 0.004284658150098632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007059036965947598\n",
      "Training Loss: 0.00727114757639356\n",
      "Training Loss: 0.007242362875840627\n",
      "Validation Loss: 0.0042673871012697566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007047671559266746\n",
      "Training Loss: 0.007257590476656333\n",
      "Training Loss: 0.007230846489546821\n",
      "Validation Loss: 0.004250245865989016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00703642783802934\n",
      "Training Loss: 0.007244162707356736\n",
      "Training Loss: 0.007219441076740623\n",
      "Validation Loss: 0.0042332192330903715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00702529939240776\n",
      "Training Loss: 0.00723085438949056\n",
      "Training Loss: 0.007208135152468458\n",
      "Validation Loss: 0.004216297818714062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00701428278000094\n",
      "Training Loss: 0.007217663417104631\n",
      "Training Loss: 0.00719691923528444\n",
      "Validation Loss: 0.004199471764182777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007003374041523784\n",
      "Training Loss: 0.007204583022976294\n",
      "Training Loss: 0.007185785291367211\n",
      "Validation Loss: 0.004182734626104657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006992568767163903\n",
      "Training Loss: 0.007191609600558877\n",
      "Training Loss: 0.00717472430143971\n",
      "Validation Loss: 0.004166080220079238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006981865245616063\n",
      "Training Loss: 0.007178737685317174\n",
      "Training Loss: 0.007163728560553864\n",
      "Validation Loss: 0.004149505219767603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006971261195139959\n",
      "Training Loss: 0.00716596532263793\n",
      "Training Loss: 0.007152792013948783\n",
      "Validation Loss: 0.004133005040498932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006960753476014361\n",
      "Training Loss: 0.007153289233101532\n",
      "Training Loss: 0.007141907862387597\n",
      "Validation Loss: 0.0041165771472968914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006950339793693274\n",
      "Training Loss: 0.007140705669298768\n",
      "Training Loss: 0.00713107016752474\n",
      "Validation Loss: 0.004100221066651971\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006940018751192838\n",
      "Training Loss: 0.007128213269170374\n",
      "Training Loss: 0.00712027262954507\n",
      "Validation Loss: 0.004083934225654753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00692978753359057\n",
      "Training Loss: 0.00711580915376544\n",
      "Training Loss: 0.0071095098915975544\n",
      "Validation Loss: 0.004067719021937653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006919644279405474\n",
      "Training Loss: 0.007103489438304677\n",
      "Training Loss: 0.0070987761463038625\n",
      "Validation Loss: 0.004051574501941462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006909586357651278\n",
      "Training Loss: 0.007091254703700542\n",
      "Training Loss: 0.007088067562435753\n",
      "Validation Loss: 0.004035502457677313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006899611836997792\n",
      "Training Loss: 0.007079100055852905\n",
      "Training Loss: 0.007077378362882882\n",
      "Validation Loss: 0.0040195066654489615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0068897167826071385\n",
      "Training Loss: 0.007067026095464826\n",
      "Training Loss: 0.007066703333985061\n",
      "Validation Loss: 0.004003588225315796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006879898292245343\n",
      "Training Loss: 0.007055029209004715\n",
      "Training Loss: 0.007056038651498966\n",
      "Validation Loss: 0.003987752593101494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006870153619674965\n",
      "Training Loss: 0.007043107452336699\n",
      "Training Loss: 0.007045379144256003\n",
      "Validation Loss: 0.003972004726267514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006860478547168896\n",
      "Training Loss: 0.007031258944189176\n",
      "Training Loss: 0.00703472123190295\n",
      "Validation Loss: 0.003956346994977486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006850869029294699\n",
      "Training Loss: 0.007019479575101286\n",
      "Training Loss: 0.007024059616378508\n",
      "Validation Loss: 0.003940788125148399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006841320998501032\n",
      "Training Loss: 0.0070077703846618536\n",
      "Training Loss: 0.007013391182408668\n",
      "Validation Loss: 0.00392533178844102\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006831830291775987\n",
      "Training Loss: 0.006996126383310184\n",
      "Training Loss: 0.007002711845561862\n",
      "Validation Loss: 0.0039099861522404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006822391063906252\n",
      "Training Loss: 0.006984547202009707\n",
      "Training Loss: 0.006992018051678314\n",
      "Validation Loss: 0.00389475783390736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006812998618697747\n",
      "Training Loss: 0.0069730283692479135\n",
      "Training Loss: 0.006981305830995552\n",
      "Validation Loss: 0.0038796545626344475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006803648106288165\n",
      "Training Loss: 0.006961568533442914\n",
      "Training Loss: 0.006970571816782467\n",
      "Validation Loss: 0.0038646811650793872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006794332906138152\n",
      "Training Loss: 0.0069501639110967515\n",
      "Training Loss: 0.006959813180146739\n",
      "Validation Loss: 0.0038498459538193735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006785046727163718\n",
      "Training Loss: 0.0069388099631760266\n",
      "Training Loss: 0.006949025274952874\n",
      "Validation Loss: 0.003835155695331482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006775782613549382\n",
      "Training Loss: 0.00692750332178548\n",
      "Training Loss: 0.006938203593017533\n",
      "Validation Loss: 0.0038206150946259666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006766535450005904\n",
      "Training Loss: 0.0069162400567438454\n",
      "Training Loss: 0.00692734602256678\n",
      "Validation Loss: 0.0038062279293146193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006757296888390556\n",
      "Training Loss: 0.006905014653457328\n",
      "Training Loss: 0.006916446929099038\n",
      "Validation Loss: 0.0037919995558102814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006748059404781088\n",
      "Training Loss: 0.006893822445999831\n",
      "Training Loss: 0.00690550260595046\n",
      "Validation Loss: 0.0037779304175376057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006738815710414201\n",
      "Training Loss: 0.006882655690424145\n",
      "Training Loss: 0.00689450733945705\n",
      "Validation Loss: 0.003764021088724977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006729558034567163\n",
      "Training Loss: 0.006871507765026763\n",
      "Training Loss: 0.006883456244831904\n",
      "Validation Loss: 0.0037502719173103235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006720278011634946\n",
      "Training Loss: 0.006860371775692329\n",
      "Training Loss: 0.006872343155555427\n",
      "Validation Loss: 0.00373668263252992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006710967320250347\n",
      "Training Loss: 0.006849240603623912\n",
      "Training Loss: 0.006861162928980775\n",
      "Validation Loss: 0.003723248698110326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006701619210653007\n",
      "Training Loss: 0.0068381047761067746\n",
      "Training Loss: 0.006849909361335449\n",
      "Validation Loss: 0.0037099661899395705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.0066922250774223355\n",
      "Training Loss: 0.006826957586454228\n",
      "Training Loss: 0.006838576606241986\n",
      "Validation Loss: 0.0036968302538911446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.0066827770927920934\n",
      "Training Loss: 0.006815789951942861\n",
      "Training Loss: 0.006827158705564215\n",
      "Validation Loss: 0.003683834615310005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.0066732686839532105\n",
      "Training Loss: 0.00680459322524257\n",
      "Training Loss: 0.006815649396157824\n",
      "Validation Loss: 0.0036709732349878284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006663692893926054\n",
      "Training Loss: 0.00679336036904715\n",
      "Training Loss: 0.006804043454467319\n",
      "Validation Loss: 0.003658238564241217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006654042665613816\n",
      "Training Loss: 0.006782083575380966\n",
      "Training Loss: 0.006792334847850725\n",
      "Validation Loss: 0.0036456253879253615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006644312081625685\n",
      "Training Loss: 0.006770753213204444\n",
      "Training Loss: 0.006780518317827955\n",
      "Validation Loss: 0.003633122331347693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006634494977770373\n",
      "Training Loss: 0.006759364509489388\n",
      "Training Loss: 0.00676858939928934\n",
      "Validation Loss: 0.0036207249197125267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006624587617116049\n",
      "Training Loss: 0.0067479079565964635\n",
      "Training Loss: 0.006756545942043886\n",
      "Validation Loss: 0.0036084264676411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006614584756316617\n",
      "Training Loss: 0.006736380596412346\n",
      "Training Loss: 0.006744381232419982\n",
      "Validation Loss: 0.003596216998732743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.00660448246402666\n",
      "Training Loss: 0.0067247754416894165\n",
      "Training Loss: 0.006732095790794119\n",
      "Validation Loss: 0.003584093225889661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006594277648255229\n",
      "Training Loss: 0.006713089402765036\n",
      "Training Loss: 0.006719687264412641\n",
      "Validation Loss: 0.0035720484401884204\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.00658396897255443\n",
      "Training Loss: 0.00670131865539588\n",
      "Training Loss: 0.0067071558209136125\n",
      "Validation Loss: 0.0035600758607635336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006573555181967094\n",
      "Training Loss: 0.006689461832866073\n",
      "Training Loss: 0.00669450058368966\n",
      "Validation Loss: 0.003548171863043576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006563034878345206\n",
      "Training Loss: 0.0066775146953295915\n",
      "Training Loss: 0.006681723248329945\n",
      "Validation Loss: 0.003536333500020457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006552408213028684\n",
      "Training Loss: 0.0066654801403637975\n",
      "Training Loss: 0.006668827526154928\n",
      "Validation Loss: 0.00352455929884415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006541676059132442\n",
      "Training Loss: 0.006653355526505038\n",
      "Training Loss: 0.0066558162629371505\n",
      "Validation Loss: 0.0035128455407645426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006530841226922348\n",
      "Training Loss: 0.006641146113397553\n",
      "Training Loss: 0.006642694206675515\n",
      "Validation Loss: 0.003501190186551448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006519906935282051\n",
      "Training Loss: 0.006628853550646454\n",
      "Training Loss: 0.006629468085011467\n",
      "Validation Loss: 0.003489594194996223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006508877053856849\n",
      "Training Loss: 0.0066164818941615525\n",
      "Training Loss: 0.006616145365987904\n",
      "Validation Loss: 0.0034780590350247838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0064977567014284435\n",
      "Training Loss: 0.006604037618963048\n",
      "Training Loss: 0.00660273426794447\n",
      "Validation Loss: 0.0034665864240901356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006486551291309297\n",
      "Training Loss: 0.006591526741394773\n",
      "Training Loss: 0.0065892444289056586\n",
      "Validation Loss: 0.003455177519805311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0064752685464918615\n",
      "Training Loss: 0.006578957834281027\n",
      "Training Loss: 0.006575686752330512\n",
      "Validation Loss: 0.0034438345733025437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006463916322682053\n",
      "Training Loss: 0.00656633771257475\n",
      "Training Loss: 0.006562072284868919\n",
      "Validation Loss: 0.0034325599573615394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006452502227621153\n",
      "Training Loss: 0.006553678205236792\n",
      "Training Loss: 0.006548413053969852\n",
      "Validation Loss: 0.0034213570611070047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006441036619944498\n",
      "Training Loss: 0.006540989505592734\n",
      "Training Loss: 0.006534723920631222\n",
      "Validation Loss: 0.0034102323671719166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.00642952976282686\n",
      "Training Loss: 0.006528282614890486\n",
      "Training Loss: 0.006521017744671553\n",
      "Validation Loss: 0.0033991883098137346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006417990991612896\n",
      "Training Loss: 0.006515567940659821\n",
      "Training Loss: 0.0065073076932458205\n",
      "Validation Loss: 0.003388230176119322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006406432730145752\n",
      "Training Loss: 0.006502858513267711\n",
      "Training Loss: 0.006493608477176167\n",
      "Validation Loss: 0.0033773622970002587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.00639486568281427\n",
      "Training Loss: 0.0064901650813408195\n",
      "Training Loss: 0.006479935016832314\n",
      "Validation Loss: 0.0033665882826395582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006383301252499223\n",
      "Training Loss: 0.006477503161877393\n",
      "Training Loss: 0.006466300992178731\n",
      "Validation Loss: 0.0033559134737536143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006371751591796055\n",
      "Training Loss: 0.006464882442378439\n",
      "Training Loss: 0.006452721008099615\n",
      "Validation Loss: 0.003345339030571533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0063602279243059456\n",
      "Training Loss: 0.0064523155835922805\n",
      "Training Loss: 0.006439206507639028\n",
      "Validation Loss: 0.003334871259141253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006348740669200197\n",
      "Training Loss: 0.006439812616445124\n",
      "Training Loss: 0.006425772308721207\n",
      "Validation Loss: 0.003324512623805092\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0063373019685968755\n",
      "Training Loss: 0.006427385526476428\n",
      "Training Loss: 0.006412429183255881\n",
      "Validation Loss: 0.003314265066998477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.00632592074922286\n",
      "Training Loss: 0.00641504391329363\n",
      "Training Loss: 0.006399187209899538\n",
      "Validation Loss: 0.003304130541621132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006314607000676915\n",
      "Training Loss: 0.00640279890911188\n",
      "Training Loss: 0.006386059196083807\n",
      "Validation Loss: 0.0032941148854436332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006303370391251519\n",
      "Training Loss: 0.00639065585215576\n",
      "Training Loss: 0.006373051150585524\n",
      "Validation Loss: 0.0032842163783969\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006292219398310408\n",
      "Training Loss: 0.006378624028293416\n",
      "Training Loss: 0.006360172485001385\n",
      "Validation Loss: 0.003274437896855008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006281160903163254\n",
      "Training Loss: 0.006366709864232689\n",
      "Training Loss: 0.0063474305043928324\n",
      "Validation Loss: 0.0032647787384019137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006270201550796628\n",
      "Training Loss: 0.006354920642916113\n",
      "Training Loss: 0.006334830042906105\n",
      "Validation Loss: 0.003255243479860214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006259348220191896\n",
      "Training Loss: 0.006343259939458221\n",
      "Training Loss: 0.006322377669857815\n",
      "Validation Loss: 0.0032458291101279887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00624860568495933\n",
      "Training Loss: 0.006331730757374317\n",
      "Training Loss: 0.006310074179200455\n",
      "Validation Loss: 0.0032365374996986113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006237977985292673\n",
      "Training Loss: 0.00632034097914584\n",
      "Training Loss: 0.006297926432453096\n",
      "Validation Loss: 0.0032273716060444713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006227470831945538\n",
      "Training Loss: 0.006309088913258165\n",
      "Training Loss: 0.006285935786436312\n",
      "Validation Loss: 0.00321832978103854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006217086377437227\n",
      "Training Loss: 0.006297980088274926\n",
      "Training Loss: 0.0062741025036666545\n",
      "Validation Loss: 0.003209410295455476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006206826997222379\n",
      "Training Loss: 0.006287014854606241\n",
      "Training Loss: 0.0062624293577391655\n",
      "Validation Loss: 0.0032006135469386248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006196695585385896\n",
      "Training Loss: 0.006276194587117061\n",
      "Training Loss: 0.006250916226999834\n",
      "Validation Loss: 0.0031919427754964385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0061866942862980065\n",
      "Training Loss: 0.006265521633904428\n",
      "Training Loss: 0.0062395648960955445\n",
      "Validation Loss: 0.0031833962048142313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006176825008587912\n",
      "Training Loss: 0.006254996614297852\n",
      "Training Loss: 0.006228373817866668\n",
      "Validation Loss: 0.0031749747858351367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006167088268557564\n",
      "Training Loss: 0.006244619217468426\n",
      "Training Loss: 0.006217344117467292\n",
      "Validation Loss: 0.003166676988155487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006157486151205376\n",
      "Training Loss: 0.0062343885900918395\n",
      "Training Loss: 0.006206474571372383\n",
      "Validation Loss: 0.0031585024416007183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.00614801776886452\n",
      "Training Loss: 0.00622430813848041\n",
      "Training Loss: 0.006195765024749562\n",
      "Validation Loss: 0.0031504520944978915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006138684498146176\n",
      "Training Loss: 0.006214375575073063\n",
      "Training Loss: 0.006185214988072403\n",
      "Validation Loss: 0.003142526901714253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006129487486323342\n",
      "Training Loss: 0.00620459156576544\n",
      "Training Loss: 0.006174823674373328\n",
      "Validation Loss: 0.0031347252975291247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006120427344576455\n",
      "Training Loss: 0.006194955796818249\n",
      "Training Loss: 0.006164590692496859\n",
      "Validation Loss: 0.0031270465350531963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006111502827843651\n",
      "Training Loss: 0.006185466763563454\n",
      "Training Loss: 0.006154514458612539\n",
      "Validation Loss: 0.0031194924311503096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006102715131710283\n",
      "Training Loss: 0.006176124841440469\n",
      "Training Loss: 0.006144594317302108\n",
      "Validation Loss: 0.003112061441028386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006094063248019666\n",
      "Training Loss: 0.006166931036859751\n",
      "Training Loss: 0.0061348299705423414\n",
      "Validation Loss: 0.0031047536850268586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006085549037670716\n",
      "Training Loss: 0.006157882113475352\n",
      "Training Loss: 0.006125219946261496\n",
      "Validation Loss: 0.003097567839411956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006077170351636596\n",
      "Training Loss: 0.006148980018333532\n",
      "Training Loss: 0.006115763032576069\n",
      "Validation Loss: 0.0030905017799310636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006068927666638047\n",
      "Training Loss: 0.006140221118694171\n",
      "Training Loss: 0.006106458369758911\n",
      "Validation Loss: 0.0030835569650457984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.0060608204797608775\n",
      "Training Loss: 0.006131606409326196\n",
      "Training Loss: 0.0060973062174161895\n",
      "Validation Loss: 0.003076734166498181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006052848694380373\n",
      "Training Loss: 0.006123135494417511\n",
      "Training Loss: 0.006088304499280639\n",
      "Validation Loss: 0.0030700329081626253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006045011721435003\n",
      "Training Loss: 0.0061148061032872646\n",
      "Training Loss: 0.006079452623962425\n",
      "Validation Loss: 0.003063448311059914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006037308779777959\n",
      "Training Loss: 0.006106617406476289\n",
      "Training Loss: 0.006070748816127889\n",
      "Validation Loss: 0.0030569835824975637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006029739214573056\n",
      "Training Loss: 0.0060985684796469285\n",
      "Training Loss: 0.006062192086246796\n",
      "Validation Loss: 0.003050634696336693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006022301657358184\n",
      "Training Loss: 0.006090658307657577\n",
      "Training Loss: 0.006053780384827405\n",
      "Validation Loss: 0.003044400021454759\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006014994836878031\n",
      "Training Loss: 0.00608288284682203\n",
      "Training Loss: 0.00604551259893924\n",
      "Validation Loss: 0.0030382783832342435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006007818078505807\n",
      "Training Loss: 0.006075244535459205\n",
      "Training Loss: 0.0060373882239218805\n",
      "Validation Loss: 0.003032272171459339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006000770705286413\n",
      "Training Loss: 0.006067740492871962\n",
      "Training Loss: 0.00602940513228532\n",
      "Validation Loss: 0.003026377727549649\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005993851210223511\n",
      "Training Loss: 0.006060367182944901\n",
      "Training Loss: 0.006021561588277109\n",
      "Validation Loss: 0.003020591311826465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005987057207385078\n",
      "Training Loss: 0.006053125244216062\n",
      "Training Loss: 0.006013855721685104\n",
      "Validation Loss: 0.0030149147084526967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.0059803879010723905\n",
      "Training Loss: 0.006046011573052965\n",
      "Training Loss: 0.006006286510964856\n",
      "Validation Loss: 0.003009344231379166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005973842369858175\n",
      "Training Loss: 0.006039024950587191\n",
      "Training Loss: 0.00599885298521258\n",
      "Validation Loss: 0.0030038801997669794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005967418477521278\n",
      "Training Loss: 0.006032164573553018\n",
      "Training Loss: 0.005991550686885603\n",
      "Validation Loss: 0.0029985158706837324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005961113687953911\n",
      "Training Loss: 0.006025425652624108\n",
      "Training Loss: 0.005984378912253305\n",
      "Validation Loss: 0.0029932527549125336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.00595492672349792\n",
      "Training Loss: 0.006018807208165527\n",
      "Training Loss: 0.005977336019277572\n",
      "Validation Loss: 0.0029880900022291232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005948856064351276\n",
      "Training Loss: 0.006012306923512369\n",
      "Training Loss: 0.005970419775112532\n",
      "Validation Loss: 0.002983022698337275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0059428984916303305\n",
      "Training Loss: 0.0060059246607124805\n",
      "Training Loss: 0.005963627889286727\n",
      "Validation Loss: 0.0029780503736515896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005937053787638433\n",
      "Training Loss: 0.0059996562742162494\n",
      "Training Loss: 0.005956959056202322\n",
      "Validation Loss: 0.0029731731158105677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005931318706716411\n",
      "Training Loss: 0.005993500301847234\n",
      "Training Loss: 0.005950410043005831\n",
      "Validation Loss: 0.002968384614842159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005925690972944721\n",
      "Training Loss: 0.005987455297727138\n",
      "Training Loss: 0.005943978437571786\n",
      "Validation Loss: 0.00296368545413101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005920169221935794\n",
      "Training Loss: 0.005981518112821505\n",
      "Training Loss: 0.0059376627998426555\n",
      "Validation Loss: 0.0029590714427255344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005914751144591719\n",
      "Training Loss: 0.00597568427270744\n",
      "Training Loss: 0.0059314597176853565\n",
      "Validation Loss: 0.00295454058783087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005909432867192663\n",
      "Training Loss: 0.005969954726169817\n",
      "Training Loss: 0.005925368196330965\n",
      "Validation Loss: 0.0029500939855822937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005904214590555057\n",
      "Training Loss: 0.005964325732202269\n",
      "Training Loss: 0.0059193852212047204\n",
      "Validation Loss: 0.0029457252828425234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005899092174367979\n",
      "Training Loss: 0.005958795319311321\n",
      "Training Loss: 0.005913508352241479\n",
      "Validation Loss: 0.0029414364298952097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005894064645981416\n",
      "Training Loss: 0.005953362419386394\n",
      "Training Loss: 0.005907735713990405\n",
      "Validation Loss: 0.0029372208819756014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005889128317940049\n",
      "Training Loss: 0.005948022187803872\n",
      "Training Loss: 0.005902065062546171\n",
      "Validation Loss: 0.002933083695955993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005884282595943659\n",
      "Training Loss: 0.00594277567055542\n",
      "Training Loss: 0.005896494585322216\n",
      "Validation Loss: 0.002929014177323225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.00587952459405642\n",
      "Training Loss: 0.005937616549199447\n",
      "Training Loss: 0.005891020034323446\n",
      "Validation Loss: 0.0029250152089915584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005874851800035686\n",
      "Training Loss: 0.00593254613224417\n",
      "Training Loss: 0.005885640624910593\n",
      "Validation Loss: 0.0029210838289104738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0058702619990799575\n",
      "Training Loss: 0.005927560468553566\n",
      "Training Loss: 0.005880353655084036\n",
      "Validation Loss: 0.0029172146767430175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0058657527406467125\n",
      "Training Loss: 0.005922656896291301\n",
      "Training Loss: 0.0058751577482325954\n",
      "Validation Loss: 0.002913413072276986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005861322645796463\n",
      "Training Loss: 0.005917836183798499\n",
      "Training Loss: 0.005870049321674742\n",
      "Validation Loss: 0.0029096737330036467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005856968368170783\n",
      "Training Loss: 0.005913092877017334\n",
      "Training Loss: 0.0058650264766765756\n",
      "Validation Loss: 0.002905992862344667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005852688606246374\n",
      "Training Loss: 0.005908424335648306\n",
      "Training Loss: 0.005860086604952812\n",
      "Validation Loss: 0.0029023702202751983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005848480326822027\n",
      "Training Loss: 0.005903832473559305\n",
      "Training Loss: 0.005855228732689284\n",
      "Validation Loss: 0.002898801825129626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.0058443427295424046\n",
      "Training Loss: 0.005899311405373737\n",
      "Training Loss: 0.005850450560683384\n",
      "Validation Loss: 0.002895291701738796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005840272296336479\n",
      "Training Loss: 0.005894860593834892\n",
      "Training Loss: 0.005845749198342674\n",
      "Validation Loss: 0.0028918330103755415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005836266827536747\n",
      "Training Loss: 0.005890479341614991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [30:50<03:25, 205.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0058411222312133755\n",
      "Validation Loss: 0.0028884238229928477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.18783397395163776\n",
      "Training Loss: 0.12589052122086286\n",
      "Training Loss: 0.09072424726560711\n",
      "Validation Loss: 0.06204957694987233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06368085389956832\n",
      "Training Loss: 0.058679582364857194\n",
      "Training Loss: 0.055967514552175995\n",
      "Validation Loss: 0.05009444606270683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05256711399182677\n",
      "Training Loss: 0.05134981200098991\n",
      "Training Loss: 0.04875052963383496\n",
      "Validation Loss: 0.04343056722722027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04469487212598324\n",
      "Training Loss: 0.04353845498524606\n",
      "Training Loss: 0.04039647378958762\n",
      "Validation Loss: 0.03492369331168325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.035327321598306295\n",
      "Training Loss: 0.033778205933049324\n",
      "Training Loss: 0.029647981012240053\n",
      "Validation Loss: 0.02359775895399324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02398027656134218\n",
      "Training Loss: 0.022939083599485457\n",
      "Training Loss: 0.020047095608897506\n",
      "Validation Loss: 0.016126492557775103\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01696954419603571\n",
      "Training Loss: 0.017398039910476656\n",
      "Training Loss: 0.016056157255079598\n",
      "Validation Loss: 0.013232286559062058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014325129687786103\n",
      "Training Loss: 0.015125795458443463\n",
      "Training Loss: 0.014333996584173291\n",
      "Validation Loss: 0.011724246589969217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.012944026244804263\n",
      "Training Loss: 0.013730243400204926\n",
      "Training Loss: 0.013163092117756604\n",
      "Validation Loss: 0.010596704692841413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011939039133721963\n",
      "Training Loss: 0.012659438315313309\n",
      "Training Loss: 0.0122233373275958\n",
      "Validation Loss: 0.009657262144296358\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.011131077321479096\n",
      "Training Loss: 0.011786250020377339\n",
      "Training Loss: 0.011442235216964036\n",
      "Validation Loss: 0.008862038082809429\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010466000591404736\n",
      "Training Loss: 0.011064885575324297\n",
      "Training Loss: 0.010791662014089525\n",
      "Validation Loss: 0.008195726658751288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009919159046839923\n",
      "Training Loss: 0.010471011430490762\n",
      "Training Loss: 0.01025447586318478\n",
      "Validation Loss: 0.007646899712219667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009474830771796405\n",
      "Training Loss: 0.009987409353489057\n",
      "Training Loss: 0.009816999826580287\n",
      "Validation Loss: 0.007202883748065555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009119903552345932\n",
      "Training Loss: 0.009599256154615432\n",
      "Training Loss: 0.0094661259255372\n",
      "Validation Loss: 0.006849022644959139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008841028270544483\n",
      "Training Loss: 0.009291804088279605\n",
      "Training Loss: 0.009187872384209185\n",
      "Validation Loss: 0.0065690737709486755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008623899007216097\n",
      "Training Loss: 0.00904970200266689\n",
      "Training Loss: 0.008967584641650319\n",
      "Validation Loss: 0.006346531157392297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008454269879730419\n",
      "Training Loss: 0.008857939162990078\n",
      "Training Loss: 0.008791367110097781\n",
      "Validation Loss: 0.006166518527198206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008319514067843557\n",
      "Training Loss: 0.008703302354551851\n",
      "Training Loss: 0.00864742555655539\n",
      "Validation Loss: 0.006016963828627145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008209550880128518\n",
      "Training Loss: 0.008575206364039332\n",
      "Training Loss: 0.00852656265022233\n",
      "Validation Loss: 0.005888802941176999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008116897238651291\n",
      "Training Loss: 0.008465757763478904\n",
      "Training Loss: 0.008422006340697407\n",
      "Validation Loss: 0.005775549836205632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00803624333580956\n",
      "Training Loss: 0.008369329744018614\n",
      "Training Loss: 0.008328942623920739\n",
      "Validation Loss: 0.005672700487317915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007963928055251018\n",
      "Training Loss: 0.008282045368105173\n",
      "Training Loss: 0.00824403831269592\n",
      "Validation Loss: 0.005577201561301193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0078974874492269\n",
      "Training Loss: 0.008201306837145239\n",
      "Training Loss: 0.008165032255928963\n",
      "Validation Loss: 0.005487028446592642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007835294585675001\n",
      "Training Loss: 0.008125420071883127\n",
      "Training Loss: 0.008090433791512624\n",
      "Validation Loss: 0.005400884653221858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007776313673239201\n",
      "Training Loss: 0.008053324760403484\n",
      "Training Loss: 0.008019297714345158\n",
      "Validation Loss: 0.005317987443805997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0077199108840432015\n",
      "Training Loss: 0.007984389879275113\n",
      "Training Loss: 0.007951056293677539\n",
      "Validation Loss: 0.00523790657478437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007665735316695645\n",
      "Training Loss: 0.007918285732157528\n",
      "Training Loss: 0.007885415344499052\n",
      "Validation Loss: 0.005160469585359933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007613630896667018\n",
      "Training Loss: 0.00785488688852638\n",
      "Training Loss: 0.007822271543554962\n",
      "Validation Loss: 0.005085678693963989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007563574796076864\n",
      "Training Loss: 0.007794203131925315\n",
      "Training Loss: 0.007761651596520096\n",
      "Validation Loss: 0.0050136629476348\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007515634858282283\n",
      "Training Loss: 0.007736330006737262\n",
      "Training Loss: 0.007703668116591871\n",
      "Validation Loss: 0.004944622340047041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007469926454359665\n",
      "Training Loss: 0.007681405887706205\n",
      "Training Loss: 0.007648473755689338\n",
      "Validation Loss: 0.004878789950371458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00742658618488349\n",
      "Training Loss: 0.00762957179103978\n",
      "Training Loss: 0.007596232449868694\n",
      "Validation Loss: 0.004816393764281457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.0073857413535006345\n",
      "Training Loss: 0.0075809479295276105\n",
      "Training Loss: 0.007547082966193557\n",
      "Validation Loss: 0.004757623266679853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0073474848899058995\n",
      "Training Loss: 0.007535608132602647\n",
      "Training Loss: 0.007501120013184846\n",
      "Validation Loss: 0.004702599929760765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007311858655884862\n",
      "Training Loss: 0.007493560707662255\n",
      "Training Loss: 0.007458371677203104\n",
      "Validation Loss: 0.004651362942322419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007278841055231169\n",
      "Training Loss: 0.007454740541288629\n",
      "Training Loss: 0.00741879122913815\n",
      "Validation Loss: 0.004603846258944257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007248345029074699\n",
      "Training Loss: 0.007419013566104696\n",
      "Training Loss: 0.007382260337471962\n",
      "Validation Loss: 0.004559902644329024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007220223562326282\n",
      "Training Loss: 0.0073861828725785015\n",
      "Training Loss: 0.007348596580559388\n",
      "Validation Loss: 0.0045193021585955544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00719428374315612\n",
      "Training Loss: 0.007356004674220457\n",
      "Training Loss: 0.007317572019528598\n",
      "Validation Loss: 0.004481759496566871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007170304990140721\n",
      "Training Loss: 0.007328215299639851\n",
      "Training Loss: 0.007288934150710702\n",
      "Validation Loss: 0.004446968495102829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00714805779629387\n",
      "Training Loss: 0.007302544241538271\n",
      "Training Loss: 0.007262425401713699\n",
      "Validation Loss: 0.004414614325316016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007127320051658899\n",
      "Training Loss: 0.00727873329888098\n",
      "Training Loss: 0.00723779687541537\n",
      "Validation Loss: 0.004384401718709158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0071078877698164435\n",
      "Training Loss: 0.007256546627031639\n",
      "Training Loss: 0.00721482299384661\n",
      "Validation Loss: 0.004356063997864807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.00708958363509737\n",
      "Training Loss: 0.007235777133610099\n",
      "Training Loss: 0.007193303185049444\n",
      "Validation Loss: 0.004329373065926386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007072258417028934\n",
      "Training Loss: 0.007216249797493219\n",
      "Training Loss: 0.007173065936076455\n",
      "Validation Loss: 0.004304131304614999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007055788130965084\n",
      "Training Loss: 0.007197812601225451\n",
      "Training Loss: 0.007153965416364372\n",
      "Validation Loss: 0.004280178841684809\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007040073947282508\n",
      "Training Loss: 0.007180342697538435\n",
      "Training Loss: 0.007135878268163651\n",
      "Validation Loss: 0.004257382212855508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007025034044636414\n",
      "Training Loss: 0.007163736335933209\n",
      "Training Loss: 0.007118702958105132\n",
      "Validation Loss: 0.004235630870660704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007010603988310322\n",
      "Training Loss: 0.007147907760227099\n",
      "Training Loss: 0.007102352519286797\n",
      "Validation Loss: 0.004214837826694247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006996729922248051\n",
      "Training Loss: 0.00713278591632843\n",
      "Training Loss: 0.00708675569971092\n",
      "Validation Loss: 0.004194925676539457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006983370475936681\n",
      "Training Loss: 0.007118307790951803\n",
      "Training Loss: 0.007071849676431157\n",
      "Validation Loss: 0.004175834458457369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006970487715443596\n",
      "Training Loss: 0.007104422893607989\n",
      "Training Loss: 0.007057580875698477\n",
      "Validation Loss: 0.004157506464457328\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006958051295951009\n",
      "Training Loss: 0.0070910831983201205\n",
      "Training Loss: 0.007043902142904699\n",
      "Validation Loss: 0.004139896132983267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006946033693384379\n",
      "Training Loss: 0.007078252802602947\n",
      "Training Loss: 0.007030774001032114\n",
      "Validation Loss: 0.004122961638233719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0069344102160539475\n",
      "Training Loss: 0.007065892409300432\n",
      "Training Loss: 0.007018158364808187\n",
      "Validation Loss: 0.004106669523230011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0069231607438996435\n",
      "Training Loss: 0.007053972830763086\n",
      "Training Loss: 0.007006023802096024\n",
      "Validation Loss: 0.00409098067765616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006912263840204105\n",
      "Training Loss: 0.007042465875856579\n",
      "Training Loss: 0.006994341014069505\n",
      "Validation Loss: 0.004075867499308556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0069017024582717565\n",
      "Training Loss: 0.007031344950664788\n",
      "Training Loss: 0.0069830824341624975\n",
      "Validation Loss: 0.004061303686172691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006891458691097796\n",
      "Training Loss: 0.007020586542785168\n",
      "Training Loss: 0.00697222298651468\n",
      "Validation Loss: 0.004047260218132497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006881518122972921\n",
      "Training Loss: 0.007010169281857088\n",
      "Training Loss: 0.0069617411051876845\n",
      "Validation Loss: 0.004033715258812888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006871864211279899\n",
      "Training Loss: 0.007000071936054155\n",
      "Training Loss: 0.006951615085126832\n",
      "Validation Loss: 0.004020644240656846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006862483950098977\n",
      "Training Loss: 0.0069902773632202295\n",
      "Training Loss: 0.006941825846442953\n",
      "Validation Loss: 0.004008023176875928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0068533634522464125\n",
      "Training Loss: 0.006980767493369058\n",
      "Training Loss: 0.006932354740565643\n",
      "Validation Loss: 0.003995837548255837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006844490535440855\n",
      "Training Loss: 0.006971526693087071\n",
      "Training Loss: 0.00692318502580747\n",
      "Validation Loss: 0.003984065976234551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006835853144875728\n",
      "Training Loss: 0.006962539079831913\n",
      "Training Loss: 0.006914300740463659\n",
      "Validation Loss: 0.003972687137187615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00682743945159018\n",
      "Training Loss: 0.006953790822299197\n",
      "Training Loss: 0.006905686336685903\n",
      "Validation Loss: 0.003961686246369159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0068192385463044045\n",
      "Training Loss: 0.006945268856361509\n",
      "Training Loss: 0.006897328151972033\n",
      "Validation Loss: 0.003951047254161218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006811240480747074\n",
      "Training Loss: 0.006936960609164089\n",
      "Training Loss: 0.006889212235691957\n",
      "Validation Loss: 0.003940752070407603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006803433754248545\n",
      "Training Loss: 0.006928853130666539\n",
      "Training Loss: 0.00688132576062344\n",
      "Validation Loss: 0.003930787384520505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006795810149051249\n",
      "Training Loss: 0.006920936307869852\n",
      "Training Loss: 0.006873656909447163\n",
      "Validation Loss: 0.003921134910138136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006788360076025128\n",
      "Training Loss: 0.006913199558621273\n",
      "Training Loss: 0.0068661941401660445\n",
      "Validation Loss: 0.003911785641423521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006781073650927283\n",
      "Training Loss: 0.006905631831614301\n",
      "Training Loss: 0.006858925818232819\n",
      "Validation Loss: 0.00390272230966791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006773944409214892\n",
      "Training Loss: 0.006898223843891173\n",
      "Training Loss: 0.006851842027972452\n",
      "Validation Loss: 0.00389393569320817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.00676696312322747\n",
      "Training Loss: 0.006890967066865415\n",
      "Training Loss: 0.0068449328513815995\n",
      "Validation Loss: 0.0038854079046338964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006760122068226337\n",
      "Training Loss: 0.006883852434111759\n",
      "Training Loss: 0.006838187858229503\n",
      "Validation Loss: 0.0038771318936239134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006753413960686885\n",
      "Training Loss: 0.006876872070133686\n",
      "Training Loss: 0.00683159947686363\n",
      "Validation Loss: 0.0038690936380181085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006746831460623071\n",
      "Training Loss: 0.0068700185138732195\n",
      "Training Loss: 0.006825158487772569\n",
      "Validation Loss: 0.0038612799868092277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00674036840791814\n",
      "Training Loss: 0.006863284135470167\n",
      "Training Loss: 0.006818856174359098\n",
      "Validation Loss: 0.003853682720290727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006734017922426574\n",
      "Training Loss: 0.00685666229808703\n",
      "Training Loss: 0.006812685648910701\n",
      "Validation Loss: 0.0038462925357011595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006727773846359923\n",
      "Training Loss: 0.006850146333454177\n",
      "Training Loss: 0.006806640243157744\n",
      "Validation Loss: 0.003839095277460606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0067216297145932915\n",
      "Training Loss: 0.0068437298224307596\n",
      "Training Loss: 0.006800710586248897\n",
      "Validation Loss: 0.0038320842157170344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006715581418247894\n",
      "Training Loss: 0.006837406897684559\n",
      "Training Loss: 0.006794891830068082\n",
      "Validation Loss: 0.0038252489947389516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006709621839690954\n",
      "Training Loss: 0.006831172103993595\n",
      "Training Loss: 0.006789176331367343\n",
      "Validation Loss: 0.0038185807146404066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006703747188439592\n",
      "Training Loss: 0.006825020094402135\n",
      "Training Loss: 0.0067835598980309445\n",
      "Validation Loss: 0.0038120706822053433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00669795177236665\n",
      "Training Loss: 0.00681894694804214\n",
      "Training Loss: 0.006778035791357979\n",
      "Validation Loss: 0.0038057102238382686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006692231041961349\n",
      "Training Loss: 0.006812945896526799\n",
      "Training Loss: 0.00677259843039792\n",
      "Validation Loss: 0.0037994941806399757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006686580837704241\n",
      "Training Loss: 0.006807014738442376\n",
      "Training Loss: 0.006767242880305275\n",
      "Validation Loss: 0.0037934084781288597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006680996490176767\n",
      "Training Loss: 0.006801147852092982\n",
      "Training Loss: 0.00676196450018324\n",
      "Validation Loss: 0.003787450275247854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006675473929499276\n",
      "Training Loss: 0.006795340350363404\n",
      "Training Loss: 0.006756757876137272\n",
      "Validation Loss: 0.003781612511211483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006670010040979832\n",
      "Training Loss: 0.006789590548723936\n",
      "Training Loss: 0.006751620147260837\n",
      "Validation Loss: 0.0037758868224290983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006664600467775017\n",
      "Training Loss: 0.006783893889514729\n",
      "Training Loss: 0.0067465461592655625\n",
      "Validation Loss: 0.0037702704240892377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00665924244967755\n",
      "Training Loss: 0.006778247248148545\n",
      "Training Loss: 0.0067415320919826625\n",
      "Validation Loss: 0.0037647495778758873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006653931670007296\n",
      "Training Loss: 0.006772646461613476\n",
      "Training Loss: 0.006736574202077464\n",
      "Validation Loss: 0.0037593235656765574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006648666034452617\n",
      "Training Loss: 0.006767089930363\n",
      "Training Loss: 0.006731668169377372\n",
      "Validation Loss: 0.00375398582637603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006643441242631525\n",
      "Training Loss: 0.0067615740047767756\n",
      "Training Loss: 0.006726811997359619\n",
      "Validation Loss: 0.0037487291801574355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006638255208381452\n",
      "Training Loss: 0.006756095424061641\n",
      "Training Loss: 0.006722001382731832\n",
      "Validation Loss: 0.003743549451765636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006633105487562716\n",
      "Training Loss: 0.0067506525432690975\n",
      "Training Loss: 0.006717233939561993\n",
      "Validation Loss: 0.003738441511078246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006627989205298945\n",
      "Training Loss: 0.006745242072502151\n",
      "Training Loss: 0.0067125063855201\n",
      "Validation Loss: 0.003733400108941485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006622903702082112\n",
      "Training Loss: 0.00673986304900609\n",
      "Training Loss: 0.006707816263078712\n",
      "Validation Loss: 0.0037284190243298417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006617846694425679\n",
      "Training Loss: 0.006734511541435495\n",
      "Training Loss: 0.0067031607014359906\n",
      "Validation Loss: 0.003723495325931672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006612815774278715\n",
      "Training Loss: 0.006729186583543196\n",
      "Training Loss: 0.006698537980555557\n",
      "Validation Loss: 0.003718624108607012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006607808462576941\n",
      "Training Loss: 0.006723885571118444\n",
      "Training Loss: 0.006693944909493439\n",
      "Validation Loss: 0.0037138022409145084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0066028241638559845\n",
      "Training Loss: 0.006718607207294554\n",
      "Training Loss: 0.00668937953421846\n",
      "Validation Loss: 0.0037090230126226886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006597859303001314\n",
      "Training Loss: 0.006713349454803392\n",
      "Training Loss: 0.006684838884393684\n",
      "Validation Loss: 0.0037042876912197205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006592913132044487\n",
      "Training Loss: 0.006708110005129129\n",
      "Training Loss: 0.0066803215717663985\n",
      "Validation Loss: 0.003699584272847082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006587981906486675\n",
      "Training Loss: 0.0067028878361452375\n",
      "Training Loss: 0.006675826400169171\n",
      "Validation Loss: 0.003694917470363251\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006583066039602272\n",
      "Training Loss: 0.006697681139921769\n",
      "Training Loss: 0.006671350207179785\n",
      "Validation Loss: 0.0036902773766935375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006578162466175854\n",
      "Training Loss: 0.006692488318076357\n",
      "Training Loss: 0.006666891765780747\n",
      "Validation Loss: 0.003685663285497785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006573270139051601\n",
      "Training Loss: 0.0066873084520921115\n",
      "Training Loss: 0.006662448726710863\n",
      "Validation Loss: 0.003681075302727018\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006568387154256925\n",
      "Training Loss: 0.006682139321928844\n",
      "Training Loss: 0.00665802029427141\n",
      "Validation Loss: 0.0036765031288953478\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006563512742868625\n",
      "Training Loss: 0.006676979543408379\n",
      "Training Loss: 0.006653604006278329\n",
      "Validation Loss: 0.0036719492178807936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00655864373082295\n",
      "Training Loss: 0.006671827865066007\n",
      "Training Loss: 0.006649198559462093\n",
      "Validation Loss: 0.0036674071328316846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.00655377910763491\n",
      "Training Loss: 0.0066666834149509665\n",
      "Training Loss: 0.006644802575465292\n",
      "Validation Loss: 0.003662876308675897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006548918990883976\n",
      "Training Loss: 0.006661545707611367\n",
      "Training Loss: 0.006640413893619552\n",
      "Validation Loss: 0.0036583531064535964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006544060209416784\n",
      "Training Loss: 0.006656410983996466\n",
      "Training Loss: 0.006636032008100301\n",
      "Validation Loss: 0.0036538350696706874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006539202248095535\n",
      "Training Loss: 0.0066512808843981475\n",
      "Training Loss: 0.006631654221564531\n",
      "Validation Loss: 0.0036493238673827957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006534342871163972\n",
      "Training Loss: 0.0066461522900499405\n",
      "Training Loss: 0.00662728046067059\n",
      "Validation Loss: 0.00364480877629994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006529482349287718\n",
      "Training Loss: 0.006641023741103709\n",
      "Training Loss: 0.00662290790816769\n",
      "Validation Loss: 0.0036402890560729953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006524617781979032\n",
      "Training Loss: 0.006635896067600697\n",
      "Training Loss: 0.006618536580353975\n",
      "Validation Loss: 0.003635766294659272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006519748589489609\n",
      "Training Loss: 0.006630767119349912\n",
      "Training Loss: 0.0066141646075993776\n",
      "Validation Loss: 0.003631237954466363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006514873565174639\n",
      "Training Loss: 0.006625635635573417\n",
      "Training Loss: 0.006609790907241404\n",
      "Validation Loss: 0.0036266991578230864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006509990851045586\n",
      "Training Loss: 0.00662050042534247\n",
      "Training Loss: 0.00660541374469176\n",
      "Validation Loss: 0.0036221473932977807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006505100064096041\n",
      "Training Loss: 0.006615360913565382\n",
      "Training Loss: 0.00660103177651763\n",
      "Validation Loss: 0.003617581304455741\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006500198936555535\n",
      "Training Loss: 0.006610216225963086\n",
      "Training Loss: 0.006596644144738093\n",
      "Validation Loss: 0.0036130011960696638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006495286804856733\n",
      "Training Loss: 0.0066050641692709175\n",
      "Training Loss: 0.006592249232344329\n",
      "Validation Loss: 0.0036084027162993724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006490362453623675\n",
      "Training Loss: 0.006599904322065413\n",
      "Training Loss: 0.006587845624890179\n",
      "Validation Loss: 0.0036037824707880113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006485424828133546\n",
      "Training Loss: 0.006594736542319879\n",
      "Training Loss: 0.006583432923071087\n",
      "Validation Loss: 0.003599140718526971\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006480472641997039\n",
      "Training Loss: 0.006589558230480179\n",
      "Training Loss: 0.006579009025590494\n",
      "Validation Loss: 0.0035944737786992214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006475504219997675\n",
      "Training Loss: 0.006584369564661756\n",
      "Training Loss: 0.0065745728404726835\n",
      "Validation Loss: 0.0035897821078097886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006470518452697433\n",
      "Training Loss: 0.0065791697381064294\n",
      "Training Loss: 0.0065701237961184236\n",
      "Validation Loss: 0.0035850608229553434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006465514152660034\n",
      "Training Loss: 0.0065739562956150625\n",
      "Training Loss: 0.006565660152118653\n",
      "Validation Loss: 0.003580309064755363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006460490789613686\n",
      "Training Loss: 0.0065687298285774885\n",
      "Training Loss: 0.00656118068145588\n",
      "Validation Loss: 0.003575528617372757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006455446437466889\n",
      "Training Loss: 0.006563488334650174\n",
      "Training Loss: 0.006556684144306928\n",
      "Validation Loss: 0.0035707131956881854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0064503798418445515\n",
      "Training Loss: 0.0065582309290766715\n",
      "Training Loss: 0.0065521694370545445\n",
      "Validation Loss: 0.003565863581907967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006445290052797645\n",
      "Training Loss: 0.00655295662698336\n",
      "Training Loss: 0.006547635667957365\n",
      "Validation Loss: 0.0035609754398883728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006440175522584468\n",
      "Training Loss: 0.006547664904501289\n",
      "Training Loss: 0.006543080630945042\n",
      "Validation Loss: 0.003556050702908568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006435035244794563\n",
      "Training Loss: 0.006542355528799817\n",
      "Training Loss: 0.006538504288764671\n",
      "Validation Loss: 0.003551083988394965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006429869044804946\n",
      "Training Loss: 0.006537025471916422\n",
      "Training Loss: 0.006533904912648722\n",
      "Validation Loss: 0.003546077455917185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006424673000583425\n",
      "Training Loss: 0.006531674794387072\n",
      "Training Loss: 0.006529281209222973\n",
      "Validation Loss: 0.0035410265221124454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006419448378728702\n",
      "Training Loss: 0.00652630262542516\n",
      "Training Loss: 0.006524632569635287\n",
      "Validation Loss: 0.0035359315139900766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006414193269447424\n",
      "Training Loss: 0.006520907708909363\n",
      "Training Loss: 0.006519956924021244\n",
      "Validation Loss: 0.003530788557143526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006408905559801496\n",
      "Training Loss: 0.006515489175217226\n",
      "Training Loss: 0.006515253264224157\n",
      "Validation Loss: 0.003525599074717402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0064035850937943905\n",
      "Training Loss: 0.006510045772884041\n",
      "Training Loss: 0.006510520638548769\n",
      "Validation Loss: 0.003520359347961592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006398230115883053\n",
      "Training Loss: 0.006504577482119202\n",
      "Training Loss: 0.006505757586564869\n",
      "Validation Loss: 0.0035150699550285935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006392839065520093\n",
      "Training Loss: 0.006499081848887727\n",
      "Training Loss: 0.006500963193830102\n",
      "Validation Loss: 0.0035097301581853563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006387411629548296\n",
      "Training Loss: 0.006493558807997033\n",
      "Training Loss: 0.006496135494089685\n",
      "Validation Loss: 0.003504332236087557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006381944606546313\n",
      "Training Loss: 0.006488006690051407\n",
      "Training Loss: 0.006491274159634486\n",
      "Validation Loss: 0.0034988812142145937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006376438604202121\n",
      "Training Loss: 0.006482425280846655\n",
      "Training Loss: 0.0064863769197836514\n",
      "Validation Loss: 0.0034933745850589167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006370891635306179\n",
      "Training Loss: 0.006476812363835052\n",
      "Training Loss: 0.006481443087104708\n",
      "Validation Loss: 0.003487811570338319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006365300837205723\n",
      "Training Loss: 0.0064711677457671615\n",
      "Training Loss: 0.00647647131816484\n",
      "Validation Loss: 0.0034821883937490457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006359666268108413\n",
      "Training Loss: 0.006465489378897473\n",
      "Training Loss: 0.006471459445892833\n",
      "Validation Loss: 0.003476506695569901\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.00635398687212728\n",
      "Training Loss: 0.0064597768534440545\n",
      "Training Loss: 0.006466407155967318\n",
      "Validation Loss: 0.0034707589218853398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006348259625374339\n",
      "Training Loss: 0.00645402810536325\n",
      "Training Loss: 0.006461313144536689\n",
      "Validation Loss: 0.0034649497253841227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0063424846110865475\n",
      "Training Loss: 0.006448242058977485\n",
      "Training Loss: 0.00645617475733161\n",
      "Validation Loss: 0.0034590767254383207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006336658027721569\n",
      "Training Loss: 0.006442418697988614\n",
      "Training Loss: 0.00645099124580156\n",
      "Validation Loss: 0.0034531352445064637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006330779051641002\n",
      "Training Loss: 0.006436553670791909\n",
      "Training Loss: 0.006445760429487564\n",
      "Validation Loss: 0.0034471286743293318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006324846870265901\n",
      "Training Loss: 0.006430648249806836\n",
      "Training Loss: 0.006440481959143654\n",
      "Validation Loss: 0.0034410529377545867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006318857712903992\n",
      "Training Loss: 0.006424698733026162\n",
      "Training Loss: 0.006435153083875775\n",
      "Validation Loss: 0.003434905726096352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006312811787356622\n",
      "Training Loss: 0.00641870420309715\n",
      "Training Loss: 0.006429772219853476\n",
      "Validation Loss: 0.0034286863918761524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006306704584276303\n",
      "Training Loss: 0.006412663308437914\n",
      "Training Loss: 0.006424337410717271\n",
      "Validation Loss: 0.003422391633607782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0063005363498814405\n",
      "Training Loss: 0.006406573640415445\n",
      "Training Loss: 0.006418847078457475\n",
      "Validation Loss: 0.0034160220778411193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006294303043978289\n",
      "Training Loss: 0.00640043223509565\n",
      "Training Loss: 0.006413298770785332\n",
      "Validation Loss: 0.0034095718671850275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006288002600776963\n",
      "Training Loss: 0.006394238112261519\n",
      "Training Loss: 0.006407690587220714\n",
      "Validation Loss: 0.0034030413247247257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006281631095334888\n",
      "Training Loss: 0.006387987875496037\n",
      "Training Loss: 0.006402019835077226\n",
      "Validation Loss: 0.0033964268402772004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006275188205763698\n",
      "Training Loss: 0.00638167837925721\n",
      "Training Loss: 0.006396284703514539\n",
      "Validation Loss: 0.003389726096000313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006268669227138162\n",
      "Training Loss: 0.006375309172435664\n",
      "Training Loss: 0.00639048229844775\n",
      "Validation Loss: 0.003382935371835915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006262070977827534\n",
      "Training Loss: 0.006368875034386292\n",
      "Training Loss: 0.006384608884109184\n",
      "Validation Loss: 0.0033760550222621203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006255389660364017\n",
      "Training Loss: 0.0063623728265520185\n",
      "Training Loss: 0.006378662355127744\n",
      "Validation Loss: 0.003369076037517843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0062486224912572655\n",
      "Training Loss: 0.006355799283483066\n",
      "Training Loss: 0.006372639798210003\n",
      "Validation Loss: 0.0033619983992905595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006241765081649646\n",
      "Training Loss: 0.006349149503512308\n",
      "Training Loss: 0.006366536789573729\n",
      "Validation Loss: 0.0033548195673717878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.00623481230228208\n",
      "Training Loss: 0.006342421158915385\n",
      "Training Loss: 0.0063603496947325765\n",
      "Validation Loss: 0.0033475327138066963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006227760347537696\n",
      "Training Loss: 0.006335608209483325\n",
      "Training Loss: 0.006354075241833925\n",
      "Validation Loss: 0.0033401337562107974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006220603703986853\n",
      "Training Loss: 0.006328705304767936\n",
      "Training Loss: 0.006347707263776101\n",
      "Validation Loss: 0.003332616333598585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.00621333577670157\n",
      "Training Loss: 0.006321707707829773\n",
      "Training Loss: 0.006341242600465194\n",
      "Validation Loss: 0.0033249772595911383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006205952389864251\n",
      "Training Loss: 0.0063146099320147185\n",
      "Training Loss: 0.006334674999816343\n",
      "Validation Loss: 0.0033172072052662627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006198445917107165\n",
      "Training Loss: 0.006307403912069276\n",
      "Training Loss: 0.006327999255154282\n",
      "Validation Loss: 0.0033093022242753527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006190809165127575\n",
      "Training Loss: 0.006300082915113307\n",
      "Training Loss: 0.006321208694134839\n",
      "Validation Loss: 0.003301253565848711\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006183034449350089\n",
      "Training Loss: 0.006292639340390451\n",
      "Training Loss: 0.006314295233460143\n",
      "Validation Loss: 0.003293051534813693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006175113113131374\n",
      "Training Loss: 0.006285064939875156\n",
      "Training Loss: 0.006307253505801782\n",
      "Validation Loss: 0.0032846914667092014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006167036147089675\n",
      "Training Loss: 0.0062773503502830865\n",
      "Training Loss: 0.006300072999438271\n",
      "Validation Loss: 0.0032761619122845405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006158792874775827\n",
      "Training Loss: 0.006269485227530822\n",
      "Training Loss: 0.006292746093822643\n",
      "Validation Loss: 0.0032674509487795027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006150373237906024\n",
      "Training Loss: 0.006261457608197816\n",
      "Training Loss: 0.006285261050797999\n",
      "Validation Loss: 0.003258552319851568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006141764058265835\n",
      "Training Loss: 0.006253256035270169\n",
      "Training Loss: 0.00627760756702628\n",
      "Validation Loss: 0.00324945004520875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006132952165207825\n",
      "Training Loss: 0.006244867531349883\n",
      "Training Loss: 0.006269773223320954\n",
      "Validation Loss: 0.003240131527143583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006123923505074344\n",
      "Training Loss: 0.006236277208081446\n",
      "Training Loss: 0.006261744454386644\n",
      "Validation Loss: 0.003230583184304532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00611466258764267\n",
      "Training Loss: 0.006227469671866857\n",
      "Training Loss: 0.006253506769426167\n",
      "Validation Loss: 0.003220792802239067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006105152034433558\n",
      "Training Loss: 0.006218427841085941\n",
      "Training Loss: 0.006245043252129108\n",
      "Validation Loss: 0.0032107432325778717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006095373008865863\n",
      "Training Loss: 0.0062091319385217504\n",
      "Training Loss: 0.006236337092122995\n",
      "Validation Loss: 0.003200416003217858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006085304484586231\n",
      "Training Loss: 0.0061995645199203865\n",
      "Training Loss: 0.006227367494138889\n",
      "Validation Loss: 0.0031897969114897625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006074924448039382\n",
      "Training Loss: 0.006189701443654485\n",
      "Training Loss: 0.006218114998191595\n",
      "Validation Loss: 0.003178869206667616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006064209130126983\n",
      "Training Loss: 0.006179522988968528\n",
      "Training Loss: 0.006208557197242044\n",
      "Validation Loss: 0.0031676133283612766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0060531345725758\n",
      "Training Loss: 0.0061690027394797654\n",
      "Training Loss: 0.006198668893193826\n",
      "Validation Loss: 0.003156010950967837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006041673173895106\n",
      "Training Loss: 0.0061581169744022194\n",
      "Training Loss: 0.006188425624277443\n",
      "Validation Loss: 0.003144046480066321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006029795065987855\n",
      "Training Loss: 0.006146838061977178\n",
      "Training Loss: 0.006177800678415224\n",
      "Validation Loss: 0.0031317045449101356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006017473056563177\n",
      "Training Loss: 0.006135142337298021\n",
      "Training Loss: 0.006166766409878619\n",
      "Validation Loss: 0.0031189729637476835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006004675756557844\n",
      "Training Loss: 0.006123001959640533\n",
      "Training Loss: 0.006155296440119855\n",
      "Validation Loss: 0.003105838224553409\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005991374438162893\n",
      "Training Loss: 0.006110393712297082\n",
      "Training Loss: 0.006143363252049312\n",
      "Validation Loss: 0.0030922951082583893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005977537987055257\n",
      "Training Loss: 0.006097293641651049\n",
      "Training Loss: 0.0061309416487347335\n",
      "Validation Loss: 0.0030783462701783923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005963142371620052\n",
      "Training Loss: 0.006083683264441788\n",
      "Training Loss: 0.006118009340716526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [34:15<00:00, 205.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0030639922505328325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (5692, 12, 5)\n",
      "Shape of the data after splitting into sequences: (28500, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.0762528096139431\n",
      "Training Loss: 0.07415843024849891\n",
      "Training Loss: 0.0718848935328424\n",
      "Validation Loss: 0.07087248197516029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06814275478944182\n",
      "Training Loss: 0.06588919954374432\n",
      "Training Loss: 0.0628412220813334\n",
      "Validation Loss: 0.06050111910098054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.057790092509239915\n",
      "Training Loss: 0.05472590681165457\n",
      "Training Loss: 0.05112023008987308\n",
      "Validation Loss: 0.048365079065303455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04584349756129086\n",
      "Training Loss: 0.043032163875177505\n",
      "Training Loss: 0.03967379538342357\n",
      "Validation Loss: 0.03690735569872548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03472800916060805\n",
      "Training Loss: 0.032766831642948094\n",
      "Training Loss: 0.03017855713609606\n",
      "Validation Loss: 0.02786594829679038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02630235031247139\n",
      "Training Loss: 0.025412100022658705\n",
      "Training Loss: 0.023730376907624303\n",
      "Validation Loss: 0.02191285209813982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.02099310209043324\n",
      "Training Loss: 0.02088191671529785\n",
      "Training Loss: 0.019853372890502215\n",
      "Validation Loss: 0.018327972553461122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.017926903190091253\n",
      "Training Loss: 0.01823757466394454\n",
      "Training Loss: 0.017579886487219483\n",
      "Validation Loss: 0.016176627328870503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.016153677986003458\n",
      "Training Loss: 0.016661773193627594\n",
      "Training Loss: 0.01619522294495255\n",
      "Validation Loss: 0.014822970767076431\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.015069581589195878\n",
      "Training Loss: 0.015662582986988128\n",
      "Training Loss: 0.015291813914664089\n",
      "Validation Loss: 0.013907237096135033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.014349982808344066\n",
      "Training Loss: 0.014974570260383189\n",
      "Training Loss: 0.014650818957015872\n",
      "Validation Loss: 0.013231818812763255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.013825041714590043\n",
      "Training Loss: 0.014454627535305917\n",
      "Training Loss: 0.014151811471674592\n",
      "Validation Loss: 0.01268400050950854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.013401893954724074\n",
      "Training Loss: 0.014021369477268309\n",
      "Training Loss: 0.013724221768788993\n",
      "Validation Loss: 0.012195028581792552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.013025731248781085\n",
      "Training Loss: 0.013624986426439136\n",
      "Training Loss: 0.013323736286256462\n",
      "Validation Loss: 0.011720087407993969\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.012662001010030509\n",
      "Training Loss: 0.013233441174961627\n",
      "Training Loss: 0.012921744988998398\n",
      "Validation Loss: 0.011229657853189646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.012289243363775314\n",
      "Training Loss: 0.01282720771501772\n",
      "Training Loss: 0.012501692260848359\n",
      "Validation Loss: 0.010707138103610847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.011897210970055312\n",
      "Training Loss: 0.012398207900114358\n",
      "Training Loss: 0.012058564485050738\n",
      "Validation Loss: 0.010149218220514863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.011486852805828675\n",
      "Training Loss: 0.011949840111192316\n",
      "Training Loss: 0.011598743775393813\n",
      "Validation Loss: 0.009566294068596168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.01106968780979514\n",
      "Training Loss: 0.011495991625124588\n",
      "Training Loss: 0.011138523190747946\n",
      "Validation Loss: 0.008981125862233007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.010665302525740116\n",
      "Training Loss: 0.011058145214337855\n",
      "Training Loss: 0.010700650329235941\n",
      "Validation Loss: 0.008424360057851823\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.010296507064485922\n",
      "Training Loss: 0.010660158045357093\n",
      "Training Loss: 0.010308443100657315\n",
      "Validation Loss: 0.007926084548548868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009982273031491786\n",
      "Training Loss: 0.010320840813219547\n",
      "Training Loss: 0.009977922623511404\n",
      "Validation Loss: 0.007505326860144818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009730229144915939\n",
      "Training Loss: 0.010046607705298811\n",
      "Training Loss: 0.009711301972856745\n",
      "Validation Loss: 0.00716370563258239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.009533563959412277\n",
      "Training Loss: 0.009829529352718963\n",
      "Training Loss: 0.00949734120280482\n",
      "Validation Loss: 0.006888560542648428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.009375746770529077\n",
      "Training Loss: 0.009653047878528014\n",
      "Training Loss: 0.009318625791929663\n",
      "Validation Loss: 0.006661992361821401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.009239014311460778\n",
      "Training Loss: 0.009500084288883954\n",
      "Training Loss: 0.009159184681484476\n",
      "Validation Loss: 0.006467945413308197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.009109980115899816\n",
      "Training Loss: 0.009357720317784696\n",
      "Training Loss: 0.00900784288882278\n",
      "Validation Loss: 0.006294430862704104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008980663459515198\n",
      "Training Loss: 0.009217811052221804\n",
      "Training Loss: 0.00885797837516293\n",
      "Validation Loss: 0.006132935401408023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008847148830536753\n",
      "Training Loss: 0.009075807856861502\n",
      "Training Loss: 0.008706101811258122\n",
      "Validation Loss: 0.005977436366459627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008707984368084\n",
      "Training Loss: 0.008929521879181265\n",
      "Training Loss: 0.008550681608030573\n",
      "Validation Loss: 0.005824006769513146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008563162294449285\n",
      "Training Loss: 0.008778452376136557\n",
      "Training Loss: 0.00839166458346881\n",
      "Validation Loss: 0.005671136197634041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.008413897124119102\n",
      "Training Loss: 0.008623809819109738\n",
      "Training Loss: 0.008230729199713096\n",
      "Validation Loss: 0.005520405710852715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00826307647046633\n",
      "Training Loss: 0.008469008503016084\n",
      "Training Loss: 0.008071890650317073\n",
      "Validation Loss: 0.005376926296275486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.008115827302681282\n",
      "Training Loss: 0.008319985162233933\n",
      "Training Loss: 0.007921636839164421\n",
      "Validation Loss: 0.005248467678601822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007979155610082672\n",
      "Training Loss: 0.008184244680451229\n",
      "Training Loss: 0.0077874729782342915\n",
      "Validation Loss: 0.00514244649616813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007859836214920505\n",
      "Training Loss: 0.008068240750581025\n",
      "Training Loss: 0.007675020335009322\n",
      "Validation Loss: 0.005062235981027146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007761706607416272\n",
      "Training Loss: 0.007974763871170581\n",
      "Training Loss: 0.007585768225835636\n",
      "Validation Loss: 0.005005878998683452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007684567196993158\n",
      "Training Loss: 0.007902462201891468\n",
      "Training Loss: 0.007517295234138146\n",
      "Validation Loss: 0.004968039693410268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007625297368504107\n",
      "Training Loss: 0.007847452213754878\n",
      "Training Loss: 0.00746521707624197\n",
      "Validation Loss: 0.004942776982573101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007579724350944161\n",
      "Training Loss: 0.007805264001945034\n",
      "Training Loss: 0.007425014384789392\n",
      "Validation Loss: 0.004925191467837169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0075439610809553415\n",
      "Training Loss: 0.007772013224894181\n",
      "Training Loss: 0.007392972215311602\n",
      "Validation Loss: 0.004911857894543307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007514951007906347\n",
      "Training Loss: 0.007744785512331873\n",
      "Training Loss: 0.007366385991917923\n",
      "Validation Loss: 0.004900637016699681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007490513232769444\n",
      "Training Loss: 0.007721567983971909\n",
      "Training Loss: 0.007343424551654607\n",
      "Validation Loss: 0.0048903109541089595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007469177024904639\n",
      "Training Loss: 0.0077010389184579255\n",
      "Training Loss: 0.007322893990203738\n",
      "Validation Loss: 0.004880243314566154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007449979261728004\n",
      "Training Loss: 0.0076823519403114915\n",
      "Training Loss: 0.007304030491504818\n",
      "Validation Loss: 0.004870148327232998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007432298389030621\n",
      "Training Loss: 0.007664969930192456\n",
      "Training Loss: 0.007286351396469399\n",
      "Validation Loss: 0.004859925778791978\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007415732919471338\n",
      "Training Loss: 0.007648553933249786\n",
      "Training Loss: 0.007269546147435904\n",
      "Validation Loss: 0.004849571535845151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007400018685730174\n",
      "Training Loss: 0.007632882596226409\n",
      "Training Loss: 0.0072534135146997865\n",
      "Validation Loss: 0.0048391194386261235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007384982353542\n",
      "Training Loss: 0.0076178142521530386\n",
      "Training Loss: 0.007237820817390456\n",
      "Validation Loss: 0.004828621745188041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007370504885911942\n",
      "Training Loss: 0.0076032501575537025\n",
      "Training Loss: 0.007222677207319066\n",
      "Validation Loss: 0.0048181302420365925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007356504094786942\n",
      "Training Loss: 0.00758912498713471\n",
      "Training Loss: 0.007207920256769284\n",
      "Validation Loss: 0.004807688434493173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.00734292219625786\n",
      "Training Loss: 0.007575390189886093\n",
      "Training Loss: 0.007193506394978613\n",
      "Validation Loss: 0.004797337559742455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007329716904787347\n",
      "Training Loss: 0.007562012566486373\n",
      "Training Loss: 0.007179404951166361\n",
      "Validation Loss: 0.004787105064331606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00731685807229951\n",
      "Training Loss: 0.00754896663245745\n",
      "Training Loss: 0.007165593925165013\n",
      "Validation Loss: 0.0047770161881488275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007304322639247403\n",
      "Training Loss: 0.007536232597194612\n",
      "Training Loss: 0.007152056267950684\n",
      "Validation Loss: 0.004767087766942516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007292094118893147\n",
      "Training Loss: 0.007523796373279765\n",
      "Training Loss: 0.00713878313661553\n",
      "Validation Loss: 0.0047573336148948485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007280158168869093\n",
      "Training Loss: 0.007511645833728835\n",
      "Training Loss: 0.007125765040982514\n",
      "Validation Loss: 0.004747763062236056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007268506471300498\n",
      "Training Loss: 0.007499771997099742\n",
      "Training Loss: 0.007112997457152232\n",
      "Validation Loss: 0.004738382129207923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007257129036588594\n",
      "Training Loss: 0.007488166666589678\n",
      "Training Loss: 0.007100476780324243\n",
      "Validation Loss: 0.004729195061699602\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007246019670274109\n",
      "Training Loss: 0.0074768233951181175\n",
      "Training Loss: 0.007088198896963149\n",
      "Validation Loss: 0.004720203155976082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007235172539949417\n",
      "Training Loss: 0.007465735407313332\n",
      "Training Loss: 0.007076164130703546\n",
      "Validation Loss: 0.004711407442770773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007224581693299115\n",
      "Training Loss: 0.0074548977182712405\n",
      "Training Loss: 0.007064369923318737\n",
      "Validation Loss: 0.004702808568908132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007214244108181447\n",
      "Training Loss: 0.007444304475793615\n",
      "Training Loss: 0.007052814712515101\n",
      "Validation Loss: 0.004694403127604949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007204153240891174\n",
      "Training Loss: 0.007433951754355803\n",
      "Training Loss: 0.007041496532619931\n",
      "Validation Loss: 0.004686187878198755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00719430522643961\n",
      "Training Loss: 0.00742383285658434\n",
      "Training Loss: 0.00703041493834462\n",
      "Validation Loss: 0.0046781604380995625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007184695081668906\n",
      "Training Loss: 0.0074139427556656305\n",
      "Training Loss: 0.007019566591479815\n",
      "Validation Loss: 0.0046703190931244596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007175317154615186\n",
      "Training Loss: 0.007404276067391038\n",
      "Training Loss: 0.007008950050803832\n",
      "Validation Loss: 0.004662657743241387\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007166166770039126\n",
      "Training Loss: 0.007394828831311315\n",
      "Training Loss: 0.006998560651554726\n",
      "Validation Loss: 0.004655171256365903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007157239313819445\n",
      "Training Loss: 0.007385593350045383\n",
      "Training Loss: 0.006988396681263112\n",
      "Validation Loss: 0.0046478569928786895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007148527542594821\n",
      "Training Loss: 0.0073765646293759346\n",
      "Training Loss: 0.006978453962947242\n",
      "Validation Loss: 0.0046407101104255725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0071400272240862254\n",
      "Training Loss: 0.007367737364256754\n",
      "Training Loss: 0.0069687285163672645\n",
      "Validation Loss: 0.004633725172803434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007131732392590493\n",
      "Training Loss: 0.00735910578398034\n",
      "Training Loss: 0.006959215691313148\n",
      "Validation Loss: 0.0046268978072435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007123636078904383\n",
      "Training Loss: 0.007350664271507412\n",
      "Training Loss: 0.006949910382390953\n",
      "Validation Loss: 0.004620221642295966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007115733536775224\n",
      "Training Loss: 0.007342405737144873\n",
      "Training Loss: 0.0069408075604587794\n",
      "Validation Loss: 0.0046136955556648086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007108018210856244\n",
      "Training Loss: 0.007334326091222465\n",
      "Training Loss: 0.006931903536897152\n",
      "Validation Loss: 0.0046073110084823765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007100484025431797\n",
      "Training Loss: 0.007326419956516474\n",
      "Training Loss: 0.006923191322130151\n",
      "Validation Loss: 0.004601062818304792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007093126103864051\n",
      "Training Loss: 0.007318680209573358\n",
      "Training Loss: 0.006914666527882219\n",
      "Validation Loss: 0.00459494598842948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007085938325617463\n",
      "Training Loss: 0.007311101884115487\n",
      "Training Loss: 0.006906324141309597\n",
      "Validation Loss: 0.0045889564417041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007078913382720202\n",
      "Training Loss: 0.00730368031305261\n",
      "Training Loss: 0.006898157498217188\n",
      "Validation Loss: 0.0045830887360393665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007072046981775202\n",
      "Training Loss: 0.007296409035334363\n",
      "Training Loss: 0.006890162113704718\n",
      "Validation Loss: 0.0045773391899642316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007065333142527379\n",
      "Training Loss: 0.007289283768041059\n",
      "Training Loss: 0.006882331942906603\n",
      "Validation Loss: 0.00457169882707256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007058765325928107\n",
      "Training Loss: 0.007282299041980878\n",
      "Training Loss: 0.006874662950867787\n",
      "Validation Loss: 0.004566167626435753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0070523388253059234\n",
      "Training Loss: 0.007275449431035668\n",
      "Training Loss: 0.006867148369201459\n",
      "Validation Loss: 0.004560737364423158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007046049052732996\n",
      "Training Loss: 0.007268731193616987\n",
      "Training Loss: 0.006859783356776461\n",
      "Validation Loss: 0.0045554029638879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0070398889650823545\n",
      "Training Loss: 0.007262138475198299\n",
      "Training Loss: 0.006852563389693387\n",
      "Validation Loss: 0.004550161241067134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007033854925539345\n",
      "Training Loss: 0.007255666631972417\n",
      "Training Loss: 0.006845482387579978\n",
      "Validation Loss: 0.004545007775448723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007027940214029514\n",
      "Training Loss: 0.007249311363557354\n",
      "Training Loss: 0.00683853640803136\n",
      "Validation Loss: 0.004539935722073352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0070221416157437485\n",
      "Training Loss: 0.007243068374227732\n",
      "Training Loss: 0.006831720151822083\n",
      "Validation Loss: 0.004534944052823683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007016453031683341\n",
      "Training Loss: 0.007236933090025559\n",
      "Training Loss: 0.006825029060128145\n",
      "Validation Loss: 0.0045300266552413026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007010869557852857\n",
      "Training Loss: 0.0072309007484000175\n",
      "Training Loss: 0.006818457868648693\n",
      "Validation Loss: 0.00452518141815397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007005387181998231\n",
      "Training Loss: 0.00722496734932065\n",
      "Training Loss: 0.006812002849765122\n",
      "Validation Loss: 0.004520402121190191\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007000002130516805\n",
      "Training Loss: 0.007219129354925826\n",
      "Training Loss: 0.006805659417877905\n",
      "Validation Loss: 0.004515686071101116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0069947077758843075\n",
      "Training Loss: 0.007213382137706503\n",
      "Training Loss: 0.006799423000193201\n",
      "Validation Loss: 0.0045110321410125895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006989501410862431\n",
      "Training Loss: 0.007207722277380526\n",
      "Training Loss: 0.006793288646149449\n",
      "Validation Loss: 0.004506433358431657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006984377886983566\n",
      "Training Loss: 0.00720214496832341\n",
      "Training Loss: 0.006787253796355799\n",
      "Validation Loss: 0.004501887897992235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006979333981289529\n",
      "Training Loss: 0.007196647287346422\n",
      "Training Loss: 0.006781312522944063\n",
      "Validation Loss: 0.004497392809416136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006974364496418275\n",
      "Training Loss: 0.007191225274000317\n",
      "Training Loss: 0.006775461824145168\n",
      "Validation Loss: 0.00449294652959876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006969466529553756\n",
      "Training Loss: 0.007185875496361405\n",
      "Training Loss: 0.00676969729247503\n",
      "Validation Loss: 0.004488545564118396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006964636266930029\n",
      "Training Loss: 0.007180593750672415\n",
      "Training Loss: 0.0067640158714493736\n",
      "Validation Loss: 0.004484188877009483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006959868443664164\n",
      "Training Loss: 0.007175377779640257\n",
      "Training Loss: 0.006758413333445787\n",
      "Validation Loss: 0.004479871030106847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006955161766964011\n",
      "Training Loss: 0.007170223612338305\n",
      "Training Loss: 0.006752886055619456\n",
      "Validation Loss: 0.004475592619875509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006950511486502364\n",
      "Training Loss: 0.0071651277737692\n",
      "Training Loss: 0.006747430426767096\n",
      "Validation Loss: 0.004471350822262884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006945914243697188\n",
      "Training Loss: 0.007160087781958282\n",
      "Training Loss: 0.006742043467820622\n",
      "Validation Loss: 0.004467142488823136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006941367081017233\n",
      "Training Loss: 0.007155100451782346\n",
      "Training Loss: 0.006736720644403249\n",
      "Validation Loss: 0.004462963698714385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006936867134645581\n",
      "Training Loss: 0.0071501618123147636\n",
      "Training Loss: 0.00673146006593015\n",
      "Validation Loss: 0.004458815862654886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006932411518064328\n",
      "Training Loss: 0.0071452701417729254\n",
      "Training Loss: 0.006726257076952607\n",
      "Validation Loss: 0.004454694148754764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006927995654987171\n",
      "Training Loss: 0.007140422262018546\n",
      "Training Loss: 0.0067211104446323585\n",
      "Validation Loss: 0.004450600587087945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006923619153094478\n",
      "Training Loss: 0.007135615064762533\n",
      "Training Loss: 0.006716016295249574\n",
      "Validation Loss: 0.004446530865709392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006919277787674218\n",
      "Training Loss: 0.0071308464277535675\n",
      "Training Loss: 0.006710971454158426\n",
      "Validation Loss: 0.0044424848858622855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0069149696285603565\n",
      "Training Loss: 0.007126113841077313\n",
      "Training Loss: 0.006705972417839803\n",
      "Validation Loss: 0.004438459443509202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006910691958619281\n",
      "Training Loss: 0.007121414778521284\n",
      "Training Loss: 0.00670101863972377\n",
      "Validation Loss: 0.004434455551725048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006906442589242942\n",
      "Training Loss: 0.007116746426327154\n",
      "Training Loss: 0.006696105289738625\n",
      "Validation Loss: 0.00443046968338718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006902217813185416\n",
      "Training Loss: 0.007112106516724452\n",
      "Training Loss: 0.00669123082945589\n",
      "Validation Loss: 0.004426498807119101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006898017569910735\n",
      "Training Loss: 0.007107492882059887\n",
      "Training Loss: 0.006686392448609695\n",
      "Validation Loss: 0.00442254543958462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006893838488031179\n",
      "Training Loss: 0.007102902790065855\n",
      "Training Loss: 0.0066815871844301\n",
      "Validation Loss: 0.0044186051033719784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006889678013976663\n",
      "Training Loss: 0.007098334376933053\n",
      "Training Loss: 0.006676813522353768\n",
      "Validation Loss: 0.004414678754656461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.0068855355319101365\n",
      "Training Loss: 0.0070937859185505655\n",
      "Training Loss: 0.0066720685950713236\n",
      "Validation Loss: 0.0044107644490405835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006881407130276784\n",
      "Training Loss: 0.007089254438178614\n",
      "Training Loss: 0.006667349560302682\n",
      "Validation Loss: 0.004406860558017879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006877292674034834\n",
      "Training Loss: 0.007084738635458052\n",
      "Training Loss: 0.006662655698601156\n",
      "Validation Loss: 0.00440296703646106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006873190752230585\n",
      "Training Loss: 0.00708023676997982\n",
      "Training Loss: 0.0066579832282150165\n",
      "Validation Loss: 0.004399081043313059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006869097360759042\n",
      "Training Loss: 0.0070757461653556675\n",
      "Training Loss: 0.006653331657871604\n",
      "Validation Loss: 0.004395202772817418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006865013187052682\n",
      "Training Loss: 0.007071265084668994\n",
      "Training Loss: 0.006648698060889729\n",
      "Validation Loss: 0.004391329230222684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006860935149015859\n",
      "Training Loss: 0.007066791020333767\n",
      "Training Loss: 0.006644079028628767\n",
      "Validation Loss: 0.004387459493362543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006856862347340211\n",
      "Training Loss: 0.007062323110876605\n",
      "Training Loss: 0.006639474440598861\n",
      "Validation Loss: 0.004383593559620923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006852791876881383\n",
      "Training Loss: 0.007057859145570547\n",
      "Training Loss: 0.006634881492936983\n",
      "Validation Loss: 0.0043797293269818415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006848723932635039\n",
      "Training Loss: 0.00705339704058133\n",
      "Training Loss: 0.006630298857344314\n",
      "Validation Loss: 0.004375865826843663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.00684465536440257\n",
      "Training Loss: 0.00704893524874933\n",
      "Training Loss: 0.006625723819015547\n",
      "Validation Loss: 0.004372003216824881\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006840585751924664\n",
      "Training Loss: 0.0070444718655198815\n",
      "Training Loss: 0.006621154844178818\n",
      "Validation Loss: 0.004368137549268856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006836514013120905\n",
      "Training Loss: 0.007040004921145737\n",
      "Training Loss: 0.006616589327459224\n",
      "Validation Loss: 0.004364268300306638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006832437125849538\n",
      "Training Loss: 0.0070355321594979614\n",
      "Training Loss: 0.006612026784569025\n",
      "Validation Loss: 0.004360394260003703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.00682835559011437\n",
      "Training Loss: 0.007031053229002282\n",
      "Training Loss: 0.006607464692788199\n",
      "Validation Loss: 0.0043565166500669095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0068242661526892335\n",
      "Training Loss: 0.007026565240230411\n",
      "Training Loss: 0.006602900246507488\n",
      "Validation Loss: 0.0043526316974626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006820169355487451\n",
      "Training Loss: 0.007022066985955462\n",
      "Training Loss: 0.006598333485308103\n",
      "Validation Loss: 0.004348737000634245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006816061787540093\n",
      "Training Loss: 0.0070175558852497485\n",
      "Training Loss: 0.006593761640251614\n",
      "Validation Loss: 0.004344833282926486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006811943555367179\n",
      "Training Loss: 0.007013030484085902\n",
      "Training Loss: 0.006589182000025176\n",
      "Validation Loss: 0.004340917110087329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006807812987826765\n",
      "Training Loss: 0.007008489618310704\n",
      "Training Loss: 0.006584594568121247\n",
      "Validation Loss: 0.004336988954318248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006803668451029807\n",
      "Training Loss: 0.0070039308327250185\n",
      "Training Loss: 0.0065799958934076135\n",
      "Validation Loss: 0.004333045370248931\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006799509483389556\n",
      "Training Loss: 0.006999351790873334\n",
      "Training Loss: 0.006575386297772639\n",
      "Validation Loss: 0.004329086722821792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006795334102935158\n",
      "Training Loss: 0.006994752716273069\n",
      "Training Loss: 0.006570761065813713\n",
      "Validation Loss: 0.004325109751753802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006791140282875858\n",
      "Training Loss: 0.006990129253827035\n",
      "Training Loss: 0.006566120849456638\n",
      "Validation Loss: 0.0043211145250629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006786927026696503\n",
      "Training Loss: 0.006985480347648263\n",
      "Training Loss: 0.006561463228426874\n",
      "Validation Loss: 0.004317100058451002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006782694315770641\n",
      "Training Loss: 0.006980805065250024\n",
      "Training Loss: 0.0065567844739416615\n",
      "Validation Loss: 0.004313062148540166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.0067784388293512165\n",
      "Training Loss: 0.0069761000375729056\n",
      "Training Loss: 0.006552085789153352\n",
      "Validation Loss: 0.004309000510178255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006774160465574823\n",
      "Training Loss: 0.006971363503253087\n",
      "Training Loss: 0.00654736268974375\n",
      "Validation Loss: 0.004304911873271961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00676985731406603\n",
      "Training Loss: 0.0069665939512196925\n",
      "Training Loss: 0.006542615836951882\n",
      "Validation Loss: 0.004300796359468753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006765527194947936\n",
      "Training Loss: 0.006961789578199386\n",
      "Training Loss: 0.006537840000237338\n",
      "Validation Loss: 0.004296651008026151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006761170082609169\n",
      "Training Loss: 0.00695694716530852\n",
      "Training Loss: 0.006533035965985618\n",
      "Validation Loss: 0.004292474140732266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006756783496239222\n",
      "Training Loss: 0.006952064698562026\n",
      "Training Loss: 0.006528199189342558\n",
      "Validation Loss: 0.004288262350149871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006752365295542404\n",
      "Training Loss: 0.006947140569100157\n",
      "Training Loss: 0.006523329562041908\n",
      "Validation Loss: 0.004284016047656703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006747914760489948\n",
      "Training Loss: 0.006942171627888456\n",
      "Training Loss: 0.0065184243046678605\n",
      "Validation Loss: 0.004279730185536731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006743430196074769\n",
      "Training Loss: 0.0069371556141413744\n",
      "Training Loss: 0.006513481132569723\n",
      "Validation Loss: 0.004275405000544708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006738910215208307\n",
      "Training Loss: 0.006932090845657513\n",
      "Training Loss: 0.0065084990457398816\n",
      "Validation Loss: 0.004271037524743947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006734352988423779\n",
      "Training Loss: 0.006926975017413497\n",
      "Training Loss: 0.0065034750627819445\n",
      "Validation Loss: 0.00426662446842058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006729756601853296\n",
      "Training Loss: 0.006921804002486169\n",
      "Training Loss: 0.00649840688041877\n",
      "Validation Loss: 0.004262165865583575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0067251194221898914\n",
      "Training Loss: 0.006916576798539608\n",
      "Training Loss: 0.006493291402584873\n",
      "Validation Loss: 0.004257656838561753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006720439195050858\n",
      "Training Loss: 0.006911289910785854\n",
      "Training Loss: 0.0064881275611696765\n",
      "Validation Loss: 0.0042530981394765755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006715714879101142\n",
      "Training Loss: 0.006905940527794883\n",
      "Training Loss: 0.006482912488281727\n",
      "Validation Loss: 0.004248483319704034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.00671094409422949\n",
      "Training Loss: 0.006900526821846142\n",
      "Training Loss: 0.006477643115213141\n",
      "Validation Loss: 0.0042438108233337326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006706125073833391\n",
      "Training Loss: 0.0068950439768377695\n",
      "Training Loss: 0.006472317763837054\n",
      "Validation Loss: 0.004239078687001648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006701254937797785\n",
      "Training Loss: 0.006889490474713966\n",
      "Training Loss: 0.0064669323223643\n",
      "Validation Loss: 0.0042342830938548685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006696332537103444\n",
      "Training Loss: 0.006883862168760971\n",
      "Training Loss: 0.0064614866877673195\n",
      "Validation Loss: 0.00422942106026026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006691355569055304\n",
      "Training Loss: 0.006878157403552905\n",
      "Training Loss: 0.006455975686549209\n",
      "Validation Loss: 0.004224491391979744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006686321062152274\n",
      "Training Loss: 0.006872372003272176\n",
      "Training Loss: 0.006450398178421892\n",
      "Validation Loss: 0.004219488612915065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.00668122801638674\n",
      "Training Loss: 0.006866502335760742\n",
      "Training Loss: 0.006444749524816871\n",
      "Validation Loss: 0.004214410293386893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006676073021371849\n",
      "Training Loss: 0.006860544552328065\n",
      "Training Loss: 0.006439027788001112\n",
      "Validation Loss: 0.004209251645324605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006670854187686928\n",
      "Training Loss: 0.00685449595679529\n",
      "Training Loss: 0.006433230040711351\n",
      "Validation Loss: 0.004204010551669792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.0066655689821345735\n",
      "Training Loss: 0.006848353926325217\n",
      "Training Loss: 0.006427353036124259\n",
      "Validation Loss: 0.0041986848221139544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006660215323208831\n",
      "Training Loss: 0.006842113345628604\n",
      "Training Loss: 0.006421393784694374\n",
      "Validation Loss: 0.004193268600573993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006654790312168189\n",
      "Training Loss: 0.006835770058678463\n",
      "Training Loss: 0.006415348030859604\n",
      "Validation Loss: 0.00418776044951689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006649289630004205\n",
      "Training Loss: 0.006829321690602228\n",
      "Training Loss: 0.006409214054583572\n",
      "Validation Loss: 0.004182155448106233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006643713978701271\n",
      "Training Loss: 0.006822763893287629\n",
      "Training Loss: 0.006402987084584311\n",
      "Validation Loss: 0.004176450588510194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.00663805816846434\n",
      "Training Loss: 0.006816092252265662\n",
      "Training Loss: 0.006396663824561983\n",
      "Validation Loss: 0.004170639348854677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.00663231929007452\n",
      "Training Loss: 0.0068093025020789354\n",
      "Training Loss: 0.0063902405084809285\n",
      "Validation Loss: 0.004164716904444013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.00662649541569408\n",
      "Training Loss: 0.00680239231325686\n",
      "Training Loss: 0.006383715425617993\n",
      "Validation Loss: 0.004158684289935725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006620583134936169\n",
      "Training Loss: 0.006795356140937656\n",
      "Training Loss: 0.006377082921680995\n",
      "Validation Loss: 0.004152533762402874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0066145792714087295\n",
      "Training Loss: 0.006788189660292119\n",
      "Training Loss: 0.006370339367422275\n",
      "Validation Loss: 0.004146262067448599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006608481224393472\n",
      "Training Loss: 0.006780888909706846\n",
      "Training Loss: 0.0063634818058926615\n",
      "Validation Loss: 0.004139863798954639\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0066022861102828755\n",
      "Training Loss: 0.006773450610926375\n",
      "Training Loss: 0.00635650543961674\n",
      "Validation Loss: 0.0041333326096698805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006595989055931568\n",
      "Training Loss: 0.006765868589282036\n",
      "Training Loss: 0.006349406369263306\n",
      "Validation Loss: 0.004126665892675937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006589588309288956\n",
      "Training Loss: 0.0067581410054117445\n",
      "Training Loss: 0.006342181677464396\n",
      "Validation Loss: 0.004119860251653898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006583079977426678\n",
      "Training Loss: 0.006750262463465333\n",
      "Training Loss: 0.006334826951497234\n",
      "Validation Loss: 0.004112910848827719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.00657646132458467\n",
      "Training Loss: 0.006742229791125282\n",
      "Training Loss: 0.006327337546390481\n",
      "Validation Loss: 0.004105810480181839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.0065697285952046516\n",
      "Training Loss: 0.00673403702210635\n",
      "Training Loss: 0.006319710324169137\n",
      "Validation Loss: 0.004098556243835457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006562877644901164\n",
      "Training Loss: 0.006725681581301614\n",
      "Training Loss: 0.006311939778970555\n",
      "Validation Loss: 0.004091141443945509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006555905459681526\n",
      "Training Loss: 0.006717159159015864\n",
      "Training Loss: 0.006304023632546887\n",
      "Validation Loss: 0.004083565230287737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006548809065716341\n",
      "Training Loss: 0.006708466632990167\n",
      "Training Loss: 0.006295958065893501\n",
      "Validation Loss: 0.00407582096980487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006541585403610952\n",
      "Training Loss: 0.006699601326836273\n",
      "Training Loss: 0.006287738865939901\n",
      "Validation Loss: 0.004067905756691994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006534231092082336\n",
      "Training Loss: 0.006690557911060751\n",
      "Training Loss: 0.006279362560599111\n",
      "Validation Loss: 0.0040598125040028875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006526742860442028\n",
      "Training Loss: 0.006681336051551625\n",
      "Training Loss: 0.006270827854750678\n",
      "Validation Loss: 0.004051542264707596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006519118133001029\n",
      "Training Loss: 0.006671931734308601\n",
      "Training Loss: 0.006262128772214055\n",
      "Validation Loss: 0.0040430864554652\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.0065113528596702965\n",
      "Training Loss: 0.006662342001218349\n",
      "Training Loss: 0.006253263755934313\n",
      "Validation Loss: 0.0040344410874158815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0065034446609206495\n",
      "Training Loss: 0.006652566385455429\n",
      "Training Loss: 0.006244232639437542\n",
      "Validation Loss: 0.0040256130467221304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006495391603675671\n",
      "Training Loss: 0.00664260569610633\n",
      "Training Loss: 0.006235032678232528\n",
      "Validation Loss: 0.0040165931862789425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0064871926483465354\n",
      "Training Loss: 0.006632457150844857\n",
      "Training Loss: 0.006225660898489877\n",
      "Validation Loss: 0.004007379562342853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006478844259981997\n",
      "Training Loss: 0.006622123285196722\n",
      "Training Loss: 0.006216122448677197\n",
      "Validation Loss: 0.0039979803429529325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006470348141738214\n",
      "Training Loss: 0.006611605735961348\n",
      "Training Loss: 0.0062064161128364504\n",
      "Validation Loss: 0.0039883909695991055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006461702537490055\n",
      "Training Loss: 0.0066009076207410545\n",
      "Training Loss: 0.0061965451098512855\n",
      "Validation Loss: 0.003978619082527382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.00645291072782129\n",
      "Training Loss: 0.006590034993132576\n",
      "Training Loss: 0.006186513742431998\n",
      "Validation Loss: 0.003968667125805501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.0064439740148372945\n",
      "Training Loss: 0.006578993733273819\n",
      "Training Loss: 0.00617632927838713\n",
      "Validation Loss: 0.003958544909713392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006434895609854721\n",
      "Training Loss: 0.006567793154390529\n",
      "Training Loss: 0.0061659992637578395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:26<30:59, 206.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.003948260525769941\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.08651368174701929\n",
      "Training Loss: 0.07194882493466138\n",
      "Training Loss: 0.06494210923090576\n",
      "Validation Loss: 0.061397552950663514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.05770734326913953\n",
      "Training Loss: 0.05495646914467216\n",
      "Training Loss: 0.05228116437792778\n",
      "Validation Loss: 0.05000633044231139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04662077285349369\n",
      "Training Loss: 0.04434019354172051\n",
      "Training Loss: 0.04185622123070061\n",
      "Validation Loss: 0.03896262471595507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.03594406422227621\n",
      "Training Loss: 0.03384049870073795\n",
      "Training Loss: 0.031271502794697884\n",
      "Validation Loss: 0.027592090366596586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.02551597916521132\n",
      "Training Loss: 0.024149935487657787\n",
      "Training Loss: 0.022396946474909783\n",
      "Validation Loss: 0.019677412246217888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.019056953059043737\n",
      "Training Loss: 0.01893384733237326\n",
      "Training Loss: 0.018233830148819834\n",
      "Validation Loss: 0.016421367848564065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01642156586749479\n",
      "Training Loss: 0.016539066662080586\n",
      "Training Loss: 0.016064003633800894\n",
      "Validation Loss: 0.014391316891009554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014691871800459921\n",
      "Training Loss: 0.01483927654568106\n",
      "Training Loss: 0.014438036961946637\n",
      "Validation Loss: 0.012797580074435204\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013325924526434392\n",
      "Training Loss: 0.013490985110402108\n",
      "Training Loss: 0.013135601796675474\n",
      "Validation Loss: 0.011511252593939727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.012227298573125154\n",
      "Training Loss: 0.012406133837066591\n",
      "Training Loss: 0.012084012953564524\n",
      "Validation Loss: 0.010469029830203633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.011343842381611466\n",
      "Training Loss: 0.011534367562271655\n",
      "Training Loss: 0.011235997109906748\n",
      "Validation Loss: 0.009623708383944095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010634628182742745\n",
      "Training Loss: 0.010835443981923163\n",
      "Training Loss: 0.010552184290718287\n",
      "Validation Loss: 0.008935343952891365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.010064669954590499\n",
      "Training Loss: 0.01027456320123747\n",
      "Training Loss: 0.009999185363994911\n",
      "Validation Loss: 0.008370594856632727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009604858610546217\n",
      "Training Loss: 0.009822580213658512\n",
      "Training Loss: 0.009549684541998432\n",
      "Validation Loss: 0.00790271115243393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.00923163756262511\n",
      "Training Loss: 0.009455758002586663\n",
      "Training Loss: 0.00918150445795618\n",
      "Validation Loss: 0.00751059674893328\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008926159390248357\n",
      "Training Loss: 0.009155190074816346\n",
      "Training Loss: 0.008877002571243792\n",
      "Validation Loss: 0.007177927690882529\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008673731725430116\n",
      "Training Loss: 0.008906312790932134\n",
      "Training Loss: 0.00862261102302\n",
      "Validation Loss: 0.0068923365207012284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008463188172318042\n",
      "Training Loss: 0.00869817579514347\n",
      "Training Loss: 0.008408109876327216\n",
      "Validation Loss: 0.006644596352262862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008286127087194473\n",
      "Training Loss: 0.00852261352352798\n",
      "Training Loss: 0.008225816942285746\n",
      "Validation Loss: 0.006427815921730205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008136208046926186\n",
      "Training Loss: 0.008373505345080048\n",
      "Training Loss: 0.008069916174281388\n",
      "Validation Loss: 0.006236820927758314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.00800858806935139\n",
      "Training Loss: 0.008246201259316877\n",
      "Training Loss: 0.007935942278709262\n",
      "Validation Loss: 0.006067677534426029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007899505781242624\n",
      "Training Loss: 0.008137096859281883\n",
      "Training Loss: 0.007820387858664617\n",
      "Validation Loss: 0.005917325274485132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0078059769910760225\n",
      "Training Loss: 0.00804332409054041\n",
      "Training Loss: 0.007720438532996923\n",
      "Validation Loss: 0.005783337692918486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007725581881823018\n",
      "Training Loss: 0.007962547054048627\n",
      "Training Loss: 0.00763378027244471\n",
      "Validation Loss: 0.005663723932066409\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.0076563180855009705\n",
      "Training Loss: 0.007892809241311624\n",
      "Training Loss: 0.007558465932961553\n",
      "Validation Loss: 0.005556811453000213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007596497795311734\n",
      "Training Loss: 0.007832450935384259\n",
      "Training Loss: 0.007492838224861771\n",
      "Validation Loss: 0.005461162499026552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0075446854578331115\n",
      "Training Loss: 0.007780044982209802\n",
      "Training Loss: 0.007435466926544905\n",
      "Validation Loss: 0.005375519007695525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007499649033416062\n",
      "Training Loss: 0.007734357821755111\n",
      "Training Loss: 0.007385116835357621\n",
      "Validation Loss: 0.005298759334385813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007460331787588075\n",
      "Training Loss: 0.007694326399359852\n",
      "Training Loss: 0.0073407218756619845\n",
      "Validation Loss: 0.005229876724626409\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007425826615653932\n",
      "Training Loss: 0.007659037674311548\n",
      "Training Loss: 0.007301366373430937\n",
      "Validation Loss: 0.005167976439030569\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007395362053066492\n",
      "Training Loss: 0.007627718269359321\n",
      "Training Loss: 0.00726626887684688\n",
      "Validation Loss: 0.0051122507710909745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0073682859912514685\n",
      "Training Loss: 0.00759971505147405\n",
      "Training Loss: 0.007234772690571845\n",
      "Validation Loss: 0.005061982228326496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007344049026723951\n",
      "Training Loss: 0.0075744846754241734\n",
      "Training Loss: 0.00720632013399154\n",
      "Validation Loss: 0.005016529973167298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.0073221923667006195\n",
      "Training Loss: 0.0075515747093595565\n",
      "Training Loss: 0.007180453180335462\n",
      "Validation Loss: 0.004975330759509561\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007302333925617859\n",
      "Training Loss: 0.007530616678996012\n",
      "Training Loss: 0.007156783002428711\n",
      "Validation Loss: 0.0049378795358300046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007284156996756792\n",
      "Training Loss: 0.007511304499348626\n",
      "Training Loss: 0.007134989857440814\n",
      "Validation Loss: 0.004903742432034459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007267395792296156\n",
      "Training Loss: 0.007493386855348945\n",
      "Training Loss: 0.007114802796859294\n",
      "Validation Loss: 0.004872532621591112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0072518323513213545\n",
      "Training Loss: 0.007476653949124739\n",
      "Training Loss: 0.007095993566326797\n",
      "Validation Loss: 0.004843912885283653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007237280523986556\n",
      "Training Loss: 0.007460931999376043\n",
      "Training Loss: 0.007078368947841227\n",
      "Validation Loss: 0.0048175859624739695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007223588454071433\n",
      "Training Loss: 0.007446075564948842\n",
      "Training Loss: 0.0070617642148863525\n",
      "Validation Loss: 0.0047932966635824085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007210626162122935\n",
      "Training Loss: 0.007431960169924423\n",
      "Training Loss: 0.007046041327994317\n",
      "Validation Loss: 0.004770819921166835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007198286174098029\n",
      "Training Loss: 0.007418482742505148\n",
      "Training Loss: 0.007031078344443813\n",
      "Validation Loss: 0.004749949919478445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007186477242503315\n",
      "Training Loss: 0.007405555724399164\n",
      "Training Loss: 0.007016773974755779\n",
      "Validation Loss: 0.004730512614341013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007175124034984037\n",
      "Training Loss: 0.007393102726200596\n",
      "Training Loss: 0.007003041012212634\n",
      "Validation Loss: 0.004712349438275932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007164160304237157\n",
      "Training Loss: 0.007381060306215659\n",
      "Training Loss: 0.006989806196652353\n",
      "Validation Loss: 0.004695324734078322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0071535335230873895\n",
      "Training Loss: 0.0073693753953557465\n",
      "Training Loss: 0.006977003943175078\n",
      "Validation Loss: 0.004679312158423068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00714319740771316\n",
      "Training Loss: 0.007357999846572056\n",
      "Training Loss: 0.0069645808322820815\n",
      "Validation Loss: 0.0046642014548820806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007133110134163872\n",
      "Training Loss: 0.007346893546637148\n",
      "Training Loss: 0.006952489286195487\n",
      "Validation Loss: 0.004649899210623895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007123241476365365\n",
      "Training Loss: 0.007336022906238213\n",
      "Training Loss: 0.006940688689937815\n",
      "Validation Loss: 0.00463631225284189\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007113561315927655\n",
      "Training Loss: 0.007325357634108513\n",
      "Training Loss: 0.006929143475135788\n",
      "Validation Loss: 0.004623365653234042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007104045227169991\n",
      "Training Loss: 0.007314871089765802\n",
      "Training Loss: 0.006917824324918911\n",
      "Validation Loss: 0.004610991586795014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007094672080711462\n",
      "Training Loss: 0.007304541720077396\n",
      "Training Loss: 0.006906705624423921\n",
      "Validation Loss: 0.00459912971572511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007085424870019778\n",
      "Training Loss: 0.0072943496727384625\n",
      "Training Loss: 0.006895764117361977\n",
      "Validation Loss: 0.004587721357545867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007076287555973977\n",
      "Training Loss: 0.007284278229344636\n",
      "Training Loss: 0.006884980396134779\n",
      "Validation Loss: 0.004576718320892182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0070672479155473415\n",
      "Training Loss: 0.007274312082445249\n",
      "Training Loss: 0.006874337453627959\n",
      "Validation Loss: 0.0045660805608554005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007058293229201809\n",
      "Training Loss: 0.00726443905965425\n",
      "Training Loss: 0.006863821564475074\n",
      "Validation Loss: 0.004555764110376954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0070494155527558175\n",
      "Training Loss: 0.007254647664958611\n",
      "Training Loss: 0.0068534193537198\n",
      "Validation Loss: 0.00454573659880317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007040605248766952\n",
      "Training Loss: 0.007244928734144196\n",
      "Training Loss: 0.006843121461570263\n",
      "Validation Loss: 0.004535966992294521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007031856119865552\n",
      "Training Loss: 0.007235273332335055\n",
      "Training Loss: 0.006832917232532054\n",
      "Validation Loss: 0.004526426164783914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00702316232083831\n",
      "Training Loss: 0.007225674705114216\n",
      "Training Loss: 0.006822799830697477\n",
      "Validation Loss: 0.004517088874421093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007014518475625664\n",
      "Training Loss: 0.007216126290149987\n",
      "Training Loss: 0.0068127612036187205\n",
      "Validation Loss: 0.004507932380323162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007005921083618887\n",
      "Training Loss: 0.007206622399389744\n",
      "Training Loss: 0.0068027970404364166\n",
      "Validation Loss: 0.004498937640082761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0069973641785327344\n",
      "Training Loss: 0.007197157943155616\n",
      "Training Loss: 0.006792901509907096\n",
      "Validation Loss: 0.004490086136469513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006988846230669878\n",
      "Training Loss: 0.007187728231074288\n",
      "Training Loss: 0.006783071055542678\n",
      "Validation Loss: 0.004481360983375585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006980364189948887\n",
      "Training Loss: 0.007178330324823037\n",
      "Training Loss: 0.00677329974481836\n",
      "Validation Loss: 0.004472747723064437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006971915044705384\n",
      "Training Loss: 0.0071689599251840265\n",
      "Training Loss: 0.006763585882727057\n",
      "Validation Loss: 0.004464232277784371\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00696349618548993\n",
      "Training Loss: 0.007159613635158166\n",
      "Training Loss: 0.006753924990771338\n",
      "Validation Loss: 0.004455803217905249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006955105335800908\n",
      "Training Loss: 0.007150287930853665\n",
      "Training Loss: 0.006744315146934241\n",
      "Validation Loss: 0.004447449548719346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006946739080594852\n",
      "Training Loss: 0.007140979256946594\n",
      "Training Loss: 0.006734752722550184\n",
      "Validation Loss: 0.004439159899458206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00693839619809296\n",
      "Training Loss: 0.007131685491185635\n",
      "Training Loss: 0.006725235875928774\n",
      "Validation Loss: 0.0044309261799109784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006930072858231142\n",
      "Training Loss: 0.007122403805842623\n",
      "Training Loss: 0.006715760723454878\n",
      "Validation Loss: 0.004422739375738448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006921768413158134\n",
      "Training Loss: 0.007113129456993193\n",
      "Training Loss: 0.006706325315753929\n",
      "Validation Loss: 0.004414594027846842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006913478444330394\n",
      "Training Loss: 0.007103860263014212\n",
      "Training Loss: 0.006696926497970708\n",
      "Validation Loss: 0.004406479548328043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006905201147892512\n",
      "Training Loss: 0.0070945932355243714\n",
      "Training Loss: 0.006687560058780946\n",
      "Validation Loss: 0.004398388916291715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006896933472016826\n",
      "Training Loss: 0.007085325667867437\n",
      "Training Loss: 0.006678226104704663\n",
      "Validation Loss: 0.004390315645834787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006888672837521881\n",
      "Training Loss: 0.007076053726486862\n",
      "Training Loss: 0.006668919856892898\n",
      "Validation Loss: 0.004382259699678195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0068804161960724745\n",
      "Training Loss: 0.007066774467239157\n",
      "Training Loss: 0.006659637666889467\n",
      "Validation Loss: 0.004374209088351829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006872160236816853\n",
      "Training Loss: 0.007057484341785312\n",
      "Training Loss: 0.006650377485784702\n",
      "Validation Loss: 0.00436616099565133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0068639026902383195\n",
      "Training Loss: 0.007048180677229538\n",
      "Training Loss: 0.006641135871759616\n",
      "Validation Loss: 0.004358112220155347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006855640078429133\n",
      "Training Loss: 0.007038859607418999\n",
      "Training Loss: 0.006631909085554071\n",
      "Validation Loss: 0.004350056131422687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006847368235467002\n",
      "Training Loss: 0.007029518574709073\n",
      "Training Loss: 0.006622694109100848\n",
      "Validation Loss: 0.004341988361262706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0068390861788066104\n",
      "Training Loss: 0.007020154087804258\n",
      "Training Loss: 0.006613488082075491\n",
      "Validation Loss: 0.0043339088390413885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006830789836240001\n",
      "Training Loss: 0.007010763045400381\n",
      "Training Loss: 0.006604287003865466\n",
      "Validation Loss: 0.004325811333268923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006822477190289646\n",
      "Training Loss: 0.007001342420699075\n",
      "Training Loss: 0.006595089113689028\n",
      "Validation Loss: 0.004317693313547107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006814143770025111\n",
      "Training Loss: 0.006991889303317293\n",
      "Training Loss: 0.006585889544803649\n",
      "Validation Loss: 0.004309553643191505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006805788528290577\n",
      "Training Loss: 0.006982401285786182\n",
      "Training Loss: 0.006576686350745149\n",
      "Validation Loss: 0.004301385226099637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0067974087625043466\n",
      "Training Loss: 0.006972875498468057\n",
      "Training Loss: 0.006567474641487933\n",
      "Validation Loss: 0.004293187229705744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00678900106693618\n",
      "Training Loss: 0.006963308714330196\n",
      "Training Loss: 0.006558252885006368\n",
      "Validation Loss: 0.0042849599999857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006780563179636374\n",
      "Training Loss: 0.006953699509613216\n",
      "Training Loss: 0.006549017439829186\n",
      "Validation Loss: 0.004276697460452116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006772093561594374\n",
      "Training Loss: 0.006944045025156811\n",
      "Training Loss: 0.0065397655178094285\n",
      "Validation Loss: 0.004268397872723388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006763590928167105\n",
      "Training Loss: 0.0069343425706028935\n",
      "Training Loss: 0.006530495149781927\n",
      "Validation Loss: 0.00426005999874219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006755051815416664\n",
      "Training Loss: 0.006924590972485021\n",
      "Training Loss: 0.006521203817683272\n",
      "Validation Loss: 0.0042516844003105516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00674647381354589\n",
      "Training Loss: 0.006914787667337805\n",
      "Training Loss: 0.006511887261876836\n",
      "Validation Loss: 0.004243265770721051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006737857180996798\n",
      "Training Loss: 0.0069049318204633895\n",
      "Training Loss: 0.006502545253606513\n",
      "Validation Loss: 0.00423480528132111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006729199504479766\n",
      "Training Loss: 0.006895020550582558\n",
      "Training Loss: 0.006493174615316093\n",
      "Validation Loss: 0.00422630081570634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006720499450457282\n",
      "Training Loss: 0.006885053595760837\n",
      "Training Loss: 0.006483773812651634\n",
      "Validation Loss: 0.004217750349034963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006711755302967503\n",
      "Training Loss: 0.0068750283180270344\n",
      "Training Loss: 0.006474340214044787\n",
      "Validation Loss: 0.004209155109554027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006702966075390577\n",
      "Training Loss: 0.006864944790722802\n",
      "Training Loss: 0.006464872805518098\n",
      "Validation Loss: 0.004200511968438252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006694131460390054\n",
      "Training Loss: 0.006854800811270252\n",
      "Training Loss: 0.006455369683681056\n",
      "Validation Loss: 0.004191820703975312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006685250381124206\n",
      "Training Loss: 0.006844596680020913\n",
      "Training Loss: 0.006445829877629876\n",
      "Validation Loss: 0.004183081309625021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006676323070423678\n",
      "Training Loss: 0.006834331827703864\n",
      "Training Loss: 0.006436253153369762\n",
      "Validation Loss: 0.0041742944217475365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006667347231414169\n",
      "Training Loss: 0.006824004970258102\n",
      "Training Loss: 0.006426636692485772\n",
      "Validation Loss: 0.004165458936359357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006658323727897368\n",
      "Training Loss: 0.006813616752624512\n",
      "Training Loss: 0.006416981756919995\n",
      "Validation Loss: 0.004156571676891842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006649251898052171\n",
      "Training Loss: 0.006803165384335444\n",
      "Training Loss: 0.006407285645254887\n",
      "Validation Loss: 0.0041476394039358985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.00664013150264509\n",
      "Training Loss: 0.006792652057483793\n",
      "Training Loss: 0.006397549656685442\n",
      "Validation Loss: 0.004138659499454825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006630963299539871\n",
      "Training Loss: 0.006782076947856695\n",
      "Training Loss: 0.006387772648595274\n",
      "Validation Loss: 0.004129630495176724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006621746651944704\n",
      "Training Loss: 0.0067714402917772535\n",
      "Training Loss: 0.006377955204807222\n",
      "Validation Loss: 0.0041205509986958645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006612482466734946\n",
      "Training Loss: 0.006760742327896878\n",
      "Training Loss: 0.006368096884689294\n",
      "Validation Loss: 0.00411142378959156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006603172497125343\n",
      "Training Loss: 0.006749984250636771\n",
      "Training Loss: 0.006358199634123593\n",
      "Validation Loss: 0.0041022500555617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006593815289670601\n",
      "Training Loss: 0.0067391666036564855\n",
      "Training Loss: 0.006348263765103184\n",
      "Validation Loss: 0.004093031650749192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006584413924720138\n",
      "Training Loss: 0.006728291483595967\n",
      "Training Loss: 0.006338288115221076\n",
      "Validation Loss: 0.004083766294590962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006574967498308979\n",
      "Training Loss: 0.006717357783345506\n",
      "Training Loss: 0.006328276041895151\n",
      "Validation Loss: 0.004074457355283117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006565478470874951\n",
      "Training Loss: 0.006706369252642616\n",
      "Training Loss: 0.006318227548035793\n",
      "Validation Loss: 0.004065104838057808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006555948401801288\n",
      "Training Loss: 0.006695326155750081\n",
      "Training Loss: 0.0063081435480853544\n",
      "Validation Loss: 0.00405571243092627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006546377296908759\n",
      "Training Loss: 0.006684231021208689\n",
      "Training Loss: 0.00629802766663488\n",
      "Validation Loss: 0.004046275438688528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006536768447840586\n",
      "Training Loss: 0.006673085485817865\n",
      "Training Loss: 0.006287880702293478\n",
      "Validation Loss: 0.004036802264830369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006527123296400532\n",
      "Training Loss: 0.006661892341217026\n",
      "Training Loss: 0.00627770456194412\n",
      "Validation Loss: 0.00402729309247702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.00651744345203042\n",
      "Training Loss: 0.006650653544347733\n",
      "Training Loss: 0.006267501781694591\n",
      "Validation Loss: 0.004017747626666063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006507731702877209\n",
      "Training Loss: 0.006639371666824445\n",
      "Training Loss: 0.0062572741165058685\n",
      "Validation Loss: 0.004008168249333466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006497989309718832\n",
      "Training Loss: 0.006628047812264413\n",
      "Training Loss: 0.0062470235466025766\n",
      "Validation Loss: 0.003998556510503456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006488218674785457\n",
      "Training Loss: 0.006616686632623896\n",
      "Training Loss: 0.006236754826386459\n",
      "Validation Loss: 0.0039889163656809026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006478424122324213\n",
      "Training Loss: 0.006605291669256985\n",
      "Training Loss: 0.006226468781824224\n",
      "Validation Loss: 0.003979247440767129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006468607500428334\n",
      "Training Loss: 0.00659386396408081\n",
      "Training Loss: 0.006216169522376731\n",
      "Validation Loss: 0.003969552463019958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006458770966273733\n",
      "Training Loss: 0.006582408692920581\n",
      "Training Loss: 0.006205860488698818\n",
      "Validation Loss: 0.00395983477382073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006448918832466006\n",
      "Training Loss: 0.006570928463479504\n",
      "Training Loss: 0.00619554472505115\n",
      "Validation Loss: 0.00395009787740144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006439052972127684\n",
      "Training Loss: 0.006559428181499243\n",
      "Training Loss: 0.006185226495144889\n",
      "Validation Loss: 0.003940345194933706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006429178365506232\n",
      "Training Loss: 0.006547910718945786\n",
      "Training Loss: 0.0061749071552185345\n",
      "Validation Loss: 0.0039305740109320435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006419296031235717\n",
      "Training Loss: 0.006536378276068717\n",
      "Training Loss: 0.006164591204142198\n",
      "Validation Loss: 0.003920791248183991\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.00640941129589919\n",
      "Training Loss: 0.006524837668985128\n",
      "Training Loss: 0.006154283716459759\n",
      "Validation Loss: 0.0039109982402335975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006399526752065867\n",
      "Training Loss: 0.006513291096780449\n",
      "Training Loss: 0.006143987238756381\n",
      "Validation Loss: 0.003901198590723693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006389645834569819\n",
      "Training Loss: 0.006501744092674926\n",
      "Training Loss: 0.006133705719257705\n",
      "Validation Loss: 0.0038913982237553163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0063797721400624145\n",
      "Training Loss: 0.006490200476255268\n",
      "Training Loss: 0.006123443924007006\n",
      "Validation Loss: 0.003881598688698677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006369910705834627\n",
      "Training Loss: 0.006478663921589032\n",
      "Training Loss: 0.006113204775028862\n",
      "Validation Loss: 0.003871797904466394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006360062886960805\n",
      "Training Loss: 0.006467138781445101\n",
      "Training Loss: 0.00610299215419218\n",
      "Validation Loss: 0.0038620034838356913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.00635023380862549\n",
      "Training Loss: 0.006455630757845938\n",
      "Training Loss: 0.006092812772258185\n",
      "Validation Loss: 0.003852222095180847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006340427827090025\n",
      "Training Loss: 0.00644414282287471\n",
      "Training Loss: 0.006082667267182842\n",
      "Validation Loss: 0.003842448891569557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.00633064782130532\n",
      "Training Loss: 0.006432679655263201\n",
      "Training Loss: 0.006072560182656161\n",
      "Validation Loss: 0.0038326919612506134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006320895939134061\n",
      "Training Loss: 0.006421245220699348\n",
      "Training Loss: 0.006062495768419467\n",
      "Validation Loss: 0.0038229548640475934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006311177716124803\n",
      "Training Loss: 0.006409842086140998\n",
      "Training Loss: 0.006052479837671853\n",
      "Validation Loss: 0.0038132400459902926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006301494284998626\n",
      "Training Loss: 0.006398473457666114\n",
      "Training Loss: 0.006042515614535659\n",
      "Validation Loss: 0.003803546797468463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006291848249966279\n",
      "Training Loss: 0.00638714189757593\n",
      "Training Loss: 0.006032603052444756\n",
      "Validation Loss: 0.0037938790242815538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.00628224405227229\n",
      "Training Loss: 0.006375853214412927\n",
      "Training Loss: 0.006022747168317437\n",
      "Validation Loss: 0.003784241419013464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006272684937575832\n",
      "Training Loss: 0.006364611915778369\n",
      "Training Loss: 0.006012950926087796\n",
      "Validation Loss: 0.003774640031990836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006263174117193558\n",
      "Training Loss: 0.006353422811953351\n",
      "Training Loss: 0.006003217179677449\n",
      "Validation Loss: 0.0037650736683215737\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006253715383936651\n",
      "Training Loss: 0.0063422898587305095\n",
      "Training Loss: 0.005993551175342873\n",
      "Validation Loss: 0.003755549386175077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006244312088238075\n",
      "Training Loss: 0.006331216756952926\n",
      "Training Loss: 0.005983954013208859\n",
      "Validation Loss: 0.0037460698657198234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006234965997864492\n",
      "Training Loss: 0.006320207752869464\n",
      "Training Loss: 0.005974429313791916\n",
      "Validation Loss: 0.003736637902231573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006225680793286301\n",
      "Training Loss: 0.006309265514137224\n",
      "Training Loss: 0.005964980950229801\n",
      "Validation Loss: 0.0037272557304920944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006216459114220925\n",
      "Training Loss: 0.006298395618796348\n",
      "Training Loss: 0.0059556102770147844\n",
      "Validation Loss: 0.003717924623875722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0062073026731377465\n",
      "Training Loss: 0.00628759954823181\n",
      "Training Loss: 0.005946321166702546\n",
      "Validation Loss: 0.0037086515712258772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006198215007316321\n",
      "Training Loss: 0.0062768812692957\n",
      "Training Loss: 0.005937115838751197\n",
      "Validation Loss: 0.0036994378518030633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0061891978402854875\n",
      "Training Loss: 0.00626624416327104\n",
      "Training Loss: 0.00592799625126645\n",
      "Validation Loss: 0.0036902837978487605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0061802527942927555\n",
      "Training Loss: 0.006255690262769349\n",
      "Training Loss: 0.005918964886222966\n",
      "Validation Loss: 0.0036811991424686957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006171382708707825\n",
      "Training Loss: 0.006245224224985577\n",
      "Training Loss: 0.005910024534678086\n",
      "Validation Loss: 0.003672178967442531\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006162589694722556\n",
      "Training Loss: 0.00623484774492681\n",
      "Training Loss: 0.00590117642947007\n",
      "Validation Loss: 0.0036632292910499936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006153874293086119\n",
      "Training Loss: 0.006224562883144245\n",
      "Training Loss: 0.0058924225036753345\n",
      "Validation Loss: 0.0036543510354573976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006145238468889147\n",
      "Training Loss: 0.006214373182156123\n",
      "Training Loss: 0.005883764461614192\n",
      "Validation Loss: 0.0036455488834383613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0061366842029383405\n",
      "Training Loss: 0.006204278766526841\n",
      "Training Loss: 0.00587520201166626\n",
      "Validation Loss: 0.0036368224641643047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.0061282107926672325\n",
      "Training Loss: 0.006194282958167605\n",
      "Training Loss: 0.005866738964105025\n",
      "Validation Loss: 0.0036281797756294435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006119821182219312\n",
      "Training Loss: 0.006184387311222963\n",
      "Training Loss: 0.0058583748247474435\n",
      "Validation Loss: 0.003619615425449911\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006111515917000361\n",
      "Training Loss: 0.0061745937814703215\n",
      "Training Loss: 0.0058501109504140916\n",
      "Validation Loss: 0.0036111353959344078\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006103296332294121\n",
      "Training Loss: 0.0061649034637957815\n",
      "Training Loss: 0.005841949353925884\n",
      "Validation Loss: 0.0036027421638516063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006095162378624081\n",
      "Training Loss: 0.006155317268567159\n",
      "Training Loss: 0.005833887863554992\n",
      "Validation Loss: 0.0035944349829662133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006087113560060971\n",
      "Training Loss: 0.006145836927462369\n",
      "Training Loss: 0.005825929911225103\n",
      "Validation Loss: 0.003586212345765213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.0060791516804602\n",
      "Training Loss: 0.0061364621040411295\n",
      "Training Loss: 0.005818073191330768\n",
      "Validation Loss: 0.003578081814012375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006071276632137596\n",
      "Training Loss: 0.0061271940707229074\n",
      "Training Loss: 0.0058103196992306035\n",
      "Validation Loss: 0.0035700426349322195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006063488331274129\n",
      "Training Loss: 0.006118034510873258\n",
      "Training Loss: 0.00580266910023056\n",
      "Validation Loss: 0.003562092733977551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006055788105586543\n",
      "Training Loss: 0.0061089829885168\n",
      "Training Loss: 0.0057951206486905\n",
      "Validation Loss: 0.0035542377272066187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006048174462048337\n",
      "Training Loss: 0.006100039917510003\n",
      "Training Loss: 0.0057876754144672304\n",
      "Validation Loss: 0.0035464777258025965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006040647241752595\n",
      "Training Loss: 0.006091205582488328\n",
      "Training Loss: 0.0057803315576165915\n",
      "Validation Loss: 0.0035388102059074667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006033206543070264\n",
      "Training Loss: 0.006082479104516096\n",
      "Training Loss: 0.0057730896683642645\n",
      "Validation Loss: 0.003531240476190709\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.0060258525935932995\n",
      "Training Loss: 0.006073861623881385\n",
      "Training Loss: 0.0057659498637076465\n",
      "Validation Loss: 0.0035237643385065322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006018584916600958\n",
      "Training Loss: 0.006065351755241863\n",
      "Training Loss: 0.005758910055737943\n",
      "Validation Loss: 0.003516385347446364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0060114021954359486\n",
      "Training Loss: 0.006056949648191221\n",
      "Training Loss: 0.005751970220007934\n",
      "Validation Loss: 0.003509102181892507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.0060043043299810965\n",
      "Training Loss: 0.006048655392369255\n",
      "Training Loss: 0.005745129700517282\n",
      "Validation Loss: 0.003501915866692205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005997291279491037\n",
      "Training Loss: 0.0060404670215211806\n",
      "Training Loss: 0.005738387190504\n",
      "Validation Loss: 0.0034948251310871975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005990361845470034\n",
      "Training Loss: 0.006032385565922596\n",
      "Training Loss: 0.00573174306191504\n",
      "Validation Loss: 0.0034878322405981297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005983515918487683\n",
      "Training Loss: 0.006024408992379904\n",
      "Training Loss: 0.005725193888065405\n",
      "Validation Loss: 0.003480933187398641\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005976750534609891\n",
      "Training Loss: 0.0060165367112495005\n",
      "Training Loss: 0.005718741245218552\n",
      "Validation Loss: 0.0034741307242532795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005970068336464465\n",
      "Training Loss: 0.006008768531028181\n",
      "Training Loss: 0.005712382092606276\n",
      "Validation Loss: 0.0034674226804741063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005963466273969971\n",
      "Training Loss: 0.006001102272421122\n",
      "Training Loss: 0.00570611679693684\n",
      "Validation Loss: 0.003460810250299198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005956942703924142\n",
      "Training Loss: 0.005993536621099338\n",
      "Training Loss: 0.005699942550854757\n",
      "Validation Loss: 0.003454290711048865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005950499034370295\n",
      "Training Loss: 0.005986071300576441\n",
      "Training Loss: 0.005693858791491948\n",
      "Validation Loss: 0.003447865291624173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005944133003358729\n",
      "Training Loss: 0.005978705596644432\n",
      "Training Loss: 0.005687863837811165\n",
      "Validation Loss: 0.003441531454432714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005937843568972312\n",
      "Training Loss: 0.005971436585532501\n",
      "Training Loss: 0.005681957583292387\n",
      "Validation Loss: 0.0034352904139871424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005931629805709235\n",
      "Training Loss: 0.005964264349313453\n",
      "Training Loss: 0.005676136968540959\n",
      "Validation Loss: 0.003429138221976797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005925490270019509\n",
      "Training Loss: 0.005957185386796482\n",
      "Training Loss: 0.005670400916133076\n",
      "Validation Loss: 0.003423075856159577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005919425253523514\n",
      "Training Loss: 0.005950200615334324\n",
      "Training Loss: 0.0056647486757719885\n",
      "Validation Loss: 0.00341710289730952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005913431303342804\n",
      "Training Loss: 0.005943307279376313\n",
      "Training Loss: 0.005659177146735601\n",
      "Validation Loss: 0.003411216380760032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005907508910167962\n",
      "Training Loss: 0.005936502983095124\n",
      "Training Loss: 0.005653687244048342\n",
      "Validation Loss: 0.003405413270556483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005901657302747481\n",
      "Training Loss: 0.005929788291687146\n",
      "Training Loss: 0.00564827480353415\n",
      "Validation Loss: 0.0033996988642500357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.0058958737959619615\n",
      "Training Loss: 0.005923160233651288\n",
      "Training Loss: 0.00564294052135665\n",
      "Validation Loss: 0.0033940668891477032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0058901583438273515\n",
      "Training Loss: 0.005916616710019298\n",
      "Training Loss: 0.0056376822770107535\n",
      "Validation Loss: 0.0033885154178564885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005884510158794\n",
      "Training Loss: 0.005910156965255737\n",
      "Training Loss: 0.005632497637998312\n",
      "Validation Loss: 0.003383043727031752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005878927080193535\n",
      "Training Loss: 0.005903778495267033\n",
      "Training Loss: 0.005627384564140811\n",
      "Validation Loss: 0.0033776502274081447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005873408317565918\n",
      "Training Loss: 0.005897480545681902\n",
      "Training Loss: 0.005622343209106475\n",
      "Validation Loss: 0.0033723347463247397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005867952855769545\n",
      "Training Loss: 0.00589126082661096\n",
      "Training Loss: 0.005617370982654393\n",
      "Validation Loss: 0.003367097357685646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.0058625581336673345\n",
      "Training Loss: 0.005885117028956301\n",
      "Training Loss: 0.00561246631143149\n",
      "Validation Loss: 0.0033619337927110575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005857224995852448\n",
      "Training Loss: 0.005879048375063576\n",
      "Training Loss: 0.005607628244906664\n",
      "Validation Loss: 0.003356842902290185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005851950879441574\n",
      "Training Loss: 0.005873053837567568\n",
      "Training Loss: 0.005602854011231102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [06:56<27:46, 208.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0033518238348907298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.10382066588848829\n",
      "Training Loss: 0.08293663155287505\n",
      "Training Loss: 0.07383953232318163\n",
      "Validation Loss: 0.07106847692741437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0678276763483882\n",
      "Training Loss: 0.066456453576684\n",
      "Training Loss: 0.06529856342822313\n",
      "Validation Loss: 0.06456329037299317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.0614461075514555\n",
      "Training Loss: 0.059243164714425804\n",
      "Training Loss: 0.056995768435299396\n",
      "Validation Loss: 0.05458006183250567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.051261434815824035\n",
      "Training Loss: 0.048148061195388434\n",
      "Training Loss: 0.0449816713295877\n",
      "Validation Loss: 0.04130139681144377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03821391527540982\n",
      "Training Loss: 0.03531561327166855\n",
      "Training Loss: 0.03240773088298738\n",
      "Validation Loss: 0.02895451949260543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.026764302453957497\n",
      "Training Loss: 0.02526728145778179\n",
      "Training Loss: 0.02343175130430609\n",
      "Validation Loss: 0.020970371264043483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.019812762294895946\n",
      "Training Loss: 0.019551751702092588\n",
      "Training Loss: 0.018542843260802327\n",
      "Validation Loss: 0.016734072046479986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01634189108153805\n",
      "Training Loss: 0.01664687622571364\n",
      "Training Loss: 0.016031771118287\n",
      "Validation Loss: 0.014423021868792144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01454117964487523\n",
      "Training Loss: 0.015013899081386626\n",
      "Training Loss: 0.01455671404255554\n",
      "Validation Loss: 0.01292709660130354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013404986958485098\n",
      "Training Loss: 0.013895843548234553\n",
      "Training Loss: 0.013495682321954519\n",
      "Validation Loss: 0.011767419455363677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012525982675142586\n",
      "Training Loss: 0.012984897724818438\n",
      "Training Loss: 0.01259675232344307\n",
      "Validation Loss: 0.010743403208201354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011745983429718762\n",
      "Training Loss: 0.012154417395358906\n",
      "Training Loss: 0.01175626921467483\n",
      "Validation Loss: 0.009764078742918673\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.010996237605577336\n",
      "Training Loss: 0.011338770757429301\n",
      "Training Loss: 0.010914121055975556\n",
      "Validation Loss: 0.00876216415650724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010213448366848753\n",
      "Training Loss: 0.010467794823925942\n",
      "Training Loss: 0.010025804875185713\n",
      "Validation Loss: 0.007755079079063588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009425124009139836\n",
      "Training Loss: 0.009636147964047269\n",
      "Training Loss: 0.009249863640870899\n",
      "Validation Loss: 0.006986793721869086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008837636457756162\n",
      "Training Loss: 0.009057930236449465\n",
      "Training Loss: 0.008729668949963526\n",
      "Validation Loss: 0.0065000917215758324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008475159186637028\n",
      "Training Loss: 0.008705671182833613\n",
      "Training Loss: 0.008402098473161458\n",
      "Validation Loss: 0.0061814310421560255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008248209423618392\n",
      "Training Loss: 0.008480775107163935\n",
      "Training Loss: 0.008183631381252781\n",
      "Validation Loss: 0.0059556384228190845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008093502337578684\n",
      "Training Loss: 0.008324935301207006\n",
      "Training Loss: 0.008026437270455062\n",
      "Validation Loss: 0.005785576682642437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00798022714909166\n",
      "Training Loss: 0.008210091539658605\n",
      "Training Loss: 0.007906851228326559\n",
      "Validation Loss: 0.005652111697303696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007893236021045595\n",
      "Training Loss: 0.008121724041411654\n",
      "Training Loss: 0.007812292146263644\n",
      "Validation Loss: 0.005544171312148944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00782407897990197\n",
      "Training Loss: 0.008051403319695965\n",
      "Training Loss: 0.007735292537836358\n",
      "Validation Loss: 0.005454717026081648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007767526266397908\n",
      "Training Loss: 0.007993820406263695\n",
      "Training Loss: 0.0076710496260784565\n",
      "Validation Loss: 0.0053789944026954055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007720129253575578\n",
      "Training Loss: 0.007945459249895067\n",
      "Training Loss: 0.007616316943895072\n",
      "Validation Loss: 0.005313681219469003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007679530798923224\n",
      "Training Loss: 0.007903921196702867\n",
      "Training Loss: 0.00756882740999572\n",
      "Validation Loss: 0.005256402043343177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007644085125648416\n",
      "Training Loss: 0.007867531861411408\n",
      "Training Loss: 0.007526958270464092\n",
      "Validation Loss: 0.005205424471099055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007612617361592129\n",
      "Training Loss: 0.007835102907847613\n",
      "Training Loss: 0.007489535856293515\n",
      "Validation Loss: 0.005159478962913239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007584286815836094\n",
      "Training Loss: 0.007805777626344934\n",
      "Training Loss: 0.007455690809292719\n",
      "Validation Loss: 0.005117615330388791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00755847710184753\n",
      "Training Loss: 0.007778930742060766\n",
      "Training Loss: 0.007424769737990573\n",
      "Validation Loss: 0.005079121287033129\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007534732331405394\n",
      "Training Loss: 0.007754096902208403\n",
      "Training Loss: 0.007396277454681695\n",
      "Validation Loss: 0.005043454662493817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007512714758631773\n",
      "Training Loss: 0.007730928632663563\n",
      "Training Loss: 0.007369832248659804\n",
      "Validation Loss: 0.005010196011712293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007492167602758854\n",
      "Training Loss: 0.0077091611828655005\n",
      "Training Loss: 0.007345133855706081\n",
      "Validation Loss: 0.004979022001596481\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007472892488585785\n",
      "Training Loss: 0.007688589987810701\n",
      "Training Loss: 0.007321944708237425\n",
      "Validation Loss: 0.004949679432745521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007454737707739696\n",
      "Training Loss: 0.007669057282619178\n",
      "Training Loss: 0.007300073736114427\n",
      "Validation Loss: 0.004921965405679821\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007437580576515756\n",
      "Training Loss: 0.0076504374120850115\n",
      "Training Loss: 0.007279363827547058\n",
      "Validation Loss: 0.004895715048180872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00742132168088574\n",
      "Training Loss: 0.00763262982130982\n",
      "Training Loss: 0.007259686331963167\n",
      "Validation Loss: 0.004870799691233198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007405878686113283\n",
      "Training Loss: 0.007615551025373861\n",
      "Training Loss: 0.007240932523272931\n",
      "Validation Loss: 0.004847101292970559\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007391182644059881\n",
      "Training Loss: 0.007599134028423577\n",
      "Training Loss: 0.007223008330911398\n",
      "Validation Loss: 0.0048245334124004235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007377172746928408\n",
      "Training Loss: 0.007583320464473218\n",
      "Training Loss: 0.007205835173372179\n",
      "Validation Loss: 0.004803012886471795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007363795862765983\n",
      "Training Loss: 0.0075680606637615715\n",
      "Training Loss: 0.0071893411653582\n",
      "Validation Loss: 0.004782466793411903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007351003512740135\n",
      "Training Loss: 0.0075533113593701275\n",
      "Training Loss: 0.007173467047978193\n",
      "Validation Loss: 0.004762835889594273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0073387523234123364\n",
      "Training Loss: 0.007539034090004861\n",
      "Training Loss: 0.007158158323727548\n",
      "Validation Loss: 0.004744066848953286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.0073270009673433376\n",
      "Training Loss: 0.007525194322224707\n",
      "Training Loss: 0.007143367541721091\n",
      "Validation Loss: 0.004726107785572413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00731571220967453\n",
      "Training Loss: 0.0075117607309948655\n",
      "Training Loss: 0.0071290499402675775\n",
      "Validation Loss: 0.004708915205902598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007304850246873685\n",
      "Training Loss: 0.007498703972669318\n",
      "Training Loss: 0.0071151680336333815\n",
      "Validation Loss: 0.004692447745225529\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007294382133986801\n",
      "Training Loss: 0.007485996527830139\n",
      "Training Loss: 0.007101687226677314\n",
      "Validation Loss: 0.004676669492030495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0072842750349082054\n",
      "Training Loss: 0.00747361580026336\n",
      "Training Loss: 0.007088574910303578\n",
      "Validation Loss: 0.004661543417088897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007274498615879565\n",
      "Training Loss: 0.007461536853807047\n",
      "Training Loss: 0.007075802324106917\n",
      "Validation Loss: 0.004647034895344732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007265024933731184\n",
      "Training Loss: 0.0074497380433604125\n",
      "Training Loss: 0.00706334482645616\n",
      "Validation Loss: 0.004633116374953828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007255824579624459\n",
      "Training Loss: 0.0074381983035709705\n",
      "Training Loss: 0.0070511786045972255\n",
      "Validation Loss: 0.004619756220379488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007246870774542913\n",
      "Training Loss: 0.007426899397978559\n",
      "Training Loss: 0.007039281440665945\n",
      "Validation Loss: 0.004606928486701394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007238137754611671\n",
      "Training Loss: 0.007415823171613738\n",
      "Training Loss: 0.007027634300757199\n",
      "Validation Loss: 0.0045946069713158726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007229600286809728\n",
      "Training Loss: 0.007404953232035041\n",
      "Training Loss: 0.007016220552613959\n",
      "Validation Loss: 0.004582761378116446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007221236183540896\n",
      "Training Loss: 0.007394273879472166\n",
      "Training Loss: 0.0070050232741050425\n",
      "Validation Loss: 0.004571368577733134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007213022506912239\n",
      "Training Loss: 0.007383771673776209\n",
      "Training Loss: 0.006994029573397711\n",
      "Validation Loss: 0.004560403784166687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007204939384246245\n",
      "Training Loss: 0.00737343511893414\n",
      "Training Loss: 0.006983228808967397\n",
      "Validation Loss: 0.004549839467155549\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007196966329938732\n",
      "Training Loss: 0.007363252460490913\n",
      "Training Loss: 0.0069726087851449845\n",
      "Validation Loss: 0.004539651122582511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007189089259481989\n",
      "Training Loss: 0.007353214913746342\n",
      "Training Loss: 0.006962161601986736\n",
      "Validation Loss: 0.004529814111602524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007181290620937943\n",
      "Training Loss: 0.007343314227182418\n",
      "Training Loss: 0.006951879885746166\n",
      "Validation Loss: 0.004520302973269077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007173558903159574\n",
      "Training Loss: 0.007333543680142611\n",
      "Training Loss: 0.006941757354652509\n",
      "Validation Loss: 0.004511094512156305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007165882593253628\n",
      "Training Loss: 0.00732389714801684\n",
      "Training Loss: 0.006931788020301611\n",
      "Validation Loss: 0.004502157700310848\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007158255471149459\n",
      "Training Loss: 0.007314369751838967\n",
      "Training Loss: 0.006921967978123575\n",
      "Validation Loss: 0.004493469882526257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0071506698074517774\n",
      "Training Loss: 0.007304958143504336\n",
      "Training Loss: 0.00691229406860657\n",
      "Validation Loss: 0.004485008746955879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0071431215800112115\n",
      "Training Loss: 0.007295657198410481\n",
      "Training Loss: 0.006902761660749093\n",
      "Validation Loss: 0.004476752070699599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007135608983808197\n",
      "Training Loss: 0.007286464595235884\n",
      "Training Loss: 0.006893367836019024\n",
      "Validation Loss: 0.004468672541938094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007128131607896648\n",
      "Training Loss: 0.007277376963756978\n",
      "Training Loss: 0.006884108855156228\n",
      "Validation Loss: 0.00446075597369855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0071206884912680835\n",
      "Training Loss: 0.007268390452954918\n",
      "Training Loss: 0.006874982422450557\n",
      "Validation Loss: 0.004452983981516379\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007113281126366928\n",
      "Training Loss: 0.00725950171938166\n",
      "Training Loss: 0.006865983690368012\n",
      "Validation Loss: 0.0044453391135576064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007105909120873548\n",
      "Training Loss: 0.007250707925995812\n",
      "Training Loss: 0.006857109018601477\n",
      "Validation Loss: 0.004437812218793113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007098573976545595\n",
      "Training Loss: 0.007242003827122971\n",
      "Training Loss: 0.006848354362882674\n",
      "Validation Loss: 0.004430388589651229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007091277076979168\n",
      "Training Loss: 0.007233386905863881\n",
      "Training Loss: 0.006839715634705499\n",
      "Validation Loss: 0.004423064990047617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007084016594453715\n",
      "Training Loss: 0.0072248532122466715\n",
      "Training Loss: 0.006831187136704102\n",
      "Validation Loss: 0.004415830550192112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007076794466702268\n",
      "Training Loss: 0.007216397031443194\n",
      "Training Loss: 0.006822764615062624\n",
      "Validation Loss: 0.004408681782857212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007069609071477316\n",
      "Training Loss: 0.007208015044452623\n",
      "Training Loss: 0.0068144435971044005\n",
      "Validation Loss: 0.004401617778302955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007062458252767101\n",
      "Training Loss: 0.007199702245416119\n",
      "Training Loss: 0.006806218484416604\n",
      "Validation Loss: 0.00439463507284651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007055341813829727\n",
      "Training Loss: 0.00719145436421968\n",
      "Training Loss: 0.006798085293266923\n",
      "Validation Loss: 0.004387732150472617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007048257195856422\n",
      "Training Loss: 0.0071832670923322435\n",
      "Training Loss: 0.006790037340251729\n",
      "Validation Loss: 0.004380909622034706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007041201272513718\n",
      "Training Loss: 0.007175135971046984\n",
      "Training Loss: 0.0067820729000959545\n",
      "Validation Loss: 0.004374168942724303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007034172346466221\n",
      "Training Loss: 0.007167056823382154\n",
      "Training Loss: 0.006774185687536374\n",
      "Validation Loss: 0.004367508561863156\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.0070271668065106496\n",
      "Training Loss: 0.007159024763386697\n",
      "Training Loss: 0.006766370448749512\n",
      "Validation Loss: 0.004360931599120285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007020181211992167\n",
      "Training Loss: 0.007151036453433335\n",
      "Training Loss: 0.006758625797228888\n",
      "Validation Loss: 0.004354437231740213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007013213313184679\n",
      "Training Loss: 0.0071430875279475\n",
      "Training Loss: 0.006750945552485063\n",
      "Validation Loss: 0.004348025472149295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0070062616060022264\n",
      "Training Loss: 0.007135175442090258\n",
      "Training Loss: 0.006743327784352005\n",
      "Validation Loss: 0.004341697418444863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006999322429182939\n",
      "Training Loss: 0.007127296611433849\n",
      "Training Loss: 0.006735768908401951\n",
      "Validation Loss: 0.0043354543845504105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006992394182016142\n",
      "Training Loss: 0.007119448655284941\n",
      "Training Loss: 0.006728265904821455\n",
      "Validation Loss: 0.004329293174930754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006985474596731365\n",
      "Training Loss: 0.0071116287866607305\n",
      "Training Loss: 0.006720818583853543\n",
      "Validation Loss: 0.004323216012595326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0069785639597103\n",
      "Training Loss: 0.007103836681926623\n",
      "Training Loss: 0.0067134236427955326\n",
      "Validation Loss: 0.004317220643141799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006971660297131166\n",
      "Training Loss: 0.007096069507533684\n",
      "Training Loss: 0.00670608026906848\n",
      "Validation Loss: 0.004311307642106595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00696476535871625\n",
      "Training Loss: 0.007088328381069004\n",
      "Training Loss: 0.006698788567446172\n",
      "Validation Loss: 0.0043054741278834895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006957879464025609\n",
      "Training Loss: 0.007080611559795216\n",
      "Training Loss: 0.006691549462266267\n",
      "Validation Loss: 0.004299718787857028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006951004161383025\n",
      "Training Loss: 0.007072920685168356\n",
      "Training Loss: 0.006684362472733483\n",
      "Validation Loss: 0.004294039387899461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006944143395521678\n",
      "Training Loss: 0.00706525651505217\n",
      "Training Loss: 0.0066772299318108705\n",
      "Validation Loss: 0.004288435103293257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006937299254350365\n",
      "Training Loss: 0.007057620800333097\n",
      "Training Loss: 0.006670153327286243\n",
      "Validation Loss: 0.004282903034773687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00693047636828851\n",
      "Training Loss: 0.007050015716813505\n",
      "Training Loss: 0.006663134478731081\n",
      "Validation Loss: 0.004277441884767724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006923679302562959\n",
      "Training Loss: 0.007042442878009751\n",
      "Training Loss: 0.006656175572425127\n",
      "Validation Loss: 0.004272050065972078\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006916913134627976\n",
      "Training Loss: 0.007034905365435407\n",
      "Training Loss: 0.006649279339471832\n",
      "Validation Loss: 0.004266724109471765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00691018337267451\n",
      "Training Loss: 0.007027404571417719\n",
      "Training Loss: 0.006642447666963563\n",
      "Validation Loss: 0.004261464992370666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006903494282159955\n",
      "Training Loss: 0.0070199434948153795\n",
      "Training Loss: 0.006635682220803574\n",
      "Validation Loss: 0.004256268446542992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006896852155332454\n",
      "Training Loss: 0.007012524136807769\n",
      "Training Loss: 0.006628984734416008\n",
      "Validation Loss: 0.004251133370621318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006890262005617842\n",
      "Training Loss: 0.0070051487197633835\n",
      "Training Loss: 0.006622355511644855\n",
      "Validation Loss: 0.004246055822181149\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006883727887761779\n",
      "Training Loss: 0.006997818851377815\n",
      "Training Loss: 0.006615795665420592\n",
      "Validation Loss: 0.0042410366174377755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00687725271214731\n",
      "Training Loss: 0.006990534546785057\n",
      "Training Loss: 0.006609301870921627\n",
      "Validation Loss: 0.00423606885780235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00687084200209938\n",
      "Training Loss: 0.006983295631362125\n",
      "Training Loss: 0.006602875788230449\n",
      "Validation Loss: 0.004231154190747884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006864494798937812\n",
      "Training Loss: 0.006976102872285992\n",
      "Training Loss: 0.0065965127036906775\n",
      "Validation Loss: 0.0042262871427921934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006858213766827248\n",
      "Training Loss: 0.006968954048352316\n",
      "Training Loss: 0.00659021001891233\n",
      "Validation Loss: 0.004221463280996789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006851999644422904\n",
      "Training Loss: 0.006961847255006433\n",
      "Training Loss: 0.006583963128505275\n",
      "Validation Loss: 0.004216676453008118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006845851538237184\n",
      "Training Loss: 0.006954780678497628\n",
      "Training Loss: 0.006577766629634425\n",
      "Validation Loss: 0.004211922414899082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006839766891789623\n",
      "Training Loss: 0.006947749432874843\n",
      "Training Loss: 0.006571614259155467\n",
      "Validation Loss: 0.004207192807003144\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006833744358154945\n",
      "Training Loss: 0.0069407493632752445\n",
      "Training Loss: 0.00656549934996292\n",
      "Validation Loss: 0.0042024824383741855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006827778883161955\n",
      "Training Loss: 0.006933774977223948\n",
      "Training Loss: 0.006559414165094495\n",
      "Validation Loss: 0.004197783180868274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006821865446981974\n",
      "Training Loss: 0.006926820260705426\n",
      "Training Loss: 0.006553351202746853\n",
      "Validation Loss: 0.004193084503476916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006815999746322632\n",
      "Training Loss: 0.006919877333566546\n",
      "Training Loss: 0.006547300425590947\n",
      "Validation Loss: 0.004188378874521201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006810174904530868\n",
      "Training Loss: 0.006912938492605463\n",
      "Training Loss: 0.006541250786976888\n",
      "Validation Loss: 0.0041836516099741285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006804383343551308\n",
      "Training Loss: 0.006905995309352875\n",
      "Training Loss: 0.00653519517974928\n",
      "Validation Loss: 0.004178894567957378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006798615868901834\n",
      "Training Loss: 0.0068990376079455015\n",
      "Training Loss: 0.0065291209716815506\n",
      "Validation Loss: 0.004174094512441269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006792864745366387\n",
      "Training Loss: 0.006892055146163329\n",
      "Training Loss: 0.006523018543375656\n",
      "Validation Loss: 0.004169238143302291\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.0067871207784628495\n",
      "Training Loss: 0.006885035545565188\n",
      "Training Loss: 0.006516874817898497\n",
      "Validation Loss: 0.0041643119138519\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006781370902899653\n",
      "Training Loss: 0.006877966595347971\n",
      "Training Loss: 0.006510677983751521\n",
      "Validation Loss: 0.004159300855564979\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0067756055342033505\n",
      "Training Loss: 0.006870834288420156\n",
      "Training Loss: 0.006504416392417624\n",
      "Validation Loss: 0.0041541913072997184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006769811020931229\n",
      "Training Loss: 0.006863623764365912\n",
      "Training Loss: 0.006498074386036024\n",
      "Validation Loss: 0.0041489633672682335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006763975273352116\n",
      "Training Loss: 0.00685631901375018\n",
      "Training Loss: 0.006491640191525221\n",
      "Validation Loss: 0.004143599352767963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006758081929874606\n",
      "Training Loss: 0.006848902689525858\n",
      "Training Loss: 0.006485096372198313\n",
      "Validation Loss: 0.004138081302484393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006752116436837241\n",
      "Training Loss: 0.006841354741482064\n",
      "Training Loss: 0.006478429146809504\n",
      "Validation Loss: 0.004132390349941182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.0067460610950365665\n",
      "Training Loss: 0.006833654880756513\n",
      "Training Loss: 0.00647162017528899\n",
      "Validation Loss: 0.0041265035757083405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0067398982198210436\n",
      "Training Loss: 0.006825780327199027\n",
      "Training Loss: 0.00646465110592544\n",
      "Validation Loss: 0.004120397216671806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006733606448979117\n",
      "Training Loss: 0.0068177065497729925\n",
      "Training Loss: 0.0064575029048137365\n",
      "Validation Loss: 0.004114048043396742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006727164515759796\n",
      "Training Loss: 0.0068094055622350425\n",
      "Training Loss: 0.006450153986224905\n",
      "Validation Loss: 0.00410742655310131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.0067205492308130485\n",
      "Training Loss: 0.00680084802210331\n",
      "Training Loss: 0.006442581969313323\n",
      "Validation Loss: 0.004100504868894062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006713733517681248\n",
      "Training Loss: 0.00679200297454372\n",
      "Training Loss: 0.00643476311233826\n",
      "Validation Loss: 0.004093254669150861\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006706690448336303\n",
      "Training Loss: 0.006782834501937032\n",
      "Training Loss: 0.006426671837689355\n",
      "Validation Loss: 0.004085639604168494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006699388970737345\n",
      "Training Loss: 0.006773305524839088\n",
      "Training Loss: 0.006418279483914375\n",
      "Validation Loss: 0.004077627827816256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006691795377992094\n",
      "Training Loss: 0.006763375740265473\n",
      "Training Loss: 0.006409558259183541\n",
      "Validation Loss: 0.0040691828210001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006683875549933873\n",
      "Training Loss: 0.006753001739270985\n",
      "Training Loss: 0.006400477539282292\n",
      "Validation Loss: 0.004060268355010266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006675589688238687\n",
      "Training Loss: 0.006742136898683384\n",
      "Training Loss: 0.006391006653429941\n",
      "Validation Loss: 0.004050840424201085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006666898467228748\n",
      "Training Loss: 0.0067307348700705915\n",
      "Training Loss: 0.006381113217212259\n",
      "Validation Loss: 0.004040863022229143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006657759140362032\n",
      "Training Loss: 0.006718745119869709\n",
      "Training Loss: 0.006370766141917557\n",
      "Validation Loss: 0.004030297541064785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.0066481283685425295\n",
      "Training Loss: 0.006706119194859639\n",
      "Training Loss: 0.006359936167718842\n",
      "Validation Loss: 0.0040191084655326155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0066379606461850925\n",
      "Training Loss: 0.006692809998057782\n",
      "Training Loss: 0.006348596489988268\n",
      "Validation Loss: 0.004007263066576731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.00662721534143202\n",
      "Training Loss: 0.006678772080922499\n",
      "Training Loss: 0.006336724715074524\n",
      "Validation Loss: 0.003994737377683266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006615849479567259\n",
      "Training Loss: 0.006663969613146037\n",
      "Training Loss: 0.006324305472662673\n",
      "Validation Loss: 0.003981511167438931\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006603829886880703\n",
      "Training Loss: 0.006648372273193672\n",
      "Training Loss: 0.006311332584591583\n",
      "Validation Loss: 0.003967581928990195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006591126591083594\n",
      "Training Loss: 0.006631965555716306\n",
      "Training Loss: 0.006297809030511417\n",
      "Validation Loss: 0.0039529545360841275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006577722835354507\n",
      "Training Loss: 0.006614749636501074\n",
      "Training Loss: 0.0062837507878430185\n",
      "Validation Loss: 0.0039376498695745474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006563610951998271\n",
      "Training Loss: 0.006596743403933942\n",
      "Training Loss: 0.006269188525620848\n",
      "Validation Loss: 0.003921710825237456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006548800695163663\n",
      "Training Loss: 0.006577987537020817\n",
      "Training Loss: 0.006254162197583355\n",
      "Validation Loss: 0.0039051920339057034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006533313825493678\n",
      "Training Loss: 0.0065585450548678636\n",
      "Training Loss: 0.006238726829760708\n",
      "Validation Loss: 0.0038881619778733827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.0065171902382280674\n",
      "Training Loss: 0.006538496398134157\n",
      "Training Loss: 0.006222945030895061\n",
      "Validation Loss: 0.00387070377179411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006500481059774756\n",
      "Training Loss: 0.0065179409016855065\n",
      "Training Loss: 0.0062068835028912875\n",
      "Validation Loss: 0.003852903329521376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006483250128221698\n",
      "Training Loss: 0.006496988519793376\n",
      "Training Loss: 0.006190609473269433\n",
      "Validation Loss: 0.003834849209106119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006465568703133613\n",
      "Training Loss: 0.006475753971608355\n",
      "Training Loss: 0.006174188836012035\n",
      "Validation Loss: 0.0038166254938035954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006447509652352892\n",
      "Training Loss: 0.0064543519529979675\n",
      "Training Loss: 0.006157679249881766\n",
      "Validation Loss: 0.003798306858156588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0064291512907948345\n",
      "Training Loss: 0.006432890543946996\n",
      "Training Loss: 0.0061411323782522235\n",
      "Validation Loss: 0.0037799581984748667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006410566383274272\n",
      "Training Loss: 0.006411464728880673\n",
      "Training Loss: 0.00612459045543801\n",
      "Validation Loss: 0.003761636288156419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006391821737051942\n",
      "Training Loss: 0.006390160687733442\n",
      "Training Loss: 0.006108089078916237\n",
      "Validation Loss: 0.00374338991045324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006372982329921797\n",
      "Training Loss: 0.006369047199841589\n",
      "Training Loss: 0.006091655361815356\n",
      "Validation Loss: 0.0037252555929616175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006354106363723986\n",
      "Training Loss: 0.006348181669600308\n",
      "Training Loss: 0.0060753134585684165\n",
      "Validation Loss: 0.0037072632151781424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006335245915688574\n",
      "Training Loss: 0.006327606630511582\n",
      "Training Loss: 0.0060590805491665374\n",
      "Validation Loss: 0.0036894404787172594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.00631644953682553\n",
      "Training Loss: 0.006307357134064659\n",
      "Training Loss: 0.006042971350834705\n",
      "Validation Loss: 0.003671807691512441\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.0062977545172907415\n",
      "Training Loss: 0.006287454380653799\n",
      "Training Loss: 0.006026993532432243\n",
      "Validation Loss: 0.003654382865237637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006279196555260569\n",
      "Training Loss: 0.0062679117766674605\n",
      "Training Loss: 0.0060111518466146666\n",
      "Validation Loss: 0.0036371769494732862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006260804352350533\n",
      "Training Loss: 0.006248735401313752\n",
      "Training Loss: 0.0059954483166802675\n",
      "Validation Loss: 0.003620201974892675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006242598910466768\n",
      "Training Loss: 0.006229925509542227\n",
      "Training Loss: 0.005979878954822198\n",
      "Validation Loss: 0.0036034583953847544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006224596151150763\n",
      "Training Loss: 0.006211472869617865\n",
      "Training Loss: 0.005964437975198962\n",
      "Validation Loss: 0.0035869483665950347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006206806038389914\n",
      "Training Loss: 0.006193367369705811\n",
      "Training Loss: 0.00594911364489235\n",
      "Validation Loss: 0.0035706694274512903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.0061892330308910455\n",
      "Training Loss: 0.006175590520724654\n",
      "Training Loss: 0.00593389319779817\n",
      "Validation Loss: 0.003554614752614766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006171874176361598\n",
      "Training Loss: 0.006158121739281342\n",
      "Training Loss: 0.005918761193170212\n",
      "Validation Loss: 0.0035387755056393196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006154723229119554\n",
      "Training Loss: 0.006140935772564262\n",
      "Training Loss: 0.005903698916663416\n",
      "Validation Loss: 0.003523137368748404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.0061377694399561734\n",
      "Training Loss: 0.006124005353776738\n",
      "Training Loss: 0.005888686558464542\n",
      "Validation Loss: 0.0035076858874755713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006120997165562585\n",
      "Training Loss: 0.006107301153242588\n",
      "Training Loss: 0.00587370329303667\n",
      "Validation Loss: 0.0034924081357959867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006104387873201631\n",
      "Training Loss: 0.006090792987961322\n",
      "Training Loss: 0.005858728075399995\n",
      "Validation Loss: 0.003477287777631512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006087919495766983\n",
      "Training Loss: 0.006074448436265811\n",
      "Training Loss: 0.005843737941468134\n",
      "Validation Loss: 0.0034623042153184083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006071569370105862\n",
      "Training Loss: 0.006058235359378159\n",
      "Training Loss: 0.00582871294929646\n",
      "Validation Loss: 0.0034474396739374805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006055312509415671\n",
      "Training Loss: 0.006042122567305341\n",
      "Training Loss: 0.005813629525364377\n",
      "Validation Loss: 0.0034326755126488258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006039123173686676\n",
      "Training Loss: 0.006026078741997481\n",
      "Training Loss: 0.005798469368019141\n",
      "Validation Loss: 0.0034179933528740254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006022976255626418\n",
      "Training Loss: 0.006010076040402055\n",
      "Training Loss: 0.005783211574889719\n",
      "Validation Loss: 0.003403377580571543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.0060068455088185145\n",
      "Training Loss: 0.005994084479752928\n",
      "Training Loss: 0.00576783727912698\n",
      "Validation Loss: 0.0033888082023908832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005990706684533506\n",
      "Training Loss: 0.00597807974787429\n",
      "Training Loss: 0.005752330628456548\n",
      "Validation Loss: 0.0033742685205815884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005974535048007965\n",
      "Training Loss: 0.005962034900439903\n",
      "Training Loss: 0.0057366733555682\n",
      "Validation Loss: 0.0033597423069785986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005958305865060538\n",
      "Training Loss: 0.00594592863577418\n",
      "Training Loss: 0.005720850962097757\n",
      "Validation Loss: 0.0033452130534968685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005941997927729972\n",
      "Training Loss: 0.005929739938583225\n",
      "Training Loss: 0.005704848989844322\n",
      "Validation Loss: 0.0033306648295498295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.0059255926194600765\n",
      "Training Loss: 0.005913449637591839\n",
      "Training Loss: 0.005688655534759164\n",
      "Validation Loss: 0.0033160848909298355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005909067718312145\n",
      "Training Loss: 0.0058970420865807685\n",
      "Training Loss: 0.005672258784179576\n",
      "Validation Loss: 0.0033014554980346994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005892409654334188\n",
      "Training Loss: 0.005880503710359335\n",
      "Training Loss: 0.005655648789834231\n",
      "Validation Loss: 0.003286765125093542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005875600725994445\n",
      "Training Loss: 0.005863821046659723\n",
      "Training Loss: 0.005638815950951539\n",
      "Validation Loss: 0.00327199782451531\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005858627827838064\n",
      "Training Loss: 0.005846984019735828\n",
      "Training Loss: 0.005621753717423417\n",
      "Validation Loss: 0.0032571412078785094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005841482222895138\n",
      "Training Loss: 0.005829987492179498\n",
      "Training Loss: 0.005604458838352002\n",
      "Validation Loss: 0.003242181697755717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.00582415453158319\n",
      "Training Loss: 0.00581282663391903\n",
      "Training Loss: 0.00558692718972452\n",
      "Validation Loss: 0.003227108962614131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005806639319634996\n",
      "Training Loss: 0.005795500369276852\n",
      "Training Loss: 0.0055691582016879695\n",
      "Validation Loss: 0.003211909610767629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005788935857126489\n",
      "Training Loss: 0.005778008939232677\n",
      "Training Loss: 0.005551153947599232\n",
      "Validation Loss: 0.0031965757652154462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005771045044530183\n",
      "Training Loss: 0.005760359625564888\n",
      "Training Loss: 0.0055329209176125\n",
      "Validation Loss: 0.0031810964227476147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005752972118207253\n",
      "Training Loss: 0.005742559432983399\n",
      "Training Loss: 0.005514467524481006\n",
      "Validation Loss: 0.00316547080311987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005734726413502358\n",
      "Training Loss: 0.005724622712004929\n",
      "Training Loss: 0.005495807855040767\n",
      "Validation Loss: 0.0031496935819662858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005716322877560742\n",
      "Training Loss: 0.005706566260196269\n",
      "Training Loss: 0.005476961337262764\n",
      "Validation Loss: 0.0031337671529951643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005697782393544912\n",
      "Training Loss: 0.005688413641182706\n",
      "Training Loss: 0.005457952200085856\n",
      "Validation Loss: 0.003117696896164019\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005679127817857079\n",
      "Training Loss: 0.005670191358076409\n",
      "Training Loss: 0.005438810781924985\n",
      "Validation Loss: 0.0031014926008241816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005660389950498938\n",
      "Training Loss: 0.005651931047905237\n",
      "Training Loss: 0.005419571824604646\n",
      "Validation Loss: 0.0030851714284253423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005641604390693829\n",
      "Training Loss: 0.005633668906521052\n",
      "Training Loss: 0.005400278277811595\n",
      "Validation Loss: 0.003068756061642734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005622810139320791\n",
      "Training Loss: 0.005615445276489482\n",
      "Training Loss: 0.005380977349122986\n",
      "Validation Loss: 0.0030522748881563794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005604051175760105\n",
      "Training Loss: 0.005597302638925612\n",
      "Training Loss: 0.005361719430075027\n",
      "Validation Loss: 0.0030357615147152224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005585371461347677\n",
      "Training Loss: 0.005579284495906904\n",
      "Training Loss: 0.0053425614058505745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [10:25<24:20, 208.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.003019254090881833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.2629644089192152\n",
      "Training Loss: 0.1989934278279543\n",
      "Training Loss: 0.14751470774412156\n",
      "Validation Loss: 0.10520844086167518\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.08886438073590398\n",
      "Training Loss: 0.07399251824244857\n",
      "Training Loss: 0.06777005914598704\n",
      "Validation Loss: 0.06449631704122163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.061783803422003986\n",
      "Training Loss: 0.0591765371337533\n",
      "Training Loss: 0.05711590343154967\n",
      "Validation Loss: 0.054124724140830256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.051574233919382095\n",
      "Training Loss: 0.04864682924933732\n",
      "Training Loss: 0.04618702841922641\n",
      "Validation Loss: 0.04233836222523719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04042735339142382\n",
      "Training Loss: 0.038120706584304574\n",
      "Training Loss: 0.03582887161523104\n",
      "Validation Loss: 0.03216127727934149\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.030823095859959723\n",
      "Training Loss: 0.02930156683549285\n",
      "Training Loss: 0.02741112100891769\n",
      "Validation Loss: 0.024553111006160467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.023576534129679205\n",
      "Training Loss: 0.02287900494877249\n",
      "Training Loss: 0.021557851424440742\n",
      "Validation Loss: 0.019505415807656024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.018875925596803428\n",
      "Training Loss: 0.018787122850771994\n",
      "Training Loss: 0.017949005006812513\n",
      "Validation Loss: 0.016309263697417264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.016048634944017977\n",
      "Training Loss: 0.016264956248924135\n",
      "Training Loss: 0.015714926884975285\n",
      "Validation Loss: 0.014161880758559604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.014255161585751921\n",
      "Training Loss: 0.01458254735916853\n",
      "Training Loss: 0.014182527053635567\n",
      "Validation Loss: 0.012585232158589145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01299202436581254\n",
      "Training Loss: 0.01334438267396763\n",
      "Training Loss: 0.013026347708655522\n",
      "Validation Loss: 0.011356387237672893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.012033935533836485\n",
      "Training Loss: 0.012377890134230256\n",
      "Training Loss: 0.012111104123760015\n",
      "Validation Loss: 0.010373231014393773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.011281992347212508\n",
      "Training Loss: 0.011606404362246393\n",
      "Training Loss: 0.011375356741482393\n",
      "Validation Loss: 0.009579980588947119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010684268366312609\n",
      "Training Loss: 0.01098692813422531\n",
      "Training Loss: 0.010780966776655987\n",
      "Validation Loss: 0.008936117241012582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010204936811933294\n",
      "Training Loss: 0.010487081189639867\n",
      "Training Loss: 0.010297262595267967\n",
      "Validation Loss: 0.008408173098584657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009815458246739581\n",
      "Training Loss: 0.010079656530870125\n",
      "Training Loss: 0.009898466003360227\n",
      "Validation Loss: 0.007968898089550269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009493144166190176\n",
      "Training Loss: 0.009742499438580125\n",
      "Training Loss: 0.00956402404466644\n",
      "Validation Loss: 0.007597503830479939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00922105164732784\n",
      "Training Loss: 0.009458851446397602\n",
      "Training Loss: 0.009278754451079294\n",
      "Validation Loss: 0.0072792215217846665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008987412090646104\n",
      "Training Loss: 0.00921689958544448\n",
      "Training Loss: 0.009032183000817895\n",
      "Validation Loss: 0.007004099376133403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008784552772995084\n",
      "Training Loss: 0.009008746449835599\n",
      "Training Loss: 0.008817432611249388\n",
      "Validation Loss: 0.006765493228403705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008607633470091969\n",
      "Training Loss: 0.008829173870617523\n",
      "Training Loss: 0.008630004418082536\n",
      "Validation Loss: 0.006558683758413189\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008453504422213882\n",
      "Training Loss: 0.008674534786259756\n",
      "Training Loss: 0.008466739961877466\n",
      "Validation Loss: 0.006379845107413745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008319827310042455\n",
      "Training Loss: 0.00854192052851431\n",
      "Training Loss: 0.008325048525584862\n",
      "Validation Loss: 0.00622539894310025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00820447610807605\n",
      "Training Loss: 0.008428628887049854\n",
      "Training Loss: 0.008202449351083487\n",
      "Validation Loss: 0.006091796676628292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008105280202580617\n",
      "Training Loss: 0.008331976338522508\n",
      "Training Loss: 0.008096429298166185\n",
      "Validation Loss: 0.005975577345881821\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008019996435614303\n",
      "Training Loss: 0.008249325940851123\n",
      "Training Loss: 0.008004492707550525\n",
      "Validation Loss: 0.005873542339174768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007946417599450797\n",
      "Training Loss: 0.008178199905669316\n",
      "Training Loss: 0.007924276968697085\n",
      "Validation Loss: 0.0057828976259974955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007882499730912968\n",
      "Training Loss: 0.008116402940358966\n",
      "Training Loss: 0.007853669638279825\n",
      "Validation Loss: 0.005701317195518968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0078264496603515\n",
      "Training Loss: 0.008062076373025775\n",
      "Training Loss: 0.007790864913258702\n",
      "Validation Loss: 0.005626949583692999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00777676586410962\n",
      "Training Loss: 0.008013715959386901\n",
      "Training Loss: 0.0077343837404623625\n",
      "Validation Loss: 0.005558361317648479\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007732229897519574\n",
      "Training Loss: 0.007970143439015373\n",
      "Training Loss: 0.007683051634812727\n",
      "Validation Loss: 0.005494486251479706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00769188555656001\n",
      "Training Loss: 0.007930463751545175\n",
      "Training Loss: 0.007635967560345307\n",
      "Validation Loss: 0.00543455047705577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007654999612132087\n",
      "Training Loss: 0.007894017092185094\n",
      "Training Loss: 0.007592455202247947\n",
      "Validation Loss: 0.005378018940401295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007621019432554022\n",
      "Training Loss: 0.00786032628500834\n",
      "Training Loss: 0.007552020434523001\n",
      "Validation Loss: 0.005324535754645306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0075895357562694695\n",
      "Training Loss: 0.00782905072439462\n",
      "Training Loss: 0.007514307770179585\n",
      "Validation Loss: 0.005273876917088048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0075602443632669745\n",
      "Training Loss: 0.007799947569146752\n",
      "Training Loss: 0.007479059156030417\n",
      "Validation Loss: 0.005225907184518455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007532920776866376\n",
      "Training Loss: 0.007772837764350698\n",
      "Training Loss: 0.007446084368275478\n",
      "Validation Loss: 0.005180546796744626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007507390872342512\n",
      "Training Loss: 0.0077475825848523526\n",
      "Training Loss: 0.007415232792263851\n",
      "Validation Loss: 0.0051377436637962135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007483512300532311\n",
      "Training Loss: 0.00772406400879845\n",
      "Training Loss: 0.007386377074290067\n",
      "Validation Loss: 0.005097451822549691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007461167278233915\n",
      "Training Loss: 0.007702173353172839\n",
      "Training Loss: 0.007359398669796065\n",
      "Validation Loss: 0.005059620807617066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00744024665444158\n",
      "Training Loss: 0.007681803297018632\n",
      "Training Loss: 0.007334181348560378\n",
      "Validation Loss: 0.005024190058178279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007420647124527022\n",
      "Training Loss: 0.007662846543826163\n",
      "Training Loss: 0.007310607053805143\n",
      "Validation Loss: 0.004991080666881766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007402269497979432\n",
      "Training Loss: 0.007645195304648951\n",
      "Training Loss: 0.007288557824213057\n",
      "Validation Loss: 0.004960199131295503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0073850165051408114\n",
      "Training Loss: 0.007628741301596164\n",
      "Training Loss: 0.007267913265386596\n",
      "Validation Loss: 0.004931440501044808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007368792839115485\n",
      "Training Loss: 0.007613376809749752\n",
      "Training Loss: 0.007248556152917445\n",
      "Validation Loss: 0.004904687077623237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007353508201194927\n",
      "Training Loss: 0.0075989987666253\n",
      "Training Loss: 0.0072303738782647994\n",
      "Validation Loss: 0.004879822904830066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007339075724594295\n",
      "Training Loss: 0.007585510774515569\n",
      "Training Loss: 0.007213258258998394\n",
      "Validation Loss: 0.004856720310374258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007325417537940666\n",
      "Training Loss: 0.007572823135415092\n",
      "Training Loss: 0.007197112133726477\n",
      "Validation Loss: 0.004835259846249449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007312459677923471\n",
      "Training Loss: 0.007560852241003886\n",
      "Training Loss: 0.0071818438731133935\n",
      "Validation Loss: 0.004815318819208677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007300136510748416\n",
      "Training Loss: 0.007549523933557793\n",
      "Training Loss: 0.0071673717303201556\n",
      "Validation Loss: 0.004796784222021364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00728839092538692\n",
      "Training Loss: 0.007538771206745878\n",
      "Training Loss: 0.0071536227792967115\n",
      "Validation Loss: 0.004779542555634895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007277169214794412\n",
      "Training Loss: 0.007528535589808598\n",
      "Training Loss: 0.007140531780896709\n",
      "Validation Loss: 0.004763488962545238\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007266427362337708\n",
      "Training Loss: 0.007518762978725136\n",
      "Training Loss: 0.007128042613621801\n",
      "Validation Loss: 0.004748525223537778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0072561226820107546\n",
      "Training Loss: 0.007509408299811184\n",
      "Training Loss: 0.007116102952277287\n",
      "Validation Loss: 0.004734558426105323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007246222029207275\n",
      "Training Loss: 0.007500429819338024\n",
      "Training Loss: 0.007104668671963736\n",
      "Validation Loss: 0.004721499924558435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007236693969462067\n",
      "Training Loss: 0.00749179144972004\n",
      "Training Loss: 0.007093698874814436\n",
      "Validation Loss: 0.004709270041765582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007227509655058384\n",
      "Training Loss: 0.0074834598286543045\n",
      "Training Loss: 0.0070831584022380415\n",
      "Validation Loss: 0.004697792647338441\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007218646133551374\n",
      "Training Loss: 0.007475407110759989\n",
      "Training Loss: 0.007073014872148633\n",
      "Validation Loss: 0.004686998113142222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007210078493226319\n",
      "Training Loss: 0.00746760664624162\n",
      "Training Loss: 0.007063237136462703\n",
      "Validation Loss: 0.0046768218378295725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0072017881914507595\n",
      "Training Loss: 0.00746003539999947\n",
      "Training Loss: 0.007053799470886588\n",
      "Validation Loss: 0.004667205317469125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00719375608721748\n",
      "Training Loss: 0.0074526712531223895\n",
      "Training Loss: 0.007044677013764158\n",
      "Validation Loss: 0.004658094957847608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0071859642106574025\n",
      "Training Loss: 0.007445495900465175\n",
      "Training Loss: 0.007035846140934154\n",
      "Validation Loss: 0.004649438476713186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007178396177478135\n",
      "Training Loss: 0.007438490529311821\n",
      "Training Loss: 0.007027285778895021\n",
      "Validation Loss: 0.0046411919972618645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007171037836233154\n",
      "Training Loss: 0.007431639161659405\n",
      "Training Loss: 0.0070189755957107995\n",
      "Validation Loss: 0.004633314649867459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007163874057587236\n",
      "Training Loss: 0.007424927634419873\n",
      "Training Loss: 0.007010895076673478\n",
      "Validation Loss: 0.004625765719252189\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007156891357153654\n",
      "Training Loss: 0.007418341474840417\n",
      "Training Loss: 0.0070030296943150465\n",
      "Validation Loss: 0.004618516090467279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007150076712714508\n",
      "Training Loss: 0.0074118674825876954\n",
      "Training Loss: 0.006995359644060954\n",
      "Validation Loss: 0.004611533236548598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0071434180170763285\n",
      "Training Loss: 0.007405495442217216\n",
      "Training Loss: 0.00698787103057839\n",
      "Validation Loss: 0.004604789071318725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0071369029779452834\n",
      "Training Loss: 0.007399213537573814\n",
      "Training Loss: 0.0069805492518935355\n",
      "Validation Loss: 0.0045982589801313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007130522381630726\n",
      "Training Loss: 0.007393012231914326\n",
      "Training Loss: 0.006973379555856809\n",
      "Validation Loss: 0.004591920873506016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007124264433514327\n",
      "Training Loss: 0.007386881686979905\n",
      "Training Loss: 0.0069663494674023245\n",
      "Validation Loss: 0.004585754884971997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007118119774968363\n",
      "Training Loss: 0.007380814090138302\n",
      "Training Loss: 0.006959446643013507\n",
      "Validation Loss: 0.004579742188602058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007112078654463403\n",
      "Training Loss: 0.007374801331898198\n",
      "Training Loss: 0.006952660534298047\n",
      "Validation Loss: 0.004573866383570215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007106132868211716\n",
      "Training Loss: 0.0073688359267544004\n",
      "Training Loss: 0.0069459803588688375\n",
      "Validation Loss: 0.0045681151278902975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007100273682735861\n",
      "Training Loss: 0.007362911218078807\n",
      "Training Loss: 0.006939395685913041\n",
      "Validation Loss: 0.004562472448464525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.0070944946043891835\n",
      "Training Loss: 0.007357021815842017\n",
      "Training Loss: 0.006932897688820958\n",
      "Validation Loss: 0.0045569292884424665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007088786925305612\n",
      "Training Loss: 0.007351160647813231\n",
      "Training Loss: 0.0069264784862753\n",
      "Validation Loss: 0.0045514744830715435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007083145055221393\n",
      "Training Loss: 0.007345322949113324\n",
      "Training Loss: 0.006920129370409995\n",
      "Validation Loss: 0.0045460985915923725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007077562018530444\n",
      "Training Loss: 0.0073395041807089\n",
      "Training Loss: 0.006913842774229124\n",
      "Validation Loss: 0.004540791646106525\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.00707203131983988\n",
      "Training Loss: 0.007333698703441769\n",
      "Training Loss: 0.0069076126831350846\n",
      "Validation Loss: 0.004535548430815172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007066547749564052\n",
      "Training Loss: 0.007327902821125463\n",
      "Training Loss: 0.006901432055747137\n",
      "Validation Loss: 0.004530361802526488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0070611059374641625\n",
      "Training Loss: 0.007322111850371584\n",
      "Training Loss: 0.006895295237191021\n",
      "Validation Loss: 0.00452522449967127\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007055701491190121\n",
      "Training Loss: 0.007316322239348665\n",
      "Training Loss: 0.006889196281554178\n",
      "Validation Loss: 0.004520130921887715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007050328560872003\n",
      "Training Loss: 0.0073105303256306795\n",
      "Training Loss: 0.006883130167843774\n",
      "Validation Loss: 0.004515075884115872\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007044983297819271\n",
      "Training Loss: 0.007304732559714466\n",
      "Training Loss: 0.006877091356436722\n",
      "Validation Loss: 0.004510053108430604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007039661445887759\n",
      "Training Loss: 0.007298926110379398\n",
      "Training Loss: 0.006871075431117788\n",
      "Validation Loss: 0.004505059851877643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007034360396792181\n",
      "Training Loss: 0.007293107295408845\n",
      "Training Loss: 0.006865078653208912\n",
      "Validation Loss: 0.004500090601733687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007029074835008942\n",
      "Training Loss: 0.007287273736437783\n",
      "Training Loss: 0.006859096115804277\n",
      "Validation Loss: 0.004495142672598111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007023801681352779\n",
      "Training Loss: 0.007281422554515302\n",
      "Training Loss: 0.0068531251733656975\n",
      "Validation Loss: 0.004490212614522472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007018538111587987\n",
      "Training Loss: 0.007275550438789651\n",
      "Training Loss: 0.006847161708865315\n",
      "Validation Loss: 0.004485296139760424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007013280930113979\n",
      "Training Loss: 0.007269655761774629\n",
      "Training Loss: 0.0068412021693075075\n",
      "Validation Loss: 0.004480390485083119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.00700802663108334\n",
      "Training Loss: 0.007263735729502514\n",
      "Training Loss: 0.006835243765381165\n",
      "Validation Loss: 0.004475493063192731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007002773775602691\n",
      "Training Loss: 0.0072577880101744085\n",
      "Training Loss: 0.006829283288097941\n",
      "Validation Loss: 0.004470599838140096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006997519236756488\n",
      "Training Loss: 0.007251810451271013\n",
      "Training Loss: 0.0068233183934353295\n",
      "Validation Loss: 0.004465710091812724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006992260083789006\n",
      "Training Loss: 0.007245800889795646\n",
      "Training Loss: 0.00681734544923529\n",
      "Validation Loss: 0.004460819109390082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006986993701430038\n",
      "Training Loss: 0.007239757805364206\n",
      "Training Loss: 0.006811362738371827\n",
      "Validation Loss: 0.004455925921616511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00698171928001102\n",
      "Training Loss: 0.007233678988413885\n",
      "Training Loss: 0.0068053676933050155\n",
      "Validation Loss: 0.004451028421243883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.00697643416642677\n",
      "Training Loss: 0.007227562519256025\n",
      "Training Loss: 0.006799358259304427\n",
      "Validation Loss: 0.004446122898024329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006971136295469478\n",
      "Training Loss: 0.007221406472381204\n",
      "Training Loss: 0.00679333203821443\n",
      "Validation Loss: 0.00444121148732878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006965823534992524\n",
      "Training Loss: 0.00721520978026092\n",
      "Training Loss: 0.006787286673206836\n",
      "Validation Loss: 0.004436288176109658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.0069604948174674065\n",
      "Training Loss: 0.0072089698282070454\n",
      "Training Loss: 0.006781222028075717\n",
      "Validation Loss: 0.004431355114126306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006955148259294219\n",
      "Training Loss: 0.00720268638455309\n",
      "Training Loss: 0.006775133965420537\n",
      "Validation Loss: 0.0044264072680511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006949781982693821\n",
      "Training Loss: 0.007196358107030391\n",
      "Training Loss: 0.006769023417145945\n",
      "Validation Loss: 0.004421445066920283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006944394843885675\n",
      "Training Loss: 0.007189982567215338\n",
      "Training Loss: 0.006762887455406599\n",
      "Validation Loss: 0.004416465500939972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006938986068125814\n",
      "Training Loss: 0.007183559633558616\n",
      "Training Loss: 0.0067567252897424625\n",
      "Validation Loss: 0.004411467755856934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006933553763665259\n",
      "Training Loss: 0.0071770875656511635\n",
      "Training Loss: 0.0067505353153683246\n",
      "Validation Loss: 0.004406451771501452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0069280977349262685\n",
      "Training Loss: 0.007170565600972623\n",
      "Training Loss: 0.006744316565454937\n",
      "Validation Loss: 0.004401417214324007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006922616009251215\n",
      "Training Loss: 0.007163993484573439\n",
      "Training Loss: 0.006738067904370837\n",
      "Validation Loss: 0.0043963605977511136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.0069171078916406255\n",
      "Training Loss: 0.007157369155902415\n",
      "Training Loss: 0.006731789051555097\n",
      "Validation Loss: 0.004391283367164015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006911573060788215\n",
      "Training Loss: 0.007150692641735077\n",
      "Training Loss: 0.006725478212465532\n",
      "Validation Loss: 0.004386181883602874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006906010586535558\n",
      "Training Loss: 0.007143963692942634\n",
      "Training Loss: 0.0067191359488060695\n",
      "Validation Loss: 0.004381059160131668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006900419730227441\n",
      "Training Loss: 0.007137182167498395\n",
      "Training Loss: 0.006712760677328333\n",
      "Validation Loss: 0.004375912544704722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006894799752626568\n",
      "Training Loss: 0.007130345966434106\n",
      "Training Loss: 0.006706352701294236\n",
      "Validation Loss: 0.004370739582789999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006889150515198708\n",
      "Training Loss: 0.0071234559908043595\n",
      "Training Loss: 0.006699911638861522\n",
      "Validation Loss: 0.004365543106288304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006883471175679006\n",
      "Training Loss: 0.007116511889034882\n",
      "Training Loss: 0.0066934370237868275\n",
      "Validation Loss: 0.004360323433052707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.0068777620210312305\n",
      "Training Loss: 0.007109513699542731\n",
      "Training Loss: 0.00668692814942915\n",
      "Validation Loss: 0.004355077744262774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006872022167081013\n",
      "Training Loss: 0.007102461446775124\n",
      "Training Loss: 0.006680385641520843\n",
      "Validation Loss: 0.00434980787117076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006866252748877742\n",
      "Training Loss: 0.007095354672055691\n",
      "Training Loss: 0.006673809731146321\n",
      "Validation Loss: 0.004344511869379183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006860451670363545\n",
      "Training Loss: 0.007088193281088024\n",
      "Training Loss: 0.006667200109222904\n",
      "Validation Loss: 0.0043391919108840184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006854619894875213\n",
      "Training Loss: 0.007080978754675016\n",
      "Training Loss: 0.006660556371789425\n",
      "Validation Loss: 0.004333846220678618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0068487574276514356\n",
      "Training Loss: 0.0070737099647521975\n",
      "Training Loss: 0.0066538790304912256\n",
      "Validation Loss: 0.004328474721588781\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006842864312930032\n",
      "Training Loss: 0.007066387792583555\n",
      "Training Loss: 0.006647169372299686\n",
      "Validation Loss: 0.0043230797059499145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006836940015782602\n",
      "Training Loss: 0.0070590130111668255\n",
      "Training Loss: 0.006640425942605361\n",
      "Validation Loss: 0.00431765800700366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006830985791166313\n",
      "Training Loss: 0.007051585589069873\n",
      "Training Loss: 0.006633650240837596\n",
      "Validation Loss: 0.004312211265682839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0068250007316237316\n",
      "Training Loss: 0.00704410613863729\n",
      "Training Loss: 0.006626842513214797\n",
      "Validation Loss: 0.0043067410804090624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006818984827259555\n",
      "Training Loss: 0.007036574902012944\n",
      "Training Loss: 0.006620003066491336\n",
      "Validation Loss: 0.004301247249744581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0068129395699361335\n",
      "Training Loss: 0.007028992556734011\n",
      "Training Loss: 0.0066131327603943645\n",
      "Validation Loss: 0.004295730530388988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006806865087710321\n",
      "Training Loss: 0.00702136010164395\n",
      "Training Loss: 0.006606230967445299\n",
      "Validation Loss: 0.004290187458659449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006800758989411407\n",
      "Training Loss: 0.0070136771420948206\n",
      "Training Loss: 0.0065992985310731455\n",
      "Validation Loss: 0.0042846212654081535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006794623809400946\n",
      "Training Loss: 0.0070059449295513335\n",
      "Training Loss: 0.00659233617130667\n",
      "Validation Loss: 0.004279029996427341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006788458881783299\n",
      "Training Loss: 0.006998163659591228\n",
      "Training Loss: 0.006585343664046377\n",
      "Validation Loss: 0.004273415761581214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006782264286885038\n",
      "Training Loss: 0.006990334567381069\n",
      "Training Loss: 0.006578322617569938\n",
      "Validation Loss: 0.0042677764667020165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006776040662080049\n",
      "Training Loss: 0.00698245667736046\n",
      "Training Loss: 0.006571271112770774\n",
      "Validation Loss: 0.004262113546706694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0067697874514851715\n",
      "Training Loss: 0.006974532012827694\n",
      "Training Loss: 0.006564191417419351\n",
      "Validation Loss: 0.0042564265712509665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006763504981645383\n",
      "Training Loss: 0.00696655945153907\n",
      "Training Loss: 0.006557083281804808\n",
      "Validation Loss: 0.004250714660025715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006757194164092653\n",
      "Training Loss: 0.006958540715277195\n",
      "Training Loss: 0.006549946576124057\n",
      "Validation Loss: 0.004244975820890094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006750853742123582\n",
      "Training Loss: 0.006950475696939975\n",
      "Training Loss: 0.006542781646130607\n",
      "Validation Loss: 0.004239211785031504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006744484163937159\n",
      "Training Loss: 0.006942365028662607\n",
      "Training Loss: 0.006535588783444837\n",
      "Validation Loss: 0.004233421195361219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006738085625111126\n",
      "Training Loss: 0.0069342080503702165\n",
      "Training Loss: 0.006528366717975587\n",
      "Validation Loss: 0.0042276006876072435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006731657180353068\n",
      "Training Loss: 0.006926004900597036\n",
      "Training Loss: 0.006521117427619174\n",
      "Validation Loss: 0.004221752964828708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00672519942454528\n",
      "Training Loss: 0.006917757327901199\n",
      "Training Loss: 0.006513839767430909\n",
      "Validation Loss: 0.004215873486828059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.00671871246828232\n",
      "Training Loss: 0.006909463509218767\n",
      "Training Loss: 0.006506533089559525\n",
      "Validation Loss: 0.00420996494620013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006712195367435924\n",
      "Training Loss: 0.00690112458076328\n",
      "Training Loss: 0.006499198250821792\n",
      "Validation Loss: 0.004204021138923891\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006705648374627345\n",
      "Training Loss: 0.006892740053590387\n",
      "Training Loss: 0.006491835246561095\n",
      "Validation Loss: 0.004198044427314752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006699070728500373\n",
      "Training Loss: 0.0068843099509831515\n",
      "Training Loss: 0.006484442128567025\n",
      "Validation Loss: 0.004192027550457527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006692462348146364\n",
      "Training Loss: 0.006875833770027384\n",
      "Training Loss: 0.006477019855519756\n",
      "Validation Loss: 0.004185976438339423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006685822870349511\n",
      "Training Loss: 0.006867311423411593\n",
      "Training Loss: 0.006469567308085971\n",
      "Validation Loss: 0.004179883514154242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.0066791532223578545\n",
      "Training Loss: 0.006858742611948401\n",
      "Training Loss: 0.006462084212107584\n",
      "Validation Loss: 0.00417374659478769\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006672450706828386\n",
      "Training Loss: 0.006850126637145877\n",
      "Training Loss: 0.006454569913912565\n",
      "Validation Loss: 0.004167565731907242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0066657158348243685\n",
      "Training Loss: 0.006841463099699467\n",
      "Training Loss: 0.006447023709188216\n",
      "Validation Loss: 0.004161337115854192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.00665894755104091\n",
      "Training Loss: 0.006832751504844054\n",
      "Training Loss: 0.006439445049036294\n",
      "Validation Loss: 0.004155059225381132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006652146340347827\n",
      "Training Loss: 0.006823991297278553\n",
      "Training Loss: 0.006431833552196622\n",
      "Validation Loss: 0.004148728241019076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006645310824969783\n",
      "Training Loss: 0.0068151819880586115\n",
      "Training Loss: 0.006424186839722097\n",
      "Validation Loss: 0.004142339639574959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006638441174873151\n",
      "Training Loss: 0.006806322486372664\n",
      "Training Loss: 0.00641650605655741\n",
      "Validation Loss: 0.004135892787304697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006631535480264575\n",
      "Training Loss: 0.0067974106315523385\n",
      "Training Loss: 0.006408788152621128\n",
      "Validation Loss: 0.004129383603785857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00662459351005964\n",
      "Training Loss: 0.006788446551654488\n",
      "Training Loss: 0.006401032925932668\n",
      "Validation Loss: 0.004122807561901262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006617614366696216\n",
      "Training Loss: 0.006779428874142468\n",
      "Training Loss: 0.006393239583121613\n",
      "Validation Loss: 0.004116161361472744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006610597730032169\n",
      "Training Loss: 0.006770355663029477\n",
      "Training Loss: 0.006385404941393062\n",
      "Validation Loss: 0.0041094384930525606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006603540782234632\n",
      "Training Loss: 0.006761225890368223\n",
      "Training Loss: 0.0063775299669941886\n",
      "Validation Loss: 0.004102638241144295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006596444608294405\n",
      "Training Loss: 0.006752036903053522\n",
      "Training Loss: 0.006369610183755867\n",
      "Validation Loss: 0.004095752667923448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006589305773377419\n",
      "Training Loss: 0.0067427861702162774\n",
      "Training Loss: 0.006361643703421578\n",
      "Validation Loss: 0.0040887756955945926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0065821232181042435\n",
      "Training Loss: 0.0067334708175621925\n",
      "Training Loss: 0.006353629251825623\n",
      "Validation Loss: 0.0040817034026618335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.0065748950408305975\n",
      "Training Loss: 0.006724088297924027\n",
      "Training Loss: 0.006345562958740629\n",
      "Validation Loss: 0.0040745292554787375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.0065676201129099354\n",
      "Training Loss: 0.0067146344762295486\n",
      "Training Loss: 0.006337442970252596\n",
      "Validation Loss: 0.004067244026496002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006560294616501778\n",
      "Training Loss: 0.006705105827422813\n",
      "Training Loss: 0.006329264720552601\n",
      "Validation Loss: 0.004059840620919183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006552915570209734\n",
      "Training Loss: 0.006695496299071238\n",
      "Training Loss: 0.00632102457806468\n",
      "Validation Loss: 0.0040523096123773064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006545480925706215\n",
      "Training Loss: 0.006685800194973126\n",
      "Training Loss: 0.006312716626562178\n",
      "Validation Loss: 0.004044640485558324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006537986072362401\n",
      "Training Loss: 0.006676011451054365\n",
      "Training Loss: 0.006304336139583029\n",
      "Validation Loss: 0.004036820232685069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006530425467644818\n",
      "Training Loss: 0.00666612105211243\n",
      "Training Loss: 0.006295876233489253\n",
      "Validation Loss: 0.004028836769454726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0065227951994165775\n",
      "Training Loss: 0.006656118750106544\n",
      "Training Loss: 0.00628732907702215\n",
      "Validation Loss: 0.004020673114926753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006515087573206984\n",
      "Training Loss: 0.0066459936718456444\n",
      "Training Loss: 0.00627868470561225\n",
      "Validation Loss: 0.004012313110262072\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006507293770555407\n",
      "Training Loss: 0.006635731101268903\n",
      "Training Loss: 0.006269933162257075\n",
      "Validation Loss: 0.004003735556753792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006499405644135549\n",
      "Training Loss: 0.0066253153374418615\n",
      "Training Loss: 0.006261061339755542\n",
      "Validation Loss: 0.003994915495087717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.0064914112380938605\n",
      "Training Loss: 0.006614726313855499\n",
      "Training Loss: 0.006252054009819403\n",
      "Validation Loss: 0.003985824357728694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.00648329732415732\n",
      "Training Loss: 0.006603941054781899\n",
      "Training Loss: 0.00624289333994966\n",
      "Validation Loss: 0.003976429335176526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.00647504607855808\n",
      "Training Loss: 0.006592931050108746\n",
      "Training Loss: 0.0062335566635010765\n",
      "Validation Loss: 0.003966691211818226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006466638102428987\n",
      "Training Loss: 0.006581661471864208\n",
      "Training Loss: 0.0062240177625790235\n",
      "Validation Loss: 0.003956559823768402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006458047148189507\n",
      "Training Loss: 0.006570090875029564\n",
      "Training Loss: 0.006214244512957521\n",
      "Validation Loss: 0.003945982813563073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006449244099203497\n",
      "Training Loss: 0.006558169085765258\n",
      "Training Loss: 0.006204199367202818\n",
      "Validation Loss: 0.003934892689092398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006440190525609069\n",
      "Training Loss: 0.006545834633288905\n",
      "Training Loss: 0.006193833296420053\n",
      "Validation Loss: 0.003923206817060499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006430839102831669\n",
      "Training Loss: 0.006533011636929586\n",
      "Training Loss: 0.006183090645936318\n",
      "Validation Loss: 0.0039108330985594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006421133476542309\n",
      "Training Loss: 0.006519608363742008\n",
      "Training Loss: 0.006171901255729608\n",
      "Validation Loss: 0.0038976544302396395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006411000547232106\n",
      "Training Loss: 0.0065055111492983994\n",
      "Training Loss: 0.006160178884747438\n",
      "Validation Loss: 0.003883534498261602\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006400352934142575\n",
      "Training Loss: 0.006490583852864802\n",
      "Training Loss: 0.006147822329658084\n",
      "Validation Loss: 0.003868312854843026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.0063890812348108734\n",
      "Training Loss: 0.006474659653613344\n",
      "Training Loss: 0.006134709148318507\n",
      "Validation Loss: 0.0038518092792554433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006377053477335721\n",
      "Training Loss: 0.006457542843418196\n",
      "Training Loss: 0.00612069834198337\n",
      "Validation Loss: 0.0038338137052827672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006364113026647828\n",
      "Training Loss: 0.006439005222637207\n",
      "Training Loss: 0.006105630112579093\n",
      "Validation Loss: 0.003814114557233838\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006350077293463982\n",
      "Training Loss: 0.006418797223595903\n",
      "Training Loss: 0.006089339414611459\n",
      "Validation Loss: 0.003792516834212446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006334754173294641\n",
      "Training Loss: 0.006396672808332369\n",
      "Training Loss: 0.006071680774912238\n",
      "Validation Loss: 0.0037688877154926485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006317956865532323\n",
      "Training Loss: 0.006372430188348517\n",
      "Training Loss: 0.006052561752148904\n",
      "Validation Loss: 0.0037432414351366043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006299547029775567\n",
      "Training Loss: 0.006345988145330921\n",
      "Training Loss: 0.006032009359914809\n",
      "Validation Loss: 0.003715838498587647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006279496819479391\n",
      "Training Loss: 0.00631749201216735\n",
      "Training Loss: 0.006010231205727905\n",
      "Validation Loss: 0.003687292286404147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.00625795257743448\n",
      "Training Loss: 0.006287400120636448\n",
      "Training Loss: 0.0059876591520151125\n",
      "Validation Loss: 0.003658590101234071\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006235273577622138\n",
      "Training Loss: 0.0062565092870499935\n",
      "Training Loss: 0.005964902815176174\n",
      "Validation Loss: 0.0036309696851674926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006211996680940501\n",
      "Training Loss: 0.006225831679766997\n",
      "Training Loss: 0.005942621277063154\n",
      "Validation Loss: 0.0036056274443529964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006188727269764058\n",
      "Training Loss: 0.006196357572916895\n",
      "Training Loss: 0.005921342461952008\n",
      "Validation Loss: 0.003583383986470028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0061659983760910106\n",
      "Training Loss: 0.006168802068568766\n",
      "Training Loss: 0.0059013558953301985\n",
      "Validation Loss: 0.00356449497395373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006144183673313819\n",
      "Training Loss: 0.006143509886460379\n",
      "Training Loss: 0.005882729834411293\n",
      "Validation Loss: 0.0035487330417944057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006123491614707746\n",
      "Training Loss: 0.006120504782302305\n",
      "Training Loss: 0.005865389975369908\n",
      "Validation Loss: 0.003535584804308967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006103997575701214\n",
      "Training Loss: 0.006099613881669939\n",
      "Training Loss: 0.00584920611931011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [13:54<20:53, 208.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0035244632064982246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.15395826213061808\n",
      "Training Loss: 0.11369446879252791\n",
      "Training Loss: 0.08998745264485479\n",
      "Validation Loss: 0.07777327525146892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.07385679271072149\n",
      "Training Loss: 0.0719034051336348\n",
      "Training Loss: 0.0709164671972394\n",
      "Validation Loss: 0.07024926665040214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06718028215691448\n",
      "Training Loss: 0.06564837206155062\n",
      "Training Loss: 0.06444985892623663\n",
      "Validation Loss: 0.06336566048224321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06002698335796595\n",
      "Training Loss: 0.05815523335710168\n",
      "Training Loss: 0.056489142645150425\n",
      "Validation Loss: 0.05469001516741648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.05124225764535367\n",
      "Training Loss: 0.049084297185763716\n",
      "Training Loss: 0.046987620778381825\n",
      "Validation Loss: 0.04444316232556038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.041101781008765104\n",
      "Training Loss: 0.0388524292036891\n",
      "Training Loss: 0.036470174994319676\n",
      "Validation Loss: 0.03353886712300644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.030592463705688716\n",
      "Training Loss: 0.028663642867468298\n",
      "Training Loss: 0.026342416037805377\n",
      "Validation Loss: 0.023587536270824376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.021422304562292993\n",
      "Training Loss: 0.020421658474951983\n",
      "Training Loss: 0.01904607801232487\n",
      "Validation Loss: 0.017288225122172846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01642152848886326\n",
      "Training Loss: 0.016547966683283448\n",
      "Training Loss: 0.016075555791612715\n",
      "Validation Loss: 0.014665182713900557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.014494153473060578\n",
      "Training Loss: 0.014817228410392999\n",
      "Training Loss: 0.01451701148180291\n",
      "Validation Loss: 0.013056754260166977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.013263151000719517\n",
      "Training Loss: 0.013586355566512793\n",
      "Training Loss: 0.013332730196416377\n",
      "Validation Loss: 0.011791703945256016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.012305353316478432\n",
      "Training Loss: 0.012599679324775934\n",
      "Training Loss: 0.012374948487849907\n",
      "Validation Loss: 0.01074499470767764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.011537735925521701\n",
      "Training Loss: 0.011796457306481899\n",
      "Training Loss: 0.01159540941938758\n",
      "Validation Loss: 0.009873639496587467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.01092091954080388\n",
      "Training Loss: 0.011146468752995133\n",
      "Training Loss: 0.010964429270243272\n",
      "Validation Loss: 0.009152258806495686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010427204677835106\n",
      "Training Loss: 0.010625819638371468\n",
      "Training Loss: 0.010457722414284944\n",
      "Validation Loss: 0.008559387378666676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010033684110967443\n",
      "Training Loss: 0.01021212176186964\n",
      "Training Loss: 0.010053208380704746\n",
      "Validation Loss: 0.008074610169683949\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009720315630547703\n",
      "Training Loss: 0.009884304739534855\n",
      "Training Loss: 0.009730589350219816\n",
      "Validation Loss: 0.007678593362399032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009469503354048357\n",
      "Training Loss: 0.009623359134420752\n",
      "Training Loss: 0.00947175305453129\n",
      "Validation Loss: 0.007353740820158901\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009266188456676901\n",
      "Training Loss: 0.009413000044878573\n",
      "Training Loss: 0.009261237651808188\n",
      "Validation Loss: 0.0070847655565404654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00909800943103619\n",
      "Training Loss: 0.009239992391085252\n",
      "Training Loss: 0.009086490854388103\n",
      "Validation Loss: 0.0068589888573257944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008955328480806202\n",
      "Training Loss: 0.00909413376590237\n",
      "Training Loss: 0.008937812065705658\n",
      "Validation Loss: 0.006666329780886515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008831010515568777\n",
      "Training Loss: 0.008967935397522523\n",
      "Training Loss: 0.00880803303909488\n",
      "Validation Loss: 0.006499024607722511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.0087199977459386\n",
      "Training Loss: 0.008856110236374662\n",
      "Training Loss: 0.008692026098724454\n",
      "Validation Loss: 0.006351264886913842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008618829813785851\n",
      "Training Loss: 0.008755040913820266\n",
      "Training Loss: 0.008586228262865916\n",
      "Validation Loss: 0.0062187952604249455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008525187105406076\n",
      "Training Loss: 0.008662283479934559\n",
      "Training Loss: 0.008488196949474513\n",
      "Validation Loss: 0.006098537976602406\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008437533361138776\n",
      "Training Loss: 0.008576198609080165\n",
      "Training Loss: 0.008396281937602907\n",
      "Validation Loss: 0.005988294384285306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008354857966769486\n",
      "Training Loss: 0.008495683302171528\n",
      "Training Loss: 0.008309385020984337\n",
      "Validation Loss: 0.005886506447516215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008276492996374145\n",
      "Training Loss: 0.008419985768850892\n",
      "Training Loss: 0.00822677643620409\n",
      "Validation Loss: 0.0057920384877413675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008201991298701614\n",
      "Training Loss: 0.00834858464775607\n",
      "Training Loss: 0.00814798432169482\n",
      "Validation Loss: 0.005704085656514998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008131048909854144\n",
      "Training Loss: 0.008281106408685446\n",
      "Training Loss: 0.008072700520278886\n",
      "Validation Loss: 0.005622036836183305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008063439703546465\n",
      "Training Loss: 0.008217267603613436\n",
      "Training Loss: 0.008000726881437003\n",
      "Validation Loss: 0.005545433515190995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007998998599359765\n",
      "Training Loss: 0.008156850377563387\n",
      "Training Loss: 0.007931940098060294\n",
      "Validation Loss: 0.005473917532644203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007937602159800008\n",
      "Training Loss: 0.0080996884603519\n",
      "Training Loss: 0.007866290835663677\n",
      "Validation Loss: 0.005407214401488642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007879189242376015\n",
      "Training Loss: 0.008045676400652155\n",
      "Training Loss: 0.007803799083922059\n",
      "Validation Loss: 0.005345118722585396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.00782377019058913\n",
      "Training Loss: 0.007994774907128886\n",
      "Training Loss: 0.007744560376740992\n",
      "Validation Loss: 0.005287462526283572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007771436212351546\n",
      "Training Loss: 0.007947000375716017\n",
      "Training Loss: 0.007688721950398758\n",
      "Validation Loss: 0.005234083074427555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007722325943177566\n",
      "Training Loss: 0.00790239398018457\n",
      "Training Loss: 0.007636428665136918\n",
      "Validation Loss: 0.00518478185927307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00767657229793258\n",
      "Training Loss: 0.007860974278301\n",
      "Training Loss: 0.007587773356353864\n",
      "Validation Loss: 0.005139299640902893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007634244638611562\n",
      "Training Loss: 0.007822692279005424\n",
      "Training Loss: 0.007542747545521707\n",
      "Validation Loss: 0.0050973350861047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0075953061430482196\n",
      "Training Loss: 0.007787414920749143\n",
      "Training Loss: 0.00750122093479149\n",
      "Validation Loss: 0.005058545663068594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007559613573830575\n",
      "Training Loss: 0.007754935233388096\n",
      "Training Loss: 0.007462979488773272\n",
      "Validation Loss: 0.005022601184586921\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0075269458396360275\n",
      "Training Loss: 0.007725003061350435\n",
      "Training Loss: 0.00742774965823628\n",
      "Validation Loss: 0.004989208350758581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007497037350549363\n",
      "Training Loss: 0.0076973532163538035\n",
      "Training Loss: 0.007395244083600119\n",
      "Validation Loss: 0.004958120401650458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0074696110782679175\n",
      "Training Loss: 0.007671729029389098\n",
      "Training Loss: 0.007365179986227304\n",
      "Validation Loss: 0.004929124448301919\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007444398211082444\n",
      "Training Loss: 0.007647893738467246\n",
      "Training Loss: 0.007337295634206384\n",
      "Validation Loss: 0.004902059595581939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007421147351851687\n",
      "Training Loss: 0.007625635911244899\n",
      "Training Loss: 0.007311356700956822\n",
      "Validation Loss: 0.004876781253044734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007399630884756334\n",
      "Training Loss: 0.007604770321631804\n",
      "Training Loss: 0.007287154332734644\n",
      "Validation Loss: 0.004853164925621927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007379645660985261\n",
      "Training Loss: 0.007585136381676421\n",
      "Training Loss: 0.007264503376791254\n",
      "Validation Loss: 0.004831096220871412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007361007486470044\n",
      "Training Loss: 0.007566591330105439\n",
      "Training Loss: 0.00724324049660936\n",
      "Validation Loss: 0.004810461917698509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007343553746468387\n",
      "Training Loss: 0.007549013425596059\n",
      "Training Loss: 0.007223219857551157\n",
      "Validation Loss: 0.004791159343021514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007327139441622421\n",
      "Training Loss: 0.007532292916439473\n",
      "Training Loss: 0.007204310178058222\n",
      "Validation Loss: 0.0047730806171161575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007311638849787414\n",
      "Training Loss: 0.007516337607521564\n",
      "Training Loss: 0.007186396853066981\n",
      "Validation Loss: 0.004756126958311776\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007296938604558818\n",
      "Training Loss: 0.007501063941745088\n",
      "Training Loss: 0.007169380232226103\n",
      "Validation Loss: 0.004740207951798449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007282941971207038\n",
      "Training Loss: 0.007486401872010901\n",
      "Training Loss: 0.007153168976074085\n",
      "Validation Loss: 0.004725227664810804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007269563265726902\n",
      "Training Loss: 0.0074722873757127675\n",
      "Training Loss: 0.0071376827044878155\n",
      "Validation Loss: 0.0047111024045427274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0072567307576537135\n",
      "Training Loss: 0.007458666836610064\n",
      "Training Loss: 0.007122851354070008\n",
      "Validation Loss: 0.004697748354578579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007244379540788941\n",
      "Training Loss: 0.00744549208553508\n",
      "Training Loss: 0.007108613469172269\n",
      "Validation Loss: 0.004685098334775421\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007232455127523281\n",
      "Training Loss: 0.007432721455115825\n",
      "Training Loss: 0.0070949110214132815\n",
      "Validation Loss: 0.004673079519501228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007220909945899621\n",
      "Training Loss: 0.007420318120857701\n",
      "Training Loss: 0.007081699811387807\n",
      "Validation Loss: 0.004661632350546548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007209704773267731\n",
      "Training Loss: 0.007408250537700951\n",
      "Training Loss: 0.007068935267161578\n",
      "Validation Loss: 0.004650706764090848\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007198802681523375\n",
      "Training Loss: 0.0073964901478029785\n",
      "Training Loss: 0.007056578662013635\n",
      "Validation Loss: 0.004640243380471771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007188174434704706\n",
      "Training Loss: 0.007385012113954872\n",
      "Training Loss: 0.007044595538172871\n",
      "Validation Loss: 0.004630198083514494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007177793020382524\n",
      "Training Loss: 0.007373792951693758\n",
      "Training Loss: 0.007032957547344267\n",
      "Validation Loss: 0.00462053448689076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0071676355053205045\n",
      "Training Loss: 0.007362814338412136\n",
      "Training Loss: 0.007021636174758896\n",
      "Validation Loss: 0.004611208480311914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007157682197866961\n",
      "Training Loss: 0.0073520576627925036\n",
      "Training Loss: 0.007010607565753162\n",
      "Validation Loss: 0.004602193440640282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00714791513804812\n",
      "Training Loss: 0.007341507240198553\n",
      "Training Loss: 0.006999850126449019\n",
      "Validation Loss: 0.004593455106454242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007138318627257831\n",
      "Training Loss: 0.007331147271906957\n",
      "Training Loss: 0.006989343519089744\n",
      "Validation Loss: 0.004584963904337936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007128878802759573\n",
      "Training Loss: 0.0073209651059005405\n",
      "Training Loss: 0.006979069153312594\n",
      "Validation Loss: 0.004576697647362278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007119583081803284\n",
      "Training Loss: 0.007310949140228331\n",
      "Training Loss: 0.006969012026675045\n",
      "Validation Loss: 0.004568637956294828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0071104196878150104\n",
      "Training Loss: 0.00730108731193468\n",
      "Training Loss: 0.006959156546508893\n",
      "Validation Loss: 0.004560761262919084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007101379227824509\n",
      "Training Loss: 0.007291370338061824\n",
      "Training Loss: 0.006949489817488938\n",
      "Validation Loss: 0.00455305315658785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00709245202539023\n",
      "Training Loss: 0.007281787160318345\n",
      "Training Loss: 0.006939998453017324\n",
      "Validation Loss: 0.004545493980116221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007083630973938853\n",
      "Training Loss: 0.007272331026615575\n",
      "Training Loss: 0.006930672413436696\n",
      "Validation Loss: 0.004538070407219943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007074908524518832\n",
      "Training Loss: 0.007262993166223169\n",
      "Training Loss: 0.0069214995461516085\n",
      "Validation Loss: 0.004530770647904595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0070662766619352625\n",
      "Training Loss: 0.00725376570248045\n",
      "Training Loss: 0.0069124725251458585\n",
      "Validation Loss: 0.004523583787906748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00705773031921126\n",
      "Training Loss: 0.007244642379228026\n",
      "Training Loss: 0.006903582508675754\n",
      "Validation Loss: 0.004516498638929151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007049263612716458\n",
      "Training Loss: 0.007235616891412064\n",
      "Training Loss: 0.006894818086875603\n",
      "Validation Loss: 0.004509504376962948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007040871325880289\n",
      "Training Loss: 0.0072266833728645\n",
      "Training Loss: 0.006886177005944774\n",
      "Validation Loss: 0.004502596890846832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007032549308496528\n",
      "Training Loss: 0.0072178358933888374\n",
      "Training Loss: 0.006877648121444508\n",
      "Validation Loss: 0.004495762589418989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007024292095447891\n",
      "Training Loss: 0.007209069284144789\n",
      "Training Loss: 0.006869227704592049\n",
      "Validation Loss: 0.004488999941621729\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007016095992876217\n",
      "Training Loss: 0.007200378682464361\n",
      "Training Loss: 0.006860906349029392\n",
      "Validation Loss: 0.004482297105139143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007007956404122524\n",
      "Training Loss: 0.007191759670386091\n",
      "Training Loss: 0.006852681132731959\n",
      "Validation Loss: 0.004475646558102597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006999871907755733\n",
      "Training Loss: 0.007183207417838276\n",
      "Training Loss: 0.006844546968350187\n",
      "Validation Loss: 0.004469053557514098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006991838190588169\n",
      "Training Loss: 0.007174719910835847\n",
      "Training Loss: 0.006836498886113987\n",
      "Validation Loss: 0.004462505820903174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006983851888217032\n",
      "Training Loss: 0.007166291299508885\n",
      "Training Loss: 0.006828531302744523\n",
      "Validation Loss: 0.004455999482365513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00697591092903167\n",
      "Training Loss: 0.007157919143792242\n",
      "Training Loss: 0.0068206406640820205\n",
      "Validation Loss: 0.004449530984693615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0069680121733108535\n",
      "Training Loss: 0.007149599943077191\n",
      "Training Loss: 0.0068128232669550925\n",
      "Validation Loss: 0.004443097087879027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006960153443505987\n",
      "Training Loss: 0.007141330036101862\n",
      "Training Loss: 0.006805074365111068\n",
      "Validation Loss: 0.004436696017569119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00695233196776826\n",
      "Training Loss: 0.007133107095723972\n",
      "Training Loss: 0.006797392294974998\n",
      "Validation Loss: 0.004430324412761989\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006944546987069771\n",
      "Training Loss: 0.007124927873956039\n",
      "Training Loss: 0.006789772536139935\n",
      "Validation Loss: 0.00442397906942021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006936795106157661\n",
      "Training Loss: 0.007116790602449328\n",
      "Training Loss: 0.006782212017569691\n",
      "Validation Loss: 0.004417653886857704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006929075184743851\n",
      "Training Loss: 0.007108691757312044\n",
      "Training Loss: 0.006774706830037757\n",
      "Validation Loss: 0.004411352041643113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.00692138463142328\n",
      "Training Loss: 0.007100629165070132\n",
      "Training Loss: 0.006767255035229027\n",
      "Validation Loss: 0.0044050700295444455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006913722398458048\n",
      "Training Loss: 0.007092600193573162\n",
      "Training Loss: 0.006759855133714155\n",
      "Validation Loss: 0.004398803147513503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006906086654635146\n",
      "Training Loss: 0.007084602698450908\n",
      "Training Loss: 0.006752501919399947\n",
      "Validation Loss: 0.0043925534785997245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.00689847539528273\n",
      "Training Loss: 0.007076634340919554\n",
      "Training Loss: 0.0067451950174290684\n",
      "Validation Loss: 0.00438632064151023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0068908868846483525\n",
      "Training Loss: 0.007068693985929713\n",
      "Training Loss: 0.006737930091330782\n",
      "Validation Loss: 0.004380097928629623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006883320105844177\n",
      "Training Loss: 0.0070607779105193915\n",
      "Training Loss: 0.006730705504305661\n",
      "Validation Loss: 0.004373888038438902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00687577212927863\n",
      "Training Loss: 0.0070528846094384786\n",
      "Training Loss: 0.006723519971128553\n",
      "Validation Loss: 0.004367687579851304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006868243103963323\n",
      "Training Loss: 0.007045011867303401\n",
      "Training Loss: 0.0067163691855967045\n",
      "Validation Loss: 0.004361498641148419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006860729845939204\n",
      "Training Loss: 0.00703715730109252\n",
      "Training Loss: 0.00670925177866593\n",
      "Validation Loss: 0.004355317228238276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.00685323174810037\n",
      "Training Loss: 0.007029319644207135\n",
      "Training Loss: 0.006702165399910882\n",
      "Validation Loss: 0.004349142770162585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006845746738836169\n",
      "Training Loss: 0.007021496716188267\n",
      "Training Loss: 0.006695107584819198\n",
      "Validation Loss: 0.0043429772721425616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006838272586464882\n",
      "Training Loss: 0.00701368497335352\n",
      "Training Loss: 0.006688077169237658\n",
      "Validation Loss: 0.004336817558917604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006830808778759092\n",
      "Training Loss: 0.0070058839477133\n",
      "Training Loss: 0.0066810702777002\n",
      "Validation Loss: 0.004330662181836375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.0068233532656449825\n",
      "Training Loss: 0.006998090406414121\n",
      "Training Loss: 0.0066740854841191325\n",
      "Validation Loss: 0.004324510894333839\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006815902228117921\n",
      "Training Loss: 0.006990302874473855\n",
      "Training Loss: 0.00666711894213222\n",
      "Validation Loss: 0.004318361078373293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00680845563299954\n",
      "Training Loss: 0.0069825179758481685\n",
      "Training Loss: 0.006660170137765817\n",
      "Validation Loss: 0.004312213267633963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006801010411581956\n",
      "Training Loss: 0.006974733436945826\n",
      "Training Loss: 0.006653235332923941\n",
      "Validation Loss: 0.0043060673300040824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006793564974796027\n",
      "Training Loss: 0.006966947325272485\n",
      "Training Loss: 0.006646311630611308\n",
      "Validation Loss: 0.004299918486569286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006786117151496001\n",
      "Training Loss: 0.006959156629163772\n",
      "Training Loss: 0.006639397401013412\n",
      "Validation Loss: 0.004293767756944669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.0067786635289667175\n",
      "Training Loss: 0.006951358780497685\n",
      "Training Loss: 0.0066324902593623844\n",
      "Validation Loss: 0.0042876161528971005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.0067712023720378055\n",
      "Training Loss: 0.006943551662843674\n",
      "Training Loss: 0.006625587020535022\n",
      "Validation Loss: 0.004281461174113236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006763731732207816\n",
      "Training Loss: 0.006935732356505468\n",
      "Training Loss: 0.006618684267741628\n",
      "Validation Loss: 0.00427529950014033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006756247653393075\n",
      "Training Loss: 0.006927896123379469\n",
      "Training Loss: 0.006611780472449027\n",
      "Validation Loss: 0.004269131488072571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006748748339596204\n",
      "Training Loss: 0.00692004257813096\n",
      "Training Loss: 0.006604871066519991\n",
      "Validation Loss: 0.004262953953493093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006741230776533484\n",
      "Training Loss: 0.006912166164256633\n",
      "Training Loss: 0.006597952980082482\n",
      "Validation Loss: 0.004256765494839906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006733690981054679\n",
      "Training Loss: 0.006904264388140291\n",
      "Training Loss: 0.00659102347039152\n",
      "Validation Loss: 0.004250564145478891\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.00672612713300623\n",
      "Training Loss: 0.006896333595504984\n",
      "Training Loss: 0.006584078859887086\n",
      "Validation Loss: 0.004244348123863214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006718532296654303\n",
      "Training Loss: 0.006888370153028518\n",
      "Training Loss: 0.0065771160542499275\n",
      "Validation Loss: 0.004238114423469086\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006710906949592754\n",
      "Training Loss: 0.006880370456492528\n",
      "Training Loss: 0.006570130816544406\n",
      "Validation Loss: 0.004231861194731731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006703245182870887\n",
      "Training Loss: 0.006872329993639141\n",
      "Training Loss: 0.006563119248021394\n",
      "Validation Loss: 0.004225585319290168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0066955440741730855\n",
      "Training Loss: 0.00686424331041053\n",
      "Training Loss: 0.0065560762956738475\n",
      "Validation Loss: 0.004219284165373302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.0066877966967877\n",
      "Training Loss: 0.006856108200736344\n",
      "Training Loss: 0.00654899958812166\n",
      "Validation Loss: 0.00421295510513415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0066800022558891215\n",
      "Training Loss: 0.006847918595885858\n",
      "Training Loss: 0.006541884399484843\n",
      "Validation Loss: 0.004206594338724285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006672154029947705\n",
      "Training Loss: 0.006839669219916686\n",
      "Training Loss: 0.0065347229572944344\n",
      "Validation Loss: 0.004200195758917442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006664247267181054\n",
      "Training Loss: 0.006831355363829061\n",
      "Training Loss: 0.006527514394256286\n",
      "Validation Loss: 0.004193757491296136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006656276917783544\n",
      "Training Loss: 0.006822971618967131\n",
      "Training Loss: 0.006520250847097486\n",
      "Validation Loss: 0.004187275796835677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006648237553308718\n",
      "Training Loss: 0.0068145121494308115\n",
      "Training Loss: 0.006512929245945998\n",
      "Validation Loss: 0.004180749621912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006640124066616408\n",
      "Training Loss: 0.006805970986606553\n",
      "Training Loss: 0.006505542802624404\n",
      "Validation Loss: 0.0041741706559099674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006631930167786777\n",
      "Training Loss: 0.006797341894125566\n",
      "Training Loss: 0.006498084338963963\n",
      "Validation Loss: 0.004167531010710498\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006623650738620199\n",
      "Training Loss: 0.006788618164137006\n",
      "Training Loss: 0.006490550203016028\n",
      "Validation Loss: 0.004160828611112378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006615278334065806\n",
      "Training Loss: 0.006779792648740113\n",
      "Training Loss: 0.006482931898790412\n",
      "Validation Loss: 0.004154056765850675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006606806318159215\n",
      "Training Loss: 0.006770859275711701\n",
      "Training Loss: 0.006475224697496742\n",
      "Validation Loss: 0.004147212951067375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006598228770890273\n",
      "Training Loss: 0.00676180909271352\n",
      "Training Loss: 0.006467420866247266\n",
      "Validation Loss: 0.0041402893715140445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006589537896797992\n",
      "Training Loss: 0.0067526358785107736\n",
      "Training Loss: 0.00645951344165951\n",
      "Validation Loss: 0.004133279344427996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006580727486871183\n",
      "Training Loss: 0.006743330876342952\n",
      "Training Loss: 0.006451495523797348\n",
      "Validation Loss: 0.00412617585088095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0065717899519950156\n",
      "Training Loss: 0.006733886613510549\n",
      "Training Loss: 0.006443359645782038\n",
      "Validation Loss: 0.0041189742846194696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006562716720509343\n",
      "Training Loss: 0.0067242944892495875\n",
      "Training Loss: 0.006435097872745246\n",
      "Validation Loss: 0.004111665775188443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006553501426824368\n",
      "Training Loss: 0.00671454546158202\n",
      "Training Loss: 0.006426703472388908\n",
      "Validation Loss: 0.004104238961629695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006544136590673588\n",
      "Training Loss: 0.006704631319735199\n",
      "Training Loss: 0.006418167233350687\n",
      "Validation Loss: 0.004096696020517331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006534613417461515\n",
      "Training Loss: 0.006694544208003208\n",
      "Training Loss: 0.0064094829099485655\n",
      "Validation Loss: 0.004089022137674639\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.0065249261248391125\n",
      "Training Loss: 0.006684275172883645\n",
      "Training Loss: 0.006400641615618952\n",
      "Validation Loss: 0.004081211956688778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006515065545681864\n",
      "Training Loss: 0.006673815121175721\n",
      "Training Loss: 0.006391637562774122\n",
      "Validation Loss: 0.004073257272241616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0065050266886828466\n",
      "Training Loss: 0.006663156859576702\n",
      "Training Loss: 0.006382462199544534\n",
      "Validation Loss: 0.0040651547566862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006494801500812173\n",
      "Training Loss: 0.006652292635990307\n",
      "Training Loss: 0.0063731089275097475\n",
      "Validation Loss: 0.004056895295618458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.00648438505071681\n",
      "Training Loss: 0.0066412146424409\n",
      "Training Loss: 0.006363570786779746\n",
      "Validation Loss: 0.004048467900216831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006473772879689932\n",
      "Training Loss: 0.006629917519167066\n",
      "Training Loss: 0.006353845737758093\n",
      "Validation Loss: 0.004039874938682893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006462959187338128\n",
      "Training Loss: 0.006618395483819768\n",
      "Training Loss: 0.006343924610409886\n",
      "Validation Loss: 0.004031104258041871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0064519423170713705\n",
      "Training Loss: 0.006606643770355731\n",
      "Training Loss: 0.006333805709145963\n",
      "Validation Loss: 0.004022156068233752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006440720196405891\n",
      "Training Loss: 0.006594660292612389\n",
      "Training Loss: 0.006323486081673764\n",
      "Validation Loss: 0.004013024955292054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006429291589884087\n",
      "Training Loss: 0.0065824435109971095\n",
      "Training Loss: 0.006312966721015983\n",
      "Validation Loss: 0.004003711767478982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006417661049345043\n",
      "Training Loss: 0.0065699952002614736\n",
      "Training Loss: 0.00630224654043559\n",
      "Validation Loss: 0.003994214183682304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.0064058304927311835\n",
      "Training Loss: 0.006557317979750224\n",
      "Training Loss: 0.006291330856620334\n",
      "Validation Loss: 0.003984535821279239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006393807259446476\n",
      "Training Loss: 0.006544417373952456\n",
      "Training Loss: 0.006280223236535676\n",
      "Validation Loss: 0.003974682675004842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006381599957239814\n",
      "Training Loss: 0.006531302716466598\n",
      "Training Loss: 0.006268931051599793\n",
      "Validation Loss: 0.003964653188948718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.00636921891476959\n",
      "Training Loss: 0.006517984990496189\n",
      "Training Loss: 0.006257464829250239\n",
      "Validation Loss: 0.0039544652792980915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0063566809459007344\n",
      "Training Loss: 0.006504480711882934\n",
      "Training Loss: 0.006245837579481304\n",
      "Validation Loss: 0.003944123726929381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006344001329562161\n",
      "Training Loss: 0.006490807156078518\n",
      "Training Loss: 0.006234064743621275\n",
      "Validation Loss: 0.0039336434892493855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0063312005915213375\n",
      "Training Loss: 0.006476983884931542\n",
      "Training Loss: 0.006222164233331568\n",
      "Validation Loss: 0.003923039460879112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006318302072468213\n",
      "Training Loss: 0.00646303917048499\n",
      "Training Loss: 0.00621015592943877\n",
      "Validation Loss: 0.003912329697965781\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006305328727466986\n",
      "Training Loss: 0.0064489965100074185\n",
      "Training Loss: 0.006198061794857494\n",
      "Validation Loss: 0.003901535282146939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006292307785479352\n",
      "Training Loss: 0.00643488876579795\n",
      "Training Loss: 0.00618590704514645\n",
      "Validation Loss: 0.0038906735854662873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.0062792694749077786\n",
      "Training Loss: 0.006420745525392704\n",
      "Training Loss: 0.006173717962228693\n",
      "Validation Loss: 0.0038797714782805508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006266240022960119\n",
      "Training Loss: 0.00640660194971133\n",
      "Training Loss: 0.006161519418819808\n",
      "Validation Loss: 0.003868848606656316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006253250892041251\n",
      "Training Loss: 0.006392491435399279\n",
      "Training Loss: 0.006149339197436348\n",
      "Validation Loss: 0.0038579278710570313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006240329701977316\n",
      "Training Loss: 0.006378447769675404\n",
      "Training Loss: 0.0061372049833880735\n",
      "Validation Loss: 0.0038470329011769527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006227506608702242\n",
      "Training Loss: 0.006364504094235599\n",
      "Training Loss: 0.006125139827490784\n",
      "Validation Loss: 0.003836182677945687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006214807030046359\n",
      "Training Loss: 0.006350694361608475\n",
      "Training Loss: 0.006113171121687628\n",
      "Validation Loss: 0.003825393501470347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006202256357064471\n",
      "Training Loss: 0.006337046920671128\n",
      "Training Loss: 0.006101319032604806\n",
      "Validation Loss: 0.0038146847961051914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006189876487187575\n",
      "Training Loss: 0.006323588956729509\n",
      "Training Loss: 0.006089605576125905\n",
      "Validation Loss: 0.0038040742465148395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.0061776895896764475\n",
      "Training Loss: 0.006310347463586368\n",
      "Training Loss: 0.006078049822244793\n",
      "Validation Loss: 0.0037935735341266133\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006165708288608585\n",
      "Training Loss: 0.006297341419849545\n",
      "Training Loss: 0.0060666664352174845\n",
      "Validation Loss: 0.0037831911121317175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006153950217994861\n",
      "Training Loss: 0.006284591045696289\n",
      "Training Loss: 0.006055469170678407\n",
      "Validation Loss: 0.003772933975913761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006142425296129659\n",
      "Training Loss: 0.006272110300487839\n",
      "Training Loss: 0.006044469231273979\n",
      "Validation Loss: 0.0037628103536815286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006131141223595478\n",
      "Training Loss: 0.006259910378139466\n",
      "Training Loss: 0.006033675365033559\n",
      "Validation Loss: 0.003752822539078469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006120104601141065\n",
      "Training Loss: 0.006247999595361761\n",
      "Training Loss: 0.006023093043477274\n",
      "Validation Loss: 0.0037429748126567245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006109319111565128\n",
      "Training Loss: 0.006236384362564422\n",
      "Training Loss: 0.006012726225890219\n",
      "Validation Loss: 0.0037332616034853323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006098787016817368\n",
      "Training Loss: 0.006225067389314063\n",
      "Training Loss: 0.006002577785984613\n",
      "Validation Loss: 0.0037236881201689162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.0060885071192751635\n",
      "Training Loss: 0.006214048115652986\n",
      "Training Loss: 0.005992649585241452\n",
      "Validation Loss: 0.003714251161286126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006078478007984813\n",
      "Training Loss: 0.0062033263011835515\n",
      "Training Loss: 0.005982939932728186\n",
      "Validation Loss: 0.003704944519545841\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006068696868605911\n",
      "Training Loss: 0.006192897604196332\n",
      "Training Loss: 0.0059734477126039565\n",
      "Validation Loss: 0.0036957690732951245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.00605915887223091\n",
      "Training Loss: 0.006182758811628446\n",
      "Training Loss: 0.005964169544167817\n",
      "Validation Loss: 0.0036867211848821786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.00604986013029702\n",
      "Training Loss: 0.006172903653350659\n",
      "Training Loss: 0.005955101277795621\n",
      "Validation Loss: 0.003677796795467187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.00604079516895581\n",
      "Training Loss: 0.006163324392400682\n",
      "Training Loss: 0.005946240493212827\n",
      "Validation Loss: 0.0036689907651174854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006031956902006641\n",
      "Training Loss: 0.006154015074716881\n",
      "Training Loss: 0.005937579448800534\n",
      "Validation Loss: 0.0036602987485330847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006023338909144514\n",
      "Training Loss: 0.006144966782303527\n",
      "Training Loss: 0.0059291145566385236\n",
      "Validation Loss: 0.0036517168575730384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006014934711274691\n",
      "Training Loss: 0.006136170265381225\n",
      "Training Loss: 0.005920838340534829\n",
      "Validation Loss: 0.0036432453322621963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006006735819973983\n",
      "Training Loss: 0.006127617038437165\n",
      "Training Loss: 0.005912746475078165\n",
      "Validation Loss: 0.003634873725960471\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005998735466855578\n",
      "Training Loss: 0.006119298723060638\n",
      "Training Loss: 0.005904830950894393\n",
      "Validation Loss: 0.00362660365736405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.0059909268189221624\n",
      "Training Loss: 0.006111205861670897\n",
      "Training Loss: 0.005897087457706221\n",
      "Validation Loss: 0.0036184325954207123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005983301087107975\n",
      "Training Loss: 0.006103327393648214\n",
      "Training Loss: 0.005889507726533338\n",
      "Validation Loss: 0.0036103537481466537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005975850942777469\n",
      "Training Loss: 0.006095657341065816\n",
      "Training Loss: 0.005882085608318448\n",
      "Validation Loss: 0.003602367689770259\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005968569914984983\n",
      "Training Loss: 0.006088184132240712\n",
      "Training Loss: 0.005874816304421984\n",
      "Validation Loss: 0.003594466551138988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0059614515549037605\n",
      "Training Loss: 0.00608090013556648\n",
      "Training Loss: 0.005867689428268932\n",
      "Validation Loss: 0.0035866496350689466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005954485329566523\n",
      "Training Loss: 0.006073795846896246\n",
      "Training Loss: 0.005860701688798145\n",
      "Validation Loss: 0.00357891697818518\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005947665493004024\n",
      "Training Loss: 0.006066863500745967\n",
      "Training Loss: 0.005853845712263137\n",
      "Validation Loss: 0.003571261229971947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005940986050991342\n",
      "Training Loss: 0.006060093367123045\n",
      "Training Loss: 0.00584711515402887\n",
      "Validation Loss: 0.003563684444701864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005934440394048579\n",
      "Training Loss: 0.006053479459951632\n",
      "Training Loss: 0.005840503854560666\n",
      "Validation Loss: 0.003556181063870324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005928021562285721\n",
      "Training Loss: 0.00604701284551993\n",
      "Training Loss: 0.005834006512304768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [17:24<17:26, 209.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.003548751157457323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.1372464245557785\n",
      "Training Loss: 0.1032153289206326\n",
      "Training Loss: 0.08176951456815004\n",
      "Validation Loss: 0.06952918314615662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06369084030389786\n",
      "Training Loss: 0.0597489769756794\n",
      "Training Loss: 0.05659532304853201\n",
      "Validation Loss: 0.053786832169535455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04923572960309684\n",
      "Training Loss: 0.04547320436686277\n",
      "Training Loss: 0.04201118532568216\n",
      "Validation Loss: 0.03870044475986382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.03475730186328292\n",
      "Training Loss: 0.0324728170922026\n",
      "Training Loss: 0.030087928078137337\n",
      "Validation Loss: 0.027628050913008746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.024699075208045543\n",
      "Training Loss: 0.02370252922642976\n",
      "Training Loss: 0.021805254095233977\n",
      "Validation Loss: 0.0195972791956633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.017710289140231907\n",
      "Training Loss: 0.0173295149137266\n",
      "Training Loss: 0.01607396395644173\n",
      "Validation Loss: 0.014506580022927583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.014027560448739677\n",
      "Training Loss: 0.014289538972079754\n",
      "Training Loss: 0.013761783824302256\n",
      "Validation Loss: 0.012347503952430875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.012475644354708493\n",
      "Training Loss: 0.012776040369644762\n",
      "Training Loss: 0.012428464653203264\n",
      "Validation Loss: 0.01096289957025915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.011425682646222412\n",
      "Training Loss: 0.011737817332614213\n",
      "Training Loss: 0.01147757129278034\n",
      "Validation Loss: 0.009979400072204932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.010676325181266292\n",
      "Training Loss: 0.011003451594151557\n",
      "Training Loss: 0.01079546523746103\n",
      "Validation Loss: 0.009270678881262795\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010138190754223614\n",
      "Training Loss: 0.010476193835493176\n",
      "Training Loss: 0.010299084357684478\n",
      "Validation Loss: 0.008747434252716098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009742150355596096\n",
      "Training Loss: 0.010084833733271808\n",
      "Training Loss: 0.009925065204733984\n",
      "Validation Loss: 0.008345607309759166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009439236399484798\n",
      "Training Loss: 0.009781455174088478\n",
      "Training Loss: 0.009630702717695385\n",
      "Validation Loss: 0.008022637054156722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00919767890824005\n",
      "Training Loss: 0.009535922277718782\n",
      "Training Loss: 0.009389062644913793\n",
      "Validation Loss: 0.007751581333629954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008997605326585471\n",
      "Training Loss: 0.009329712209291756\n",
      "Training Loss: 0.009183506949339061\n",
      "Validation Loss: 0.007515722897500218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008826607122318818\n",
      "Training Loss: 0.009151413671206683\n",
      "Training Loss: 0.009003737316234037\n",
      "Validation Loss: 0.0073047443476160255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008676848742179572\n",
      "Training Loss: 0.008993909211130812\n",
      "Training Loss: 0.008843306917697191\n",
      "Validation Loss: 0.007112257147281106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00854329479392618\n",
      "Training Loss: 0.008852669802727177\n",
      "Training Loss: 0.008698097794549539\n",
      "Validation Loss: 0.006934253594398582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008422628322150558\n",
      "Training Loss: 0.008724718488520012\n",
      "Training Loss: 0.008565390780568123\n",
      "Validation Loss: 0.006768144646219993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008312604653183371\n",
      "Training Loss: 0.008607994260964915\n",
      "Training Loss: 0.008443294483004137\n",
      "Validation Loss: 0.006612149986773311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008211655807681382\n",
      "Training Loss: 0.008500988610321655\n",
      "Training Loss: 0.008330420441925526\n",
      "Validation Loss: 0.00646499563087029\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008118685497902334\n",
      "Training Loss: 0.008402556700166314\n",
      "Training Loss: 0.008225722754141317\n",
      "Validation Loss: 0.006325733586308661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008032981159631162\n",
      "Training Loss: 0.008311848272569478\n",
      "Training Loss: 0.008128458563005552\n",
      "Validation Loss: 0.00619376514740079\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007954200794920326\n",
      "Training Loss: 0.008228324864758179\n",
      "Training Loss: 0.008038208038778976\n",
      "Validation Loss: 0.006068902428973508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.00788234556093812\n",
      "Training Loss: 0.008151764100184665\n",
      "Training Loss: 0.007954885277431458\n",
      "Validation Loss: 0.005951420953392648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007817639086279088\n",
      "Training Loss: 0.008082184793893247\n",
      "Training Loss: 0.007878638529218733\n",
      "Validation Loss: 0.005841957356812161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007760270128492266\n",
      "Training Loss: 0.00801965486491099\n",
      "Training Loss: 0.007809633677825331\n",
      "Validation Loss: 0.005741227992412666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007710106640588492\n",
      "Training Loss: 0.007964048201683909\n",
      "Training Loss: 0.007747803771635518\n",
      "Validation Loss: 0.005649691388753944\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007666538988705725\n",
      "Training Loss: 0.007914872044930235\n",
      "Training Loss: 0.007692693494027481\n",
      "Validation Loss: 0.005567296289085421\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.0076285375689622015\n",
      "Training Loss: 0.007871283474378288\n",
      "Training Loss: 0.007643494951771572\n",
      "Validation Loss: 0.005493477648751957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007594881886616349\n",
      "Training Loss: 0.007832247386686505\n",
      "Training Loss: 0.007599205638980493\n",
      "Validation Loss: 0.005427319253010027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007564398210379295\n",
      "Training Loss: 0.007796719241887331\n",
      "Training Loss: 0.007558799987891689\n",
      "Validation Loss: 0.005367727765782077\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007536106067709625\n",
      "Training Loss: 0.007763779248343781\n",
      "Training Loss: 0.0075213524920400236\n",
      "Validation Loss: 0.005313616064167843\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007509267526329495\n",
      "Training Loss: 0.007732685869559646\n",
      "Training Loss: 0.00748608198016882\n",
      "Validation Loss: 0.005263968474189803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007483352357521653\n",
      "Training Loss: 0.007702858507400379\n",
      "Training Loss: 0.007452339010778814\n",
      "Validation Loss: 0.0052178577386533444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0074579724966315555\n",
      "Training Loss: 0.007673838241025806\n",
      "Training Loss: 0.0074195672746282075\n",
      "Validation Loss: 0.005174417451568199\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007432811921462417\n",
      "Training Loss: 0.0076452295738272365\n",
      "Training Loss: 0.007387231324100867\n",
      "Validation Loss: 0.0051327402588356745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007407533656805754\n",
      "Training Loss: 0.007616625892696902\n",
      "Training Loss: 0.007354720528237522\n",
      "Validation Loss: 0.0050917038003380375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007381665728171356\n",
      "Training Loss: 0.00758749830420129\n",
      "Training Loss: 0.007321171227376908\n",
      "Validation Loss: 0.005049598120738951\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007354395294096321\n",
      "Training Loss: 0.007556949864374473\n",
      "Training Loss: 0.007285149294184521\n",
      "Validation Loss: 0.00500349756304091\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007324195305118337\n",
      "Training Loss: 0.007523127846652642\n",
      "Training Loss: 0.007244146068114787\n",
      "Validation Loss: 0.004948550514782664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007288314495235681\n",
      "Training Loss: 0.007482153826858848\n",
      "Training Loss: 0.007194460574537515\n",
      "Validation Loss: 0.004878943347832544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007243245709105395\n",
      "Training Loss: 0.007430866190697998\n",
      "Training Loss: 0.0071337759774178265\n",
      "Validation Loss: 0.0047999397763888235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007191837774589658\n",
      "Training Loss: 0.007378135808976367\n",
      "Training Loss: 0.00707192532136105\n",
      "Validation Loss: 0.004736183058167023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007147104414761998\n",
      "Training Loss: 0.007335472928825765\n",
      "Training Loss: 0.007021341151557863\n",
      "Validation Loss: 0.004692591011937541\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007110969146015123\n",
      "Training Loss: 0.007301298986421898\n",
      "Training Loss: 0.0069812910561449825\n",
      "Validation Loss: 0.004660778367640764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007080213658045977\n",
      "Training Loss: 0.007272089074831456\n",
      "Training Loss: 0.006948170770192519\n",
      "Validation Loss: 0.00463523061650418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007053224394330755\n",
      "Training Loss: 0.007246219732332975\n",
      "Training Loss: 0.00691964041790925\n",
      "Validation Loss: 0.004613310362871611\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007029066826798953\n",
      "Training Loss: 0.007222819125745445\n",
      "Training Loss: 0.006894319033017382\n",
      "Validation Loss: 0.00459367510459773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007007059092866257\n",
      "Training Loss: 0.007201299781445414\n",
      "Training Loss: 0.006871354355243966\n",
      "Validation Loss: 0.004575580113248251\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006986708727199584\n",
      "Training Loss: 0.007181246972177178\n",
      "Training Loss: 0.006850190877448767\n",
      "Validation Loss: 0.004558591009902485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.0069676603830885146\n",
      "Training Loss: 0.007162361518712714\n",
      "Training Loss: 0.00683044611592777\n",
      "Validation Loss: 0.0045424425370175015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006949661248363555\n",
      "Training Loss: 0.007144426023587585\n",
      "Training Loss: 0.006811847713543102\n",
      "Validation Loss: 0.0045269671029651935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.006932525176089257\n",
      "Training Loss: 0.007127277079271153\n",
      "Training Loss: 0.006794193763053045\n",
      "Validation Loss: 0.004512056703757746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006916110430611297\n",
      "Training Loss: 0.007110791244776919\n",
      "Training Loss: 0.006777330634649843\n",
      "Validation Loss: 0.004497635890494279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.006900310734054073\n",
      "Training Loss: 0.007094872565940023\n",
      "Training Loss: 0.006761135077103972\n",
      "Validation Loss: 0.0044836457151647535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0068850390223087745\n",
      "Training Loss: 0.007079441871028393\n",
      "Training Loss: 0.006745509032625705\n",
      "Validation Loss: 0.004470047316634295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006870224521844648\n",
      "Training Loss: 0.007064434719504789\n",
      "Training Loss: 0.006730370265431702\n",
      "Validation Loss: 0.004456804339967543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006855807403335348\n",
      "Training Loss: 0.007049794823396951\n",
      "Training Loss: 0.006715647464152426\n",
      "Validation Loss: 0.004443885857930009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006841735728667118\n",
      "Training Loss: 0.007035474968142807\n",
      "Training Loss: 0.006701280450215563\n",
      "Validation Loss: 0.004431264416126304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0068279645853908735\n",
      "Training Loss: 0.007021430808817968\n",
      "Training Loss: 0.006687213546829298\n",
      "Validation Loss: 0.004418908755080461\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006814450510428287\n",
      "Training Loss: 0.007007623738609255\n",
      "Training Loss: 0.006673399937571958\n",
      "Validation Loss: 0.004406797046919636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.006801156490691938\n",
      "Training Loss: 0.006994015510426835\n",
      "Training Loss: 0.00665979377750773\n",
      "Validation Loss: 0.004394897766636287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0067880456621060145\n",
      "Training Loss: 0.006980571118183434\n",
      "Training Loss: 0.006646352299139835\n",
      "Validation Loss: 0.00438318770834025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.0067750822333619\n",
      "Training Loss: 0.006967256817733869\n",
      "Training Loss: 0.006633038489962928\n",
      "Validation Loss: 0.00437163898009765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0067622344521805645\n",
      "Training Loss: 0.006954040402779356\n",
      "Training Loss: 0.006619814406731166\n",
      "Validation Loss: 0.004360227306043792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006749469581991434\n",
      "Training Loss: 0.006940889528486878\n",
      "Training Loss: 0.006606645486899651\n",
      "Validation Loss: 0.004348925974748484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006736755914171226\n",
      "Training Loss: 0.006927771779010073\n",
      "Training Loss: 0.00659349802066572\n",
      "Validation Loss: 0.0043377102544960265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0067240619822405276\n",
      "Training Loss: 0.006914655342698097\n",
      "Training Loss: 0.0065803383861202745\n",
      "Validation Loss: 0.004326552624835141\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006711356943706051\n",
      "Training Loss: 0.006901509582530707\n",
      "Training Loss: 0.006567135683144443\n",
      "Validation Loss: 0.004315424803382812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006698609188315458\n",
      "Training Loss: 0.0068883011082652955\n",
      "Training Loss: 0.006553858380648307\n",
      "Validation Loss: 0.004304301805972132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006685788857284933\n",
      "Training Loss: 0.006874998050043359\n",
      "Training Loss: 0.006540477686794475\n",
      "Validation Loss: 0.004293157591542041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006672863630228676\n",
      "Training Loss: 0.006861565907020122\n",
      "Training Loss: 0.006526963747455738\n",
      "Validation Loss: 0.004281959401605797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006659801546484232\n",
      "Training Loss: 0.0068479704402852806\n",
      "Training Loss: 0.006513290408765898\n",
      "Validation Loss: 0.004270681015901226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006646569627919235\n",
      "Training Loss: 0.006834176484262571\n",
      "Training Loss: 0.006499433188582771\n",
      "Validation Loss: 0.004259288993800122\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006633135479060002\n",
      "Training Loss: 0.00682014646125026\n",
      "Training Loss: 0.006485368898138404\n",
      "Validation Loss: 0.004247751735082796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006619462450616993\n",
      "Training Loss: 0.006805842405883595\n",
      "Training Loss: 0.0064710770733654496\n",
      "Validation Loss: 0.0042360305879003465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006605514427646995\n",
      "Training Loss: 0.006791223513428122\n",
      "Training Loss: 0.0064565383613808085\n",
      "Validation Loss: 0.004224088131266991\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006591254852246493\n",
      "Training Loss: 0.006776249528629705\n",
      "Training Loss: 0.006441736185806803\n",
      "Validation Loss: 0.004211884806209945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006576643506996334\n",
      "Training Loss: 0.006760878070490434\n",
      "Training Loss: 0.006426652343943715\n",
      "Validation Loss: 0.0041993821073804845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.00656164267740678\n",
      "Training Loss: 0.006745066333096474\n",
      "Training Loss: 0.00641126814938616\n",
      "Validation Loss: 0.004186532028500786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0065462131949607285\n",
      "Training Loss: 0.006728772183414548\n",
      "Training Loss: 0.00639556571491994\n",
      "Validation Loss: 0.004173296301630901\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.00653031888534315\n",
      "Training Loss: 0.006711957397637889\n",
      "Training Loss: 0.006379523399518802\n",
      "Validation Loss: 0.004159630503861255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006513926691259258\n",
      "Training Loss: 0.006694583072094247\n",
      "Training Loss: 0.006363121484755538\n",
      "Validation Loss: 0.004145489206401568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006497006932040677\n",
      "Training Loss: 0.00667661695741117\n",
      "Training Loss: 0.006346343086916022\n",
      "Validation Loss: 0.004130838143252088\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006479537503910251\n",
      "Training Loss: 0.006658033567946404\n",
      "Training Loss: 0.00632917523093056\n",
      "Validation Loss: 0.004115645443429396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006461503494647331\n",
      "Training Loss: 0.006638813973404467\n",
      "Training Loss: 0.006311610010452568\n",
      "Validation Loss: 0.004099880892579349\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0064428992051398385\n",
      "Training Loss: 0.006618950837291777\n",
      "Training Loss: 0.006293644378311001\n",
      "Validation Loss: 0.0040835233201178605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00642372986418195\n",
      "Training Loss: 0.006598442643880844\n",
      "Training Loss: 0.0062752835248829795\n",
      "Validation Loss: 0.00406656353642871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006404008491663262\n",
      "Training Loss: 0.006577306374674663\n",
      "Training Loss: 0.006256538250599988\n",
      "Validation Loss: 0.004049001446025174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006383760722819716\n",
      "Training Loss: 0.006555564262671396\n",
      "Training Loss: 0.006237422444391996\n",
      "Validation Loss: 0.004030840061971227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006363018793053925\n",
      "Training Loss: 0.0065332505339756606\n",
      "Training Loss: 0.006217953575542196\n",
      "Validation Loss: 0.004012100336408724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006341824100236409\n",
      "Training Loss: 0.006510409188922495\n",
      "Training Loss: 0.006198149682604708\n",
      "Validation Loss: 0.003992809803523333\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006320223443908617\n",
      "Training Loss: 0.006487086212728172\n",
      "Training Loss: 0.006178027568967082\n",
      "Validation Loss: 0.003973000030833809\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.0062982665095478296\n",
      "Training Loss: 0.006463334473082795\n",
      "Training Loss: 0.006157605573534965\n",
      "Validation Loss: 0.0039527094707133646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006276004711980932\n",
      "Training Loss: 0.00643920949078165\n",
      "Training Loss: 0.0061369061120785775\n",
      "Validation Loss: 0.0039319832347532255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006253494105185382\n",
      "Training Loss: 0.006414768478134647\n",
      "Training Loss: 0.006115956085268408\n",
      "Validation Loss: 0.0039108701369442635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006230792689020746\n",
      "Training Loss: 0.006390072947833687\n",
      "Training Loss: 0.006094783768057823\n",
      "Validation Loss: 0.0038894225641813002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006207957148435525\n",
      "Training Loss: 0.006365185261238367\n",
      "Training Loss: 0.0060734311427222566\n",
      "Validation Loss: 0.0038677035756356846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006185048108454794\n",
      "Training Loss: 0.006340171764604747\n",
      "Training Loss: 0.006051941681071185\n",
      "Validation Loss: 0.00384577909181041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006162127584102564\n",
      "Training Loss: 0.006315103881061077\n",
      "Training Loss: 0.0060303676419425755\n",
      "Validation Loss: 0.0038237120528454276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006139257713221014\n",
      "Training Loss: 0.0062900530849583445\n",
      "Training Loss: 0.0060087653726805\n",
      "Validation Loss: 0.0038015725289921413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006116498032934032\n",
      "Training Loss: 0.00626509127439931\n",
      "Training Loss: 0.005987193324835971\n",
      "Validation Loss: 0.0037794341307049724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006093909639166668\n",
      "Training Loss: 0.00624029318569228\n",
      "Training Loss: 0.005965710990130902\n",
      "Validation Loss: 0.0037573656293542618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006071548648178577\n",
      "Training Loss: 0.0062157283152919265\n",
      "Training Loss: 0.005944375636754557\n",
      "Validation Loss: 0.003735433834254365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006049465453834273\n",
      "Training Loss: 0.006191464563598857\n",
      "Training Loss: 0.005923238875111565\n",
      "Validation Loss: 0.0037136987025661165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006027704873704351\n",
      "Training Loss: 0.006167563049821183\n",
      "Training Loss: 0.005902349504176527\n",
      "Validation Loss: 0.0036922182169680097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.0060063087561866265\n",
      "Training Loss: 0.006144078888464719\n",
      "Training Loss: 0.005881749816471711\n",
      "Validation Loss: 0.0036710441737760153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.0059853069961536675\n",
      "Training Loss: 0.006121060490841046\n",
      "Training Loss: 0.005861473527620547\n",
      "Validation Loss: 0.003650214285014218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.005964726509409957\n",
      "Training Loss: 0.006098546782741323\n",
      "Training Loss: 0.005841550278128125\n",
      "Validation Loss: 0.0036297639553288645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005944588136626408\n",
      "Training Loss: 0.006076571168377996\n",
      "Training Loss: 0.005822002868517302\n",
      "Validation Loss: 0.003609720606414413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.005924904271960258\n",
      "Training Loss: 0.006055158791132271\n",
      "Training Loss: 0.005802847267477773\n",
      "Validation Loss: 0.0035901036390804508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005905684195458889\n",
      "Training Loss: 0.006034328731475398\n",
      "Training Loss: 0.005784096777788363\n",
      "Validation Loss: 0.0035709283776382468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.005886931702843867\n",
      "Training Loss: 0.006014093427802436\n",
      "Training Loss: 0.005765759034547954\n",
      "Validation Loss: 0.003552199706299168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005868647350580431\n",
      "Training Loss: 0.005994459287030622\n",
      "Training Loss: 0.005747835160582327\n",
      "Validation Loss: 0.003533919894507971\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005850826172973029\n",
      "Training Loss: 0.005975427280063741\n",
      "Training Loss: 0.005730327304336242\n",
      "Validation Loss: 0.0035160924713493564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005833465494797565\n",
      "Training Loss: 0.0059569976286729795\n",
      "Training Loss: 0.005713235478033311\n",
      "Validation Loss: 0.0034987113747243464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.0058165567624382675\n",
      "Training Loss: 0.005939160953857936\n",
      "Training Loss: 0.005696552963927388\n",
      "Validation Loss: 0.0034817705758889155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005800090790726245\n",
      "Training Loss: 0.005921911412733607\n",
      "Training Loss: 0.005680276946513914\n",
      "Validation Loss: 0.0034652590598607583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0057840574614238\n",
      "Training Loss: 0.005905235352693126\n",
      "Training Loss: 0.005664399473462253\n",
      "Validation Loss: 0.003449170825364633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005768447183654644\n",
      "Training Loss: 0.005889122380758636\n",
      "Training Loss: 0.005648912010947242\n",
      "Validation Loss: 0.003433494877038796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005753247709362768\n",
      "Training Loss: 0.0058735561429057274\n",
      "Training Loss: 0.005633807489066385\n",
      "Validation Loss: 0.0034182173411853693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.005738447080657352\n",
      "Training Loss: 0.0058585215639322995\n",
      "Training Loss: 0.005619076209259219\n",
      "Validation Loss: 0.003403330275401724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.005724037521868013\n",
      "Training Loss: 0.005843999568023719\n",
      "Training Loss: 0.005604710523621179\n",
      "Validation Loss: 0.003388820136269408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.00571000282507157\n",
      "Training Loss: 0.0058299749169964344\n",
      "Training Loss: 0.00559069934533909\n",
      "Validation Loss: 0.0033746778682460276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.005696333661035169\n",
      "Training Loss: 0.005816431505954824\n",
      "Training Loss: 0.005577036087634042\n",
      "Validation Loss: 0.0033608900740863023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.005683021798613481\n",
      "Training Loss: 0.005803352290531621\n",
      "Training Loss: 0.0055637087486684325\n",
      "Validation Loss: 0.003347445489299808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005670052799105179\n",
      "Training Loss: 0.0057907211891142655\n",
      "Training Loss: 0.005550710695679299\n",
      "Validation Loss: 0.0033343352215218073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.005657419534109067\n",
      "Training Loss: 0.005778518895385787\n",
      "Training Loss: 0.005538029775489122\n",
      "Validation Loss: 0.003321546074290749\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005645108813187107\n",
      "Training Loss: 0.005766732483753003\n",
      "Training Loss: 0.005525660380953923\n",
      "Validation Loss: 0.003309070114033255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005633114095544443\n",
      "Training Loss: 0.005755345238139853\n",
      "Training Loss: 0.005513591577764601\n",
      "Validation Loss: 0.003296897717845741\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005621425465797074\n",
      "Training Loss: 0.005744342663674616\n",
      "Training Loss: 0.0055018157901940866\n",
      "Validation Loss: 0.003285015987172158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0056100325426086785\n",
      "Training Loss: 0.005733709469786845\n",
      "Training Loss: 0.005490323108388111\n",
      "Validation Loss: 0.0032734148596083807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005598927857354283\n",
      "Training Loss: 0.005723432770464569\n",
      "Training Loss: 0.005479106932762079\n",
      "Validation Loss: 0.003262087815896388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005588101591856684\n",
      "Training Loss: 0.005713498777477071\n",
      "Training Loss: 0.005468159090378321\n",
      "Validation Loss: 0.003251022606593651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0055775466957129535\n",
      "Training Loss: 0.005703894814942032\n",
      "Training Loss: 0.00545746882155072\n",
      "Validation Loss: 0.0032402132202876376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.005567254385096021\n",
      "Training Loss: 0.005694608655758202\n",
      "Training Loss: 0.005447030217037536\n",
      "Validation Loss: 0.0032296460223242935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0055572161698364654\n",
      "Training Loss: 0.005685627434286289\n",
      "Training Loss: 0.005436837408924475\n",
      "Validation Loss: 0.003219316888788945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005547425718687009\n",
      "Training Loss: 0.005676940564881079\n",
      "Training Loss: 0.0054268805147148665\n",
      "Validation Loss: 0.0032092190028450798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005537875761801842\n",
      "Training Loss: 0.0056685369514161725\n",
      "Training Loss: 0.005417155081522651\n",
      "Validation Loss: 0.0031993406533075267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005528557062498294\n",
      "Training Loss: 0.005660406168899499\n",
      "Training Loss: 0.005407651202986017\n",
      "Validation Loss: 0.0031896798925087106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005519463814562186\n",
      "Training Loss: 0.005652537778369151\n",
      "Training Loss: 0.005398362242267467\n",
      "Validation Loss: 0.0031802267031717964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00551059032935882\n",
      "Training Loss: 0.005644923978252336\n",
      "Training Loss: 0.005389283619588241\n",
      "Validation Loss: 0.003170971748526365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005501925512799061\n",
      "Training Loss: 0.005637551874388009\n",
      "Training Loss: 0.00538040458864998\n",
      "Validation Loss: 0.0031619093287997783\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.005493467066553421\n",
      "Training Loss: 0.0056304144579917195\n",
      "Training Loss: 0.00537172248295974\n",
      "Validation Loss: 0.0031530329407574715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005485205043514725\n",
      "Training Loss: 0.005623502499656752\n",
      "Training Loss: 0.005363228899659589\n",
      "Validation Loss: 0.003144341383294171\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005477134484099224\n",
      "Training Loss: 0.005616806733887643\n",
      "Training Loss: 0.005354919332894496\n",
      "Validation Loss: 0.003135824411207538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.00546924952941481\n",
      "Training Loss: 0.005610317955142818\n",
      "Training Loss: 0.005346786470036022\n",
      "Validation Loss: 0.003127475230224703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005461542484699749\n",
      "Training Loss: 0.0056040320609463375\n",
      "Training Loss: 0.005338823141064495\n",
      "Validation Loss: 0.003119289747823888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0054540079965954644\n",
      "Training Loss: 0.005597938284045085\n",
      "Training Loss: 0.005331025742343627\n",
      "Validation Loss: 0.0031112623531789926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.0054466400167439135\n",
      "Training Loss: 0.005592030223924667\n",
      "Training Loss: 0.005323387694079429\n",
      "Validation Loss: 0.0031033879236888476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0054394313757075\n",
      "Training Loss: 0.005586299730930477\n",
      "Training Loss: 0.005315902912407182\n",
      "Validation Loss: 0.0030956607321120295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005432378392433748\n",
      "Training Loss: 0.005580738365533761\n",
      "Training Loss: 0.005308567835600115\n",
      "Validation Loss: 0.003088078366754723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005425473816285375\n",
      "Training Loss: 0.005575341359362937\n",
      "Training Loss: 0.005301374639966525\n",
      "Validation Loss: 0.00308063197482032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005418713313993066\n",
      "Training Loss: 0.00557010134391021\n",
      "Training Loss: 0.005294320614775643\n",
      "Validation Loss: 0.0030733157499311385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005412090489408002\n",
      "Training Loss: 0.005565010475693271\n",
      "Training Loss: 0.005287399290245957\n",
      "Validation Loss: 0.003066128488365833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.005405600988597143\n",
      "Training Loss: 0.005560063813463785\n",
      "Training Loss: 0.005280608265311457\n",
      "Validation Loss: 0.0030590660194473947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005399240750120953\n",
      "Training Loss: 0.005555253115599044\n",
      "Training Loss: 0.005273941329214722\n",
      "Validation Loss: 0.003052122072771903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005393004241341259\n",
      "Training Loss: 0.0055505746818380435\n",
      "Training Loss: 0.005267395415576175\n",
      "Validation Loss: 0.0030452923766164674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005386887201166246\n",
      "Training Loss: 0.005546019455068745\n",
      "Training Loss: 0.005260964686167427\n",
      "Validation Loss: 0.0030385709277437893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.0053808880079304795\n",
      "Training Loss: 0.005541581627912819\n",
      "Training Loss: 0.0052546483610058205\n",
      "Validation Loss: 0.003031954525386538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005375000720960088\n",
      "Training Loss: 0.005537255812087096\n",
      "Training Loss: 0.005248438915004954\n",
      "Validation Loss: 0.0030254406414355747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005369221004948486\n",
      "Training Loss: 0.005533037350396626\n",
      "Training Loss: 0.0052423355099745095\n",
      "Validation Loss: 0.0030190232955442553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005363548601744697\n",
      "Training Loss: 0.005528918920317665\n",
      "Training Loss: 0.0052363344625337045\n",
      "Validation Loss: 0.0030126986836130324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.0053579804554465225\n",
      "Training Loss: 0.005524895093985833\n",
      "Training Loss: 0.005230433564865962\n",
      "Validation Loss: 0.0030064620859162317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005352512722020038\n",
      "Training Loss: 0.005520960736903362\n",
      "Training Loss: 0.0052246279147220775\n",
      "Validation Loss: 0.003000309434130767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005347145086561795\n",
      "Training Loss: 0.005517111186054535\n",
      "Training Loss: 0.005218915808363818\n",
      "Validation Loss: 0.0029942380595334877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005341877690516412\n",
      "Training Loss: 0.00551333868468646\n",
      "Training Loss: 0.00521329563925974\n",
      "Validation Loss: 0.002988243882028972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0053367066610371695\n",
      "Training Loss: 0.0055096411268459634\n",
      "Training Loss: 0.0052077631832798945\n",
      "Validation Loss: 0.0029823212849049503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005331632556044496\n",
      "Training Loss: 0.005506013666745275\n",
      "Training Loss: 0.005202314865891821\n",
      "Validation Loss: 0.002976470862664387\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005326654179953039\n",
      "Training Loss: 0.005502449975465424\n",
      "Training Loss: 0.005196950362878852\n",
      "Validation Loss: 0.0029706844731019495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005321769773145206\n",
      "Training Loss: 0.005498948523891159\n",
      "Training Loss: 0.0051916657900437715\n",
      "Validation Loss: 0.0029649609043210577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005316981429350562\n",
      "Training Loss: 0.005495504037244245\n",
      "Training Loss: 0.005186459055403247\n",
      "Validation Loss: 0.002959299073920826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005312290355213918\n",
      "Training Loss: 0.005492113390355371\n",
      "Training Loss: 0.005181328460457735\n",
      "Validation Loss: 0.0029536982739260527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005307692475325893\n",
      "Training Loss: 0.005488772576209158\n",
      "Training Loss: 0.005176269947551191\n",
      "Validation Loss: 0.0029481474187204176\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005303188933758065\n",
      "Training Loss: 0.005485481259529479\n",
      "Training Loss: 0.005171280605136417\n",
      "Validation Loss: 0.0029426526613114926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.0052987783376011064\n",
      "Training Loss: 0.005482235961826518\n",
      "Training Loss: 0.005166358874412254\n",
      "Validation Loss: 0.0029372105975321422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005294462172023486\n",
      "Training Loss: 0.0054790336871519685\n",
      "Training Loss: 0.005161502560949885\n",
      "Validation Loss: 0.0029318223392140914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.00529023746115854\n",
      "Training Loss: 0.0054758736479561775\n",
      "Training Loss: 0.005156710873125121\n",
      "Validation Loss: 0.0029264868775335548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005286103466060013\n",
      "Training Loss: 0.005472755539813079\n",
      "Training Loss: 0.005151977386558429\n",
      "Validation Loss: 0.002921198762553022\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005282057955337222\n",
      "Training Loss: 0.005469675808562897\n",
      "Training Loss: 0.00514730281138327\n",
      "Validation Loss: 0.002915962306217531\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005278099593706429\n",
      "Training Loss: 0.0054666351235937325\n",
      "Training Loss: 0.005142684638849459\n",
      "Validation Loss: 0.0029107768152673006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005274226978071965\n",
      "Training Loss: 0.005463629520381801\n",
      "Training Loss: 0.0051381215517176315\n",
      "Validation Loss: 0.002905642584337738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.0052704392079613175\n",
      "Training Loss: 0.0054606618901016195\n",
      "Training Loss: 0.00513361073913984\n",
      "Validation Loss: 0.0029005567619074762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005266732143936679\n",
      "Training Loss: 0.005457730860216543\n",
      "Training Loss: 0.005129152400768362\n",
      "Validation Loss: 0.002895524765867112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005263101808959618\n",
      "Training Loss: 0.005454834500560537\n",
      "Training Loss: 0.005124743256019428\n",
      "Validation Loss: 0.0028905420017355447\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005259549435868394\n",
      "Training Loss: 0.005451971503789537\n",
      "Training Loss: 0.005120382790337317\n",
      "Validation Loss: 0.0028856134505189034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005256072444026359\n",
      "Training Loss: 0.005449143330333754\n",
      "Training Loss: 0.0051160695945145565\n",
      "Validation Loss: 0.0028807340864107807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005252666122396476\n",
      "Training Loss: 0.005446348923142068\n",
      "Training Loss: 0.0051118038210552184\n",
      "Validation Loss: 0.002875911497989711\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005249331193626858\n",
      "Training Loss: 0.005443587130866945\n",
      "Training Loss: 0.005107582165510394\n",
      "Validation Loss: 0.002871135842601842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005246063235099427\n",
      "Training Loss: 0.005440857638604939\n",
      "Training Loss: 0.005103404967230745\n",
      "Validation Loss: 0.0028664149707601813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005242860969738103\n",
      "Training Loss: 0.005438160191988573\n",
      "Training Loss: 0.005099271833896637\n",
      "Validation Loss: 0.002861742589170155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.00523972281429451\n",
      "Training Loss: 0.005435493353870697\n",
      "Training Loss: 0.005095182085642591\n",
      "Validation Loss: 0.002857122315863001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.00523664631677093\n",
      "Training Loss: 0.005432858291896991\n",
      "Training Loss: 0.005091134035610594\n",
      "Validation Loss: 0.002852556248603577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0052336299701710234\n",
      "Training Loss: 0.005430253912345506\n",
      "Training Loss: 0.0050871287297923114\n",
      "Validation Loss: 0.0028480376114315364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005230670879536774\n",
      "Training Loss: 0.005427678499836474\n",
      "Training Loss: 0.005083162970258855\n",
      "Validation Loss: 0.0028435688170217227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.0052277683245483784\n",
      "Training Loss: 0.005425132933887653\n",
      "Training Loss: 0.005079237604513764\n",
      "Validation Loss: 0.0028391506616418575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005224921495828312\n",
      "Training Loss: 0.005422614919953048\n",
      "Training Loss: 0.005075351542327553\n",
      "Validation Loss: 0.0028347771198180076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.0052221275289775805\n",
      "Training Loss: 0.005420124225202017\n",
      "Training Loss: 0.005071505027008243\n",
      "Validation Loss: 0.002830453708851605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005219385619857349\n",
      "Training Loss: 0.0054176622623344885\n",
      "Training Loss: 0.005067696484620683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [20:53<13:57, 209.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0028261761687920963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5154098466038703\n",
      "Training Loss: 0.43363903686404226\n",
      "Training Loss: 0.339044976234436\n",
      "Validation Loss: 0.22689524937546654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.17792908664792775\n",
      "Training Loss: 0.11706793025135993\n",
      "Training Loss: 0.08654069794341922\n",
      "Validation Loss: 0.07410323287077834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06984960000962019\n",
      "Training Loss: 0.06845189262181521\n",
      "Training Loss: 0.06792561849579215\n",
      "Validation Loss: 0.06827476526495446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.06597111359238625\n",
      "Training Loss: 0.06530306283384561\n",
      "Training Loss: 0.06477711260318757\n",
      "Validation Loss: 0.06486397253328495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.06260083610191941\n",
      "Training Loss: 0.061646605283021925\n",
      "Training Loss: 0.06075003007426858\n",
      "Validation Loss: 0.06013152110024115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.057832889202982185\n",
      "Training Loss: 0.05625835865736008\n",
      "Training Loss: 0.054558066353201866\n",
      "Validation Loss: 0.052593696381101444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.05026195179671049\n",
      "Training Loss: 0.04781401728279889\n",
      "Training Loss: 0.04507010381668806\n",
      "Validation Loss: 0.04172356919584314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.03958411984145641\n",
      "Training Loss: 0.03683715973049402\n",
      "Training Loss: 0.033709893152117726\n",
      "Validation Loss: 0.030145629895118514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.028625648859888317\n",
      "Training Loss: 0.026856448454782366\n",
      "Training Loss: 0.024554487611167134\n",
      "Validation Loss: 0.021963570162319066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.021260071508586408\n",
      "Training Loss: 0.020771247316151858\n",
      "Training Loss: 0.019433531421236695\n",
      "Validation Loss: 0.017530577950535364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.017429056821856647\n",
      "Training Loss: 0.017580395622644573\n",
      "Training Loss: 0.01676851647440344\n",
      "Validation Loss: 0.015094433278054669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.015405050208792091\n",
      "Training Loss: 0.015805095734540375\n",
      "Training Loss: 0.015250173164531589\n",
      "Validation Loss: 0.01361958693262985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.014224063626024873\n",
      "Training Loss: 0.014715828644111752\n",
      "Training Loss: 0.014287365132477135\n",
      "Validation Loss: 0.01263589903272772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.013460115047637373\n",
      "Training Loss: 0.01398519509471953\n",
      "Training Loss: 0.013623250930104405\n",
      "Validation Loss: 0.011927389309563663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.012924782834015786\n",
      "Training Loss: 0.01346134758554399\n",
      "Training Loss: 0.013137700541410596\n",
      "Validation Loss: 0.011386220623330955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.012527637495659293\n",
      "Training Loss: 0.013066273727454246\n",
      "Training Loss: 0.012765268326038495\n",
      "Validation Loss: 0.01094912777633898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.012214873635675758\n",
      "Training Loss: 0.012746119803050533\n",
      "Training Loss: 0.012451220070943236\n",
      "Validation Loss: 0.010552315046654994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.011924904021434486\n",
      "Training Loss: 0.012424156359629705\n",
      "Training Loss: 0.01210775154759176\n",
      "Validation Loss: 0.010087689306335837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.011563041831832379\n",
      "Training Loss: 0.012002303896006197\n",
      "Training Loss: 0.011648905547335744\n",
      "Validation Loss: 0.00947114297978873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.01107272579567507\n",
      "Training Loss: 0.011434780929703266\n",
      "Training Loss: 0.011043242570012808\n",
      "Validation Loss: 0.008687136560061088\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.010447716804919764\n",
      "Training Loss: 0.010728121072752402\n",
      "Training Loss: 0.010325491017429158\n",
      "Validation Loss: 0.007824731713391087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.009775432064197958\n",
      "Training Loss: 0.010009229951538145\n",
      "Training Loss: 0.009657792203361168\n",
      "Validation Loss: 0.007103445365491292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.009235728200292215\n",
      "Training Loss: 0.009459817241877317\n",
      "Training Loss: 0.00918369801598601\n",
      "Validation Loss: 0.006630056291776761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008882910364773124\n",
      "Training Loss: 0.009095222677569837\n",
      "Training Loss: 0.008869391229236499\n",
      "Validation Loss: 0.006322779088396202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008642133526736871\n",
      "Training Loss: 0.008838495545787736\n",
      "Training Loss: 0.008640377280535176\n",
      "Validation Loss: 0.006100786355418268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008457946616690606\n",
      "Training Loss: 0.00864107052097097\n",
      "Training Loss: 0.008457502697128803\n",
      "Validation Loss: 0.005927108899229781\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008306964057264849\n",
      "Training Loss: 0.008481245745206251\n",
      "Training Loss: 0.008304057642817497\n",
      "Validation Loss: 0.005785763934725539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008179121552966535\n",
      "Training Loss: 0.008348714873427525\n",
      "Training Loss: 0.008172541953390464\n",
      "Validation Loss: 0.005668816555636736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.008069412390468642\n",
      "Training Loss: 0.008237727319356054\n",
      "Training Loss: 0.008059024289250373\n",
      "Validation Loss: 0.0055715282162483995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007974873480852693\n",
      "Training Loss: 0.00814446244505234\n",
      "Training Loss: 0.007960943219950422\n",
      "Validation Loss: 0.005490510992632572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00789339316310361\n",
      "Training Loss: 0.008065989220049231\n",
      "Training Loss: 0.007876259641489015\n",
      "Validation Loss: 0.005423017136564248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007823226401815191\n",
      "Training Loss: 0.007999867131002248\n",
      "Training Loss: 0.007803163867210969\n",
      "Validation Loss: 0.005366691118734104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007762824337696657\n",
      "Training Loss: 0.00794399799196981\n",
      "Training Loss: 0.007739991251146421\n",
      "Validation Loss: 0.0053194759170305025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007710772539139725\n",
      "Training Loss: 0.00789657189976424\n",
      "Training Loss: 0.007685223474400118\n",
      "Validation Loss: 0.005279608299756904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0076657919067656625\n",
      "Training Loss: 0.007856048545800149\n",
      "Training Loss: 0.007637502256548032\n",
      "Validation Loss: 0.005245603378365088\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007626743391156197\n",
      "Training Loss: 0.007821131565142423\n",
      "Training Loss: 0.00759564102627337\n",
      "Validation Loss: 0.0052162285049163395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007592633271706291\n",
      "Training Loss: 0.00779074864462018\n",
      "Training Loss: 0.007558620877098292\n",
      "Validation Loss: 0.005190487960850548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007562604770064354\n",
      "Training Loss: 0.007764018605230376\n",
      "Training Loss: 0.0075255818932782855\n",
      "Validation Loss: 0.005167581982063025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007535931672900915\n",
      "Training Loss: 0.007740223498549312\n",
      "Training Loss: 0.0074958071357104925\n",
      "Validation Loss: 0.005146879979456367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007512007424957119\n",
      "Training Loss: 0.007718784902244806\n",
      "Training Loss: 0.007468704780330881\n",
      "Validation Loss: 0.005127885519511203\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007490330782602541\n",
      "Training Loss: 0.007699237077031284\n",
      "Training Loss: 0.007443785567302257\n",
      "Validation Loss: 0.005110213608910026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0074704844946973025\n",
      "Training Loss: 0.007681206004926935\n",
      "Training Loss: 0.007420653343433514\n",
      "Validation Loss: 0.0050935714899332084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007452132758917287\n",
      "Training Loss: 0.007664396675536409\n",
      "Training Loss: 0.007398987088818103\n",
      "Validation Loss: 0.005077729535320502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00743500332115218\n",
      "Training Loss: 0.007648571578320116\n",
      "Training Loss: 0.0073785264499019836\n",
      "Validation Loss: 0.0050625133784644805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007418874786235392\n",
      "Training Loss: 0.00763354726950638\n",
      "Training Loss: 0.00735906423185952\n",
      "Validation Loss: 0.00504779910048721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007403569402522407\n",
      "Training Loss: 0.007619176473235711\n",
      "Training Loss: 0.00734043212258257\n",
      "Validation Loss: 0.005033487198335443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007388947547296993\n",
      "Training Loss: 0.007605347876669839\n",
      "Training Loss: 0.00732249999884516\n",
      "Validation Loss: 0.005019506609611465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007374896265100688\n",
      "Training Loss: 0.007591971949441358\n",
      "Training Loss: 0.0073051624721847475\n",
      "Validation Loss: 0.005005803388239962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007361327161779627\n",
      "Training Loss: 0.007578981375554576\n",
      "Training Loss: 0.007288338273065164\n",
      "Validation Loss: 0.004992343852913865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.0073481705505400894\n",
      "Training Loss: 0.007566325605148449\n",
      "Training Loss: 0.007271963951643557\n",
      "Validation Loss: 0.004979098511969649\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007335371512454003\n",
      "Training Loss: 0.007553964535472915\n",
      "Training Loss: 0.007255992258433252\n",
      "Validation Loss: 0.004966047893309694\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007322885914472863\n",
      "Training Loss: 0.0075418699812144045\n",
      "Training Loss: 0.007240384513279423\n",
      "Validation Loss: 0.004953178730165439\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007310680897790007\n",
      "Training Loss: 0.0075300191855058075\n",
      "Training Loss: 0.007225111265433952\n",
      "Validation Loss: 0.004940482123958973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007298727597226389\n",
      "Training Loss: 0.007518394811777398\n",
      "Training Loss: 0.007210153497289866\n",
      "Validation Loss: 0.004927951156480886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0072870028164470566\n",
      "Training Loss: 0.007506984560750425\n",
      "Training Loss: 0.007195488979341462\n",
      "Validation Loss: 0.00491557953345558\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007275484066340141\n",
      "Training Loss: 0.007495774257695303\n",
      "Training Loss: 0.007181101411115378\n",
      "Validation Loss: 0.004903362067861043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0072641493717674165\n",
      "Training Loss: 0.007484749937430024\n",
      "Training Loss: 0.007166970003163442\n",
      "Validation Loss: 0.004891287352957794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007252970457775518\n",
      "Training Loss: 0.007473890316905454\n",
      "Training Loss: 0.0071530660544522106\n",
      "Validation Loss: 0.004879342764223601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007241908418363891\n",
      "Training Loss: 0.007463161997729912\n",
      "Training Loss: 0.007139345942996442\n",
      "Validation Loss: 0.004867497342377064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007230893810046836\n",
      "Training Loss: 0.007452503474196419\n",
      "Training Loss: 0.007125750238774344\n",
      "Validation Loss: 0.004855705324424368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0072198283392935995\n",
      "Training Loss: 0.0074418229435104875\n",
      "Training Loss: 0.007112288132775575\n",
      "Validation Loss: 0.004843959569135744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007208689056569711\n",
      "Training Loss: 0.0074311483185738325\n",
      "Training Loss: 0.007099354051752016\n",
      "Validation Loss: 0.00483241754393041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007197776832035743\n",
      "Training Loss: 0.007420822090934962\n",
      "Training Loss: 0.007086907310876995\n",
      "Validation Loss: 0.0048213686690707636\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007187372915796004\n",
      "Training Loss: 0.007410839720396325\n",
      "Training Loss: 0.007074674140894786\n",
      "Validation Loss: 0.004810624566907586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007177315048757009\n",
      "Training Loss: 0.007401116525288671\n",
      "Training Loss: 0.007062665667617694\n",
      "Validation Loss: 0.0048000846042433815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007167505895486101\n",
      "Training Loss: 0.0073916178615763784\n",
      "Training Loss: 0.00705090681090951\n",
      "Validation Loss: 0.004789719396019668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0071579100552480665\n",
      "Training Loss: 0.007382327679079026\n",
      "Training Loss: 0.007039405931718648\n",
      "Validation Loss: 0.004779519898466389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007148507775273174\n",
      "Training Loss: 0.007373235244303941\n",
      "Training Loss: 0.007028165319934487\n",
      "Validation Loss: 0.004769486908832293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007139287767931819\n",
      "Training Loss: 0.00736433158046566\n",
      "Training Loss: 0.007017179803224281\n",
      "Validation Loss: 0.004759616168801871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007130242213024758\n",
      "Training Loss: 0.007355608474463224\n",
      "Training Loss: 0.007006443466525525\n",
      "Validation Loss: 0.004749906996233661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007121361737372354\n",
      "Training Loss: 0.007347059083404019\n",
      "Training Loss: 0.006995946711394935\n",
      "Validation Loss: 0.004740357085057859\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007112642510328442\n",
      "Training Loss: 0.007338676678482443\n",
      "Training Loss: 0.006985678457422182\n",
      "Validation Loss: 0.004730963144906577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007104077761759982\n",
      "Training Loss: 0.007330453576287255\n",
      "Training Loss: 0.0069756282353773714\n",
      "Validation Loss: 0.004721726560991341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007095663782674819\n",
      "Training Loss: 0.007322386121377349\n",
      "Training Loss: 0.006965785139473155\n",
      "Validation Loss: 0.004712642922610296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0070873983646743\n",
      "Training Loss: 0.007314467717660591\n",
      "Training Loss: 0.00695613922085613\n",
      "Validation Loss: 0.004703707382177118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007079281128826551\n",
      "Training Loss: 0.00730669786571525\n",
      "Training Loss: 0.00694668339099735\n",
      "Validation Loss: 0.004694925128021853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0070713129412615676\n",
      "Training Loss: 0.0072990714863408355\n",
      "Training Loss: 0.0069374101457651705\n",
      "Validation Loss: 0.004686295499585652\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007063495164038614\n",
      "Training Loss: 0.007291586411884055\n",
      "Training Loss: 0.006928317883284763\n",
      "Validation Loss: 0.004677819446503614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007055828226730228\n",
      "Training Loss: 0.007284236361738294\n",
      "Training Loss: 0.006919407598907128\n",
      "Validation Loss: 0.00466949973854477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007048301167669706\n",
      "Training Loss: 0.007277007788652554\n",
      "Training Loss: 0.006910676939878613\n",
      "Validation Loss: 0.004661325063148325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007040895745740272\n",
      "Training Loss: 0.007269883579574525\n",
      "Training Loss: 0.0069021275313571094\n",
      "Validation Loss: 0.00465328331769894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007033592908410356\n",
      "Training Loss: 0.007262850650586188\n",
      "Training Loss: 0.006893750743474811\n",
      "Validation Loss: 0.004645360275328661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007026380046736449\n",
      "Training Loss: 0.007255896859569475\n",
      "Training Loss: 0.006885535727487877\n",
      "Validation Loss: 0.004637550043329345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007019248622236773\n",
      "Training Loss: 0.007249014073750004\n",
      "Training Loss: 0.006877466775476932\n",
      "Validation Loss: 0.0046298459337061545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0070121902565006165\n",
      "Training Loss: 0.0072421950474381444\n",
      "Training Loss: 0.00686952834483236\n",
      "Validation Loss: 0.004622242012547769\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00700520035228692\n",
      "Training Loss: 0.007235431094886735\n",
      "Training Loss: 0.00686170639586635\n",
      "Validation Loss: 0.0046147325813895865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006998272003838793\n",
      "Training Loss: 0.0072287145466543735\n",
      "Training Loss: 0.0068539913883432745\n",
      "Validation Loss: 0.004607318121589344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00699140039854683\n",
      "Training Loss: 0.007222039805492386\n",
      "Training Loss: 0.006846369463019073\n",
      "Validation Loss: 0.004599989650854736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.0069845810875995085\n",
      "Training Loss: 0.007215400335844606\n",
      "Training Loss: 0.006838831743225455\n",
      "Validation Loss: 0.00459274367672611\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006977806204231456\n",
      "Training Loss: 0.00720878983498551\n",
      "Training Loss: 0.006831368897110224\n",
      "Validation Loss: 0.004585575898376743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006971073430031538\n",
      "Training Loss: 0.007202202198095619\n",
      "Training Loss: 0.006823970969999209\n",
      "Validation Loss: 0.004578479791970484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006964375399402343\n",
      "Training Loss: 0.007195631383219734\n",
      "Training Loss: 0.006816629414679483\n",
      "Validation Loss: 0.00457144698541444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0069577061600284654\n",
      "Training Loss: 0.007189072384499014\n",
      "Training Loss: 0.006809336524456739\n",
      "Validation Loss: 0.004564480557174453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0069510622596135364\n",
      "Training Loss: 0.0071825198596343395\n",
      "Training Loss: 0.006802084005903453\n",
      "Validation Loss: 0.004557567323542336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006944437974598258\n",
      "Training Loss: 0.0071759687620215114\n",
      "Training Loss: 0.006794864714611322\n",
      "Validation Loss: 0.004550703433656207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006937826754874549\n",
      "Training Loss: 0.007169415346579626\n",
      "Training Loss: 0.00678766977507621\n",
      "Validation Loss: 0.004543883971911803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.006931224845466204\n",
      "Training Loss: 0.007162853751797229\n",
      "Training Loss: 0.00678049411973916\n",
      "Validation Loss: 0.0045371021260507405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.0069246261526132\n",
      "Training Loss: 0.00715627918485552\n",
      "Training Loss: 0.006773327288683504\n",
      "Validation Loss: 0.004530351456605275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006918025518534705\n",
      "Training Loss: 0.007149689083453268\n",
      "Training Loss: 0.006766162957064808\n",
      "Validation Loss: 0.004523624673883399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006911417517112568\n",
      "Training Loss: 0.007143077056389302\n",
      "Training Loss: 0.0067589937534648925\n",
      "Validation Loss: 0.004516915169026536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006904795668669976\n",
      "Training Loss: 0.0071364402060862635\n",
      "Training Loss: 0.006751811696449295\n",
      "Validation Loss: 0.004510217385492131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006898155775270425\n",
      "Training Loss: 0.007129774041241035\n",
      "Training Loss: 0.0067446098523214456\n",
      "Validation Loss: 0.004503523225875132\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00689149142766837\n",
      "Training Loss: 0.007123076186981052\n",
      "Training Loss: 0.006737380151171237\n",
      "Validation Loss: 0.004496822556156372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006884799267863855\n",
      "Training Loss: 0.0071163440751843155\n",
      "Training Loss: 0.006730117077240721\n",
      "Validation Loss: 0.0044901115673311644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006878074486739934\n",
      "Training Loss: 0.0071095751249231395\n",
      "Training Loss: 0.006722814313834533\n",
      "Validation Loss: 0.004483385016131895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006871315831667744\n",
      "Training Loss: 0.007102769740158692\n",
      "Training Loss: 0.006715467019239441\n",
      "Validation Loss: 0.004476637293040501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006864521049428731\n",
      "Training Loss: 0.007095927221234888\n",
      "Training Loss: 0.006708072448382154\n",
      "Validation Loss: 0.004469866295386985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006857691647019238\n",
      "Training Loss: 0.007089050010545179\n",
      "Training Loss: 0.006700627660611644\n",
      "Validation Loss: 0.004463066503907857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006850829732138663\n",
      "Training Loss: 0.007082141079008579\n",
      "Training Loss: 0.006693133992375806\n",
      "Validation Loss: 0.004456239354828101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006843939741374924\n",
      "Training Loss: 0.0070752066595014184\n",
      "Training Loss: 0.00668559436337091\n",
      "Validation Loss: 0.004449383092761626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006837030625902117\n",
      "Training Loss: 0.00706825184635818\n",
      "Training Loss: 0.006678012962220236\n",
      "Validation Loss: 0.004442502270332339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006830110895680264\n",
      "Training Loss: 0.007061284609371796\n",
      "Training Loss: 0.0066703978751320395\n",
      "Validation Loss: 0.00443560127665948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006823194068856537\n",
      "Training Loss: 0.007054312446853146\n",
      "Training Loss: 0.00666275876457803\n",
      "Validation Loss: 0.004428686269328751\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006816292311414145\n",
      "Training Loss: 0.007047345461323858\n",
      "Training Loss: 0.006655107607366517\n",
      "Validation Loss: 0.004421766686483464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0068094216712052\n",
      "Training Loss: 0.007040391475893557\n",
      "Training Loss: 0.006647454818012193\n",
      "Validation Loss: 0.004414846142884762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006802595986519009\n",
      "Training Loss: 0.007033458383521065\n",
      "Training Loss: 0.006639811884379014\n",
      "Validation Loss: 0.004407935667903361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006795829050242901\n",
      "Training Loss: 0.0070265532995108515\n",
      "Training Loss: 0.006632190993987024\n",
      "Validation Loss: 0.004401040621222195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.00678913154755719\n",
      "Training Loss: 0.0070196804555598645\n",
      "Training Loss: 0.006624599983915687\n",
      "Validation Loss: 0.004394166889009223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006782513521029614\n",
      "Training Loss: 0.007012843786505982\n",
      "Training Loss: 0.006617046815808863\n",
      "Validation Loss: 0.004387317491522624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.00677598156966269\n",
      "Training Loss: 0.007006043849978596\n",
      "Training Loss: 0.0066095368983224035\n",
      "Validation Loss: 0.004380495210303768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006769538407679647\n",
      "Training Loss: 0.0069992812490090725\n",
      "Training Loss: 0.006602072860114276\n",
      "Validation Loss: 0.004373701750379307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006763186063617468\n",
      "Training Loss: 0.0069925555086229\n",
      "Training Loss: 0.006594656815286726\n",
      "Validation Loss: 0.0043669381006254575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006756924132932909\n",
      "Training Loss: 0.006985863288864493\n",
      "Training Loss: 0.006587288477458059\n",
      "Validation Loss: 0.004360203546199822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006750749931088648\n",
      "Training Loss: 0.006979203009977937\n",
      "Training Loss: 0.0065799666265957055\n",
      "Validation Loss: 0.00435349551680906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006744657264789566\n",
      "Training Loss: 0.0069725693517830225\n",
      "Training Loss: 0.0065726869611535226\n",
      "Validation Loss: 0.00434681474037594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006738644638680853\n",
      "Training Loss: 0.006965961353853345\n",
      "Training Loss: 0.006565450399648398\n",
      "Validation Loss: 0.004340157897755755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006732704910682515\n",
      "Training Loss: 0.0069593756168615075\n",
      "Training Loss: 0.006558250279631465\n",
      "Validation Loss: 0.0043335234611609095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006726832406129688\n",
      "Training Loss: 0.006952807633206248\n",
      "Training Loss: 0.006551085069077089\n",
      "Validation Loss: 0.004326909662124941\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006721021038247272\n",
      "Training Loss: 0.0069462554866913705\n",
      "Training Loss: 0.006543950979830697\n",
      "Validation Loss: 0.00432031631098244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006715267737745307\n",
      "Training Loss: 0.006939715578919276\n",
      "Training Loss: 0.006536844910588115\n",
      "Validation Loss: 0.00431374023705093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006709565200144425\n",
      "Training Loss: 0.006933186713140458\n",
      "Training Loss: 0.006529763742582873\n",
      "Validation Loss: 0.004307179002148842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006703910115757026\n",
      "Training Loss: 0.006926665913779289\n",
      "Training Loss: 0.006522704567760229\n",
      "Validation Loss: 0.004300634495082071\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006698296726099216\n",
      "Training Loss: 0.006920151619706303\n",
      "Training Loss: 0.006515665361657739\n",
      "Validation Loss: 0.004294102302532685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006692722364095971\n",
      "Training Loss: 0.006913641734281555\n",
      "Training Loss: 0.0065086443151813\n",
      "Validation Loss: 0.004287586300215276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0066871826071292165\n",
      "Training Loss: 0.006907134094508365\n",
      "Training Loss: 0.006501638198969885\n",
      "Validation Loss: 0.004281084855699263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006681674116407521\n",
      "Training Loss: 0.006900628338335082\n",
      "Training Loss: 0.006494646726641804\n",
      "Validation Loss: 0.004274597544526535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006676195494947024\n",
      "Training Loss: 0.0068941234145313505\n",
      "Training Loss: 0.006487668922636658\n",
      "Validation Loss: 0.00426812251517026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006670742794522084\n",
      "Training Loss: 0.006887618522159755\n",
      "Training Loss: 0.006480702160624787\n",
      "Validation Loss: 0.0042616612077795305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006665313711273484\n",
      "Training Loss: 0.006881111147813499\n",
      "Training Loss: 0.006473746907431632\n",
      "Validation Loss: 0.004255214621694863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006659905645647086\n",
      "Training Loss: 0.006874601872405037\n",
      "Training Loss: 0.006466800728812814\n",
      "Validation Loss: 0.004248782546322248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.00665451678505633\n",
      "Training Loss: 0.006868089383933693\n",
      "Training Loss: 0.006459864067146555\n",
      "Validation Loss: 0.004242360880310657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.0066491433797637\n",
      "Training Loss: 0.006861571910558268\n",
      "Training Loss: 0.006452935058623552\n",
      "Validation Loss: 0.004235956024540735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006643784487387165\n",
      "Training Loss: 0.00685505005531013\n",
      "Training Loss: 0.0064460128720384095\n",
      "Validation Loss: 0.004229562523188802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0066384373151231555\n",
      "Training Loss: 0.0068485222442541275\n",
      "Training Loss: 0.006439098286209628\n",
      "Validation Loss: 0.0042231851558232406\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006633099135942757\n",
      "Training Loss: 0.006841988661326468\n",
      "Training Loss: 0.0064321902405936274\n",
      "Validation Loss: 0.004216822811266344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006627768736798316\n",
      "Training Loss: 0.006835446793120354\n",
      "Training Loss: 0.0064252859796397385\n",
      "Validation Loss: 0.004210471619035672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006622441238723695\n",
      "Training Loss: 0.0068288975208997725\n",
      "Training Loss: 0.006418385885190218\n",
      "Validation Loss: 0.004204133698151687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006617116025299765\n",
      "Training Loss: 0.006822339771315455\n",
      "Training Loss: 0.006411489004967734\n",
      "Validation Loss: 0.004197809752992491\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.0066117908776504915\n",
      "Training Loss: 0.006815773635171354\n",
      "Training Loss: 0.006404596327338368\n",
      "Validation Loss: 0.004191496461797296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006606463275966234\n",
      "Training Loss: 0.006809198867995292\n",
      "Training Loss: 0.00639770642039366\n",
      "Validation Loss: 0.004185196812123353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006601130728377029\n",
      "Training Loss: 0.006802614517509937\n",
      "Training Loss: 0.006390818564686924\n",
      "Validation Loss: 0.004178909413526986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006595792601583526\n",
      "Training Loss: 0.006796021903865039\n",
      "Training Loss: 0.006383933263132349\n",
      "Validation Loss: 0.004172634474640147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006590447896160185\n",
      "Training Loss: 0.006789421351859346\n",
      "Training Loss: 0.006377051330637187\n",
      "Validation Loss: 0.004166370204105722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006585094969486818\n",
      "Training Loss: 0.006782813416793943\n",
      "Training Loss: 0.006370172691531479\n",
      "Validation Loss: 0.004160115517560769\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006579733700491488\n",
      "Training Loss: 0.006776199779706076\n",
      "Training Loss: 0.006363298362120986\n",
      "Validation Loss: 0.004153873176272079\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.0065743646438932045\n",
      "Training Loss: 0.006769580972613767\n",
      "Training Loss: 0.006356428752187639\n",
      "Validation Loss: 0.0041476375838019625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006568987224018202\n",
      "Training Loss: 0.006762959173647687\n",
      "Training Loss: 0.006349567701108754\n",
      "Validation Loss: 0.004141411812076073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.0065636031748726965\n",
      "Training Loss: 0.006756336619146168\n",
      "Training Loss: 0.006342716250801459\n",
      "Validation Loss: 0.00413519443925784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006558216811390594\n",
      "Training Loss: 0.006749716270714998\n",
      "Training Loss: 0.006335877486271783\n",
      "Validation Loss: 0.004128982656337111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006552827614941634\n",
      "Training Loss: 0.006743101259926334\n",
      "Training Loss: 0.006329054795205593\n",
      "Validation Loss: 0.004122779981934287\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006547442236333154\n",
      "Training Loss: 0.006736494851065799\n",
      "Training Loss: 0.006322250708471984\n",
      "Validation Loss: 0.004116578919687465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006542059936909936\n",
      "Training Loss: 0.006729899091878906\n",
      "Training Loss: 0.006315469674300403\n",
      "Validation Loss: 0.0041103860182855065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006536690085777081\n",
      "Training Loss: 0.0067233199859038\n",
      "Training Loss: 0.0063087180559523405\n",
      "Validation Loss: 0.004104195500781571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.0065313347463961694\n",
      "Training Loss: 0.006716761099523865\n",
      "Training Loss: 0.0063019981747493145\n",
      "Validation Loss: 0.004098008314848699\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006525998595752753\n",
      "Training Loss: 0.0067102240363601596\n",
      "Training Loss: 0.006295313908485696\n",
      "Validation Loss: 0.0040918246841612745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006520686047151685\n",
      "Training Loss: 0.0067037141288165\n",
      "Training Loss: 0.006288670592475683\n",
      "Validation Loss: 0.004085645727091207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006515402325312607\n",
      "Training Loss: 0.006697234014864079\n",
      "Training Loss: 0.006282071946188807\n",
      "Validation Loss: 0.004079466319402282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006510151913389563\n",
      "Training Loss: 0.006690786759136245\n",
      "Training Loss: 0.006275521659990773\n",
      "Validation Loss: 0.004073293618020717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006504939119331539\n",
      "Training Loss: 0.006684376201592386\n",
      "Training Loss: 0.00626902402145788\n",
      "Validation Loss: 0.004067119335876045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006499766977503896\n",
      "Training Loss: 0.006678003692650236\n",
      "Training Loss: 0.006262580216862261\n",
      "Validation Loss: 0.0040609484977936474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.00649463891168125\n",
      "Training Loss: 0.006671672451775521\n",
      "Training Loss: 0.006256194817833603\n",
      "Validation Loss: 0.004054781182255763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.00648955802724231\n",
      "Training Loss: 0.006665382607025094\n",
      "Training Loss: 0.006249869487946853\n",
      "Validation Loss: 0.00404862090984485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006484526255517267\n",
      "Training Loss: 0.006659134876681492\n",
      "Training Loss: 0.006243605021154508\n",
      "Validation Loss: 0.004042463511845955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006479544820031151\n",
      "Training Loss: 0.006652932022116147\n",
      "Training Loss: 0.006237403486156836\n",
      "Validation Loss: 0.004036312948996096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006474615221377462\n",
      "Training Loss: 0.00664677285880316\n",
      "Training Loss: 0.00623126422171481\n",
      "Validation Loss: 0.004030166709863612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.00646973722090479\n",
      "Training Loss: 0.006640656985691749\n",
      "Training Loss: 0.006225188915850595\n",
      "Validation Loss: 0.004024030798339818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.006464911781367846\n",
      "Training Loss: 0.006634584425482899\n",
      "Training Loss: 0.006219175955047831\n",
      "Validation Loss: 0.004017903103906494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006460136123350822\n",
      "Training Loss: 0.006628554778872058\n",
      "Training Loss: 0.006213225852698088\n",
      "Validation Loss: 0.004011783676269056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006455411498318426\n",
      "Training Loss: 0.006622566082514822\n",
      "Training Loss: 0.006207336981315165\n",
      "Validation Loss: 0.004005678836517873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006450736831175164\n",
      "Training Loss: 0.006616617346298881\n",
      "Training Loss: 0.006201509172096848\n",
      "Validation Loss: 0.003999587738352796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006446109708049335\n",
      "Training Loss: 0.006610708029475063\n",
      "Training Loss: 0.006195739447139204\n",
      "Validation Loss: 0.003993510449137748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.0064415291091427206\n",
      "Training Loss: 0.0066048366948962215\n",
      "Training Loss: 0.006190027991542593\n",
      "Validation Loss: 0.003987448323345377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.0064369924506172535\n",
      "Training Loss: 0.00659900062601082\n",
      "Training Loss: 0.00618437301600352\n",
      "Validation Loss: 0.003981407195476167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.0064324989938177165\n",
      "Training Loss: 0.006593199962517247\n",
      "Training Loss: 0.006178771627601236\n",
      "Validation Loss: 0.0039753814854428925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006428046190994792\n",
      "Training Loss: 0.006587431782972999\n",
      "Training Loss: 0.00617322332574986\n",
      "Validation Loss: 0.003969379395293595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.00642363187042065\n",
      "Training Loss: 0.006581695065833628\n",
      "Training Loss: 0.0061677249008789655\n",
      "Validation Loss: 0.0039633952461842325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006419253066997044\n",
      "Training Loss: 0.006575986922835\n",
      "Training Loss: 0.00616227570688352\n",
      "Validation Loss: 0.003957436008645703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006414908730075695\n",
      "Training Loss: 0.0065703077049693095\n",
      "Training Loss: 0.006156873962609098\n",
      "Validation Loss: 0.003951499898515097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006410598602378741\n",
      "Training Loss: 0.006564655660768039\n",
      "Training Loss: 0.0061515183909796175\n",
      "Validation Loss: 0.0039455861787133836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006406317451619543\n",
      "Training Loss: 0.006559029390336946\n",
      "Training Loss: 0.006146205554250628\n",
      "Validation Loss: 0.003939696905475235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.00640206488489639\n",
      "Training Loss: 0.006553426471073181\n",
      "Training Loss: 0.006140935002476909\n",
      "Validation Loss: 0.003933834477741104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006397839551209472\n",
      "Training Loss: 0.006547846271423623\n",
      "Training Loss: 0.006135703960317187\n",
      "Validation Loss: 0.003927996476295959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0063936373742762955\n",
      "Training Loss: 0.0065422868356108665\n",
      "Training Loss: 0.006130511955707334\n",
      "Validation Loss: 0.003922186067898161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0063894588948460295\n",
      "Training Loss: 0.006536747659556568\n",
      "Training Loss: 0.00612535671913065\n",
      "Validation Loss: 0.003916402643656337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00638530129508581\n",
      "Training Loss: 0.006531227432424203\n",
      "Training Loss: 0.006120236340793781\n",
      "Validation Loss: 0.003910642540411961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.00638116312562488\n",
      "Training Loss: 0.006525725775281899\n",
      "Training Loss: 0.006115149678662419\n",
      "Validation Loss: 0.0039049116547972885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006377043251995928\n",
      "Training Loss: 0.006520240140380338\n",
      "Training Loss: 0.00611009617394302\n",
      "Validation Loss: 0.0038992062190108083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006372940084547736\n",
      "Training Loss: 0.006514771105721593\n",
      "Training Loss: 0.006105073369108141\n",
      "Validation Loss: 0.00389352747503396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006368851216393523\n",
      "Training Loss: 0.006509316795272752\n",
      "Training Loss: 0.006100080583710223\n",
      "Validation Loss: 0.0038878767812635037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006364777128328569\n",
      "Training Loss: 0.006503875945927575\n",
      "Training Loss: 0.006095116381766274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [24:22<10:27, 209.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.003882249827716458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.2284257760643959\n",
      "Training Loss: 0.1833690009638667\n",
      "Training Loss: 0.13855758048593997\n",
      "Validation Loss: 0.09603228436762028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.08020601630210876\n",
      "Training Loss: 0.06692513888701797\n",
      "Training Loss: 0.06242634888738394\n",
      "Validation Loss: 0.061312156363149704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.059288966935127974\n",
      "Training Loss: 0.058313791770488024\n",
      "Training Loss: 0.05719414813444018\n",
      "Validation Loss: 0.05653681991140494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.054508141987025735\n",
      "Training Loss: 0.05330164389684797\n",
      "Training Loss: 0.05179394830018282\n",
      "Validation Loss: 0.05053386397743493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04836911760270596\n",
      "Training Loss: 0.04691533615812659\n",
      "Training Loss: 0.045002613505348565\n",
      "Validation Loss: 0.043063027595870954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.040840153684839606\n",
      "Training Loss: 0.039260569186881186\n",
      "Training Loss: 0.03710871263407171\n",
      "Validation Loss: 0.034642346820720794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.03258840830996632\n",
      "Training Loss: 0.03117875010240823\n",
      "Training Loss: 0.029130956754088402\n",
      "Validation Loss: 0.026578109465497598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.02500582984648645\n",
      "Training Loss: 0.024232910303398966\n",
      "Training Loss: 0.02276351704262197\n",
      "Validation Loss: 0.020648401591591956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01975156616885215\n",
      "Training Loss: 0.01973885515006259\n",
      "Training Loss: 0.018841293761506676\n",
      "Validation Loss: 0.01707631784355205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.016728093207348138\n",
      "Training Loss: 0.017100348728708924\n",
      "Training Loss: 0.01649395241169259\n",
      "Validation Loss: 0.014852437488944008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.014875878407619893\n",
      "Training Loss: 0.015347096705809235\n",
      "Training Loss: 0.01485169226070866\n",
      "Validation Loss: 0.013196912233121274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.01348848667461425\n",
      "Training Loss: 0.013917689968366176\n",
      "Training Loss: 0.013447647113353015\n",
      "Validation Loss: 0.011734702927845248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.012276505217887462\n",
      "Training Loss: 0.01263963150093332\n",
      "Training Loss: 0.012204381804913282\n",
      "Validation Loss: 0.010468795280798936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.011285702774766832\n",
      "Training Loss: 0.011615244927816093\n",
      "Training Loss: 0.011243040289264173\n",
      "Validation Loss: 0.00948767327400071\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.010557631455594674\n",
      "Training Loss: 0.010857339757494628\n",
      "Training Loss: 0.010525768205989152\n",
      "Validation Loss: 0.008720782909835323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009994749318575486\n",
      "Training Loss: 0.01026375352172181\n",
      "Training Loss: 0.009951244922121986\n",
      "Validation Loss: 0.008085153962935457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009525806601159275\n",
      "Training Loss: 0.00977093888213858\n",
      "Training Loss: 0.009468127235304564\n",
      "Validation Loss: 0.007545131046764469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.009126102585578338\n",
      "Training Loss: 0.009355622807051987\n",
      "Training Loss: 0.009058732057455927\n",
      "Validation Loss: 0.007089494724935862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008789768154965714\n",
      "Training Loss: 0.009010685585672036\n",
      "Training Loss: 0.008717734364327044\n",
      "Validation Loss: 0.006713993167190739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008514899386791513\n",
      "Training Loss: 0.008732157472986729\n",
      "Training Loss: 0.008441336937248706\n",
      "Validation Loss: 0.006413082335813997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008297473601996898\n",
      "Training Loss: 0.008513944937149062\n",
      "Training Loss: 0.008223221231019125\n",
      "Validation Loss: 0.0061775530568125205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00813011764199473\n",
      "Training Loss: 0.008347074802732096\n",
      "Training Loss: 0.00805442787357606\n",
      "Validation Loss: 0.005995634668559003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008003377494169399\n",
      "Training Loss: 0.008221158924279735\n",
      "Training Loss: 0.007924936971394346\n",
      "Validation Loss: 0.005855157803953364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007907607946544886\n",
      "Training Loss: 0.008126147573348135\n",
      "Training Loss: 0.007825301046250389\n",
      "Validation Loss: 0.005745345903194269\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007834361675195396\n",
      "Training Loss: 0.008053502539405599\n",
      "Training Loss: 0.007747593212407082\n",
      "Validation Loss: 0.0056576102401726365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.0077769725723192094\n",
      "Training Loss: 0.007996586476219819\n",
      "Training Loss: 0.0076856705150567\n",
      "Validation Loss: 0.005585599221090336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0077305421116761865\n",
      "Training Loss: 0.007950540641322732\n",
      "Training Loss: 0.007635016336571425\n",
      "Validation Loss: 0.00552484757277403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007691620483528823\n",
      "Training Loss: 0.007911933806026355\n",
      "Training Loss: 0.00759239443577826\n",
      "Validation Loss: 0.005472276682881743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007657823811750859\n",
      "Training Loss: 0.007878357133595273\n",
      "Training Loss: 0.007555500887101516\n",
      "Validation Loss: 0.005425790965745456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007627474217442796\n",
      "Training Loss: 0.007848085063742474\n",
      "Training Loss: 0.007522661472903564\n",
      "Validation Loss: 0.005383905861788335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007599323560716584\n",
      "Training Loss: 0.007819793277885765\n",
      "Training Loss: 0.00749259083531797\n",
      "Validation Loss: 0.005345514202438128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007572328661335632\n",
      "Training Loss: 0.007792345546185971\n",
      "Training Loss: 0.007464199810056016\n",
      "Validation Loss: 0.0053096667613593464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007545480948174373\n",
      "Training Loss: 0.007764630769379437\n",
      "Training Loss: 0.007436439726734534\n",
      "Validation Loss: 0.005275415768716066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.0075176590750925245\n",
      "Training Loss: 0.0077354233956430105\n",
      "Training Loss: 0.007408157292520628\n",
      "Validation Loss: 0.0052416357290250865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007487524941097945\n",
      "Training Loss: 0.007703300755238161\n",
      "Training Loss: 0.007377972253598273\n",
      "Validation Loss: 0.005206862900777605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007453477751696482\n",
      "Training Loss: 0.007666627443395555\n",
      "Training Loss: 0.007344205217668787\n",
      "Validation Loss: 0.00516918291510449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007413717242889107\n",
      "Training Loss: 0.007623641528189182\n",
      "Training Loss: 0.007304936046712101\n",
      "Validation Loss: 0.0051262982888147235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007366433131974191\n",
      "Training Loss: 0.007572616735706106\n",
      "Training Loss: 0.007258229723665863\n",
      "Validation Loss: 0.005075892179764891\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007310136662563309\n",
      "Training Loss: 0.0075121592881623655\n",
      "Training Loss: 0.007202645972138271\n",
      "Validation Loss: 0.005016324139105972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007244308174122125\n",
      "Training Loss: 0.007441856139339506\n",
      "Training Loss: 0.0071380603301804514\n",
      "Validation Loss: 0.0049475900596007705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007170374834095128\n",
      "Training Loss: 0.0073632009420543905\n",
      "Training Loss: 0.007066455101594329\n",
      "Validation Loss: 0.004872064362541678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007092207138775848\n",
      "Training Loss: 0.0072798750211950395\n",
      "Training Loss: 0.006991706461412832\n",
      "Validation Loss: 0.00479398312680214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007014948329306207\n",
      "Training Loss: 0.0071964626188855615\n",
      "Training Loss: 0.006917892643250525\n",
      "Validation Loss: 0.004717464232424881\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.006942608713870868\n",
      "Training Loss: 0.007116390329319984\n",
      "Training Loss: 0.00684745236649178\n",
      "Validation Loss: 0.004644738266302084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.006876620441908017\n",
      "Training Loss: 0.007040961894672364\n",
      "Training Loss: 0.006780813639052212\n",
      "Validation Loss: 0.004576024451565123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0068163254973478615\n",
      "Training Loss: 0.006969898209208622\n",
      "Training Loss: 0.006717262628953904\n",
      "Validation Loss: 0.004510524182376357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006760290524689481\n",
      "Training Loss: 0.006902347746072337\n",
      "Training Loss: 0.006655888034729287\n",
      "Validation Loss: 0.004447328062136814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006707215815549716\n",
      "Training Loss: 0.00683752563665621\n",
      "Training Loss: 0.006596029171487316\n",
      "Validation Loss: 0.004385812536373818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0066562472190707924\n",
      "Training Loss: 0.0067749455786542965\n",
      "Training Loss: 0.006537361448863521\n",
      "Validation Loss: 0.004325706946658327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.006606957337353379\n",
      "Training Loss: 0.0067144205654039975\n",
      "Training Loss: 0.006479850370669738\n",
      "Validation Loss: 0.004267033245126727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.006559242216171697\n",
      "Training Loss: 0.006656013268511742\n",
      "Training Loss: 0.006423680466832593\n",
      "Validation Loss: 0.004210036928148082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.006513221234781668\n",
      "Training Loss: 0.006599964736378752\n",
      "Training Loss: 0.006369190486730077\n",
      "Validation Loss: 0.00415509677978672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.006469153020880185\n",
      "Training Loss: 0.006546629499644041\n",
      "Training Loss: 0.006316804806119763\n",
      "Validation Loss: 0.004102658570660383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0064273578592110425\n",
      "Training Loss: 0.006496396434959024\n",
      "Training Loss: 0.006266969029675238\n",
      "Validation Loss: 0.004053154762107042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.006388147315010429\n",
      "Training Loss: 0.006449608428520151\n",
      "Training Loss: 0.006220071834977716\n",
      "Validation Loss: 0.004006913842847884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00635175704548601\n",
      "Training Loss: 0.006406501543824561\n",
      "Training Loss: 0.006176387474406511\n",
      "Validation Loss: 0.003964121389370202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.006318307475885377\n",
      "Training Loss: 0.006367166147683747\n",
      "Training Loss: 0.006136052942601964\n",
      "Validation Loss: 0.003924799956161571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.006287792483344674\n",
      "Training Loss: 0.006331537974765524\n",
      "Training Loss: 0.006099058847175911\n",
      "Validation Loss: 0.0038888216616449816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.006260090386494994\n",
      "Training Loss: 0.006299423958989791\n",
      "Training Loss: 0.006065273938584141\n",
      "Validation Loss: 0.0038559418524814286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.006234995051054284\n",
      "Training Loss: 0.006270540150580928\n",
      "Training Loss: 0.006034482414834202\n",
      "Validation Loss: 0.0038258639612925773\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.006212251443648711\n",
      "Training Loss: 0.006244553871802054\n",
      "Training Loss: 0.00600642568024341\n",
      "Validation Loss: 0.0037982701081939545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.006191589111695066\n",
      "Training Loss: 0.006221120898844674\n",
      "Training Loss: 0.00598082289157901\n",
      "Validation Loss: 0.0037728432530610497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00617274111660663\n",
      "Training Loss: 0.0061999093682970855\n",
      "Training Loss: 0.005957400907063857\n",
      "Validation Loss: 0.0037493010998567505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.006155461944872514\n",
      "Training Loss: 0.006180611330782995\n",
      "Training Loss: 0.0059359021211275835\n",
      "Validation Loss: 0.003727393752628456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.006139529338106513\n",
      "Training Loss: 0.006162954869214445\n",
      "Training Loss: 0.005916092984843999\n",
      "Validation Loss: 0.0037069013257238887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.006124751305324025\n",
      "Training Loss: 0.006146700672106817\n",
      "Training Loss: 0.0058977637498173864\n",
      "Validation Loss: 0.003687642620656681\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.006110960515215993\n",
      "Training Loss: 0.0061316443752730265\n",
      "Training Loss: 0.0058807317062746734\n",
      "Validation Loss: 0.00366946113010701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.006098015552270226\n",
      "Training Loss: 0.006117611520458013\n",
      "Training Loss: 0.005864835512475111\n",
      "Validation Loss: 0.0036522200157122916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.006085797543055378\n",
      "Training Loss: 0.006104453228181228\n",
      "Training Loss: 0.00584993580065202\n",
      "Validation Loss: 0.003635813371576578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.006074203700409271\n",
      "Training Loss: 0.006092047163983807\n",
      "Training Loss: 0.005835910668247379\n",
      "Validation Loss: 0.0036201459895871748\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.006063149877591058\n",
      "Training Loss: 0.006080288416706025\n",
      "Training Loss: 0.005822656954987906\n",
      "Validation Loss: 0.0036051356000825763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006052563990815543\n",
      "Training Loss: 0.006069089721422643\n",
      "Training Loss: 0.005810083485557698\n",
      "Validation Loss: 0.0035907197298921563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006042386526823975\n",
      "Training Loss: 0.0060583793453406545\n",
      "Training Loss: 0.005798112997435965\n",
      "Validation Loss: 0.0035768352433243828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006032566636567935\n",
      "Training Loss: 0.006048095762962475\n",
      "Training Loss: 0.0057866771734552454\n",
      "Validation Loss: 0.0035634348600621472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006023062055464834\n",
      "Training Loss: 0.006038186853984371\n",
      "Training Loss: 0.005775718063814566\n",
      "Validation Loss: 0.0035504743135063334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006013836021302268\n",
      "Training Loss: 0.006028609921922907\n",
      "Training Loss: 0.005765185006312095\n",
      "Validation Loss: 0.003537917837992394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006004857229418121\n",
      "Training Loss: 0.006019329549744725\n",
      "Training Loss: 0.005755034776520915\n",
      "Validation Loss: 0.0035257320497917495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0059961011452833194\n",
      "Training Loss: 0.006010315623134374\n",
      "Training Loss: 0.005745228802552447\n",
      "Validation Loss: 0.0035138883545544793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.005987544584204443\n",
      "Training Loss: 0.006001541068544611\n",
      "Training Loss: 0.0057357335317647085\n",
      "Validation Loss: 0.003502366028391243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.005979166243923828\n",
      "Training Loss: 0.005992981714662164\n",
      "Training Loss: 0.005726518397568725\n",
      "Validation Loss: 0.0034911395933510466\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.005970950745395384\n",
      "Training Loss: 0.005984620322706178\n",
      "Training Loss: 0.005717558427713812\n",
      "Validation Loss: 0.003480188869688074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.005962882761959918\n",
      "Training Loss: 0.005976439684163779\n",
      "Training Loss: 0.0057088296546135096\n",
      "Validation Loss: 0.003469496369597324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.005954949326696806\n",
      "Training Loss: 0.005968424074817449\n",
      "Training Loss: 0.005700312959379517\n",
      "Validation Loss: 0.003459050098376537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.005947139095515013\n",
      "Training Loss: 0.005960561715764925\n",
      "Training Loss: 0.0056919883657246826\n",
      "Validation Loss: 0.0034488320011865307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.005939440872170962\n",
      "Training Loss: 0.005952840566169471\n",
      "Training Loss: 0.00568384112266358\n",
      "Validation Loss: 0.0034388320865842066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.005931845274753869\n",
      "Training Loss: 0.005945249024080113\n",
      "Training Loss: 0.005675856184680015\n",
      "Validation Loss: 0.0034290402257825467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.005924345813109539\n",
      "Training Loss: 0.005937780168605969\n",
      "Training Loss: 0.005668019519653171\n",
      "Validation Loss: 0.0034194407386841314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.005916933277621866\n",
      "Training Loss: 0.005930423949612304\n",
      "Training Loss: 0.005660320472088642\n",
      "Validation Loss: 0.0034100257659467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00590960142260883\n",
      "Training Loss: 0.00592317343573086\n",
      "Training Loss: 0.005652746294508688\n",
      "Validation Loss: 0.0034007868798857743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.005902343530324288\n",
      "Training Loss: 0.005916022058809176\n",
      "Training Loss: 0.005645290043903514\n",
      "Validation Loss: 0.0033917190968791506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00589515455183573\n",
      "Training Loss: 0.005908962008543312\n",
      "Training Loss: 0.005637941274326295\n",
      "Validation Loss: 0.003382810016732998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.005888030116329901\n",
      "Training Loss: 0.00590198915801011\n",
      "Training Loss: 0.005630691756960004\n",
      "Validation Loss: 0.003374052305282041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0058809636475052685\n",
      "Training Loss: 0.005895098150940612\n",
      "Training Loss: 0.005623534614569508\n",
      "Validation Loss: 0.0033654417800769378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.005873952584224753\n",
      "Training Loss: 0.005888282811501995\n",
      "Training Loss: 0.005616463315091096\n",
      "Validation Loss: 0.0033569722534471263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.005866992532392032\n",
      "Training Loss: 0.0058815400418825445\n",
      "Training Loss: 0.005609472298528999\n",
      "Validation Loss: 0.003348637703842787\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.005860079218982719\n",
      "Training Loss: 0.005874864840880036\n",
      "Training Loss: 0.00560255597694777\n",
      "Validation Loss: 0.0033404328539873357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.005853210459463298\n",
      "Training Loss: 0.005868254358647391\n",
      "Training Loss: 0.00559570943005383\n",
      "Validation Loss: 0.0033323520943627097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.005846383887110278\n",
      "Training Loss: 0.0058617045183200385\n",
      "Training Loss: 0.005588926766067743\n",
      "Validation Loss: 0.003324393284365828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.005839595987345092\n",
      "Training Loss: 0.0058552112209144976\n",
      "Training Loss: 0.005582204998936504\n",
      "Validation Loss: 0.003316550310884257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.005832843945245259\n",
      "Training Loss: 0.0058487725572194905\n",
      "Training Loss: 0.0055755407235119495\n",
      "Validation Loss: 0.0033088179332664593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.005826126809115522\n",
      "Training Loss: 0.0058423852449050176\n",
      "Training Loss: 0.005568930018926039\n",
      "Validation Loss: 0.003301193050809958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.005819441573694348\n",
      "Training Loss: 0.005836046410840936\n",
      "Training Loss: 0.005562370038242079\n",
      "Validation Loss: 0.0032936741605798683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.005812787318136543\n",
      "Training Loss: 0.005829755239537917\n",
      "Training Loss: 0.005555857546278275\n",
      "Validation Loss: 0.0032862569205462933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.005806161800283007\n",
      "Training Loss: 0.0058235074736876415\n",
      "Training Loss: 0.005549390258383937\n",
      "Validation Loss: 0.003278939003710834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0057995647180359815\n",
      "Training Loss: 0.005817302181385458\n",
      "Training Loss: 0.005542965999338776\n",
      "Validation Loss: 0.00327171542448923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.0057929937512381\n",
      "Training Loss: 0.00581113769498188\n",
      "Training Loss: 0.005536582564818673\n",
      "Validation Loss: 0.0032645847492725746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0057864486414473506\n",
      "Training Loss: 0.005805011143675074\n",
      "Training Loss: 0.0055302385176764805\n",
      "Validation Loss: 0.003257543337138977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.005779927716357634\n",
      "Training Loss: 0.0057989217154681685\n",
      "Training Loss: 0.005523931345087476\n",
      "Validation Loss: 0.0032505908741594786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.005773431799025275\n",
      "Training Loss: 0.005792867274722085\n",
      "Training Loss: 0.005517659995239228\n",
      "Validation Loss: 0.0032437233682041672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.00576695833238773\n",
      "Training Loss: 0.005786847547278739\n",
      "Training Loss: 0.005511423305142671\n",
      "Validation Loss: 0.003236939824510659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.005760507735540159\n",
      "Training Loss: 0.005780859843944199\n",
      "Training Loss: 0.005505219665938057\n",
      "Validation Loss: 0.0032302380429601735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.005754079946200363\n",
      "Training Loss: 0.0057749043742660435\n",
      "Training Loss: 0.005499049033969641\n",
      "Validation Loss: 0.0032236167187854816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.005747674026060849\n",
      "Training Loss: 0.005768977532279678\n",
      "Training Loss: 0.0054929097247077155\n",
      "Validation Loss: 0.003217072506027108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.0057412906113313514\n",
      "Training Loss: 0.005763081789482385\n",
      "Training Loss: 0.005486801820225083\n",
      "Validation Loss: 0.0032106037545959684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.005734929199679755\n",
      "Training Loss: 0.005757214121986181\n",
      "Training Loss: 0.0054807226627599445\n",
      "Validation Loss: 0.003204208319964871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.005728589333011768\n",
      "Training Loss: 0.005751372756203636\n",
      "Training Loss: 0.0054746740328846496\n",
      "Validation Loss: 0.0031978866350941696\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.005722271124832332\n",
      "Training Loss: 0.005745559526840225\n",
      "Training Loss: 0.0054686546907760205\n",
      "Validation Loss: 0.003191635488098215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.005715975418570452\n",
      "Training Loss: 0.005739771085209213\n",
      "Training Loss: 0.005462662610807456\n",
      "Validation Loss: 0.0031854516088836984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.005709702642634511\n",
      "Training Loss: 0.005734008373110555\n",
      "Training Loss: 0.005456698940834031\n",
      "Validation Loss: 0.0031793365847539116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.005703450228320434\n",
      "Training Loss: 0.005728269588435069\n",
      "Training Loss: 0.0054507639002986255\n",
      "Validation Loss: 0.0031732882201682064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.005697222517919726\n",
      "Training Loss: 0.005722554653766565\n",
      "Training Loss: 0.005444856449612416\n",
      "Validation Loss: 0.0031673049552920747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.005691016442142427\n",
      "Training Loss: 0.005716863531852141\n",
      "Training Loss: 0.005438976600416936\n",
      "Validation Loss: 0.0031613841027628336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0056848340766737235\n",
      "Training Loss: 0.005711194684263319\n",
      "Training Loss: 0.005433124458650127\n",
      "Validation Loss: 0.0031555254572186242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.0056786739360541105\n",
      "Training Loss: 0.005705548289115541\n",
      "Training Loss: 0.005427298925351352\n",
      "Validation Loss: 0.003149725789769312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.005672538432409055\n",
      "Training Loss: 0.005699923243955709\n",
      "Training Loss: 0.005421500221127644\n",
      "Validation Loss: 0.0031439843417532492\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.00566642704885453\n",
      "Training Loss: 0.005694319055182859\n",
      "Training Loss: 0.005415728515363299\n",
      "Validation Loss: 0.0031383005095112107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0056603393092518675\n",
      "Training Loss: 0.005688735600560903\n",
      "Training Loss: 0.005409985407604836\n",
      "Validation Loss: 0.0031326732178365165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.005654277223511599\n",
      "Training Loss: 0.005683173245633952\n",
      "Training Loss: 0.005404268488055095\n",
      "Validation Loss: 0.0031271009199750305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.00564823996683117\n",
      "Training Loss: 0.005677630099235102\n",
      "Training Loss: 0.005398579362663441\n",
      "Validation Loss: 0.0031215798363529064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.005642227359930985\n",
      "Training Loss: 0.005672107266145758\n",
      "Training Loss: 0.005392917014542036\n",
      "Validation Loss: 0.003116110165791816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.005636241171741858\n",
      "Training Loss: 0.005666602727724239\n",
      "Training Loss: 0.005387281653820537\n",
      "Validation Loss: 0.003110693145695069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.005630280332406983\n",
      "Training Loss: 0.005661117063136771\n",
      "Training Loss: 0.005381673061056063\n",
      "Validation Loss: 0.0031053225223362196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.005624345656833611\n",
      "Training Loss: 0.005655650545377284\n",
      "Training Loss: 0.0053760922671062875\n",
      "Validation Loss: 0.003099999787531835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.005618437635130249\n",
      "Training Loss: 0.005650202623801306\n",
      "Training Loss: 0.005370538179995492\n",
      "Validation Loss: 0.0030947231087216248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.005612555599655024\n",
      "Training Loss: 0.005644772453815676\n",
      "Training Loss: 0.005365010933019221\n",
      "Validation Loss: 0.0030894904290168974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.005606701013166457\n",
      "Training Loss: 0.005639359346823767\n",
      "Training Loss: 0.005359511218848638\n",
      "Validation Loss: 0.0030843028517471356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.005600872532231733\n",
      "Training Loss: 0.005633963018772193\n",
      "Training Loss: 0.005354037625947967\n",
      "Validation Loss: 0.0030791571257855702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0055950709275202825\n",
      "Training Loss: 0.0056285837013274435\n",
      "Training Loss: 0.005348592087393626\n",
      "Validation Loss: 0.003074052680827928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.005589296113466844\n",
      "Training Loss: 0.005623222023132257\n",
      "Training Loss: 0.005343172329012305\n",
      "Validation Loss: 0.0030689858164366208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.005583548482973128\n",
      "Training Loss: 0.005617875987663865\n",
      "Training Loss: 0.00533777826000005\n",
      "Validation Loss: 0.003063956860274997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.005577826810185798\n",
      "Training Loss: 0.005612546040210873\n",
      "Training Loss: 0.005332411538693123\n",
      "Validation Loss: 0.003058966227644908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.005572132798843086\n",
      "Training Loss: 0.0056072316656354815\n",
      "Training Loss: 0.00532707104110159\n",
      "Validation Loss: 0.003054011859695605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.005566465289448388\n",
      "Training Loss: 0.005601933492580429\n",
      "Training Loss: 0.005321756332414225\n",
      "Validation Loss: 0.003049089905565207\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.005560824371059425\n",
      "Training Loss: 0.005596649935469032\n",
      "Training Loss: 0.005316466939984821\n",
      "Validation Loss: 0.0030442009414441548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.005555209660669789\n",
      "Training Loss: 0.005591382230632007\n",
      "Training Loss: 0.005311203121673316\n",
      "Validation Loss: 0.0030393452099733726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.005549620865494944\n",
      "Training Loss: 0.005586129708681256\n",
      "Training Loss: 0.005305965219740756\n",
      "Validation Loss: 0.003034521236340777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005544058692175895\n",
      "Training Loss: 0.005580891150166281\n",
      "Training Loss: 0.005300752524053678\n",
      "Validation Loss: 0.003029727831540441\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005538521992857568\n",
      "Training Loss: 0.005575667483499274\n",
      "Training Loss: 0.0052955628506606445\n",
      "Validation Loss: 0.003024961765374193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005533010215149261\n",
      "Training Loss: 0.005570456613786519\n",
      "Training Loss: 0.005290398726356216\n",
      "Validation Loss: 0.003020225425664168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005527523697819561\n",
      "Training Loss: 0.0055652611679397525\n",
      "Training Loss: 0.0052852580806938936\n",
      "Validation Loss: 0.0030155154357120145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005522062121890485\n",
      "Training Loss: 0.00556007907143794\n",
      "Training Loss: 0.005280141938710585\n",
      "Validation Loss: 0.003010835112046367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.00551662611134816\n",
      "Training Loss: 0.005554910249775276\n",
      "Training Loss: 0.005275048238108866\n",
      "Validation Loss: 0.00300617635791619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0055112128023756665\n",
      "Training Loss: 0.005549755492247641\n",
      "Training Loss: 0.005269977713469416\n",
      "Validation Loss: 0.0030015444355556385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005505823817220517\n",
      "Training Loss: 0.00554461374762468\n",
      "Training Loss: 0.005264930202974938\n",
      "Validation Loss: 0.002996935498353952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005500458851456642\n",
      "Training Loss: 0.005539485024637542\n",
      "Training Loss: 0.005259904925478623\n",
      "Validation Loss: 0.0029923492451355365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005495116551755928\n",
      "Training Loss: 0.005534368968801573\n",
      "Training Loss: 0.005254901073058136\n",
      "Validation Loss: 0.0029877864126524145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.0054897972679464144\n",
      "Training Loss: 0.005529266475932672\n",
      "Training Loss: 0.005249918977497146\n",
      "Validation Loss: 0.002983245511704093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005484499628655612\n",
      "Training Loss: 0.0055241757252952085\n",
      "Training Loss: 0.005244956631795503\n",
      "Validation Loss: 0.0029787243075088043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005479224496521056\n",
      "Training Loss: 0.005519098770455457\n",
      "Training Loss: 0.005240015928284265\n",
      "Validation Loss: 0.0029742244148386245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005473971008905209\n",
      "Training Loss: 0.0055140339332865555\n",
      "Training Loss: 0.005235095298849047\n",
      "Validation Loss: 0.00296974250179548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005468737531336956\n",
      "Training Loss: 0.005508981241728179\n",
      "Training Loss: 0.005230193189927377\n",
      "Validation Loss: 0.002965279796626419\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005463525303057395\n",
      "Training Loss: 0.005503940369235352\n",
      "Training Loss: 0.005225310640526004\n",
      "Validation Loss: 0.002960836628302827\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005458332691341638\n",
      "Training Loss: 0.005498911103932187\n",
      "Training Loss: 0.005220446844468825\n",
      "Validation Loss: 0.0029564104520380914\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005453160850447602\n",
      "Training Loss: 0.005493894868413918\n",
      "Training Loss: 0.005215601737145335\n",
      "Validation Loss: 0.0029520029421199866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005448007307713851\n",
      "Training Loss: 0.005488891025306657\n",
      "Training Loss: 0.005210775687010028\n",
      "Validation Loss: 0.0029476104991568064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.00544287362950854\n",
      "Training Loss: 0.00548389894363936\n",
      "Training Loss: 0.0052059672062750905\n",
      "Validation Loss: 0.0029432387189322223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005437758996267803\n",
      "Training Loss: 0.005478918435401283\n",
      "Training Loss: 0.005201175013789907\n",
      "Validation Loss: 0.002938880314043294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005432662308448926\n",
      "Training Loss: 0.005473951114690862\n",
      "Training Loss: 0.0051964000350562855\n",
      "Validation Loss: 0.0029345375127316025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005427584054996259\n",
      "Training Loss: 0.00546899450593628\n",
      "Training Loss: 0.005191640589619056\n",
      "Validation Loss: 0.0029302103228453715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.005422522171866149\n",
      "Training Loss: 0.005464050696464256\n",
      "Training Loss: 0.00518689721240662\n",
      "Validation Loss: 0.0029258981518436936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005417478628223762\n",
      "Training Loss: 0.005459118017461151\n",
      "Training Loss: 0.005182170535554178\n",
      "Validation Loss: 0.0029215993774332778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.00541245196480304\n",
      "Training Loss: 0.00545419855217915\n",
      "Training Loss: 0.005177457855315879\n",
      "Validation Loss: 0.002917316980958194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0054074415453942495\n",
      "Training Loss: 0.005449289891403169\n",
      "Training Loss: 0.005172759761335328\n",
      "Validation Loss: 0.0029130468767638623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005402447068481706\n",
      "Training Loss: 0.005444393797661178\n",
      "Training Loss: 0.005168077975977212\n",
      "Validation Loss: 0.0029087903895650812\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005397469077724964\n",
      "Training Loss: 0.005439508815761655\n",
      "Training Loss: 0.0051634086994454265\n",
      "Validation Loss: 0.002904548334923123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005392506796051748\n",
      "Training Loss: 0.005434636941645294\n",
      "Training Loss: 0.005158755079028196\n",
      "Validation Loss: 0.0029003199374988634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005387560052331537\n",
      "Training Loss: 0.005429777016397566\n",
      "Training Loss: 0.0051541140541667115\n",
      "Validation Loss: 0.002896104929144651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.0053826291265431795\n",
      "Training Loss: 0.005424928938737139\n",
      "Training Loss: 0.005149485445581376\n",
      "Validation Loss: 0.00289190090339882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005377713231137022\n",
      "Training Loss: 0.00542009366909042\n",
      "Training Loss: 0.005144870085641742\n",
      "Validation Loss: 0.002887708870720202\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005372811928973533\n",
      "Training Loss: 0.005415270411176607\n",
      "Training Loss: 0.005140267455135472\n",
      "Validation Loss: 0.00288352990042931\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.0053679258178453895\n",
      "Training Loss: 0.005410459208069369\n",
      "Training Loss: 0.005135676771751605\n",
      "Validation Loss: 0.0028793617740948425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005363053781911731\n",
      "Training Loss: 0.005405660741962493\n",
      "Training Loss: 0.005131097612902522\n",
      "Validation Loss: 0.002875204794854449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.0053581950283842165\n",
      "Training Loss: 0.005400875624036417\n",
      "Training Loss: 0.00512653035519179\n",
      "Validation Loss: 0.002871058125891252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.0053533517470350485\n",
      "Training Loss: 0.005396100966027007\n",
      "Training Loss: 0.0051219747302820905\n",
      "Validation Loss: 0.0028669259542327247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005348521912237629\n",
      "Training Loss: 0.005391339697525837\n",
      "Training Loss: 0.005117430319660343\n",
      "Validation Loss: 0.002862803822741687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005343706186977215\n",
      "Training Loss: 0.005386591572314501\n",
      "Training Loss: 0.005112897754297591\n",
      "Validation Loss: 0.002858694894579396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005338905281969346\n",
      "Training Loss: 0.005381857383763417\n",
      "Training Loss: 0.005108375159325078\n",
      "Validation Loss: 0.002854595997101324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005334118048194796\n",
      "Training Loss: 0.005377134682494216\n",
      "Training Loss: 0.005103863158728928\n",
      "Validation Loss: 0.0028505061764212514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.0053293445508461445\n",
      "Training Loss: 0.005372424644883722\n",
      "Training Loss: 0.005099362550536171\n",
      "Validation Loss: 0.0028464285378197855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.00532458551984746\n",
      "Training Loss: 0.005367730385041796\n",
      "Training Loss: 0.005094872734625824\n",
      "Validation Loss: 0.0028423652261511285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005319839598378166\n",
      "Training Loss: 0.005363047543796711\n",
      "Training Loss: 0.005090392748243176\n",
      "Validation Loss: 0.0028383094016881136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005315107938367873\n",
      "Training Loss: 0.005358377380180173\n",
      "Training Loss: 0.0050859232299262655\n",
      "Validation Loss: 0.002834265240012888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.00531039118708577\n",
      "Training Loss: 0.005353722365107387\n",
      "Training Loss: 0.0050814636627910656\n",
      "Validation Loss: 0.0028302320141837083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005305688175722026\n",
      "Training Loss: 0.005349080812884495\n",
      "Training Loss: 0.005077014587004669\n",
      "Validation Loss: 0.0028262095482695553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005300999296014197\n",
      "Training Loss: 0.005344452422577888\n",
      "Training Loss: 0.005072575765661895\n",
      "Validation Loss: 0.0028221982163691033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.0052963256608927626\n",
      "Training Loss: 0.00533983830246143\n",
      "Training Loss: 0.005068147199344821\n",
      "Validation Loss: 0.0028181998324031117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005291665963013657\n",
      "Training Loss: 0.005335237930994481\n",
      "Training Loss: 0.005063729996327311\n",
      "Validation Loss: 0.002814211386577697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005287022885750048\n",
      "Training Loss: 0.005330653533455916\n",
      "Training Loss: 0.005059323406894692\n",
      "Validation Loss: 0.0028102350208039782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005282393852830865\n",
      "Training Loss: 0.00532608360867016\n",
      "Training Loss: 0.0050549274368677285\n",
      "Validation Loss: 0.0028062718848467626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005277781244949438\n",
      "Training Loss: 0.005321527881314978\n",
      "Training Loss: 0.005050543090328574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [27:51<06:58, 209.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0028023201562830486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.07701804490759968\n",
      "Training Loss: 0.06698856849223375\n",
      "Training Loss: 0.06255834752693773\n",
      "Validation Loss: 0.06057102017606912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.057761295158416034\n",
      "Training Loss: 0.05515991572290659\n",
      "Training Loss: 0.05162403800524771\n",
      "Validation Loss: 0.0480634518742059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.044943293081596496\n",
      "Training Loss: 0.04133239504881203\n",
      "Training Loss: 0.037154224663972855\n",
      "Validation Loss: 0.03343506700495321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.031128086410462857\n",
      "Training Loss: 0.028985157259739935\n",
      "Training Loss: 0.026267596008256077\n",
      "Validation Loss: 0.023506812405971328\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.02226740981452167\n",
      "Training Loss: 0.02149816027842462\n",
      "Training Loss: 0.02000235448591411\n",
      "Validation Loss: 0.017928189032951767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.017550753792747856\n",
      "Training Loss: 0.017627870053984224\n",
      "Training Loss: 0.016858611153438688\n",
      "Validation Loss: 0.01516865919019734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.015326111300382764\n",
      "Training Loss: 0.015765473297797143\n",
      "Training Loss: 0.015294268205761909\n",
      "Validation Loss: 0.013729882447488522\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014167163271922618\n",
      "Training Loss: 0.014683093279600143\n",
      "Training Loss: 0.014266905300319195\n",
      "Validation Loss: 0.012670674808637311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013251732664648443\n",
      "Training Loss: 0.013694833759218454\n",
      "Training Loss: 0.013214064138010144\n",
      "Validation Loss: 0.011478015148405279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.012166503416374326\n",
      "Training Loss: 0.012443620403064414\n",
      "Training Loss: 0.0119000658870209\n",
      "Validation Loss: 0.010064055253699255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010962748393649236\n",
      "Training Loss: 0.011225346664432437\n",
      "Training Loss: 0.01088344180607237\n",
      "Validation Loss: 0.009148089835169107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.010288480371236801\n",
      "Training Loss: 0.010611783668864519\n",
      "Training Loss: 0.010394594348035753\n",
      "Validation Loss: 0.008683250616618505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009941613210830837\n",
      "Training Loss: 0.010268449236173182\n",
      "Training Loss: 0.010076356960926205\n",
      "Validation Loss: 0.00835415121858542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00968982144142501\n",
      "Training Loss: 0.010009687091223896\n",
      "Training Loss: 0.00982291460968554\n",
      "Validation Loss: 0.008079932723979184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009482196881435812\n",
      "Training Loss: 0.009792398617137224\n",
      "Training Loss: 0.009606344138737767\n",
      "Validation Loss: 0.007838256369355354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009302271056221799\n",
      "Training Loss: 0.009602102828212082\n",
      "Training Loss: 0.009415218294598161\n",
      "Validation Loss: 0.007619899403293397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009142266105627642\n",
      "Training Loss: 0.009431591297034175\n",
      "Training Loss: 0.009243015599204228\n",
      "Validation Loss: 0.007419186704425832\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008997308034449815\n",
      "Training Loss: 0.009276282102800905\n",
      "Training Loss: 0.009085426053497941\n",
      "Validation Loss: 0.007232299949607572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008864260707050563\n",
      "Training Loss: 0.009133289032615722\n",
      "Training Loss: 0.008939759386703373\n",
      "Validation Loss: 0.007056855268284595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.00874122429988347\n",
      "Training Loss: 0.0090008981898427\n",
      "Training Loss: 0.008804435052443296\n",
      "Validation Loss: 0.006891507988931674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008627084923209622\n",
      "Training Loss: 0.008878132118843496\n",
      "Training Loss: 0.008678558685351162\n",
      "Validation Loss: 0.006735586204168418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008521184732671827\n",
      "Training Loss: 0.00876442256849259\n",
      "Training Loss: 0.008561612274497747\n",
      "Validation Loss: 0.006588812846836917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008423097024206072\n",
      "Training Loss: 0.008659399267053232\n",
      "Training Loss: 0.008453245344571769\n",
      "Validation Loss: 0.006451092175145247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008332480789395049\n",
      "Training Loss: 0.00856274160090834\n",
      "Training Loss: 0.008353140188846737\n",
      "Validation Loss: 0.006322382853805935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008248998848721385\n",
      "Training Loss: 0.00847410456975922\n",
      "Training Loss: 0.008260949043324218\n",
      "Validation Loss: 0.006202598952615027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008172280407743529\n",
      "Training Loss: 0.008393085417337716\n",
      "Training Loss: 0.008176264106296002\n",
      "Validation Loss: 0.006091576273647252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008101912990678101\n",
      "Training Loss: 0.008319222851423547\n",
      "Training Loss: 0.008098620885284617\n",
      "Validation Loss: 0.00598905593277154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00803745592595078\n",
      "Training Loss: 0.008252006255788728\n",
      "Training Loss: 0.008027515657013283\n",
      "Validation Loss: 0.00589468151859395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007978449385846034\n",
      "Training Loss: 0.008190901138586924\n",
      "Training Loss: 0.007962423202116042\n",
      "Validation Loss: 0.0058080250622306985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00792444157297723\n",
      "Training Loss: 0.008135373308323323\n",
      "Training Loss: 0.00790282585658133\n",
      "Validation Loss: 0.005728603548663302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007874998961342498\n",
      "Training Loss: 0.008084903203416616\n",
      "Training Loss: 0.007848223891342059\n",
      "Validation Loss: 0.00565589869557095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007829714883118868\n",
      "Training Loss: 0.008039002167060971\n",
      "Training Loss: 0.007798147852299735\n",
      "Validation Loss: 0.005589372971555574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007788215150358155\n",
      "Training Loss: 0.007997216259827838\n",
      "Training Loss: 0.007752160725649446\n",
      "Validation Loss: 0.005528492953764338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007750154555542395\n",
      "Training Loss: 0.007959126560017467\n",
      "Training Loss: 0.007709864972857758\n",
      "Validation Loss: 0.005472737688864215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0077152159047545864\n",
      "Training Loss: 0.007924351637484506\n",
      "Training Loss: 0.00767089192639105\n",
      "Validation Loss: 0.005421605468675327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007683110490906983\n",
      "Training Loss: 0.007892545051872731\n",
      "Training Loss: 0.007634906538296491\n",
      "Validation Loss: 0.005374629113279032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007653570479014889\n",
      "Training Loss: 0.007863392407307402\n",
      "Training Loss: 0.0076016071229241785\n",
      "Validation Loss: 0.005331374638127896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007626351622166112\n",
      "Training Loss: 0.007836610210360959\n",
      "Training Loss: 0.007570718965725973\n",
      "Validation Loss: 0.005291453908652779\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007601227543782443\n",
      "Training Loss: 0.007811943204142153\n",
      "Training Loss: 0.007541991221951321\n",
      "Validation Loss: 0.005254508211968069\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007577992707956583\n",
      "Training Loss: 0.0077891629165969785\n",
      "Training Loss: 0.007515201430069282\n",
      "Validation Loss: 0.005220229100446437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0075564587442204355\n",
      "Training Loss: 0.0077680642413906755\n",
      "Training Loss: 0.00749014952685684\n",
      "Validation Loss: 0.005188338652781598\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0075364539632573726\n",
      "Training Loss: 0.007748465879121796\n",
      "Training Loss: 0.007466654321178794\n",
      "Validation Loss: 0.005158592906278255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007517823087400757\n",
      "Training Loss: 0.007730205808766186\n",
      "Training Loss: 0.007444557357812301\n",
      "Validation Loss: 0.005130785092282412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007500424794270657\n",
      "Training Loss: 0.007713141296990216\n",
      "Training Loss: 0.007423717469209805\n",
      "Validation Loss: 0.005104729604875941\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007484134446713142\n",
      "Training Loss: 0.00769714672700502\n",
      "Training Loss: 0.007404008159646765\n",
      "Validation Loss: 0.005080268052511252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007468837224296294\n",
      "Training Loss: 0.007682109803427011\n",
      "Training Loss: 0.007385318306041881\n",
      "Validation Loss: 0.005057263146860923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.00745443198364228\n",
      "Training Loss: 0.007667932513868436\n",
      "Training Loss: 0.007367547795874998\n",
      "Validation Loss: 0.005035586864425895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007440826522069983\n",
      "Training Loss: 0.007654526279075071\n",
      "Training Loss: 0.007350608244305477\n",
      "Validation Loss: 0.00501513515214509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.0074279383983230215\n",
      "Training Loss: 0.00764181463397108\n",
      "Training Loss: 0.007334422550629824\n",
      "Validation Loss: 0.004995810611597314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007415693191578612\n",
      "Training Loss: 0.007629727344028652\n",
      "Training Loss: 0.0073189193999860435\n",
      "Validation Loss: 0.004977531701697853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007404023333801888\n",
      "Training Loss: 0.007618202999001369\n",
      "Training Loss: 0.007304037514841184\n",
      "Validation Loss: 0.004960216120084266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007392869895556942\n",
      "Training Loss: 0.0076071864739060404\n",
      "Training Loss: 0.007289719723630696\n",
      "Validation Loss: 0.004943795401466947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.0073821775120450185\n",
      "Training Loss: 0.007596627686871216\n",
      "Training Loss: 0.0072759164148010315\n",
      "Validation Loss: 0.004928208730612578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007371896653785371\n",
      "Training Loss: 0.00758648103219457\n",
      "Training Loss: 0.007262582584517076\n",
      "Validation Loss: 0.004913390720043373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.00736198470229283\n",
      "Training Loss: 0.007576707946136594\n",
      "Training Loss: 0.00724967556539923\n",
      "Validation Loss: 0.004899289569519251\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007352399630472064\n",
      "Training Loss: 0.007567269966239109\n",
      "Training Loss: 0.007237160640070215\n",
      "Validation Loss: 0.004885853872519363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.0073431070742662995\n",
      "Training Loss: 0.007558134590508417\n",
      "Training Loss: 0.00722500458243303\n",
      "Validation Loss: 0.004873035053115631\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00733407445368357\n",
      "Training Loss: 0.007549272272735834\n",
      "Training Loss: 0.007213177434168756\n",
      "Validation Loss: 0.004860788026531593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007325271997833624\n",
      "Training Loss: 0.007540655240882188\n",
      "Training Loss: 0.0072016519377939405\n",
      "Validation Loss: 0.00484907292248158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007316674834582954\n",
      "Training Loss: 0.007532260487787426\n",
      "Training Loss: 0.007190404676366597\n",
      "Validation Loss: 0.00483784884975679\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007308259754790924\n",
      "Training Loss: 0.007524064349709079\n",
      "Training Loss: 0.007179413859266788\n",
      "Validation Loss: 0.004827078113991642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007300006796140224\n",
      "Training Loss: 0.007516048651887104\n",
      "Training Loss: 0.007168661126634106\n",
      "Validation Loss: 0.004816728122166118\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00729189854755532\n",
      "Training Loss: 0.007508195425616577\n",
      "Training Loss: 0.0071581292664632205\n",
      "Validation Loss: 0.004806769920874052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007283918844186701\n",
      "Training Loss: 0.007500489004887641\n",
      "Training Loss: 0.007147802223917097\n",
      "Validation Loss: 0.004797169571125022\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007276055276161059\n",
      "Training Loss: 0.007492914940230549\n",
      "Training Loss: 0.007137666766066104\n",
      "Validation Loss: 0.004787901425577198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007268295606481842\n",
      "Training Loss: 0.007485461749602109\n",
      "Training Loss: 0.007127711399225518\n",
      "Validation Loss: 0.004778940775405532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007260629938100465\n",
      "Training Loss: 0.007478117621503771\n",
      "Training Loss: 0.007117925226921216\n",
      "Validation Loss: 0.004770262828724605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007253050680737942\n",
      "Training Loss: 0.007470873821293935\n",
      "Training Loss: 0.0071082986774854365\n",
      "Validation Loss: 0.004761845439808506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007245550259831361\n",
      "Training Loss: 0.007463721277890727\n",
      "Training Loss: 0.007098824905697256\n",
      "Validation Loss: 0.004753673026662613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007238122809212655\n",
      "Training Loss: 0.007456652979599312\n",
      "Training Loss: 0.007089495224645362\n",
      "Validation Loss: 0.004745719590737076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0072307645517867055\n",
      "Training Loss: 0.007449661910068244\n",
      "Training Loss: 0.007080303290858864\n",
      "Validation Loss: 0.004737976018281842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.00722347081755288\n",
      "Training Loss: 0.007442742761923\n",
      "Training Loss: 0.007071244408143685\n",
      "Validation Loss: 0.0047304226357615395\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007216238544206135\n",
      "Training Loss: 0.007435890999622643\n",
      "Training Loss: 0.007062313087517396\n",
      "Validation Loss: 0.004723046600211705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0072090650431346145\n",
      "Training Loss: 0.007429101187735796\n",
      "Training Loss: 0.007053505206713453\n",
      "Validation Loss: 0.004715839202065816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007201949324226007\n",
      "Training Loss: 0.007422370824497193\n",
      "Training Loss: 0.007044815733097494\n",
      "Validation Loss: 0.004708784410018432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007194888792000711\n",
      "Training Loss: 0.00741569550591521\n",
      "Training Loss: 0.007036241296445951\n",
      "Validation Loss: 0.00470187150601172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007187883257865906\n",
      "Training Loss: 0.007409072685986757\n",
      "Training Loss: 0.007027779167983681\n",
      "Validation Loss: 0.00469509514344312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007180932465125807\n",
      "Training Loss: 0.007402499436866492\n",
      "Training Loss: 0.007019425680628046\n",
      "Validation Loss: 0.004688443110476175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00717403317335993\n",
      "Training Loss: 0.007395973947132007\n",
      "Training Loss: 0.007011178062530234\n",
      "Validation Loss: 0.0046819103253858815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007167187221930362\n",
      "Training Loss: 0.007389493526425213\n",
      "Training Loss: 0.007003032779321075\n",
      "Validation Loss: 0.004675488110652633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007160394453094341\n",
      "Training Loss: 0.007383055743994191\n",
      "Training Loss: 0.006994988252408803\n",
      "Validation Loss: 0.004669169425111515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007153652503620833\n",
      "Training Loss: 0.007376659204019234\n",
      "Training Loss: 0.00698704085429199\n",
      "Validation Loss: 0.0046629483185007415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0071469618665287275\n",
      "Training Loss: 0.007370302130002528\n",
      "Training Loss: 0.006979188953991979\n",
      "Validation Loss: 0.004656820867362359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007140323535422794\n",
      "Training Loss: 0.007363982370588928\n",
      "Training Loss: 0.006971428875112906\n",
      "Validation Loss: 0.004650782572047973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007133734927047044\n",
      "Training Loss: 0.0073576978722121565\n",
      "Training Loss: 0.006963757305638865\n",
      "Validation Loss: 0.00464482686032405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007127197860390879\n",
      "Training Loss: 0.007351447596447542\n",
      "Training Loss: 0.006956173770595342\n",
      "Validation Loss: 0.004638948462108213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.0071207101410254835\n",
      "Training Loss: 0.007345230185892433\n",
      "Training Loss: 0.006948674188461155\n",
      "Validation Loss: 0.004633146635089279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007114271590835415\n",
      "Training Loss: 0.007339043086394667\n",
      "Training Loss: 0.006941256913123652\n",
      "Validation Loss: 0.004627418190272253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.0071078816789668054\n",
      "Training Loss: 0.007332885587820783\n",
      "Training Loss: 0.006933918655849993\n",
      "Validation Loss: 0.004621756606437056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007101539771538228\n",
      "Training Loss: 0.007326754520181567\n",
      "Training Loss: 0.0069266560347750784\n",
      "Validation Loss: 0.004616160413349738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007095245427917689\n",
      "Training Loss: 0.007320649703033268\n",
      "Training Loss: 0.006919467567931861\n",
      "Validation Loss: 0.004610625295141147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0070889972493750975\n",
      "Training Loss: 0.0073145692504476756\n",
      "Training Loss: 0.006912350023631006\n",
      "Validation Loss: 0.004605149113170258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007082794265006669\n",
      "Training Loss: 0.007308510584989563\n",
      "Training Loss: 0.00690530079882592\n",
      "Validation Loss: 0.004599730295830228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007076635530684144\n",
      "Training Loss: 0.007302473245654255\n",
      "Training Loss: 0.0068983185850083825\n",
      "Validation Loss: 0.0045943662813299575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00707052034616936\n",
      "Training Loss: 0.007296455430332571\n",
      "Training Loss: 0.006891399091109633\n",
      "Validation Loss: 0.004589053173680277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007064447396551259\n",
      "Training Loss: 0.007290455233305693\n",
      "Training Loss: 0.006884539732709527\n",
      "Validation Loss: 0.004583790131813187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007058414519415237\n",
      "Training Loss: 0.007284470772137865\n",
      "Training Loss: 0.0068777384294662625\n",
      "Validation Loss: 0.0045785751622798064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007052421664702706\n",
      "Training Loss: 0.007278500364627689\n",
      "Training Loss: 0.006870992627227679\n",
      "Validation Loss: 0.004573405318726064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00704646717873402\n",
      "Training Loss: 0.0072725431795697655\n",
      "Training Loss: 0.006864299225853756\n",
      "Validation Loss: 0.004568277715621621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007040549326338805\n",
      "Training Loss: 0.007266596332192421\n",
      "Training Loss: 0.006857656425563618\n",
      "Validation Loss: 0.004563190554415159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007034667331608944\n",
      "Training Loss: 0.007260659375460819\n",
      "Training Loss: 0.006851060835178942\n",
      "Validation Loss: 0.004558142252381514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007028819671249948\n",
      "Training Loss: 0.007254730538697914\n",
      "Training Loss: 0.006844510340597481\n",
      "Validation Loss: 0.004553131145043194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007023004570510238\n",
      "Training Loss: 0.007248807966243475\n",
      "Training Loss: 0.006838003095472231\n",
      "Validation Loss: 0.004548152796191613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0070172202016692605\n",
      "Training Loss: 0.007242890575435012\n",
      "Training Loss: 0.006831535955425352\n",
      "Validation Loss: 0.0045432098951515105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.007011466280091554\n",
      "Training Loss: 0.0072369761753361675\n",
      "Training Loss: 0.006825106865726412\n",
      "Validation Loss: 0.004538296334042601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007005739846499636\n",
      "Training Loss: 0.007231063280487433\n",
      "Training Loss: 0.006818713290849701\n",
      "Validation Loss: 0.004533414800227568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0070000396831892435\n",
      "Training Loss: 0.0072251507441978904\n",
      "Training Loss: 0.006812352522974834\n",
      "Validation Loss: 0.004528558663919233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006994365635327995\n",
      "Training Loss: 0.007219237125245854\n",
      "Training Loss: 0.006806022865930572\n",
      "Validation Loss: 0.0045237275882979875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006988715206971392\n",
      "Training Loss: 0.007213320423616097\n",
      "Training Loss: 0.00679972241865471\n",
      "Validation Loss: 0.004518919551792146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006983086836989969\n",
      "Training Loss: 0.007207399751059711\n",
      "Training Loss: 0.0067934486456215385\n",
      "Validation Loss: 0.004514133297377841\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006977479322813451\n",
      "Training Loss: 0.00720147363608703\n",
      "Training Loss: 0.006787199107930064\n",
      "Validation Loss: 0.004509367528790085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006971890537533909\n",
      "Training Loss: 0.007195539909880608\n",
      "Training Loss: 0.006780973008135334\n",
      "Validation Loss: 0.004504619162984904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.0069663197651971135\n",
      "Training Loss: 0.007189598120748997\n",
      "Training Loss: 0.006774765792069957\n",
      "Validation Loss: 0.0044998874831578455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006960764224641025\n",
      "Training Loss: 0.007183645954355598\n",
      "Training Loss: 0.006768577091861516\n",
      "Validation Loss: 0.004495172535090216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0069552246516104786\n",
      "Training Loss: 0.007177683542249724\n",
      "Training Loss: 0.006762404300970957\n",
      "Validation Loss: 0.0044904675614611984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006949697595555335\n",
      "Training Loss: 0.007171707692323253\n",
      "Training Loss: 0.006756245534634217\n",
      "Validation Loss: 0.004485771104463198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006944182737497613\n",
      "Training Loss: 0.0071657176641747354\n",
      "Training Loss: 0.0067500996636226775\n",
      "Validation Loss: 0.004481083099348366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006938676919671707\n",
      "Training Loss: 0.00715971204568632\n",
      "Training Loss: 0.006743963656481356\n",
      "Validation Loss: 0.004476404517334415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006933180493069813\n",
      "Training Loss: 0.007153689997503534\n",
      "Training Loss: 0.0067378360161092134\n",
      "Validation Loss: 0.004471729679577304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006927691519376822\n",
      "Training Loss: 0.00714765002951026\n",
      "Training Loss: 0.006731715375790373\n",
      "Validation Loss: 0.004467058918318513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006922208067262545\n",
      "Training Loss: 0.007141589820384979\n",
      "Training Loss: 0.006725599424680695\n",
      "Validation Loss: 0.004462387582177318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.00691672905057203\n",
      "Training Loss: 0.007135509374784306\n",
      "Training Loss: 0.006719486383954063\n",
      "Validation Loss: 0.004457718169505007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006911253407597542\n",
      "Training Loss: 0.007129407105967402\n",
      "Training Loss: 0.0067133735166862605\n",
      "Validation Loss: 0.004453044828142594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006905778291984461\n",
      "Training Loss: 0.007123279618099332\n",
      "Training Loss: 0.006707260686671362\n",
      "Validation Loss: 0.004448368074110804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.00690030287776608\n",
      "Training Loss: 0.0071171286678873005\n",
      "Training Loss: 0.006701145751867444\n",
      "Validation Loss: 0.004443685969552339\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006894827354699373\n",
      "Training Loss: 0.007110951048089191\n",
      "Training Loss: 0.006695026105735451\n",
      "Validation Loss: 0.004438997475885566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0068893483059946446\n",
      "Training Loss: 0.0071047451731283216\n",
      "Training Loss: 0.0066889002500101925\n",
      "Validation Loss: 0.004434298317136473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006883865233394317\n",
      "Training Loss: 0.0070985112036578354\n",
      "Training Loss: 0.00668276718002744\n",
      "Validation Loss: 0.0044295891002343775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.0068783763941610235\n",
      "Training Loss: 0.007092246365500614\n",
      "Training Loss: 0.006676624463871121\n",
      "Validation Loss: 0.00442486586640432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006872880554292351\n",
      "Training Loss: 0.0070859504549298435\n",
      "Training Loss: 0.006670470914104954\n",
      "Validation Loss: 0.004420129864821943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.00686737693962641\n",
      "Training Loss: 0.007079620942240581\n",
      "Training Loss: 0.00666430493351072\n",
      "Validation Loss: 0.004415379478753115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006861863150261343\n",
      "Training Loss: 0.007073257312877104\n",
      "Training Loss: 0.006658124108798802\n",
      "Validation Loss: 0.004410609926013381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006856337992940098\n",
      "Training Loss: 0.007066857271129265\n",
      "Training Loss: 0.006651927150087431\n",
      "Validation Loss: 0.0044058204812960425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006850801011314616\n",
      "Training Loss: 0.007060419942717999\n",
      "Training Loss: 0.006645712924655527\n",
      "Validation Loss: 0.004401010991560735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006845249732141383\n",
      "Training Loss: 0.007053944901563227\n",
      "Training Loss: 0.006639478608267382\n",
      "Validation Loss: 0.004396177323409513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006839683286962099\n",
      "Training Loss: 0.007047429078957066\n",
      "Training Loss: 0.006633224198594689\n",
      "Validation Loss: 0.004391320760681011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006834100864361972\n",
      "Training Loss: 0.007040871711215004\n",
      "Training Loss: 0.006626947129843757\n",
      "Validation Loss: 0.004386437164745137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006828499314142391\n",
      "Training Loss: 0.007034270960139111\n",
      "Training Loss: 0.006620645597577095\n",
      "Validation Loss: 0.004381529188301581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006822879077517428\n",
      "Training Loss: 0.007027626222698018\n",
      "Training Loss: 0.006614318747306242\n",
      "Validation Loss: 0.0043765899890071056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006817238717339933\n",
      "Training Loss: 0.007020935820182785\n",
      "Training Loss: 0.006607964102877304\n",
      "Validation Loss: 0.004371619998514024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.0068115752615267415\n",
      "Training Loss: 0.007014197274111211\n",
      "Training Loss: 0.006601580361602828\n",
      "Validation Loss: 0.0043666183816405075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006805889355018735\n",
      "Training Loss: 0.007007409905781969\n",
      "Training Loss: 0.006595166106708347\n",
      "Validation Loss: 0.004361582123360523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006800177990808152\n",
      "Training Loss: 0.007000572112156078\n",
      "Training Loss: 0.006588719380088151\n",
      "Validation Loss: 0.004356510853499509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006794440781231969\n",
      "Training Loss: 0.006993681128369645\n",
      "Training Loss: 0.006582238863920793\n",
      "Validation Loss: 0.004351406537383543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.00678867622744292\n",
      "Training Loss: 0.006986736765829846\n",
      "Training Loss: 0.0065757228748407216\n",
      "Validation Loss: 0.0043462605700890925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006782881116960198\n",
      "Training Loss: 0.006979736364446581\n",
      "Training Loss: 0.006569169217254966\n",
      "Validation Loss: 0.004341074143892175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006777056391001679\n",
      "Training Loss: 0.006972678886959329\n",
      "Training Loss: 0.0065625762671697885\n",
      "Validation Loss: 0.004335846730999732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006771199582144618\n",
      "Training Loss: 0.006965562833938748\n",
      "Training Loss: 0.006555943370331079\n",
      "Validation Loss: 0.004330577387008816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006765309415059164\n",
      "Training Loss: 0.006958386027254165\n",
      "Training Loss: 0.006549267857335508\n",
      "Validation Loss: 0.00432526294777714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006759384163306095\n",
      "Training Loss: 0.006951146584469825\n",
      "Training Loss: 0.006542547438293696\n",
      "Validation Loss: 0.0043199012086077935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006753422790206969\n",
      "Training Loss: 0.0069438422657549384\n",
      "Training Loss: 0.006535781422862783\n",
      "Validation Loss: 0.004314492794088601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006747422815533355\n",
      "Training Loss: 0.006936471255030483\n",
      "Training Loss: 0.006528967794729397\n",
      "Validation Loss: 0.00430903586184899\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006741383484331891\n",
      "Training Loss: 0.00692903243470937\n",
      "Training Loss: 0.00652210402302444\n",
      "Validation Loss: 0.0043035246800694075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.0067353023058967666\n",
      "Training Loss: 0.006921522937482223\n",
      "Training Loss: 0.006515188629273325\n",
      "Validation Loss: 0.004297963342252659\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.00672917905729264\n",
      "Training Loss: 0.006913940680678934\n",
      "Training Loss: 0.00650822080206126\n",
      "Validation Loss: 0.0042923464161197375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006723010467831045\n",
      "Training Loss: 0.0069062843034043905\n",
      "Training Loss: 0.006501195798628032\n",
      "Validation Loss: 0.004286671484417669\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006716795525280758\n",
      "Training Loss: 0.006898550890618935\n",
      "Training Loss: 0.00649411445017904\n",
      "Validation Loss: 0.004280940458843003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.00671053264522925\n",
      "Training Loss: 0.006890738274669275\n",
      "Training Loss: 0.0064869720581918955\n",
      "Validation Loss: 0.004275148417905308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.00670421855407767\n",
      "Training Loss: 0.006882843740750104\n",
      "Training Loss: 0.0064797679975163195\n",
      "Validation Loss: 0.004269291792624745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.0066978532733628525\n",
      "Training Loss: 0.006874865430872888\n",
      "Training Loss: 0.006472499340306967\n",
      "Validation Loss: 0.004263373753683788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006691433388623409\n",
      "Training Loss: 0.00686679971171543\n",
      "Training Loss: 0.006465164454421028\n",
      "Validation Loss: 0.004257388260566075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.00668495696154423\n",
      "Training Loss: 0.0068586451606824994\n",
      "Training Loss: 0.006457760386401787\n",
      "Validation Loss: 0.004251332699813032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006678422365803271\n",
      "Training Loss: 0.006850399044342339\n",
      "Training Loss: 0.006450283256126568\n",
      "Validation Loss: 0.004245204783013362\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006671826438978314\n",
      "Training Loss: 0.006842056965688244\n",
      "Training Loss: 0.006442732585128397\n",
      "Validation Loss: 0.004239004779622754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006665168130421079\n",
      "Training Loss: 0.006833617306547239\n",
      "Training Loss: 0.0064351043081842365\n",
      "Validation Loss: 0.004232727720407413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0066584441420855\n",
      "Training Loss: 0.006825077383546159\n",
      "Training Loss: 0.0064273966115433725\n",
      "Validation Loss: 0.0042263724804552415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006651651218417101\n",
      "Training Loss: 0.006816432778723538\n",
      "Training Loss: 0.006419606363633648\n",
      "Validation Loss: 0.004219934830227553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006644787672557868\n",
      "Training Loss: 0.006807680426863954\n",
      "Training Loss: 0.0064117285737302155\n",
      "Validation Loss: 0.004213413745531121\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.006637849672115408\n",
      "Training Loss: 0.006798816692316904\n",
      "Training Loss: 0.006403761593392118\n",
      "Validation Loss: 0.0042068017188857275\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006630834810202942\n",
      "Training Loss: 0.006789838908007368\n",
      "Training Loss: 0.0063957015972118825\n",
      "Validation Loss: 0.0042000973297628376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.0066237403033301235\n",
      "Training Loss: 0.006780742655973881\n",
      "Training Loss: 0.006387544439639896\n",
      "Validation Loss: 0.004193295351899324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006616562110721134\n",
      "Training Loss: 0.006771523612551391\n",
      "Training Loss: 0.006379287281306461\n",
      "Validation Loss: 0.0041863952195690425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006609297212562524\n",
      "Training Loss: 0.006762179194483906\n",
      "Training Loss: 0.006370926520321518\n",
      "Validation Loss: 0.004179391318021782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006601941536646336\n",
      "Training Loss: 0.006752703009406105\n",
      "Training Loss: 0.006362456950591877\n",
      "Validation Loss: 0.004172279838252854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006594491153373383\n",
      "Training Loss: 0.006743092079996131\n",
      "Training Loss: 0.0063538741448428485\n",
      "Validation Loss: 0.0041650531537506435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.00658694205863867\n",
      "Training Loss: 0.006733341607032344\n",
      "Training Loss: 0.006345174132147804\n",
      "Validation Loss: 0.00415770955360233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00657928925822489\n",
      "Training Loss: 0.00672344682214316\n",
      "Training Loss: 0.006336352226790041\n",
      "Validation Loss: 0.0041502406755253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006571529543143697\n",
      "Training Loss: 0.006713402882451191\n",
      "Training Loss: 0.0063274034322239455\n",
      "Validation Loss: 0.00414264316440382\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006563656947109848\n",
      "Training Loss: 0.0067032042663777245\n",
      "Training Loss: 0.006318322336301208\n",
      "Validation Loss: 0.004134911267489739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006555667638313025\n",
      "Training Loss: 0.006692846834193915\n",
      "Training Loss: 0.0063091046013869344\n",
      "Validation Loss: 0.0041270371587957475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006547555328579619\n",
      "Training Loss: 0.006682325216243044\n",
      "Training Loss: 0.006299743262352422\n",
      "Validation Loss: 0.004119013630382172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006539314707624726\n",
      "Training Loss: 0.006671632087090984\n",
      "Training Loss: 0.006290233283070847\n",
      "Validation Loss: 0.004110833584838495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006530940328957513\n",
      "Training Loss: 0.006660763755789958\n",
      "Training Loss: 0.006280568642541767\n",
      "Validation Loss: 0.004102491440769452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006522424741997383\n",
      "Training Loss: 0.006649712933576666\n",
      "Training Loss: 0.006270743138156831\n",
      "Validation Loss: 0.004093978939227383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006513763314578682\n",
      "Training Loss: 0.006638475030194968\n",
      "Training Loss: 0.006260751432273537\n",
      "Validation Loss: 0.004085286542004121\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006504947924404405\n",
      "Training Loss: 0.006627044132910669\n",
      "Training Loss: 0.006250585203524679\n",
      "Validation Loss: 0.00407640643619273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006495972891571\n",
      "Training Loss: 0.006615412788232788\n",
      "Training Loss: 0.006240239004837349\n",
      "Validation Loss: 0.004067327749386974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006486830227659084\n",
      "Training Loss: 0.006603576993220486\n",
      "Training Loss: 0.006229705805890262\n",
      "Validation Loss: 0.004058040552929546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006477512259734795\n",
      "Training Loss: 0.006591528709977865\n",
      "Training Loss: 0.006218978622928262\n",
      "Validation Loss: 0.004048539192829114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.0064680123812286185\n",
      "Training Loss: 0.006579265430336818\n",
      "Training Loss: 0.006208051224239171\n",
      "Validation Loss: 0.0040388113264454885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006458321737591177\n",
      "Training Loss: 0.0065667781146476045\n",
      "Training Loss: 0.006196916959015653\n",
      "Validation Loss: 0.004028847639898906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006448433471960015\n",
      "Training Loss: 0.006554063586518169\n",
      "Training Loss: 0.0061855683533940465\n",
      "Validation Loss: 0.004018636372625786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006438339955639094\n",
      "Training Loss: 0.006541115418076515\n",
      "Training Loss: 0.006173999883467332\n",
      "Validation Loss: 0.00400817048607729\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006428031651885249\n",
      "Training Loss: 0.006527929031290114\n",
      "Training Loss: 0.006162203641142696\n",
      "Validation Loss: 0.0039974388030744835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.0064175021508708595\n",
      "Training Loss: 0.006514501139172353\n",
      "Training Loss: 0.006150176328374073\n",
      "Validation Loss: 0.0039864327376603744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006406743314582855\n",
      "Training Loss: 0.006500827251002193\n",
      "Training Loss: 0.0061379102186765525\n",
      "Validation Loss: 0.003975140595327268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006395748413633555\n",
      "Training Loss: 0.006486903332406655\n",
      "Training Loss: 0.006125400976161472\n",
      "Validation Loss: 0.003963555028829514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006384510197094641\n",
      "Training Loss: 0.006472728149965405\n",
      "Training Loss: 0.006112643925007433\n",
      "Validation Loss: 0.00395166766803628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006373021032777615\n",
      "Training Loss: 0.006458298727520742\n",
      "Training Loss: 0.006099635317223146\n",
      "Validation Loss: 0.003939472554837552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006361277039395645\n",
      "Training Loss: 0.006443615814205259\n",
      "Training Loss: 0.006086373781436123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [31:20<03:29, 209.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.003926964689260662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.23635491617023946\n",
      "Training Loss: 0.18011668197810649\n",
      "Training Loss: 0.13378145154565574\n",
      "Validation Loss: 0.09515253912783071\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.07829450322315097\n",
      "Training Loss: 0.0630861720070243\n",
      "Training Loss: 0.05655861735343933\n",
      "Validation Loss: 0.05390147816682799\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05288561233319342\n",
      "Training Loss: 0.05165079396218061\n",
      "Training Loss: 0.05027166717685759\n",
      "Validation Loss: 0.04856400317355488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.047679076911881564\n",
      "Training Loss: 0.0461440435051918\n",
      "Training Loss: 0.044284603418782355\n",
      "Validation Loss: 0.04181677002585336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.04074254467152059\n",
      "Training Loss: 0.03885647348128259\n",
      "Training Loss: 0.03648285015486181\n",
      "Validation Loss: 0.03323279649772671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.032038790974766015\n",
      "Training Loss: 0.03012986919376999\n",
      "Training Loss: 0.027705803271383046\n",
      "Validation Loss: 0.02430897259435962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.02351748290937394\n",
      "Training Loss: 0.022344746766611932\n",
      "Training Loss: 0.020597552387043833\n",
      "Validation Loss: 0.01782254451948605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01770665100309998\n",
      "Training Loss: 0.017453608657233416\n",
      "Training Loss: 0.01645777626428753\n",
      "Validation Loss: 0.014323927464717057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.014682688128668814\n",
      "Training Loss: 0.014966928625945002\n",
      "Training Loss: 0.01439346965868026\n",
      "Validation Loss: 0.012550668524096855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013167066760361194\n",
      "Training Loss: 0.013604107080027461\n",
      "Training Loss: 0.013168166799005121\n",
      "Validation Loss: 0.011346123772516344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.012109041346702725\n",
      "Training Loss: 0.012509211478754879\n",
      "Training Loss: 0.012112651758361608\n",
      "Validation Loss: 0.010265503337690503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.011176871142815799\n",
      "Training Loss: 0.01156829692190513\n",
      "Training Loss: 0.011278987287078053\n",
      "Validation Loss: 0.009472494194116653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.010551711171865463\n",
      "Training Loss: 0.010970616999547928\n",
      "Training Loss: 0.010763075427385048\n",
      "Validation Loss: 0.008963452467663486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.010177000812254845\n",
      "Training Loss: 0.010591607007663697\n",
      "Training Loss: 0.010406710596289486\n",
      "Validation Loss: 0.008583552163523318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009904037246014923\n",
      "Training Loss: 0.010302103681024164\n",
      "Training Loss: 0.010121641680598259\n",
      "Validation Loss: 0.008268269112469692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.009679301681462676\n",
      "Training Loss: 0.01005915462039411\n",
      "Training Loss: 0.009879243015311658\n",
      "Validation Loss: 0.007995548072072227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.009485059964936227\n",
      "Training Loss: 0.009847148419357837\n",
      "Training Loss: 0.00966675060801208\n",
      "Validation Loss: 0.007754601509404484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00931267452193424\n",
      "Training Loss: 0.00965810675639659\n",
      "Training Loss: 0.009476734108757228\n",
      "Validation Loss: 0.007538723254450754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009156969774048776\n",
      "Training Loss: 0.00948715551290661\n",
      "Training Loss: 0.009304471351206302\n",
      "Validation Loss: 0.007343400987859271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009014687683666124\n",
      "Training Loss: 0.009331151406513527\n",
      "Training Loss: 0.00914689188823104\n",
      "Validation Loss: 0.007165526916283403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008883767126826569\n",
      "Training Loss: 0.009188045148039236\n",
      "Training Loss: 0.009001982102636247\n",
      "Validation Loss: 0.007002954137134837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008762910384684802\n",
      "Training Loss: 0.009056486878544092\n",
      "Training Loss: 0.00886840994702652\n",
      "Validation Loss: 0.0068541905369211955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008651301468489692\n",
      "Training Loss: 0.008935587096493692\n",
      "Training Loss: 0.008745289518265054\n",
      "Validation Loss: 0.006718182071698097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008548426406923682\n",
      "Training Loss: 0.008824736553942785\n",
      "Training Loss: 0.008632001146906987\n",
      "Validation Loss: 0.006594143558052902\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008453928863164038\n",
      "Training Loss: 0.008723473026184364\n",
      "Training Loss: 0.008528079175157473\n",
      "Validation Loss: 0.00648144442520073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008367528084199875\n",
      "Training Loss: 0.008631397064309567\n",
      "Training Loss: 0.008433112313505263\n",
      "Validation Loss: 0.006379485408922009\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.00828893986530602\n",
      "Training Loss: 0.008548095532460139\n",
      "Training Loss: 0.008346688527381048\n",
      "Validation Loss: 0.006287661956602268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008217839411227033\n",
      "Training Loss: 0.008473110758932307\n",
      "Training Loss: 0.008268352751620113\n",
      "Validation Loss: 0.006205299661201791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.00815383069915697\n",
      "Training Loss: 0.008405907405540347\n",
      "Training Loss: 0.00819758408353664\n",
      "Validation Loss: 0.006131649354807614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.008096435053739698\n",
      "Training Loss: 0.008345880351262167\n",
      "Training Loss: 0.008133793282322586\n",
      "Validation Loss: 0.006065901960089301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.008045111544197426\n",
      "Training Loss: 0.00829236751771532\n",
      "Training Loss: 0.008076346133602783\n",
      "Validation Loss: 0.006007201201805657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00799926970852539\n",
      "Training Loss: 0.00824467397062108\n",
      "Training Loss: 0.008024578732438385\n",
      "Validation Loss: 0.005954690047361878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007958298004232346\n",
      "Training Loss: 0.008202102922368795\n",
      "Training Loss: 0.007977827158756555\n",
      "Validation Loss: 0.005907528583755654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007921590961050242\n",
      "Training Loss: 0.008163981225807219\n",
      "Training Loss: 0.007935452313395217\n",
      "Validation Loss: 0.005864927945449279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007888569473288953\n",
      "Training Loss: 0.008129679332487285\n",
      "Training Loss: 0.007896856417646632\n",
      "Validation Loss: 0.005826171639302139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007858699505450205\n",
      "Training Loss: 0.008098627679282799\n",
      "Training Loss: 0.007861496643163263\n",
      "Validation Loss: 0.005790617327425587\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00783150108763948\n",
      "Training Loss: 0.008070321513805538\n",
      "Training Loss: 0.007828891411190853\n",
      "Validation Loss: 0.005757713516431159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007806553699774668\n",
      "Training Loss: 0.008044322442729027\n",
      "Training Loss: 0.007798621658002958\n",
      "Validation Loss: 0.005726982048042955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007783491347217932\n",
      "Training Loss: 0.008020257968455553\n",
      "Training Loss: 0.007770323731238022\n",
      "Validation Loss: 0.0056980253037672195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007762003662064671\n",
      "Training Loss: 0.007997807427309454\n",
      "Training Loss: 0.007743689425988123\n",
      "Validation Loss: 0.005670501718433637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007741824584081769\n",
      "Training Loss: 0.007976703589083627\n",
      "Training Loss: 0.0077184532082173974\n",
      "Validation Loss: 0.005644132848829031\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007722731576068327\n",
      "Training Loss: 0.007956720360089093\n",
      "Training Loss: 0.007694390431279317\n",
      "Validation Loss: 0.005618683466677334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007704535337397829\n",
      "Training Loss: 0.007937665707431733\n",
      "Training Loss: 0.007671305248513818\n",
      "Validation Loss: 0.005593957951072645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007687075473368168\n",
      "Training Loss: 0.007919378540245816\n",
      "Training Loss: 0.007649029029998929\n",
      "Validation Loss: 0.005569794210683806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007670217428822071\n",
      "Training Loss: 0.007901717750355601\n",
      "Training Loss: 0.007627416999312118\n",
      "Validation Loss: 0.005546057732184574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007653846562607214\n",
      "Training Loss: 0.00788456948241219\n",
      "Training Loss: 0.007606348296394572\n",
      "Validation Loss: 0.005522647757459892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0076378734188620005\n",
      "Training Loss: 0.007867840048857034\n",
      "Training Loss: 0.007585727662080899\n",
      "Validation Loss: 0.00549949156944483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007622232676949352\n",
      "Training Loss: 0.00785146255744621\n",
      "Training Loss: 0.007565496030729264\n",
      "Validation Loss: 0.0054765547458291725\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007606890313327313\n",
      "Training Loss: 0.007835400586482138\n",
      "Training Loss: 0.007545637167058885\n",
      "Validation Loss: 0.005453844004038596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007591846294235438\n",
      "Training Loss: 0.007819655776256696\n",
      "Training Loss: 0.007526175681268796\n",
      "Validation Loss: 0.0054314038088398705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007577128262491897\n",
      "Training Loss: 0.007804258794058114\n",
      "Training Loss: 0.0075071546703111385\n",
      "Validation Loss: 0.005409291160575459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007562768096104264\n",
      "Training Loss: 0.007789245870662853\n",
      "Training Loss: 0.007488603269448504\n",
      "Validation Loss: 0.005387562013157968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007548783051315695\n",
      "Training Loss: 0.007774638799019158\n",
      "Training Loss: 0.00747052718535997\n",
      "Validation Loss: 0.005366241275542154\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007535175115335733\n",
      "Training Loss: 0.007760442636208609\n",
      "Training Loss: 0.007452919859206304\n",
      "Validation Loss: 0.005345342275320312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007521937169367447\n",
      "Training Loss: 0.007746657159877941\n",
      "Training Loss: 0.0074357717472594235\n",
      "Validation Loss: 0.005324870197552393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007509074363624677\n",
      "Training Loss: 0.007733287722803652\n",
      "Training Loss: 0.007419080274412408\n",
      "Validation Loss: 0.005304823322823334\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007496610967209562\n",
      "Training Loss: 0.007720352712785825\n",
      "Training Loss: 0.007402849327772856\n",
      "Validation Loss: 0.005285214295275928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007484595847781748\n",
      "Training Loss: 0.00770788720343262\n",
      "Training Loss: 0.007387097680475563\n",
      "Validation Loss: 0.005266061571970833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0074730951653327795\n",
      "Training Loss: 0.007695940147386864\n",
      "Training Loss: 0.007371863513253629\n",
      "Validation Loss: 0.00524740254446299\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.0074621735140681265\n",
      "Training Loss: 0.007684561344794929\n",
      "Training Loss: 0.007357177878729999\n",
      "Validation Loss: 0.005229264788141244\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0074518436670769\n",
      "Training Loss: 0.007673757469747216\n",
      "Training Loss: 0.007343027238966897\n",
      "Validation Loss: 0.005211640209524652\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007442039357265458\n",
      "Training Loss: 0.007663483512587845\n",
      "Training Loss: 0.007329375382978469\n",
      "Validation Loss: 0.005194478767683332\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007432654935400933\n",
      "Training Loss: 0.007653665069956333\n",
      "Training Loss: 0.007316190784331411\n",
      "Validation Loss: 0.005177702793323048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007423602256458253\n",
      "Training Loss: 0.007644232899183407\n",
      "Training Loss: 0.007303438828093931\n",
      "Validation Loss: 0.005161243963076241\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007414820961421356\n",
      "Training Loss: 0.007635130987036973\n",
      "Training Loss: 0.007291083037853241\n",
      "Validation Loss: 0.005145052370086857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007406272389926016\n",
      "Training Loss: 0.007626318731345236\n",
      "Training Loss: 0.0072790844703558835\n",
      "Validation Loss: 0.005129095064894704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007397932502208278\n",
      "Training Loss: 0.007617764302995056\n",
      "Training Loss: 0.0072674110019579526\n",
      "Validation Loss: 0.00511334391554106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007389784129918553\n",
      "Training Loss: 0.007609443496912718\n",
      "Training Loss: 0.007256033609155566\n",
      "Validation Loss: 0.005097783117010938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007381814398104325\n",
      "Training Loss: 0.0076013362174853685\n",
      "Training Loss: 0.007244924843544141\n",
      "Validation Loss: 0.005082394858414119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007374012144864537\n",
      "Training Loss: 0.007593424946535378\n",
      "Training Loss: 0.007234064607182518\n",
      "Validation Loss: 0.005067168116920073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007366368895745836\n",
      "Training Loss: 0.0075856951647438105\n",
      "Training Loss: 0.0072234332899097356\n",
      "Validation Loss: 0.005052093706182675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007358875247300603\n",
      "Training Loss: 0.007578133426140994\n",
      "Training Loss: 0.007213013547589071\n",
      "Validation Loss: 0.005037160517040933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007351521714008413\n",
      "Training Loss: 0.007570726367412135\n",
      "Training Loss: 0.007202790793962776\n",
      "Validation Loss: 0.005022356609730155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007344302969868295\n",
      "Training Loss: 0.007563464081613347\n",
      "Training Loss: 0.007192751802504063\n",
      "Validation Loss: 0.005007678871775527\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007337210278492421\n",
      "Training Loss: 0.007556335367262364\n",
      "Training Loss: 0.007182883758214302\n",
      "Validation Loss: 0.004993117592307959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007330237367423251\n",
      "Training Loss: 0.007549332224298269\n",
      "Training Loss: 0.0071731740119867025\n",
      "Validation Loss: 0.0049786651585502235\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.00732337671215646\n",
      "Training Loss: 0.007542443859856576\n",
      "Training Loss: 0.007163613615557551\n",
      "Validation Loss: 0.0049643149963067325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.0073166228563059125\n",
      "Training Loss: 0.007535660915309563\n",
      "Training Loss: 0.007154192304005847\n",
      "Validation Loss: 0.0049500603796495644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007309967812616378\n",
      "Training Loss: 0.007528976700268686\n",
      "Training Loss: 0.007144900254206732\n",
      "Validation Loss: 0.004935896692515006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007303406985010951\n",
      "Training Loss: 0.007522381715243682\n",
      "Training Loss: 0.007135730430018156\n",
      "Validation Loss: 0.004921817948016223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007296932293102145\n",
      "Training Loss: 0.007515869012568146\n",
      "Training Loss: 0.007126673200400546\n",
      "Validation Loss: 0.004907816951293917\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0072905404260382055\n",
      "Training Loss: 0.007509430315112695\n",
      "Training Loss: 0.007117721965187229\n",
      "Validation Loss: 0.004893893377954831\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0072842243034392596\n",
      "Training Loss: 0.0075030575285200025\n",
      "Training Loss: 0.007108866397175007\n",
      "Validation Loss: 0.004880034821918967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007277977432240732\n",
      "Training Loss: 0.0074967437086161225\n",
      "Training Loss: 0.0071001016930677\n",
      "Validation Loss: 0.004866244342031606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.00727179431996774\n",
      "Training Loss: 0.007490481906570494\n",
      "Training Loss: 0.007091421034419909\n",
      "Validation Loss: 0.004852512563589249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007265671322238631\n",
      "Training Loss: 0.007484264500671998\n",
      "Training Loss: 0.007082816986949183\n",
      "Validation Loss: 0.004838838364295871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007259601034456864\n",
      "Training Loss: 0.0074780846782959995\n",
      "Training Loss: 0.0070742809475632384\n",
      "Validation Loss: 0.004825214812207674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007253578047384508\n",
      "Training Loss: 0.0074719335313420746\n",
      "Training Loss: 0.007065807225881144\n",
      "Validation Loss: 0.004811641490060753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007247596083907411\n",
      "Training Loss: 0.007465804914245382\n",
      "Training Loss: 0.007057388160610571\n",
      "Validation Loss: 0.0047981117098602685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007241651291842573\n",
      "Training Loss: 0.0074596899130847305\n",
      "Training Loss: 0.007049017454264685\n",
      "Validation Loss: 0.004784622223749547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007235736510483548\n",
      "Training Loss: 0.007453581786248833\n",
      "Training Loss: 0.007040686820982955\n",
      "Validation Loss: 0.004771169903557329\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007229844345129095\n",
      "Training Loss: 0.007447471966734156\n",
      "Training Loss: 0.007032387688523159\n",
      "Validation Loss: 0.004757751034457613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007223970588529483\n",
      "Training Loss: 0.007441351959714666\n",
      "Training Loss: 0.007024114466039464\n",
      "Validation Loss: 0.004744364167799064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007218107453081757\n",
      "Training Loss: 0.0074352131003979595\n",
      "Training Loss: 0.007015857883961871\n",
      "Validation Loss: 0.004731006264356959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.00721224827284459\n",
      "Training Loss: 0.007429045590106398\n",
      "Training Loss: 0.007007609457941726\n",
      "Validation Loss: 0.004717673117483265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007206385022727773\n",
      "Training Loss: 0.0074228413903620095\n",
      "Training Loss: 0.006999359563342296\n",
      "Validation Loss: 0.0047043630692406736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007200512061244808\n",
      "Training Loss: 0.007416589631466195\n",
      "Training Loss: 0.0069911003136076035\n",
      "Validation Loss: 0.004691076863248403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007194617973873392\n",
      "Training Loss: 0.007410281678894535\n",
      "Training Loss: 0.00698282194614876\n",
      "Validation Loss: 0.00467780716010903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007188697766978293\n",
      "Training Loss: 0.007403908277628943\n",
      "Training Loss: 0.006974515088368207\n",
      "Validation Loss: 0.004664557995771717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007182739760610275\n",
      "Training Loss: 0.007397457060869783\n",
      "Training Loss: 0.006966171396779828\n",
      "Validation Loss: 0.004651329629227854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007176736789988354\n",
      "Training Loss: 0.007390921600162983\n",
      "Training Loss: 0.006957780935335904\n",
      "Validation Loss: 0.004638120057218279\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007170679687988013\n",
      "Training Loss: 0.007384290470508858\n",
      "Training Loss: 0.006949335060198791\n",
      "Validation Loss: 0.004624933014843571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007164558288641274\n",
      "Training Loss: 0.0073775568953715264\n",
      "Training Loss: 0.006940824799821712\n",
      "Validation Loss: 0.004611769046247257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.007158364318893291\n",
      "Training Loss: 0.007370711890980601\n",
      "Training Loss: 0.006932244369527325\n",
      "Validation Loss: 0.004598632384892135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.007152089856099338\n",
      "Training Loss: 0.007363749940413982\n",
      "Training Loss: 0.006923586506163701\n",
      "Validation Loss: 0.004585523597812385\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007145726581220515\n",
      "Training Loss: 0.007356665874831378\n",
      "Training Loss: 0.006914846346480772\n",
      "Validation Loss: 0.004572448445604381\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.007139268573955633\n",
      "Training Loss: 0.00734945727745071\n",
      "Training Loss: 0.006906020915484987\n",
      "Validation Loss: 0.004559414096966679\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00713271368527785\n",
      "Training Loss: 0.007342123951530084\n",
      "Training Loss: 0.006897108611301519\n",
      "Validation Loss: 0.004546418992064768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.007126059110742062\n",
      "Training Loss: 0.007334668714320287\n",
      "Training Loss: 0.006888110939762555\n",
      "Validation Loss: 0.004533469746297414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.007119305447558872\n",
      "Training Loss: 0.007327095898799599\n",
      "Training Loss: 0.006879031126154587\n",
      "Validation Loss: 0.004520569406737563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.007112456783070229\n",
      "Training Loss: 0.007319415541132912\n",
      "Training Loss: 0.006869871326489374\n",
      "Validation Loss: 0.004507721391940761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.007105519062606618\n",
      "Training Loss: 0.007311636906815693\n",
      "Training Loss: 0.006860640796949155\n",
      "Validation Loss: 0.004494922197675019\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00709849925187882\n",
      "Training Loss: 0.007303771671140566\n",
      "Training Loss: 0.006851347120245919\n",
      "Validation Loss: 0.004482173354998021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.007091406515100971\n",
      "Training Loss: 0.007295831855153665\n",
      "Training Loss: 0.006841997839510441\n",
      "Validation Loss: 0.0044694720457433565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.00708425035700202\n",
      "Training Loss: 0.007287829391425475\n",
      "Training Loss: 0.006832601099740714\n",
      "Validation Loss: 0.00445680904824789\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.007077038080315106\n",
      "Training Loss: 0.00727977444883436\n",
      "Training Loss: 0.006823164764791727\n",
      "Validation Loss: 0.004444180414200959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.007069778735167347\n",
      "Training Loss: 0.007271674233488738\n",
      "Training Loss: 0.006813692735740915\n",
      "Validation Loss: 0.004431579496810904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.007062476366409101\n",
      "Training Loss: 0.007263534200610593\n",
      "Training Loss: 0.006804191578994505\n",
      "Validation Loss: 0.0044189995381028885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.007055136754643172\n",
      "Training Loss: 0.007255356714595109\n",
      "Training Loss: 0.006794661760795862\n",
      "Validation Loss: 0.004406430175151216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.007047762380097993\n",
      "Training Loss: 0.007247142080450431\n",
      "Training Loss: 0.006785106013412587\n",
      "Validation Loss: 0.0043938686715418035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.007040351941250265\n",
      "Training Loss: 0.007238887189887464\n",
      "Training Loss: 0.0067755206511355935\n",
      "Validation Loss: 0.004381305198028182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0070329053269233555\n",
      "Training Loss: 0.007230586757650599\n",
      "Training Loss: 0.006765904996427707\n",
      "Validation Loss: 0.004368738029309119\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.007025417812983505\n",
      "Training Loss: 0.007222233165521175\n",
      "Training Loss: 0.006756253257044591\n",
      "Validation Loss: 0.0043561608076692045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.007017883149092086\n",
      "Training Loss: 0.0072138170304242525\n",
      "Training Loss: 0.006746558847371489\n",
      "Validation Loss: 0.004343571266933774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.007010295990621671\n",
      "Training Loss: 0.007205328209092841\n",
      "Training Loss: 0.006736814852338284\n",
      "Validation Loss: 0.00433096307031601\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.007002646408509463\n",
      "Training Loss: 0.00719675317988731\n",
      "Training Loss: 0.006727012835908681\n",
      "Validation Loss: 0.004318331237463804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006994925115141087\n",
      "Training Loss: 0.007188078727340326\n",
      "Training Loss: 0.006717140957480296\n",
      "Validation Loss: 0.004305670650027106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006987119259429164\n",
      "Training Loss: 0.007179288730258122\n",
      "Training Loss: 0.006707188686705195\n",
      "Validation Loss: 0.00429297522170825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006979216888430529\n",
      "Training Loss: 0.007170366091886535\n",
      "Training Loss: 0.006697141801705584\n",
      "Validation Loss: 0.0042802355621072855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.0069712007284397255\n",
      "Training Loss: 0.007161292668897658\n",
      "Training Loss: 0.006686985051492229\n",
      "Validation Loss: 0.004267439231789263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.0069630553043680266\n",
      "Training Loss: 0.007152049359865487\n",
      "Training Loss: 0.00667670241673477\n",
      "Validation Loss: 0.004254580047007734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006954763602116145\n",
      "Training Loss: 0.007142616179771721\n",
      "Training Loss: 0.006666276034084148\n",
      "Validation Loss: 0.004241643124260008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006946306967292913\n",
      "Training Loss: 0.007132970229722559\n",
      "Training Loss: 0.00665568818047177\n",
      "Validation Loss: 0.004228611011058092\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006937666217563674\n",
      "Training Loss: 0.0071230918494984505\n",
      "Training Loss: 0.006644919841201045\n",
      "Validation Loss: 0.0042154716538380455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006928825529757887\n",
      "Training Loss: 0.00711296106223017\n",
      "Training Loss: 0.00663395227631554\n",
      "Validation Loss: 0.004202209172372738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006919766209903173\n",
      "Training Loss: 0.007102560271741823\n",
      "Training Loss: 0.006622767614317127\n",
      "Validation Loss: 0.004188808148172213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006910474165924825\n",
      "Training Loss: 0.0070918718818575146\n",
      "Training Loss: 0.0066113521705847235\n",
      "Validation Loss: 0.004175261700960148\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006900940353516489\n",
      "Training Loss: 0.007080888693453744\n",
      "Training Loss: 0.006599693848402239\n",
      "Validation Loss: 0.004161555757562975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006891157057834789\n",
      "Training Loss: 0.007069603685522452\n",
      "Training Loss: 0.006587786556920037\n",
      "Validation Loss: 0.004147687228396535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006881123572238721\n",
      "Training Loss: 0.007058019022224471\n",
      "Training Loss: 0.0065756297344341874\n",
      "Validation Loss: 0.004133653540551411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006870844739023596\n",
      "Training Loss: 0.007046142709441483\n",
      "Training Loss: 0.006563229216262698\n",
      "Validation Loss: 0.004119463158991146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006860327847534791\n",
      "Training Loss: 0.00703398949932307\n",
      "Training Loss: 0.006550597142195329\n",
      "Validation Loss: 0.004105122775634688\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006849587614415214\n",
      "Training Loss: 0.007021579693537205\n",
      "Training Loss: 0.00653775233833585\n",
      "Validation Loss: 0.004090650246499546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006838641657377593\n",
      "Training Loss: 0.007008938939543441\n",
      "Training Loss: 0.006524717750726268\n",
      "Validation Loss: 0.004076061406031544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006827507668640464\n",
      "Training Loss: 0.006996092511108145\n",
      "Training Loss: 0.0065115206845803185\n",
      "Validation Loss: 0.004061375449024392\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006816208582604304\n",
      "Training Loss: 0.006983073317678645\n",
      "Training Loss: 0.006498190442216583\n",
      "Validation Loss: 0.004046619041126975\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006804765448905527\n",
      "Training Loss: 0.006969913659850136\n",
      "Training Loss: 0.006484759860322811\n",
      "Validation Loss: 0.004031816052058398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.0067931998858693984\n",
      "Training Loss: 0.006956644234014675\n",
      "Training Loss: 0.0064712606614921245\n",
      "Validation Loss: 0.004016992533998041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.0067815358273219314\n",
      "Training Loss: 0.00694330082507804\n",
      "Training Loss: 0.00645772417250555\n",
      "Validation Loss: 0.004002173708521583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.00676979637646582\n",
      "Training Loss: 0.006929915531072766\n",
      "Training Loss: 0.0064441829302813855\n",
      "Validation Loss: 0.003987386425711173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006758004840812646\n",
      "Training Loss: 0.006916522646788508\n",
      "Training Loss: 0.006430669948458672\n",
      "Validation Loss: 0.003972662523849292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006746186068048701\n",
      "Training Loss: 0.006903157354099676\n",
      "Training Loss: 0.006417212864616886\n",
      "Validation Loss: 0.003958027363817594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.006734364385483787\n",
      "Training Loss: 0.006889851614832878\n",
      "Training Loss: 0.0064038437197450546\n",
      "Validation Loss: 0.003943513703448803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006722564549418167\n",
      "Training Loss: 0.006876640223781578\n",
      "Training Loss: 0.006390591490198858\n",
      "Validation Loss: 0.003929149918650602\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006710810884251259\n",
      "Training Loss: 0.006863554056035354\n",
      "Training Loss: 0.006377484664553777\n",
      "Validation Loss: 0.003914972336235551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.006699128516484052\n",
      "Training Loss: 0.0068506254866952075\n",
      "Training Loss: 0.006364547516568564\n",
      "Validation Loss: 0.003901009486786749\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006687542616273277\n",
      "Training Loss: 0.006837883883854375\n",
      "Training Loss: 0.006351807988248765\n",
      "Validation Loss: 0.003887295300138361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006676077450974844\n",
      "Training Loss: 0.006825355401961133\n",
      "Training Loss: 0.006339285831782036\n",
      "Validation Loss: 0.0038738613810882054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006664752978831529\n",
      "Training Loss: 0.006813064521411434\n",
      "Training Loss: 0.006327005537459626\n",
      "Validation Loss: 0.0038607392961740117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006653590905480087\n",
      "Training Loss: 0.006801031179493293\n",
      "Training Loss: 0.0063149801071267575\n",
      "Validation Loss: 0.0038479509939350646\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006642606715322472\n",
      "Training Loss: 0.006789270705776289\n",
      "Training Loss: 0.006303226215532049\n",
      "Validation Loss: 0.003835520530812798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.006631816470180638\n",
      "Training Loss: 0.006777795344241895\n",
      "Training Loss: 0.006291751135722734\n",
      "Validation Loss: 0.003823462068600308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006621228497242555\n",
      "Training Loss: 0.0067666102666407825\n",
      "Training Loss: 0.006280561774619855\n",
      "Validation Loss: 0.0038117847148344715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006610853762831539\n",
      "Training Loss: 0.006755719566135667\n",
      "Training Loss: 0.006269661700935103\n",
      "Validation Loss: 0.003800497122509196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006600691526546143\n",
      "Training Loss: 0.006745120528503321\n",
      "Training Loss: 0.006259049735381268\n",
      "Validation Loss: 0.0037895967968702943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0065907473099650815\n",
      "Training Loss: 0.006734808223554865\n",
      "Training Loss: 0.006248719834256917\n",
      "Validation Loss: 0.0037790770646383503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006581017562421038\n",
      "Training Loss: 0.00672477399231866\n",
      "Training Loss: 0.00623866700916551\n",
      "Validation Loss: 0.0037689289964965723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006571497785625979\n",
      "Training Loss: 0.006715006484300829\n",
      "Training Loss: 0.006228882204741239\n",
      "Validation Loss: 0.0037591367668283874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.00656218289397657\n",
      "Training Loss: 0.00670549241185654\n",
      "Training Loss: 0.006219353305641562\n",
      "Validation Loss: 0.003749682878999542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006553064190084115\n",
      "Training Loss: 0.006696218964643777\n",
      "Training Loss: 0.006210069707012735\n",
      "Validation Loss: 0.003740548176476418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006544131836853921\n",
      "Training Loss: 0.00668716816464439\n",
      "Training Loss: 0.006201016940758563\n",
      "Validation Loss: 0.0037317105403478685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006535377965192311\n",
      "Training Loss: 0.006678326160181314\n",
      "Training Loss: 0.006192181109800004\n",
      "Validation Loss: 0.003723146847784101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0065267915610456835\n",
      "Training Loss: 0.006669677752070129\n",
      "Training Loss: 0.006183548150002025\n",
      "Validation Loss: 0.003714836632906135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006518362752976827\n",
      "Training Loss: 0.006661206314456649\n",
      "Training Loss: 0.006175105345901102\n",
      "Validation Loss: 0.003706756583872785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006510077847051435\n",
      "Training Loss: 0.0066528954252135005\n",
      "Training Loss: 0.006166837354539894\n",
      "Validation Loss: 0.0036988834424723943\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006501929537043907\n",
      "Training Loss: 0.0066447323519969355\n",
      "Training Loss: 0.006158728587324731\n",
      "Validation Loss: 0.003691193205239042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.0064939058711752295\n",
      "Training Loss: 0.006636703258845955\n",
      "Training Loss: 0.006150767594808712\n",
      "Validation Loss: 0.003683669094304983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006485995237599127\n",
      "Training Loss: 0.006628793807467445\n",
      "Training Loss: 0.006142939659766853\n",
      "Validation Loss: 0.0036762899377780936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006478189808549359\n",
      "Training Loss: 0.00662099224224221\n",
      "Training Loss: 0.006135231068474241\n",
      "Validation Loss: 0.0036690359803706702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006470478856936097\n",
      "Training Loss: 0.006613286898937076\n",
      "Training Loss: 0.006127630191622302\n",
      "Validation Loss: 0.0036618893464446444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006462850658572279\n",
      "Training Loss: 0.006605664753587917\n",
      "Training Loss: 0.006120125286397524\n",
      "Validation Loss: 0.0036548349644669616\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.006455299139488489\n",
      "Training Loss: 0.006598117470275611\n",
      "Training Loss: 0.006112702131504193\n",
      "Validation Loss: 0.0036478551788768324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006447813088307157\n",
      "Training Loss: 0.006590634864987805\n",
      "Training Loss: 0.006105351152946241\n",
      "Validation Loss: 0.003640935753977052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006440385371097364\n",
      "Training Loss: 0.006583206893410533\n",
      "Training Loss: 0.0060980587673839185\n",
      "Validation Loss: 0.0036340612160130877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.00643300631432794\n",
      "Training Loss: 0.006575824766186998\n",
      "Training Loss: 0.006090813695918768\n",
      "Validation Loss: 0.0036272170474056908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006425666491850279\n",
      "Training Loss: 0.0065684796322602775\n",
      "Training Loss: 0.006083606941974722\n",
      "Validation Loss: 0.0036203930981122375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.006418358038063161\n",
      "Training Loss: 0.006561162582947873\n",
      "Training Loss: 0.00607642418355681\n",
      "Validation Loss: 0.0036135758829219373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.006411071878974326\n",
      "Training Loss: 0.0065538664453197275\n",
      "Training Loss: 0.0060692556446883825\n",
      "Validation Loss: 0.003606748914351331\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.006403800466796383\n",
      "Training Loss: 0.006546582434093579\n",
      "Training Loss: 0.006062089487095364\n",
      "Validation Loss: 0.0035999055403766085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006396533069200814\n",
      "Training Loss: 0.006539303011377342\n",
      "Training Loss: 0.006054913803236559\n",
      "Validation Loss: 0.0035930272676390753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006389262422453612\n",
      "Training Loss: 0.0065320192580111324\n",
      "Training Loss: 0.006047716308385134\n",
      "Validation Loss: 0.0035861059732269496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006381976404227317\n",
      "Training Loss: 0.006524723946349695\n",
      "Training Loss: 0.0060404836718225855\n",
      "Validation Loss: 0.003579126275275321\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006374666331103071\n",
      "Training Loss: 0.006517408798681572\n",
      "Training Loss: 0.006033203323604539\n",
      "Validation Loss: 0.003572073491719248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006367320675053634\n",
      "Training Loss: 0.006510065708425827\n",
      "Training Loss: 0.0060258630773751065\n",
      "Validation Loss: 0.003564939148438927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006359928397578187\n",
      "Training Loss: 0.006502686400199309\n",
      "Training Loss: 0.006018448919639922\n",
      "Validation Loss: 0.003557705461031893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006352478484041057\n",
      "Training Loss: 0.006495262741809711\n",
      "Training Loss: 0.006010945506277494\n",
      "Validation Loss: 0.0035503598811690894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006344956299290061\n",
      "Training Loss: 0.00648778464703355\n",
      "Training Loss: 0.00600333847978618\n",
      "Validation Loss: 0.0035428862709400316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006337349621462636\n",
      "Training Loss: 0.006480246464489028\n",
      "Training Loss: 0.00599561074282974\n",
      "Validation Loss: 0.003535270105244257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.006329643726348877\n",
      "Training Loss: 0.006472637672559358\n",
      "Training Loss: 0.005987748030456715\n",
      "Validation Loss: 0.0035274990649862485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006321823898470029\n",
      "Training Loss: 0.006464950735680759\n",
      "Training Loss: 0.005979733214480802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [34:50<00:00, 209.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0035195559681147296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (5692, 12, 5)\n",
      "Shape of the data after splitting into sequences: (28500, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.33563279151916503\n",
      "Training Loss: 0.24180472224950791\n",
      "Training Loss: 0.17050122752785682\n",
      "Validation Loss: 0.11775131444080492\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.09134437264874577\n",
      "Training Loss: 0.06530407648533583\n",
      "Training Loss: 0.05898112816736102\n",
      "Validation Loss: 0.06709461786857482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.057496819701045754\n",
      "Training Loss: 0.05464989146217704\n",
      "Training Loss: 0.05122443807311356\n",
      "Validation Loss: 0.06035053792796778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04915817112661898\n",
      "Training Loss: 0.045904551232233644\n",
      "Training Loss: 0.042056720219552514\n",
      "Validation Loss: 0.05254565407469701\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03907963316887617\n",
      "Training Loss: 0.03548635576851666\n",
      "Training Loss: 0.03161623863503337\n",
      "Validation Loss: 0.04435452955952856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.028365097222849727\n",
      "Training Loss: 0.02504415675997734\n",
      "Training Loss: 0.02195352803915739\n",
      "Validation Loss: 0.037394932596787306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01956497298553586\n",
      "Training Loss: 0.017347001056186855\n",
      "Training Loss: 0.015684440401382744\n",
      "Validation Loss: 0.033133503279826615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014669098376762122\n",
      "Training Loss: 0.01355060019530356\n",
      "Training Loss: 0.012890214859507977\n",
      "Validation Loss: 0.03088327119482702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.012497462260071188\n",
      "Training Loss: 0.01184199380222708\n",
      "Training Loss: 0.011581413322128356\n",
      "Validation Loss: 0.029338829585591728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011330861616879701\n",
      "Training Loss: 0.010852062696358189\n",
      "Training Loss: 0.010764481956139207\n",
      "Validation Loss: 0.02810084933331341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010541694632265716\n",
      "Training Loss: 0.010150883638998494\n",
      "Training Loss: 0.010153984426287933\n",
      "Validation Loss: 0.027052581446308097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009928575265221298\n",
      "Training Loss: 0.009591033258475363\n",
      "Training Loss: 0.009647306780098007\n",
      "Validation Loss: 0.026119661559298468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00940467678126879\n",
      "Training Loss: 0.009102930310182273\n",
      "Training Loss: 0.009192144209519028\n",
      "Validation Loss: 0.02524106096204245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008921220417832956\n",
      "Training Loss: 0.008644924580585212\n",
      "Training Loss: 0.008754673532675951\n",
      "Validation Loss: 0.02436727729594607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008445681262528523\n",
      "Training Loss: 0.008188225459307433\n",
      "Training Loss: 0.00831021236605011\n",
      "Validation Loss: 0.02346347365528345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007955336992163211\n",
      "Training Loss: 0.007712914440780878\n",
      "Training Loss: 0.007841897124890237\n",
      "Validation Loss: 0.022519338687651613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.007438573575345799\n",
      "Training Loss: 0.00721111650695093\n",
      "Training Loss: 0.0073460997978691015\n",
      "Validation Loss: 0.021569474401433815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.006904366058879532\n",
      "Training Loss: 0.0066985056269913915\n",
      "Training Loss: 0.006845846953219734\n",
      "Validation Loss: 0.020714078009589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.006396627534995787\n",
      "Training Loss: 0.006226108656846918\n",
      "Training Loss: 0.006397652142914012\n",
      "Validation Loss: 0.02006961820971514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005979204199975357\n",
      "Training Loss: 0.005850986709119752\n",
      "Training Loss: 0.006047304629464634\n",
      "Validation Loss: 0.01962647341411519\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0056665396556491035\n",
      "Training Loss: 0.00557207681296859\n",
      "Training Loss: 0.005780449727899395\n",
      "Validation Loss: 0.01928602830046432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.005423845468321815\n",
      "Training Loss: 0.005355823055724613\n",
      "Training Loss: 0.005567360079730861\n",
      "Validation Loss: 0.0189868032283495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.005225760763860308\n",
      "Training Loss: 0.005181675955536775\n",
      "Training Loss: 0.00539271880290471\n",
      "Validation Loss: 0.01870392352666999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.005060910835745744\n",
      "Training Loss: 0.005039558922289871\n",
      "Training Loss: 0.005248725494602695\n",
      "Validation Loss: 0.018428854853584524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004922893596813083\n",
      "Training Loss: 0.0049230624607298525\n",
      "Training Loss: 0.0051299204397946595\n",
      "Validation Loss: 0.01816212059929967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004807195471948944\n",
      "Training Loss: 0.004827381260693073\n",
      "Training Loss: 0.005031854038825259\n",
      "Validation Loss: 0.017907817026579315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0047102213476318865\n",
      "Training Loss: 0.004748669578111731\n",
      "Training Loss: 0.004950772900483571\n",
      "Validation Loss: 0.0176701113461318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.00462892115872819\n",
      "Training Loss: 0.004683759981417097\n",
      "Training Loss: 0.004883520243456587\n",
      "Validation Loss: 0.017451905030652547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004560657463152893\n",
      "Training Loss: 0.0046300324430922045\n",
      "Training Loss: 0.004827486089197919\n",
      "Validation Loss: 0.017254602300065956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004503180072642863\n",
      "Training Loss: 0.004585332676069811\n",
      "Training Loss: 0.004780541185173206\n",
      "Validation Loss: 0.017078397897584887\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0044545843359082935\n",
      "Training Loss: 0.004547900793841109\n",
      "Training Loss: 0.004740959630580619\n",
      "Validation Loss: 0.01692258362040928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.004413281556335278\n",
      "Training Loss: 0.004516309362370521\n",
      "Training Loss: 0.0047073506365995854\n",
      "Validation Loss: 0.016785908404088924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00437796265585348\n",
      "Training Loss: 0.0044894125167047605\n",
      "Training Loss: 0.004678598854807206\n",
      "Validation Loss: 0.016666792618278206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00434755768161267\n",
      "Training Loss: 0.00446629969170317\n",
      "Training Loss: 0.004653811256284826\n",
      "Validation Loss: 0.016563533551551487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0043212046171538536\n",
      "Training Loss: 0.004446249410975724\n",
      "Training Loss: 0.004632276583579369\n",
      "Validation Loss: 0.0164744069805013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004298206981620751\n",
      "Training Loss: 0.004428695374517701\n",
      "Training Loss: 0.004613425103016198\n",
      "Validation Loss: 0.016397798758293135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004278006808599457\n",
      "Training Loss: 0.004413191143539734\n",
      "Training Loss: 0.004596801298903302\n",
      "Validation Loss: 0.01633218860546692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.00426015408243984\n",
      "Training Loss: 0.004399385427241213\n",
      "Training Loss: 0.004582038547378034\n",
      "Validation Loss: 0.0162761260891396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004244283936568536\n",
      "Training Loss: 0.004386996993562206\n",
      "Training Loss: 0.004568840535939671\n",
      "Validation Loss: 0.016228416160251318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.004230099546257407\n",
      "Training Loss: 0.004375803585280664\n",
      "Training Loss: 0.004556965042720549\n",
      "Validation Loss: 0.01618787298355712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004217355881701223\n",
      "Training Loss: 0.004365622731857002\n",
      "Training Loss: 0.004546212281566113\n",
      "Validation Loss: 0.016153540538121642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.00420584871142637\n",
      "Training Loss: 0.00435630697698798\n",
      "Training Loss: 0.00453641910396982\n",
      "Validation Loss: 0.01612449347386869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.004195408553932793\n",
      "Training Loss: 0.004347735116025433\n",
      "Training Loss: 0.004527448293520138\n",
      "Validation Loss: 0.01609994507959803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004185892587993294\n",
      "Training Loss: 0.004339806032949128\n",
      "Training Loss: 0.004519185870885849\n",
      "Validation Loss: 0.016079264978114308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004177180577535182\n",
      "Training Loss: 0.004332435632823035\n",
      "Training Loss: 0.004511537421494722\n",
      "Validation Loss: 0.016061831127035985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.004169170060777105\n",
      "Training Loss: 0.004325554329552688\n",
      "Training Loss: 0.004504423105390743\n",
      "Validation Loss: 0.016047164559720106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004161773302475922\n",
      "Training Loss: 0.004319101798464544\n",
      "Training Loss: 0.0044977758359164\n",
      "Validation Loss: 0.016034835431557357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004154917076230049\n",
      "Training Loss: 0.004313028242904693\n",
      "Training Loss: 0.004491537614958361\n",
      "Validation Loss: 0.0160244734319492\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004148536812863313\n",
      "Training Loss: 0.004307290829601697\n",
      "Training Loss: 0.004485661026556045\n",
      "Validation Loss: 0.016015785128882763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.004142577841994352\n",
      "Training Loss: 0.004301853028591722\n",
      "Training Loss: 0.00448010484164115\n",
      "Validation Loss: 0.016008516893920938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.004136992894345894\n",
      "Training Loss: 0.004296682943822816\n",
      "Training Loss: 0.004474833551212214\n",
      "Validation Loss: 0.016002438350298097\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004131741189630702\n",
      "Training Loss: 0.004291753471479751\n",
      "Training Loss: 0.004469817333156243\n",
      "Validation Loss: 0.015997367848254992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004126788104185835\n",
      "Training Loss: 0.00428704067657236\n",
      "Training Loss: 0.004465030228020623\n",
      "Validation Loss: 0.015993172734494458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00412210121168755\n",
      "Training Loss: 0.004282524332520552\n",
      "Training Loss: 0.004460449747275561\n",
      "Validation Loss: 0.015989703013760487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.004117654103902168\n",
      "Training Loss: 0.004278185059665702\n",
      "Training Loss: 0.004456056149210781\n",
      "Validation Loss: 0.015986873558984045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.004113422808004543\n",
      "Training Loss: 0.004274007902131416\n",
      "Training Loss: 0.00445183169329539\n",
      "Validation Loss: 0.015984580598332073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004109387425123714\n",
      "Training Loss: 0.004269978124066256\n",
      "Training Loss: 0.004447762149502523\n",
      "Validation Loss: 0.015982766248536912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.004105528735090047\n",
      "Training Loss: 0.0042660828202497215\n",
      "Training Loss: 0.0044438332982826975\n",
      "Validation Loss: 0.01598133269979964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.0041018303239252416\n",
      "Training Loss: 0.00426231004355941\n",
      "Training Loss: 0.004440033879945986\n",
      "Validation Loss: 0.015980278892610014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.004098278020392172\n",
      "Training Loss: 0.004258649633848108\n",
      "Training Loss: 0.004436353022465482\n",
      "Validation Loss: 0.01597951721724416\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.004094858856406063\n",
      "Training Loss: 0.004255092302337289\n",
      "Training Loss: 0.004432781271170825\n",
      "Validation Loss: 0.015979020989740664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.004091561156092212\n",
      "Training Loss: 0.0042516297067049895\n",
      "Training Loss: 0.004429309724946507\n",
      "Validation Loss: 0.01597878354957348\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.004088374758139252\n",
      "Training Loss: 0.004248254072736018\n",
      "Training Loss: 0.004425931196310557\n",
      "Validation Loss: 0.015978740598859915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.004085289806243964\n",
      "Training Loss: 0.004244957831688225\n",
      "Training Loss: 0.0044226388621609655\n",
      "Validation Loss: 0.015978903119881333\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 64\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.004082298326538876\n",
      "Training Loss: 0.004241735824616626\n",
      "Training Loss: 0.004419425439555198\n",
      "Validation Loss: 0.015979228810710688\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 65\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.004079392439452931\n",
      "Training Loss: 0.00423858103051316\n",
      "Training Loss: 0.00441628610540647\n",
      "Validation Loss: 0.015979704099152697\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 66\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.004076565754367038\n",
      "Training Loss: 0.004235488320700824\n",
      "Training Loss: 0.0044132154108956455\n",
      "Validation Loss: 0.015980339737274172\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 67\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.004073811777052469\n",
      "Training Loss: 0.004232453763252124\n",
      "Training Loss: 0.004410208208719268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:10<10:37, 70.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.015981109532935734\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 68\n",
      "Early stopping after 68 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.5603973086178303\n",
      "Training Loss: 0.38743603065609933\n",
      "Training Loss: 0.24075033769011497\n",
      "Validation Loss: 0.14013239548782283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.1033786103501916\n",
      "Training Loss: 0.06485965602099895\n",
      "Training Loss: 0.05250861642882228\n",
      "Validation Loss: 0.06300518714058935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04973911435343325\n",
      "Training Loss: 0.04690767495892942\n",
      "Training Loss: 0.0429624349810183\n",
      "Validation Loss: 0.057246100659785644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04099810482002795\n",
      "Training Loss: 0.03810692798346281\n",
      "Training Loss: 0.03422102740034461\n",
      "Validation Loss: 0.051097239587414134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.032124202298000455\n",
      "Training Loss: 0.0294274345273152\n",
      "Training Loss: 0.026216069888323545\n",
      "Validation Loss: 0.045012607678687304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02454639969393611\n",
      "Training Loss: 0.022317760828882455\n",
      "Training Loss: 0.02012991227209568\n",
      "Validation Loss: 0.0398106961458754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.019109685621224344\n",
      "Training Loss: 0.01747097578831017\n",
      "Training Loss: 0.016194182257167997\n",
      "Validation Loss: 0.035817499806204536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01562593222828582\n",
      "Training Loss: 0.014465897066984326\n",
      "Training Loss: 0.013766314797103406\n",
      "Validation Loss: 0.032840399715128574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.0133893182547763\n",
      "Training Loss: 0.012552299873204902\n",
      "Training Loss: 0.01218086170265451\n",
      "Validation Loss: 0.030616144152630247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011869625819381327\n",
      "Training Loss: 0.011245355148566887\n",
      "Training Loss: 0.011069000012939796\n",
      "Validation Loss: 0.02891734519743183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010782141749514267\n",
      "Training Loss: 0.01029891055659391\n",
      "Training Loss: 0.010246059175115079\n",
      "Validation Loss: 0.02756090737418847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009965841834200547\n",
      "Training Loss: 0.009575974681647495\n",
      "Training Loss: 0.009603359284810722\n",
      "Validation Loss: 0.02641339147505298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009315947889117524\n",
      "Training Loss: 0.008987648569745942\n",
      "Training Loss: 0.009066904798382893\n",
      "Validation Loss: 0.025379031080375897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008758608186617493\n",
      "Training Loss: 0.008469725827453659\n",
      "Training Loss: 0.008580323446076364\n",
      "Validation Loss: 0.024377436246304365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008235516506247223\n",
      "Training Loss: 0.007967827758984641\n",
      "Training Loss: 0.008092121715890244\n",
      "Validation Loss: 0.023329072082519865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007694615543587133\n",
      "Training Loss: 0.007434665811015293\n",
      "Training Loss: 0.007564133724663406\n",
      "Validation Loss: 0.022231256992168977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.007124882395146415\n",
      "Training Loss: 0.0068816491536563265\n",
      "Training Loss: 0.007025878721033223\n",
      "Validation Loss: 0.02119669790139024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.006566966218524612\n",
      "Training Loss: 0.00634323391597718\n",
      "Training Loss: 0.0064981789432931696\n",
      "Validation Loss: 0.020261085851201684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.006040476698544807\n",
      "Training Loss: 0.005846116293687373\n",
      "Training Loss: 0.006024173792684451\n",
      "Validation Loss: 0.01956111946394353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005607028491795063\n",
      "Training Loss: 0.005453421387937851\n",
      "Training Loss: 0.00566195305029396\n",
      "Validation Loss: 0.019108221251412892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005290225274511613\n",
      "Training Loss: 0.005174955707625486\n",
      "Training Loss: 0.0054058996494859455\n",
      "Validation Loss: 0.018778332401841378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.005061929384246469\n",
      "Training Loss: 0.004978661463246681\n",
      "Training Loss: 0.005222421563230455\n",
      "Validation Loss: 0.01849439693353233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.004892962488811463\n",
      "Training Loss: 0.004836511522298679\n",
      "Training Loss: 0.005086769834160804\n",
      "Validation Loss: 0.018240837534638437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0047653330763569104\n",
      "Training Loss: 0.004731294567463919\n",
      "Training Loss: 0.004983982394915074\n",
      "Validation Loss: 0.01801772535977404\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004667324078618549\n",
      "Training Loss: 0.004651899365708232\n",
      "Training Loss: 0.0049043665226781745\n",
      "Validation Loss: 0.01782470460709059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004590627293800935\n",
      "Training Loss: 0.0045906421588733795\n",
      "Training Loss: 0.004841269241296686\n",
      "Validation Loss: 0.017659945866051182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0045292627206072215\n",
      "Training Loss: 0.004542140967096202\n",
      "Training Loss: 0.0047900711366673935\n",
      "Validation Loss: 0.017520975980782106\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.004479011930525303\n",
      "Training Loss: 0.00450271665758919\n",
      "Training Loss: 0.004747641039721202\n",
      "Validation Loss: 0.017404945755607627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004437012323178351\n",
      "Training Loss: 0.0044699635362485425\n",
      "Training Loss: 0.004711938790569548\n",
      "Validation Loss: 0.017308506751014443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004401391749270261\n",
      "Training Loss: 0.0044423703616485\n",
      "Training Loss: 0.004681664211675525\n",
      "Validation Loss: 0.017227724275624988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.004370938297361135\n",
      "Training Loss: 0.004418972380226478\n",
      "Training Loss: 0.00465594043082092\n",
      "Validation Loss: 0.01715846485824565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.004344813478528522\n",
      "Training Loss: 0.0043990708247292785\n",
      "Training Loss: 0.004634073300985619\n",
      "Validation Loss: 0.01709701069055146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004322354182950221\n",
      "Training Loss: 0.004382077980553731\n",
      "Training Loss: 0.004615432287973818\n",
      "Validation Loss: 0.01704046736324855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.004302974886377342\n",
      "Training Loss: 0.004367469780263491\n",
      "Training Loss: 0.004599441601312719\n",
      "Validation Loss: 0.016987047974396957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.004286153867142275\n",
      "Training Loss: 0.004354793223901652\n",
      "Training Loss: 0.004585596443503164\n",
      "Validation Loss: 0.016935865358146052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004271443270845339\n",
      "Training Loss: 0.004343676925054751\n",
      "Training Loss: 0.004573481742409058\n",
      "Validation Loss: 0.016886728860207655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004258474595262669\n",
      "Training Loss: 0.004333827212685719\n",
      "Training Loss: 0.004562764536822215\n",
      "Validation Loss: 0.016839765739533004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0042469513631658625\n",
      "Training Loss: 0.004325013276538812\n",
      "Training Loss: 0.004553183379466645\n",
      "Validation Loss: 0.01679524822484995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004236638024449349\n",
      "Training Loss: 0.004317055092542432\n",
      "Training Loss: 0.004544532611616887\n",
      "Validation Loss: 0.01675333908047485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0042273441981524225\n",
      "Training Loss: 0.0043098070699488745\n",
      "Training Loss: 0.004536648799548857\n",
      "Validation Loss: 0.016714229476062603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004218914677621797\n",
      "Training Loss: 0.0043031541001982984\n",
      "Training Loss: 0.004529400753090158\n",
      "Validation Loss: 0.016677913177507313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.004211223110905849\n",
      "Training Loss: 0.0042970019718632105\n",
      "Training Loss: 0.004522682568640448\n",
      "Validation Loss: 0.01664437566036254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.004204163129325025\n",
      "Training Loss: 0.004291273445705884\n",
      "Training Loss: 0.004516409264178947\n",
      "Validation Loss: 0.016613543146091064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004197647508699447\n",
      "Training Loss: 0.004285905092256143\n",
      "Training Loss: 0.004510511138360016\n",
      "Validation Loss: 0.016585235005202755\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004191601597121917\n",
      "Training Loss: 0.004280843697488308\n",
      "Training Loss: 0.004504931657575071\n",
      "Validation Loss: 0.01655934796030267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.0041859632212435825\n",
      "Training Loss: 0.00427604716969654\n",
      "Training Loss: 0.004499623697483912\n",
      "Validation Loss: 0.01653570004508653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004180680433637463\n",
      "Training Loss: 0.004271480297320523\n",
      "Training Loss: 0.004494550456875004\n",
      "Validation Loss: 0.016514147265573566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004175708733382635\n",
      "Training Loss: 0.004267112470697612\n",
      "Training Loss: 0.0044896798732224855\n",
      "Validation Loss: 0.016494522158977357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.00417101033963263\n",
      "Training Loss: 0.004262920558685437\n",
      "Training Loss: 0.004484986097668298\n",
      "Validation Loss: 0.016476666350754794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00416655270208139\n",
      "Training Loss: 0.0042588828736916185\n",
      "Training Loss: 0.004480448591639288\n",
      "Validation Loss: 0.016460448911601908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0041623093414818865\n",
      "Training Loss: 0.004254983604769222\n",
      "Training Loss: 0.00447604974731803\n",
      "Validation Loss: 0.016445726080368577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004158256842056289\n",
      "Training Loss: 0.004251208005589433\n",
      "Training Loss: 0.0044717759417835625\n",
      "Validation Loss: 0.016432366420232346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004154374863719568\n",
      "Training Loss: 0.004247544921818189\n",
      "Training Loss: 0.004467614346067421\n",
      "Validation Loss: 0.01642028837506607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0041506463190307845\n",
      "Training Loss: 0.004243983324849978\n",
      "Training Loss: 0.004463555031688884\n",
      "Validation Loss: 0.016409332628539774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.004147056411020458\n",
      "Training Loss: 0.004240515666897409\n",
      "Training Loss: 0.00445959055388812\n",
      "Validation Loss: 0.016399441095948052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.004143591925967484\n",
      "Training Loss: 0.004237133929273114\n",
      "Training Loss: 0.004455713100032881\n",
      "Validation Loss: 0.016390504660817345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004140241479617544\n",
      "Training Loss: 0.004233831564779394\n",
      "Training Loss: 0.00445191720908042\n",
      "Validation Loss: 0.01638246917563459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0041369961679447445\n",
      "Training Loss: 0.004230604120530188\n",
      "Training Loss: 0.004448197719175369\n",
      "Validation Loss: 0.01637524611243371\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00413384590880014\n",
      "Training Loss: 0.004227446113945916\n",
      "Training Loss: 0.004444550507469103\n",
      "Validation Loss: 0.01636874745338318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.004130784421577118\n",
      "Training Loss: 0.004224352572928183\n",
      "Training Loss: 0.00444097155588679\n",
      "Validation Loss: 0.0163629345538283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.004127803632291034\n",
      "Training Loss: 0.004221320375218056\n",
      "Training Loss: 0.004437457646708935\n",
      "Validation Loss: 0.016357768562444475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.004124898856389336\n",
      "Training Loss: 0.00421834580367431\n",
      "Training Loss: 0.004434005121001974\n",
      "Validation Loss: 0.016353156409760036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.00412206296226941\n",
      "Training Loss: 0.004215424827416428\n",
      "Training Loss: 0.004430613266304135\n",
      "Validation Loss: 0.0163490855255363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.004119292757823132\n",
      "Training Loss: 0.0042125557619147\n",
      "Training Loss: 0.004427278101211414\n",
      "Validation Loss: 0.016345493662893104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.004116582848364487\n",
      "Training Loss: 0.004209734402829781\n",
      "Training Loss: 0.0044239976425888014\n",
      "Validation Loss: 0.016342383848628805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.00411392911861185\n",
      "Training Loss: 0.004206959746079519\n",
      "Training Loss: 0.0044207706896122545\n",
      "Validation Loss: 0.016339709772989992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.004111328865401447\n",
      "Training Loss: 0.00420422792842146\n",
      "Training Loss: 0.004417594140395522\n",
      "Validation Loss: 0.0163374273498867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0041087774332845585\n",
      "Training Loss: 0.004201537980698049\n",
      "Training Loss: 0.0044144681468606\n",
      "Validation Loss: 0.016335498167494876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.004106272877543234\n",
      "Training Loss: 0.004198887245729565\n",
      "Training Loss: 0.004411389743327163\n",
      "Validation Loss: 0.016333937019716655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0041038114193361255\n",
      "Training Loss: 0.004196273568668403\n",
      "Training Loss: 0.004408358713262715\n",
      "Validation Loss: 0.016332670232657803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.004101391019066796\n",
      "Training Loss: 0.004193695407011546\n",
      "Training Loss: 0.004405372321489267\n",
      "Validation Loss: 0.016331746028422304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.004099008763441816\n",
      "Training Loss: 0.004191151078557596\n",
      "Training Loss: 0.004402429512119852\n",
      "Validation Loss: 0.016331103096684712\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.004096662785159424\n",
      "Training Loss: 0.0041886381601216275\n",
      "Training Loss: 0.00439952987304423\n",
      "Validation Loss: 0.01633072426553104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.004094350803061388\n",
      "Training Loss: 0.004186155824572779\n",
      "Training Loss: 0.004396671672584489\n",
      "Validation Loss: 0.016330618521177703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.004092071067425422\n",
      "Training Loss: 0.004183702672016807\n",
      "Training Loss: 0.004393854002119042\n",
      "Validation Loss: 0.016330798457408053\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 75\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.004089820781373419\n",
      "Training Loss: 0.004181276748422533\n",
      "Training Loss: 0.004391074681770988\n",
      "Validation Loss: 0.016331189853568257\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 76\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.00408759915502742\n",
      "Training Loss: 0.00417887692921795\n",
      "Training Loss: 0.004388333756942302\n",
      "Validation Loss: 0.01633182105482713\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 77\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.004085403817589395\n",
      "Training Loss: 0.004176501606125384\n",
      "Training Loss: 0.004385629451135174\n",
      "Validation Loss: 0.01633267322021505\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 78\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.004083234648569487\n",
      "Training Loss: 0.004174149645841681\n",
      "Training Loss: 0.004382962010568008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:33<10:20, 77.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016333733813502314\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 79\n",
      "Early stopping after 79 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.4871057167649269\n",
      "Training Loss: 0.36594637542963027\n",
      "Training Loss: 0.26639449641108515\n",
      "Validation Loss: 0.17659512258480103\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.12878999419510365\n",
      "Training Loss: 0.07173186691477895\n",
      "Training Loss: 0.057127338722348216\n",
      "Validation Loss: 0.06703204429300313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05334266395308077\n",
      "Training Loss: 0.048974869027733806\n",
      "Training Loss: 0.0456453962624073\n",
      "Validation Loss: 0.057574522691998586\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04338360077701509\n",
      "Training Loss: 0.03978803431615233\n",
      "Training Loss: 0.03647812377661466\n",
      "Validation Loss: 0.049663809640856274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03402450244873762\n",
      "Training Loss: 0.03067080450709909\n",
      "Training Loss: 0.027508309250697492\n",
      "Validation Loss: 0.04236629596921835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.025152600836008787\n",
      "Training Loss: 0.02241359137929976\n",
      "Training Loss: 0.020045365099795164\n",
      "Validation Loss: 0.03661764192321662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01857065241318196\n",
      "Training Loss: 0.016763263805769382\n",
      "Training Loss: 0.015372050073929132\n",
      "Validation Loss: 0.03283012335010794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014655568390153348\n",
      "Training Loss: 0.013476087509188802\n",
      "Training Loss: 0.012758750908542425\n",
      "Validation Loss: 0.030289048637692512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.012404516874812543\n",
      "Training Loss: 0.011582050416618585\n",
      "Training Loss: 0.011255433592014015\n",
      "Validation Loss: 0.028469490588464763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011034854800673202\n",
      "Training Loss: 0.010417793070664629\n",
      "Training Loss: 0.01030134525266476\n",
      "Validation Loss: 0.027081827486582687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01011464576702565\n",
      "Training Loss: 0.009621677374234423\n",
      "Training Loss: 0.009618483282392844\n",
      "Validation Loss: 0.025950258487856454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009428323054453357\n",
      "Training Loss: 0.009016649413388223\n",
      "Training Loss: 0.009078036076389254\n",
      "Validation Loss: 0.02497094024621536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008870762812439353\n",
      "Training Loss: 0.00851717941928655\n",
      "Training Loss: 0.00861828553956002\n",
      "Validation Loss: 0.02408195866711354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008388162326300517\n",
      "Training Loss: 0.008079210319556296\n",
      "Training Loss: 0.008206189059419557\n",
      "Validation Loss: 0.023244652284958055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007950093284016475\n",
      "Training Loss: 0.007677403192501515\n",
      "Training Loss: 0.007821309324353933\n",
      "Validation Loss: 0.02243424179241731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007537129449192434\n",
      "Training Loss: 0.0072951856919098645\n",
      "Training Loss: 0.007449129053275101\n",
      "Validation Loss: 0.021635734327032828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.007135459833079949\n",
      "Training Loss: 0.00692052390484605\n",
      "Training Loss: 0.007078512594453059\n",
      "Validation Loss: 0.02084348556386788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.006735146357677877\n",
      "Training Loss: 0.006544790932675824\n",
      "Training Loss: 0.006701592069584876\n",
      "Validation Loss: 0.02006445038184691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.006331076039932668\n",
      "Training Loss: 0.006164170888951048\n",
      "Training Loss: 0.006315977814374492\n",
      "Validation Loss: 0.019328348338603973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005927419618819841\n",
      "Training Loss: 0.005784846366732381\n",
      "Training Loss: 0.005932089199195616\n",
      "Validation Loss: 0.01871742926056633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005551178139867261\n",
      "Training Loss: 0.005440615108818747\n",
      "Training Loss: 0.005596217972342856\n",
      "Validation Loss: 0.018343684085634318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.005257049743668176\n",
      "Training Loss: 0.005184931271942333\n",
      "Training Loss: 0.0053567294141976165\n",
      "Validation Loss: 0.01813959313315873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.005054236824507825\n",
      "Training Loss: 0.005014261778560467\n",
      "Training Loss: 0.005196958691813052\n",
      "Validation Loss: 0.01798166932402116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.004914121930487454\n",
      "Training Loss: 0.004899163147201762\n",
      "Training Loss: 0.005087532839388587\n",
      "Validation Loss: 0.01783830028686547\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004813892844831571\n",
      "Training Loss: 0.004818223635666073\n",
      "Training Loss: 0.005008866670541465\n",
      "Validation Loss: 0.017708647637784982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004738665550830774\n",
      "Training Loss: 0.004758002072339878\n",
      "Training Loss: 0.004949009103002027\n",
      "Validation Loss: 0.017592786390104153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.004679053836734965\n",
      "Training Loss: 0.004710339151206427\n",
      "Training Loss: 0.004900812851265073\n",
      "Validation Loss: 0.017489235120919648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.004629341062973254\n",
      "Training Loss: 0.004670433131395839\n",
      "Training Loss: 0.004860064928070642\n",
      "Validation Loss: 0.01739594465895985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004586146333022043\n",
      "Training Loss: 0.004635529673541896\n",
      "Training Loss: 0.004824309417745099\n",
      "Validation Loss: 0.017311209109036274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004547504629590549\n",
      "Training Loss: 0.0046040762291522696\n",
      "Training Loss: 0.004792110256967135\n",
      "Validation Loss: 0.01723361276404074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.004512273060390726\n",
      "Training Loss: 0.004575198315433226\n",
      "Training Loss: 0.004762619388638995\n",
      "Validation Loss: 0.01716221950090166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.004479775726795196\n",
      "Training Loss: 0.004548391800490208\n",
      "Training Loss: 0.004735318619059399\n",
      "Validation Loss: 0.017096359737928998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004449593166355043\n",
      "Training Loss: 0.004523354558041319\n",
      "Training Loss: 0.004709882693132386\n",
      "Validation Loss: 0.017035542762304626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00442145160981454\n",
      "Training Loss: 0.004499894336331636\n",
      "Training Loss: 0.004686091300100088\n",
      "Validation Loss: 0.01697944104409871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.004395159432897344\n",
      "Training Loss: 0.004477877642493695\n",
      "Training Loss: 0.0046637943980749694\n",
      "Validation Loss: 0.016927773030893354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004370574682834558\n",
      "Training Loss: 0.004457207965315319\n",
      "Training Loss: 0.004642878302838653\n",
      "Validation Loss: 0.01688031887823946\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004347583465860225\n",
      "Training Loss: 0.004437803357723169\n",
      "Training Loss: 0.00462325441185385\n",
      "Validation Loss: 0.01683689077813806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.004326086935470812\n",
      "Training Loss: 0.004419594834325835\n",
      "Training Loss: 0.004604844518471509\n",
      "Validation Loss: 0.016797277976999456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004305996130569838\n",
      "Training Loss: 0.0044025140843586994\n",
      "Training Loss: 0.004587578725186177\n",
      "Validation Loss: 0.016761290995152982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00428722741024103\n",
      "Training Loss: 0.004386498351814225\n",
      "Training Loss: 0.0045713913458166645\n",
      "Validation Loss: 0.0167287579434139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004269698436837643\n",
      "Training Loss: 0.004371483742725104\n",
      "Training Loss: 0.004556216768105514\n",
      "Validation Loss: 0.016699442543152174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.004253328533377498\n",
      "Training Loss: 0.004357406795024872\n",
      "Training Loss: 0.004541992163867689\n",
      "Validation Loss: 0.016673123675890352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.00423803961602971\n",
      "Training Loss: 0.0043442047096323225\n",
      "Training Loss: 0.004528653205488809\n",
      "Validation Loss: 0.01664961162127889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.0042237546260003\n",
      "Training Loss: 0.004331815656623803\n",
      "Training Loss: 0.004516139996703714\n",
      "Validation Loss: 0.01662865581953626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004210397725692019\n",
      "Training Loss: 0.004320180618087761\n",
      "Training Loss: 0.004504390577203594\n",
      "Validation Loss: 0.016610059167750265\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.004197898500133306\n",
      "Training Loss: 0.004309242983581498\n",
      "Training Loss: 0.004493347679381259\n",
      "Validation Loss: 0.01659358924076882\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004186188814928755\n",
      "Training Loss: 0.004298949837102555\n",
      "Training Loss: 0.004482958216685802\n",
      "Validation Loss: 0.016579059789773455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004175206017098389\n",
      "Training Loss: 0.004289251156151295\n",
      "Training Loss: 0.004473171057761647\n",
      "Validation Loss: 0.016566261963060734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004164891482214443\n",
      "Training Loss: 0.004280099974712357\n",
      "Training Loss: 0.004463938573608175\n",
      "Validation Loss: 0.016555066707052205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.004155191461322829\n",
      "Training Loss: 0.004271455347188749\n",
      "Training Loss: 0.004455217138165608\n",
      "Validation Loss: 0.016545280222937966\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.004146056431927718\n",
      "Training Loss: 0.0042632773198420185\n",
      "Training Loss: 0.0044469668995589014\n",
      "Validation Loss: 0.016536771832557206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004137441253988072\n",
      "Training Loss: 0.0042555308516602965\n",
      "Training Loss: 0.004439151196856983\n",
      "Validation Loss: 0.016529444981826825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004129304828238673\n",
      "Training Loss: 0.004248182909213938\n",
      "Training Loss: 0.004431736459955573\n",
      "Validation Loss: 0.01652316773948626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.00412161078886129\n",
      "Training Loss: 0.004241203743731603\n",
      "Training Loss: 0.004424691136227921\n",
      "Validation Loss: 0.016517851475542515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0041143239161465315\n",
      "Training Loss: 0.00423456599644851\n",
      "Training Loss: 0.004417987815104425\n",
      "Validation Loss: 0.016513419314025994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.004107414211612195\n",
      "Training Loss: 0.004228243843535893\n",
      "Training Loss: 0.004411600173916667\n",
      "Validation Loss: 0.01650980083020718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.00410085182345938\n",
      "Training Loss: 0.0042222141119418665\n",
      "Training Loss: 0.004405504493042826\n",
      "Validation Loss: 0.016506945039407257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.004094611667678692\n",
      "Training Loss: 0.004216455033165403\n",
      "Training Loss: 0.004399679139605723\n",
      "Validation Loss: 0.016504776203649096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.004088669977500103\n",
      "Training Loss: 0.0042109462927328424\n",
      "Training Loss: 0.0043941041681682695\n",
      "Validation Loss: 0.01650328054668361\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.004083003767882474\n",
      "Training Loss: 0.004205669701332226\n",
      "Training Loss: 0.004388760170550086\n",
      "Validation Loss: 0.016502400677065165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.004077593612018973\n",
      "Training Loss: 0.004200608115061186\n",
      "Training Loss: 0.004383631070959381\n",
      "Validation Loss: 0.016502090128075877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00407242028566543\n",
      "Training Loss: 0.004195744480821304\n",
      "Training Loss: 0.00437870042398572\n",
      "Validation Loss: 0.01650234594093531\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 62\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.004067467174027115\n",
      "Training Loss: 0.004191065118066035\n",
      "Training Loss: 0.0043739537626970556\n",
      "Validation Loss: 0.016503116767330284\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 63\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.004062717261258513\n",
      "Training Loss: 0.004186555764172226\n",
      "Training Loss: 0.004369377844850533\n",
      "Validation Loss: 0.01650440275637705\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 64\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.004058156731771305\n",
      "Training Loss: 0.004182202717638575\n",
      "Training Loss: 0.004364960407838225\n",
      "Validation Loss: 0.016506157744822374\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 65\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.004053770965547301\n",
      "Training Loss: 0.004177994868950918\n",
      "Training Loss: 0.004360689199529588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:41<08:34, 73.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016508377907965124\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 66\n",
      "Early stopping after 66 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.5506631666421891\n",
      "Training Loss: 0.41747450560331345\n",
      "Training Loss: 0.2891980154812336\n",
      "Validation Loss: 0.17096071916349817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.1128405905328691\n",
      "Training Loss: 0.06485782142728568\n",
      "Training Loss: 0.05342306721955538\n",
      "Validation Loss: 0.06693834476591495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.051970511022955176\n",
      "Training Loss: 0.0494470245577395\n",
      "Training Loss: 0.045698505360633135\n",
      "Validation Loss: 0.06251079227063763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04483721544034779\n",
      "Training Loss: 0.04213066510856152\n",
      "Training Loss: 0.03842026797123253\n",
      "Validation Loss: 0.05716137893581658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03720149118453264\n",
      "Training Loss: 0.034443723224103454\n",
      "Training Loss: 0.030986500377766787\n",
      "Validation Loss: 0.05037744249102105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02949127126019448\n",
      "Training Loss: 0.02680136217735708\n",
      "Training Loss: 0.023699432970024647\n",
      "Validation Loss: 0.04269745985694816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.022139847413636744\n",
      "Training Loss: 0.019725653673522175\n",
      "Training Loss: 0.017388904322870075\n",
      "Validation Loss: 0.037540288035119516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.016559086560737343\n",
      "Training Loss: 0.014759665671736002\n",
      "Training Loss: 0.01354729944607243\n",
      "Validation Loss: 0.0359961180947721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013544994445983321\n",
      "Training Loss: 0.01222825975390151\n",
      "Training Loss: 0.011642363872379064\n",
      "Validation Loss: 0.03434668249565731\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011743332853075116\n",
      "Training Loss: 0.010673425027634948\n",
      "Training Loss: 0.010346771214390173\n",
      "Validation Loss: 0.032336717586587654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010346257315250114\n",
      "Training Loss: 0.009477329831570387\n",
      "Training Loss: 0.009308244198327884\n",
      "Validation Loss: 0.030492609753953608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009216084112413227\n",
      "Training Loss: 0.008516649003140628\n",
      "Training Loss: 0.00845870170276612\n",
      "Validation Loss: 0.028869562013221255\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00830557942041196\n",
      "Training Loss: 0.007741410492453724\n",
      "Training Loss: 0.007762950606411323\n",
      "Validation Loss: 0.02742350443653511\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.007572939903475344\n",
      "Training Loss: 0.00711410021642223\n",
      "Training Loss: 0.007192095288191922\n",
      "Validation Loss: 0.026123408704284538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0069806467322632675\n",
      "Training Loss: 0.006604319412726909\n",
      "Training Loss: 0.006722325466689653\n",
      "Validation Loss: 0.024957189195151074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.006498416184913367\n",
      "Training Loss: 0.006188372514443472\n",
      "Training Loss: 0.006334825450903736\n",
      "Validation Loss: 0.023920207744820066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00610325058165472\n",
      "Training Loss: 0.005848022775608115\n",
      "Training Loss: 0.006014732326148078\n",
      "Validation Loss: 0.023007466844963225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.005777800644282251\n",
      "Training Loss: 0.005568959332886152\n",
      "Training Loss: 0.005750010850024409\n",
      "Validation Loss: 0.022211104448298723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0055086890124948695\n",
      "Training Loss: 0.00533966604503803\n",
      "Training Loss: 0.005530697859940119\n",
      "Validation Loss: 0.021520822261868234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005285354086081498\n",
      "Training Loss: 0.005150773011264391\n",
      "Training Loss: 0.005348505612346344\n",
      "Validation Loss: 0.020924961231021066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005099364890484139\n",
      "Training Loss: 0.004994694295455702\n",
      "Training Loss: 0.005196627519326285\n",
      "Validation Loss: 0.020411909735772046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.004943997286027298\n",
      "Training Loss: 0.004865358679089695\n",
      "Training Loss: 0.005069562464486807\n",
      "Validation Loss: 0.01997090256092756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.004813892241218127\n",
      "Training Loss: 0.004757935520028695\n",
      "Training Loss: 0.004962901967810467\n",
      "Validation Loss: 0.019592434037058206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.004704760271706619\n",
      "Training Loss: 0.004668570073554292\n",
      "Training Loss: 0.004873122143326327\n",
      "Validation Loss: 0.01926826426152433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004613130821380765\n",
      "Training Loss: 0.004594152678619139\n",
      "Training Loss: 0.004797379741212353\n",
      "Validation Loss: 0.018991323064991766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.0045361395081272345\n",
      "Training Loss: 0.004532121070660651\n",
      "Training Loss: 0.0047333390190033246\n",
      "Validation Loss: 0.01875546197877841\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0044713834580034015\n",
      "Training Loss: 0.004480334995314479\n",
      "Training Loss: 0.0046790582785615695\n",
      "Validation Loss: 0.018555274264614903\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0044168176659150045\n",
      "Training Loss: 0.004436980573809706\n",
      "Training Loss: 0.0046328967058798295\n",
      "Validation Loss: 0.018385939365462137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004370692808297463\n",
      "Training Loss: 0.004400521588977426\n",
      "Training Loss: 0.004593468594248406\n",
      "Validation Loss: 0.01824314705504293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004331514906953089\n",
      "Training Loss: 0.004369659787043929\n",
      "Training Loss: 0.0045595966739347205\n",
      "Validation Loss: 0.0181229947961532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.00429802353901323\n",
      "Training Loss: 0.004343313893768936\n",
      "Training Loss: 0.00453029865573626\n",
      "Validation Loss: 0.018021992224613936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.004269165024743416\n",
      "Training Loss: 0.004320596330217086\n",
      "Training Loss: 0.004504755964153446\n",
      "Validation Loss: 0.017937024225993605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004244075626484118\n",
      "Training Loss: 0.004300789984408766\n",
      "Training Loss: 0.0044823000725591556\n",
      "Validation Loss: 0.017865420897292456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.004222054528654553\n",
      "Training Loss: 0.00428332480834797\n",
      "Training Loss: 0.00446238637319766\n",
      "Validation Loss: 0.01780482595315559\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0042025385273154825\n",
      "Training Loss: 0.004267750424332917\n",
      "Training Loss: 0.004444575916277244\n",
      "Validation Loss: 0.017753276191756463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004185081091709435\n",
      "Training Loss: 0.004253717738902196\n",
      "Training Loss: 0.004428517187479883\n",
      "Validation Loss: 0.017709064153493957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004169329418218694\n",
      "Training Loss: 0.0042409563477849585\n",
      "Training Loss: 0.004413930041482672\n",
      "Validation Loss: 0.017670823114641597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.004155004270724021\n",
      "Training Loss: 0.004229255254613235\n",
      "Training Loss: 0.0044005896570160985\n",
      "Validation Loss: 0.01763736124391134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004141884982236661\n",
      "Training Loss: 0.004218451864435337\n",
      "Training Loss: 0.004388315531541593\n",
      "Validation Loss: 0.0176077727960904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.004129795890767127\n",
      "Training Loss: 0.004208417952759192\n",
      "Training Loss: 0.004376961502130143\n",
      "Validation Loss: 0.017581208847107344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004118596622138284\n",
      "Training Loss: 0.004199053994379937\n",
      "Training Loss: 0.004366409689537249\n",
      "Validation Loss: 0.017557072175896905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.004108172281994484\n",
      "Training Loss: 0.004190277599846013\n",
      "Training Loss: 0.004356562037719414\n",
      "Validation Loss: 0.017534851656410465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.004098429442383349\n",
      "Training Loss: 0.004182023621397093\n",
      "Training Loss: 0.004347335827769711\n",
      "Validation Loss: 0.017514106705052296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004089289080002345\n",
      "Training Loss: 0.004174236978287809\n",
      "Training Loss: 0.004338662669761106\n",
      "Validation Loss: 0.01749449513141024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004080686754314229\n",
      "Training Loss: 0.004166870753397234\n",
      "Training Loss: 0.0043304854055168105\n",
      "Validation Loss: 0.017475769522840554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00407256516511552\n",
      "Training Loss: 0.00415988654771354\n",
      "Training Loss: 0.004322752961306833\n",
      "Validation Loss: 0.01745767985324093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004064876046031713\n",
      "Training Loss: 0.004153248111251741\n",
      "Training Loss: 0.004315421596984379\n",
      "Validation Loss: 0.017440081521701276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004057576404884458\n",
      "Training Loss: 0.004146925673703663\n",
      "Training Loss: 0.004308452631812542\n",
      "Validation Loss: 0.01742284889123664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004050629393896088\n",
      "Training Loss: 0.004140892379800789\n",
      "Training Loss: 0.0043018122157081964\n",
      "Validation Loss: 0.017405846852055762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.004044001509901136\n",
      "Training Loss: 0.0041351220750948416\n",
      "Training Loss: 0.004295471063232981\n",
      "Validation Loss: 0.017388992678646124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00403766440867912\n",
      "Training Loss: 0.004129593535326421\n",
      "Training Loss: 0.0042894021270331\n",
      "Validation Loss: 0.017372276817103117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004031590176746249\n",
      "Training Loss: 0.004124285883153789\n",
      "Training Loss: 0.0042835805006325245\n",
      "Validation Loss: 0.017355608774788592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004025755607290194\n",
      "Training Loss: 0.004119180379784666\n",
      "Training Loss: 0.004277985786902718\n",
      "Validation Loss: 0.01733899422596847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.004020139924250543\n",
      "Training Loss: 0.004114259844645858\n",
      "Training Loss: 0.004272597046801821\n",
      "Validation Loss: 0.017322399883708928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.004014722677529789\n",
      "Training Loss: 0.004109509236877784\n",
      "Training Loss: 0.004267397031071596\n",
      "Validation Loss: 0.01730580049504139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.004009486992727034\n",
      "Training Loss: 0.004104912573820911\n",
      "Training Loss: 0.004262370471842587\n",
      "Validation Loss: 0.017289221187362844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004004416631651111\n",
      "Training Loss: 0.004100457740714773\n",
      "Training Loss: 0.0042575019976357\n",
      "Validation Loss: 0.017272654319119254\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.003999497647746466\n",
      "Training Loss: 0.004096132017439231\n",
      "Training Loss: 0.0042527786368737\n",
      "Validation Loss: 0.017256101106785323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.003994715695735067\n",
      "Training Loss: 0.004091923870146274\n",
      "Training Loss: 0.004248187241028063\n",
      "Validation Loss: 0.017239583261164555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.003990060504293069\n",
      "Training Loss: 0.004087822667788715\n",
      "Training Loss: 0.004243718455545604\n",
      "Validation Loss: 0.0172230922224607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.003985519849229604\n",
      "Training Loss: 0.0040838191768853\n",
      "Training Loss: 0.004239360989886336\n",
      "Validation Loss: 0.01720665102521104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.003981085179257207\n",
      "Training Loss: 0.004079904904356227\n",
      "Training Loss: 0.004235107214190066\n",
      "Validation Loss: 0.017190270751107777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.003976747007109225\n",
      "Training Loss: 0.0040760711452458055\n",
      "Training Loss: 0.004230947144096717\n",
      "Validation Loss: 0.017173966683259004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.003972497165086679\n",
      "Training Loss: 0.0040723113453714176\n",
      "Training Loss: 0.004226874065352604\n",
      "Validation Loss: 0.017157723515011956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.003968328768387437\n",
      "Training Loss: 0.004068618030869402\n",
      "Training Loss: 0.00422288152796682\n",
      "Validation Loss: 0.01714159171567874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.003964235128951259\n",
      "Training Loss: 0.004064985709846951\n",
      "Training Loss: 0.0042189626087201755\n",
      "Validation Loss: 0.017125548645749354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.003960209775250405\n",
      "Training Loss: 0.004061408130801283\n",
      "Training Loss: 0.00421511253749486\n",
      "Validation Loss: 0.017109623618340224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.003956247580936179\n",
      "Training Loss: 0.004057880552718416\n",
      "Training Loss: 0.004211324526695534\n",
      "Validation Loss: 0.017093807524279428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.003952344065764919\n",
      "Training Loss: 0.004054398445878178\n",
      "Training Loss: 0.004207595768966712\n",
      "Validation Loss: 0.017078113402083015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0039484937483211975\n",
      "Training Loss: 0.004050957000581548\n",
      "Training Loss: 0.004203920669970103\n",
      "Validation Loss: 0.017062551242540056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.003944693239754997\n",
      "Training Loss: 0.004047553346026689\n",
      "Training Loss: 0.004200295909540728\n",
      "Validation Loss: 0.017047121649963803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.003940938487648964\n",
      "Training Loss: 0.004044183400692418\n",
      "Training Loss: 0.00419671765237581\n",
      "Validation Loss: 0.01703182746802739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.003937226214329712\n",
      "Training Loss: 0.004040843660477549\n",
      "Training Loss: 0.004193182749440893\n",
      "Validation Loss: 0.017016657989137294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.003933554147952236\n",
      "Training Loss: 0.004037532901857048\n",
      "Training Loss: 0.004189688628539443\n",
      "Validation Loss: 0.01700164013793378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.003929918833309784\n",
      "Training Loss: 0.00403424690826796\n",
      "Training Loss: 0.004186232375795953\n",
      "Validation Loss: 0.016986757294494618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.003926317933364771\n",
      "Training Loss: 0.004030984165146947\n",
      "Training Loss: 0.004182811192586087\n",
      "Validation Loss: 0.016972006944772064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.003922749765915796\n",
      "Training Loss: 0.004027742744656279\n",
      "Training Loss: 0.004179423896130174\n",
      "Validation Loss: 0.016957405575268557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.003919211911852472\n",
      "Training Loss: 0.004024520943057723\n",
      "Training Loss: 0.004176067698863335\n",
      "Validation Loss: 0.016942953672573976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.003915702971862629\n",
      "Training Loss: 0.004021316968137398\n",
      "Training Loss: 0.004172741527436301\n",
      "Validation Loss: 0.016928621698589472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.003912221499485895\n",
      "Training Loss: 0.004018129796604626\n",
      "Training Loss: 0.0041694434691453355\n",
      "Validation Loss: 0.01691442959041994\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.003908765587839298\n",
      "Training Loss: 0.004014957980252802\n",
      "Training Loss: 0.004166172043187544\n",
      "Validation Loss: 0.016900377696003305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0039053341216640546\n",
      "Training Loss: 0.00401180049055256\n",
      "Training Loss: 0.004162926179124043\n",
      "Validation Loss: 0.016886460783190272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0039019266155082733\n",
      "Training Loss: 0.004008656546357087\n",
      "Training Loss: 0.00415970406786073\n",
      "Validation Loss: 0.01687266749821687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.003898542132228613\n",
      "Training Loss: 0.004005524987587705\n",
      "Training Loss: 0.004156505885184743\n",
      "Validation Loss: 0.01685901373112051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0038951791980070993\n",
      "Training Loss: 0.004002406562212854\n",
      "Training Loss: 0.00415332964155823\n",
      "Validation Loss: 0.016845484347909355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.0038918383268173786\n",
      "Training Loss: 0.0039992994745261965\n",
      "Training Loss: 0.004150176093098708\n",
      "Validation Loss: 0.016832094869754288\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.003888518164167181\n",
      "Training Loss: 0.003996204367140308\n",
      "Training Loss: 0.004147042626864277\n",
      "Validation Loss: 0.01681882870812597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.0038852186675649137\n",
      "Training Loss: 0.003993120403029024\n",
      "Training Loss: 0.004143929723650217\n",
      "Validation Loss: 0.016805672521043695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00388193900405895\n",
      "Training Loss: 0.00399004727776628\n",
      "Training Loss: 0.0041408366634277625\n",
      "Validation Loss: 0.0167926640924736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.0038786790805170313\n",
      "Training Loss: 0.003986985091469251\n",
      "Training Loss: 0.0041377625823952255\n",
      "Validation Loss: 0.01677976098183668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.003875439300900325\n",
      "Training Loss: 0.003983933998970315\n",
      "Training Loss: 0.004134707632474601\n",
      "Validation Loss: 0.016767011199334866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.0038722190540283917\n",
      "Training Loss: 0.003980893492698669\n",
      "Training Loss: 0.004131671072682366\n",
      "Validation Loss: 0.01675438177719545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.0038690178463002666\n",
      "Training Loss: 0.003977864024345763\n",
      "Training Loss: 0.004128652912913822\n",
      "Validation Loss: 0.016741867109170454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0038658360490808263\n",
      "Training Loss: 0.00397484537854325\n",
      "Training Loss: 0.004125652587972582\n",
      "Validation Loss: 0.016729493293220574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.003862674062838778\n",
      "Training Loss: 0.003971838303841651\n",
      "Training Loss: 0.004122670335927978\n",
      "Validation Loss: 0.01671725482774082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.0038595315045677125\n",
      "Training Loss: 0.0039688426413340494\n",
      "Training Loss: 0.004119704911718145\n",
      "Validation Loss: 0.01670512764484444\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0038564087270060556\n",
      "Training Loss: 0.0039658582321135324\n",
      "Training Loss: 0.004116757161100395\n",
      "Validation Loss: 0.016693158381294166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.0038533048803219574\n",
      "Training Loss: 0.003962885942310095\n",
      "Training Loss: 0.004113825997919775\n",
      "Validation Loss: 0.01668132032958393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0038502210058504716\n",
      "Training Loss: 0.003959925295202993\n",
      "Training Loss: 0.0041109111130936075\n",
      "Validation Loss: 0.0166696300442341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.0038471570779802277\n",
      "Training Loss: 0.003956976811750792\n",
      "Training Loss: 0.004108013688237406\n",
      "Validation Loss: 0.016658063776519023\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.0038441128632985054\n",
      "Training Loss: 0.003954040289390832\n",
      "Training Loss: 0.004105132663971745\n",
      "Validation Loss: 0.01664668327888076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.0038410885841585695\n",
      "Training Loss: 0.003951117161195725\n",
      "Training Loss: 0.0041022675990825515\n",
      "Validation Loss: 0.01663542916119266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.0038380845467327162\n",
      "Training Loss: 0.003948206444038078\n",
      "Training Loss: 0.004099419332924299\n",
      "Validation Loss: 0.016624339144635066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0038351009966572746\n",
      "Training Loss: 0.003945308197289705\n",
      "Training Loss: 0.004096586590749212\n",
      "Validation Loss: 0.01661340598529728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.003832137520657852\n",
      "Training Loss: 0.003942423690459691\n",
      "Training Loss: 0.004093769260798581\n",
      "Validation Loss: 0.0166026380101449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.003829194306745194\n",
      "Training Loss: 0.003939552013180219\n",
      "Training Loss: 0.004090967650408856\n",
      "Validation Loss: 0.01659203702165337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.0038262714922893794\n",
      "Training Loss: 0.003936693849391304\n",
      "Training Loss: 0.004088181655970402\n",
      "Validation Loss: 0.016581606436416173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.003823369172750972\n",
      "Training Loss: 0.00393384944065474\n",
      "Training Loss: 0.004085410188999958\n",
      "Validation Loss: 0.016571369466863658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.003820487350458279\n",
      "Training Loss: 0.003931018983130343\n",
      "Training Loss: 0.004082653885125183\n",
      "Validation Loss: 0.016561288504306687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0038176260713953525\n",
      "Training Loss: 0.003928202140377835\n",
      "Training Loss: 0.004079912645393051\n",
      "Validation Loss: 0.01655140869172939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.0038147850608220325\n",
      "Training Loss: 0.00392539870692417\n",
      "Training Loss: 0.004077185549540445\n",
      "Validation Loss: 0.01654170244524067\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.0038119647547136992\n",
      "Training Loss: 0.003922609667060897\n",
      "Training Loss: 0.004074472492793575\n",
      "Validation Loss: 0.01653219432454933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00380916406866163\n",
      "Training Loss: 0.00391983431240078\n",
      "Training Loss: 0.0040717732149641965\n",
      "Validation Loss: 0.016522902087570075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.0038063840492395685\n",
      "Training Loss: 0.003917073249467649\n",
      "Training Loss: 0.004069087519310415\n",
      "Validation Loss: 0.01651377933560295\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.003803624783176929\n",
      "Training Loss: 0.003914325473597273\n",
      "Training Loss: 0.004066415646811947\n",
      "Validation Loss: 0.016504881283519474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.0038008850568439813\n",
      "Training Loss: 0.003911592197837308\n",
      "Training Loss: 0.004063756364048459\n",
      "Validation Loss: 0.0164961995781933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.003798165053012781\n",
      "Training Loss: 0.003908872412284836\n",
      "Training Loss: 0.004061109798494726\n",
      "Validation Loss: 0.016487713576179376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.0037954645534045996\n",
      "Training Loss: 0.003906166203087196\n",
      "Training Loss: 0.004058475504862145\n",
      "Validation Loss: 0.01647944999021593\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0037927838519681246\n",
      "Training Loss: 0.0039034737984184175\n",
      "Training Loss: 0.004055853373720311\n",
      "Validation Loss: 0.016471418410832626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0037901220872299745\n",
      "Training Loss: 0.0039007943903561684\n",
      "Training Loss: 0.0040532421972602605\n",
      "Validation Loss: 0.016463592502005985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0037874799111159516\n",
      "Training Loss: 0.0038981288339709863\n",
      "Training Loss: 0.004050642921356484\n",
      "Validation Loss: 0.016456018037194115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.003784855821286328\n",
      "Training Loss: 0.0038954763137735425\n",
      "Training Loss: 0.004048053873702884\n",
      "Validation Loss: 0.01644864322335114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0037822505144868047\n",
      "Training Loss: 0.003892836323357187\n",
      "Training Loss: 0.004045475516468286\n",
      "Validation Loss: 0.016441513221773705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.003779663195600733\n",
      "Training Loss: 0.0038902094325749203\n",
      "Training Loss: 0.004042907174443826\n",
      "Validation Loss: 0.016434607169266497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.003777093879180029\n",
      "Training Loss: 0.00388759481778834\n",
      "Training Loss: 0.004040348976850509\n",
      "Validation Loss: 0.016427959768059715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.0037745420791907235\n",
      "Training Loss: 0.0038849931268487127\n",
      "Training Loss: 0.004037800416699611\n",
      "Validation Loss: 0.016421542442769985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.003772007906809449\n",
      "Training Loss: 0.0038824035128345712\n",
      "Training Loss: 0.004035260328091681\n",
      "Validation Loss: 0.016415340009700047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.0037694898061454295\n",
      "Training Loss: 0.003879825351177715\n",
      "Training Loss: 0.004032728766323998\n",
      "Validation Loss: 0.01640941807476992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.0037669891957193614\n",
      "Training Loss: 0.0038772590894950556\n",
      "Training Loss: 0.004030205644667149\n",
      "Validation Loss: 0.016403740005086313\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.003764504477730952\n",
      "Training Loss: 0.0038747047033393755\n",
      "Training Loss: 0.004027690013754181\n",
      "Validation Loss: 0.016398316084438664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.003762034997926094\n",
      "Training Loss: 0.0038721608492778615\n",
      "Training Loss: 0.004025181944598444\n",
      "Validation Loss: 0.01639311850133739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.003759581396006979\n",
      "Training Loss: 0.003869628037791699\n",
      "Training Loss: 0.004022680913330987\n",
      "Validation Loss: 0.016388192192096723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0037571426486829296\n",
      "Training Loss: 0.003867106212419458\n",
      "Training Loss: 0.00402018660272006\n",
      "Validation Loss: 0.01638349772200742\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.003754718686104752\n",
      "Training Loss: 0.0038645945338066667\n",
      "Training Loss: 0.004017698574461975\n",
      "Validation Loss: 0.01637906846694983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.0037523090885952116\n",
      "Training Loss: 0.003862092620693147\n",
      "Training Loss: 0.0040152160520665345\n",
      "Validation Loss: 0.016374892529016465\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.0037499131995718925\n",
      "Training Loss: 0.0038596001773839816\n",
      "Training Loss: 0.004012739380123094\n",
      "Validation Loss: 0.016370967323525568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.003747530847904272\n",
      "Training Loss: 0.0038571175280958415\n",
      "Training Loss: 0.004010267546400428\n",
      "Validation Loss: 0.016367308934104076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.0037451609660638496\n",
      "Training Loss: 0.0038546440307982268\n",
      "Training Loss: 0.004007800893159583\n",
      "Validation Loss: 0.016363902572082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.0037428042222745718\n",
      "Training Loss: 0.0038521790388040245\n",
      "Training Loss: 0.004005338828428648\n",
      "Validation Loss: 0.01636075469654765\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.003740459861001\n",
      "Training Loss: 0.0038497230951907114\n",
      "Training Loss: 0.004002880430780351\n",
      "Validation Loss: 0.0163578664141006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.0037381276075029745\n",
      "Training Loss: 0.003847275275038555\n",
      "Training Loss: 0.004000425843405537\n",
      "Validation Loss: 0.01635524658276961\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.0037358065362786876\n",
      "Training Loss: 0.0038448353379499168\n",
      "Training Loss: 0.003997975104139187\n",
      "Validation Loss: 0.01635285404123617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.003733496540226042\n",
      "Training Loss: 0.0038424031459726392\n",
      "Training Loss: 0.003995526602957398\n",
      "Validation Loss: 0.01635077490806161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.0037311973213218154\n",
      "Training Loss: 0.003839978214818984\n",
      "Training Loss: 0.003993081793887541\n",
      "Validation Loss: 0.016348921824665217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.0037289084028452636\n",
      "Training Loss: 0.003837560886167921\n",
      "Training Loss: 0.0039906398911261935\n",
      "Validation Loss: 0.01634731215916658\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.0037266293773427607\n",
      "Training Loss: 0.0038351501396391543\n",
      "Training Loss: 0.003988199498853646\n",
      "Validation Loss: 0.016345993856365763\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.003724359796033241\n",
      "Training Loss: 0.003832746199914254\n",
      "Training Loss: 0.0039857615320943295\n",
      "Validation Loss: 0.016344934756857124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.003722100087325089\n",
      "Training Loss: 0.003830348560004495\n",
      "Training Loss: 0.003983325763256289\n",
      "Validation Loss: 0.016344127109211484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.003719848768087104\n",
      "Training Loss: 0.0038279570231679826\n",
      "Training Loss: 0.003980890838429332\n",
      "Validation Loss: 0.016343575201175187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.003717606207355857\n",
      "Training Loss: 0.0038255712011596187\n",
      "Training Loss: 0.003978457998018711\n",
      "Validation Loss: 0.01634329522363423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.0037153717898763716\n",
      "Training Loss: 0.003823191653937101\n",
      "Training Loss: 0.003976026173913852\n",
      "Validation Loss: 0.0163432664677417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.0037131450441665946\n",
      "Training Loss: 0.0038208168256096543\n",
      "Training Loss: 0.003973594501148909\n",
      "Validation Loss: 0.016343488724211628\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 152\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0037109260441502557\n",
      "Training Loss: 0.003818447350640781\n",
      "Training Loss: 0.003971164218964987\n",
      "Validation Loss: 0.016343971494627133\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 153\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.003708714078529738\n",
      "Training Loss: 0.003816082916455343\n",
      "Training Loss: 0.003968734642257914\n",
      "Validation Loss: 0.016344709209365288\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 154\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.0037065092200646178\n",
      "Training Loss: 0.003813723105704412\n",
      "Training Loss: 0.0039663054799893875\n",
      "Validation Loss: 0.016345702352399908\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 155\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.0037043108546640723\n",
      "Training Loss: 0.003811367515590973\n",
      "Training Loss: 0.003963876572088338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [06:24<10:52, 108.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016346953573814604\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 156\n",
      "Early stopping after 156 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.16432576928287745\n",
      "Training Loss: 0.11343899441882968\n",
      "Training Loss: 0.08233821500092744\n",
      "Validation Loss: 0.07254779093972083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06519515523687006\n",
      "Training Loss: 0.06188300643116236\n",
      "Training Loss: 0.05839577393606305\n",
      "Validation Loss: 0.06454290617048071\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05739967694506049\n",
      "Training Loss: 0.05517559277825058\n",
      "Training Loss: 0.05123785689473152\n",
      "Validation Loss: 0.05892600043770972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.049180102348327634\n",
      "Training Loss: 0.04621029610745609\n",
      "Training Loss: 0.04187866508029401\n",
      "Validation Loss: 0.051399486871917595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03864507652819157\n",
      "Training Loss: 0.034966486254706976\n",
      "Training Loss: 0.030622028396464884\n",
      "Validation Loss: 0.042538294736086654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.026976123587228357\n",
      "Training Loss: 0.02353141178376973\n",
      "Training Loss: 0.02038665775209665\n",
      "Validation Loss: 0.0351842985687296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01803233233746141\n",
      "Training Loss: 0.01589600447099656\n",
      "Training Loss: 0.014434769852086901\n",
      "Validation Loss: 0.03104558019909296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.013477134872227908\n",
      "Training Loss: 0.012390679374802857\n",
      "Training Loss: 0.0119040261185728\n",
      "Validation Loss: 0.028987857131182813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.01151472236495465\n",
      "Training Loss: 0.0109028380329255\n",
      "Training Loss: 0.010792951609473675\n",
      "Validation Loss: 0.02773927290808786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.010538238892331719\n",
      "Training Loss: 0.010114031034754589\n",
      "Training Loss: 0.010140798587817699\n",
      "Validation Loss: 0.026760735491479046\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.009895378586370497\n",
      "Training Loss: 0.009551078866934404\n",
      "Training Loss: 0.009627203366253525\n",
      "Validation Loss: 0.025843174322351312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009342187428846955\n",
      "Training Loss: 0.009028348402353004\n",
      "Training Loss: 0.009109767115442082\n",
      "Validation Loss: 0.024847940117999744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00874915967346169\n",
      "Training Loss: 0.008436338008614257\n",
      "Training Loss: 0.00849958004313521\n",
      "Validation Loss: 0.02373463050409984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008062276672571898\n",
      "Training Loss: 0.007748840764397755\n",
      "Training Loss: 0.007810995782492682\n",
      "Validation Loss: 0.02269446537463685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007374713236931712\n",
      "Training Loss: 0.007095062994631007\n",
      "Training Loss: 0.007202264375519007\n",
      "Validation Loss: 0.021968798369190162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.006838824601145461\n",
      "Training Loss: 0.0066061167238513005\n",
      "Training Loss: 0.006759836941491812\n",
      "Validation Loss: 0.02145649842248204\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.006445024309796281\n",
      "Training Loss: 0.006245339779998176\n",
      "Training Loss: 0.006422748502809554\n",
      "Validation Loss: 0.02097723295577289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.006119568460271694\n",
      "Training Loss: 0.005946852738852613\n",
      "Training Loss: 0.006137090343399904\n",
      "Validation Loss: 0.02048902656213286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.005831959736533463\n",
      "Training Loss: 0.005685382307856344\n",
      "Training Loss: 0.005884977662353776\n",
      "Validation Loss: 0.020004151797110445\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005575669083045795\n",
      "Training Loss: 0.005454607441206463\n",
      "Training Loss: 0.005661897711688652\n",
      "Validation Loss: 0.019538197517290377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005349854216910898\n",
      "Training Loss: 0.0052533370681339875\n",
      "Training Loss: 0.00546693938493263\n",
      "Validation Loss: 0.019103638181630314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.005154708732734434\n",
      "Training Loss: 0.005081472745514475\n",
      "Training Loss: 0.005299948018509895\n",
      "Validation Loss: 0.018710879622069135\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.00499017137044575\n",
      "Training Loss: 0.004938580411253497\n",
      "Training Loss: 0.005160393310943618\n",
      "Validation Loss: 0.018368413486109857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.004855209539528005\n",
      "Training Loss: 0.004823153913603165\n",
      "Training Loss: 0.005046773068024777\n",
      "Validation Loss: 0.018081585855715062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004747420885250903\n",
      "Training Loss: 0.0047323366301134226\n",
      "Training Loss: 0.004956404466647655\n",
      "Validation Loss: 0.01785107788870509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004663085517822765\n",
      "Training Loss: 0.004662169401999563\n",
      "Training Loss: 0.004885680008446798\n",
      "Validation Loss: 0.0176726118687624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.004597714354167693\n",
      "Training Loss: 0.004608255308121443\n",
      "Training Loss: 0.004830650672665797\n",
      "Validation Loss: 0.01753807615677125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.004546842441777698\n",
      "Training Loss: 0.004566498564090579\n",
      "Training Loss: 0.004787630745558999\n",
      "Validation Loss: 0.01743801690774101\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004506634798599407\n",
      "Training Loss: 0.0045335513161262496\n",
      "Training Loss: 0.004753558051888831\n",
      "Validation Loss: 0.017363557534480697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004474121338571422\n",
      "Training Loss: 0.004506908644689247\n",
      "Training Loss: 0.004726070473552681\n",
      "Validation Loss: 0.017307549231068305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.004447150627383962\n",
      "Training Loss: 0.0044847889180528\n",
      "Training Loss: 0.004703424473991618\n",
      "Validation Loss: 0.017264565466013685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.0044242119777482\n",
      "Training Loss: 0.004465953281032853\n",
      "Training Loss: 0.004684362069237977\n",
      "Validation Loss: 0.01723076142056772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004404259455623105\n",
      "Training Loss: 0.004449549398850649\n",
      "Training Loss: 0.004667984648840502\n",
      "Validation Loss: 0.017203439254669495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00438657165854238\n",
      "Training Loss: 0.004434989913715981\n",
      "Training Loss: 0.00465365473064594\n",
      "Validation Loss: 0.017180686929064354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.004370646355673671\n",
      "Training Loss: 0.004421867899363861\n",
      "Training Loss: 0.0046409167340607385\n",
      "Validation Loss: 0.01716119739268854\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004356131759705022\n",
      "Training Loss: 0.00440989937807899\n",
      "Training Loss: 0.004629446163307876\n",
      "Validation Loss: 0.017144037622518923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0043427791312569755\n",
      "Training Loss: 0.004398883205722086\n",
      "Training Loss: 0.004619006064604037\n",
      "Validation Loss: 0.017128547909931187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.004330405472428538\n",
      "Training Loss: 0.0043886720819864425\n",
      "Training Loss: 0.004609424370573834\n",
      "Validation Loss: 0.017114269031797736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004318875247263349\n",
      "Training Loss: 0.004379157109069638\n",
      "Training Loss: 0.004600568963796832\n",
      "Validation Loss: 0.01710085744519582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0043080836784793065\n",
      "Training Loss: 0.004370253728120587\n",
      "Training Loss: 0.004592338658112567\n",
      "Validation Loss: 0.017088061946789534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00429794910014607\n",
      "Training Loss: 0.00436189443047624\n",
      "Training Loss: 0.004584653944766615\n",
      "Validation Loss: 0.017075719895218028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0042884022655198355\n",
      "Training Loss: 0.004354022989864461\n",
      "Training Loss: 0.00457744812098099\n",
      "Validation Loss: 0.01706366010763672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.004279387137503363\n",
      "Training Loss: 0.004346593190566636\n",
      "Training Loss: 0.004570667830994353\n",
      "Validation Loss: 0.017051805464781068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00427085401432123\n",
      "Training Loss: 0.004339562613749876\n",
      "Training Loss: 0.004564265914668794\n",
      "Validation Loss: 0.017040072179012253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004262760676210746\n",
      "Training Loss: 0.004332895308034494\n",
      "Training Loss: 0.004558201485779136\n",
      "Validation Loss: 0.01702839270589894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.004255067871999927\n",
      "Training Loss: 0.004326558285392821\n",
      "Training Loss: 0.004552439773688093\n",
      "Validation Loss: 0.017016732487095038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004247742599691264\n",
      "Training Loss: 0.004320521331974306\n",
      "Training Loss: 0.004546948864299338\n",
      "Validation Loss: 0.0170050615816262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004240753346239217\n",
      "Training Loss: 0.0043147580925142395\n",
      "Training Loss: 0.004541699901164975\n",
      "Validation Loss: 0.01699337544013861\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004234072384424508\n",
      "Training Loss: 0.004309242847375572\n",
      "Training Loss: 0.00453666819492355\n",
      "Validation Loss: 0.01698163032448024\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00422767354582902\n",
      "Training Loss: 0.004303953226772137\n",
      "Training Loss: 0.004531830107735005\n",
      "Validation Loss: 0.016969851260021162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.004221534401876852\n",
      "Training Loss: 0.004298868852783926\n",
      "Training Loss: 0.004527166376356036\n",
      "Validation Loss: 0.01695803416045278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004215632934938185\n",
      "Training Loss: 0.0042939700209535655\n",
      "Training Loss: 0.0045226566880592145\n",
      "Validation Loss: 0.016946179250757514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004209949808428064\n",
      "Training Loss: 0.004289240016369149\n",
      "Training Loss: 0.0045182845336967144\n",
      "Validation Loss: 0.016934346258535647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.004204467377858237\n",
      "Training Loss: 0.004284661464625969\n",
      "Training Loss: 0.004514034512103535\n",
      "Validation Loss: 0.016922492855699377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0041991687990957875\n",
      "Training Loss: 0.004280220682849176\n",
      "Training Loss: 0.004509892725327518\n",
      "Validation Loss: 0.016910689893398393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0041940392262768\n",
      "Training Loss: 0.004275903145316989\n",
      "Training Loss: 0.004505846062966157\n",
      "Validation Loss: 0.016898939705171277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004189064291422255\n",
      "Training Loss: 0.004271697414806113\n",
      "Training Loss: 0.004501882065669633\n",
      "Validation Loss: 0.016887281665557557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.00418423107243143\n",
      "Training Loss: 0.004267590764211491\n",
      "Training Loss: 0.004497990224626847\n",
      "Validation Loss: 0.016875733255168026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.004179527731030248\n",
      "Training Loss: 0.004263572744093835\n",
      "Training Loss: 0.00449416083691176\n",
      "Validation Loss: 0.01686434900084657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.004174941939418204\n",
      "Training Loss: 0.004259633250767365\n",
      "Training Loss: 0.004490382595395204\n",
      "Validation Loss: 0.016853141098733197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.004170464146300219\n",
      "Training Loss: 0.004255762926186435\n",
      "Training Loss: 0.0044866490532876925\n",
      "Validation Loss: 0.01684215923593369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.004166083519230597\n",
      "Training Loss: 0.004251952806953341\n",
      "Training Loss: 0.004482949991361238\n",
      "Validation Loss: 0.016831435393960623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.004161790763610043\n",
      "Training Loss: 0.004248194383690134\n",
      "Training Loss: 0.004479278259968851\n",
      "Validation Loss: 0.016820994069736996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.004157576966099441\n",
      "Training Loss: 0.004244479742483236\n",
      "Training Loss: 0.004475626180355903\n",
      "Validation Loss: 0.016810878310771136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.004153433166211471\n",
      "Training Loss: 0.004240801350097172\n",
      "Training Loss: 0.0044719857440213675\n",
      "Validation Loss: 0.016801155394654762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.004149351007654332\n",
      "Training Loss: 0.004237151925335639\n",
      "Training Loss: 0.004468350819370244\n",
      "Validation Loss: 0.016791808233188276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.004145321877440438\n",
      "Training Loss: 0.004233524342998863\n",
      "Training Loss: 0.004464713830093388\n",
      "Validation Loss: 0.016782923083584964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0041413383407052605\n",
      "Training Loss: 0.004229911516304128\n",
      "Training Loss: 0.004461069147801026\n",
      "Validation Loss: 0.01677450407401062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.004137393054552376\n",
      "Training Loss: 0.0042263074655784294\n",
      "Training Loss: 0.004457409299502615\n",
      "Validation Loss: 0.01676662280119621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.004133478434523568\n",
      "Training Loss: 0.0042227058886783195\n",
      "Training Loss: 0.004453728659427725\n",
      "Validation Loss: 0.0167592966960471\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.004129586642375216\n",
      "Training Loss: 0.004219099787296727\n",
      "Training Loss: 0.004450020383810625\n",
      "Validation Loss: 0.016752586420102234\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.004125710893422365\n",
      "Training Loss: 0.004215483230073005\n",
      "Training Loss: 0.004446278629766312\n",
      "Validation Loss: 0.016746520240048177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.004121843844186515\n",
      "Training Loss: 0.004211850298452191\n",
      "Training Loss: 0.004442497301206458\n",
      "Validation Loss: 0.016741146953525337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.0041179792390903455\n",
      "Training Loss: 0.0042081956175388764\n",
      "Training Loss: 0.004438670510135126\n",
      "Validation Loss: 0.01673649249629777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.004114109025686048\n",
      "Training Loss: 0.0042045118159148845\n",
      "Training Loss: 0.004434792452375404\n",
      "Validation Loss: 0.016732632878414366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.004110227362252772\n",
      "Training Loss: 0.00420079491508659\n",
      "Training Loss: 0.004430857023689896\n",
      "Validation Loss: 0.01672957837320027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0041063273436157035\n",
      "Training Loss: 0.004197038294514641\n",
      "Training Loss: 0.0044268583771190605\n",
      "Validation Loss: 0.016727390699088573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.004102402327698655\n",
      "Training Loss: 0.0041932366404216735\n",
      "Training Loss: 0.0044227928604232145\n",
      "Validation Loss: 0.016726122996403595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.004098447165451944\n",
      "Training Loss: 0.004189385116915218\n",
      "Training Loss: 0.004418652697349899\n",
      "Validation Loss: 0.01672579911066575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.004094454564619809\n",
      "Training Loss: 0.004185477411956526\n",
      "Training Loss: 0.004414434811042156\n",
      "Validation Loss: 0.016726508924967787\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 80\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0040904189139837396\n",
      "Training Loss: 0.004181509693153202\n",
      "Training Loss: 0.004410133574274369\n",
      "Validation Loss: 0.016728257109002952\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 81\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.004086334845051169\n",
      "Training Loss: 0.004177476554759778\n",
      "Training Loss: 0.004405744776304346\n",
      "Validation Loss: 0.016731098652660346\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 82\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.004082197411335074\n",
      "Training Loss: 0.004173374801757746\n",
      "Training Loss: 0.004401265060296282\n",
      "Validation Loss: 0.016735072687184542\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 83\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.004078001658199355\n",
      "Training Loss: 0.004169199694297276\n",
      "Training Loss: 0.004396690895664506\n",
      "Validation Loss: 0.016740223332674484\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 84\n",
      "Early stopping after 84 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [07:52<08:25, 101.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.3773073135316372\n",
      "Training Loss: 0.27564119510352614\n",
      "Training Loss: 0.20541233725845814\n",
      "Validation Loss: 0.15129611871383164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.12274991430342197\n",
      "Training Loss: 0.07792410142719745\n",
      "Training Loss: 0.05732045892626047\n",
      "Validation Loss: 0.06076344489800126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.049409868363291025\n",
      "Training Loss: 0.04607091651298106\n",
      "Training Loss: 0.04354707703925669\n",
      "Validation Loss: 0.05518350411164627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04230668161064386\n",
      "Training Loss: 0.03939515635371208\n",
      "Training Loss: 0.03651700625196099\n",
      "Validation Loss: 0.04982388675673289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03456602991558611\n",
      "Training Loss: 0.03140555031131953\n",
      "Training Loss: 0.028504165606573224\n",
      "Validation Loss: 0.043938151089830346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02638269340619445\n",
      "Training Loss: 0.023552615437656643\n",
      "Training Loss: 0.021255655796267092\n",
      "Validation Loss: 0.03868689768937197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.0197682024538517\n",
      "Training Loss: 0.01780777856707573\n",
      "Training Loss: 0.016408004867844283\n",
      "Validation Loss: 0.03476017128592462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.015638312385417522\n",
      "Training Loss: 0.014428904708474875\n",
      "Training Loss: 0.013665242320857942\n",
      "Validation Loss: 0.031942603848037425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013240356729365885\n",
      "Training Loss: 0.012454872016096488\n",
      "Training Loss: 0.01204396243672818\n",
      "Validation Loss: 0.0298542437991232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011735607101581991\n",
      "Training Loss: 0.011168934599263594\n",
      "Training Loss: 0.010946783922845498\n",
      "Validation Loss: 0.028177020181849432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010655930598732084\n",
      "Training Loss: 0.010201151155633852\n",
      "Training Loss: 0.010077603382524104\n",
      "Validation Loss: 0.026680127738483165\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009757704278454184\n",
      "Training Loss: 0.009362611124524847\n",
      "Training Loss: 0.009293203444685786\n",
      "Validation Loss: 0.0252601272018438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00893555090529844\n",
      "Training Loss: 0.008588200553786009\n",
      "Training Loss: 0.008564604381099343\n",
      "Validation Loss: 0.02398582748817594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00819951236830093\n",
      "Training Loss: 0.007912203178275377\n",
      "Training Loss: 0.007941688932478428\n",
      "Validation Loss: 0.022998098113961266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007601307940203697\n",
      "Training Loss: 0.0073762157279998065\n",
      "Training Loss: 0.00745284311065916\n",
      "Validation Loss: 0.022297695954068657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007135223275399767\n",
      "Training Loss: 0.006956566057633609\n",
      "Training Loss: 0.007064616790157743\n",
      "Validation Loss: 0.021760973268387357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.006753756536636501\n",
      "Training Loss: 0.006606933192815631\n",
      "Training Loss: 0.006735763405449688\n",
      "Validation Loss: 0.02128940603559774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.006422759653651156\n",
      "Training Loss: 0.00630034628266003\n",
      "Training Loss: 0.006444857001770288\n",
      "Validation Loss: 0.0208441565294614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0061277391557814555\n",
      "Training Loss: 0.00602624103485141\n",
      "Training Loss: 0.006183803836465813\n",
      "Validation Loss: 0.0204176183141182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005863933796063065\n",
      "Training Loss: 0.005781540982425213\n",
      "Training Loss: 0.0059507258806843315\n",
      "Validation Loss: 0.020011166482117405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005630519351107068\n",
      "Training Loss: 0.0055660814413568006\n",
      "Training Loss: 0.005745950433774852\n",
      "Validation Loss: 0.019626444592820796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.005427404031506739\n",
      "Training Loss: 0.0053798120864666996\n",
      "Training Loss: 0.005569375230115838\n",
      "Validation Loss: 0.0192647556135996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.005253454681951553\n",
      "Training Loss: 0.005221405526972376\n",
      "Training Loss: 0.005419408515444956\n",
      "Validation Loss: 0.01892738502074996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.005106124141602777\n",
      "Training Loss: 0.005088191539398395\n",
      "Training Loss: 0.005293169189826585\n",
      "Validation Loss: 0.018615226010174565\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004981944792089053\n",
      "Training Loss: 0.004976740740821697\n",
      "Training Loss: 0.005187168891425244\n",
      "Validation Loss: 0.018328488391060174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004877226872486063\n",
      "Training Loss: 0.0048835095227696005\n",
      "Training Loss: 0.005097945681773126\n",
      "Validation Loss: 0.018066735864941324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.004788553911494091\n",
      "Training Loss: 0.004805250084027648\n",
      "Training Loss: 0.005022413513506763\n",
      "Validation Loss: 0.017829018707774327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.004712992639979347\n",
      "Training Loss: 0.004739183433703147\n",
      "Training Loss: 0.004957988708047196\n",
      "Validation Loss: 0.017614055691768278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.0046481353521812705\n",
      "Training Loss: 0.004683020153315738\n",
      "Training Loss: 0.004902573207509704\n",
      "Validation Loss: 0.01742035281070079\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004592040972202085\n",
      "Training Loss: 0.004634910789318383\n",
      "Training Loss: 0.004854494321043603\n",
      "Validation Loss: 0.01724628314082877\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.004543159924796782\n",
      "Training Loss: 0.004593378257122822\n",
      "Training Loss: 0.004812427632277832\n",
      "Validation Loss: 0.01709017367363813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.004500259750057012\n",
      "Training Loss: 0.004557244842872023\n",
      "Training Loss: 0.00477532425778918\n",
      "Validation Loss: 0.01695039764496634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004462351998081431\n",
      "Training Loss: 0.004525573210557922\n",
      "Training Loss: 0.004742355102789589\n",
      "Validation Loss: 0.016825372293026428\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.004428648523171433\n",
      "Training Loss: 0.004497615236905403\n",
      "Training Loss: 0.0047128592123044655\n",
      "Validation Loss: 0.01671362231914582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.004398509151069447\n",
      "Training Loss: 0.004472769422573037\n",
      "Training Loss: 0.004686304946080782\n",
      "Validation Loss: 0.01661383361147528\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004371412442997098\n",
      "Training Loss: 0.004450549452449195\n",
      "Training Loss: 0.0046622625685995445\n",
      "Validation Loss: 0.016524679770462968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004346930013271049\n",
      "Training Loss: 0.004430558970780112\n",
      "Training Loss: 0.004640379634220153\n",
      "Validation Loss: 0.016445081762111423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.004324704606551677\n",
      "Training Loss: 0.0044124720426043495\n",
      "Training Loss: 0.004620365952141583\n",
      "Validation Loss: 0.016373981860351196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0043044388765702025\n",
      "Training Loss: 0.004396017098915763\n",
      "Training Loss: 0.004601979705621488\n",
      "Validation Loss: 0.016310528935759926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.004285880648531019\n",
      "Training Loss: 0.004380968672339804\n",
      "Training Loss: 0.0045850134751526635\n",
      "Validation Loss: 0.01625387828137851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004268814342212863\n",
      "Training Loss: 0.004367135189240799\n",
      "Training Loss: 0.004569295697729103\n",
      "Validation Loss: 0.01620333172966925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.004253057515015825\n",
      "Training Loss: 0.004354354982497171\n",
      "Training Loss: 0.0045546754199313\n",
      "Validation Loss: 0.016158262466530453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.004238450767588802\n",
      "Training Loss: 0.0043424898228840905\n",
      "Training Loss: 0.004541026213555597\n",
      "Validation Loss: 0.01611811227918592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004224858477246016\n",
      "Training Loss: 0.0043314229394309225\n",
      "Training Loss: 0.004528236369369551\n",
      "Validation Loss: 0.016082405981220557\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004212164089549333\n",
      "Training Loss: 0.004321053441963159\n",
      "Training Loss: 0.004516212152666412\n",
      "Validation Loss: 0.016050711870612053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.004200264913379215\n",
      "Training Loss: 0.004311295593506657\n",
      "Training Loss: 0.004504870223463513\n",
      "Validation Loss: 0.01602262534787146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004189072306617163\n",
      "Training Loss: 0.004302075054147281\n",
      "Training Loss: 0.004494139777380042\n",
      "Validation Loss: 0.015997803950514852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004178511373465881\n",
      "Training Loss: 0.004293329161009751\n",
      "Training Loss: 0.004483959099161439\n",
      "Validation Loss: 0.01597596028704573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004168515683268197\n",
      "Training Loss: 0.004285003748955205\n",
      "Training Loss: 0.0044742742151720446\n",
      "Validation Loss: 0.015956764609102954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.004159028123831376\n",
      "Training Loss: 0.0042770511656999586\n",
      "Training Loss: 0.00446503858838696\n",
      "Validation Loss: 0.01593998759943113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.004149997852509841\n",
      "Training Loss: 0.004269431604188867\n",
      "Training Loss: 0.004456211245269515\n",
      "Validation Loss: 0.015925340168701296\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004141381251392886\n",
      "Training Loss: 0.004262109820265323\n",
      "Training Loss: 0.004447755982982926\n",
      "Validation Loss: 0.015912631937313113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004133139696787112\n",
      "Training Loss: 0.004255055378889665\n",
      "Training Loss: 0.004439640528871678\n",
      "Validation Loss: 0.015901664779469204\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.004125239655841142\n",
      "Training Loss: 0.004248241079621949\n",
      "Training Loss: 0.0044318369310349225\n",
      "Validation Loss: 0.015892227130596726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.004117649990366772\n",
      "Training Loss: 0.0042416431597666815\n",
      "Training Loss: 0.004424318832461722\n",
      "Validation Loss: 0.015884151700570174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.004110342920175754\n",
      "Training Loss: 0.00423524092126172\n",
      "Training Loss: 0.004417062971624546\n",
      "Validation Loss: 0.015877270087432324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004103295321692712\n",
      "Training Loss: 0.004229014360462315\n",
      "Training Loss: 0.0044100485788658265\n",
      "Validation Loss: 0.01587142691466162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.004096483482280746\n",
      "Training Loss: 0.004222946435329504\n",
      "Training Loss: 0.004403255049255677\n",
      "Validation Loss: 0.015866495810156124\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.004089886991423554\n",
      "Training Loss: 0.004217022151569836\n",
      "Training Loss: 0.004396665351232514\n",
      "Validation Loss: 0.015862376251247493\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.00408348809054587\n",
      "Training Loss: 0.004211226669722237\n",
      "Training Loss: 0.004390261424705386\n",
      "Validation Loss: 0.015858948481886573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.004077268600813113\n",
      "Training Loss: 0.004205546393641271\n",
      "Training Loss: 0.004384027675259858\n",
      "Validation Loss: 0.015856143314747162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00407121395575814\n",
      "Training Loss: 0.004199970549088903\n",
      "Training Loss: 0.00437794950499665\n",
      "Validation Loss: 0.015853847392698687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.004065308732679114\n",
      "Training Loss: 0.004194486467167735\n",
      "Training Loss: 0.004372013946413063\n",
      "Validation Loss: 0.01585202631697561\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.004059539880836382\n",
      "Training Loss: 0.004189085010439158\n",
      "Training Loss: 0.004366206655395217\n",
      "Validation Loss: 0.015850599096522908\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.004053894782555289\n",
      "Training Loss: 0.004183755913400092\n",
      "Training Loss: 0.00436051533499267\n",
      "Validation Loss: 0.015849571627972837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.004048362360335887\n",
      "Training Loss: 0.004178490545600652\n",
      "Training Loss: 0.004354930012486875\n",
      "Validation Loss: 0.015848839100910707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.004042931622825563\n",
      "Training Loss: 0.004173280545510352\n",
      "Training Loss: 0.004349439137731679\n",
      "Validation Loss: 0.015848415809568396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00403759288135916\n",
      "Training Loss: 0.004168119101086632\n",
      "Training Loss: 0.0043440328340511765\n",
      "Validation Loss: 0.01584826286076411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.004032337601529434\n",
      "Training Loss: 0.004162998974788934\n",
      "Training Loss: 0.004338702796958387\n",
      "Validation Loss: 0.015848388060864606\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 69\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.004027157101081685\n",
      "Training Loss: 0.004157914483221248\n",
      "Training Loss: 0.004333439255715348\n",
      "Validation Loss: 0.015848766784759216\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 70\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.004022044250741601\n",
      "Training Loss: 0.004152859480236657\n",
      "Training Loss: 0.004328235628199764\n",
      "Validation Loss: 0.015849375356972385\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 71\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.004016991255339235\n",
      "Training Loss: 0.004147829607245512\n",
      "Training Loss: 0.004323082920745946\n",
      "Validation Loss: 0.015850215940997843\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 72\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.004011991560691968\n",
      "Training Loss: 0.004142817989340983\n",
      "Training Loss: 0.004317975359153934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [09:08<06:10, 92.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.015851301823878724\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 73\n",
      "Early stopping after 73 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.7292816430330277\n",
      "Training Loss: 0.5672819857299328\n",
      "Training Loss: 0.4239041029661894\n",
      "Validation Loss: 0.28724234207962335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.21624394431710242\n",
      "Training Loss: 0.11199983771890402\n",
      "Training Loss: 0.06763674112036824\n",
      "Validation Loss: 0.07195387851823581\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05305002113804221\n",
      "Training Loss: 0.048039675997570155\n",
      "Training Loss: 0.04499694937840104\n",
      "Validation Loss: 0.06214938756455196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.04343404522165656\n",
      "Training Loss: 0.03966185302473604\n",
      "Training Loss: 0.036600962076336147\n",
      "Validation Loss: 0.054959166815943934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03489055072888732\n",
      "Training Loss: 0.03147411273792386\n",
      "Training Loss: 0.028628818336874248\n",
      "Validation Loss: 0.04854560682152429\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02706738217268139\n",
      "Training Loss: 0.0242353952024132\n",
      "Training Loss: 0.02200329736806452\n",
      "Validation Loss: 0.04300996090881945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.020948302852921187\n",
      "Training Loss: 0.01888158602640033\n",
      "Training Loss: 0.01739269990939647\n",
      "Validation Loss: 0.03834195155650377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.016760041972156615\n",
      "Training Loss: 0.015314427551347763\n",
      "Training Loss: 0.014404208024498075\n",
      "Validation Loss: 0.03459381599900093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013903768595773726\n",
      "Training Loss: 0.012832195102237164\n",
      "Training Loss: 0.012292843139730393\n",
      "Validation Loss: 0.03203784224441212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011778724119067193\n",
      "Training Loss: 0.010940082841552795\n",
      "Training Loss: 0.010659181782975792\n",
      "Validation Loss: 0.030574605638014802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.0101780408853665\n",
      "Training Loss: 0.009523415089352056\n",
      "Training Loss: 0.009434422644553707\n",
      "Validation Loss: 0.0294528963473322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009010899913264439\n",
      "Training Loss: 0.008490267905872316\n",
      "Training Loss: 0.008520666223485024\n",
      "Validation Loss: 0.028279142674016818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008139020714443177\n",
      "Training Loss: 0.007714535634731874\n",
      "Training Loss: 0.007816775105893611\n",
      "Validation Loss: 0.027102079373271613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.007466215982567519\n",
      "Training Loss: 0.007115622841520235\n",
      "Training Loss: 0.007263069412438199\n",
      "Validation Loss: 0.0260151375419973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.0069355432770680635\n",
      "Training Loss: 0.00664388993056491\n",
      "Training Loss: 0.006820722408592701\n",
      "Validation Loss: 0.025050495364023057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.00650846641859971\n",
      "Training Loss: 0.006264859699876979\n",
      "Training Loss: 0.006461387384915724\n",
      "Validation Loss: 0.024201535734902607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0061576331377727915\n",
      "Training Loss: 0.005953974153380841\n",
      "Training Loss: 0.0061642986891092735\n",
      "Validation Loss: 0.023446334348049727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.005863895438378677\n",
      "Training Loss: 0.00569409329094924\n",
      "Training Loss: 0.005914640579721891\n",
      "Validation Loss: 0.0227618490167883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00561411559523549\n",
      "Training Loss: 0.005473566419095732\n",
      "Training Loss: 0.005702082154457457\n",
      "Validation Loss: 0.022130591847169936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005399379640002735\n",
      "Training Loss: 0.005284588644863106\n",
      "Training Loss: 0.005519479039940052\n",
      "Validation Loss: 0.021541955875588603\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005213594892411493\n",
      "Training Loss: 0.005121907683787868\n",
      "Training Loss: 0.005361856806557625\n",
      "Validation Loss: 0.020991089738110143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.0050525046716211365\n",
      "Training Loss: 0.0049818664003396405\n",
      "Training Loss: 0.005225633402587846\n",
      "Validation Loss: 0.020476795727742858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.004912979432265274\n",
      "Training Loss: 0.004861742141074501\n",
      "Training Loss: 0.005108091577421874\n",
      "Validation Loss: 0.019999937463049473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.004792559801135212\n",
      "Training Loss: 0.004759323023026809\n",
      "Training Loss: 0.005007027640240267\n",
      "Validation Loss: 0.01956206484268723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004689165788004174\n",
      "Training Loss: 0.004672652225708589\n",
      "Training Loss: 0.004920522902975791\n",
      "Validation Loss: 0.019164606060288594\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004600914080510847\n",
      "Training Loss: 0.004599892100086436\n",
      "Training Loss: 0.004846832103794441\n",
      "Validation Loss: 0.018808298414635858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0045260260213399305\n",
      "Training Loss: 0.004539261184399948\n",
      "Training Loss: 0.004784315349534154\n",
      "Validation Loss: 0.018492878977146545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0044627908035181464\n",
      "Training Loss: 0.004489031282137148\n",
      "Training Loss: 0.0047314231761265545\n",
      "Validation Loss: 0.018217053039397083\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004409562785294838\n",
      "Training Loss: 0.004447549159522168\n",
      "Training Loss: 0.0046867068152641874\n",
      "Validation Loss: 0.017978490678216802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004364790024701506\n",
      "Training Loss: 0.004413277988205664\n",
      "Training Loss: 0.004648833576356992\n",
      "Validation Loss: 0.01777413818891045\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.004327039452618919\n",
      "Training Loss: 0.004384832495707087\n",
      "Training Loss: 0.004616611641249619\n",
      "Validation Loss: 0.01760041395338315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.004295035557006486\n",
      "Training Loss: 0.004361014118185267\n",
      "Training Loss: 0.004589005607413128\n",
      "Validation Loss: 0.01745354338664185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004267680941266008\n",
      "Training Loss: 0.004340824885875918\n",
      "Training Loss: 0.004565146552631631\n",
      "Validation Loss: 0.017329898024542947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.00424405875033699\n",
      "Training Loss: 0.004323459469596855\n",
      "Training Loss: 0.004544316658284515\n",
      "Validation Loss: 0.017225975659937505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.004223427188117057\n",
      "Training Loss: 0.004308288316824473\n",
      "Training Loss: 0.00452594437811058\n",
      "Validation Loss: 0.017138670277101604\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004205199320567772\n",
      "Training Loss: 0.004294831777224317\n",
      "Training Loss: 0.004509577035205439\n",
      "Validation Loss: 0.017065302293559306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004188918992877006\n",
      "Training Loss: 0.004282730923732742\n",
      "Training Loss: 0.004494861573330127\n",
      "Validation Loss: 0.017003571470738964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.004174234906677157\n",
      "Training Loss: 0.004271718311356381\n",
      "Training Loss: 0.0044815233844565225\n",
      "Validation Loss: 0.016951502227548803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004160876756650396\n",
      "Training Loss: 0.004261595686548389\n",
      "Training Loss: 0.004469346241676248\n",
      "Validation Loss: 0.016907530324010368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.004148636208265088\n",
      "Training Loss: 0.004252215943997726\n",
      "Training Loss: 0.004458160939393565\n",
      "Validation Loss: 0.01687032845802605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004137350899982266\n",
      "Training Loss: 0.004243467280757613\n",
      "Training Loss: 0.00444783138227649\n",
      "Validation Loss: 0.016838832096500177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.004126892135827802\n",
      "Training Loss: 0.00423526402330026\n",
      "Training Loss: 0.004438248025835491\n",
      "Validation Loss: 0.016812109495670104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.0041171575896441935\n",
      "Training Loss: 0.004227540053543635\n",
      "Training Loss: 0.004429319603950717\n",
      "Validation Loss: 0.016789434179454374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004108063424355351\n",
      "Training Loss: 0.004220240110298618\n",
      "Training Loss: 0.0044209708366543055\n",
      "Validation Loss: 0.016770220393042885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004099539635353722\n",
      "Training Loss: 0.004213320804410614\n",
      "Training Loss: 0.004413137319497764\n",
      "Validation Loss: 0.016753943686718852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00409152710752096\n",
      "Training Loss: 0.004206744628609158\n",
      "Training Loss: 0.004405763971153647\n",
      "Validation Loss: 0.016740208782067292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004083976459223777\n",
      "Training Loss: 0.004200480154249817\n",
      "Training Loss: 0.004398803046788089\n",
      "Validation Loss: 0.016728660136231043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004076843350776471\n",
      "Training Loss: 0.004194499119184911\n",
      "Training Loss: 0.0043922126886900515\n",
      "Validation Loss: 0.01671899246114693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004070088392472826\n",
      "Training Loss: 0.004188775303773582\n",
      "Training Loss: 0.0043859552568756045\n",
      "Validation Loss: 0.01671098290126394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.004063677547965199\n",
      "Training Loss: 0.004183287239866332\n",
      "Training Loss: 0.004379999270895496\n",
      "Validation Loss: 0.016704431549237852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.004057580481166952\n",
      "Training Loss: 0.004178014030912891\n",
      "Training Loss: 0.004374312483123504\n",
      "Validation Loss: 0.016699138377385025\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004051769045763649\n",
      "Training Loss: 0.0041729364410275594\n",
      "Training Loss: 0.004368870022008195\n",
      "Validation Loss: 0.01669496904765622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004046217246796004\n",
      "Training Loss: 0.0041680376185104255\n",
      "Training Loss: 0.0043636466551106425\n",
      "Validation Loss: 0.01669180884517813\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.004040902234264649\n",
      "Training Loss: 0.004163300169166178\n",
      "Training Loss: 0.004358619847916998\n",
      "Validation Loss: 0.016689550905917467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.0040358029701747\n",
      "Training Loss: 0.004158708841423504\n",
      "Training Loss: 0.0043537695059785615\n",
      "Validation Loss: 0.016688093634615285\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.00403089884610381\n",
      "Training Loss: 0.004154250134015456\n",
      "Training Loss: 0.0043490766966715454\n",
      "Validation Loss: 0.016687358789711018\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004026171758887358\n",
      "Training Loss: 0.004149908840772696\n",
      "Training Loss: 0.004344523680047132\n",
      "Validation Loss: 0.016687293442782393\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0040216045913985\n",
      "Training Loss: 0.004145673140301369\n",
      "Training Loss: 0.004340094341314398\n",
      "Validation Loss: 0.01668784008989257\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 58\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00401718090637587\n",
      "Training Loss: 0.004141530680353753\n",
      "Training Loss: 0.004335773555212654\n",
      "Validation Loss: 0.016688930331153817\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 59\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.004012886567506939\n",
      "Training Loss: 0.004137469578417949\n",
      "Training Loss: 0.004331547563779168\n",
      "Validation Loss: 0.01669054662840169\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 60\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.004008706989698112\n",
      "Training Loss: 0.004133478895528242\n",
      "Training Loss: 0.004327402376220562\n",
      "Validation Loss: 0.016692649400426765\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 61\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.004004629168775864\n",
      "Training Loss: 0.004129547263728455\n",
      "Training Loss: 0.0043233257404062895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [10:13<04:10, 83.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016695196871132998\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 62\n",
      "Early stopping after 62 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.34058753587305546\n",
      "Training Loss: 0.21668857909739017\n",
      "Training Loss: 0.12511736266314982\n",
      "Validation Loss: 0.08143067456195864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06280338931828737\n",
      "Training Loss: 0.052377994386479255\n",
      "Training Loss: 0.04885593711398542\n",
      "Validation Loss: 0.05842982060956151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04756446707993746\n",
      "Training Loss: 0.044896248588338496\n",
      "Training Loss: 0.041411368325352665\n",
      "Validation Loss: 0.052524265958770605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.03916967548429966\n",
      "Training Loss: 0.03606200598180294\n",
      "Training Loss: 0.03252909348346293\n",
      "Validation Loss: 0.04590857227782855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.029925174405798317\n",
      "Training Loss: 0.026932317963801324\n",
      "Training Loss: 0.024011913957074284\n",
      "Validation Loss: 0.04003570185911454\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.02194902552757412\n",
      "Training Loss: 0.019696115930564702\n",
      "Training Loss: 0.017878874843008815\n",
      "Validation Loss: 0.03588335669149509\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.016770909558981657\n",
      "Training Loss: 0.015367477536201476\n",
      "Training Loss: 0.014461469396483153\n",
      "Validation Loss: 0.03309689472649205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.013919139113277197\n",
      "Training Loss: 0.013043112109880895\n",
      "Training Loss: 0.012618113968055695\n",
      "Validation Loss: 0.031025978093025056\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.012264341693371534\n",
      "Training Loss: 0.011659526613075287\n",
      "Training Loss: 0.011470290056895465\n",
      "Validation Loss: 0.029386999007063302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.011169209948275239\n",
      "Training Loss: 0.010708178771892563\n",
      "Training Loss: 0.010646584093337878\n",
      "Validation Loss: 0.028048196331378113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010355549649102614\n",
      "Training Loss: 0.009974551318446174\n",
      "Training Loss: 0.009987493868684395\n",
      "Validation Loss: 0.026900887442229505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009684207481332124\n",
      "Training Loss: 0.009347260413924231\n",
      "Training Loss: 0.009403999941423536\n",
      "Validation Loss: 0.025844912949865788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009069629944860935\n",
      "Training Loss: 0.008753806678578257\n",
      "Training Loss: 0.008834517232608051\n",
      "Validation Loss: 0.024797646297413982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008452571863308549\n",
      "Training Loss: 0.008144045092049055\n",
      "Training Loss: 0.008237800801871344\n",
      "Validation Loss: 0.02372496576686756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007805132099892944\n",
      "Training Loss: 0.007505090749473311\n",
      "Training Loss: 0.007615826820838265\n",
      "Validation Loss: 0.022714446084259935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007167312966194004\n",
      "Training Loss: 0.006900595829938539\n",
      "Training Loss: 0.00704882406978868\n",
      "Validation Loss: 0.021978597658989806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.006651392780477181\n",
      "Training Loss: 0.006441349014639854\n",
      "Training Loss: 0.006630375478416681\n",
      "Validation Loss: 0.021546722007810735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.006297027389518916\n",
      "Training Loss: 0.0061281394306570295\n",
      "Training Loss: 0.006331968045560643\n",
      "Validation Loss: 0.02119598574308532\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.006029518606956117\n",
      "Training Loss: 0.005885460767894983\n",
      "Training Loss: 0.006090354081243277\n",
      "Validation Loss: 0.020819063235618426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005800035099964589\n",
      "Training Loss: 0.0056760931352619086\n",
      "Training Loss: 0.005879391182097606\n",
      "Validation Loss: 0.02041625679899635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005593486365978606\n",
      "Training Loss: 0.005488480543717742\n",
      "Training Loss: 0.005690309659694321\n",
      "Validation Loss: 0.020004091998876147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.005405278223915957\n",
      "Training Loss: 0.005318846975569613\n",
      "Training Loss: 0.005519768744707107\n",
      "Validation Loss: 0.019596475547995797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.005233881696476601\n",
      "Training Loss: 0.0051657761697424575\n",
      "Training Loss: 0.005366212435183116\n",
      "Validation Loss: 0.019204139442633043\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.005078649631468579\n",
      "Training Loss: 0.005028516401071101\n",
      "Training Loss: 0.005228646791074425\n",
      "Validation Loss: 0.018835158668081747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004939093239954673\n",
      "Training Loss: 0.004906428547692485\n",
      "Training Loss: 0.005106243655318394\n",
      "Validation Loss: 0.018495237161771635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004814662926946767\n",
      "Training Loss: 0.004798816063557751\n",
      "Training Loss: 0.004998210684279911\n",
      "Validation Loss: 0.01818787420346412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.004704688886995427\n",
      "Training Loss: 0.004704892238951288\n",
      "Training Loss: 0.004903743308968842\n",
      "Validation Loss: 0.01791464126135191\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.004608372491784394\n",
      "Training Loss: 0.004623769095051102\n",
      "Training Loss: 0.004821971681085415\n",
      "Validation Loss: 0.017675490011304116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004524776049074717\n",
      "Training Loss: 0.0045544510491890835\n",
      "Training Loss: 0.004751921652932652\n",
      "Validation Loss: 0.017469056902892802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.004452836387208663\n",
      "Training Loss: 0.004495841337484307\n",
      "Training Loss: 0.0046925090177683156\n",
      "Validation Loss: 0.017292978875129747\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.004391392293618992\n",
      "Training Loss: 0.004446764725144021\n",
      "Training Loss: 0.004642550769494847\n",
      "Validation Loss: 0.01714436769004116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.004339221938862465\n",
      "Training Loss: 0.004405999752925709\n",
      "Training Loss: 0.004600810722331516\n",
      "Validation Loss: 0.017020117467939015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004295095761190169\n",
      "Training Loss: 0.004372329157195054\n",
      "Training Loss: 0.004566058587515727\n",
      "Validation Loss: 0.01691705412283707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.004257830023416318\n",
      "Training Loss: 0.0043445865774992855\n",
      "Training Loss: 0.004537128062802367\n",
      "Validation Loss: 0.01683219499739536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.004226322826580145\n",
      "Training Loss: 0.004321698829880915\n",
      "Training Loss: 0.0045129544311203066\n",
      "Validation Loss: 0.016762800907109226\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004199587294715456\n",
      "Training Loss: 0.004302715128869749\n",
      "Training Loss: 0.004492607600986957\n",
      "Validation Loss: 0.016706386301143284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004176763161085546\n",
      "Training Loss: 0.004286821114365011\n",
      "Training Loss: 0.004475303186918609\n",
      "Validation Loss: 0.01666080315722927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.004157121720490977\n",
      "Training Loss: 0.0042733415681868794\n",
      "Training Loss: 0.004460392383043655\n",
      "Validation Loss: 0.01662418489302561\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004140058428747579\n",
      "Training Loss: 0.004261731322621927\n",
      "Training Loss: 0.0044473598350305114\n",
      "Validation Loss: 0.01659500382819705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.00412508106965106\n",
      "Training Loss: 0.004251561830169521\n",
      "Training Loss: 0.004435798948979937\n",
      "Validation Loss: 0.016571937073963913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.00411179386486765\n",
      "Training Loss: 0.004242501434637233\n",
      "Training Loss: 0.004425399551982991\n",
      "Validation Loss: 0.016553894729154667\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.004099883974995464\n",
      "Training Loss: 0.004234299515374005\n",
      "Training Loss: 0.0044159231835510585\n",
      "Validation Loss: 0.016540075670613833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.004089103844598867\n",
      "Training Loss: 0.0042267669155262415\n",
      "Training Loss: 0.004407192264916375\n",
      "Validation Loss: 0.016529717634358766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004079257632256485\n",
      "Training Loss: 0.0042197641922393815\n",
      "Training Loss: 0.004399071047082544\n",
      "Validation Loss: 0.01652232219538327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.0040701911301584915\n",
      "Training Loss: 0.004213187072309665\n",
      "Training Loss: 0.004391458774916828\n",
      "Validation Loss: 0.016517408812167438\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.004061782509670593\n",
      "Training Loss: 0.004206957631395198\n",
      "Training Loss: 0.004384278553188779\n",
      "Validation Loss: 0.016514619124341715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004053934183320962\n",
      "Training Loss: 0.00420101843366865\n",
      "Training Loss: 0.004377470351755619\n",
      "Validation Loss: 0.016513661525913336\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004046566908364184\n",
      "Training Loss: 0.0041953253443352875\n",
      "Training Loss: 0.004370988457230851\n",
      "Validation Loss: 0.016514272839772734\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 48\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004039617623784579\n",
      "Training Loss: 0.004189844339271076\n",
      "Training Loss: 0.0043647950509330255\n",
      "Validation Loss: 0.016516258981957865\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 49\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.004033032768638804\n",
      "Training Loss: 0.0041845489019760864\n",
      "Training Loss: 0.004358860697830096\n",
      "Validation Loss: 0.01651944584485269\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 50\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.00402677011967171\n",
      "Training Loss: 0.004179417242994532\n",
      "Training Loss: 0.004353160343016498\n",
      "Validation Loss: 0.016523710017751776\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 51\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004020792002556846\n",
      "Training Loss: 0.004174433046719059\n",
      "Training Loss: 0.004347673223237507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [11:07<02:28, 74.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.01652888131715106\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 52\n",
      "Early stopping after 52 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.11116851679980755\n",
      "Training Loss: 0.08721277754753828\n",
      "Training Loss: 0.07606401707977056\n",
      "Validation Loss: 0.0745028866810745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.07130225764587522\n",
      "Training Loss: 0.06815222572535276\n",
      "Training Loss: 0.06386476010084152\n",
      "Validation Loss: 0.0668473770276884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.06185092430561781\n",
      "Training Loss: 0.05898643884807825\n",
      "Training Loss: 0.05451818026602268\n",
      "Validation Loss: 0.05911879272859418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.05129453219473362\n",
      "Training Loss: 0.047456677863374354\n",
      "Training Loss: 0.04249600954353809\n",
      "Validation Loss: 0.04961300234237079\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.03806769088841975\n",
      "Training Loss: 0.033780526984483\n",
      "Training Loss: 0.02931212296243757\n",
      "Validation Loss: 0.04063344027930766\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.025478495387360453\n",
      "Training Loss: 0.02219136593863368\n",
      "Training Loss: 0.019422445236705242\n",
      "Validation Loss: 0.03453181392063251\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.017404720196500422\n",
      "Training Loss: 0.015573708391748368\n",
      "Training Loss: 0.014315925962291658\n",
      "Validation Loss: 0.0311377844459304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.013479513886850328\n",
      "Training Loss: 0.012532129494938999\n",
      "Training Loss: 0.012048660705331712\n",
      "Validation Loss: 0.029307349098406817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.011663090975489468\n",
      "Training Loss: 0.011116586254211143\n",
      "Training Loss: 0.01096948293969035\n",
      "Validation Loss: 0.02819447439645281\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.010730479741469026\n",
      "Training Loss: 0.010357612378429621\n",
      "Training Loss: 0.010360283069312573\n",
      "Validation Loss: 0.027411915534542183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.010174111074302345\n",
      "Training Loss: 0.009882586683379485\n",
      "Training Loss: 0.009960313534829766\n",
      "Validation Loss: 0.0268178428470921\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.009798180522629991\n",
      "Training Loss: 0.00954932605731301\n",
      "Training Loss: 0.009669132707640528\n",
      "Validation Loss: 0.026345661862261508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.009518517282558606\n",
      "Training Loss: 0.009293850659159943\n",
      "Training Loss: 0.00943874457385391\n",
      "Validation Loss: 0.025949551891326236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.009291502175619826\n",
      "Training Loss: 0.009080786909908056\n",
      "Training Loss: 0.00924081017030403\n",
      "Validation Loss: 0.025594196622416878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.009090033660177141\n",
      "Training Loss: 0.008886737204156815\n",
      "Training Loss: 0.009055371882859618\n",
      "Validation Loss: 0.02525087325634916\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008894036796409637\n",
      "Training Loss: 0.00869327805005014\n",
      "Training Loss: 0.008865675723645836\n",
      "Validation Loss: 0.024893770460039377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00868573947576806\n",
      "Training Loss: 0.008483145631616935\n",
      "Training Loss: 0.008655083337798715\n",
      "Validation Loss: 0.024497417288340543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008446844165446237\n",
      "Training Loss: 0.008237884872360155\n",
      "Training Loss: 0.008405203964794055\n",
      "Validation Loss: 0.024036187008860406\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00815732778981328\n",
      "Training Loss: 0.007937310449779033\n",
      "Training Loss: 0.00809613823890686\n",
      "Validation Loss: 0.023489375242942506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007797771740006283\n",
      "Training Loss: 0.007563472408801317\n",
      "Training Loss: 0.0077123432874213905\n",
      "Validation Loss: 0.02285894128923001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007360538588836789\n",
      "Training Loss: 0.007115475932369009\n",
      "Training Loss: 0.007261106747901067\n",
      "Validation Loss: 0.02220719238596686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.006876450452255085\n",
      "Training Loss: 0.006639393761288375\n",
      "Training Loss: 0.006803138530231081\n",
      "Validation Loss: 0.021680170068454543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.006438237818656489\n",
      "Training Loss: 0.0062377650430426\n",
      "Training Loss: 0.006440696339122951\n",
      "Validation Loss: 0.021377104831587397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0061292729462729765\n",
      "Training Loss: 0.005967117388499901\n",
      "Training Loss: 0.00619835497403983\n",
      "Validation Loss: 0.02119206100325571\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.005920339273288846\n",
      "Training Loss: 0.005780189792858437\n",
      "Training Loss: 0.006021845263312571\n",
      "Validation Loss: 0.02100052684022302\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.005755452516605146\n",
      "Training Loss: 0.005629581960383803\n",
      "Training Loss: 0.005874531884910539\n",
      "Validation Loss: 0.020775145011315686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.005610657882061787\n",
      "Training Loss: 0.005497263330034911\n",
      "Training Loss: 0.005743473683833144\n",
      "Validation Loss: 0.020525607144397297\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.005478538383031264\n",
      "Training Loss: 0.005377388836350292\n",
      "Training Loss: 0.005624193995608948\n",
      "Validation Loss: 0.02026333821560727\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.005356662425911054\n",
      "Training Loss: 0.0052678900910541416\n",
      "Training Loss: 0.005515005221241154\n",
      "Validation Loss: 0.01999692888302582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.005244269681279548\n",
      "Training Loss: 0.005168023998849094\n",
      "Training Loss: 0.0054152680130209775\n",
      "Validation Loss: 0.019733209646924325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.005141189114656299\n",
      "Training Loss: 0.005077472731936723\n",
      "Training Loss: 0.0053246709768427535\n",
      "Validation Loss: 0.01947776636035506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.005047338181175292\n",
      "Training Loss: 0.0049959433783078565\n",
      "Training Loss: 0.005242889379151166\n",
      "Validation Loss: 0.01923477736019184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004962486570002511\n",
      "Training Loss: 0.0049229966627899555\n",
      "Training Loss: 0.005169459699536674\n",
      "Validation Loss: 0.019007029393792486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.004886204254580662\n",
      "Training Loss: 0.004858039620448835\n",
      "Training Loss: 0.005103784933453426\n",
      "Validation Loss: 0.018796046008094307\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0048178995185298844\n",
      "Training Loss: 0.0048003715300001205\n",
      "Training Loss: 0.0050451785436598584\n",
      "Validation Loss: 0.01860233590142864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004756878986372612\n",
      "Training Loss: 0.004749244674458169\n",
      "Training Loss: 0.004992922705132514\n",
      "Validation Loss: 0.018425684801585386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004702414972125552\n",
      "Training Loss: 0.004703918150044046\n",
      "Training Loss: 0.004946315714623779\n",
      "Validation Loss: 0.018265389714369112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0046537916857050735\n",
      "Training Loss: 0.004663690340821631\n",
      "Training Loss: 0.004904694931465201\n",
      "Validation Loss: 0.01812042176116551\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004610337027697824\n",
      "Training Loss: 0.004627924420055933\n",
      "Training Loss: 0.0048674645437859\n",
      "Validation Loss: 0.017989603491248878\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.004571432434604503\n",
      "Training Loss: 0.004596047184895724\n",
      "Training Loss: 0.004834082305897027\n",
      "Validation Loss: 0.01787170601401771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004536524414434097\n",
      "Training Loss: 0.004567553344531916\n",
      "Training Loss: 0.004804076012806036\n",
      "Validation Loss: 0.017765514612762948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.004505118388915434\n",
      "Training Loss: 0.004542002240777947\n",
      "Training Loss: 0.004777027752134018\n",
      "Validation Loss: 0.017669797890683573\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.0044767822360154245\n",
      "Training Loss: 0.0045190105494111775\n",
      "Training Loss: 0.004752574794692919\n",
      "Validation Loss: 0.017583448403211455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004451136187417433\n",
      "Training Loss: 0.004498248400050215\n",
      "Training Loss: 0.004730401049600914\n",
      "Validation Loss: 0.017505441567326866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004427849837811664\n",
      "Training Loss: 0.004479428821941838\n",
      "Training Loss: 0.004710231221397407\n",
      "Validation Loss: 0.0174347883550806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.004406635058694519\n",
      "Training Loss: 0.004462306958739646\n",
      "Training Loss: 0.0046918277343502264\n",
      "Validation Loss: 0.017370638016381123\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004387244257377461\n",
      "Training Loss: 0.0044466726860264314\n",
      "Training Loss: 0.004674984420998954\n",
      "Validation Loss: 0.017312244671721305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004369461753522046\n",
      "Training Loss: 0.00443234350066632\n",
      "Training Loss: 0.004659521308494732\n",
      "Validation Loss: 0.017258901737651294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004353102560853586\n",
      "Training Loss: 0.004419165777508169\n",
      "Training Loss: 0.0046452840458368885\n",
      "Validation Loss: 0.017210012202391798\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.004338005884783343\n",
      "Training Loss: 0.00440700525417924\n",
      "Training Loss: 0.004632136470754631\n",
      "Validation Loss: 0.01716505408841656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.004324031346477568\n",
      "Training Loss: 0.004395746503141709\n",
      "Training Loss: 0.0046199623506981875\n",
      "Validation Loss: 0.017123541993538986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004311060105683282\n",
      "Training Loss: 0.0043852913606679065\n",
      "Training Loss: 0.004608657668577507\n",
      "Validation Loss: 0.01708511498840421\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004298987250658684\n",
      "Training Loss: 0.004375554352300241\n",
      "Training Loss: 0.004598133789259009\n",
      "Validation Loss: 0.017049364923509988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.004287722716690041\n",
      "Training Loss: 0.004366460385499522\n",
      "Training Loss: 0.004588312587584369\n",
      "Validation Loss: 0.01701600197441039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.004277187030529603\n",
      "Training Loss: 0.004357945384690538\n",
      "Training Loss: 0.004579124361043796\n",
      "Validation Loss: 0.016984777007084548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.004267309448914602\n",
      "Training Loss: 0.004349951721378602\n",
      "Training Loss: 0.004570507804746739\n",
      "Validation Loss: 0.0169554345016734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004258031354984268\n",
      "Training Loss: 0.0043424309458350765\n",
      "Training Loss: 0.004562409098143689\n",
      "Validation Loss: 0.016927778401694606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.004249297175556421\n",
      "Training Loss: 0.004335337887168862\n",
      "Training Loss: 0.004554780048783869\n",
      "Validation Loss: 0.016901634492273075\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.004241059225751087\n",
      "Training Loss: 0.004328632890828885\n",
      "Training Loss: 0.004547576957847923\n",
      "Validation Loss: 0.016876876974227222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.004233274245634675\n",
      "Training Loss: 0.004322281898348592\n",
      "Training Loss: 0.004540760820964352\n",
      "Validation Loss: 0.016853344911876858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00422590451373253\n",
      "Training Loss: 0.00431625259865541\n",
      "Training Loss: 0.004534296573256142\n",
      "Validation Loss: 0.01683093599315858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00421891569159925\n",
      "Training Loss: 0.004310517009580508\n",
      "Training Loss: 0.004528153298306279\n",
      "Validation Loss: 0.016809542323305702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.004212276781909168\n",
      "Training Loss: 0.0043050499720266085\n",
      "Training Loss: 0.004522302339319139\n",
      "Validation Loss: 0.0167891090170721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.004205959842656739\n",
      "Training Loss: 0.004299827772192657\n",
      "Training Loss: 0.004516717820079066\n",
      "Validation Loss: 0.016769521440682788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.004199939043610356\n",
      "Training Loss: 0.00429482911771629\n",
      "Training Loss: 0.0045113758923253046\n",
      "Validation Loss: 0.016750751698933794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.004194191209389828\n",
      "Training Loss: 0.004290035942103714\n",
      "Training Loss: 0.004506255282904021\n",
      "Validation Loss: 0.016732749181244982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.004188695352640934\n",
      "Training Loss: 0.004285429666051641\n",
      "Training Loss: 0.004501336745452136\n",
      "Validation Loss: 0.0167154628663125\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.004183431815472431\n",
      "Training Loss: 0.004280995216686278\n",
      "Training Loss: 0.004496601444552653\n",
      "Validation Loss: 0.016698855995671467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.00417838312627282\n",
      "Training Loss: 0.0042767176707275215\n",
      "Training Loss: 0.0044920346728758885\n",
      "Validation Loss: 0.01668288832101343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.00417353336699307\n",
      "Training Loss: 0.004272583399433642\n",
      "Training Loss: 0.004487621471052989\n",
      "Validation Loss: 0.016667517689527588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.004168867382104508\n",
      "Training Loss: 0.004268581938231364\n",
      "Training Loss: 0.004483348815701902\n",
      "Validation Loss: 0.01665278216771614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.004164372259983793\n",
      "Training Loss: 0.0042647005815524604\n",
      "Training Loss: 0.004479203500086442\n",
      "Validation Loss: 0.01663860636030774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.004160035393433645\n",
      "Training Loss: 0.004260930201853625\n",
      "Training Loss: 0.004475175575353205\n",
      "Validation Loss: 0.016625023177521448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.00415584473812487\n",
      "Training Loss: 0.00425726177461911\n",
      "Training Loss: 0.004471254168311134\n",
      "Validation Loss: 0.0166119711572995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.004151790314936079\n",
      "Training Loss: 0.0042536869156174365\n",
      "Training Loss: 0.004467431119410321\n",
      "Validation Loss: 0.016599485148372273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.004147862804820761\n",
      "Training Loss: 0.00425019831804093\n",
      "Training Loss: 0.0044636984093813226\n",
      "Validation Loss: 0.01658753557078373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.004144053470226936\n",
      "Training Loss: 0.004246789429453201\n",
      "Training Loss: 0.004460047908942215\n",
      "Validation Loss: 0.016576134058217822\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.004140353835537098\n",
      "Training Loss: 0.004243453483213671\n",
      "Training Loss: 0.004456472970196046\n",
      "Validation Loss: 0.016565276757196597\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.004136756549123675\n",
      "Training Loss: 0.004240184618975035\n",
      "Training Loss: 0.0044529682106804105\n",
      "Validation Loss: 0.01655493742587526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.004133255178458057\n",
      "Training Loss: 0.0042369789944496005\n",
      "Training Loss: 0.004449527465621941\n",
      "Validation Loss: 0.016545124804559216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0041298428224399684\n",
      "Training Loss: 0.004233831224846654\n",
      "Training Loss: 0.004446146847330965\n",
      "Validation Loss: 0.01653584843930485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.0041265143733471635\n",
      "Training Loss: 0.00423073724086862\n",
      "Training Loss: 0.00444282078417018\n",
      "Validation Loss: 0.016527096128740003\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.004123264498193748\n",
      "Training Loss: 0.004227693460416048\n",
      "Training Loss: 0.004439546157373115\n",
      "Validation Loss: 0.01651888171974779\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.004120087731280364\n",
      "Training Loss: 0.004224696459132247\n",
      "Training Loss: 0.0044363181095104665\n",
      "Validation Loss: 0.016511176555846514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.004116979994578287\n",
      "Training Loss: 0.0042217430996242915\n",
      "Training Loss: 0.004433135303552263\n",
      "Validation Loss: 0.01650401265255772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.004113936949870549\n",
      "Training Loss: 0.004218830158933997\n",
      "Training Loss: 0.004429993057856336\n",
      "Validation Loss: 0.01649737846252791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.004110955139040016\n",
      "Training Loss: 0.004215955934487283\n",
      "Training Loss: 0.004426889104652218\n",
      "Validation Loss: 0.016491268730063117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.004108030167990364\n",
      "Training Loss: 0.004213117696344852\n",
      "Training Loss: 0.004423822076059878\n",
      "Validation Loss: 0.016485671873800876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.004105159491300583\n",
      "Training Loss: 0.004210313656949438\n",
      "Training Loss: 0.004420789576251991\n",
      "Validation Loss: 0.016480593881936054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.004102339405799285\n",
      "Training Loss: 0.004207541350624524\n",
      "Training Loss: 0.004417788627324626\n",
      "Validation Loss: 0.01647604965824592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.00409956747549586\n",
      "Training Loss: 0.0042047994479071345\n",
      "Training Loss: 0.0044148183520883325\n",
      "Validation Loss: 0.016472011142713804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.004096841022837907\n",
      "Training Loss: 0.00420208656520117\n",
      "Training Loss: 0.004411876547965221\n",
      "Validation Loss: 0.016468482816675574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.004094156955252401\n",
      "Training Loss: 0.004199400408542715\n",
      "Training Loss: 0.004408962426823564\n",
      "Validation Loss: 0.016465456588612346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.004091513477615081\n",
      "Training Loss: 0.004196740212501026\n",
      "Training Loss: 0.004406073873396963\n",
      "Validation Loss: 0.016462943616082495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.004088908492703922\n",
      "Training Loss: 0.004194104133057408\n",
      "Training Loss: 0.004403210032032803\n",
      "Validation Loss: 0.016460915959408778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.004086339739151299\n",
      "Training Loss: 0.004191492023528554\n",
      "Training Loss: 0.004400370423682034\n",
      "Validation Loss: 0.016459387243107967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.004083804713445716\n",
      "Training Loss: 0.004188902510795742\n",
      "Training Loss: 0.004397553887101822\n",
      "Validation Loss: 0.016458343366537703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.004081301941187121\n",
      "Training Loss: 0.004186333898687735\n",
      "Training Loss: 0.004394758345442824\n",
      "Validation Loss: 0.016457761593393228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0040788301371503626\n",
      "Training Loss: 0.004183785663335584\n",
      "Training Loss: 0.004391984203830361\n",
      "Validation Loss: 0.01645765378495699\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.004076386901433579\n",
      "Training Loss: 0.0041812569269677625\n",
      "Training Loss: 0.004389229930238798\n",
      "Validation Loss: 0.016458000966839578\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 100\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.004073970603058114\n",
      "Training Loss: 0.004178747193072922\n",
      "Training Loss: 0.004386494834325277\n",
      "Validation Loss: 0.016458802176325508\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 101\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.004071580259478651\n",
      "Training Loss: 0.004176255321362987\n",
      "Training Loss: 0.004383778680348769\n",
      "Validation Loss: 0.01646003789226577\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 102\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.004069213769398629\n",
      "Training Loss: 0.004173780803685076\n",
      "Training Loss: 0.004381080655730329\n",
      "Validation Loss: 0.016461686084695747\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 103\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00406687080860138\n",
      "Training Loss: 0.004171322495094501\n",
      "Training Loss: 0.004378400287823752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [12:55<01:24, 84.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016463742146707986\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 104\n",
      "Early stopping after 104 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.07539870679378509\n",
      "Training Loss: 0.069364838860929\n",
      "Training Loss: 0.0643068665266037\n",
      "Validation Loss: 0.06762443535197317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.060618198774755\n",
      "Training Loss: 0.05670572002418339\n",
      "Training Loss: 0.05106452191248536\n",
      "Validation Loss: 0.056657328971483734\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.045759299322962764\n",
      "Training Loss: 0.04112690822221339\n",
      "Training Loss: 0.03566788444295525\n",
      "Validation Loss: 0.04559687812802162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.030554107995703815\n",
      "Training Loss: 0.026604720717296006\n",
      "Training Loss: 0.02297801023349166\n",
      "Validation Loss: 0.03766127915404151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.020049992548301816\n",
      "Training Loss: 0.017679642741568385\n",
      "Training Loss: 0.01601682080421597\n",
      "Validation Loss: 0.03310315077601189\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.0148018409172073\n",
      "Training Loss: 0.013538337296340614\n",
      "Training Loss: 0.012892132059205324\n",
      "Validation Loss: 0.030518846371828504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.012336965713184328\n",
      "Training Loss: 0.011600739567074924\n",
      "Training Loss: 0.011374717880971729\n",
      "Validation Loss: 0.02886200983998146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.011007632768014445\n",
      "Training Loss: 0.010511789417359979\n",
      "Training Loss: 0.010464733582921326\n",
      "Validation Loss: 0.02760220973574546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.010131354635814206\n",
      "Training Loss: 0.009747450081631541\n",
      "Training Loss: 0.009776017083786427\n",
      "Validation Loss: 0.0264429759830655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.009400093210861087\n",
      "Training Loss: 0.009053222332149745\n",
      "Training Loss: 0.009089519190602004\n",
      "Validation Loss: 0.025122494384478986\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.008599885400617496\n",
      "Training Loss: 0.008245673882775008\n",
      "Training Loss: 0.008256939543643966\n",
      "Validation Loss: 0.02364865056333247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.007686558503191918\n",
      "Training Loss: 0.007372998362407088\n",
      "Training Loss: 0.007425168204354122\n",
      "Validation Loss: 0.022636587919897578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.006951663770596497\n",
      "Training Loss: 0.0067326839437009765\n",
      "Training Loss: 0.006855904810363427\n",
      "Validation Loss: 0.022097454934768126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.006492917770519853\n",
      "Training Loss: 0.006325213443487882\n",
      "Training Loss: 0.006482752764131874\n",
      "Validation Loss: 0.021630321278791415\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.006174900506739505\n",
      "Training Loss: 0.006034305476932786\n",
      "Training Loss: 0.0062089075025869534\n",
      "Validation Loss: 0.021180887685649182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.005927065556752495\n",
      "Training Loss: 0.005807305443449877\n",
      "Training Loss: 0.005992093476234004\n",
      "Validation Loss: 0.02075581242633837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00572119487915188\n",
      "Training Loss: 0.005620627349708229\n",
      "Training Loss: 0.005812477468280122\n",
      "Validation Loss: 0.020356728177350222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.005544349793926813\n",
      "Training Loss: 0.005462486227042973\n",
      "Training Loss: 0.005659847645438277\n",
      "Validation Loss: 0.01998401859649614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.00538999839918688\n",
      "Training Loss: 0.005326497534406371\n",
      "Training Loss: 0.0055284420127281915\n",
      "Validation Loss: 0.019637946714385505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.005254412997164764\n",
      "Training Loss: 0.005208806868758984\n",
      "Training Loss: 0.005414629881852306\n",
      "Validation Loss: 0.019318460732740298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.005135126060340553\n",
      "Training Loss: 0.005106772497529164\n",
      "Training Loss: 0.005315846529556439\n",
      "Validation Loss: 0.019025210631236935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.005030256944592111\n",
      "Training Loss: 0.0050183603394543756\n",
      "Training Loss: 0.0052300963026937096\n",
      "Validation Loss: 0.018757378794985374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.004938223630888388\n",
      "Training Loss: 0.004941869292524643\n",
      "Training Loss: 0.005155717912712135\n",
      "Validation Loss: 0.01851393491437847\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0048576216551009565\n",
      "Training Loss: 0.004875809483928606\n",
      "Training Loss: 0.005091270877164789\n",
      "Validation Loss: 0.018293568744125327\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.004787167514441535\n",
      "Training Loss: 0.004818844099645503\n",
      "Training Loss: 0.005035473639145494\n",
      "Validation Loss: 0.01809488169671026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.004725676372763701\n",
      "Training Loss: 0.004769762897631154\n",
      "Training Loss: 0.004987181153264828\n",
      "Validation Loss: 0.017916331630137363\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.004672056256677024\n",
      "Training Loss: 0.0047274780337465926\n",
      "Training Loss: 0.004945369032211602\n",
      "Validation Loss: 0.017756318267999907\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.004625306818052195\n",
      "Training Loss: 0.004691015974385664\n",
      "Training Loss: 0.004909124441328458\n",
      "Validation Loss: 0.017613280174751462\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.004584519938798621\n",
      "Training Loss: 0.0046595129318302494\n",
      "Training Loss: 0.0048776425776304675\n",
      "Validation Loss: 0.01748560525979219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.0045488804311025885\n",
      "Training Loss: 0.00463221299869474\n",
      "Training Loss: 0.004850217351922766\n",
      "Validation Loss: 0.017371782373762534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.004517663856386207\n",
      "Training Loss: 0.004608460706658661\n",
      "Training Loss: 0.004826238309033215\n",
      "Validation Loss: 0.017270361136100934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00449023672787007\n",
      "Training Loss: 0.0045876949012745175\n",
      "Training Loss: 0.004805180463590659\n",
      "Validation Loss: 0.017179946511921087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.004466045299777761\n",
      "Training Loss: 0.004569437945610844\n",
      "Training Loss: 0.0047865969879785555\n",
      "Validation Loss: 0.01709930549030391\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.004444615393294953\n",
      "Training Loss: 0.004553286263835617\n",
      "Training Loss: 0.004770106987562031\n",
      "Validation Loss: 0.017027289229916052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.004425540117663332\n",
      "Training Loss: 0.004538903069333173\n",
      "Training Loss: 0.004755390869104303\n",
      "Validation Loss: 0.016962863750797644\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.004408473918447271\n",
      "Training Loss: 0.004526006430969573\n",
      "Training Loss: 0.004742180253961123\n",
      "Validation Loss: 0.016905100124082372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.004393125246861018\n",
      "Training Loss: 0.004514361998881214\n",
      "Training Loss: 0.004730250213178806\n",
      "Validation Loss: 0.016853158631665487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.004379247543402016\n",
      "Training Loss: 0.0045037766912719235\n",
      "Training Loss: 0.004719411670812405\n",
      "Validation Loss: 0.016806386487056197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.004366633694735356\n",
      "Training Loss: 0.004494088764186017\n",
      "Training Loss: 0.004709508249070495\n",
      "Validation Loss: 0.01676406990736723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.004355109296739101\n",
      "Training Loss: 0.004485165777732618\n",
      "Training Loss: 0.00470040658430662\n",
      "Validation Loss: 0.01672571373506962\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.004344527932698838\n",
      "Training Loss: 0.004476897676358931\n",
      "Training Loss: 0.00469199700455647\n",
      "Validation Loss: 0.016690792181016354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.0043347675312543285\n",
      "Training Loss: 0.004469192785327323\n",
      "Training Loss: 0.0046841872675577175\n",
      "Validation Loss: 0.016658933699821656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.004325723824440502\n",
      "Training Loss: 0.004461974873556755\n",
      "Training Loss: 0.004676898600882851\n",
      "Validation Loss: 0.016629748577461315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.004317309945472516\n",
      "Training Loss: 0.004455180207150989\n",
      "Training Loss: 0.004670065523241646\n",
      "Validation Loss: 0.016602930479442304\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.004309450828004629\n",
      "Training Loss: 0.004448755367775448\n",
      "Training Loss: 0.004663631436415017\n",
      "Validation Loss: 0.016578230494110103\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.00430208390171174\n",
      "Training Loss: 0.004442655657185241\n",
      "Training Loss: 0.004657548139221035\n",
      "Validation Loss: 0.016555381423448413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.004295154539868236\n",
      "Training Loss: 0.004436842283466831\n",
      "Training Loss: 0.004651776008540764\n",
      "Validation Loss: 0.016534197366576683\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.004288616027333774\n",
      "Training Loss: 0.004431283331359737\n",
      "Training Loss: 0.00464627998881042\n",
      "Validation Loss: 0.016514497775103103\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.004282427792204544\n",
      "Training Loss: 0.004425950424047187\n",
      "Training Loss: 0.0046410283219302075\n",
      "Validation Loss: 0.016496125263360778\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.00427655563573353\n",
      "Training Loss: 0.004420819274382665\n",
      "Training Loss: 0.004635995187563822\n",
      "Validation Loss: 0.01647894955868048\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.004270968696800992\n",
      "Training Loss: 0.004415869017830119\n",
      "Training Loss: 0.004631157599505969\n",
      "Validation Loss: 0.016462872791093555\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.004265638859942555\n",
      "Training Loss: 0.0044110815791646016\n",
      "Training Loss: 0.004626494341064245\n",
      "Validation Loss: 0.016447760313853955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.004260543166892603\n",
      "Training Loss: 0.004406440502498299\n",
      "Training Loss: 0.004621988438884728\n",
      "Validation Loss: 0.01643354508220061\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.004255661020288244\n",
      "Training Loss: 0.004401932175387629\n",
      "Training Loss: 0.00461762489634566\n",
      "Validation Loss: 0.016420141610662253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.004250971733126789\n",
      "Training Loss: 0.004397543833474629\n",
      "Training Loss: 0.004613388183061034\n",
      "Validation Loss: 0.016407465734885315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.004246459865244106\n",
      "Training Loss: 0.004393264153040945\n",
      "Training Loss: 0.004609266933985054\n",
      "Validation Loss: 0.01639547719086489\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.004242109808837995\n",
      "Training Loss: 0.004389083932037466\n",
      "Training Loss: 0.004605249452288263\n",
      "Validation Loss: 0.016384109527688852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0042379079689271746\n",
      "Training Loss: 0.004384993796120398\n",
      "Training Loss: 0.0046013265516376125\n",
      "Validation Loss: 0.01637332188750335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.004233841930981725\n",
      "Training Loss: 0.0043809858511667694\n",
      "Training Loss: 0.0045974896021652965\n",
      "Validation Loss: 0.01636306656880325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.004229900175123476\n",
      "Training Loss: 0.004377053410862573\n",
      "Training Loss: 0.004593729461776093\n",
      "Validation Loss: 0.016353321332337984\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.004226072997553274\n",
      "Training Loss: 0.004373190038604662\n",
      "Training Loss: 0.004590040200273506\n",
      "Validation Loss: 0.016344005341400927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0042223511019255965\n",
      "Training Loss: 0.004369389582425356\n",
      "Training Loss: 0.004586415053345263\n",
      "Validation Loss: 0.016335143061522187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.004218725519021973\n",
      "Training Loss: 0.004365647062077187\n",
      "Training Loss: 0.004582847306155599\n",
      "Validation Loss: 0.016326677938400026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.004215189146343619\n",
      "Training Loss: 0.004361957390210591\n",
      "Training Loss: 0.004579333163565025\n",
      "Validation Loss: 0.016318578453567087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.004211734753334894\n",
      "Training Loss: 0.0043583167454926295\n",
      "Training Loss: 0.004575867266976274\n",
      "Validation Loss: 0.01631083848017655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.004208355991868302\n",
      "Training Loss: 0.0043547210720134896\n",
      "Training Loss: 0.004572445061057806\n",
      "Validation Loss: 0.016303419397118386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.004205046574934385\n",
      "Training Loss: 0.004351166666019708\n",
      "Training Loss: 0.004569062595255673\n",
      "Validation Loss: 0.01629631695065522\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.004201801311573945\n",
      "Training Loss: 0.0043476497806841504\n",
      "Training Loss: 0.004565716336946935\n",
      "Validation Loss: 0.016289501927081455\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.0041986154118785635\n",
      "Training Loss: 0.004344168192474172\n",
      "Training Loss: 0.004562403176096268\n",
      "Validation Loss: 0.01628298615628665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.004195484127267264\n",
      "Training Loss: 0.004340718258172274\n",
      "Training Loss: 0.004559119864716195\n",
      "Validation Loss: 0.01627672311661535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.004192403274355456\n",
      "Training Loss: 0.004337297630845569\n",
      "Training Loss: 0.004555863404530101\n",
      "Validation Loss: 0.01627070496507575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.004189368151710369\n",
      "Training Loss: 0.00433390466903802\n",
      "Training Loss: 0.004552632075501606\n",
      "Validation Loss: 0.016264944290219064\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.0041863763937726615\n",
      "Training Loss: 0.00433053627377376\n",
      "Training Loss: 0.004549422144773416\n",
      "Validation Loss: 0.016259394928792054\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.004183423628564924\n",
      "Training Loss: 0.0043271910352632404\n",
      "Training Loss: 0.004546232447610237\n",
      "Validation Loss: 0.01625408019525198\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.004180506799020805\n",
      "Training Loss: 0.004323866241611541\n",
      "Training Loss: 0.004543060605064966\n",
      "Validation Loss: 0.016248979205474925\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.004177623203140683\n",
      "Training Loss: 0.004320560595951975\n",
      "Training Loss: 0.004539905281853862\n",
      "Validation Loss: 0.016244083203459055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.00417477086710278\n",
      "Training Loss: 0.004317272521439009\n",
      "Training Loss: 0.004536763817886822\n",
      "Validation Loss: 0.01623938490866861\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.004171946223359555\n",
      "Training Loss: 0.004314000197337009\n",
      "Training Loss: 0.004533634326653555\n",
      "Validation Loss: 0.01623490942233985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.004169147404027172\n",
      "Training Loss: 0.004310742726083845\n",
      "Training Loss: 0.004530516321538016\n",
      "Validation Loss: 0.01623058927067545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.004166372024337761\n",
      "Training Loss: 0.004307497889385559\n",
      "Training Loss: 0.004527407737332396\n",
      "Validation Loss: 0.016226460490103685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.004163617846206762\n",
      "Training Loss: 0.0043042653525481\n",
      "Training Loss: 0.004524307528627105\n",
      "Validation Loss: 0.016222494272410536\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.004160883458098397\n",
      "Training Loss: 0.004301043284358457\n",
      "Training Loss: 0.004521214760025032\n",
      "Validation Loss: 0.01621872843295503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.004158166850102134\n",
      "Training Loss: 0.004297830945579335\n",
      "Training Loss: 0.004518127896008081\n",
      "Validation Loss: 0.016215137402223568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.004155466516385787\n",
      "Training Loss: 0.004294627230265178\n",
      "Training Loss: 0.004515046303276904\n",
      "Validation Loss: 0.01621171116326632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.0041527801501797515\n",
      "Training Loss: 0.004291431030142121\n",
      "Training Loss: 0.004511968326405622\n",
      "Validation Loss: 0.016208451908353842\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.004150107327150181\n",
      "Training Loss: 0.004288241689209826\n",
      "Training Loss: 0.004508893876336515\n",
      "Validation Loss: 0.016205375585077186\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.004147446400020271\n",
      "Training Loss: 0.004285058424575255\n",
      "Training Loss: 0.0045058215485187245\n",
      "Validation Loss: 0.016202448859413184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.004144796000327915\n",
      "Training Loss: 0.004281880200142041\n",
      "Training Loss: 0.00450275145645719\n",
      "Validation Loss: 0.016199675090401697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.004142154659493826\n",
      "Training Loss: 0.004278706510667689\n",
      "Training Loss: 0.004499682136229239\n",
      "Validation Loss: 0.016197088959344318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.004139521576580592\n",
      "Training Loss: 0.004275536819477566\n",
      "Training Loss: 0.004496612995862961\n",
      "Validation Loss: 0.016194670829984745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.004136895936098881\n",
      "Training Loss: 0.004272370572434739\n",
      "Training Loss: 0.00449354387645144\n",
      "Validation Loss: 0.016192425814132844\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.004134277427219786\n",
      "Training Loss: 0.004269206557655707\n",
      "Training Loss: 0.004490474564954638\n",
      "Validation Loss: 0.01619036110599389\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.004131663871230557\n",
      "Training Loss: 0.004266045471304096\n",
      "Training Loss: 0.004487403960665688\n",
      "Validation Loss: 0.0161884365331256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0041290550213307145\n",
      "Training Loss: 0.004262886513024569\n",
      "Training Loss: 0.004484332836000249\n",
      "Validation Loss: 0.01618672230573936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.004126450782059692\n",
      "Training Loss: 0.004259729254990816\n",
      "Training Loss: 0.004481259895255789\n",
      "Validation Loss: 0.016185168770738365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.004123849893803708\n",
      "Training Loss: 0.0042565733386436475\n",
      "Training Loss: 0.004478185009793379\n",
      "Validation Loss: 0.016183798551936163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.004121251889155246\n",
      "Training Loss: 0.004253419304732233\n",
      "Training Loss: 0.004475109020713717\n",
      "Validation Loss: 0.016182604410654205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.004118656889768317\n",
      "Training Loss: 0.004250265979790129\n",
      "Training Loss: 0.004472031517652794\n",
      "Validation Loss: 0.016181595021796027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.004116063580731862\n",
      "Training Loss: 0.004247113682795316\n",
      "Training Loss: 0.004468952212482691\n",
      "Validation Loss: 0.016180758848472424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.004113472194294445\n",
      "Training Loss: 0.004243962829350494\n",
      "Training Loss: 0.004465871702996083\n",
      "Validation Loss: 0.016180139675924785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.004110882338718511\n",
      "Training Loss: 0.004240813166252338\n",
      "Training Loss: 0.004462789402459748\n",
      "Validation Loss: 0.016179711895398376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.0041082937293685975\n",
      "Training Loss: 0.004237664545071311\n",
      "Training Loss: 0.004459705901681445\n",
      "Validation Loss: 0.016179486538879993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.004105706411064602\n",
      "Training Loss: 0.004234517348813824\n",
      "Training Loss: 0.0044566224957816305\n",
      "Validation Loss: 0.016179444438390686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.004103120163199492\n",
      "Training Loss: 0.004231372401700355\n",
      "Training Loss: 0.004453538283705712\n",
      "Validation Loss: 0.016179619417159577\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 104\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.004100534782628529\n",
      "Training Loss: 0.004228229274158366\n",
      "Training Loss: 0.004450454184552655\n",
      "Validation Loss: 0.01618001001803309\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 105\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.004097950982977636\n",
      "Training Loss: 0.004225088891107589\n",
      "Training Loss: 0.004447370573179796\n",
      "Validation Loss: 0.01618062613500554\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 106\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.004095368481939659\n",
      "Training Loss: 0.004221951452782377\n",
      "Training Loss: 0.004444288773229345\n",
      "Validation Loss: 0.016181438303228175\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 107\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.0040927872154861685\n",
      "Training Loss: 0.004218817410874181\n",
      "Training Loss: 0.004441208506468683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [14:47<00:00, 88.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016182475312602487\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 108\n",
      "Early stopping after 108 epochs\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2841, 12, 5)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 5)\n",
      "Shape of the data after splitting into sequences: (22797, 12, 5)\n",
      "Shape of the data after splitting into sequences: (5692, 12, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.17935671865940095\n",
      "Training Loss: 0.13317626100033522\n",
      "Training Loss: 0.10044941803440452\n",
      "Training Loss: 0.08228253401815891\n",
      "Training Loss: 0.07422187721356749\n",
      "Training Loss: 0.0698017199896276\n",
      "Training Loss: 0.06755188563838602\n",
      "Validation Loss: 0.06926205491975006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06736459022387863\n",
      "Training Loss: 0.06330747328698635\n",
      "Training Loss: 0.05973321262747049\n",
      "Training Loss: 0.05470339383929968\n",
      "Training Loss: 0.047803448736667635\n",
      "Training Loss: 0.043779861638322475\n",
      "Training Loss: 0.04115770881064236\n",
      "Validation Loss: 0.05324687618301826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04420494575053453\n",
      "Training Loss: 0.040766728864982726\n",
      "Training Loss: 0.03760402005165815\n",
      "Training Loss: 0.032950702467933295\n",
      "Training Loss: 0.027007215148769317\n",
      "Training Loss: 0.024673544438555836\n",
      "Training Loss: 0.023011613241396844\n",
      "Validation Loss: 0.03628621782326185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.027099174377508462\n",
      "Training Loss: 0.024874775907956063\n",
      "Training Loss: 0.023446636055596173\n",
      "Training Loss: 0.020040420861914755\n",
      "Training Loss: 0.015828037122264504\n",
      "Training Loss: 0.014951466820202769\n",
      "Training Loss: 0.014056854243390262\n",
      "Validation Loss: 0.026467520769769222\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.01859505381435156\n",
      "Training Loss: 0.01721270248061046\n",
      "Training Loss: 0.016974685988388957\n",
      "Training Loss: 0.014241220022086054\n",
      "Training Loss: 0.010954169554170222\n",
      "Training Loss: 0.010675336343701929\n",
      "Training Loss: 0.010095095471478998\n",
      "Validation Loss: 0.021648603742628284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.014606713138055056\n",
      "Training Loss: 0.013531504010315984\n",
      "Training Loss: 0.013699324592016638\n",
      "Training Loss: 0.011226179838413373\n",
      "Training Loss: 0.008428998914314433\n",
      "Training Loss: 0.008302860774565489\n",
      "Training Loss: 0.00787751432042569\n",
      "Validation Loss: 0.018651979501020818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.012156229312531651\n",
      "Training Loss: 0.011245783832855523\n",
      "Training Loss: 0.01152053956524469\n",
      "Training Loss: 0.009293493216391653\n",
      "Training Loss: 0.006938778187613934\n",
      "Training Loss: 0.0068599602265749125\n",
      "Training Loss: 0.0065961790166329595\n",
      "Validation Loss: 0.016974929782949136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.010767115268390626\n",
      "Training Loss: 0.010018204222433269\n",
      "Training Loss: 0.01035039909183979\n",
      "Training Loss: 0.008268381119705737\n",
      "Training Loss: 0.006150485946564004\n",
      "Training Loss: 0.006071386201656423\n",
      "Training Loss: 0.005888135862769559\n",
      "Validation Loss: 0.015991727860770032\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.010002373554743826\n",
      "Training Loss: 0.00931688685901463\n",
      "Training Loss: 0.009671075806254521\n",
      "Training Loss: 0.007629626586567611\n",
      "Training Loss: 0.0056446901097660885\n",
      "Training Loss: 0.005560753793688491\n",
      "Training Loss: 0.005428157740971074\n",
      "Validation Loss: 0.015255900852431016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.009500590889947489\n",
      "Training Loss: 0.00885168484179303\n",
      "Training Loss: 0.009219622956588864\n",
      "Training Loss: 0.007190772218746133\n",
      "Training Loss: 0.005298760372097604\n",
      "Training Loss: 0.005208749147714116\n",
      "Training Loss: 0.005112936935038306\n",
      "Validation Loss: 0.01471633080319826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.009148653455777095\n",
      "Training Loss: 0.008523140362231061\n",
      "Training Loss: 0.008899352248990909\n",
      "Training Loss: 0.006874361463706009\n",
      "Training Loss: 0.005054516723612323\n",
      "Training Loss: 0.004960747763398103\n",
      "Training Loss: 0.004891982790431939\n",
      "Validation Loss: 0.014335156931133752\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008883406256791205\n",
      "Training Loss: 0.008274750263663009\n",
      "Training Loss: 0.008654821355594321\n",
      "Training Loss: 0.006635051672928966\n",
      "Training Loss: 0.00487778696930036\n",
      "Training Loss: 0.004783744876040146\n",
      "Training Loss: 0.004734469476970844\n",
      "Validation Loss: 0.014077478222730342\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00866640980471857\n",
      "Training Loss: 0.008072248295648024\n",
      "Training Loss: 0.008453486829530447\n",
      "Training Loss: 0.006445307905087247\n",
      "Training Loss: 0.004747124697896652\n",
      "Training Loss: 0.004656227739178576\n",
      "Training Loss: 0.004620626696269028\n",
      "Validation Loss: 0.013913573809700567\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008477887591579929\n",
      "Training Loss: 0.007897909047314897\n",
      "Training Loss: 0.00827955137589015\n",
      "Training Loss: 0.006290277228690684\n",
      "Training Loss: 0.004649593338835984\n",
      "Training Loss: 0.0045643831556662915\n",
      "Training Loss: 0.004538004724890925\n",
      "Validation Loss: 0.013818753155973855\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008311036919476465\n",
      "Training Loss: 0.007745199364144355\n",
      "Training Loss: 0.008127728025428951\n",
      "Training Loss: 0.006162888998514973\n",
      "Training Loss: 0.004577087072539144\n",
      "Training Loss: 0.004498657128424384\n",
      "Training Loss: 0.0044780636561336\n",
      "Validation Loss: 0.013770644369008446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008165363596053793\n",
      "Training Loss: 0.007612993610091507\n",
      "Training Loss: 0.007997287522302941\n",
      "Training Loss: 0.006059256307198666\n",
      "Training Loss: 0.004523299317224882\n",
      "Training Loss: 0.004451350560993887\n",
      "Training Loss: 0.0044340167217887935\n",
      "Validation Loss: 0.013749899496132515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008041641346644611\n",
      "Training Loss: 0.0075013110158033665\n",
      "Training Loss: 0.007888026318978518\n",
      "Training Loss: 0.005976005507400259\n",
      "Training Loss: 0.004482609392143786\n",
      "Training Loss: 0.004415900349849835\n",
      "Training Loss: 0.0044000568456249315\n",
      "Validation Loss: 0.013741318335275301\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.007939548910362646\n",
      "Training Loss: 0.007409310025395826\n",
      "Training Loss: 0.0077986400935333225\n",
      "Training Loss: 0.005909430688479916\n",
      "Training Loss: 0.0044499178894329815\n",
      "Training Loss: 0.004386688093072735\n",
      "Training Loss: 0.004371164330514148\n",
      "Validation Loss: 0.013735090648800777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007857323726639151\n",
      "Training Loss: 0.007334900404093787\n",
      "Training Loss: 0.0077265421289484945\n",
      "Training Loss: 0.005855556285823695\n",
      "Training Loss: 0.004421183223603293\n",
      "Training Loss: 0.004359949306817725\n",
      "Training Loss: 0.00434502825315576\n",
      "Validation Loss: 0.013731715362693431\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007791976040462032\n",
      "Training Loss: 0.007274873952846974\n",
      "Training Loss: 0.007668332848697901\n",
      "Training Loss: 0.005811271735583432\n",
      "Training Loss: 0.00439533733704593\n",
      "Training Loss: 0.004335568840615451\n",
      "Training Loss: 0.004322130156797357\n",
      "Validation Loss: 0.013731476496329552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007739388631889597\n",
      "Training Loss: 0.007225848168600351\n",
      "Training Loss: 0.00762080964166671\n",
      "Training Loss: 0.005774731074343436\n",
      "Training Loss: 0.004372449700022116\n",
      "Training Loss: 0.004312885538092814\n",
      "Training Loss: 0.004300031953607686\n",
      "Validation Loss: 0.013717535904552857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007697853923309595\n",
      "Training Loss: 0.00718624543165788\n",
      "Training Loss: 0.0075821730401366945\n",
      "Training Loss: 0.005743917834479362\n",
      "Training Loss: 0.004350365343270823\n",
      "Training Loss: 0.004287934155436233\n",
      "Training Loss: 0.0042712655192008245\n",
      "Validation Loss: 0.013621283005766068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007671181024052203\n",
      "Training Loss: 0.0071574983699247245\n",
      "Training Loss: 0.007552314961794764\n",
      "Training Loss: 0.005715407924726606\n",
      "Training Loss: 0.004322720232303254\n",
      "Training Loss: 0.004246770427562297\n",
      "Training Loss: 0.004210618230863474\n",
      "Validation Loss: 0.013402179564167973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007671720280777663\n",
      "Training Loss: 0.0071436080010607835\n",
      "Training Loss: 0.007525694859214127\n",
      "Training Loss: 0.005685936791123823\n",
      "Training Loss: 0.004290664862492122\n",
      "Training Loss: 0.004200722515233793\n",
      "Training Loss: 0.004180803466588259\n",
      "Validation Loss: 0.013507120665302326\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 24\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007634418294765055\n",
      "Training Loss: 0.00712784877512604\n",
      "Training Loss: 0.007500126908998936\n",
      "Training Loss: 0.005660510379821062\n",
      "Training Loss: 0.0042667509609600526\n",
      "Training Loss: 0.004175511346547864\n",
      "Training Loss: 0.0041689007199602205\n",
      "Validation Loss: 0.013545315906279878\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 25\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007596094518667087\n",
      "Training Loss: 0.007108108008978888\n",
      "Training Loss: 0.007478795814095065\n",
      "Training Loss: 0.00563878292508889\n",
      "Training Loss: 0.004244697900721803\n",
      "Training Loss: 0.004160017893300391\n",
      "Training Loss: 0.0041591156955109905\n",
      "Validation Loss: 0.01357256684300563\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 26\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007560653788968921\n",
      "Training Loss: 0.0070842277782503515\n",
      "Training Loss: 0.007457076306454837\n",
      "Training Loss: 0.0056198238109936936\n",
      "Training Loss: 0.004228545730002225\n",
      "Training Loss: 0.004147110209451057\n",
      "Training Loss: 0.0041500435426132755\n",
      "Validation Loss: 0.013594481196299838\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 27\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007527385648572817\n",
      "Training Loss: 0.007056364357704297\n",
      "Training Loss: 0.00742953086970374\n",
      "Training Loss: 0.005604523181100376\n",
      "Training Loss: 0.0042185680876718834\n",
      "Training Loss: 0.004134192449855618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:56<08:32, 56.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.004141278716851957\n",
      "Validation Loss: 0.01361266833342863\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 28\n",
      "Early stopping after 28 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.13574638733640312\n",
      "Training Loss: 0.0974667072482407\n",
      "Training Loss: 0.0740848089568317\n",
      "Training Loss: 0.06327890345826745\n",
      "Training Loss: 0.05643174396827817\n",
      "Training Loss: 0.05160518417134881\n",
      "Training Loss: 0.04815253777429462\n",
      "Validation Loss: 0.05412312269852626\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.04896372319199145\n",
      "Training Loss: 0.04402456530369818\n",
      "Training Loss: 0.04063030371442437\n",
      "Training Loss: 0.035613184617832305\n",
      "Training Loss: 0.02972206856124103\n",
      "Training Loss: 0.027019104016944767\n",
      "Training Loss: 0.025198678360320626\n",
      "Validation Loss: 0.03809732075236487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.02876919728703797\n",
      "Training Loss: 0.026064749360084533\n",
      "Training Loss: 0.024323504827916623\n",
      "Training Loss: 0.021144634406082333\n",
      "Training Loss: 0.016954204104840755\n",
      "Training Loss: 0.01606465089134872\n",
      "Training Loss: 0.015107644989620894\n",
      "Validation Loss: 0.028070239986777865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.01942904866300523\n",
      "Training Loss: 0.017979806470684707\n",
      "Training Loss: 0.017411045229528098\n",
      "Training Loss: 0.014957009898498654\n",
      "Training Loss: 0.011669531639199704\n",
      "Training Loss: 0.011426665103062988\n",
      "Training Loss: 0.010768550776410847\n",
      "Validation Loss: 0.023007992848628357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.0151449328311719\n",
      "Training Loss: 0.014066100798081606\n",
      "Training Loss: 0.013981766286306083\n",
      "Training Loss: 0.011720515753841027\n",
      "Training Loss: 0.008966159522533417\n",
      "Training Loss: 0.008901000707410275\n",
      "Training Loss: 0.008434761330718174\n",
      "Validation Loss: 0.020108013549882373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.012671532626263797\n",
      "Training Loss: 0.011774936246220023\n",
      "Training Loss: 0.01188115440425463\n",
      "Training Loss: 0.009762916752370074\n",
      "Training Loss: 0.007375835723942146\n",
      "Training Loss: 0.007362282803514972\n",
      "Training Loss: 0.007031280314549804\n",
      "Validation Loss: 0.0182203281468499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.011137009277008473\n",
      "Training Loss: 0.010355466960463673\n",
      "Training Loss: 0.010556522622937336\n",
      "Training Loss: 0.00854481938178651\n",
      "Training Loss: 0.006393837870564312\n",
      "Training Loss: 0.006402230411185883\n",
      "Training Loss: 0.006149251104216091\n",
      "Validation Loss: 0.016890266243096315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.010166840667370707\n",
      "Training Loss: 0.009462455292232335\n",
      "Training Loss: 0.009718606253154577\n",
      "Training Loss: 0.0077686253818683325\n",
      "Training Loss: 0.005775932963006198\n",
      "Training Loss: 0.005796244394150563\n",
      "Training Loss: 0.005584662694018334\n",
      "Validation Loss: 0.015916492421117225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.009534243965754285\n",
      "Training Loss: 0.008887803860707208\n",
      "Training Loss: 0.009175718354526907\n",
      "Training Loss: 0.007260354302125052\n",
      "Training Loss: 0.005382586056366562\n",
      "Training Loss: 0.005408627604483626\n",
      "Training Loss: 0.00521983657439705\n",
      "Validation Loss: 0.015201036061407922\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.00910979655222036\n",
      "Training Loss: 0.008509651130298152\n",
      "Training Loss: 0.008815285838209093\n",
      "Training Loss: 0.006921323224669322\n",
      "Training Loss: 0.005129626066773199\n",
      "Training Loss: 0.005156915450352244\n",
      "Training Loss: 0.00498275090707466\n",
      "Validation Loss: 0.014676969756515284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.008821195799391716\n",
      "Training Loss: 0.008257321096025408\n",
      "Training Loss: 0.008572808293392882\n",
      "Training Loss: 0.006692016712622717\n",
      "Training Loss: 0.0049642076285090295\n",
      "Training Loss: 0.004989712372771464\n",
      "Training Loss: 0.004827016239869408\n",
      "Validation Loss: 0.014293278092239401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008623375326860696\n",
      "Training Loss: 0.008086465318920091\n",
      "Training Loss: 0.008407621053047478\n",
      "Training Loss: 0.006533728404901922\n",
      "Training Loss: 0.004852798100328073\n",
      "Training Loss: 0.004874818066018634\n",
      "Training Loss: 0.004722315255203284\n",
      "Validation Loss: 0.014012108590935221\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008485391160938889\n",
      "Training Loss: 0.007967643627198413\n",
      "Training Loss: 0.008292409173445776\n",
      "Training Loss: 0.006420965346624143\n",
      "Training Loss: 0.004774642332340591\n",
      "Training Loss: 0.0047924802487250414\n",
      "Training Loss: 0.004649370092665777\n",
      "Validation Loss: 0.013805519643393153\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008386038086609916\n",
      "Training Loss: 0.00788160938420333\n",
      "Training Loss: 0.008209110024617985\n",
      "Training Loss: 0.00633740775869228\n",
      "Training Loss: 0.004717263200436719\n",
      "Training Loss: 0.004730838332907297\n",
      "Training Loss: 0.004596337113180198\n",
      "Validation Loss: 0.013652779301454065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008311420399695634\n",
      "Training Loss: 0.007816258117090911\n",
      "Training Loss: 0.008146218656329439\n",
      "Training Loss: 0.006272880886099301\n",
      "Training Loss: 0.0046732293110108005\n",
      "Training Loss: 0.004682783787720837\n",
      "Training Loss: 0.0045560635183937844\n",
      "Validation Loss: 0.013538683156835173\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008252781549235805\n",
      "Training Loss: 0.007764196775387973\n",
      "Training Loss: 0.008096593304071576\n",
      "Training Loss: 0.0062210976390633735\n",
      "Training Loss: 0.004638076402479783\n",
      "Training Loss: 0.004643990297336131\n",
      "Training Loss: 0.004524218593141996\n",
      "Validation Loss: 0.01345235421208923\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008204700829228386\n",
      "Training Loss: 0.007720943952444941\n",
      "Training Loss: 0.008055818867869675\n",
      "Training Loss: 0.006178134852088988\n",
      "Training Loss: 0.004609062117524445\n",
      "Training Loss: 0.0046117435867199675\n",
      "Training Loss: 0.00449813422630541\n",
      "Validation Loss: 0.013386146113109053\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008163823874201625\n",
      "Training Loss: 0.007683747885748744\n",
      "Training Loss: 0.008021136011229828\n",
      "Training Loss: 0.006141483308747411\n",
      "Training Loss: 0.004584452123381198\n",
      "Training Loss: 0.004584286233293824\n",
      "Training Loss: 0.004476128338137641\n",
      "Validation Loss: 0.013334766565734863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008128033494576812\n",
      "Training Loss: 0.007650875538820401\n",
      "Training Loss: 0.007990780991967768\n",
      "Training Loss: 0.006109491211827844\n",
      "Training Loss: 0.004563109493465163\n",
      "Training Loss: 0.004560433382866904\n",
      "Training Loss: 0.004457107101334259\n",
      "Validation Loss: 0.013294415568500367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.008095963530940935\n",
      "Training Loss: 0.007621198809938505\n",
      "Training Loss: 0.007963596109766513\n",
      "Training Loss: 0.00608103723207023\n",
      "Training Loss: 0.00454426490527112\n",
      "Training Loss: 0.004539364648517221\n",
      "Training Loss: 0.004440338095300831\n",
      "Validation Loss: 0.013262473128749971\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008066710345447063\n",
      "Training Loss: 0.007593963328981772\n",
      "Training Loss: 0.007938801504205912\n",
      "Training Loss: 0.006055336779681965\n",
      "Training Loss: 0.00452738054911606\n",
      "Training Loss: 0.004520487257977947\n",
      "Training Loss: 0.004425314119434916\n",
      "Validation Loss: 0.013237027460988262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.008039653605083004\n",
      "Training Loss: 0.007568638861412183\n",
      "Training Loss: 0.007915853433078155\n",
      "Training Loss: 0.006031817722250707\n",
      "Training Loss: 0.004512060814886354\n",
      "Training Loss: 0.00450336433481425\n",
      "Training Loss: 0.004411670532426797\n",
      "Validation Loss: 0.013216710810319342\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008014355036430061\n",
      "Training Loss: 0.007544842384522781\n",
      "Training Loss: 0.007894357632612809\n",
      "Training Loss: 0.006010053742793389\n",
      "Training Loss: 0.004498007163638249\n",
      "Training Loss: 0.004487659531296231\n",
      "Training Loss: 0.004399138077860698\n",
      "Validation Loss: 0.013200462282171354\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0079904863727279\n",
      "Training Loss: 0.007522284714505076\n",
      "Training Loss: 0.007874016946880147\n",
      "Training Loss: 0.005989715854520909\n",
      "Training Loss: 0.004484988282783888\n",
      "Training Loss: 0.00447311150317546\n",
      "Training Loss: 0.004387512083631009\n",
      "Validation Loss: 0.013187511948770965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007967793630668893\n",
      "Training Loss: 0.007500734676141292\n",
      "Training Loss: 0.00785459959297441\n",
      "Training Loss: 0.005970540482085198\n",
      "Training Loss: 0.0044728185207350175\n",
      "Training Loss: 0.004459509843145497\n",
      "Training Loss: 0.0043766283645527435\n",
      "Validation Loss: 0.013177264470010577\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007946071800542995\n",
      "Training Loss: 0.007480002591619268\n",
      "Training Loss: 0.00783591749612242\n",
      "Training Loss: 0.005952314782771282\n",
      "Training Loss: 0.0044613435759674755\n",
      "Training Loss: 0.004446684987633489\n",
      "Training Loss: 0.004366359754349105\n",
      "Validation Loss: 0.013169237082014873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007925146638881416\n",
      "Training Loss: 0.00745992936193943\n",
      "Training Loss: 0.007817809503758327\n",
      "Training Loss: 0.005934855936793611\n",
      "Training Loss: 0.004450435860780999\n",
      "Training Loss: 0.004434492660802789\n",
      "Training Loss: 0.004356595113058574\n",
      "Validation Loss: 0.013163107780003677\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0079048699431587\n",
      "Training Loss: 0.007440369706600904\n",
      "Training Loss: 0.00780013365438208\n",
      "Training Loss: 0.00591800676251296\n",
      "Training Loss: 0.004439982868498191\n",
      "Training Loss: 0.004422811117838137\n",
      "Training Loss: 0.004347242219955661\n",
      "Validation Loss: 0.01315853921286692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007885100281564519\n",
      "Training Loss: 0.007421193161280826\n",
      "Training Loss: 0.0077827619889285415\n",
      "Training Loss: 0.005901629391009919\n",
      "Training Loss: 0.004429889305029065\n",
      "Training Loss: 0.004411536785191857\n",
      "Training Loss: 0.004338220929494128\n",
      "Validation Loss: 0.013155358987825501\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007865715441294014\n",
      "Training Loss: 0.007402277708752081\n",
      "Training Loss: 0.007765573769574985\n",
      "Training Loss: 0.005885596366133541\n",
      "Training Loss: 0.004420068418257869\n",
      "Training Loss: 0.004400577148189768\n",
      "Training Loss: 0.004329461727757007\n",
      "Validation Loss: 0.01315334918106512\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007846589254913851\n",
      "Training Loss: 0.007383502674056217\n",
      "Training Loss: 0.007748452621744946\n",
      "Training Loss: 0.005869790639844723\n",
      "Training Loss: 0.00441044557839632\n",
      "Training Loss: 0.004389851928572171\n",
      "Training Loss: 0.004320899018784985\n",
      "Validation Loss: 0.013152387550829698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00782760530244559\n",
      "Training Loss: 0.007364753367146477\n",
      "Training Loss: 0.007731286690104752\n",
      "Training Loss: 0.005854099972639233\n",
      "Training Loss: 0.004400945476954803\n",
      "Training Loss: 0.004379284831811674\n",
      "Training Loss: 0.00431247366417665\n",
      "Validation Loss: 0.01315236257952516\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007808646326884628\n",
      "Training Loss: 0.007345910804579034\n",
      "Training Loss: 0.007713960114633664\n",
      "Training Loss: 0.005838418223429471\n",
      "Training Loss: 0.004391503215301782\n",
      "Training Loss: 0.004368807037244551\n",
      "Training Loss: 0.0043041302188066765\n",
      "Validation Loss: 0.013153189684662005\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 33\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007789592121262103\n",
      "Training Loss: 0.007326856082072481\n",
      "Training Loss: 0.007696356392698362\n",
      "Training Loss: 0.005822638651006855\n",
      "Training Loss: 0.004382054748130031\n",
      "Training Loss: 0.004358351893606596\n",
      "Training Loss: 0.004295811110641807\n",
      "Validation Loss: 0.013154835941632756\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 34\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007770326395984739\n",
      "Training Loss: 0.007307466176571325\n",
      "Training Loss: 0.007678354966919869\n",
      "Training Loss: 0.005806654031039216\n",
      "Training Loss: 0.004372535673319362\n",
      "Training Loss: 0.004347854627412744\n",
      "Training Loss: 0.004287464087828994\n",
      "Validation Loss: 0.013157260073139594\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 35\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007750724472571164\n",
      "Training Loss: 0.007287614054512233\n",
      "Training Loss: 0.0076598325371742245\n",
      "Training Loss: 0.005790358375525102\n",
      "Training Loss: 0.004362884464208037\n",
      "Training Loss: 0.004337250498356298\n",
      "Training Loss: 0.004279032188933342\n",
      "Validation Loss: 0.013160482045936256\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 36\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.00773065669927746\n",
      "Training Loss: 0.007267161722993478\n",
      "Training Loss: 0.007640651683323086\n",
      "Training Loss: 0.005773643946740776\n",
      "Training Loss: 0.004353043475421145\n",
      "Training Loss: 0.004326479641022161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:12<09:02, 67.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00427046212775167\n",
      "Validation Loss: 0.013164504415491659\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 37\n",
      "Early stopping after 37 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.17041425716131925\n",
      "Training Loss: 0.12763388130813838\n",
      "Training Loss: 0.09442181764170528\n",
      "Training Loss: 0.0752409490197897\n",
      "Training Loss: 0.06594655361026526\n",
      "Training Loss: 0.061889548879116775\n",
      "Training Loss: 0.0603041017614305\n",
      "Validation Loss: 0.06199948069698802\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06086425054818392\n",
      "Training Loss: 0.05635611053556204\n",
      "Training Loss: 0.05284425033256412\n",
      "Training Loss: 0.047688668817281725\n",
      "Training Loss: 0.04151459762826562\n",
      "Training Loss: 0.03708182535134256\n",
      "Training Loss: 0.033509236807003615\n",
      "Validation Loss: 0.04037513440886464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.033810524409636854\n",
      "Training Loss: 0.02956656221766025\n",
      "Training Loss: 0.026677616331726314\n",
      "Training Loss: 0.02238522850908339\n",
      "Training Loss: 0.01750136417336762\n",
      "Training Loss: 0.015992978578433393\n",
      "Training Loss: 0.014734971325378866\n",
      "Validation Loss: 0.027805058880314957\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.018862427657004445\n",
      "Training Loss: 0.0172444700775668\n",
      "Training Loss: 0.016769848698750138\n",
      "Training Loss: 0.014078126084059476\n",
      "Training Loss: 0.010705317216925324\n",
      "Training Loss: 0.010580105261178687\n",
      "Training Loss: 0.009880531011149288\n",
      "Validation Loss: 0.02230433425220769\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.014380392716266215\n",
      "Training Loss: 0.013313841698691249\n",
      "Training Loss: 0.013354741449002177\n",
      "Training Loss: 0.01098648581886664\n",
      "Training Loss: 0.008205104059306904\n",
      "Training Loss: 0.008253273128066212\n",
      "Training Loss: 0.0077292676852084696\n",
      "Validation Loss: 0.019678650007056497\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.01188119149301201\n",
      "Training Loss: 0.01098594669252634\n",
      "Training Loss: 0.011126589716877789\n",
      "Training Loss: 0.009003303812351078\n",
      "Training Loss: 0.0068264749483205375\n",
      "Training Loss: 0.006862672903225757\n",
      "Training Loss: 0.006525780604570173\n",
      "Validation Loss: 0.018589949074867513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.010237039512721821\n",
      "Training Loss: 0.009530747898388654\n",
      "Training Loss: 0.009765572826145217\n",
      "Training Loss: 0.007839439193485304\n",
      "Training Loss: 0.006086438269121573\n",
      "Training Loss: 0.006100229340372607\n",
      "Training Loss: 0.005886965836398303\n",
      "Validation Loss: 0.017864777635057432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.009333163003902882\n",
      "Training Loss: 0.008750799432164058\n",
      "Training Loss: 0.009048774213297292\n",
      "Training Loss: 0.007207433966686949\n",
      "Training Loss: 0.005647662577684969\n",
      "Training Loss: 0.0056487990979803724\n",
      "Training Loss: 0.005502604248467833\n",
      "Validation Loss: 0.01717843440507821\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.008838550234213472\n",
      "Training Loss: 0.008311173382680863\n",
      "Training Loss: 0.00864834308042191\n",
      "Training Loss: 0.006831044806167483\n",
      "Training Loss: 0.0053518440760672095\n",
      "Training Loss: 0.005342914405628107\n",
      "Training Loss: 0.005237036502803676\n",
      "Validation Loss: 0.01655173352535828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.008537573504727334\n",
      "Training Loss: 0.008030921483878047\n",
      "Training Loss: 0.008393814354203642\n",
      "Training Loss: 0.006578690915484913\n",
      "Training Loss: 0.005136949667939916\n",
      "Training Loss: 0.005116626876988448\n",
      "Training Loss: 0.005038106706924736\n",
      "Validation Loss: 0.016006242836152346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.008333610187983141\n",
      "Training Loss: 0.007833211235702037\n",
      "Training Loss: 0.008214227593271062\n",
      "Training Loss: 0.006394982338533737\n",
      "Training Loss: 0.004974444936960936\n",
      "Training Loss: 0.0049410588009050115\n",
      "Training Loss: 0.0048827941430499774\n",
      "Validation Loss: 0.01553915103606196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008186038045678287\n",
      "Training Loss: 0.007686044652946294\n",
      "Training Loss: 0.00808053917135112\n",
      "Training Loss: 0.006255519239930436\n",
      "Training Loss: 0.004848849757690914\n",
      "Training Loss: 0.004801545800291933\n",
      "Training Loss: 0.004759227278409526\n",
      "Validation Loss: 0.015140540349778584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008076308115851133\n",
      "Training Loss: 0.007574438978917897\n",
      "Training Loss: 0.007979217759566382\n",
      "Training Loss: 0.006147876258473843\n",
      "Training Loss: 0.004750571848126129\n",
      "Training Loss: 0.004689473644830287\n",
      "Training Loss: 0.00466021933068987\n",
      "Validation Loss: 0.014800941964004482\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.007994096974143758\n",
      "Training Loss: 0.00748956615338102\n",
      "Training Loss: 0.007902160938829183\n",
      "Training Loss: 0.00606431920779869\n",
      "Training Loss: 0.00467304780613631\n",
      "Training Loss: 0.00459906283474993\n",
      "Training Loss: 0.00458073484885972\n",
      "Validation Loss: 0.014512614360121027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007932243717368693\n",
      "Training Loss: 0.007424943969817832\n",
      "Training Loss: 0.007843303908593953\n",
      "Training Loss: 0.00599917548825033\n",
      "Training Loss: 0.00461147797643207\n",
      "Training Loss: 0.004525999986217357\n",
      "Training Loss: 0.004516857140697539\n",
      "Validation Loss: 0.014269071925005941\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007885164745384827\n",
      "Training Loss: 0.007375326949404553\n",
      "Training Loss: 0.007797727049328387\n",
      "Training Loss: 0.005947978643816896\n",
      "Training Loss: 0.004562219751533121\n",
      "Training Loss: 0.004466857964871451\n",
      "Training Loss: 0.004465394887956791\n",
      "Validation Loss: 0.014064280824624142\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.0078484291350469\n",
      "Training Loss: 0.007336482268292457\n",
      "Training Loss: 0.007761499648913741\n",
      "Training Loss: 0.005907193922321312\n",
      "Training Loss: 0.004522467041970231\n",
      "Training Loss: 0.004418845710461028\n",
      "Training Loss: 0.004423730014823377\n",
      "Validation Loss: 0.013892494094966169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00781865203520283\n",
      "Training Loss: 0.0073051318526268\n",
      "Training Loss: 0.007731635370291769\n",
      "Training Loss: 0.005874082347727381\n",
      "Training Loss: 0.004490039627416991\n",
      "Training Loss: 0.004379673585062847\n",
      "Training Loss: 0.0043897287879372015\n",
      "Validation Loss: 0.013748333922828013\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007793394865002483\n",
      "Training Loss: 0.007278873610775918\n",
      "Training Loss: 0.007705989785026759\n",
      "Training Loss: 0.005846583069651388\n",
      "Training Loss: 0.004463257134775631\n",
      "Training Loss: 0.004347491558874026\n",
      "Training Loss: 0.004361689012730494\n",
      "Validation Loss: 0.013626956032965792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007770987469702959\n",
      "Training Loss: 0.0072560185834299774\n",
      "Training Loss: 0.00768309707636945\n",
      "Training Loss: 0.005823184461914935\n",
      "Training Loss: 0.004440828203223645\n",
      "Training Loss: 0.004320814881939441\n",
      "Training Loss: 0.004338272621971555\n",
      "Validation Loss: 0.013524047692030779\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0077503497269935905\n",
      "Training Loss: 0.007235447341809049\n",
      "Training Loss: 0.007662016142858192\n",
      "Training Loss: 0.0058028037595795464\n",
      "Training Loss: 0.004421766471350566\n",
      "Training Loss: 0.004298468743218109\n",
      "Training Loss: 0.004318445029202849\n",
      "Validation Loss: 0.013436049683811317\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007730825381586328\n",
      "Training Loss: 0.007216433164430782\n",
      "Training Loss: 0.007642160444520414\n",
      "Training Loss: 0.005784673838643357\n",
      "Training Loss: 0.00440532457025256\n",
      "Training Loss: 0.004279536556568928\n",
      "Training Loss: 0.004301410767948255\n",
      "Validation Loss: 0.013360066681207343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007712042882340029\n",
      "Training Loss: 0.0071985326881986115\n",
      "Training Loss: 0.007623191304737702\n",
      "Training Loss: 0.005768252286943607\n",
      "Training Loss: 0.004390927085769363\n",
      "Training Loss: 0.004263299069134518\n",
      "Training Loss: 0.004286558484309353\n",
      "Validation Loss: 0.01329371536827266\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0076938036503270265\n",
      "Training Loss: 0.007181476871483028\n",
      "Training Loss: 0.007604919429868459\n",
      "Training Loss: 0.005753155243000947\n",
      "Training Loss: 0.004378137547173537\n",
      "Training Loss: 0.004249194184667431\n",
      "Training Loss: 0.004273420687532052\n",
      "Validation Loss: 0.013235127092478623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007676020535873249\n",
      "Training Loss: 0.0071651130693499\n",
      "Training Loss: 0.007587246912298724\n",
      "Training Loss: 0.005739110129652545\n",
      "Training Loss: 0.0043666173925157635\n",
      "Training Loss: 0.004236782828811556\n",
      "Training Loss: 0.004261635807924904\n",
      "Validation Loss: 0.013182817818335352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.0076586578343994915\n",
      "Training Loss: 0.007149348655948415\n",
      "Training Loss: 0.0075701247749384495\n",
      "Training Loss: 0.005725913319620304\n",
      "Training Loss: 0.004356102924793959\n",
      "Training Loss: 0.004225720023969188\n",
      "Training Loss: 0.004250924333464354\n",
      "Validation Loss: 0.013135604566043376\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007641706119757146\n",
      "Training Loss: 0.007134128588950262\n",
      "Training Loss: 0.0075535283645149325\n",
      "Training Loss: 0.005713412395562045\n",
      "Training Loss: 0.004346383765805512\n",
      "Training Loss: 0.004215731236035936\n",
      "Training Loss: 0.004241064953384921\n",
      "Validation Loss: 0.013092561161898997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007625167208025232\n",
      "Training Loss: 0.0071194177807774395\n",
      "Training Loss: 0.007537441845051944\n",
      "Training Loss: 0.005701489802449941\n",
      "Training Loss: 0.004337295953300782\n",
      "Training Loss: 0.004206601548939943\n",
      "Training Loss: 0.004231883546453901\n",
      "Validation Loss: 0.013052948011078414\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007609039635863155\n",
      "Training Loss: 0.007105185493128374\n",
      "Training Loss: 0.00752184942830354\n",
      "Training Loss: 0.005690050530247391\n",
      "Training Loss: 0.004328707203967497\n",
      "Training Loss: 0.004198156760539859\n",
      "Training Loss: 0.004223242008010857\n",
      "Validation Loss: 0.013016199844816093\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007593315863050521\n",
      "Training Loss: 0.007091406005201861\n",
      "Training Loss: 0.007506733207264915\n",
      "Training Loss: 0.005679016025387682\n",
      "Training Loss: 0.004320505576906726\n",
      "Training Loss: 0.004190256412839517\n",
      "Training Loss: 0.004215027379104868\n",
      "Validation Loss: 0.012981847974590344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007577980611240491\n",
      "Training Loss: 0.007078048622934148\n",
      "Training Loss: 0.007492069113068283\n",
      "Training Loss: 0.005668318766984157\n",
      "Training Loss: 0.004312603991129435\n",
      "Training Loss: 0.004182790143531747\n",
      "Training Loss: 0.00420714866486378\n",
      "Validation Loss: 0.012949516359291105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007563009147997945\n",
      "Training Loss: 0.007065081978216767\n",
      "Training Loss: 0.007477826689137146\n",
      "Training Loss: 0.005657900986261666\n",
      "Training Loss: 0.004304925239412114\n",
      "Training Loss: 0.004175662060733884\n",
      "Training Loss: 0.0041995293000945825\n",
      "Validation Loss: 0.012918921615248232\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00754837050801143\n",
      "Training Loss: 0.007052472537616268\n",
      "Training Loss: 0.007463971445104107\n",
      "Training Loss: 0.005647712273639627\n",
      "Training Loss: 0.004297410047147423\n",
      "Training Loss: 0.004168801847263239\n",
      "Training Loss: 0.004192110672593116\n",
      "Validation Loss: 0.012889825859741912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007534025458153337\n",
      "Training Loss: 0.007040182077325881\n",
      "Training Loss: 0.007450464861467481\n",
      "Training Loss: 0.005637709460570477\n",
      "Training Loss: 0.004290005485527218\n",
      "Training Loss: 0.004162147002643906\n",
      "Training Loss: 0.004184840462403372\n",
      "Validation Loss: 0.012862067665705938\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007519935453310609\n",
      "Training Loss: 0.007028174775186926\n",
      "Training Loss: 0.007437266831984744\n",
      "Training Loss: 0.00562785220448859\n",
      "Training Loss: 0.004282669067033566\n",
      "Training Loss: 0.004155645734863355\n",
      "Training Loss: 0.004177676815306768\n",
      "Validation Loss: 0.012835500433549201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007506062121829018\n",
      "Training Loss: 0.007016416295664385\n",
      "Training Loss: 0.00742434143438004\n",
      "Training Loss: 0.005618116086116061\n",
      "Training Loss: 0.004275368237867952\n",
      "Training Loss: 0.004149257122771814\n",
      "Training Loss: 0.004170589439454488\n",
      "Validation Loss: 0.012810059286800495\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007492370685795322\n",
      "Training Loss: 0.00700487635913305\n",
      "Training Loss: 0.007411653518211096\n",
      "Training Loss: 0.005608484240365214\n",
      "Training Loss: 0.0042680843768175694\n",
      "Training Loss: 0.004142948690569029\n",
      "Training Loss: 0.004163558111176826\n",
      "Validation Loss: 0.012785702476396543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007478841724805534\n",
      "Training Loss: 0.006993531995685771\n",
      "Training Loss: 0.007399182057706639\n",
      "Training Loss: 0.005598956841859035\n",
      "Training Loss: 0.004260808985563926\n",
      "Training Loss: 0.0041366941499290984\n",
      "Training Loss: 0.004156569120823406\n",
      "Validation Loss: 0.012762424308886884\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007465479077072814\n",
      "Training Loss: 0.006982379993423819\n",
      "Training Loss: 0.007386922001605853\n",
      "Training Loss: 0.00558954898675438\n",
      "Training Loss: 0.004253549023414962\n",
      "Training Loss: 0.004130473878467456\n",
      "Training Loss: 0.004149621348478832\n",
      "Validation Loss: 0.012740259235358556\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007452308360952884\n",
      "Training Loss: 0.006971426910022274\n",
      "Training Loss: 0.0073748840275220575\n",
      "Training Loss: 0.00558029216772411\n",
      "Training Loss: 0.004246318614459597\n",
      "Training Loss: 0.004124273565830663\n",
      "Training Loss: 0.00414272248162888\n",
      "Validation Loss: 0.012719241004046542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.0074393722298555075\n",
      "Training Loss: 0.006960693330038339\n",
      "Training Loss: 0.007363095072796568\n",
      "Training Loss: 0.005571231715730391\n",
      "Training Loss: 0.004239146369509399\n",
      "Training Loss: 0.004118087337701581\n",
      "Training Loss: 0.004135888373712078\n",
      "Validation Loss: 0.012699431259261814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007426733081229031\n",
      "Training Loss: 0.006950208923080936\n",
      "Training Loss: 0.007351590897887945\n",
      "Training Loss: 0.005562411962309852\n",
      "Training Loss: 0.004232064679963514\n",
      "Training Loss: 0.004111913707456552\n",
      "Training Loss: 0.004129137443960644\n",
      "Validation Loss: 0.012680850946606042\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007414449078496545\n",
      "Training Loss: 0.006940000287722796\n",
      "Training Loss: 0.007340404909336939\n",
      "Training Loss: 0.005553870799485594\n",
      "Training Loss: 0.004225101542542689\n",
      "Training Loss: 0.004105756452772767\n",
      "Training Loss: 0.004122489298461005\n",
      "Validation Loss: 0.012663520728272808\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00740257314988412\n",
      "Training Loss: 0.006930091799004004\n",
      "Training Loss: 0.007329566973494366\n",
      "Training Loss: 0.0055456388427410274\n",
      "Training Loss: 0.004218287958065048\n",
      "Training Loss: 0.004099629532429389\n",
      "Training Loss: 0.004115965490345843\n",
      "Validation Loss: 0.012647435229536746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007391126038273796\n",
      "Training Loss: 0.006920487296301871\n",
      "Training Loss: 0.00731908488785848\n",
      "Training Loss: 0.0055377240246161814\n",
      "Training Loss: 0.004211644672905095\n",
      "Training Loss: 0.004093553028069436\n",
      "Training Loss: 0.0041095855250023305\n",
      "Validation Loss: 0.012632554861776224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007380113261751831\n",
      "Training Loss: 0.00691118325223215\n",
      "Training Loss: 0.007308959184447303\n",
      "Training Loss: 0.005530125187360682\n",
      "Training Loss: 0.004205188416526653\n",
      "Training Loss: 0.004087546460214071\n",
      "Training Loss: 0.004103363261674531\n",
      "Validation Loss: 0.012618825979764514\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0073695182695519175\n",
      "Training Loss: 0.006902164162602276\n",
      "Training Loss: 0.007299174938816577\n",
      "Training Loss: 0.005522828244138509\n",
      "Training Loss: 0.004198928874102421\n",
      "Training Loss: 0.004081634094472974\n",
      "Training Loss: 0.004097313723759726\n",
      "Validation Loss: 0.012606190086328442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007359313652850688\n",
      "Training Loss: 0.0068934125581290575\n",
      "Training Loss: 0.0072897127969190475\n",
      "Training Loss: 0.005515814903774298\n",
      "Training Loss: 0.004192872809362598\n",
      "Training Loss: 0.004075836901320145\n",
      "Training Loss: 0.00409144357428886\n",
      "Validation Loss: 0.012594558292483625\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007349463677965105\n",
      "Training Loss: 0.006884902575984597\n",
      "Training Loss: 0.007280548436101526\n",
      "Training Loss: 0.0055090642778668555\n",
      "Training Loss: 0.004187021448742599\n",
      "Training Loss: 0.004070174418739043\n",
      "Training Loss: 0.004085760076413862\n",
      "Validation Loss: 0.012583858859795058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007339935343479737\n",
      "Training Loss: 0.006876616064691916\n",
      "Training Loss: 0.007271661413833499\n",
      "Training Loss: 0.005502553258556872\n",
      "Training Loss: 0.0041813716443721205\n",
      "Training Loss: 0.004064656722475774\n",
      "Training Loss: 0.004080263305222615\n",
      "Validation Loss: 0.01257399547834661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0073306992510333655\n",
      "Training Loss: 0.00686853418359533\n",
      "Training Loss: 0.007263031960465014\n",
      "Training Loss: 0.0054962609155336396\n",
      "Training Loss: 0.004175919250119477\n",
      "Training Loss: 0.004059294547769241\n",
      "Training Loss: 0.004074950873036869\n",
      "Validation Loss: 0.012564917473464311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007321730259573087\n",
      "Training Loss: 0.006860642295796424\n",
      "Training Loss: 0.007254643453052267\n",
      "Training Loss: 0.0054901687247911465\n",
      "Training Loss: 0.004170653932378627\n",
      "Training Loss: 0.004054088417324238\n",
      "Training Loss: 0.004069816793198697\n",
      "Validation Loss: 0.01255651034479298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007313008172204718\n",
      "Training Loss: 0.006852930791210383\n",
      "Training Loss: 0.0072464837552979585\n",
      "Training Loss: 0.005484257872449234\n",
      "Training Loss: 0.004165566595620476\n",
      "Training Loss: 0.004049036209471524\n",
      "Training Loss: 0.004064852356677875\n",
      "Validation Loss: 0.012548719082386948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007304518957389519\n",
      "Training Loss: 0.006845391370006837\n",
      "Training Loss: 0.007238540933467447\n",
      "Training Loss: 0.005478512764675543\n",
      "Training Loss: 0.004160647831740789\n",
      "Training Loss: 0.004044133712304756\n",
      "Training Loss: 0.004060046448139474\n",
      "Validation Loss: 0.012541463017840399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007296251090010628\n",
      "Training Loss: 0.006838018114794977\n",
      "Training Loss: 0.007230807087616995\n",
      "Training Loss: 0.005472917640581727\n",
      "Training Loss: 0.004155882155173458\n",
      "Training Loss: 0.004039372543920763\n",
      "Training Loss: 0.004055388835840858\n",
      "Validation Loss: 0.012534668065227345\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007288194006541744\n",
      "Training Loss: 0.006830805786303244\n",
      "Training Loss: 0.007223273676354438\n",
      "Training Loss: 0.005467458616476506\n",
      "Training Loss: 0.004151258014608175\n",
      "Training Loss: 0.004034743770607747\n",
      "Training Loss: 0.004050867948681116\n",
      "Validation Loss: 0.012528270360933484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007280340669676661\n",
      "Training Loss: 0.006823750177863986\n",
      "Training Loss: 0.007215932459803298\n",
      "Training Loss: 0.005462122334865854\n",
      "Training Loss: 0.004146764800534584\n",
      "Training Loss: 0.004030237463302911\n",
      "Training Loss: 0.004046470789471641\n",
      "Validation Loss: 0.01252220239540848\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0072726845787838106\n",
      "Training Loss: 0.006816848649759777\n",
      "Training Loss: 0.0072087781270965936\n",
      "Training Loss: 0.005456897731637583\n",
      "Training Loss: 0.004142389534390532\n",
      "Training Loss: 0.004025844120187685\n",
      "Training Loss: 0.004042188690509647\n",
      "Validation Loss: 0.012516424182823368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007265217110980302\n",
      "Training Loss: 0.006810095993569121\n",
      "Training Loss: 0.007201801822520793\n",
      "Training Loss: 0.005451773544191383\n",
      "Training Loss: 0.004138119695126079\n",
      "Training Loss: 0.004021553268539719\n",
      "Training Loss: 0.004038007739000022\n",
      "Validation Loss: 0.012510893908713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007257934045046568\n",
      "Training Loss: 0.0068034889223054056\n",
      "Training Loss: 0.007194995887111873\n",
      "Training Loss: 0.005446738922037184\n",
      "Training Loss: 0.004133946617948823\n",
      "Training Loss: 0.004017355278483592\n",
      "Training Loss: 0.0040339177218265835\n",
      "Validation Loss: 0.012505543324049939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0072508278861641885\n",
      "Training Loss: 0.006797023023827933\n",
      "Training Loss: 0.007188354930840433\n",
      "Training Loss: 0.005441784714930691\n",
      "Training Loss: 0.004129859250970185\n",
      "Training Loss: 0.004013241904904135\n",
      "Training Loss: 0.00402991259470582\n",
      "Validation Loss: 0.012500374104866012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.0072438895283266904\n",
      "Training Loss: 0.006790692945942283\n",
      "Training Loss: 0.007181868156185374\n",
      "Training Loss: 0.005436902715009637\n",
      "Training Loss: 0.004125849644187838\n",
      "Training Loss: 0.004009204294998198\n",
      "Training Loss: 0.004025980406440794\n",
      "Validation Loss: 0.012495341705514139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007237113430164754\n",
      "Training Loss: 0.0067844951141159985\n",
      "Training Loss: 0.007175529992673546\n",
      "Training Loss: 0.005432082947227173\n",
      "Training Loss: 0.0041219070105580615\n",
      "Training Loss: 0.004005232893978246\n",
      "Training Loss: 0.004022112506791018\n",
      "Validation Loss: 0.012490420852097148\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007230493867537007\n",
      "Training Loss: 0.006778424087096937\n",
      "Training Loss: 0.007169333043275401\n",
      "Training Loss: 0.005427319368463941\n",
      "Training Loss: 0.004118023941409774\n",
      "Training Loss: 0.004001321661053226\n",
      "Training Loss: 0.004018303435877897\n",
      "Validation Loss: 0.012485600832661384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.00722402119776234\n",
      "Training Loss: 0.006772474093013443\n",
      "Training Loss: 0.007163267993601039\n",
      "Training Loss: 0.0054226045723771675\n",
      "Training Loss: 0.004114193295827136\n",
      "Training Loss: 0.003997463482664898\n",
      "Training Loss: 0.004014546271646395\n",
      "Validation Loss: 0.012480832103549151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007217686448711902\n",
      "Training Loss: 0.006766639390261844\n",
      "Training Loss: 0.007157327349996194\n",
      "Training Loss: 0.005417931012343616\n",
      "Training Loss: 0.0041104096453636885\n",
      "Training Loss: 0.0039936530229169875\n",
      "Training Loss: 0.004010834270738997\n",
      "Validation Loss: 0.012476127516227157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007211483920691535\n",
      "Training Loss: 0.00676091525296215\n",
      "Training Loss: 0.007151503749191761\n",
      "Training Loss: 0.005413293906021863\n",
      "Training Loss: 0.004106665070285089\n",
      "Training Loss: 0.003989883959875442\n",
      "Training Loss: 0.00400716295291204\n",
      "Validation Loss: 0.01247147108211918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007205403513507918\n",
      "Training Loss: 0.0067552934511331845\n",
      "Training Loss: 0.007145789136411622\n",
      "Training Loss: 0.00540868780342862\n",
      "Training Loss: 0.004102956591523253\n",
      "Training Loss: 0.00398615108220838\n",
      "Training Loss: 0.004003525773296133\n",
      "Validation Loss: 0.012466864282795496\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007199442479759455\n",
      "Training Loss: 0.006749773176270537\n",
      "Training Loss: 0.0071401773008983585\n",
      "Training Loss: 0.005404106599162333\n",
      "Training Loss: 0.004099275495973415\n",
      "Training Loss: 0.003982448952156119\n",
      "Training Loss: 0.003999919883790426\n",
      "Validation Loss: 0.012462284858948952\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.0071935873269103464\n",
      "Training Loss: 0.006744342991150915\n",
      "Training Loss: 0.007134660284500569\n",
      "Training Loss: 0.005399546432308853\n",
      "Training Loss: 0.004095619528088719\n",
      "Training Loss: 0.003978773357230239\n",
      "Training Loss: 0.003996340071898885\n",
      "Validation Loss: 0.01245773370396904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.0071878344763536\n",
      "Training Loss: 0.006739001140231266\n",
      "Training Loss: 0.007129230910213664\n",
      "Training Loss: 0.005395003410521895\n",
      "Training Loss: 0.004091983526595868\n",
      "Training Loss: 0.003975122072151862\n",
      "Training Loss: 0.003992782196146436\n",
      "Validation Loss: 0.012453206452499196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0071821754041593525\n",
      "Training Loss: 0.0067337418918032195\n",
      "Training Loss: 0.007123884151224047\n",
      "Training Loss: 0.005390475515741855\n",
      "Training Loss: 0.00408836523653008\n",
      "Training Loss: 0.0039714906306471676\n",
      "Training Loss: 0.003989245804259554\n",
      "Validation Loss: 0.012448712548132889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007176601530518383\n",
      "Training Loss: 0.00672855706885457\n",
      "Training Loss: 0.007118610328761861\n",
      "Training Loss: 0.00538595542544499\n",
      "Training Loss: 0.004084759464021772\n",
      "Training Loss: 0.0039678751758765425\n",
      "Training Loss: 0.0039857239089906215\n",
      "Validation Loss: 0.01244424329024185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007171109615592286\n",
      "Training Loss: 0.006723444483359344\n",
      "Training Loss: 0.007113407014403492\n",
      "Training Loss: 0.005381442512734793\n",
      "Training Loss: 0.004081163924420253\n",
      "Training Loss: 0.003964273268938996\n",
      "Training Loss: 0.003982217277516611\n",
      "Validation Loss: 0.012439801196797929\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007165690051624552\n",
      "Training Loss: 0.006718397056683898\n",
      "Training Loss: 0.0071082660520914945\n",
      "Training Loss: 0.005376932547660545\n",
      "Training Loss: 0.004077574750990607\n",
      "Training Loss: 0.003960682501201518\n",
      "Training Loss: 0.003978721605380997\n",
      "Validation Loss: 0.012435383102786815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007160336811793968\n",
      "Training Loss: 0.006713409653748385\n",
      "Training Loss: 0.0071031831915024666\n",
      "Training Loss: 0.005372422971995547\n",
      "Training Loss: 0.004073989828466438\n",
      "Training Loss: 0.003957099422696047\n",
      "Training Loss: 0.003975235209218227\n",
      "Validation Loss: 0.012431007738866972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.0071550442837178705\n",
      "Training Loss: 0.006708477498032153\n",
      "Training Loss: 0.007098151968093589\n",
      "Training Loss: 0.005367911402136088\n",
      "Training Loss: 0.004070406690589152\n",
      "Training Loss: 0.003953523255186156\n",
      "Training Loss: 0.003971756502869539\n",
      "Validation Loss: 0.01242667938929665\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.00714980561286211\n",
      "Training Loss: 0.006703596028964967\n",
      "Training Loss: 0.007093168451683595\n",
      "Training Loss: 0.0053633963793981825\n",
      "Training Loss: 0.004066824303008616\n",
      "Training Loss: 0.003949952035909519\n",
      "Training Loss: 0.0039682830311357975\n",
      "Validation Loss: 0.012422393349937621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00714461573283188\n",
      "Training Loss: 0.006698759739520028\n",
      "Training Loss: 0.007088226160267368\n",
      "Training Loss: 0.0053588732791831715\n",
      "Training Loss: 0.004063235867652111\n",
      "Training Loss: 0.003946378556429408\n",
      "Training Loss: 0.003964810458710417\n",
      "Validation Loss: 0.012418136996921668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007139470534166321\n",
      "Training Loss: 0.006693965643062256\n",
      "Training Loss: 0.007083322891267016\n",
      "Training Loss: 0.005354341145721264\n",
      "Training Loss: 0.0040596427640412006\n",
      "Training Loss: 0.003942806675331667\n",
      "Training Loss: 0.0039613408030709256\n",
      "Validation Loss: 0.012413945700014044\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007134361974895\n",
      "Training Loss: 0.006689207423478365\n",
      "Training Loss: 0.007078452048590407\n",
      "Training Loss: 0.005349796918453649\n",
      "Training Loss: 0.004056042750598863\n",
      "Training Loss: 0.003939233684213832\n",
      "Training Loss: 0.003957871963502839\n",
      "Validation Loss: 0.012409807789777771\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007129285223782062\n",
      "Training Loss: 0.006684480900294148\n",
      "Training Loss: 0.007073609633371234\n",
      "Training Loss: 0.005345240146270953\n",
      "Training Loss: 0.004052432322059758\n",
      "Training Loss: 0.003935653603984974\n",
      "Training Loss: 0.003954399064532481\n",
      "Validation Loss: 0.012405723199938958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007124237936222926\n",
      "Training Loss: 0.006679784425650723\n",
      "Training Loss: 0.007068792744539678\n",
      "Training Loss: 0.005340667306445539\n",
      "Training Loss: 0.004048809867235832\n",
      "Training Loss: 0.003932067407295108\n",
      "Training Loss: 0.0039509222999913616\n",
      "Validation Loss: 0.012401713725887518\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007119213687255979\n",
      "Training Loss: 0.006675111119402572\n",
      "Training Loss: 0.0070639963005669415\n",
      "Training Loss: 0.005336077513638884\n",
      "Training Loss: 0.004045175846549683\n",
      "Training Loss: 0.003928475926513784\n",
      "Training Loss: 0.003947443013894372\n",
      "Validation Loss: 0.012397789358412533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007114205820253119\n",
      "Training Loss: 0.006670456552528776\n",
      "Training Loss: 0.00705921595566906\n",
      "Training Loss: 0.005331467209034599\n",
      "Training Loss: 0.004041524986969307\n",
      "Training Loss: 0.0039248726319056\n",
      "Training Loss: 0.003943955732393078\n",
      "Validation Loss: 0.012393926958769756\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007109211694914848\n",
      "Training Loss: 0.00666581749508623\n",
      "Training Loss: 0.007054448954295367\n",
      "Training Loss: 0.005326836460735649\n",
      "Training Loss: 0.004037859897944145\n",
      "Training Loss: 0.003921261730720289\n",
      "Training Loss: 0.003940461216843687\n",
      "Validation Loss: 0.012390170286039818\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007104228816460818\n",
      "Training Loss: 0.006661193818436004\n",
      "Training Loss: 0.007049692352302373\n",
      "Training Loss: 0.005322181790834293\n",
      "Training Loss: 0.004034171915263869\n",
      "Training Loss: 0.003917634138488211\n",
      "Training Loss: 0.003936955584795215\n",
      "Validation Loss: 0.01238648658827617\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.007099250111496076\n",
      "Training Loss: 0.0066565768106374885\n",
      "Training Loss: 0.007044941525673493\n",
      "Training Loss: 0.005317500635865145\n",
      "Training Loss: 0.004030465196119621\n",
      "Training Loss: 0.003913993056048639\n",
      "Training Loss: 0.0039334388013230635\n",
      "Validation Loss: 0.01238289510060367\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007094271966489032\n",
      "Training Loss: 0.006651964992051944\n",
      "Training Loss: 0.00704019351862371\n",
      "Training Loss: 0.005312792984186672\n",
      "Training Loss: 0.004026734762592241\n",
      "Training Loss: 0.003910335851833225\n",
      "Training Loss: 0.003929910991573706\n",
      "Validation Loss: 0.012379428162937111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007089290391886607\n",
      "Training Loss: 0.006647355273016729\n",
      "Training Loss: 0.007035444518551231\n",
      "Training Loss: 0.0053080556128406895\n",
      "Training Loss: 0.004022980600129813\n",
      "Training Loss: 0.003906661334913224\n",
      "Training Loss: 0.003926367515814491\n",
      "Validation Loss: 0.012376057195096985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007084303962765262\n",
      "Training Loss: 0.006642743680858984\n",
      "Training Loss: 0.007030692787375301\n",
      "Training Loss: 0.005303286430425942\n",
      "Training Loss: 0.004019198448513634\n",
      "Training Loss: 0.003902964986045845\n",
      "Training Loss: 0.003922807707567699\n",
      "Validation Loss: 0.012372785665126245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007079306038795039\n",
      "Training Loss: 0.006638126365141943\n",
      "Training Loss: 0.0070259334880393\n",
      "Training Loss: 0.005298484560917131\n",
      "Training Loss: 0.004015390157583169\n",
      "Training Loss: 0.0038992488430812954\n",
      "Training Loss: 0.003919232016778551\n",
      "Validation Loss: 0.012369636065162691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007074293085606769\n",
      "Training Loss: 0.006633500645984895\n",
      "Training Loss: 0.007021163788158447\n",
      "Training Loss: 0.005293646638747305\n",
      "Training Loss: 0.0040115517523372545\n",
      "Training Loss: 0.003895510079455562\n",
      "Training Loss: 0.00391563669545576\n",
      "Validation Loss: 0.01236662429396398\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.0070692612603306774\n",
      "Training Loss: 0.00662886186153628\n",
      "Training Loss: 0.007016380704008043\n",
      "Training Loss: 0.005288771314080804\n",
      "Training Loss: 0.004007680187933147\n",
      "Training Loss: 0.0038917439000215382\n",
      "Training Loss: 0.003912020652205683\n",
      "Validation Loss: 0.012363728233927002\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007064209379022941\n",
      "Training Loss: 0.006624209171277471\n",
      "Training Loss: 0.0070115817070472986\n",
      "Training Loss: 0.0052838566817808895\n",
      "Training Loss: 0.004003775468445383\n",
      "Training Loss: 0.003887951913638972\n",
      "Training Loss: 0.0039083816896891225\n",
      "Validation Loss: 0.012360953827465323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007059131242567673\n",
      "Training Loss: 0.0066195381007855755\n",
      "Training Loss: 0.007006763664539903\n",
      "Training Loss: 0.005278898999094963\n",
      "Training Loss: 0.003999833885463886\n",
      "Training Loss: 0.003884130732039921\n",
      "Training Loss: 0.0039047187264077366\n",
      "Validation Loss: 0.012358343050804702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.0070540254784282296\n",
      "Training Loss: 0.0066148452344350515\n",
      "Training Loss: 0.007001923458883539\n",
      "Training Loss: 0.005273897239239886\n",
      "Training Loss: 0.003995855055982247\n",
      "Training Loss: 0.0038802779716206716\n",
      "Training Loss: 0.003901028612162918\n",
      "Validation Loss: 0.012355855823937483\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007048887895653024\n",
      "Training Loss: 0.00661012876778841\n",
      "Training Loss: 0.006997056544059887\n",
      "Training Loss: 0.005268849828862585\n",
      "Training Loss: 0.003991836102795787\n",
      "Training Loss: 0.0038763916329480706\n",
      "Training Loss: 0.0038973104953765867\n",
      "Validation Loss: 0.012353502413648623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.0070437135617248715\n",
      "Training Loss: 0.006605384022695944\n",
      "Training Loss: 0.006992161771049723\n",
      "Training Loss: 0.005263753049075603\n",
      "Training Loss: 0.003987774806446396\n",
      "Training Loss: 0.0038724711473332716\n",
      "Training Loss: 0.003893563246820122\n",
      "Validation Loss: 0.012351295562837733\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007038498711772263\n",
      "Training Loss: 0.006600607509026304\n",
      "Training Loss: 0.006987233830150217\n",
      "Training Loss: 0.005258604792761617\n",
      "Training Loss: 0.003983670735033229\n",
      "Training Loss: 0.0038685153552796693\n",
      "Training Loss: 0.0038897860335418955\n",
      "Validation Loss: 0.012349269545570796\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007033241798635573\n",
      "Training Loss: 0.006595796128967777\n",
      "Training Loss: 0.006982270403532311\n",
      "Training Loss: 0.005253402999951504\n",
      "Training Loss: 0.003979519518325105\n",
      "Training Loss: 0.0038645199360325933\n",
      "Training Loss: 0.003885973807191476\n",
      "Validation Loss: 0.012347385339606344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007027937678503804\n",
      "Training Loss: 0.006590947120566852\n",
      "Training Loss: 0.006977267714682966\n",
      "Training Loss: 0.005248144641518593\n",
      "Training Loss: 0.00397532170813065\n",
      "Training Loss: 0.003860484284814447\n",
      "Training Loss: 0.003882126486860216\n",
      "Validation Loss: 0.012345662312181004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007022582730278373\n",
      "Training Loss: 0.006586056941305287\n",
      "Training Loss: 0.006972223150078207\n",
      "Training Loss: 0.005242827623151243\n",
      "Training Loss: 0.003971073644352146\n",
      "Training Loss: 0.0038564055622555314\n",
      "Training Loss: 0.0038782414403976872\n",
      "Validation Loss: 0.012344125263246426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.0070171742257662114\n",
      "Training Loss: 0.00658112253062427\n",
      "Training Loss: 0.0069671324198134245\n",
      "Training Loss: 0.0052374494948890064\n",
      "Training Loss: 0.003966772111598402\n",
      "Training Loss: 0.0038522799743805083\n",
      "Training Loss: 0.003874316538567655\n",
      "Validation Loss: 0.012342740217841158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.007011709735961631\n",
      "Training Loss: 0.006576141646364704\n",
      "Training Loss: 0.0069619931350462134\n",
      "Training Loss: 0.005232007161830552\n",
      "Training Loss: 0.003962417700677179\n",
      "Training Loss: 0.0038481083483202384\n",
      "Training Loss: 0.003870351546211168\n",
      "Validation Loss: 0.012341545504946889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007006182213663123\n",
      "Training Loss: 0.006571107541094534\n",
      "Training Loss: 0.006956799691542983\n",
      "Training Loss: 0.005226497608236969\n",
      "Training Loss: 0.003958007585606538\n",
      "Training Loss: 0.003843888202100061\n",
      "Training Loss: 0.0038663430215092375\n",
      "Validation Loss: 0.012340522686033492\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.00700059081078507\n",
      "Training Loss: 0.006566020273603499\n",
      "Training Loss: 0.00695154853281565\n",
      "Training Loss: 0.005220919710118324\n",
      "Training Loss: 0.00395353973202873\n",
      "Training Loss: 0.003839617006597109\n",
      "Training Loss: 0.0038622898043831812\n",
      "Validation Loss: 0.012339691452730851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.006994927123887464\n",
      "Training Loss: 0.0065608707332285125\n",
      "Training Loss: 0.006946235970826819\n",
      "Training Loss: 0.005215268493629992\n",
      "Training Loss: 0.0039490123401628805\n",
      "Training Loss: 0.003835292920703068\n",
      "Training Loss: 0.003858190422761254\n",
      "Validation Loss: 0.012339062439818424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006989192571491003\n",
      "Training Loss: 0.0065556592197390275\n",
      "Training Loss: 0.006940857300069183\n",
      "Training Loss: 0.005209541941876523\n",
      "Training Loss: 0.0039444227435160425\n",
      "Training Loss: 0.0038309141353238376\n",
      "Training Loss: 0.0038540418760385363\n",
      "Validation Loss: 0.012338632221546457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006983379686716944\n",
      "Training Loss: 0.006550381123670377\n",
      "Training Loss: 0.006935408670688048\n",
      "Training Loss: 0.005203736939001828\n",
      "Training Loss: 0.003939770244178362\n",
      "Training Loss: 0.003826478059636429\n",
      "Training Loss: 0.0038498442381387577\n",
      "Validation Loss: 0.012338405224749268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006977484535891563\n",
      "Training Loss: 0.006545028634718619\n",
      "Training Loss: 0.006929884366691112\n",
      "Training Loss: 0.00519785129930824\n",
      "Training Loss: 0.0039350538316648455\n",
      "Training Loss: 0.0038219841616228224\n",
      "Training Loss: 0.0038455942668952046\n",
      "Validation Loss: 0.012338388216339945\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.0069715025986079125\n",
      "Training Loss: 0.0065396025433437895\n",
      "Training Loss: 0.006924280772218481\n",
      "Training Loss: 0.005191881381324493\n",
      "Training Loss: 0.003930269865668379\n",
      "Training Loss: 0.003817430075723678\n",
      "Training Loss: 0.0038412915967637675\n",
      "Validation Loss: 0.012338590975641535\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 112\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006965429440606385\n",
      "Training Loss: 0.006534094243543223\n",
      "Training Loss: 0.006918592241127044\n",
      "Training Loss: 0.0051858243328752\n",
      "Training Loss: 0.0039254173001972955\n",
      "Training Loss: 0.0038128140004118904\n",
      "Training Loss: 0.0038369347830303014\n",
      "Validation Loss: 0.012339027627277073\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 113\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006959260229486972\n",
      "Training Loss: 0.006528499550186097\n",
      "Training Loss: 0.006912813545204699\n",
      "Training Loss: 0.005179677262785845\n",
      "Training Loss: 0.003920496520004235\n",
      "Training Loss: 0.0038081357919145377\n",
      "Training Loss: 0.0038325229636393485\n",
      "Validation Loss: 0.01233968943966141\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 114\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0069529905694071205\n",
      "Training Loss: 0.0065228151867631826\n",
      "Training Loss: 0.006906941069755704\n",
      "Training Loss: 0.005173437842749991\n",
      "Training Loss: 0.003915505465702154\n",
      "Training Loss: 0.003803392652189359\n",
      "Training Loss: 0.0038280544569715856\n",
      "Validation Loss: 0.012340595198826592\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 115\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006946614264743403\n",
      "Training Loss: 0.006517034744028934\n",
      "Training Loss: 0.006900966567918658\n",
      "Training Loss: 0.005167103501735255\n",
      "Training Loss: 0.003910441558691673\n",
      "Training Loss: 0.0037985850032418965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [06:09<16:54, 144.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.003823530526715331\n",
      "Validation Loss: 0.012341752007415288\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 116\n",
      "Early stopping after 116 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.1572899107262492\n",
      "Training Loss: 0.10597464291378855\n",
      "Training Loss: 0.07931890398263931\n",
      "Training Loss: 0.06730661280453205\n",
      "Training Loss: 0.06165396988391876\n",
      "Training Loss: 0.059154044259339573\n",
      "Training Loss: 0.05835522923618555\n",
      "Validation Loss: 0.06129333016912589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06014372879639268\n",
      "Training Loss: 0.05605075985193252\n",
      "Training Loss: 0.053288208106532696\n",
      "Training Loss: 0.048871028786525134\n",
      "Training Loss: 0.04332186472602188\n",
      "Training Loss: 0.03956788587383926\n",
      "Training Loss: 0.036593905156478285\n",
      "Validation Loss: 0.04277990975378828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.03717723216861486\n",
      "Training Loss: 0.033124105464667083\n",
      "Training Loss: 0.030305453529581427\n",
      "Training Loss: 0.025810727532953024\n",
      "Training Loss: 0.020617859014309944\n",
      "Training Loss: 0.018593178405426444\n",
      "Training Loss: 0.01702874677721411\n",
      "Validation Loss: 0.02832047404435355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.020911079212091864\n",
      "Training Loss: 0.019222698118537666\n",
      "Training Loss: 0.018837697480339557\n",
      "Training Loss: 0.015872940130066127\n",
      "Training Loss: 0.012422917447984218\n",
      "Training Loss: 0.01211921866517514\n",
      "Training Loss: 0.011566672227345406\n",
      "Validation Loss: 0.02391849330029963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.016580253629945217\n",
      "Training Loss: 0.015591097224969416\n",
      "Training Loss: 0.015991397122852503\n",
      "Training Loss: 0.013420762536115944\n",
      "Training Loss: 0.010440396555932239\n",
      "Training Loss: 0.01047975551104173\n",
      "Training Loss: 0.010103020345559344\n",
      "Validation Loss: 0.022328098787671505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.015193488624645398\n",
      "Training Loss: 0.01435924916760996\n",
      "Training Loss: 0.014924909577239305\n",
      "Training Loss: 0.012482520783087238\n",
      "Training Loss: 0.009660571817075834\n",
      "Training Loss: 0.009777158312499524\n",
      "Training Loss: 0.00945819070446305\n",
      "Validation Loss: 0.02145981370324918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.014499339397298172\n",
      "Training Loss: 0.013724341015331447\n",
      "Training Loss: 0.014345710867783055\n",
      "Training Loss: 0.01197075481293723\n",
      "Training Loss: 0.009232653641374782\n",
      "Training Loss: 0.009375523410271853\n",
      "Training Loss: 0.00908700306317769\n",
      "Validation Loss: 0.020911255025580413\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.014078239019727334\n",
      "Training Loss: 0.01332906176103279\n",
      "Training Loss: 0.013977119743358343\n",
      "Training Loss: 0.011641091115307063\n",
      "Training Loss: 0.008956282335566357\n",
      "Training Loss: 0.009109600586816669\n",
      "Training Loss: 0.00883931790245697\n",
      "Validation Loss: 0.020525517771439104\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.013788629852933809\n",
      "Training Loss: 0.013049149392172695\n",
      "Training Loss: 0.01371197554981336\n",
      "Training Loss: 0.011399624708574266\n",
      "Training Loss: 0.00875230357516557\n",
      "Training Loss: 0.008908940709661693\n",
      "Training Loss: 0.008649978301255032\n",
      "Validation Loss: 0.020219531185813388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.013561637225793675\n",
      "Training Loss: 0.012822733155917376\n",
      "Training Loss: 0.013493592506274582\n",
      "Training Loss: 0.011195767485769465\n",
      "Training Loss: 0.008577012789901346\n",
      "Training Loss: 0.008732212592149154\n",
      "Training Loss: 0.008479965692386031\n",
      "Validation Loss: 0.019937086774538575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.01335293273674324\n",
      "Training Loss: 0.012608075754251331\n",
      "Training Loss: 0.013281510958913714\n",
      "Training Loss: 0.010991618089610711\n",
      "Training Loss: 0.00839637917233631\n",
      "Training Loss: 0.008545059643220157\n",
      "Training Loss: 0.008295628046616911\n",
      "Validation Loss: 0.01962607420374001\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.013122206453699619\n",
      "Training Loss: 0.01236480128020048\n",
      "Training Loss: 0.013034343250328675\n",
      "Training Loss: 0.0107459722913336\n",
      "Training Loss: 0.00817189837922342\n",
      "Training Loss: 0.008306472898693755\n",
      "Training Loss: 0.008055399699369446\n",
      "Validation Loss: 0.019221027968590904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.01281886002747342\n",
      "Training Loss: 0.012040453122463077\n",
      "Training Loss: 0.012696602223441005\n",
      "Training Loss: 0.010401534563861788\n",
      "Training Loss: 0.007849543167976663\n",
      "Training Loss: 0.007957781197037548\n",
      "Training Loss: 0.007699820426059887\n",
      "Validation Loss: 0.018631879821915026\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.01237415798008442\n",
      "Training Loss: 0.011566185394767671\n",
      "Training Loss: 0.012196320667862892\n",
      "Training Loss: 0.009885377901955508\n",
      "Training Loss: 0.007365531739778817\n",
      "Training Loss: 0.007432547743665054\n",
      "Training Loss: 0.007167644901783205\n",
      "Validation Loss: 0.01778104364495264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.011732797692529858\n",
      "Training Loss: 0.01090080562629737\n",
      "Training Loss: 0.011496031731367111\n",
      "Training Loss: 0.009171891203150153\n",
      "Training Loss: 0.006719658198999241\n",
      "Training Loss: 0.006741950701689347\n",
      "Training Loss: 0.006491357631748542\n",
      "Validation Loss: 0.016753626704802006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.010966682258294896\n",
      "Training Loss: 0.010147670613368973\n",
      "Training Loss: 0.010707698217593133\n",
      "Training Loss: 0.008401584511157125\n",
      "Training Loss: 0.00607481665094383\n",
      "Training Loss: 0.006063335015205666\n",
      "Training Loss: 0.0058601834409637375\n",
      "Validation Loss: 0.015820851810241628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.010288649570429697\n",
      "Training Loss: 0.009515281319618225\n",
      "Training Loss: 0.010035374735016376\n",
      "Training Loss: 0.007776785314781591\n",
      "Training Loss: 0.0055939935747301205\n",
      "Training Loss: 0.005549768335185945\n",
      "Training Loss: 0.005397130562341772\n",
      "Validation Loss: 0.015088878946957852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.00979203764232807\n",
      "Training Loss: 0.009057767953490838\n",
      "Training Loss: 0.00953881125897169\n",
      "Training Loss: 0.007327475629863329\n",
      "Training Loss: 0.005260290284641087\n",
      "Training Loss: 0.005187413488747552\n",
      "Training Loss: 0.005071543544181623\n",
      "Validation Loss: 0.014505387393736772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.009433469151845201\n",
      "Training Loss: 0.00872590507613495\n",
      "Training Loss: 0.009179966601077467\n",
      "Training Loss: 0.007004924591747112\n",
      "Training Loss: 0.005022708362084813\n",
      "Training Loss: 0.004931957630324177\n",
      "Training Loss: 0.00484194905613549\n",
      "Validation Loss: 0.01405450315406539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.009168063218239694\n",
      "Training Loss: 0.008479883704567329\n",
      "Training Loss: 0.008916476714657619\n",
      "Training Loss: 0.006768356679822318\n",
      "Training Loss: 0.004851383958593942\n",
      "Training Loss: 0.004751642087940127\n",
      "Training Loss: 0.004679733033990488\n",
      "Validation Loss: 0.01372376528013958\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.008960168831981719\n",
      "Training Loss: 0.008287683431990444\n",
      "Training Loss: 0.008712621924933045\n",
      "Training Loss: 0.006586946120951325\n",
      "Training Loss: 0.0047252031217794865\n",
      "Training Loss: 0.004622306749224663\n",
      "Training Loss: 0.00456305400643032\n",
      "Validation Loss: 0.013488785478405041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.00878483964712359\n",
      "Training Loss: 0.008126842066412792\n",
      "Training Loss: 0.008544046794995666\n",
      "Training Loss: 0.006440364143345505\n",
      "Training Loss: 0.004629871279466897\n",
      "Training Loss: 0.004527442124090158\n",
      "Training Loss: 0.004477261169231497\n",
      "Validation Loss: 0.013324717289074028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.008629194813547656\n",
      "Training Loss: 0.007985612559132278\n",
      "Training Loss: 0.008397897628601641\n",
      "Training Loss: 0.00631755361915566\n",
      "Training Loss: 0.004556892350083217\n",
      "Training Loss: 0.004457070364733227\n",
      "Training Loss: 0.004413622138672508\n",
      "Validation Loss: 0.013211375367932356\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.008488579917466267\n",
      "Training Loss: 0.007859559473581612\n",
      "Training Loss: 0.008268924980657176\n",
      "Training Loss: 0.006213298289803788\n",
      "Training Loss: 0.004501283990684897\n",
      "Training Loss: 0.004405172218102962\n",
      "Training Loss: 0.004366821313160471\n",
      "Validation Loss: 0.013132863308735582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.008362246357137337\n",
      "Training Loss: 0.007747736544115469\n",
      "Training Loss: 0.008155508734053001\n",
      "Training Loss: 0.006125108391861431\n",
      "Training Loss: 0.004459564151475206\n",
      "Training Loss: 0.004367534695193171\n",
      "Training Loss: 0.0043330217158654705\n",
      "Validation Loss: 0.013076598121181187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.008250509072095156\n",
      "Training Loss: 0.007650091138202697\n",
      "Training Loss: 0.00805700833327137\n",
      "Training Loss: 0.006051258893567137\n",
      "Training Loss: 0.0044286944880150255\n",
      "Training Loss: 0.004340658696601167\n",
      "Training Loss: 0.004308938284520991\n",
      "Validation Loss: 0.0130334296180912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.008153305277228356\n",
      "Training Loss: 0.00756615204620175\n",
      "Training Loss: 0.007972494785208254\n",
      "Training Loss: 0.005989926311303862\n",
      "Training Loss: 0.004405849231407046\n",
      "Training Loss: 0.0043215110729215665\n",
      "Training Loss: 0.004291707752272487\n",
      "Validation Loss: 0.012997701253972194\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.008069769741268829\n",
      "Training Loss: 0.007494727440644056\n",
      "Training Loss: 0.007900510989129543\n",
      "Training Loss: 0.005939111362094991\n",
      "Training Loss: 0.004388607670553029\n",
      "Training Loss: 0.00430762350151781\n",
      "Training Loss: 0.004279026706353761\n",
      "Validation Loss: 0.012966856074411325\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007998476906213909\n",
      "Training Loss: 0.007434195629321039\n",
      "Training Loss: 0.007839340950595216\n",
      "Training Loss: 0.0058968644769629465\n",
      "Training Loss: 0.004375104224309325\n",
      "Training Loss: 0.0042971453751670195\n",
      "Training Loss: 0.004269217394175939\n",
      "Validation Loss: 0.01294013765581259\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007937804200919345\n",
      "Training Loss: 0.007382879466749728\n",
      "Training Loss: 0.007787321809446439\n",
      "Training Loss: 0.005861488220398314\n",
      "Training Loss: 0.004364023703383282\n",
      "Training Loss: 0.004288786200340837\n",
      "Training Loss: 0.004261158630833961\n",
      "Validation Loss: 0.01291736052284359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007886171174468472\n",
      "Training Loss: 0.007339257389539853\n",
      "Training Loss: 0.007742979889735579\n",
      "Training Loss: 0.005831588483997621\n",
      "Training Loss: 0.004354484872892499\n",
      "Training Loss: 0.0042816838721046226\n",
      "Training Loss: 0.004254136749659665\n",
      "Validation Loss: 0.012898383768491643\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007842162922024727\n",
      "Training Loss: 0.007302033466985449\n",
      "Training Loss: 0.007705067722126841\n",
      "Training Loss: 0.005806065315264277\n",
      "Training Loss: 0.0043459189182613045\n",
      "Training Loss: 0.004275292175007053\n",
      "Training Loss: 0.004247724118176848\n",
      "Validation Loss: 0.012882884359859237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0078045439790003\n",
      "Training Loss: 0.007270124059868976\n",
      "Training Loss: 0.007672534411540255\n",
      "Training Loss: 0.0057840620505157855\n",
      "Training Loss: 0.0043379778665257615\n",
      "Training Loss: 0.004269281552988105\n",
      "Training Loss: 0.004241679860278964\n",
      "Validation Loss: 0.012870381954684157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007772248019464314\n",
      "Training Loss: 0.007242618541931733\n",
      "Training Loss: 0.007644491456449032\n",
      "Training Loss: 0.005764902348164469\n",
      "Training Loss: 0.004330462231300771\n",
      "Training Loss: 0.0042634743195958434\n",
      "Training Loss: 0.004235880019259639\n",
      "Validation Loss: 0.01286043923859195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007744373033056036\n",
      "Training Loss: 0.0072187586245127024\n",
      "Training Loss: 0.007620188615983352\n",
      "Training Loss: 0.005748056612792425\n",
      "Training Loss: 0.004323262297548354\n",
      "Training Loss: 0.004257781885098666\n",
      "Training Loss: 0.004230267388629727\n",
      "Validation Loss: 0.012852545039316689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007720151075627655\n",
      "Training Loss: 0.0071979081688914445\n",
      "Training Loss: 0.007598995027365163\n",
      "Training Loss: 0.00573310146399308\n",
      "Training Loss: 0.004316323392558843\n",
      "Training Loss: 0.004252168846433051\n",
      "Training Loss: 0.004224818393122404\n",
      "Validation Loss: 0.012846300384109973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007698943206341937\n",
      "Training Loss: 0.007179538138443604\n",
      "Training Loss: 0.0075803780881688\n",
      "Training Loss: 0.005719702008645982\n",
      "Training Loss: 0.00430962233338505\n",
      "Training Loss: 0.004246632326976396\n",
      "Training Loss: 0.004219532826682553\n",
      "Validation Loss: 0.01284136679258951\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007680207587545737\n",
      "Training Loss: 0.0071632027183659375\n",
      "Training Loss: 0.007563891033641994\n",
      "Training Loss: 0.005707581663154997\n",
      "Training Loss: 0.0043031491630245\n",
      "Training Loss: 0.0042411779175745325\n",
      "Training Loss: 0.004214407259132713\n",
      "Validation Loss: 0.012837449146246308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0076635038142558185\n",
      "Training Loss: 0.007148538006003946\n",
      "Training Loss: 0.007549161966890097\n",
      "Training Loss: 0.005696518280892633\n",
      "Training Loss: 0.004296900844783522\n",
      "Training Loss: 0.004235815748688765\n",
      "Training Loss: 0.004209443029831164\n",
      "Validation Loss: 0.01283428346657993\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007648462421493605\n",
      "Training Loss: 0.007135241542709991\n",
      "Training Loss: 0.00753588552470319\n",
      "Training Loss: 0.005686325400602072\n",
      "Training Loss: 0.004290865790680982\n",
      "Training Loss: 0.004230546508915722\n",
      "Training Loss: 0.004204628271982074\n",
      "Validation Loss: 0.012831676797592517\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007634788703871891\n",
      "Training Loss: 0.007123069763183594\n",
      "Training Loss: 0.007523807239485905\n",
      "Training Loss: 0.005676856481004506\n",
      "Training Loss: 0.0042850359878502785\n",
      "Training Loss: 0.0042253737553255635\n",
      "Training Loss: 0.004199957845266908\n",
      "Validation Loss: 0.012829485334532705\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007622237369650975\n",
      "Training Loss: 0.007111820458667353\n",
      "Training Loss: 0.007512720089871436\n",
      "Training Loss: 0.005667985518230125\n",
      "Training Loss: 0.004279399047372862\n",
      "Training Loss: 0.004220295699778945\n",
      "Training Loss: 0.004195417762966827\n",
      "Validation Loss: 0.012827547691319458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.0076106122497003525\n",
      "Training Loss: 0.007101331395097077\n",
      "Training Loss: 0.007502452401677146\n",
      "Training Loss: 0.0056596107839141045\n",
      "Training Loss: 0.004273943179869093\n",
      "Training Loss: 0.004215307441772893\n",
      "Training Loss: 0.0041909929760731756\n",
      "Validation Loss: 0.012825758037704988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.00759975123917684\n",
      "Training Loss: 0.007091470789164305\n",
      "Training Loss: 0.007492865328676998\n",
      "Training Loss: 0.005651646088226698\n",
      "Training Loss: 0.004268649735022337\n",
      "Training Loss: 0.004210398843279109\n",
      "Training Loss: 0.004186667850590311\n",
      "Validation Loss: 0.012824054618195146\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007589525312650949\n",
      "Training Loss: 0.007082130094058812\n",
      "Training Loss: 0.007483842895599082\n",
      "Training Loss: 0.005644021840998903\n",
      "Training Loss: 0.004263502975227311\n",
      "Training Loss: 0.004205561237758957\n",
      "Training Loss: 0.0041824271978111935\n",
      "Validation Loss: 0.012822351492121676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007579830829054117\n",
      "Training Loss: 0.007073225651402027\n",
      "Training Loss: 0.007475294444011524\n",
      "Training Loss: 0.00563668021117337\n",
      "Training Loss: 0.00425848517625127\n",
      "Training Loss: 0.004200783955748193\n",
      "Training Loss: 0.004178254274884239\n",
      "Validation Loss: 0.012820555924434452\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007570580104365945\n",
      "Training Loss: 0.00706468487274833\n",
      "Training Loss: 0.0074671396426856515\n",
      "Training Loss: 0.005629573062178679\n",
      "Training Loss: 0.004253583433455788\n",
      "Training Loss: 0.0041960589040536435\n",
      "Training Loss: 0.0041741360368905585\n",
      "Validation Loss: 0.012818684917438622\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007561705459374934\n",
      "Training Loss: 0.007056451814714819\n",
      "Training Loss: 0.007459318301407621\n",
      "Training Loss: 0.005622661098022945\n",
      "Training Loss: 0.004248779088375159\n",
      "Training Loss: 0.004191374509828165\n",
      "Training Loss: 0.004170059551252052\n",
      "Validation Loss: 0.012816685821759873\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007553149443119764\n",
      "Training Loss: 0.007048478535143659\n",
      "Training Loss: 0.007451774806249887\n",
      "Training Loss: 0.005615909793996252\n",
      "Training Loss: 0.004244060771306977\n",
      "Training Loss: 0.0041867227881448345\n",
      "Training Loss: 0.004166013152571395\n",
      "Validation Loss: 0.012814517991882417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007544863861985504\n",
      "Training Loss: 0.00704072599299252\n",
      "Training Loss: 0.007444466373417526\n",
      "Training Loss: 0.005609290727879852\n",
      "Training Loss: 0.004239415080519393\n",
      "Training Loss: 0.004182096809963696\n",
      "Training Loss: 0.004161987261613831\n",
      "Validation Loss: 0.01281216893779386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007536808861186728\n",
      "Training Loss: 0.007033162135630846\n",
      "Training Loss: 0.007437354481080547\n",
      "Training Loss: 0.0056027812272077425\n",
      "Training Loss: 0.00423483123537153\n",
      "Training Loss: 0.004177489321446046\n",
      "Training Loss: 0.004157973935361952\n",
      "Validation Loss: 0.012809643185303341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007528950144769624\n",
      "Training Loss: 0.007025757562369108\n",
      "Training Loss: 0.0074304080265574154\n",
      "Training Loss: 0.005596360141644254\n",
      "Training Loss: 0.004230297322501428\n",
      "Training Loss: 0.0041728922247421\n",
      "Training Loss: 0.004153965301811695\n",
      "Validation Loss: 0.012806903558682078\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007521259842906147\n",
      "Training Loss: 0.007018490511691198\n",
      "Training Loss: 0.007423599874600768\n",
      "Training Loss: 0.0055900117341661825\n",
      "Training Loss: 0.004225805537425913\n",
      "Training Loss: 0.004168301383615471\n",
      "Training Loss: 0.004149952855077572\n",
      "Validation Loss: 0.012803985747292442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007513715735403821\n",
      "Training Loss: 0.00701134056202136\n",
      "Training Loss: 0.007416908255545422\n",
      "Training Loss: 0.005583718015113846\n",
      "Training Loss: 0.004221344689722173\n",
      "Training Loss: 0.00416370973107405\n",
      "Training Loss: 0.004145932053215801\n",
      "Validation Loss: 0.012800837997765688\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007506294408813119\n",
      "Training Loss: 0.007004289652686566\n",
      "Training Loss: 0.0074103103647939865\n",
      "Training Loss: 0.005577468050178141\n",
      "Training Loss: 0.004216910244431347\n",
      "Training Loss: 0.004159114774665795\n",
      "Training Loss: 0.004141898273373954\n",
      "Validation Loss: 0.012797499695977663\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007498976475326344\n",
      "Training Loss: 0.006997322917450219\n",
      "Training Loss: 0.007403789698146284\n",
      "Training Loss: 0.0055712492822203785\n",
      "Training Loss: 0.004212490899371915\n",
      "Training Loss: 0.004154507736093365\n",
      "Training Loss: 0.00413784523436334\n",
      "Validation Loss: 0.012793938456668277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007491748742759228\n",
      "Training Loss: 0.006990426320116967\n",
      "Training Loss: 0.007397331219399348\n",
      "Training Loss: 0.005565051625017077\n",
      "Training Loss: 0.004208083063713275\n",
      "Training Loss: 0.004149888557149098\n",
      "Training Loss: 0.004133769768523052\n",
      "Validation Loss: 0.012790167084214895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007484592262189835\n",
      "Training Loss: 0.006983584857080132\n",
      "Training Loss: 0.00739091799245216\n",
      "Training Loss: 0.0055588651826838035\n",
      "Training Loss: 0.004203679116326384\n",
      "Training Loss: 0.004145251273876056\n",
      "Training Loss: 0.004129669580142945\n",
      "Validation Loss: 0.012786196079105139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.00747749418253079\n",
      "Training Loss: 0.006976788492174819\n",
      "Training Loss: 0.007384537016041577\n",
      "Training Loss: 0.005552680553519167\n",
      "Training Loss: 0.0041992764815222475\n",
      "Training Loss: 0.004140594860073179\n",
      "Training Loss: 0.0041255398170324045\n",
      "Validation Loss: 0.01278201937248184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007470442710909992\n",
      "Training Loss: 0.006970024238107726\n",
      "Training Loss: 0.00737817666027695\n",
      "Training Loss: 0.005546490737469867\n",
      "Training Loss: 0.004194866449106485\n",
      "Training Loss: 0.0041359130054479465\n",
      "Training Loss: 0.004121377923875116\n",
      "Validation Loss: 0.012777638032139464\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007463424139423296\n",
      "Training Loss: 0.006963284257799387\n",
      "Training Loss: 0.007371827204478904\n",
      "Training Loss: 0.005540286786854267\n",
      "Training Loss: 0.00419044403010048\n",
      "Training Loss: 0.0041312031086999925\n",
      "Training Loss: 0.004117180072353221\n",
      "Validation Loss: 0.01277307177281656\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007456431046593934\n",
      "Training Loss: 0.006956557468511164\n",
      "Training Loss: 0.007365476069971919\n",
      "Training Loss: 0.0055340618517948316\n",
      "Training Loss: 0.004186006936943158\n",
      "Training Loss: 0.004126461621490307\n",
      "Training Loss: 0.0041129445214755835\n",
      "Validation Loss: 0.012768291430512953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007449448190163821\n",
      "Training Loss: 0.006949833079706877\n",
      "Training Loss: 0.007359113891143351\n",
      "Training Loss: 0.005527809985796921\n",
      "Training Loss: 0.0041815486515406515\n",
      "Training Loss: 0.004121685213176534\n",
      "Training Loss: 0.004108668667613529\n",
      "Validation Loss: 0.012763336198386991\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007442468762164935\n",
      "Training Loss: 0.0069431026699021455\n",
      "Training Loss: 0.0073527300858404485\n",
      "Training Loss: 0.00552152301534079\n",
      "Training Loss: 0.0041770659649046134\n",
      "Training Loss: 0.004116872173617594\n",
      "Training Loss: 0.004104348373948597\n",
      "Validation Loss: 0.012758181801446005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007435483508743346\n",
      "Training Loss: 0.006936359512619675\n",
      "Training Loss: 0.0073463188810274005\n",
      "Training Loss: 0.005515195459593087\n",
      "Training Loss: 0.004172553882235661\n",
      "Training Loss: 0.004112016360159032\n",
      "Training Loss: 0.004099981585750356\n",
      "Validation Loss: 0.012752835937489647\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.0074284817127045245\n",
      "Training Loss: 0.006929594473913312\n",
      "Training Loss: 0.00733987005893141\n",
      "Training Loss: 0.005508820840041153\n",
      "Training Loss: 0.00416800646984484\n",
      "Training Loss: 0.0041071149928029625\n",
      "Training Loss: 0.00409556487808004\n",
      "Validation Loss: 0.012747321858625399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007421457330929115\n",
      "Training Loss: 0.006922798559535295\n",
      "Training Loss: 0.007333375373855233\n",
      "Training Loss: 0.005502391870249994\n",
      "Training Loss: 0.004163419856340624\n",
      "Training Loss: 0.004102164255455136\n",
      "Training Loss: 0.004091095700277947\n",
      "Validation Loss: 0.012741612595303703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.00741439784411341\n",
      "Training Loss: 0.006915963529609144\n",
      "Training Loss: 0.00732682753703557\n",
      "Training Loss: 0.0054959043965209274\n",
      "Training Loss: 0.004158791576628573\n",
      "Training Loss: 0.004097162454854697\n",
      "Training Loss: 0.004086573472595774\n",
      "Validation Loss: 0.0127357343911134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007407296407036483\n",
      "Training Loss: 0.006909079818287864\n",
      "Training Loss: 0.007320217840606347\n",
      "Training Loss: 0.005489351446158253\n",
      "Training Loss: 0.004154116886784322\n",
      "Training Loss: 0.0040921051381155845\n",
      "Training Loss: 0.004081993601284921\n",
      "Validation Loss: 0.012729693171899585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007400142524857074\n",
      "Training Loss: 0.006902139988960698\n",
      "Training Loss: 0.007313536768779158\n",
      "Training Loss: 0.005482726781629026\n",
      "Training Loss: 0.0041493896744214\n",
      "Training Loss: 0.0040869888378074395\n",
      "Training Loss: 0.00407735283661168\n",
      "Validation Loss: 0.012723488623297282\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007392933489754796\n",
      "Training Loss: 0.006895138882100582\n",
      "Training Loss: 0.007306782437954098\n",
      "Training Loss: 0.005476025159587152\n",
      "Training Loss: 0.004144606261397712\n",
      "Training Loss: 0.004081807653419673\n",
      "Training Loss: 0.004072648863657377\n",
      "Validation Loss: 0.012717113607346816\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0073856548860203475\n",
      "Training Loss: 0.006888065920211375\n",
      "Training Loss: 0.007299943076213821\n",
      "Training Loss: 0.005469240170205012\n",
      "Training Loss: 0.004139762133127079\n",
      "Training Loss: 0.004076559249660931\n",
      "Training Loss: 0.004067878319183364\n",
      "Validation Loss: 0.012710592433921853\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007378303168807178\n",
      "Training Loss: 0.006880913979839534\n",
      "Training Loss: 0.007293013550806791\n",
      "Training Loss: 0.005462366210995242\n",
      "Training Loss: 0.004134853354771622\n",
      "Training Loss: 0.004071241864003241\n",
      "Training Loss: 0.004063040117034689\n",
      "Validation Loss: 0.012703924341744671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007370866518467665\n",
      "Training Loss: 0.006873674102826044\n",
      "Training Loss: 0.0072859862830955534\n",
      "Training Loss: 0.005455397925688885\n",
      "Training Loss: 0.004129874111968092\n",
      "Training Loss: 0.00406584921409376\n",
      "Training Loss: 0.004058129657641985\n",
      "Validation Loss: 0.012697119557051065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007363337265560404\n",
      "Training Loss: 0.006866338403197006\n",
      "Training Loss: 0.007278854291653261\n",
      "Training Loss: 0.0054483296175021675\n",
      "Training Loss: 0.004124822505982593\n",
      "Training Loss: 0.004060379903530702\n",
      "Training Loss: 0.004053146441001445\n",
      "Validation Loss: 0.012690166251259518\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.00735570601071231\n",
      "Training Loss: 0.00685889937216416\n",
      "Training Loss: 0.007271610231837258\n",
      "Training Loss: 0.005441154528525658\n",
      "Training Loss: 0.004119690814986825\n",
      "Training Loss: 0.004054828200023622\n",
      "Training Loss: 0.004048085704562254\n",
      "Validation Loss: 0.012683116078327937\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007347967019304633\n",
      "Training Loss: 0.006851348080672324\n",
      "Training Loss: 0.007264249367872253\n",
      "Training Loss: 0.0054338692623423415\n",
      "Training Loss: 0.004114476211252622\n",
      "Training Loss: 0.004049191302619874\n",
      "Training Loss: 0.004042945547844283\n",
      "Validation Loss: 0.012675952912336181\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007340111607918516\n",
      "Training Loss: 0.006843678046716377\n",
      "Training Loss: 0.007256763643817976\n",
      "Training Loss: 0.005426466314238496\n",
      "Training Loss: 0.004109173571923748\n",
      "Training Loss: 0.004043465534341522\n",
      "Training Loss: 0.004037724149529822\n",
      "Validation Loss: 0.012668706474508323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.007332127552945167\n",
      "Training Loss: 0.006835877113044262\n",
      "Training Loss: 0.0072491441341117025\n",
      "Training Loss: 0.005418940069503151\n",
      "Training Loss: 0.004103778789867647\n",
      "Training Loss: 0.004037647661170922\n",
      "Training Loss: 0.004032418616698123\n",
      "Validation Loss: 0.012661349811427268\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007324006936978549\n",
      "Training Loss: 0.006827939685899764\n",
      "Training Loss: 0.00724138724966906\n",
      "Training Loss: 0.005411286516464315\n",
      "Training Loss: 0.004098285216605291\n",
      "Training Loss: 0.004031733110896312\n",
      "Training Loss: 0.0040270259440876545\n",
      "Validation Loss: 0.012653952246019094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007315741981146857\n",
      "Training Loss: 0.0068198542040772735\n",
      "Training Loss: 0.0072334834141656755\n",
      "Training Loss: 0.005403498520608991\n",
      "Training Loss: 0.00409268986841198\n",
      "Training Loss: 0.004025718664051965\n",
      "Training Loss: 0.00402154380979482\n",
      "Validation Loss: 0.012646481938475276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.00730732083087787\n",
      "Training Loss: 0.006811613916652277\n",
      "Training Loss: 0.0072254286450333894\n",
      "Training Loss: 0.005395570833934471\n",
      "Training Loss: 0.004086983674205839\n",
      "Training Loss: 0.004019599459716119\n",
      "Training Loss: 0.004015969617757947\n",
      "Validation Loss: 0.012638973461530322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007298737746896222\n",
      "Training Loss: 0.006803208116907627\n",
      "Training Loss: 0.007217213602270931\n",
      "Training Loss: 0.005387499100179411\n",
      "Training Loss: 0.004081167093245313\n",
      "Training Loss: 0.0040133743383921686\n",
      "Training Loss: 0.0040103028400335465\n",
      "Validation Loss: 0.012631445919505359\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007289976299507544\n",
      "Training Loss: 0.006794626112096012\n",
      "Training Loss: 0.007208829640876502\n",
      "Training Loss: 0.005379274791921489\n",
      "Training Loss: 0.004075232082395814\n",
      "Training Loss: 0.004007036747061647\n",
      "Training Loss: 0.004004538565641269\n",
      "Validation Loss: 0.012623912721527008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007281029580626637\n",
      "Training Loss: 0.006785857477225364\n",
      "Training Loss: 0.007200271873734891\n",
      "Training Loss: 0.005370894051156938\n",
      "Training Loss: 0.00406917241634801\n",
      "Training Loss: 0.004000584221212193\n",
      "Training Loss: 0.003998675637412816\n",
      "Validation Loss: 0.012616380964569775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007271884931251407\n",
      "Training Loss: 0.006776890996843576\n",
      "Training Loss: 0.0071915292867925015\n",
      "Training Loss: 0.00536234857456293\n",
      "Training Loss: 0.004062981808674522\n",
      "Training Loss: 0.0039940109971212225\n",
      "Training Loss: 0.003992712558829226\n",
      "Validation Loss: 0.012608884123488841\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007262528940336779\n",
      "Training Loss: 0.006767714084126055\n",
      "Training Loss: 0.007182591762393713\n",
      "Training Loss: 0.00535363104310818\n",
      "Training Loss: 0.004056654893211089\n",
      "Training Loss: 0.003987312904791906\n",
      "Training Loss: 0.003986642631352879\n",
      "Validation Loss: 0.012601405083923862\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00725295070791617\n",
      "Training Loss: 0.006758314308244735\n",
      "Training Loss: 0.007173449938418344\n",
      "Training Loss: 0.005344734512036666\n",
      "Training Loss: 0.0040501825948013\n",
      "Training Loss: 0.003980482608312741\n",
      "Training Loss: 0.003980462813051418\n",
      "Validation Loss: 0.012593969959967982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.0072431360126938675\n",
      "Training Loss: 0.006748678213916719\n",
      "Training Loss: 0.007164095292100683\n",
      "Training Loss: 0.005335649287444539\n",
      "Training Loss: 0.004043557364493609\n",
      "Training Loss: 0.003973514892277308\n",
      "Training Loss: 0.0039741709479130805\n",
      "Validation Loss: 0.012586605297802679\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007233066410990432\n",
      "Training Loss: 0.006738788578659296\n",
      "Training Loss: 0.007154509318061173\n",
      "Training Loss: 0.005326364840730093\n",
      "Training Loss: 0.004036772003164515\n",
      "Training Loss: 0.003966403842205182\n",
      "Training Loss: 0.003967762226238847\n",
      "Validation Loss: 0.012579315252190505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.007222723601153121\n",
      "Training Loss: 0.0067286252300255\n",
      "Training Loss: 0.007144678861368448\n",
      "Training Loss: 0.00531686961883679\n",
      "Training Loss: 0.004029815348912962\n",
      "Training Loss: 0.003959140296210535\n",
      "Training Loss: 0.003961230429122224\n",
      "Validation Loss: 0.012572102268289231\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007212088863598183\n",
      "Training Loss: 0.006718171149259433\n",
      "Training Loss: 0.0071345872187521305\n",
      "Training Loss: 0.0053071498352801425\n",
      "Training Loss: 0.0040226730046560985\n",
      "Training Loss: 0.003951712216367014\n",
      "Training Loss: 0.003954565984313377\n",
      "Validation Loss: 0.01256495019968613\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007201142304111272\n",
      "Training Loss: 0.00670740298461169\n",
      "Training Loss: 0.00712421307223849\n",
      "Training Loss: 0.005297188887489028\n",
      "Training Loss: 0.00401533339114394\n",
      "Training Loss: 0.003944109769072383\n",
      "Training Loss: 0.003947763178148307\n",
      "Validation Loss: 0.012557877906971377\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007189853659365326\n",
      "Training Loss: 0.006696291057160124\n",
      "Training Loss: 0.007113530929200351\n",
      "Training Loss: 0.005286969657172449\n",
      "Training Loss: 0.0040077837655553596\n",
      "Training Loss: 0.003936322364606895\n",
      "Training Loss: 0.0039408127753995355\n",
      "Validation Loss: 0.012550871302146981\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007178194285370409\n",
      "Training Loss: 0.006684807911515236\n",
      "Training Loss: 0.007102514775469899\n",
      "Training Loss: 0.005276468783267774\n",
      "Training Loss: 0.004000002354150638\n",
      "Training Loss: 0.003928330740309321\n",
      "Training Loss: 0.0039337012951727954\n",
      "Validation Loss: 0.012543931452571397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007166136124869809\n",
      "Training Loss: 0.006672919490374625\n",
      "Training Loss: 0.007091133766807616\n",
      "Training Loss: 0.0052656617044704035\n",
      "Training Loss: 0.003991968316258862\n",
      "Training Loss: 0.003920118800015189\n",
      "Training Loss: 0.003926417202455923\n",
      "Validation Loss: 0.01253704113488117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007153634305577725\n",
      "Training Loss: 0.006660582858603448\n",
      "Training Loss: 0.00707934784819372\n",
      "Training Loss: 0.005254518946749158\n",
      "Training Loss: 0.0039836604020092635\n",
      "Training Loss: 0.0039116660476429385\n",
      "Training Loss: 0.003918944131582975\n",
      "Validation Loss: 0.01253016876782315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007140646984335035\n",
      "Training Loss: 0.006647753750439733\n",
      "Training Loss: 0.007067114892415702\n",
      "Training Loss: 0.005243006548844278\n",
      "Training Loss: 0.003975049561122432\n",
      "Training Loss: 0.003902949162875302\n",
      "Training Loss: 0.003911264174384996\n",
      "Validation Loss: 0.012523313534746037\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007127123961690813\n",
      "Training Loss: 0.006634380037430674\n",
      "Training Loss: 0.0070543853752315045\n",
      "Training Loss: 0.005231086364365183\n",
      "Training Loss: 0.003966103530838154\n",
      "Training Loss: 0.003893940969137475\n",
      "Training Loss: 0.0039033581875264644\n",
      "Validation Loss: 0.0125164538290533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007113003499107436\n",
      "Training Loss: 0.006620398943778127\n",
      "Training Loss: 0.007041100014466792\n",
      "Training Loss: 0.005218711365596391\n",
      "Training Loss: 0.003956786866183393\n",
      "Training Loss: 0.003884612823603675\n",
      "Training Loss: 0.0038952047337079423\n",
      "Validation Loss: 0.01250954234862721\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.007098218166502193\n",
      "Training Loss: 0.006605739482911304\n",
      "Training Loss: 0.007027192029636353\n",
      "Training Loss: 0.0052058328205021095\n",
      "Training Loss: 0.00394706510938704\n",
      "Training Loss: 0.0038749347772682086\n",
      "Training Loss: 0.0038867816096171738\n",
      "Validation Loss: 0.012502588086660379\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007082686360226944\n",
      "Training Loss: 0.0065903201373294\n",
      "Training Loss: 0.007012584360782057\n",
      "Training Loss: 0.005192393235629425\n",
      "Training Loss: 0.003936892043566331\n",
      "Training Loss: 0.0038648702384671196\n",
      "Training Loss: 0.003878061319119297\n",
      "Validation Loss: 0.01249558263508889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.007066328714136034\n",
      "Training Loss: 0.006574059883132577\n",
      "Training Loss: 0.006997199354227632\n",
      "Training Loss: 0.005178331207134761\n",
      "Training Loss: 0.0039262187521671875\n",
      "Training Loss: 0.003854378231917508\n",
      "Training Loss: 0.0038690162647981195\n",
      "Validation Loss: 0.012488502287044284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.007049047730397433\n",
      "Training Loss: 0.0065568583086133\n",
      "Training Loss: 0.006980940506327898\n",
      "Training Loss: 0.005163579263025895\n",
      "Training Loss: 0.003914999007829465\n",
      "Training Loss: 0.0038434246921679005\n",
      "Training Loss: 0.003859622374875471\n",
      "Validation Loss: 0.012481372920736977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.00703073178534396\n",
      "Training Loss: 0.006538605510722845\n",
      "Training Loss: 0.00696370527963154\n",
      "Training Loss: 0.0051480636524502184\n",
      "Training Loss: 0.0039031809044536205\n",
      "Training Loss: 0.0038319668342592195\n",
      "Training Loss: 0.0038498505449388177\n",
      "Validation Loss: 0.012474182799148062\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007011269587092101\n",
      "Training Loss: 0.006519189552636817\n",
      "Training Loss: 0.006945386910811067\n",
      "Training Loss: 0.005131711210706272\n",
      "Training Loss: 0.0038907155877677723\n",
      "Training Loss: 0.0038199686276493595\n",
      "Training Loss: 0.003839678101358004\n",
      "Validation Loss: 0.012467027728163292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006990544182481244\n",
      "Training Loss: 0.006498496231506579\n",
      "Training Loss: 0.006925875543383881\n",
      "Training Loss: 0.005114450845867396\n",
      "Training Loss: 0.0038775581144727764\n",
      "Training Loss: 0.0038073976465966552\n",
      "Training Loss: 0.0038290863577276468\n",
      "Validation Loss: 0.01246000747571347\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00696843441342935\n",
      "Training Loss: 0.006476408383459784\n",
      "Training Loss: 0.006905059978598729\n",
      "Training Loss: 0.005096215302473866\n",
      "Training Loss: 0.0038636790896998717\n",
      "Training Loss: 0.003794231544598006\n",
      "Training Loss: 0.0038180618471233174\n",
      "Validation Loss: 0.012453216529618739\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006944834019523114\n",
      "Training Loss: 0.006452825947781094\n",
      "Training Loss: 0.006882844031788409\n",
      "Training Loss: 0.005076949827489443\n",
      "Training Loss: 0.0038490540604107083\n",
      "Training Loss: 0.0037804564111866058\n",
      "Training Loss: 0.0038065996271325277\n",
      "Validation Loss: 0.01244681567339094\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0069196504063438625\n",
      "Training Loss: 0.006427666281815618\n",
      "Training Loss: 0.006859144989866763\n",
      "Training Loss: 0.005056618641829118\n",
      "Training Loss: 0.003833684329292737\n",
      "Training Loss: 0.003766070943675004\n",
      "Training Loss: 0.003794698945712298\n",
      "Validation Loss: 0.012441013762657618\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006892827309202403\n",
      "Training Loss: 0.006400881221634336\n",
      "Training Loss: 0.006833910763962194\n",
      "Training Loss: 0.00503521129663568\n",
      "Training Loss: 0.003817593321437016\n",
      "Training Loss: 0.0037510937883052974\n",
      "Training Loss: 0.003782371373963542\n",
      "Validation Loss: 0.012435962681480672\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006864346435759216\n",
      "Training Loss: 0.00637247214326635\n",
      "Training Loss: 0.006807132979156449\n",
      "Training Loss: 0.005012752554612234\n",
      "Training Loss: 0.0038008287461707368\n",
      "Training Loss: 0.003735556020983495\n",
      "Training Loss: 0.0037696325400611384\n",
      "Validation Loss: 0.01243182650918999\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.0068342451960779725\n",
      "Training Loss: 0.00634248650923837\n",
      "Training Loss: 0.006778843827778474\n",
      "Training Loss: 0.004989300458692014\n",
      "Training Loss: 0.0037834695732453837\n",
      "Training Loss: 0.003719507469795644\n",
      "Training Loss: 0.003756501849857159\n",
      "Validation Loss: 0.012428714499167038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006802621529204771\n",
      "Training Loss: 0.006311043557943776\n",
      "Training Loss: 0.006749137728475034\n",
      "Training Loss: 0.004964954119641334\n",
      "Training Loss: 0.0037656120280735194\n",
      "Training Loss: 0.003703007543226704\n",
      "Training Loss: 0.0037430004175985233\n",
      "Validation Loss: 0.012426647344562277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006769634198863059\n",
      "Training Loss: 0.006278314923401922\n",
      "Training Loss: 0.006718154877889901\n",
      "Training Loss: 0.004939844920299947\n",
      "Training Loss: 0.0037473704968579115\n",
      "Training Loss: 0.003686122201033868\n",
      "Training Loss: 0.003729147835401818\n",
      "Validation Loss: 0.012425501175549174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006735496397595853\n",
      "Training Loss: 0.006244533011340536\n",
      "Training Loss: 0.006686091324081644\n",
      "Training Loss: 0.004914135553990491\n",
      "Training Loss: 0.0037288638431346045\n",
      "Training Loss: 0.0036689183709677307\n",
      "Training Loss: 0.0037149645161116494\n",
      "Validation Loss: 0.012425037092190892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006700465554604307\n",
      "Training Loss: 0.006209966916358099\n",
      "Training Loss: 0.006653178966371342\n",
      "Training Loss: 0.004888007834088057\n",
      "Training Loss: 0.0037102133920416235\n",
      "Training Loss: 0.0036514599109068514\n",
      "Training Loss: 0.003700468080351129\n",
      "Validation Loss: 0.012424968731108257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006664828220382332\n",
      "Training Loss: 0.006174910948029719\n",
      "Training Loss: 0.006619671672815457\n",
      "Training Loss: 0.004861659854068421\n",
      "Training Loss: 0.003691531749209389\n",
      "Training Loss: 0.003633812026819214\n",
      "Training Loss: 0.0036856854305369778\n",
      "Validation Loss: 0.01242487529059\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006628883302910254\n",
      "Training Loss: 0.0061396695568691935\n",
      "Training Loss: 0.006585838859900832\n",
      "Training Loss: 0.004835290867486037\n",
      "Training Loss: 0.003672928232699633\n",
      "Training Loss: 0.0036160358763299883\n",
      "Training Loss: 0.0036706508049974217\n",
      "Validation Loss: 0.01242431213212468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006592934158979915\n",
      "Training Loss: 0.006104543395922519\n",
      "Training Loss: 0.006551950707798824\n",
      "Training Loss: 0.004809101435239427\n",
      "Training Loss: 0.003654498272226192\n",
      "Training Loss: 0.0035981935635209083\n",
      "Training Loss: 0.0036554104764945803\n",
      "Validation Loss: 0.0124228330274995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.00655726584198419\n",
      "Training Loss: 0.0060698123881593345\n",
      "Training Loss: 0.006518266425700858\n",
      "Training Loss: 0.00478328830038663\n",
      "Training Loss: 0.0036363384273136036\n",
      "Training Loss: 0.003580351521377452\n",
      "Training Loss: 0.003640024606138468\n",
      "Validation Loss: 0.012420118342097919\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.0065221552329603584\n",
      "Training Loss: 0.006035739404615015\n",
      "Training Loss: 0.006485025387955829\n",
      "Training Loss: 0.004758033715188503\n",
      "Training Loss: 0.003618533647968434\n",
      "Training Loss: 0.003562579379067756\n",
      "Training Loss: 0.0036245634144870566\n",
      "Validation Loss: 0.012415759040440401\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.0064878509612753986\n",
      "Training Loss: 0.006002552204881795\n",
      "Training Loss: 0.006452447454212234\n",
      "Training Loss: 0.004733506366610527\n",
      "Training Loss: 0.0036011688748840242\n",
      "Training Loss: 0.0035449504433199765\n",
      "Training Loss: 0.0036091041809413584\n",
      "Validation Loss: 0.012409550546361517\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006454572897055187\n",
      "Training Loss: 0.005970445171697065\n",
      "Training Loss: 0.006420721205649897\n",
      "Training Loss: 0.004709853507811204\n",
      "Training Loss: 0.0035843128350097684\n",
      "Training Loss: 0.0035275344055844472\n",
      "Training Loss: 0.0035937280097277837\n",
      "Validation Loss: 0.012401274464281506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006422514166333712\n",
      "Training Loss: 0.005939580649719573\n",
      "Training Loss: 0.006390012158080935\n",
      "Training Loss: 0.004687200103071518\n",
      "Training Loss: 0.003568033304181881\n",
      "Training Loss: 0.00351041023270227\n",
      "Training Loss: 0.0035785177763318645\n",
      "Validation Loss: 0.01239091936413422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.0063918362488038834\n",
      "Training Loss: 0.005910083282506093\n",
      "Training Loss: 0.0063604521541856225\n",
      "Training Loss: 0.0046656429168069734\n",
      "Training Loss: 0.003552386313676834\n",
      "Training Loss: 0.0034936540288617833\n",
      "Training Loss: 0.0035635559872025623\n",
      "Validation Loss: 0.012378487946144707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.0063626585341989995\n",
      "Training Loss: 0.0058820394554641095\n",
      "Training Loss: 0.006332144517218694\n",
      "Training Loss: 0.004645246501313522\n",
      "Training Loss: 0.003537411952856928\n",
      "Training Loss: 0.0034773331333417448\n",
      "Training Loss: 0.0035489095939556137\n",
      "Validation Loss: 0.01236414664323801\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006335069370106794\n",
      "Training Loss: 0.005855504045612179\n",
      "Training Loss: 0.006305167836835608\n",
      "Training Loss: 0.004626044044853188\n",
      "Training Loss: 0.0035231330565875397\n",
      "Training Loss: 0.003461511888890527\n",
      "Training Loss: 0.0035346467740600927\n",
      "Validation Loss: 0.01234810621074788\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006309114856412635\n",
      "Training Loss: 0.005830491293454543\n",
      "Training Loss: 0.006279564240248874\n",
      "Training Loss: 0.004608039654558524\n",
      "Training Loss: 0.003509567861328833\n",
      "Training Loss: 0.003446252169669606\n",
      "Training Loss: 0.0035208243393572048\n",
      "Validation Loss: 0.012330639871510535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006284797977423295\n",
      "Training Loss: 0.005806982590002008\n",
      "Training Loss: 0.006255344888195395\n",
      "Training Loss: 0.004591203078161925\n",
      "Training Loss: 0.0034967147035058588\n",
      "Training Loss: 0.0034316021436825396\n",
      "Training Loss: 0.00350748787925113\n",
      "Validation Loss: 0.01231208009373271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006262080998858437\n",
      "Training Loss: 0.0057849288295255975\n",
      "Training Loss: 0.006232494215946644\n",
      "Training Loss: 0.004575479677296244\n",
      "Training Loss: 0.0034845586778828874\n",
      "Training Loss: 0.0034175949572818353\n",
      "Training Loss: 0.0034946695709368214\n",
      "Validation Loss: 0.0122927661251786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.0062408939312445\n",
      "Training Loss: 0.0057642531167948615\n",
      "Training Loss: 0.006210962503682822\n",
      "Training Loss: 0.004560795763973146\n",
      "Training Loss: 0.003473082092241384\n",
      "Training Loss: 0.0034042601427063347\n",
      "Training Loss: 0.0034823919279733675\n",
      "Validation Loss: 0.012273014666973038\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0062211344519164415\n",
      "Training Loss: 0.005744859601836651\n",
      "Training Loss: 0.006190680883591994\n",
      "Training Loss: 0.0045470630656927824\n",
      "Training Loss: 0.003462255034246482\n",
      "Training Loss: 0.0033916030498221516\n",
      "Training Loss: 0.0034706640557851643\n",
      "Validation Loss: 0.012253068937320082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0062026823731139305\n",
      "Training Loss: 0.005726641406072304\n",
      "Training Loss: 0.006171563891693949\n",
      "Training Loss: 0.0045341853599529715\n",
      "Training Loss: 0.003452040241099894\n",
      "Training Loss: 0.003379617964383215\n",
      "Training Loss: 0.0034594816289609297\n",
      "Validation Loss: 0.012233181071750233\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006185404863208533\n",
      "Training Loss: 0.005709480932564475\n",
      "Training Loss: 0.00615351882763207\n",
      "Training Loss: 0.004522069383529015\n",
      "Training Loss: 0.003442398497718386\n",
      "Training Loss: 0.0033682884916197506\n",
      "Training Loss: 0.003448831515852362\n",
      "Validation Loss: 0.012213520736656804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006169168608030304\n",
      "Training Loss: 0.005693266264279373\n",
      "Training Loss: 0.00613644766388461\n",
      "Training Loss: 0.004510622107191011\n",
      "Training Loss: 0.0034332884912146255\n",
      "Training Loss: 0.0033575854747323317\n",
      "Training Loss: 0.0034386928007006643\n",
      "Validation Loss: 0.012194265670767437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006153844262007624\n",
      "Training Loss: 0.00567788842425216\n",
      "Training Loss: 0.006120256471913308\n",
      "Training Loss: 0.004499759704340249\n",
      "Training Loss: 0.00342466659611091\n",
      "Training Loss: 0.0033474756253417583\n",
      "Training Loss: 0.003429038378526457\n",
      "Validation Loss: 0.012175448198736494\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006139312653103844\n",
      "Training Loss: 0.005663246543263085\n",
      "Training Loss: 0.006104854127625003\n",
      "Training Loss: 0.004489405549247749\n",
      "Training Loss: 0.0034164919226896016\n",
      "Training Loss: 0.003337921074416954\n",
      "Training Loss: 0.0034198394371196626\n",
      "Validation Loss: 0.012157181356789384\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006125459972536191\n",
      "Training Loss: 0.005649246925022453\n",
      "Training Loss: 0.006090157217113301\n",
      "Training Loss: 0.00447949055058416\n",
      "Training Loss: 0.0034087209909921513\n",
      "Training Loss: 0.003328878219181206\n",
      "Training Loss: 0.00341106227831915\n",
      "Validation Loss: 0.012139449161146017\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006112191739957779\n",
      "Training Loss: 0.005635810947278514\n",
      "Training Loss: 0.006076087381225079\n",
      "Training Loss: 0.004469954977976158\n",
      "Training Loss: 0.003401317252428271\n",
      "Training Loss: 0.0033203056221827866\n",
      "Training Loss: 0.0034026758786058053\n",
      "Validation Loss: 0.012122328493444159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006099417235236615\n",
      "Training Loss: 0.0056228642881615085\n",
      "Training Loss: 0.006062573053641245\n",
      "Training Loss: 0.004460746722179465\n",
      "Training Loss: 0.0033942405570996925\n",
      "Training Loss: 0.0033121646125800906\n",
      "Training Loss: 0.0033946505398489537\n",
      "Validation Loss: 0.01210575963262371\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006087059818673879\n",
      "Training Loss: 0.005610341687570326\n",
      "Training Loss: 0.0060495458671357485\n",
      "Training Loss: 0.004451819875393994\n",
      "Training Loss: 0.003387461531674489\n",
      "Training Loss: 0.0033044188714120536\n",
      "Training Loss: 0.003386955435271375\n",
      "Validation Loss: 0.012089717352748866\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00607505259802565\n",
      "Training Loss: 0.0055981865955982354\n",
      "Training Loss: 0.006036948504624888\n",
      "Training Loss: 0.00444313368818257\n",
      "Training Loss: 0.0033809479133924468\n",
      "Training Loss: 0.003297034388233442\n",
      "Training Loss: 0.003379567149677314\n",
      "Validation Loss: 0.012074221370302224\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006063334306818433\n",
      "Training Loss: 0.005586348595679738\n",
      "Training Loss: 0.006024721621070057\n",
      "Training Loss: 0.004434654855867848\n",
      "Training Loss: 0.003374677678802982\n",
      "Training Loss: 0.003289981701527722\n",
      "Training Loss: 0.003372462285333313\n",
      "Validation Loss: 0.01205923390393372\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006051847491180524\n",
      "Training Loss: 0.005574777816073038\n",
      "Training Loss: 0.0060128132131649185\n",
      "Training Loss: 0.004426353816525079\n",
      "Training Loss: 0.0033686285617295655\n",
      "Training Loss: 0.00328323964640731\n",
      "Training Loss: 0.0033656215597875415\n",
      "Validation Loss: 0.012044712612039168\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006040549633908086\n",
      "Training Loss: 0.00556343802891206\n",
      "Training Loss: 0.006001176139689051\n",
      "Training Loss: 0.00441820366308093\n",
      "Training Loss: 0.0033627813257044183\n",
      "Training Loss: 0.003276785059424583\n",
      "Training Loss: 0.003359029198763892\n",
      "Validation Loss: 0.012030700197241057\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006029394908691757\n",
      "Training Loss: 0.005552288471371867\n",
      "Training Loss: 0.0059897615830414\n",
      "Training Loss: 0.00441018141573295\n",
      "Training Loss: 0.0033571230963571\n",
      "Training Loss: 0.0032706004843930715\n",
      "Training Loss: 0.0033526692120358346\n",
      "Validation Loss: 0.012017145612510794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.0060183426301227885\n",
      "Training Loss: 0.005541294516879134\n",
      "Training Loss: 0.005978529192507267\n",
      "Training Loss: 0.004402264124946669\n",
      "Training Loss: 0.0033516345586394893\n",
      "Training Loss: 0.003264664442976937\n",
      "Training Loss: 0.003346526062232442\n",
      "Validation Loss: 0.012004020535352218\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006007363641401753\n",
      "Training Loss: 0.005530426949844696\n",
      "Training Loss: 0.005967438092338853\n",
      "Training Loss: 0.004394434140995145\n",
      "Training Loss: 0.003346311598434113\n",
      "Training Loss: 0.003258973655465525\n",
      "Training Loss: 0.003340593909379095\n",
      "Validation Loss: 0.011991358812975136\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.005996416108100675\n",
      "Training Loss: 0.005519651421927847\n",
      "Training Loss: 0.005956447690841742\n",
      "Training Loss: 0.004386671585962176\n",
      "Training Loss: 0.0033411414112197234\n",
      "Training Loss: 0.003253513754461892\n",
      "Training Loss: 0.0033348618366289885\n",
      "Validation Loss: 0.011979109951214732\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005985473564942367\n",
      "Training Loss: 0.005508939609280787\n",
      "Training Loss: 0.005945520804380067\n",
      "Training Loss: 0.0043789612303953614\n",
      "Training Loss: 0.0033361192600568756\n",
      "Training Loss: 0.003248276427621022\n",
      "Training Loss: 0.003329322683857754\n",
      "Validation Loss: 0.0119673198770055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005974504479090683\n",
      "Training Loss: 0.0054982621344970535\n",
      "Training Loss: 0.0059346199280116705\n",
      "Training Loss: 0.004371284353546798\n",
      "Training Loss: 0.0033312398038106037\n",
      "Training Loss: 0.0032432597666047515\n",
      "Training Loss: 0.0033239730872446673\n",
      "Validation Loss: 0.011955965166887066\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0059634788357652724\n",
      "Training Loss: 0.005487589582335204\n",
      "Training Loss: 0.005923707945039496\n",
      "Training Loss: 0.004363629958243109\n",
      "Training Loss: 0.0033265059906989335\n",
      "Training Loss: 0.0032384630758315325\n",
      "Training Loss: 0.00331881208170671\n",
      "Validation Loss: 0.011945079808901256\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.005952369099250063\n",
      "Training Loss: 0.0054768952348968015\n",
      "Training Loss: 0.00591275374754332\n",
      "Training Loss: 0.0043559830507729205\n",
      "Training Loss: 0.0033219117199769243\n",
      "Training Loss: 0.0032338814035756513\n",
      "Training Loss: 0.003313832116546109\n",
      "Validation Loss: 0.011934636734523689\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005941156432963907\n",
      "Training Loss: 0.005466156431939453\n",
      "Training Loss: 0.0059017249790485945\n",
      "Training Loss: 0.004348328678170219\n",
      "Training Loss: 0.0033174562273779883\n",
      "Training Loss: 0.0032295143191004173\n",
      "Training Loss: 0.003309033230179921\n",
      "Validation Loss: 0.011924668039938205\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.005929813350085169\n",
      "Training Loss: 0.005455343934590929\n",
      "Training Loss: 0.0058905916381627324\n",
      "Training Loss: 0.004340656928252429\n",
      "Training Loss: 0.0033131433726521207\n",
      "Training Loss: 0.003225366186816245\n",
      "Training Loss: 0.003304414854501374\n",
      "Validation Loss: 0.011915167408632568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.0059183239727281034\n",
      "Training Loss: 0.005444438214180991\n",
      "Training Loss: 0.00587932908849325\n",
      "Training Loss: 0.004332957675214857\n",
      "Training Loss: 0.0033089741558069365\n",
      "Training Loss: 0.0032214378978824244\n",
      "Training Loss: 0.003299977852148004\n",
      "Validation Loss: 0.011906119996563214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005906669064424932\n",
      "Training Loss: 0.005433419488254003\n",
      "Training Loss: 0.005867915393901057\n",
      "Training Loss: 0.004325221806648187\n",
      "Training Loss: 0.00330494899477344\n",
      "Training Loss: 0.003217730140022468\n",
      "Training Loss: 0.0032957200991222636\n",
      "Validation Loss: 0.011897522021322215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005894843189162202\n",
      "Training Loss: 0.005422274894081056\n",
      "Training Loss: 0.005856336244032718\n",
      "Training Loss: 0.004317446682252921\n",
      "Training Loss: 0.003301071481546387\n",
      "Training Loss: 0.0032142470771213995\n",
      "Training Loss: 0.0032916411315090954\n",
      "Validation Loss: 0.011889349261110418\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005882846493041143\n",
      "Training Loss: 0.005410998002043925\n",
      "Training Loss: 0.005844586764578707\n",
      "Training Loss: 0.004309632015647367\n",
      "Training Loss: 0.003297344105085358\n",
      "Training Loss: 0.0032109915043110958\n",
      "Training Loss: 0.003287743108230643\n",
      "Validation Loss: 0.011881580320361318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005870678803185001\n",
      "Training Loss: 0.005399585837731138\n",
      "Training Loss: 0.005832674233242869\n",
      "Training Loss: 0.004301783100818284\n",
      "Training Loss: 0.0032937655033310875\n",
      "Training Loss: 0.003207959489081986\n",
      "Training Loss: 0.0032840197888435794\n",
      "Validation Loss: 0.01187413364338378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.00585837105056271\n",
      "Training Loss: 0.005388055906514637\n",
      "Training Loss: 0.005820618197903968\n",
      "Training Loss: 0.004293911416316405\n",
      "Training Loss: 0.003290335602359846\n",
      "Training Loss: 0.003205149238347076\n",
      "Training Loss: 0.0032804717231192625\n",
      "Validation Loss: 0.01186696943009014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.005845950074144639\n",
      "Training Loss: 0.005376433319761418\n",
      "Training Loss: 0.005808457190869376\n",
      "Training Loss: 0.0042860360204940665\n",
      "Training Loss: 0.003287051127990708\n",
      "Training Loss: 0.003202556395845022\n",
      "Training Loss: 0.0032770954165607692\n",
      "Validation Loss: 0.011859965322745008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005833462099544704\n",
      "Training Loss: 0.005364753609173931\n",
      "Training Loss: 0.0057962397037772465\n",
      "Training Loss: 0.004278180802357383\n",
      "Training Loss: 0.0032839033578056843\n",
      "Training Loss: 0.0032001683363341725\n",
      "Training Loss: 0.0032738806700217536\n",
      "Validation Loss: 0.011853013029810362\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005820972211076878\n",
      "Training Loss: 0.00535307316982653\n",
      "Training Loss: 0.005784038957208395\n",
      "Training Loss: 0.004270380518282764\n",
      "Training Loss: 0.0032808843802195043\n",
      "Training Loss: 0.003197969516913872\n",
      "Training Loss: 0.003270822023041546\n",
      "Validation Loss: 0.011846005938396081\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.005808551276568323\n",
      "Training Loss: 0.005341456890455447\n",
      "Training Loss: 0.005771934631047771\n",
      "Training Loss: 0.004262671603937633\n",
      "Training Loss: 0.0032779804954770953\n",
      "Training Loss: 0.003195941972953733\n",
      "Training Loss: 0.0032679096050560476\n",
      "Validation Loss: 0.011838767862850834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.005796280466602184\n",
      "Training Loss: 0.005329978752415627\n",
      "Training Loss: 0.005760019111912698\n",
      "Training Loss: 0.004255094609106891\n",
      "Training Loss: 0.0032751768018351867\n",
      "Training Loss: 0.003194058875669725\n",
      "Training Loss: 0.003265130163927097\n",
      "Validation Loss: 0.011831192750996502\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.005784247743431479\n",
      "Training Loss: 0.005318719411152415\n",
      "Training Loss: 0.005748387196217663\n",
      "Training Loss: 0.004247692700009793\n",
      "Training Loss: 0.0032724528008839116\n",
      "Training Loss: 0.003192293617175892\n",
      "Training Loss: 0.003262472597998567\n",
      "Validation Loss: 0.011823163545264928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005772537006996572\n",
      "Training Loss: 0.005307756207184866\n",
      "Training Loss: 0.005737126325257123\n",
      "Training Loss: 0.004240504035260528\n",
      "Training Loss: 0.003269795997766778\n",
      "Training Loss: 0.0031906214938499035\n",
      "Training Loss: 0.003259924923768267\n",
      "Validation Loss: 0.011814561563941619\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0057612202950986105\n",
      "Training Loss: 0.005297161023481749\n",
      "Training Loss: 0.005726317463559099\n",
      "Training Loss: 0.0042335636087227615\n",
      "Training Loss: 0.0032671809429302813\n",
      "Training Loss: 0.0031890074943657963\n",
      "Training Loss: 0.0032574683803250084\n",
      "Validation Loss: 0.011805307990801608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.0057503683096729215\n",
      "Training Loss: 0.005286998370429501\n",
      "Training Loss: 0.005716025730944239\n",
      "Training Loss: 0.004226899560890161\n",
      "Training Loss: 0.0032645938044879586\n",
      "Training Loss: 0.0031874272588174792\n",
      "Training Loss: 0.003255095517379232\n",
      "Validation Loss: 0.01179541852708892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005740020865923725\n",
      "Training Loss: 0.00527731282345485\n",
      "Training Loss: 0.0057062934950226915\n",
      "Training Loss: 0.004220530056627468\n",
      "Training Loss: 0.003262018560199067\n",
      "Training Loss: 0.0031858531100442634\n",
      "Training Loss: 0.003252787100500427\n",
      "Validation Loss: 0.011784872703327473\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005730217362288386\n",
      "Training Loss: 0.005268138321698643\n",
      "Training Loss: 0.0056971476983744655\n",
      "Training Loss: 0.0042144669449771755\n",
      "Training Loss: 0.0032594424311537295\n",
      "Training Loss: 0.003184264281007927\n",
      "Training Loss: 0.003250534599937964\n",
      "Validation Loss: 0.011773727152301242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005720970464171842\n",
      "Training Loss: 0.005259488961310126\n",
      "Training Loss: 0.005688593378290534\n",
      "Training Loss: 0.004208714111882728\n",
      "Training Loss: 0.003256860171095468\n",
      "Training Loss: 0.0031826472206739707\n",
      "Training Loss: 0.003248326613684185\n",
      "Validation Loss: 0.011762010754602316\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005712279547005892\n",
      "Training Loss: 0.005251368749304675\n",
      "Training Loss: 0.005680621832725592\n",
      "Training Loss: 0.004203267198172398\n",
      "Training Loss: 0.003254262693808414\n",
      "Training Loss: 0.0031809881870867684\n",
      "Training Loss: 0.0032461537976632825\n",
      "Validation Loss: 0.011749864561345484\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005704130639205687\n",
      "Training Loss: 0.005243763179169037\n",
      "Training Loss: 0.00567320978618227\n",
      "Training Loss: 0.004198114484315738\n",
      "Training Loss: 0.003251647585420869\n",
      "Training Loss: 0.0031792783600394616\n",
      "Training Loss: 0.0032440093689365315\n",
      "Validation Loss: 0.011737342814004488\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005696503763902001\n",
      "Training Loss: 0.005236655613989569\n",
      "Training Loss: 0.005666324884514324\n",
      "Training Loss: 0.004193245421629399\n",
      "Training Loss: 0.003249019019422121\n",
      "Training Loss: 0.0031775167089654133\n",
      "Training Loss: 0.003241887697658967\n",
      "Validation Loss: 0.011724556979813965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.00568936626019422\n",
      "Training Loss: 0.005230018645524978\n",
      "Training Loss: 0.005659929932444356\n",
      "Training Loss: 0.0041886422329116615\n",
      "Training Loss: 0.0032463766762521116\n",
      "Training Loss: 0.0031757022097008304\n",
      "Training Loss: 0.0032397875149035825\n",
      "Validation Loss: 0.011711610861781858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.00568268371920567\n",
      "Training Loss: 0.0052238172595389185\n",
      "Training Loss: 0.005653982067015022\n",
      "Training Loss: 0.0041842862032353875\n",
      "Training Loss: 0.003243725331267342\n",
      "Training Loss: 0.0031738392187980937\n",
      "Training Loss: 0.003237705052597448\n",
      "Validation Loss: 0.011698580596618675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005676419866504147\n",
      "Training Loss: 0.005218018039013259\n",
      "Training Loss: 0.005648438810603693\n",
      "Training Loss: 0.004180160233518109\n",
      "Training Loss: 0.003241071511874907\n",
      "Training Loss: 0.003171930781682022\n",
      "Training Loss: 0.0032356382871512324\n",
      "Validation Loss: 0.01168552189755815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005670542026637122\n",
      "Training Loss: 0.005212589859147556\n",
      "Training Loss: 0.005643260824726894\n",
      "Training Loss: 0.004176244759582915\n",
      "Training Loss: 0.003238419060362503\n",
      "Training Loss: 0.0031699857753119433\n",
      "Training Loss: 0.003233591430762317\n",
      "Validation Loss: 0.011672535295334857\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005665005627670325\n",
      "Training Loss: 0.0052074941870523615\n",
      "Training Loss: 0.005638407511869445\n",
      "Training Loss: 0.004172521840955596\n",
      "Training Loss: 0.0032357758347643538\n",
      "Training Loss: 0.0031680078958743253\n",
      "Training Loss: 0.0032315608850331046\n",
      "Validation Loss: 0.011659675270793366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005659782789298334\n",
      "Training Loss: 0.005202701059752144\n",
      "Training Loss: 0.005633842280367389\n",
      "Training Loss: 0.004168974776112009\n",
      "Training Loss: 0.0032331454451195894\n",
      "Training Loss: 0.0031660067511256784\n",
      "Training Loss: 0.003229549410752952\n",
      "Validation Loss: 0.011646952086140503\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.00565483957005199\n",
      "Training Loss: 0.005198176709236577\n",
      "Training Loss: 0.005629530661390163\n",
      "Training Loss: 0.0041655892072594725\n",
      "Training Loss: 0.003230538437492214\n",
      "Training Loss: 0.0031639939558226614\n",
      "Training Loss: 0.0032275613144156523\n",
      "Validation Loss: 0.011634429071747353\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.00565014302090276\n",
      "Training Loss: 0.005193894192925655\n",
      "Training Loss: 0.005625442666350864\n",
      "Training Loss: 0.004162349164253101\n",
      "Training Loss: 0.0032279565633507447\n",
      "Training Loss: 0.0031619720210437664\n",
      "Training Loss: 0.003225597251439467\n",
      "Validation Loss: 0.011622128421301196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005645668536890298\n",
      "Training Loss: 0.005189824858098291\n",
      "Training Loss: 0.005621550154755823\n",
      "Training Loss: 0.004159242714522406\n",
      "Training Loss: 0.0032254048791946844\n",
      "Training Loss: 0.003159949250984937\n",
      "Training Loss: 0.0032236564671620726\n",
      "Validation Loss: 0.011610064477213284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005641391733661294\n",
      "Training Loss: 0.0051859479810809715\n",
      "Training Loss: 0.005617828757385724\n",
      "Training Loss: 0.004156258163857274\n",
      "Training Loss: 0.0032228879793547095\n",
      "Training Loss: 0.003157934510963969\n",
      "Training Loss: 0.003221743393805809\n",
      "Validation Loss: 0.011598225793503015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005637290690792725\n",
      "Training Loss: 0.005182242990704253\n",
      "Training Loss: 0.005614258070709184\n",
      "Training Loss: 0.004153386236575898\n",
      "Training Loss: 0.003220410655485466\n",
      "Training Loss: 0.0031559314092737623\n",
      "Training Loss: 0.003219861035468057\n",
      "Validation Loss: 0.01158666026809912\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005633345766691491\n",
      "Training Loss: 0.005178687358857133\n",
      "Training Loss: 0.005610819596331567\n",
      "Training Loss: 0.004150617143022828\n",
      "Training Loss: 0.0032179721450665967\n",
      "Training Loss: 0.0031539443047950044\n",
      "Training Loss: 0.003218007432005834\n",
      "Validation Loss: 0.011575337686211443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005629541535163298\n",
      "Training Loss: 0.005175268091843464\n",
      "Training Loss: 0.005607496883603744\n",
      "Training Loss: 0.004147941724222619\n",
      "Training Loss: 0.0032155780552420767\n",
      "Training Loss: 0.0031519793975166976\n",
      "Training Loss: 0.0032161860133055596\n",
      "Validation Loss: 0.011564280790684934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.0056258593138773\n",
      "Training Loss: 0.005171966018388048\n",
      "Training Loss: 0.005604273272911087\n",
      "Training Loss: 0.004145353393105324\n",
      "Training Loss: 0.003213228948879987\n",
      "Training Loss: 0.0031500392642919905\n",
      "Training Loss: 0.0032143963771522977\n",
      "Validation Loss: 0.011553481220109005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005622289102175273\n",
      "Training Loss: 0.005168771336320788\n",
      "Training Loss: 0.005601137631456368\n",
      "Training Loss: 0.004142847056209575\n",
      "Training Loss: 0.003210927238105796\n",
      "Training Loss: 0.0031481287837959826\n",
      "Training Loss: 0.0032126405322924255\n",
      "Validation Loss: 0.01154293876606971\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.005618816716014408\n",
      "Training Loss: 0.005165671319118701\n",
      "Training Loss: 0.0055980819469550625\n",
      "Training Loss: 0.0041404158133082096\n",
      "Training Loss: 0.0032086717122001575\n",
      "Training Loss: 0.00314624791033566\n",
      "Training Loss: 0.0032109175727237016\n",
      "Validation Loss: 0.01153265274097543\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005615432598278858\n",
      "Training Loss: 0.0051626548817148435\n",
      "Training Loss: 0.0055950929567916315\n",
      "Training Loss: 0.004138053334318101\n",
      "Training Loss: 0.0032064607058418914\n",
      "Training Loss: 0.0031443982417113147\n",
      "Training Loss: 0.003209227910556365\n",
      "Validation Loss: 0.011522585440650303\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005612131877569482\n",
      "Training Loss: 0.0051597167522413655\n",
      "Training Loss: 0.005592166693531908\n",
      "Training Loss: 0.004135756371542811\n",
      "Training Loss: 0.0032043007656466214\n",
      "Training Loss: 0.0031425851932726802\n",
      "Training Loss: 0.0032075736750266514\n",
      "Validation Loss: 0.011512776881880179\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005608900295919738\n",
      "Training Loss: 0.005156845093588345\n",
      "Training Loss: 0.005589293366065249\n",
      "Training Loss: 0.0041335197945591064\n",
      "Training Loss: 0.0032021846785210075\n",
      "Training Loss: 0.0031408016994828357\n",
      "Training Loss: 0.003205948378308676\n",
      "Validation Loss: 0.011503189319504028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005605738523299806\n",
      "Training Loss: 0.005154037036700174\n",
      "Training Loss: 0.005586469834088348\n",
      "Training Loss: 0.004131341693282593\n",
      "Training Loss: 0.003200115224462934\n",
      "Training Loss: 0.0031390539958374574\n",
      "Training Loss: 0.0032043566307402216\n",
      "Validation Loss: 0.011493806510532365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005602635171962902\n",
      "Training Loss: 0.0051512847939739\n",
      "Training Loss: 0.005583689359482378\n",
      "Training Loss: 0.004129215965222101\n",
      "Training Loss: 0.003198090099613182\n",
      "Training Loss: 0.0031373407630599106\n",
      "Training Loss: 0.0032027948947506955\n",
      "Validation Loss: 0.011484632275960223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005599589127814397\n",
      "Training Loss: 0.0051485836948268115\n",
      "Training Loss: 0.005580948318820447\n",
      "Training Loss: 0.004127141097269487\n",
      "Training Loss: 0.0031961078429594636\n",
      "Training Loss: 0.0031356588791823015\n",
      "Training Loss: 0.0032012630318058654\n",
      "Validation Loss: 0.011475670844890274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005596594981034287\n",
      "Training Loss: 0.005145931037841365\n",
      "Training Loss: 0.0055782433686545115\n",
      "Training Loss: 0.0041251133487094195\n",
      "Training Loss: 0.0031941691390238703\n",
      "Training Loss: 0.003134012451337185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [12:56<24:52, 248.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0031997621088521557\n",
      "Validation Loss: 0.011466905486217111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.17311797253787517\n",
      "Training Loss: 0.13964952394366265\n",
      "Training Loss: 0.11089332561939955\n",
      "Training Loss: 0.08886632207781077\n",
      "Training Loss: 0.07336717268452048\n",
      "Training Loss: 0.06375563632696866\n",
      "Training Loss: 0.059895531255751845\n",
      "Validation Loss: 0.06073834735914116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.0595851731300354\n",
      "Training Loss: 0.05538221448659897\n",
      "Training Loss: 0.05190549080260098\n",
      "Training Loss: 0.0470245804823935\n",
      "Training Loss: 0.04093437248840928\n",
      "Training Loss: 0.03672764102928341\n",
      "Training Loss: 0.03339147857390344\n",
      "Validation Loss: 0.04281942780767934\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.03487238741479814\n",
      "Training Loss: 0.031674305172637106\n",
      "Training Loss: 0.02884085631929338\n",
      "Training Loss: 0.02460048279725015\n",
      "Training Loss: 0.019734221280086787\n",
      "Training Loss: 0.01813403276260942\n",
      "Training Loss: 0.016690342917572706\n",
      "Validation Loss: 0.03002829343945569\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.020624589044600725\n",
      "Training Loss: 0.01892457637004554\n",
      "Training Loss: 0.018032727646641433\n",
      "Training Loss: 0.015125530012883246\n",
      "Training Loss: 0.011827182935085147\n",
      "Training Loss: 0.01152098978869617\n",
      "Training Loss: 0.010759186514187604\n",
      "Validation Loss: 0.023193049005647837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.015015702559612692\n",
      "Training Loss: 0.013992514049168675\n",
      "Training Loss: 0.013913646677974612\n",
      "Training Loss: 0.011474649596493691\n",
      "Training Loss: 0.008827148898271844\n",
      "Training Loss: 0.00887680047773756\n",
      "Training Loss: 0.008352950514527037\n",
      "Validation Loss: 0.020024788267701196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.012462592262309044\n",
      "Training Loss: 0.011681224345229566\n",
      "Training Loss: 0.011858479778748005\n",
      "Training Loss: 0.009636341497534886\n",
      "Training Loss: 0.0073712669115047905\n",
      "Training Loss: 0.00749027130077593\n",
      "Training Loss: 0.00709185503073968\n",
      "Validation Loss: 0.0185140095274435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.010956692714244128\n",
      "Training Loss: 0.01030005443142727\n",
      "Training Loss: 0.010587962267454714\n",
      "Training Loss: 0.008514154193690046\n",
      "Training Loss: 0.006524101645918563\n",
      "Training Loss: 0.006641680423053913\n",
      "Training Loss: 0.006340806459193118\n",
      "Validation Loss: 0.017599024549161506\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.009995496631599963\n",
      "Training Loss: 0.009421278233639896\n",
      "Training Loss: 0.009769213008694351\n",
      "Training Loss: 0.007799271132098511\n",
      "Training Loss: 0.005997026824625209\n",
      "Training Loss: 0.006094681841786951\n",
      "Training Loss: 0.005866826623096131\n",
      "Validation Loss: 0.016929940712090568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.00937387275393121\n",
      "Training Loss: 0.008847066556336358\n",
      "Training Loss: 0.00922161540715024\n",
      "Training Loss: 0.007318726055673324\n",
      "Training Loss: 0.005641465625958517\n",
      "Training Loss: 0.005716644065687433\n",
      "Training Loss: 0.005540823263581842\n",
      "Validation Loss: 0.016393479147284163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.008947481974028051\n",
      "Training Loss: 0.008446360364323481\n",
      "Training Loss: 0.00883115200791508\n",
      "Training Loss: 0.006971568830776959\n",
      "Training Loss: 0.005381420322228223\n",
      "Training Loss: 0.005437362095690333\n",
      "Training Loss: 0.0052993686846457425\n",
      "Validation Loss: 0.015949126168185574\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.008636582035105676\n",
      "Training Loss: 0.008150168310385198\n",
      "Training Loss: 0.008539611558662728\n",
      "Training Loss: 0.0067086282762466\n",
      "Training Loss: 0.005181760101695545\n",
      "Training Loss: 0.005222222591983155\n",
      "Training Loss: 0.005112634192919359\n",
      "Validation Loss: 0.01557733194051443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008402134401258081\n",
      "Training Loss: 0.007924524063710123\n",
      "Training Loss: 0.008317558966809883\n",
      "Training Loss: 0.006505129213328473\n",
      "Training Loss: 0.005024469989002682\n",
      "Training Loss: 0.005052124051144346\n",
      "Training Loss: 0.0049644987296778706\n",
      "Validation Loss: 0.015263978592015469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008223174932645634\n",
      "Training Loss: 0.0077505841758102175\n",
      "Training Loss: 0.008147426710929722\n",
      "Training Loss: 0.006346119843074121\n",
      "Training Loss: 0.004898474252549931\n",
      "Training Loss: 0.004914937687572092\n",
      "Training Loss: 0.004844780897838063\n",
      "Validation Loss: 0.014998603235469775\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.00808611876796931\n",
      "Training Loss: 0.007615838503697887\n",
      "Training Loss: 0.008016671154182404\n",
      "Training Loss: 0.006220980552607216\n",
      "Training Loss: 0.004796115086064674\n",
      "Training Loss: 0.0048023980157449846\n",
      "Training Loss: 0.004746515398146585\n",
      "Validation Loss: 0.014773939725287148\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007980748042464257\n",
      "Training Loss: 0.007510859564645216\n",
      "Training Loss: 0.007915486899437383\n",
      "Training Loss: 0.006121599056641571\n",
      "Training Loss: 0.004711865142453462\n",
      "Training Loss: 0.00470872619014699\n",
      "Training Loss: 0.0046647779655177146\n",
      "Validation Loss: 0.014584660121982687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007898967197397723\n",
      "Training Loss: 0.007428246409399435\n",
      "Training Loss: 0.007836159748258069\n",
      "Training Loss: 0.00604172860912513\n",
      "Training Loss: 0.004641679624910466\n",
      "Training Loss: 0.004629829412442632\n",
      "Training Loss: 0.0045960273256059735\n",
      "Validation Loss: 0.014426411116453871\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.007834436072735117\n",
      "Training Loss: 0.007362248862627894\n",
      "Training Loss: 0.007772784312255681\n",
      "Training Loss: 0.005976646253257059\n",
      "Training Loss: 0.0045825767354108395\n",
      "Training Loss: 0.004562749851029366\n",
      "Training Loss: 0.004537659731577151\n",
      "Validation Loss: 0.014295210331950463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.007782376602990553\n",
      "Training Loss: 0.00730853513116017\n",
      "Training Loss: 0.0077210067375563084\n",
      "Training Loss: 0.0059228407737100496\n",
      "Training Loss: 0.004532329590292647\n",
      "Training Loss: 0.004505293983384035\n",
      "Training Loss: 0.0044877179968170824\n",
      "Validation Loss: 0.014187273970972537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007739320498658344\n",
      "Training Loss: 0.0072639322152826934\n",
      "Training Loss: 0.007677716938778758\n",
      "Training Loss: 0.0058777367352740835\n",
      "Training Loss: 0.004489245678996667\n",
      "Training Loss: 0.004455783416633494\n",
      "Training Loss: 0.004444693508557976\n",
      "Validation Loss: 0.014099084231514163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007702844206942245\n",
      "Training Loss: 0.007226178891723976\n",
      "Training Loss: 0.0076407449622638525\n",
      "Training Loss: 0.005839448712067679\n",
      "Training Loss: 0.004452025612117723\n",
      "Training Loss: 0.004412907988880761\n",
      "Training Loss: 0.004407407827093266\n",
      "Validation Loss: 0.014027463403017668\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007671282365918159\n",
      "Training Loss: 0.007193670183187351\n",
      "Training Loss: 0.0076085955474991356\n",
      "Training Loss: 0.005806588080013171\n",
      "Training Loss: 0.004419653603690676\n",
      "Training Loss: 0.004375617690966465\n",
      "Training Loss: 0.004374917155946605\n",
      "Validation Loss: 0.013969606037115615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007643511564237997\n",
      "Training Loss: 0.007165272231213748\n",
      "Training Loss: 0.00758023357251659\n",
      "Training Loss: 0.005778110703104176\n",
      "Training Loss: 0.004391334771644324\n",
      "Training Loss: 0.004343067078152672\n",
      "Training Loss: 0.004346468347939662\n",
      "Validation Loss: 0.013923087950415686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007618757999734953\n",
      "Training Loss: 0.007140164844458923\n",
      "Training Loss: 0.007554925821023062\n",
      "Training Loss: 0.005753214452997781\n",
      "Training Loss: 0.004366429531364702\n",
      "Training Loss: 0.004314555695164018\n",
      "Training Loss: 0.0043214416957926\n",
      "Validation Loss: 0.013885870633022476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007596469703130424\n",
      "Training Loss: 0.007117734994972124\n",
      "Training Loss: 0.0075321308022830635\n",
      "Training Loss: 0.0057312657503644\n",
      "Training Loss: 0.004344424157170579\n",
      "Training Loss: 0.004289503017207608\n",
      "Training Loss: 0.004299330037902109\n",
      "Validation Loss: 0.01385621365756215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007576233317377046\n",
      "Training Loss: 0.00709750764654018\n",
      "Training Loss: 0.00751143348054029\n",
      "Training Loss: 0.005711745478911325\n",
      "Training Loss: 0.004324891953147016\n",
      "Training Loss: 0.004267416188959032\n",
      "Training Loss: 0.004279700068873353\n",
      "Validation Loss: 0.013832636543354263\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007557725389488041\n",
      "Training Loss: 0.007079104401636869\n",
      "Training Loss: 0.007492500700755045\n",
      "Training Loss: 0.005694228034117259\n",
      "Training Loss: 0.004307475775131024\n",
      "Training Loss: 0.004247872840496711\n",
      "Training Loss: 0.004262190164881758\n",
      "Validation Loss: 0.013813860544826738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007540673967450857\n",
      "Training Loss: 0.00706221304833889\n",
      "Training Loss: 0.007475055770482868\n",
      "Training Loss: 0.005678356327698566\n",
      "Training Loss: 0.0042918715684209015\n",
      "Training Loss: 0.004230504364822991\n",
      "Training Loss: 0.004246482836315409\n",
      "Validation Loss: 0.013798798441848533\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007524849463952705\n",
      "Training Loss: 0.007046573859406635\n",
      "Training Loss: 0.007458866449305788\n",
      "Training Loss: 0.00566383310186211\n",
      "Training Loss: 0.004277820133720525\n",
      "Training Loss: 0.0042149956460343675\n",
      "Training Loss: 0.004232313053798862\n",
      "Validation Loss: 0.013786541547866935\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007510058209300041\n",
      "Training Loss: 0.007031975012505427\n",
      "Training Loss: 0.007443739415612072\n",
      "Training Loss: 0.0056504101207247\n",
      "Training Loss: 0.004265099397161976\n",
      "Training Loss: 0.0042010719899553805\n",
      "Training Loss: 0.00421944834641181\n",
      "Validation Loss: 0.01377633073775286\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.0074961332383099944\n",
      "Training Loss: 0.007018239970784634\n",
      "Training Loss: 0.007429511027876288\n",
      "Training Loss: 0.005637885562027805\n",
      "Training Loss: 0.004253513734438457\n",
      "Training Loss: 0.004188489338266663\n",
      "Training Loss: 0.004207689160830341\n",
      "Validation Loss: 0.013767516446275434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007482936172746122\n",
      "Training Loss: 0.007005224276799709\n",
      "Training Loss: 0.0074160468485206365\n",
      "Training Loss: 0.0056260931561701\n",
      "Training Loss: 0.004242896698997356\n",
      "Training Loss: 0.004177041882649064\n",
      "Training Loss: 0.0041968671529321\n",
      "Validation Loss: 0.013759579694365963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007470352157251909\n",
      "Training Loss: 0.0069928132800851014\n",
      "Training Loss: 0.00740323550067842\n",
      "Training Loss: 0.005614900255459361\n",
      "Training Loss: 0.004233109536580741\n",
      "Training Loss: 0.004166555544943548\n",
      "Training Loss: 0.00418683898053132\n",
      "Validation Loss: 0.013752164357962707\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007458284915192053\n",
      "Training Loss: 0.006980910539859906\n",
      "Training Loss: 0.007390983856748789\n",
      "Training Loss: 0.005604200400994159\n",
      "Training Loss: 0.004224026429583318\n",
      "Training Loss: 0.004156873417668976\n",
      "Training Loss: 0.004177482764353044\n",
      "Validation Loss: 0.013744935296974686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007446657249238342\n",
      "Training Loss: 0.0069694410334341225\n",
      "Training Loss: 0.007379214403918013\n",
      "Training Loss: 0.005593910102033988\n",
      "Training Loss: 0.004215547883650288\n",
      "Training Loss: 0.004147871798486449\n",
      "Training Loss: 0.004168700901791453\n",
      "Validation Loss: 0.013737700388623814\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007435402693226933\n",
      "Training Loss: 0.0069583421293646095\n",
      "Training Loss: 0.007367864566622302\n",
      "Training Loss: 0.005583961717202328\n",
      "Training Loss: 0.00420758371707052\n",
      "Training Loss: 0.004139439433347433\n",
      "Training Loss: 0.004160405449802056\n",
      "Validation Loss: 0.013730299269714242\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007424469713587314\n",
      "Training Loss: 0.006947562911082059\n",
      "Training Loss: 0.007356879633152858\n",
      "Training Loss: 0.005574301646556705\n",
      "Training Loss: 0.004200063116732053\n",
      "Training Loss: 0.004131490321015008\n",
      "Training Loss: 0.004152529571438208\n",
      "Validation Loss: 0.013722640233313184\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007413809188874438\n",
      "Training Loss: 0.006937058806652203\n",
      "Training Loss: 0.007346212884876877\n",
      "Training Loss: 0.005564888892113231\n",
      "Training Loss: 0.004192922862130217\n",
      "Training Loss: 0.004123948928900063\n",
      "Training Loss: 0.004145016945549287\n",
      "Validation Loss: 0.013714690342604807\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.0074033838685136286\n",
      "Training Loss: 0.006926793557358906\n",
      "Training Loss: 0.007335823937319219\n",
      "Training Loss: 0.0055556894349865615\n",
      "Training Loss: 0.004186112262541428\n",
      "Training Loss: 0.004116756077855825\n",
      "Training Loss: 0.004137819712050259\n",
      "Validation Loss: 0.01370645651754257\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007393157858168706\n",
      "Training Loss: 0.006916735350387171\n",
      "Training Loss: 0.007325678718043491\n",
      "Training Loss: 0.005546674465877004\n",
      "Training Loss: 0.004179584078956395\n",
      "Training Loss: 0.004109855573624373\n",
      "Training Loss: 0.004130895456764847\n",
      "Validation Loss: 0.013697949965826274\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007383108125068248\n",
      "Training Loss: 0.006906857280991972\n",
      "Training Loss: 0.007315744793741033\n",
      "Training Loss: 0.0055378238391131165\n",
      "Training Loss: 0.004173307928722352\n",
      "Training Loss: 0.004103214293718338\n",
      "Training Loss: 0.004124217676580884\n",
      "Validation Loss: 0.013689179172258028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007373197687556967\n",
      "Training Loss: 0.006897130775032565\n",
      "Training Loss: 0.007305993105983361\n",
      "Training Loss: 0.005529116368852556\n",
      "Training Loss: 0.004167249468737282\n",
      "Training Loss: 0.004096796529483982\n",
      "Training Loss: 0.004117759766522795\n",
      "Validation Loss: 0.013680231568668638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007363406514050439\n",
      "Training Loss: 0.006887532593682408\n",
      "Training Loss: 0.007296396334422753\n",
      "Training Loss: 0.005520537691772916\n",
      "Training Loss: 0.004161386839114129\n",
      "Training Loss: 0.004090575616573915\n",
      "Training Loss: 0.00411149904539343\n",
      "Validation Loss: 0.013671161803113443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007353713827906176\n",
      "Training Loss: 0.006878046625060961\n",
      "Training Loss: 0.0072869363042991605\n",
      "Training Loss: 0.005512073118588887\n",
      "Training Loss: 0.004155694120563567\n",
      "Training Loss: 0.004084528880775906\n",
      "Training Loss: 0.004105416996753775\n",
      "Validation Loss: 0.013661978499482521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007344098527682945\n",
      "Training Loss: 0.006868651947006583\n",
      "Training Loss: 0.007277590403100475\n",
      "Training Loss: 0.005503711199853569\n",
      "Training Loss: 0.0041501563898054886\n",
      "Training Loss: 0.004078636746271513\n",
      "Training Loss: 0.004099496074486524\n",
      "Validation Loss: 0.013652773486792148\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.0073345477425027636\n",
      "Training Loss: 0.006859334782930091\n",
      "Training Loss: 0.007268341657472774\n",
      "Training Loss: 0.005495442624669522\n",
      "Training Loss: 0.00414475784113165\n",
      "Training Loss: 0.004072890339302831\n",
      "Training Loss: 0.00409373021684587\n",
      "Validation Loss: 0.013643578921831894\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007325042077573016\n",
      "Training Loss: 0.006850077620474622\n",
      "Training Loss: 0.007259173684287816\n",
      "Training Loss: 0.0054872565402183686\n",
      "Training Loss: 0.004139485430205241\n",
      "Training Loss: 0.004067271201056428\n",
      "Training Loss: 0.004088100108201615\n",
      "Validation Loss: 0.013634439688158476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007315572049701586\n",
      "Training Loss: 0.006840873003238812\n",
      "Training Loss: 0.007250074424082414\n",
      "Training Loss: 0.005479146458092146\n",
      "Training Loss: 0.004134327636566013\n",
      "Training Loss: 0.004061771794804372\n",
      "Training Loss: 0.004082601689151488\n",
      "Validation Loss: 0.013625395802121736\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007306123446905986\n",
      "Training Loss: 0.006831705500371754\n",
      "Training Loss: 0.007241031597368419\n",
      "Training Loss: 0.0054711032524937765\n",
      "Training Loss: 0.004129273184225894\n",
      "Training Loss: 0.004056380986003205\n",
      "Training Loss: 0.004077220089966431\n",
      "Validation Loss: 0.013616462872531055\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007296692554373294\n",
      "Training Loss: 0.006822571153752506\n",
      "Training Loss: 0.007232035653432831\n",
      "Training Loss: 0.005463121999637224\n",
      "Training Loss: 0.004124314982327633\n",
      "Training Loss: 0.004051092949230224\n",
      "Training Loss: 0.004071952310041525\n",
      "Validation Loss: 0.013607679956508904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007287266671191901\n",
      "Training Loss: 0.0068134577863384034\n",
      "Training Loss: 0.00722307785297744\n",
      "Training Loss: 0.005455195634276606\n",
      "Training Loss: 0.004119444072712213\n",
      "Training Loss: 0.004045899881166406\n",
      "Training Loss: 0.004066787917399779\n",
      "Validation Loss: 0.013599054390836633\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007277842945186421\n",
      "Training Loss: 0.006804362728726119\n",
      "Training Loss: 0.007214151134248823\n",
      "Training Loss: 0.005447319867089391\n",
      "Training Loss: 0.004114653177093714\n",
      "Training Loss: 0.0040407925279578195\n",
      "Training Loss: 0.004061719542951323\n",
      "Validation Loss: 0.013590596372973216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007268416081788018\n",
      "Training Loss: 0.006795279630459845\n",
      "Training Loss: 0.007205250224797055\n",
      "Training Loss: 0.005439489034470171\n",
      "Training Loss: 0.0041099380276864396\n",
      "Training Loss: 0.00403577140183188\n",
      "Training Loss: 0.004056743737892248\n",
      "Validation Loss: 0.013582318985471955\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007258978328900411\n",
      "Training Loss: 0.0067862004041671755\n",
      "Training Loss: 0.007196369449375197\n",
      "Training Loss: 0.005431699639302678\n",
      "Training Loss: 0.004105293567990884\n",
      "Training Loss: 0.004030828064423985\n",
      "Training Loss: 0.004051853446289897\n",
      "Validation Loss: 0.01357422685573289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007249527621315793\n",
      "Training Loss: 0.006777124305954203\n",
      "Training Loss: 0.007187504407484085\n",
      "Training Loss: 0.0054239454556955025\n",
      "Training Loss: 0.00410071196150966\n",
      "Training Loss: 0.004025956527329982\n",
      "Training Loss: 0.004047041326411999\n",
      "Validation Loss: 0.01356631905810161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007240066537633538\n",
      "Training Loss: 0.006768050239188596\n",
      "Training Loss: 0.0071786551096010955\n",
      "Training Loss: 0.005416225698427297\n",
      "Training Loss: 0.004096190638374537\n",
      "Training Loss: 0.004021154522197321\n",
      "Training Loss: 0.0040423033881234\n",
      "Validation Loss: 0.013558580892854666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0072305895632598545\n",
      "Training Loss: 0.006758974882541224\n",
      "Training Loss: 0.00716981716803275\n",
      "Training Loss: 0.005408535388414748\n",
      "Training Loss: 0.004091723657329567\n",
      "Training Loss: 0.004016414619400166\n",
      "Training Loss: 0.0040376327326521275\n",
      "Validation Loss: 0.01355101735713065\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007221100174356252\n",
      "Training Loss: 0.006749897187110037\n",
      "Training Loss: 0.007160990457050502\n",
      "Training Loss: 0.005400871824240312\n",
      "Training Loss: 0.004087305036955513\n",
      "Training Loss: 0.004011731212958693\n",
      "Training Loss: 0.004033024171367288\n",
      "Validation Loss: 0.013543604203841687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0072115951881278305\n",
      "Training Loss: 0.006740815703524277\n",
      "Training Loss: 0.007152173633221537\n",
      "Training Loss: 0.005393233335926197\n",
      "Training Loss: 0.0040829356154426935\n",
      "Training Loss: 0.004007104261545464\n",
      "Training Loss: 0.004028475368977524\n",
      "Validation Loss: 0.013536346298886623\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007202075045788661\n",
      "Training Loss: 0.006731729528401047\n",
      "Training Loss: 0.0071433650073595345\n",
      "Training Loss: 0.005385615285485983\n",
      "Training Loss: 0.0040786064934218305\n",
      "Training Loss: 0.004002526340773329\n",
      "Training Loss: 0.004023979248595424\n",
      "Validation Loss: 0.013529222084066312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007192542385309935\n",
      "Training Loss: 0.006722640490625054\n",
      "Training Loss: 0.0071345664176624265\n",
      "Training Loss: 0.0053780161269241945\n",
      "Training Loss: 0.00407431565457955\n",
      "Training Loss: 0.003997992657823488\n",
      "Training Loss: 0.004019529174547643\n",
      "Validation Loss: 0.01352219719026405\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.00718299848609604\n",
      "Training Loss: 0.006713546743849292\n",
      "Training Loss: 0.007125776781467721\n",
      "Training Loss: 0.005370434811920859\n",
      "Training Loss: 0.004070060410886072\n",
      "Training Loss: 0.0039935014944057915\n",
      "Training Loss: 0.00401512494252529\n",
      "Validation Loss: 0.013515290519491201\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007173445239895954\n",
      "Training Loss: 0.006704451917903498\n",
      "Training Loss: 0.007116998460842297\n",
      "Training Loss: 0.00536286847142037\n",
      "Training Loss: 0.004065835566143506\n",
      "Training Loss: 0.003989047252689488\n",
      "Training Loss: 0.004010760987875983\n",
      "Validation Loss: 0.013508469552195836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.0071638815919868645\n",
      "Training Loss: 0.006695351015077904\n",
      "Training Loss: 0.0071082284685689955\n",
      "Training Loss: 0.005355317238136195\n",
      "Training Loss: 0.004061643350287341\n",
      "Training Loss: 0.00398462951532565\n",
      "Training Loss: 0.004006434222683311\n",
      "Validation Loss: 0.013501734490251719\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.0071543120616115626\n",
      "Training Loss: 0.006686249412596225\n",
      "Training Loss: 0.007099471549736336\n",
      "Training Loss: 0.005347777908900753\n",
      "Training Loss: 0.004057474961155094\n",
      "Training Loss: 0.003980241110548377\n",
      "Training Loss: 0.004002139084041119\n",
      "Validation Loss: 0.0134950525607837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007144738790811971\n",
      "Training Loss: 0.006677145762369037\n",
      "Training Loss: 0.0070907263684785\n",
      "Training Loss: 0.005340250583249145\n",
      "Training Loss: 0.004053329501184635\n",
      "Training Loss: 0.0039758803637232635\n",
      "Training Loss: 0.003997873461339623\n",
      "Validation Loss: 0.013488417955234033\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007135163041530177\n",
      "Training Loss: 0.0066680432681459935\n",
      "Training Loss: 0.007081995346816257\n",
      "Training Loss: 0.005332732216920703\n",
      "Training Loss: 0.004049204988987185\n",
      "Training Loss: 0.00397154270671308\n",
      "Training Loss: 0.003993633150821551\n",
      "Validation Loss: 0.013481820069780147\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.007125587324844673\n",
      "Training Loss: 0.00665894006495364\n",
      "Training Loss: 0.007073278824682347\n",
      "Training Loss: 0.005325224153348245\n",
      "Training Loss: 0.004045099526410923\n",
      "Training Loss: 0.0039672278158832345\n",
      "Training Loss: 0.003989417460397817\n",
      "Validation Loss: 0.01347525776424951\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007116011136677116\n",
      "Training Loss: 0.006649837606819347\n",
      "Training Loss: 0.007064577601850033\n",
      "Training Loss: 0.00531772309797816\n",
      "Training Loss: 0.00404100832703989\n",
      "Training Loss: 0.003962930049165152\n",
      "Training Loss: 0.00398522119387053\n",
      "Validation Loss: 0.01346869136150996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007106438594637439\n",
      "Training Loss: 0.006640737692359835\n",
      "Training Loss: 0.007055892047937959\n",
      "Training Loss: 0.005310230795294047\n",
      "Training Loss: 0.00403693190892227\n",
      "Training Loss: 0.003958647691179067\n",
      "Training Loss: 0.003981042949017137\n",
      "Validation Loss: 0.01346214244112526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007096873696427792\n",
      "Training Loss: 0.006631643096916377\n",
      "Training Loss: 0.007047227443545126\n",
      "Training Loss: 0.005302745139924809\n",
      "Training Loss: 0.004032865812187083\n",
      "Training Loss: 0.0039543771371245385\n",
      "Training Loss: 0.003976879183319397\n",
      "Validation Loss: 0.013455560704700175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007087315922835842\n",
      "Training Loss: 0.00662255104049109\n",
      "Training Loss: 0.007038579736254178\n",
      "Training Loss: 0.005295266195316799\n",
      "Training Loss: 0.00402880999550689\n",
      "Training Loss: 0.003950118884677068\n",
      "Training Loss: 0.003972729442757554\n",
      "Validation Loss: 0.013448974966116892\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.0070777673355769365\n",
      "Training Loss: 0.006613464092370122\n",
      "Training Loss: 0.0070299540314590556\n",
      "Training Loss: 0.005287794363102876\n",
      "Training Loss: 0.0040247636660933495\n",
      "Training Loss: 0.0039458685379941015\n",
      "Training Loss: 0.003968591173761524\n",
      "Validation Loss: 0.013442360404059151\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.007068231476005167\n",
      "Training Loss: 0.006604383130325004\n",
      "Training Loss: 0.007021348848356865\n",
      "Training Loss: 0.005280327894724906\n",
      "Training Loss: 0.004020722592831589\n",
      "Training Loss: 0.003941623060964048\n",
      "Training Loss: 0.003964460837305523\n",
      "Validation Loss: 0.013435718527566014\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007058710823766887\n",
      "Training Loss: 0.00659531113691628\n",
      "Training Loss: 0.0070127669727662574\n",
      "Training Loss: 0.005272867720923387\n",
      "Training Loss: 0.004016686566756107\n",
      "Training Loss: 0.0039373832620913166\n",
      "Training Loss: 0.003960340438061394\n",
      "Validation Loss: 0.013429033936242039\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.0070492032240144905\n",
      "Training Loss: 0.006586244305362925\n",
      "Training Loss: 0.007004207446007058\n",
      "Training Loss: 0.005265414142049849\n",
      "Training Loss: 0.004012653644895181\n",
      "Training Loss: 0.003933145197224803\n",
      "Training Loss: 0.0039562265609856696\n",
      "Validation Loss: 0.013422304276056058\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.0070397136360406875\n",
      "Training Loss: 0.0065771885483991354\n",
      "Training Loss: 0.006995674659847282\n",
      "Training Loss: 0.005257967017241754\n",
      "Training Loss: 0.0040086242195684465\n",
      "Training Loss: 0.003928907616063952\n",
      "Training Loss: 0.003952116355067119\n",
      "Validation Loss: 0.013415531288877772\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007030245201895014\n",
      "Training Loss: 0.006568142068572342\n",
      "Training Loss: 0.006987168589839712\n",
      "Training Loss: 0.005250526092713699\n",
      "Training Loss: 0.004004595871665515\n",
      "Training Loss: 0.00392467113386374\n",
      "Training Loss: 0.003948013102635741\n",
      "Validation Loss: 0.013408698878871897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007020795459393412\n",
      "Training Loss: 0.006559104599291459\n",
      "Training Loss: 0.006978687371010892\n",
      "Training Loss: 0.005243092523305677\n",
      "Training Loss: 0.004000568347983062\n",
      "Training Loss: 0.00392043195781298\n",
      "Training Loss: 0.003943911230308004\n",
      "Validation Loss: 0.013401807913267182\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.00701137027470395\n",
      "Training Loss: 0.0065500796609558164\n",
      "Training Loss: 0.006970236064516939\n",
      "Training Loss: 0.005235665632644668\n",
      "Training Loss: 0.003996538383653388\n",
      "Training Loss: 0.003916188461589627\n",
      "Training Loss: 0.003939811418531463\n",
      "Validation Loss: 0.013394854338019947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007001969814300537\n",
      "Training Loss: 0.006541066047502681\n",
      "Training Loss: 0.006961813152302056\n",
      "Training Loss: 0.005228246022597887\n",
      "Training Loss: 0.003992506293579936\n",
      "Training Loss: 0.003911941017140635\n",
      "Training Loss: 0.00393571476219222\n",
      "Validation Loss: 0.013387844321398197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.0069925910688471045\n",
      "Training Loss: 0.006532062974292785\n",
      "Training Loss: 0.006953417903278023\n",
      "Training Loss: 0.005220835984218865\n",
      "Training Loss: 0.003988476479426026\n",
      "Training Loss: 0.0039076917676720765\n",
      "Training Loss: 0.0039316215476719665\n",
      "Validation Loss: 0.01338077342261522\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006983237700769678\n",
      "Training Loss: 0.006523072426207363\n",
      "Training Loss: 0.006945053638191894\n",
      "Training Loss: 0.005213431837037205\n",
      "Training Loss: 0.003984438897459768\n",
      "Training Loss: 0.0039034322497900576\n",
      "Training Loss: 0.003927527110208757\n",
      "Validation Loss: 0.01337362349744928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.0069739157240837815\n",
      "Training Loss: 0.006514097121544183\n",
      "Training Loss: 0.006936721903621219\n",
      "Training Loss: 0.005206037908210419\n",
      "Training Loss: 0.003980399178108201\n",
      "Training Loss: 0.003899167167255655\n",
      "Training Loss: 0.00392343406972941\n",
      "Validation Loss: 0.013366412063136223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006964620897779241\n",
      "Training Loss: 0.006505133237224073\n",
      "Training Loss: 0.006928419813048095\n",
      "Training Loss: 0.005198653645347804\n",
      "Training Loss: 0.003976356270140968\n",
      "Training Loss: 0.0038948959804838523\n",
      "Training Loss: 0.003919341471628286\n",
      "Validation Loss: 0.013359140531048318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006955356328980997\n",
      "Training Loss: 0.006496185209834948\n",
      "Training Loss: 0.0069201517786132176\n",
      "Training Loss: 0.005191279810969718\n",
      "Training Loss: 0.003972306622890756\n",
      "Training Loss: 0.003890611850656569\n",
      "Training Loss: 0.003915245638345368\n",
      "Validation Loss: 0.013351789628127624\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.00694612513994798\n",
      "Training Loss: 0.006487252936931327\n",
      "Training Loss: 0.006911917193210684\n",
      "Training Loss: 0.005183915621601045\n",
      "Training Loss: 0.003968252545455471\n",
      "Training Loss: 0.0038863213220611216\n",
      "Training Loss: 0.003911152665968984\n",
      "Validation Loss: 0.013344365382682155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006936924449400976\n",
      "Training Loss: 0.006478333619888872\n",
      "Training Loss: 0.006903714012005366\n",
      "Training Loss: 0.005176564346766099\n",
      "Training Loss: 0.003964192268322222\n",
      "Training Loss: 0.0038820196577580646\n",
      "Training Loss: 0.00390705972444266\n",
      "Validation Loss: 0.013336871393122588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006927755062934011\n",
      "Training Loss: 0.006469429809367284\n",
      "Training Loss: 0.006895544148283079\n",
      "Training Loss: 0.005169223206466995\n",
      "Training Loss: 0.003960126939346082\n",
      "Training Loss: 0.0038777088659116997\n",
      "Training Loss: 0.0039029652258614077\n",
      "Validation Loss: 0.013329310834491521\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.00691861764062196\n",
      "Training Loss: 0.006460539813851938\n",
      "Training Loss: 0.006887407478061504\n",
      "Training Loss: 0.0051618959748884665\n",
      "Training Loss: 0.0039560547785367816\n",
      "Training Loss: 0.0038733869610587134\n",
      "Training Loss: 0.0038988700200570745\n",
      "Validation Loss: 0.013321677249444698\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.0069095151009969415\n",
      "Training Loss: 0.006451665534405038\n",
      "Training Loss: 0.0068793036916758865\n",
      "Training Loss: 0.005154579094378278\n",
      "Training Loss: 0.003951972735812888\n",
      "Training Loss: 0.0038690514920745045\n",
      "Training Loss: 0.003894773595966399\n",
      "Validation Loss: 0.013313953633060895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006900444864295423\n",
      "Training Loss: 0.006442803474492394\n",
      "Training Loss: 0.006871232656994835\n",
      "Training Loss: 0.005147277950309217\n",
      "Training Loss: 0.003947885066154413\n",
      "Training Loss: 0.0038647058908827603\n",
      "Training Loss: 0.0038906767586013302\n",
      "Validation Loss: 0.013306174342248463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.00689140930888243\n",
      "Training Loss: 0.006433958654524758\n",
      "Training Loss: 0.006863196559133939\n",
      "Training Loss: 0.005139990203897469\n",
      "Training Loss: 0.003943789176992141\n",
      "Training Loss: 0.0038603476132266223\n",
      "Training Loss: 0.003886580059188418\n",
      "Validation Loss: 0.013298330754861375\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006882405361393467\n",
      "Training Loss: 0.006425126741523854\n",
      "Training Loss: 0.006855191685026511\n",
      "Training Loss: 0.0051327162818051875\n",
      "Training Loss: 0.0039396839932305736\n",
      "Training Loss: 0.0038559745613019913\n",
      "Training Loss: 0.003882480481406674\n",
      "Validation Loss: 0.013290399082496846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.006873435962479562\n",
      "Training Loss: 0.006416309218620881\n",
      "Training Loss: 0.006847218765760772\n",
      "Training Loss: 0.0051254575344501065\n",
      "Training Loss: 0.003935572001500987\n",
      "Training Loss: 0.0038515934406314046\n",
      "Training Loss: 0.0038783846033038573\n",
      "Validation Loss: 0.013282416330838806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006864496609196067\n",
      "Training Loss: 0.006407503352384083\n",
      "Training Loss: 0.006839276138925925\n",
      "Training Loss: 0.005118212951929308\n",
      "Training Loss: 0.003931449882220477\n",
      "Training Loss: 0.0038471957639558243\n",
      "Training Loss: 0.003874286304344423\n",
      "Validation Loss: 0.013274360046554566\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.0068555885786190625\n",
      "Training Loss: 0.006398706396576017\n",
      "Training Loss: 0.0068313612655038014\n",
      "Training Loss: 0.005110985252540559\n",
      "Training Loss: 0.003927320016664453\n",
      "Training Loss: 0.0038427852955646813\n",
      "Training Loss: 0.003870187127031386\n",
      "Validation Loss: 0.013266236742797973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00684670964605175\n",
      "Training Loss: 0.006389921604422853\n",
      "Training Loss: 0.006823476489516906\n",
      "Training Loss: 0.005103771672584117\n",
      "Training Loss: 0.003923179657431319\n",
      "Training Loss: 0.003838361379457638\n",
      "Training Loss: 0.00386608827393502\n",
      "Validation Loss: 0.013258045295964969\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.006837859810329974\n",
      "Training Loss: 0.006381146353087388\n",
      "Training Loss: 0.006815619668923318\n",
      "Training Loss: 0.005096571990288794\n",
      "Training Loss: 0.003919025951763615\n",
      "Training Loss: 0.003833918650634587\n",
      "Training Loss: 0.0038619863073108716\n",
      "Validation Loss: 0.013249793327117012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.006829040682059712\n",
      "Training Loss: 0.006372380735701882\n",
      "Training Loss: 0.006807787898578681\n",
      "Training Loss: 0.005089389016502537\n",
      "Training Loss: 0.003914864073158242\n",
      "Training Loss: 0.0038294647645670922\n",
      "Training Loss: 0.0038578851614147424\n",
      "Validation Loss: 0.01324147850533159\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006820243401452899\n",
      "Training Loss: 0.006363619014737196\n",
      "Training Loss: 0.006799979176721535\n",
      "Training Loss: 0.005082220216281712\n",
      "Training Loss: 0.003910689726471901\n",
      "Training Loss: 0.003824993706657551\n",
      "Training Loss: 0.0038537817227188497\n",
      "Validation Loss: 0.013233087566238217\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00681146900053136\n",
      "Training Loss: 0.006354862115113064\n",
      "Training Loss: 0.006792191745480522\n",
      "Training Loss: 0.005075063369004056\n",
      "Training Loss: 0.00390650044195354\n",
      "Training Loss: 0.0038205031940015035\n",
      "Training Loss: 0.0038496746425516902\n",
      "Validation Loss: 0.013224606253974112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.0068027191923465576\n",
      "Training Loss: 0.006346109513542615\n",
      "Training Loss: 0.0067844248318579044\n",
      "Training Loss: 0.0050679213996045296\n",
      "Training Loss: 0.0039022996270796284\n",
      "Training Loss: 0.0038159977429313586\n",
      "Training Loss: 0.003845567561802454\n",
      "Validation Loss: 0.01321608927981642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006793982945964672\n",
      "Training Loss: 0.006337354673887603\n",
      "Training Loss: 0.006776673029526137\n",
      "Training Loss: 0.005060792354051955\n",
      "Training Loss: 0.0038980861013988032\n",
      "Training Loss: 0.0038114756520371885\n",
      "Training Loss: 0.0038414587534498423\n",
      "Validation Loss: 0.01320749975580457\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.00678526590927504\n",
      "Training Loss: 0.006328597778920084\n",
      "Training Loss: 0.0067689361737575384\n",
      "Training Loss: 0.0050536759046372025\n",
      "Training Loss: 0.0038938588422024623\n",
      "Training Loss: 0.003806935803149827\n",
      "Training Loss: 0.0038373479299480097\n",
      "Validation Loss: 0.013198844066904754\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.006776558335404843\n",
      "Training Loss: 0.0063198365911375735\n",
      "Training Loss: 0.006761210489203222\n",
      "Training Loss: 0.0050465712294681\n",
      "Training Loss: 0.0038896169129293413\n",
      "Training Loss: 0.0038023789506405592\n",
      "Training Loss: 0.0038332354294834657\n",
      "Validation Loss: 0.01319012291684105\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006767860879190266\n",
      "Training Loss: 0.006311069145449437\n",
      "Training Loss: 0.006753494594013318\n",
      "Training Loss: 0.005039477299433202\n",
      "Training Loss: 0.0038853594195097686\n",
      "Training Loss: 0.003797802685876377\n",
      "Training Loss: 0.0038291209883755074\n",
      "Validation Loss: 0.013181339837750246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006759168584831059\n",
      "Training Loss: 0.00630228961177636\n",
      "Training Loss: 0.006745781902573071\n",
      "Training Loss: 0.00503239382582251\n",
      "Training Loss: 0.003881087365443818\n",
      "Training Loss: 0.003793207467533648\n",
      "Training Loss: 0.0038250018743565305\n",
      "Validation Loss: 0.01317249014816676\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.0067504804395139215\n",
      "Training Loss: 0.006293499710736796\n",
      "Training Loss: 0.006738074148306623\n",
      "Training Loss: 0.005025317486142739\n",
      "Training Loss: 0.0038767939858371393\n",
      "Training Loss: 0.00378858934098389\n",
      "Training Loss: 0.003820878876140341\n",
      "Validation Loss: 0.013163542042291036\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006741791815729811\n",
      "Training Loss: 0.006284692083136178\n",
      "Training Loss: 0.006730363651295193\n",
      "Training Loss: 0.005018250174471177\n",
      "Training Loss: 0.003872488492052071\n",
      "Training Loss: 0.0037839550204807892\n",
      "Training Loss: 0.003816754498402588\n",
      "Validation Loss: 0.01315453708082898\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.0067330961913103235\n",
      "Training Loss: 0.006275865394272841\n",
      "Training Loss: 0.006722648072754964\n",
      "Training Loss: 0.005011188806383871\n",
      "Training Loss: 0.0038681647385237737\n",
      "Training Loss: 0.0037793010863242673\n",
      "Training Loss: 0.003812627157312818\n",
      "Validation Loss: 0.013145463969750323\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006724389605224133\n",
      "Training Loss: 0.006267014443874359\n",
      "Training Loss: 0.006714923465624452\n",
      "Training Loss: 0.005004133214242756\n",
      "Training Loss: 0.0038638218736741694\n",
      "Training Loss: 0.0037746249191695823\n",
      "Training Loss: 0.0038084963732399045\n",
      "Validation Loss: 0.013136301326568933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006715669406112283\n",
      "Training Loss: 0.006258139025885612\n",
      "Training Loss: 0.006707188495784067\n",
      "Training Loss: 0.004997079555760137\n",
      "Training Loss: 0.0038594591844594104\n",
      "Training Loss: 0.0037699255219195036\n",
      "Training Loss: 0.003804359811474569\n",
      "Validation Loss: 0.013127051964873092\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006706934386165812\n",
      "Training Loss: 0.006249235831201076\n",
      "Training Loss: 0.006699438160285354\n",
      "Training Loss: 0.00499002847878728\n",
      "Training Loss: 0.0038550752820447087\n",
      "Training Loss: 0.003765204563969746\n",
      "Training Loss: 0.003800217542448081\n",
      "Validation Loss: 0.013117714565725167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006698177605867386\n",
      "Training Loss: 0.0062402992969146\n",
      "Training Loss: 0.00669166746083647\n",
      "Training Loss: 0.00498298007179983\n",
      "Training Loss: 0.003850674500572495\n",
      "Training Loss: 0.0037604644848033787\n",
      "Training Loss: 0.003796074010897428\n",
      "Validation Loss: 0.013108291001798592\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.006689395133289509\n",
      "Training Loss: 0.006231327743735165\n",
      "Training Loss: 0.006683873989386484\n",
      "Training Loss: 0.004975931319640949\n",
      "Training Loss: 0.0038462526834337043\n",
      "Training Loss: 0.003755699771572836\n",
      "Training Loss: 0.003791926556150429\n",
      "Validation Loss: 0.013098787324510041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006680580282118171\n",
      "Training Loss: 0.006222317146020942\n",
      "Training Loss: 0.00667605365626514\n",
      "Training Loss: 0.00496888071007561\n",
      "Training Loss: 0.0038418117398396133\n",
      "Training Loss: 0.0037509145465446634\n",
      "Training Loss: 0.003787774050142616\n",
      "Validation Loss: 0.013089162314551348\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006671733540715649\n",
      "Training Loss: 0.006213264937396161\n",
      "Training Loss: 0.0066682028688956054\n",
      "Training Loss: 0.004961828947998583\n",
      "Training Loss: 0.0038373517629224805\n",
      "Training Loss: 0.0037461093330057337\n",
      "Training Loss: 0.003783620793838054\n",
      "Validation Loss: 0.013079466016994517\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.006662846686085686\n",
      "Training Loss: 0.006204167698742821\n",
      "Training Loss: 0.00666031974775251\n",
      "Training Loss: 0.0049547714478103445\n",
      "Training Loss: 0.0038328693591756745\n",
      "Training Loss: 0.003741279065143317\n",
      "Training Loss: 0.0037794595869490876\n",
      "Validation Loss: 0.013069632169720805\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006653923455742188\n",
      "Training Loss: 0.0061950243322644385\n",
      "Training Loss: 0.006652399503509514\n",
      "Training Loss: 0.004947709037223831\n",
      "Training Loss: 0.0038283662433968857\n",
      "Training Loss: 0.0037364253017585724\n",
      "Training Loss: 0.003775296185631305\n",
      "Validation Loss: 0.013059688835362956\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.006644955294905231\n",
      "Training Loss: 0.006185832621413283\n",
      "Training Loss: 0.006644439962110482\n",
      "Training Loss: 0.0049406404583714906\n",
      "Training Loss: 0.00382384299300611\n",
      "Training Loss: 0.0037315503985155376\n",
      "Training Loss: 0.003771130297682248\n",
      "Validation Loss: 0.013049630077611585\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006635936295497231\n",
      "Training Loss: 0.006176586032961495\n",
      "Training Loss: 0.0066364362474996596\n",
      "Training Loss: 0.004933565587271005\n",
      "Training Loss: 0.0038193014793796464\n",
      "Training Loss: 0.003726655340869911\n",
      "Training Loss: 0.0037669628643197937\n",
      "Validation Loss: 0.013039446898477941\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006626867599552497\n",
      "Training Loss: 0.006167285137926228\n",
      "Training Loss: 0.006628387182718143\n",
      "Training Loss: 0.004926481102593243\n",
      "Training Loss: 0.003814741317182779\n",
      "Training Loss: 0.003721740665496327\n",
      "Training Loss: 0.0037627943226834757\n",
      "Validation Loss: 0.013029147484095607\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.006617746487609111\n",
      "Training Loss: 0.00615792868717108\n",
      "Training Loss: 0.006620288877165877\n",
      "Training Loss: 0.0049193907511653374\n",
      "Training Loss: 0.003810165207833052\n",
      "Training Loss: 0.0037168068153550847\n",
      "Training Loss: 0.003758627292700112\n",
      "Validation Loss: 0.01301872157291178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006608565475326031\n",
      "Training Loss: 0.006148512496729382\n",
      "Training Loss: 0.006612138896016404\n",
      "Training Loss: 0.004912290106294677\n",
      "Training Loss: 0.00380557133234106\n",
      "Training Loss: 0.0037118545960402117\n",
      "Training Loss: 0.0037544617609819395\n",
      "Validation Loss: 0.013008162302526641\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.0065993246890138834\n",
      "Training Loss: 0.006139037744142115\n",
      "Training Loss: 0.006603935816092417\n",
      "Training Loss: 0.004905179751222022\n",
      "Training Loss: 0.003800961299566552\n",
      "Training Loss: 0.0037068837467813865\n",
      "Training Loss: 0.0037502949527697636\n",
      "Validation Loss: 0.012997461766726599\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006590028216014616\n",
      "Training Loss: 0.006129501347895711\n",
      "Training Loss: 0.006595676263095811\n",
      "Training Loss: 0.0048980571160791445\n",
      "Training Loss: 0.003796334594953805\n",
      "Training Loss: 0.0037018944835290313\n",
      "Training Loss: 0.00374612970801536\n",
      "Validation Loss: 0.012986592508500185\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006580665001529269\n",
      "Training Loss: 0.006119901918573305\n",
      "Training Loss: 0.006587357730604708\n",
      "Training Loss: 0.004890923416242004\n",
      "Training Loss: 0.003791693988023326\n",
      "Training Loss: 0.003696889478596859\n",
      "Training Loss: 0.0037419703672640025\n",
      "Validation Loss: 0.012975580284410341\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006571239201002754\n",
      "Training Loss: 0.006110240396228619\n",
      "Training Loss: 0.006578978901379742\n",
      "Training Loss: 0.004883779808878898\n",
      "Training Loss: 0.003787043989868835\n",
      "Training Loss: 0.003691871833289042\n",
      "Training Loss: 0.0037378165690461172\n",
      "Validation Loss: 0.01296444560273826\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006561744069331326\n",
      "Training Loss: 0.00610051273892168\n",
      "Training Loss: 0.006570536376093514\n",
      "Training Loss: 0.004876623433665373\n",
      "Training Loss: 0.003782379351905547\n",
      "Training Loss: 0.0036868383671389894\n",
      "Training Loss: 0.003733665208565071\n",
      "Validation Loss: 0.012953126703193655\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.0065521832788363096\n",
      "Training Loss: 0.0060907213611062615\n",
      "Training Loss: 0.00656203040969558\n",
      "Training Loss: 0.004869454005965963\n",
      "Training Loss: 0.0037777042598463595\n",
      "Training Loss: 0.0036817914323182778\n",
      "Training Loss: 0.003729519338812679\n",
      "Validation Loss: 0.01294163434874364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006542552429018542\n",
      "Training Loss: 0.006080863443203271\n",
      "Training Loss: 0.006553457371192053\n",
      "Training Loss: 0.004862269851146266\n",
      "Training Loss: 0.003773015295737423\n",
      "Training Loss: 0.0036767291824799033\n",
      "Training Loss: 0.0037253791867988186\n",
      "Validation Loss: 0.012929946693856869\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006532852013478987\n",
      "Training Loss: 0.006070939838537015\n",
      "Training Loss: 0.006544815279776231\n",
      "Training Loss: 0.0048550747253466395\n",
      "Training Loss: 0.0037683206307701765\n",
      "Training Loss: 0.003671657721279189\n",
      "Training Loss: 0.0037212470598751678\n",
      "Validation Loss: 0.012918052236525139\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.0065230767172761266\n",
      "Training Loss: 0.006060947029618546\n",
      "Training Loss: 0.006536101354868151\n",
      "Training Loss: 0.004847864336334169\n",
      "Training Loss: 0.0037636135244974865\n",
      "Training Loss: 0.0036665731412358583\n",
      "Training Loss: 0.0037171215069247408\n",
      "Validation Loss: 0.012905982148149905\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006513232869328931\n",
      "Training Loss: 0.006050891047343612\n",
      "Training Loss: 0.006527318443404511\n",
      "Training Loss: 0.004840638932073489\n",
      "Training Loss: 0.0037588980636792256\n",
      "Training Loss: 0.003661476974375546\n",
      "Training Loss: 0.0037130017462186516\n",
      "Validation Loss: 0.012893679428388703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006503317211172544\n",
      "Training Loss: 0.006040767356753349\n",
      "Training Loss: 0.006518459829385393\n",
      "Training Loss: 0.004833398003247566\n",
      "Training Loss: 0.0037541724712355064\n",
      "Training Loss: 0.0036563670443138106\n",
      "Training Loss: 0.003708888536784798\n",
      "Validation Loss: 0.012881150569466784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006493327373755164\n",
      "Training Loss: 0.006030577326309867\n",
      "Training Loss: 0.006509527831804007\n",
      "Training Loss: 0.004826140871155076\n",
      "Training Loss: 0.0037494377983966843\n",
      "Training Loss: 0.003651247620000504\n",
      "Training Loss: 0.0037047837011050435\n",
      "Validation Loss: 0.012868364351585311\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006483263227855787\n",
      "Training Loss: 0.0060203200666001065\n",
      "Training Loss: 0.006500519079854712\n",
      "Training Loss: 0.004818867745343596\n",
      "Training Loss: 0.0037446940428344532\n",
      "Training Loss: 0.003646116046002135\n",
      "Training Loss: 0.003700683761853725\n",
      "Validation Loss: 0.012855313580102995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.00647313009831123\n",
      "Training Loss: 0.00600999740709085\n",
      "Training Loss: 0.006491433866322041\n",
      "Training Loss: 0.004811578143853694\n",
      "Training Loss: 0.003739941561361775\n",
      "Training Loss: 0.0036409758077934383\n",
      "Training Loss: 0.0036965939606307075\n",
      "Validation Loss: 0.012842005368998825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006462919875048101\n",
      "Training Loss: 0.005999606247642077\n",
      "Training Loss: 0.006482268447289243\n",
      "Training Loss: 0.00480427016329486\n",
      "Training Loss: 0.003735181106021628\n",
      "Training Loss: 0.0036358246492454783\n",
      "Training Loss: 0.003692512371344492\n",
      "Validation Loss: 0.012828412832001621\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.00645263624319341\n",
      "Training Loss: 0.005989149693632499\n",
      "Training Loss: 0.006473024462466128\n",
      "Training Loss: 0.004796945406706072\n",
      "Training Loss: 0.003730412338627502\n",
      "Training Loss: 0.0036306643771240486\n",
      "Training Loss: 0.0036884385923622175\n",
      "Validation Loss: 0.012814492224419162\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.0064422785694478076\n",
      "Training Loss: 0.005978625885327347\n",
      "Training Loss: 0.006463700074818917\n",
      "Training Loss: 0.004789602206437848\n",
      "Training Loss: 0.0037256368360249325\n",
      "Training Loss: 0.0036254953918978573\n",
      "Training Loss: 0.0036843741504708305\n",
      "Validation Loss: 0.01280027066012112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006431847298517823\n",
      "Training Loss: 0.005968035082914867\n",
      "Training Loss: 0.006454293467104435\n",
      "Training Loss: 0.004782239904743619\n",
      "Training Loss: 0.0037208533147349955\n",
      "Training Loss: 0.00362031775934156\n",
      "Training Loss: 0.003680321314604953\n",
      "Validation Loss: 0.012785716150182714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006421339185908437\n",
      "Training Loss: 0.005957374538993463\n",
      "Training Loss: 0.006444803967606276\n",
      "Training Loss: 0.004774858091841452\n",
      "Training Loss: 0.0037160646583652124\n",
      "Training Loss: 0.00361513391835615\n",
      "Training Loss: 0.0036762790306238457\n",
      "Validation Loss: 0.012770805407179456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006410758424317464\n",
      "Training Loss: 0.005946649562101811\n",
      "Training Loss: 0.006435234033269808\n",
      "Training Loss: 0.004767456484260037\n",
      "Training Loss: 0.0037112680170685052\n",
      "Training Loss: 0.0036099442216800527\n",
      "Training Loss: 0.0036722491716500373\n",
      "Validation Loss: 0.012755553011803396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006400104856584221\n",
      "Training Loss: 0.005935856156866066\n",
      "Training Loss: 0.006425580233917571\n",
      "Training Loss: 0.004760034570936113\n",
      "Training Loss: 0.0037064676091540603\n",
      "Training Loss: 0.0036047500889981165\n",
      "Training Loss: 0.0036682330968324096\n",
      "Validation Loss: 0.012739914463316735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006389377258601598\n",
      "Training Loss: 0.005924996780231595\n",
      "Training Loss: 0.006415844877483323\n",
      "Training Loss: 0.004752593990415335\n",
      "Training Loss: 0.0037016632431186736\n",
      "Training Loss: 0.0035995512694353238\n",
      "Training Loss: 0.0036642323451815174\n",
      "Validation Loss: 0.012723911244052458\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006378576607094146\n",
      "Training Loss: 0.0059140691527863965\n",
      "Training Loss: 0.006406028276542202\n",
      "Training Loss: 0.004745132536045276\n",
      "Training Loss: 0.003696858478360809\n",
      "Training Loss: 0.0035943518136627973\n",
      "Training Loss: 0.003660247955704108\n",
      "Validation Loss: 0.012707499311085833\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006367706475430168\n",
      "Training Loss: 0.00590307941660285\n",
      "Training Loss: 0.006396133254165761\n",
      "Training Loss: 0.004737651626928709\n",
      "Training Loss: 0.003692051688558422\n",
      "Training Loss: 0.003589150320040062\n",
      "Training Loss: 0.003656280392315239\n",
      "Validation Loss: 0.012690692968241005\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006356769247213378\n",
      "Training Loss: 0.005892024232889525\n",
      "Training Loss: 0.0063861586974235255\n",
      "Training Loss: 0.004730153641430661\n",
      "Training Loss: 0.0036872484773630278\n",
      "Training Loss: 0.0035839527251664547\n",
      "Training Loss: 0.003652333716163412\n",
      "Validation Loss: 0.012673491495225425\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006345763056888245\n",
      "Training Loss: 0.00588090863195248\n",
      "Training Loss: 0.006376109523698687\n",
      "Training Loss: 0.004722638181992807\n",
      "Training Loss: 0.003682450499618426\n",
      "Training Loss: 0.003578760763630271\n",
      "Training Loss: 0.003648411491885781\n",
      "Validation Loss: 0.012655891171980942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006334693319513462\n",
      "Training Loss: 0.005869734436273575\n",
      "Training Loss: 0.006365988756879232\n",
      "Training Loss: 0.004715109028038569\n",
      "Training Loss: 0.003677660865942016\n",
      "Training Loss: 0.0035735774104250595\n",
      "Training Loss: 0.00364451376197394\n",
      "Validation Loss: 0.012637879048938051\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006323564617196098\n",
      "Training Loss: 0.005858506095828489\n",
      "Training Loss: 0.006355801121680997\n",
      "Training Loss: 0.004707566996221431\n",
      "Training Loss: 0.003672882059472613\n",
      "Training Loss: 0.00356840587744955\n",
      "Training Loss: 0.003640643381513655\n",
      "Validation Loss: 0.01261947485958383\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0063123815070139245\n",
      "Training Loss: 0.0058472290763165805\n",
      "Training Loss: 0.006345552311977372\n",
      "Training Loss: 0.004700016044662334\n",
      "Training Loss: 0.003668118941714056\n",
      "Training Loss: 0.0035632491012802347\n",
      "Training Loss: 0.0036368032201426104\n",
      "Validation Loss: 0.012600672162706486\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006301148220081813\n",
      "Training Loss: 0.005835908565786667\n",
      "Training Loss: 0.006335248546674848\n",
      "Training Loss: 0.004692457991768606\n",
      "Training Loss: 0.003663370515569113\n",
      "Training Loss: 0.00355810716166161\n",
      "Training Loss: 0.003632993085193448\n",
      "Validation Loss: 0.01258145722958228\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006289876084774732\n",
      "Training Loss: 0.005824554464197718\n",
      "Training Loss: 0.006324898064485751\n",
      "Training Loss: 0.004684900168213062\n",
      "Training Loss: 0.003658646239200607\n",
      "Training Loss: 0.0035529881884576752\n",
      "Training Loss: 0.003629217722918838\n",
      "Validation Loss: 0.01256189285385098\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00627856956445612\n",
      "Training Loss: 0.005813172575435601\n",
      "Training Loss: 0.006314510253141634\n",
      "Training Loss: 0.0046773443330312145\n",
      "Training Loss: 0.003653945715050213\n",
      "Training Loss: 0.0035478917666478082\n",
      "Training Loss: 0.0036254783463664352\n",
      "Validation Loss: 0.012541934726620267\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006267236839048565\n",
      "Training Loss: 0.005801772839040495\n",
      "Training Loss: 0.006304093126091175\n",
      "Training Loss: 0.004669796875095927\n",
      "Training Loss: 0.003649272708571516\n",
      "Training Loss: 0.0035428227885859085\n",
      "Training Loss: 0.0036217763065360484\n",
      "Validation Loss: 0.012521616154008507\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006255888722953387\n",
      "Training Loss: 0.005790365412831306\n",
      "Training Loss: 0.006293657840578817\n",
      "Training Loss: 0.00466226339689456\n",
      "Training Loss: 0.003644633747753687\n",
      "Training Loss: 0.003537787418463267\n",
      "Training Loss: 0.003618115409044549\n",
      "Validation Loss: 0.012500971509056508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.0062445372849470005\n",
      "Training Loss: 0.005778960784664377\n",
      "Training Loss: 0.00628321361145936\n",
      "Training Loss: 0.00465475027973298\n",
      "Training Loss: 0.0036400313064223156\n",
      "Training Loss: 0.003532787738949992\n",
      "Training Loss: 0.003614497446687892\n",
      "Validation Loss: 0.012480011965891116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006233190224738791\n",
      "Training Loss: 0.005767572395852767\n",
      "Training Loss: 0.006272774738026783\n",
      "Training Loss: 0.00464726313308347\n",
      "Training Loss: 0.003635468240827322\n",
      "Training Loss: 0.0035278236924204975\n",
      "Training Loss: 0.003610920777427964\n",
      "Validation Loss: 0.012458753424578028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006221862144302577\n",
      "Training Loss: 0.005756212250562384\n",
      "Training Loss: 0.006262352958437987\n",
      "Training Loss: 0.004639808782376349\n",
      "Training Loss: 0.003630946889752522\n",
      "Training Loss: 0.0035229026788147167\n",
      "Training Loss: 0.0036073883780045435\n",
      "Validation Loss: 0.012437225499518272\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0062105642480310055\n",
      "Training Loss: 0.005744894146337174\n",
      "Training Loss: 0.006251960300724022\n",
      "Training Loss: 0.0046323940664296966\n",
      "Training Loss: 0.003626471026800573\n",
      "Training Loss: 0.0035180224193027245\n",
      "Training Loss: 0.003603900216985494\n",
      "Validation Loss: 0.012415447040837718\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006199309771764092\n",
      "Training Loss: 0.005733631507027894\n",
      "Training Loss: 0.006241610014694743\n",
      "Training Loss: 0.004625024377019144\n",
      "Training Loss: 0.0036220425058854744\n",
      "Training Loss: 0.003513188727083616\n",
      "Training Loss: 0.0036004565953044222\n",
      "Validation Loss: 0.012393454042671437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006188109896029346\n",
      "Training Loss: 0.0057224339427193625\n",
      "Training Loss: 0.006231313287862576\n",
      "Training Loss: 0.004617708813166246\n",
      "Training Loss: 0.0036176655034068973\n",
      "Training Loss: 0.0035084039060166105\n",
      "Training Loss: 0.003597059088642709\n",
      "Validation Loss: 0.012371281766653591\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006176979984156787\n",
      "Training Loss: 0.005711320872069337\n",
      "Training Loss: 0.006221083491109312\n",
      "Training Loss: 0.004610451537882909\n",
      "Training Loss: 0.003613340418669395\n",
      "Training Loss: 0.003503670705249533\n",
      "Training Loss: 0.0035937066696351393\n",
      "Validation Loss: 0.012348960520226982\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0061659290519310165\n",
      "Training Loss: 0.0057003005739534275\n",
      "Training Loss: 0.006210932056419551\n",
      "Training Loss: 0.004603261320153251\n",
      "Training Loss: 0.0036090702872024847\n",
      "Training Loss: 0.0034989893255988136\n",
      "Training Loss: 0.0035903985297773035\n",
      "Validation Loss: 0.012326517127095007\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.006154971685027703\n",
      "Training Loss: 0.005689388790051453\n",
      "Training Loss: 0.006200872811023146\n",
      "Training Loss: 0.004596138984197751\n",
      "Training Loss: 0.0036048496986040846\n",
      "Training Loss: 0.0034943561616819353\n",
      "Training Loss: 0.0035871301486622544\n",
      "Validation Loss: 0.012303971878186649\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006144119735690765\n",
      "Training Loss: 0.005678595385397785\n",
      "Training Loss: 0.006190913026221097\n",
      "Training Loss: 0.004589094140101224\n",
      "Training Loss: 0.003600686714053154\n",
      "Training Loss: 0.003489779022638686\n",
      "Training Loss: 0.003583905079285614\n",
      "Validation Loss: 0.012281379255218508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0061333827406633646\n",
      "Training Loss: 0.0056679342122515665\n",
      "Training Loss: 0.006181064479169436\n",
      "Training Loss: 0.004582127602770924\n",
      "Training Loss: 0.003596573675167747\n",
      "Training Loss: 0.003485249643563293\n",
      "Training Loss: 0.0035807164578000083\n",
      "Validation Loss: 0.012258728482797115\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.0061227743490599095\n",
      "Training Loss: 0.005657416279427707\n",
      "Training Loss: 0.006171337448176928\n",
      "Training Loss: 0.004575245886226185\n",
      "Training Loss: 0.003592514482443221\n",
      "Training Loss: 0.0034807731170440094\n",
      "Training Loss: 0.0035775650647701697\n",
      "Validation Loss: 0.0122360803170761\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006112299096421339\n",
      "Training Loss: 0.005647047495585866\n",
      "Training Loss: 0.006161738433293067\n",
      "Training Loss: 0.004568451116210781\n",
      "Training Loss: 0.0035885078727733344\n",
      "Training Loss: 0.003476348604890518\n",
      "Training Loss: 0.0035744491231162103\n",
      "Validation Loss: 0.012213457638898355\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006101968137663789\n",
      "Training Loss: 0.005636839234502986\n",
      "Training Loss: 0.006152275261702016\n",
      "Training Loss: 0.004561748469131999\n",
      "Training Loss: 0.0035845512233208866\n",
      "Training Loss: 0.003471973940031603\n",
      "Training Loss: 0.0035713640693575146\n",
      "Validation Loss: 0.012190879832723\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.006091789242927917\n",
      "Training Loss: 0.005626797549193725\n",
      "Training Loss: 0.0061429553641937674\n",
      "Training Loss: 0.0045551375980721785\n",
      "Training Loss: 0.003580643110908568\n",
      "Training Loss: 0.003467647329089232\n",
      "Training Loss: 0.0035683100536698475\n",
      "Validation Loss: 0.012168373722035424\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.006081767043797299\n",
      "Training Loss: 0.005616928397794254\n",
      "Training Loss: 0.006133780555101112\n",
      "Training Loss: 0.004548623859300278\n",
      "Training Loss: 0.003576785739278421\n",
      "Training Loss: 0.0034633719420526176\n",
      "Training Loss: 0.003565284215146676\n",
      "Validation Loss: 0.01214598440360243\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.0060719055216759445\n",
      "Training Loss: 0.005607236191863194\n",
      "Training Loss: 0.006124757617944851\n",
      "Training Loss: 0.0045422056759707626\n",
      "Training Loss: 0.003572973917471245\n",
      "Training Loss: 0.0034591438341885807\n",
      "Training Loss: 0.0035622858046554027\n",
      "Validation Loss: 0.012123722840302836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006062212839606218\n",
      "Training Loss: 0.005597726325504482\n",
      "Training Loss: 0.006115888910717331\n",
      "Training Loss: 0.004535884677316062\n",
      "Training Loss: 0.003569204857922159\n",
      "Training Loss: 0.0034549597889417783\n",
      "Training Loss: 0.0035593084275024013\n",
      "Validation Loss: 0.012101598207146446\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00605269173916895\n",
      "Training Loss: 0.005588403463480063\n",
      "Training Loss: 0.006107177148805931\n",
      "Training Loss: 0.004529660894186236\n",
      "Training Loss: 0.0035654789058025926\n",
      "Training Loss: 0.0034508211008505898\n",
      "Training Loss: 0.0035563529771752657\n",
      "Validation Loss: 0.012079639652218976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.006043341520708055\n",
      "Training Loss: 0.005579267121502199\n",
      "Training Loss: 0.006098625010345131\n",
      "Training Loss: 0.004523535944754258\n",
      "Training Loss: 0.003561791299725883\n",
      "Training Loss: 0.003446722665685229\n",
      "Training Loss: 0.003553414679481648\n",
      "Validation Loss: 0.012057849970360178\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006034169648773968\n",
      "Training Loss: 0.005570320519036613\n",
      "Training Loss: 0.006090231561101973\n",
      "Training Loss: 0.004517508302233182\n",
      "Training Loss: 0.0035581427346915006\n",
      "Training Loss: 0.003442668055649847\n",
      "Training Loss: 0.0035504952451447026\n",
      "Validation Loss: 0.012036268985420396\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.006025169612839818\n",
      "Training Loss: 0.005561561700887978\n",
      "Training Loss: 0.0060819979052757845\n",
      "Training Loss: 0.004511577657540329\n",
      "Training Loss: 0.003554529204557184\n",
      "Training Loss: 0.003438650352763943\n",
      "Training Loss: 0.0035475885833147914\n",
      "Validation Loss: 0.012014890594097475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006016350089921616\n",
      "Training Loss: 0.005552991987788119\n",
      "Training Loss: 0.006073922849609516\n",
      "Training Loss: 0.004505744090420194\n",
      "Training Loss: 0.003550952136574779\n",
      "Training Loss: 0.0034346746566006913\n",
      "Training Loss: 0.00354469847981818\n",
      "Validation Loss: 0.011993737223781366\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.00600770408520475\n",
      "Training Loss: 0.005544611322693527\n",
      "Training Loss: 0.006066006026812829\n",
      "Training Loss: 0.004500006079324521\n",
      "Training Loss: 0.0035474052737117746\n",
      "Training Loss: 0.00343073372321669\n",
      "Training Loss: 0.003541817883960903\n",
      "Validation Loss: 0.011972822144292714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005999234558548778\n",
      "Training Loss: 0.0055364163668127735\n",
      "Training Loss: 0.006058245762251318\n",
      "Training Loss: 0.004494361957767978\n",
      "Training Loss: 0.0035438892990350725\n",
      "Training Loss: 0.0034268284810241314\n",
      "Training Loss: 0.0035389479011064397\n",
      "Validation Loss: 0.011952122961160508\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005990936855669133\n",
      "Training Loss: 0.0055284047668101265\n",
      "Training Loss: 0.006050640154862777\n",
      "Training Loss: 0.00448881106916815\n",
      "Training Loss: 0.003540403312363196\n",
      "Training Loss: 0.0034229591436451302\n",
      "Training Loss: 0.0035360877943458034\n",
      "Validation Loss: 0.01193169058973758\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.005982811924186535\n",
      "Training Loss: 0.005520575115224346\n",
      "Training Loss: 0.0060431865626014766\n",
      "Training Loss: 0.0044833510258467865\n",
      "Training Loss: 0.0035369453148450703\n",
      "Training Loss: 0.003419124266365543\n",
      "Training Loss: 0.0035332371265394615\n",
      "Validation Loss: 0.01191151387987777\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005974855012027547\n",
      "Training Loss: 0.0055129232764011245\n",
      "Training Loss: 0.006035883299773559\n",
      "Training Loss: 0.004477981186355464\n",
      "Training Loss: 0.0035335119758383372\n",
      "Training Loss: 0.0034153193136444316\n",
      "Training Loss: 0.003530393093824387\n",
      "Validation Loss: 0.011891585314290578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.0059670639835530895\n",
      "Training Loss: 0.005505446230527014\n",
      "Training Loss: 0.006028726049116813\n",
      "Training Loss: 0.004472699378384277\n",
      "Training Loss: 0.0035301053035072982\n",
      "Training Loss: 0.0034115496242884545\n",
      "Training Loss: 0.0035275566641939805\n",
      "Validation Loss: 0.011871922093448804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.005959436752018519\n",
      "Training Loss: 0.005498140845447779\n",
      "Training Loss: 0.006021713759400882\n",
      "Training Loss: 0.004467503976775334\n",
      "Training Loss: 0.0035267217963701114\n",
      "Training Loss: 0.003407808759948239\n",
      "Training Loss: 0.003524726771283895\n",
      "Validation Loss: 0.011852535905101954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.005951968877925537\n",
      "Training Loss: 0.005491002898779697\n",
      "Training Loss: 0.006014841935248114\n",
      "Training Loss: 0.004462393688736483\n",
      "Training Loss: 0.0035233627184061336\n",
      "Training Loss: 0.0034041003574384375\n",
      "Training Loss: 0.0035219041089294477\n",
      "Validation Loss: 0.011833389830550576\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.005944657250656746\n",
      "Training Loss: 0.005484029753715731\n",
      "Training Loss: 0.006008108383975923\n",
      "Training Loss: 0.004457366408314556\n",
      "Training Loss: 0.0035200232156785203\n",
      "Training Loss: 0.0034004173235734924\n",
      "Training Loss: 0.0035190841130679474\n",
      "Validation Loss: 0.011814512653810004\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005937503465102054\n",
      "Training Loss: 0.005477217409061268\n",
      "Training Loss: 0.00600150999496691\n",
      "Training Loss: 0.004452420102898032\n",
      "Training Loss: 0.0035167057989747264\n",
      "Training Loss: 0.003396764988428913\n",
      "Training Loss: 0.0035162719030631708\n",
      "Validation Loss: 0.01179591413807082\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005930497383815236\n",
      "Training Loss: 0.005470559982932173\n",
      "Training Loss: 0.005995042471331544\n",
      "Training Loss: 0.004447554306825623\n",
      "Training Loss: 0.003513410590530839\n",
      "Training Loss: 0.003393143477733247\n",
      "Training Loss: 0.0035134654986904933\n",
      "Validation Loss: 0.011777569287393786\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.00592363738513086\n",
      "Training Loss: 0.005464054049225524\n",
      "Training Loss: 0.0059887034102575855\n",
      "Training Loss: 0.004442766647553071\n",
      "Training Loss: 0.0035101348627358674\n",
      "Training Loss: 0.0033895484841195865\n",
      "Training Loss: 0.0035106640501180665\n",
      "Validation Loss: 0.01175949513918305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.005916918184957467\n",
      "Training Loss: 0.005457694012438879\n",
      "Training Loss: 0.0059824861842207614\n",
      "Training Loss: 0.004438055573264137\n",
      "Training Loss: 0.0035068817468709313\n",
      "Training Loss: 0.0033859849395230413\n",
      "Training Loss: 0.003507872189511545\n",
      "Validation Loss: 0.011741704051339239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.005910335466032848\n",
      "Training Loss: 0.005451475048321299\n",
      "Training Loss: 0.005976391600561328\n",
      "Training Loss: 0.0044334193202666934\n",
      "Training Loss: 0.003503647369216196\n",
      "Training Loss: 0.0033824464137433095\n",
      "Training Loss: 0.003505082550109364\n",
      "Validation Loss: 0.0117241545632213\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.005903894336079248\n",
      "Training Loss: 0.005445400150492787\n",
      "Training Loss: 0.00597041527973488\n",
      "Training Loss: 0.004428856752929278\n",
      "Training Loss: 0.0035004321922315284\n",
      "Training Loss: 0.0033789366733981297\n",
      "Training Loss: 0.003502301332191564\n",
      "Validation Loss: 0.01170687388483965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005897578866570257\n",
      "Training Loss: 0.005439456035965122\n",
      "Training Loss: 0.005964553765370511\n",
      "Training Loss: 0.004424365200684406\n",
      "Training Loss: 0.0034972366943839006\n",
      "Training Loss: 0.003375453656190075\n",
      "Training Loss: 0.003499526567175053\n",
      "Validation Loss: 0.011689845417200653\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.0058913910103729\n",
      "Training Loss: 0.005433642975403928\n",
      "Training Loss: 0.005958802800159901\n",
      "Training Loss: 0.004419944296241738\n",
      "Training Loss: 0.003494061169330962\n",
      "Training Loss: 0.003371998100192286\n",
      "Training Loss: 0.003496757986722514\n",
      "Validation Loss: 0.011673067036051693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005885330736055039\n",
      "Training Loss: 0.005427958521177061\n",
      "Training Loss: 0.005953161639627069\n",
      "Training Loss: 0.004415591470897198\n",
      "Training Loss: 0.0034909049805719405\n",
      "Training Loss: 0.003368569750455208\n",
      "Training Loss: 0.003493997930199839\n",
      "Validation Loss: 0.011656561478351554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005879389623878524\n",
      "Training Loss: 0.005422397195943631\n",
      "Training Loss: 0.0059476264734985304\n",
      "Training Loss: 0.004411306452821009\n",
      "Training Loss: 0.0034877673123264686\n",
      "Training Loss: 0.0033651687094243244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [19:45<25:31, 306.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0034912467165850104\n",
      "Validation Loss: 0.011640277627745664\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.1321497790515423\n",
      "Training Loss: 0.10089269690215588\n",
      "Training Loss: 0.07884959110990167\n",
      "Training Loss: 0.06813116589561105\n",
      "Training Loss: 0.06315087335184216\n",
      "Training Loss: 0.0609509783051908\n",
      "Training Loss: 0.06029979791492224\n",
      "Validation Loss: 0.06247752745834629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06180105062201619\n",
      "Training Loss: 0.059009719379246234\n",
      "Training Loss: 0.056543928775936364\n",
      "Training Loss: 0.05258319356478751\n",
      "Training Loss: 0.04734129622578621\n",
      "Training Loss: 0.04381357344798744\n",
      "Training Loss: 0.04108288074843586\n",
      "Validation Loss: 0.048567963994286034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04247803253121674\n",
      "Training Loss: 0.03914690162055194\n",
      "Training Loss: 0.03606227335520089\n",
      "Training Loss: 0.0313486669678241\n",
      "Training Loss: 0.02571391699835658\n",
      "Training Loss: 0.023334791115485132\n",
      "Training Loss: 0.021528314244933427\n",
      "Validation Loss: 0.034659164675166096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.025391822466626763\n",
      "Training Loss: 0.023363446975126864\n",
      "Training Loss: 0.022064036554656923\n",
      "Training Loss: 0.01873196316882968\n",
      "Training Loss: 0.014819284449331463\n",
      "Training Loss: 0.014110101941041649\n",
      "Training Loss: 0.013227902860380709\n",
      "Validation Loss: 0.026197246478151963\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.017898019005078824\n",
      "Training Loss: 0.016695572601165623\n",
      "Training Loss: 0.01642766725970432\n",
      "Training Loss: 0.013786742032971233\n",
      "Training Loss: 0.010669209472835063\n",
      "Training Loss: 0.010496001839637756\n",
      "Training Loss: 0.00988417780259624\n",
      "Validation Loss: 0.021972292922576714\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.014551186487078666\n",
      "Training Loss: 0.01359968513250351\n",
      "Training Loss: 0.013609067511279136\n",
      "Training Loss: 0.011246646837098523\n",
      "Training Loss: 0.008564316616393626\n",
      "Training Loss: 0.008517334193456919\n",
      "Training Loss: 0.00802799476776272\n",
      "Validation Loss: 0.019658598059976704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.012375497429165988\n",
      "Training Loss: 0.011445196873974056\n",
      "Training Loss: 0.011486468380317092\n",
      "Training Loss: 0.009290013476856984\n",
      "Training Loss: 0.007090624077245593\n",
      "Training Loss: 0.007077638278715313\n",
      "Training Loss: 0.00669145962165203\n",
      "Validation Loss: 0.018835657990401548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.010501292704138904\n",
      "Training Loss: 0.009637381006032229\n",
      "Training Loss: 0.00974805888487026\n",
      "Training Loss: 0.007885084002045914\n",
      "Training Loss: 0.006185574139235542\n",
      "Training Loss: 0.006156565947458148\n",
      "Training Loss: 0.005862610053736716\n",
      "Validation Loss: 0.01828209892497834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.009367484335089103\n",
      "Training Loss: 0.008646338531980291\n",
      "Training Loss: 0.008863490048097446\n",
      "Training Loss: 0.0071578572707949204\n",
      "Training Loss: 0.005623609686736018\n",
      "Training Loss: 0.005567035152344033\n",
      "Training Loss: 0.005337633372982964\n",
      "Validation Loss: 0.01734971494609246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.008773649234790355\n",
      "Training Loss: 0.008119016303680837\n",
      "Training Loss: 0.008394458586117252\n",
      "Training Loss: 0.006711507461732253\n",
      "Training Loss: 0.00522252292605117\n",
      "Training Loss: 0.005149741184432059\n",
      "Training Loss: 0.00497371023404412\n",
      "Validation Loss: 0.016560390693212298\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.008415052365744486\n",
      "Training Loss: 0.00779080563574098\n",
      "Training Loss: 0.008100074685644358\n",
      "Training Loss: 0.0064084165135864166\n",
      "Training Loss: 0.004936925588990562\n",
      "Training Loss: 0.004848586221924051\n",
      "Training Loss: 0.004715953336562962\n",
      "Validation Loss: 0.016005507825563352\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008186102533945814\n",
      "Training Loss: 0.007577961618080735\n",
      "Training Loss: 0.007909994170768186\n",
      "Training Loss: 0.006202932976884767\n",
      "Training Loss: 0.00473774409678299\n",
      "Training Loss: 0.004635477983392775\n",
      "Training Loss: 0.004537363023264334\n",
      "Validation Loss: 0.01564523342592216\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008046275299275294\n",
      "Training Loss: 0.007446525382110849\n",
      "Training Loss: 0.007793052975321188\n",
      "Training Loss: 0.0060686947143403815\n",
      "Training Loss: 0.00460294566117227\n",
      "Training Loss: 0.004489521677023731\n",
      "Training Loss: 0.004417164867045358\n",
      "Validation Loss: 0.015419196283831942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.007964362940983847\n",
      "Training Loss: 0.00736838391632773\n",
      "Training Loss: 0.007722788187675178\n",
      "Training Loss: 0.0059815090225311\n",
      "Training Loss: 0.0045121602987637744\n",
      "Training Loss: 0.0043905307876411824\n",
      "Training Loss: 0.004336500815115869\n",
      "Validation Loss: 0.015274347386877524\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007914737940300256\n",
      "Training Loss: 0.007320355379488319\n",
      "Training Loss: 0.00767859639134258\n",
      "Training Loss: 0.005922513844561763\n",
      "Training Loss: 0.004449556965264492\n",
      "Training Loss: 0.004322370172594674\n",
      "Training Loss: 0.004281134702614509\n",
      "Validation Loss: 0.015176580178949019\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007880844727624207\n",
      "Training Loss: 0.007287411002907902\n",
      "Training Loss: 0.007647657841444016\n",
      "Training Loss: 0.00587963176483754\n",
      "Training Loss: 0.0044045987882418555\n",
      "Training Loss: 0.004274000191944651\n",
      "Training Loss: 0.004241700749844313\n",
      "Validation Loss: 0.015106995425654456\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.00785373621270992\n",
      "Training Loss: 0.007261311924085021\n",
      "Training Loss: 0.00762305821874179\n",
      "Training Loss: 0.005845918961567804\n",
      "Training Loss: 0.004370772437541745\n",
      "Training Loss: 0.004238385608186945\n",
      "Training Loss: 0.004212390117463656\n",
      "Validation Loss: 0.015055546147682553\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.007829073754837736\n",
      "Training Loss: 0.007237963431980461\n",
      "Training Loss: 0.0076013341057114304\n",
      "Training Loss: 0.005817522532888688\n",
      "Training Loss: 0.004344111928949132\n",
      "Training Loss: 0.004211119802203029\n",
      "Training Loss: 0.004189653322682716\n",
      "Validation Loss: 0.01501668129405809\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.0078048992983531205\n",
      "Training Loss: 0.007215451719239354\n",
      "Training Loss: 0.007580809096107259\n",
      "Training Loss: 0.0057922981452429665\n",
      "Training Loss: 0.004322177086141892\n",
      "Training Loss: 0.004189428151003085\n",
      "Training Loss: 0.004171292954706587\n",
      "Validation Loss: 0.014986985024284529\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007780360943870619\n",
      "Training Loss: 0.007192903629038483\n",
      "Training Loss: 0.007560671423561871\n",
      "Training Loss: 0.0057690192293375735\n",
      "Training Loss: 0.004303438136121258\n",
      "Training Loss: 0.004171528485021554\n",
      "Training Loss: 0.00415592401928734\n",
      "Validation Loss: 0.01496397400813784\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.0077551259857136755\n",
      "Training Loss: 0.007169944128254429\n",
      "Training Loss: 0.00754053320037201\n",
      "Training Loss: 0.005746959837269969\n",
      "Training Loss: 0.004286910630762577\n",
      "Training Loss: 0.00415625583846122\n",
      "Training Loss: 0.004142654059105553\n",
      "Validation Loss: 0.014945690209230875\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007729101412696764\n",
      "Training Loss: 0.007146426070248708\n",
      "Training Loss: 0.007520213522948325\n",
      "Training Loss: 0.005725682196789421\n",
      "Training Loss: 0.004271958862664178\n",
      "Training Loss: 0.0041428266244474795\n",
      "Training Loss: 0.004130892801331356\n",
      "Validation Loss: 0.014930467849007846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.00770232253242284\n",
      "Training Loss: 0.007122328276745975\n",
      "Training Loss: 0.00749964969814755\n",
      "Training Loss: 0.005704923925804906\n",
      "Training Loss: 0.004258160864119418\n",
      "Training Loss: 0.004130701944231987\n",
      "Training Loss: 0.004120236232411117\n",
      "Validation Loss: 0.014916818470376708\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.00767491186154075\n",
      "Training Loss: 0.007097701383754611\n",
      "Training Loss: 0.00747883492440451\n",
      "Training Loss: 0.005684533147723414\n",
      "Training Loss: 0.00424523841298651\n",
      "Training Loss: 0.004119492436293512\n",
      "Training Loss: 0.0041103944653877985\n",
      "Validation Loss: 0.014903538099102926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007647043337346986\n",
      "Training Loss: 0.00707264082855545\n",
      "Training Loss: 0.007457804263103753\n",
      "Training Loss: 0.005664425285649486\n",
      "Training Loss: 0.004232993763871491\n",
      "Training Loss: 0.004108898955164478\n",
      "Training Loss: 0.004101142453728244\n",
      "Validation Loss: 0.014889646045103223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007618914922932163\n",
      "Training Loss: 0.007047255749348551\n",
      "Training Loss: 0.007436597425257787\n",
      "Training Loss: 0.005644550822325982\n",
      "Training Loss: 0.004221272457507439\n",
      "Training Loss: 0.004098673230037093\n",
      "Training Loss: 0.004092284253565595\n",
      "Validation Loss: 0.01487445736073711\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007590711339144036\n",
      "Training Loss: 0.007021646643988788\n",
      "Training Loss: 0.007415238315006718\n",
      "Training Loss: 0.005624867223668843\n",
      "Training Loss: 0.004209939908469096\n",
      "Training Loss: 0.0040886022290214895\n",
      "Training Loss: 0.0040836434555239975\n",
      "Validation Loss: 0.014857558736731107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007562575681367889\n",
      "Training Loss: 0.006995887449011207\n",
      "Training Loss: 0.007393728528404609\n",
      "Training Loss: 0.005605324383941479\n",
      "Training Loss: 0.0041988636110909285\n",
      "Training Loss: 0.004078492227708921\n",
      "Training Loss: 0.004075051180552691\n",
      "Validation Loss: 0.014838726473850117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007534592921147123\n",
      "Training Loss: 0.006970006070332602\n",
      "Training Loss: 0.007372031069826335\n",
      "Training Loss: 0.00558585456747096\n",
      "Training Loss: 0.004187907373416237\n",
      "Training Loss: 0.0040681683586444705\n",
      "Training Loss: 0.004066345127648674\n",
      "Validation Loss: 0.014818042519324448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.00750677653355524\n",
      "Training Loss: 0.006943978224880993\n",
      "Training Loss: 0.0073500692698871715\n",
      "Training Loss: 0.005566367242718116\n",
      "Training Loss: 0.004176942747435532\n",
      "Training Loss: 0.004057485532830469\n",
      "Training Loss: 0.0040573823201702905\n",
      "Validation Loss: 0.0147955873728231\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0074790595914237205\n",
      "Training Loss: 0.006917725787498057\n",
      "Training Loss: 0.0073277282319031654\n",
      "Training Loss: 0.005546753376838751\n",
      "Training Loss: 0.0041658446291694415\n",
      "Training Loss: 0.004046321506029927\n",
      "Training Loss: 0.00404803344514221\n",
      "Validation Loss: 0.01477162667666998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.00745132416835986\n",
      "Training Loss: 0.006891133622266352\n",
      "Training Loss: 0.0073048660904169085\n",
      "Training Loss: 0.005526887285523117\n",
      "Training Loss: 0.004154492204543203\n",
      "Training Loss: 0.00403457309352234\n",
      "Training Loss: 0.004038179399794899\n",
      "Validation Loss: 0.01474641715542654\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007423407412134111\n",
      "Training Loss: 0.00686405070591718\n",
      "Training Loss: 0.007281316682929173\n",
      "Training Loss: 0.005506633900222368\n",
      "Training Loss: 0.00414278005482629\n",
      "Training Loss: 0.004022154734120704\n",
      "Training Loss: 0.0040277151111513376\n",
      "Validation Loss: 0.014720283370213897\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007395116476109251\n",
      "Training Loss: 0.006836311017395929\n",
      "Training Loss: 0.007256901156506501\n",
      "Training Loss: 0.005485850509139709\n",
      "Training Loss: 0.004130603556404822\n",
      "Training Loss: 0.004008988779387437\n",
      "Training Loss: 0.0040165418287506326\n",
      "Validation Loss: 0.01469353380332237\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007366246108431369\n",
      "Training Loss: 0.00680773169035092\n",
      "Training Loss: 0.007231425285572186\n",
      "Training Loss: 0.005464388540713116\n",
      "Training Loss: 0.0041178667650092395\n",
      "Training Loss: 0.0039950047706952315\n",
      "Training Loss: 0.004004563884809614\n",
      "Validation Loss: 0.014666487979929378\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.00733658398152329\n",
      "Training Loss: 0.006778128915466368\n",
      "Training Loss: 0.007204694502870552\n",
      "Training Loss: 0.005442101936787367\n",
      "Training Loss: 0.004104481198592112\n",
      "Training Loss: 0.00398013919533696\n",
      "Training Loss: 0.003991688489331863\n",
      "Validation Loss: 0.014639580844681753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.0073059211345389485\n",
      "Training Loss: 0.006747325045289472\n",
      "Training Loss: 0.007176512375008315\n",
      "Training Loss: 0.005418844819650985\n",
      "Training Loss: 0.004090349526959472\n",
      "Training Loss: 0.003964314048644156\n",
      "Training Loss: 0.003977811332442798\n",
      "Validation Loss: 0.014613256257808722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007274071507854387\n",
      "Training Loss: 0.006715158539591357\n",
      "Training Loss: 0.00714669420325663\n",
      "Training Loss: 0.005394479613751173\n",
      "Training Loss: 0.004075384892639704\n",
      "Training Loss: 0.0039474669360788535\n",
      "Training Loss: 0.003962838548468426\n",
      "Validation Loss: 0.014588062804931782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0072408582153730095\n",
      "Training Loss: 0.0066814855777192865\n",
      "Training Loss: 0.007115069684223272\n",
      "Training Loss: 0.005368890219251625\n",
      "Training Loss: 0.0040595027786912395\n",
      "Training Loss: 0.0039295273006428036\n",
      "Training Loss: 0.00394666706037242\n",
      "Validation Loss: 0.014564775936793856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007206161033827811\n",
      "Training Loss: 0.006646209290483967\n",
      "Training Loss: 0.007081509147537872\n",
      "Training Loss: 0.005341994394548237\n",
      "Training Loss: 0.004042629378382116\n",
      "Training Loss: 0.003910443956847302\n",
      "Training Loss: 0.003929219683632254\n",
      "Validation Loss: 0.014544231427767163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007169909605290741\n",
      "Training Loss: 0.006609295866219327\n",
      "Training Loss: 0.007045948321465403\n",
      "Training Loss: 0.005313779739080929\n",
      "Training Loss: 0.0040247318899491805\n",
      "Training Loss: 0.003890209212549962\n",
      "Training Loss: 0.003910456236335449\n",
      "Validation Loss: 0.014527488045990886\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007132137602893635\n",
      "Training Loss: 0.006570816254243255\n",
      "Training Loss: 0.007008438683114946\n",
      "Training Loss: 0.005284339571953751\n",
      "Training Loss: 0.0040058319614036005\n",
      "Training Loss: 0.003868877604836598\n",
      "Training Loss: 0.003890410854364745\n",
      "Validation Loss: 0.014515758984746614\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007093017677543684\n",
      "Training Loss: 0.006530988920712843\n",
      "Training Loss: 0.006969200504827313\n",
      "Training Loss: 0.005253924277494662\n",
      "Training Loss: 0.0039860532572492955\n",
      "Training Loss: 0.003846611689659767\n",
      "Training Loss: 0.003869239846826531\n",
      "Validation Loss: 0.014510245821508491\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007052895983215421\n",
      "Training Loss: 0.0064902301994152365\n",
      "Training Loss: 0.006928680606652051\n",
      "Training Loss: 0.005222970995819196\n",
      "Training Loss: 0.0039656479767290875\n",
      "Training Loss: 0.003823722814559005\n",
      "Training Loss: 0.0038472613913472743\n",
      "Validation Loss: 0.01451198722991032\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 44\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007012308635748923\n",
      "Training Loss: 0.006449159997282549\n",
      "Training Loss: 0.006887573346612044\n",
      "Training Loss: 0.005192096792161465\n",
      "Training Loss: 0.003945006789872423\n",
      "Training Loss: 0.0038006630179006607\n",
      "Training Loss: 0.0038249503850238398\n",
      "Validation Loss: 0.01452163178892283\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 45\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.006971951548475772\n",
      "Training Loss: 0.006408570786006749\n",
      "Training Loss: 0.006846766110393219\n",
      "Training Loss: 0.00516201772261411\n",
      "Training Loss: 0.003924624513019808\n",
      "Training Loss: 0.003777999813319184\n",
      "Training Loss: 0.0038029063708381727\n",
      "Validation Loss: 0.014539154380741302\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 46\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.006932535538217053\n",
      "Training Loss: 0.0063692764472216366\n",
      "Training Loss: 0.006807186423102394\n",
      "Training Loss: 0.005133396520395763\n",
      "Training Loss: 0.0039050058217253536\n",
      "Training Loss: 0.0037562977557536216\n",
      "Training Loss: 0.0037817245861515403\n",
      "Validation Loss: 0.014563801408002383\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 47\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.006894674102077261\n",
      "Training Loss: 0.00633196180104278\n",
      "Training Loss: 0.006769614417571575\n",
      "Training Loss: 0.005106691108667291\n",
      "Training Loss: 0.0038865671161329375\n",
      "Training Loss: 0.0037360149133019147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [21:23<15:42, 235.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0037618725578067824\n",
      "Validation Loss: 0.014594321588249633\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 48\n",
      "Early stopping after 48 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.31079083777964117\n",
      "Training Loss: 0.24078349240124225\n",
      "Training Loss: 0.17319303963333368\n",
      "Training Loss: 0.11933041768148542\n",
      "Training Loss: 0.08250319814309477\n",
      "Training Loss: 0.06370168929919601\n",
      "Training Loss: 0.058200292848050596\n",
      "Validation Loss: 0.059366310357154534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.05881585769355297\n",
      "Training Loss: 0.05509495312348008\n",
      "Training Loss: 0.052352508660405875\n",
      "Training Loss: 0.04844772175885737\n",
      "Training Loss: 0.04316872539930046\n",
      "Training Loss: 0.0402306304872036\n",
      "Training Loss: 0.037973133781924844\n",
      "Validation Loss: 0.04333234946016738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.03946575007401407\n",
      "Training Loss: 0.03561862749047577\n",
      "Training Loss: 0.03294082033447921\n",
      "Training Loss: 0.028894610591232776\n",
      "Training Loss: 0.02360920258332044\n",
      "Training Loss: 0.021418206845410168\n",
      "Training Loss: 0.019537863908335566\n",
      "Validation Loss: 0.029258468076726246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.02273315701633692\n",
      "Training Loss: 0.020513123399578035\n",
      "Training Loss: 0.019573591416701674\n",
      "Training Loss: 0.0166851793252863\n",
      "Training Loss: 0.012955080664251\n",
      "Training Loss: 0.012487374627962709\n",
      "Training Loss: 0.011783767133019865\n",
      "Validation Loss: 0.02364768764555231\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.016466355726588517\n",
      "Training Loss: 0.01533811256987974\n",
      "Training Loss: 0.015493513136170804\n",
      "Training Loss: 0.013014911278150975\n",
      "Training Loss: 0.009999032921623439\n",
      "Training Loss: 0.009981052345829085\n",
      "Training Loss: 0.009524268334498629\n",
      "Validation Loss: 0.021274695157209474\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.014234602588694543\n",
      "Training Loss: 0.01323244619416073\n",
      "Training Loss: 0.013550596595741808\n",
      "Training Loss: 0.011059276923770085\n",
      "Training Loss: 0.00831105571007356\n",
      "Training Loss: 0.008262187890941276\n",
      "Training Loss: 0.007819648406002671\n",
      "Validation Loss: 0.01874414487822114\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.012111066485522315\n",
      "Training Loss: 0.011138584527652711\n",
      "Training Loss: 0.011461650258861483\n",
      "Training Loss: 0.009166352668544278\n",
      "Training Loss: 0.006883289985125884\n",
      "Training Loss: 0.006854302891297266\n",
      "Training Loss: 0.00660369832883589\n",
      "Validation Loss: 0.017256438940561163\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.010815792998764664\n",
      "Training Loss: 0.010021396279335022\n",
      "Training Loss: 0.010395967467920854\n",
      "Training Loss: 0.00826087398803793\n",
      "Training Loss: 0.006208310863003135\n",
      "Training Loss: 0.006166026906576008\n",
      "Training Loss: 0.005998554569669068\n",
      "Validation Loss: 0.016352057773515248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.010090009872801602\n",
      "Training Loss: 0.009363197793718428\n",
      "Training Loss: 0.009742489851778374\n",
      "Training Loss: 0.007656293331529014\n",
      "Training Loss: 0.005728758440236561\n",
      "Training Loss: 0.005679143787710927\n",
      "Training Loss: 0.005559528894955292\n",
      "Validation Loss: 0.015568514099023706\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.009543271948350593\n",
      "Training Loss: 0.008872845551231877\n",
      "Training Loss: 0.009255697692278773\n",
      "Training Loss: 0.007201558060478419\n",
      "Training Loss: 0.005369085388956592\n",
      "Training Loss: 0.005317516134819016\n",
      "Training Loss: 0.005230803639278747\n",
      "Validation Loss: 0.014925515851222175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.009124221203383059\n",
      "Training Loss: 0.008499551354907453\n",
      "Training Loss: 0.00888535953592509\n",
      "Training Loss: 0.006860767724574544\n",
      "Training Loss: 0.0051075533946277575\n",
      "Training Loss: 0.005057803830713965\n",
      "Training Loss: 0.004993713546427898\n",
      "Validation Loss: 0.014409168220512318\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008802443468011916\n",
      "Training Loss: 0.008214517245069147\n",
      "Training Loss: 0.008605097179533915\n",
      "Training Loss: 0.006611069522914476\n",
      "Training Loss: 0.0049248333385912705\n",
      "Training Loss: 0.0048775603523245085\n",
      "Training Loss: 0.004828296414925717\n",
      "Validation Loss: 0.014000563995654552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008556813579052686\n",
      "Training Loss: 0.007997532365843654\n",
      "Training Loss: 0.008394296958576887\n",
      "Training Loss: 0.006429549711174332\n",
      "Training Loss: 0.004797906725434587\n",
      "Training Loss: 0.004751872743363492\n",
      "Training Loss: 0.004711936395033263\n",
      "Validation Loss: 0.013677854649896981\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008369165332987904\n",
      "Training Loss: 0.007831666065612808\n",
      "Training Loss: 0.008234646046767012\n",
      "Training Loss: 0.006295055854716338\n",
      "Training Loss: 0.004706379332346842\n",
      "Training Loss: 0.004660023284959607\n",
      "Training Loss: 0.004626132727134973\n",
      "Validation Loss: 0.013420498828762926\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008224334813421592\n",
      "Training Loss: 0.007703302962472663\n",
      "Training Loss: 0.008111660934519023\n",
      "Training Loss: 0.006191905747982673\n",
      "Training Loss: 0.004636433885898441\n",
      "Training Loss: 0.0045885315461782735\n",
      "Training Loss: 0.004558997314306907\n",
      "Validation Loss: 0.01321225976161589\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.00811094238073565\n",
      "Training Loss: 0.007602422565687448\n",
      "Training Loss: 0.00801507840747945\n",
      "Training Loss: 0.006110023651272059\n",
      "Training Loss: 0.004580084508052096\n",
      "Training Loss: 0.004529821231844835\n",
      "Training Loss: 0.004503863754216582\n",
      "Validation Loss: 0.013041586657874426\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008020959737477825\n",
      "Training Loss: 0.007521983698243275\n",
      "Training Loss: 0.007937969097401947\n",
      "Training Loss: 0.006043303300393745\n",
      "Training Loss: 0.004533036248176359\n",
      "Training Loss: 0.0044799262273591016\n",
      "Training Loss: 0.004457224025391043\n",
      "Validation Loss: 0.012900611925050477\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.007948844500351698\n",
      "Training Loss: 0.007457115462748334\n",
      "Training Loss: 0.007875702143646777\n",
      "Training Loss: 0.005988062709802761\n",
      "Training Loss: 0.00449301193759311\n",
      "Training Loss: 0.0044368056784151125\n",
      "Training Loss: 0.004417238825117238\n",
      "Validation Loss: 0.012783984347134968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007890719806309789\n",
      "Training Loss: 0.007404409057926387\n",
      "Training Loss: 0.007825104198418557\n",
      "Training Loss: 0.005941979544004426\n",
      "Training Loss: 0.004458727422752417\n",
      "Training Loss: 0.004399351446772925\n",
      "Training Loss: 0.004382874551811256\n",
      "Validation Loss: 0.012687917354024863\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007843793655047194\n",
      "Training Loss: 0.007361411690944806\n",
      "Training Loss: 0.0077839057252276685\n",
      "Training Loss: 0.0059034667757805435\n",
      "Training Loss: 0.004429362369701266\n",
      "Training Loss: 0.004366873317048885\n",
      "Training Loss: 0.004353448007022962\n",
      "Validation Loss: 0.012609540111182977\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007805935867363587\n",
      "Training Loss: 0.007326265285955742\n",
      "Training Loss: 0.007750364993698895\n",
      "Training Loss: 0.005871316838893108\n",
      "Training Loss: 0.004404287571087479\n",
      "Training Loss: 0.0043388415896333755\n",
      "Training Loss: 0.00432840699038934\n",
      "Validation Loss: 0.012546537063792627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007775438959943131\n",
      "Training Loss: 0.007297487674513832\n",
      "Training Loss: 0.007723065088503063\n",
      "Training Loss: 0.005844526352011599\n",
      "Training Loss: 0.004382954187458381\n",
      "Training Loss: 0.0043147784611210225\n",
      "Training Loss: 0.004307236091117375\n",
      "Validation Loss: 0.012496883874978828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007750871209427714\n",
      "Training Loss: 0.0072738549066707495\n",
      "Training Loss: 0.007700805763015524\n",
      "Training Loss: 0.005822214921936393\n",
      "Training Loss: 0.0043648473458597434\n",
      "Training Loss: 0.004294217650895007\n",
      "Training Loss: 0.0042894317186437545\n",
      "Validation Loss: 0.012458758198478248\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.0077310155192390085\n",
      "Training Loss: 0.007254332018783316\n",
      "Training Loss: 0.007682555156061426\n",
      "Training Loss: 0.005803599110222422\n",
      "Training Loss: 0.004349485808052123\n",
      "Training Loss: 0.004276706457021646\n",
      "Training Loss: 0.00427450641989708\n",
      "Validation Loss: 0.01243048362139166\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007714832368073985\n",
      "Training Loss: 0.0072380431939382105\n",
      "Training Loss: 0.007667428229469806\n",
      "Training Loss: 0.005787982672336512\n",
      "Training Loss: 0.004336419611354359\n",
      "Training Loss: 0.004261806983267888\n",
      "Training Loss: 0.004261998783913441\n",
      "Validation Loss: 0.01241056829227016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.00770144920097664\n",
      "Training Loss: 0.007224252392770723\n",
      "Training Loss: 0.007654676490928978\n",
      "Training Loss: 0.0057747583149466665\n",
      "Training Loss: 0.004325248340028338\n",
      "Training Loss: 0.004249111862736754\n",
      "Training Loss: 0.004251485924469307\n",
      "Validation Loss: 0.012397618693550735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007690143653890118\n",
      "Training Loss: 0.007212353664217516\n",
      "Training Loss: 0.007643685237271711\n",
      "Training Loss: 0.0057634135306579995\n",
      "Training Loss: 0.0043156176659977065\n",
      "Training Loss: 0.0042382578138494865\n",
      "Training Loss: 0.0042425991018535565\n",
      "Validation Loss: 0.01239046210742273\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.0076803333521820605\n",
      "Training Loss: 0.007201857964973897\n",
      "Training Loss: 0.00763396015507169\n",
      "Training Loss: 0.0057535197713878\n",
      "Training Loss: 0.004307228843681514\n",
      "Training Loss: 0.004228920330060646\n",
      "Training Loss: 0.004235017015016638\n",
      "Validation Loss: 0.012388019116633757\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007671563965268433\n",
      "Training Loss: 0.007192379649495706\n",
      "Training Loss: 0.007625115630216897\n",
      "Training Loss: 0.005744730258011259\n",
      "Training Loss: 0.004299829081865028\n",
      "Training Loss: 0.004220823358045891\n",
      "Training Loss: 0.004228472066461109\n",
      "Validation Loss: 0.012389451258794896\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 29\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007663491736166179\n",
      "Training Loss: 0.007183622723678127\n",
      "Training Loss: 0.007616859982954338\n",
      "Training Loss: 0.005736768687493168\n",
      "Training Loss: 0.004293212566990405\n",
      "Training Loss: 0.004213733808137476\n",
      "Training Loss: 0.004222743540885858\n",
      "Validation Loss: 0.012393984142237444\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 30\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007655858412617817\n",
      "Training Loss: 0.007175363728310913\n",
      "Training Loss: 0.007608974860049784\n",
      "Training Loss: 0.005729420953430236\n",
      "Training Loss: 0.00428721361211501\n",
      "Training Loss: 0.004207455766154453\n",
      "Training Loss: 0.004217653206433169\n",
      "Validation Loss: 0.012401037542969128\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 31\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007648477968759834\n",
      "Training Loss: 0.007167437104508281\n",
      "Training Loss: 0.007601307055447251\n",
      "Training Loss: 0.0057225214265054095\n",
      "Training Loss: 0.004281699591665529\n",
      "Training Loss: 0.004201833119732328\n",
      "Training Loss: 0.004213061663904227\n",
      "Validation Loss: 0.012410095964352625\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 32\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.0076412217644974585\n",
      "Training Loss: 0.007159723945660517\n",
      "Training Loss: 0.007593744231853634\n",
      "Training Loss: 0.005715944174444303\n",
      "Training Loss: 0.0042765642172889785\n",
      "Training Loss: 0.004196732392301783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [22:30<09:01, 180.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0042088540608529006\n",
      "Validation Loss: 0.012420775414591006\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 33\n",
      "Early stopping after 33 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.07799619039520621\n",
      "Training Loss: 0.07130253253504634\n",
      "Training Loss: 0.06760810233652592\n",
      "Training Loss: 0.06275586653500795\n",
      "Training Loss: 0.05689685393124819\n",
      "Training Loss: 0.05182112567126751\n",
      "Training Loss: 0.047532343436032534\n",
      "Validation Loss: 0.05136042261279924\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.04665457395836711\n",
      "Training Loss: 0.040268490444868806\n",
      "Training Loss: 0.03586593573912978\n",
      "Training Loss: 0.02979255666024983\n",
      "Training Loss: 0.02340794652234763\n",
      "Training Loss: 0.02054548243060708\n",
      "Training Loss: 0.018370892726816235\n",
      "Validation Loss: 0.030844974066462187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.02173208090942353\n",
      "Training Loss: 0.019316591247916223\n",
      "Training Loss: 0.018414693092927335\n",
      "Training Loss: 0.015309928625356406\n",
      "Training Loss: 0.011827435605227947\n",
      "Training Loss: 0.011465282962890342\n",
      "Training Loss: 0.010665397397242487\n",
      "Validation Loss: 0.022909670107220108\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.015199484867043794\n",
      "Training Loss: 0.014153515184298159\n",
      "Training Loss: 0.014287052704021334\n",
      "Training Loss: 0.011840088353492319\n",
      "Training Loss: 0.009026845778571442\n",
      "Training Loss: 0.009039965769043192\n",
      "Training Loss: 0.008479148178594187\n",
      "Validation Loss: 0.01994244855469309\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.013032374860486015\n",
      "Training Loss: 0.012210546266287566\n",
      "Training Loss: 0.012480924502015114\n",
      "Training Loss: 0.010220739825163036\n",
      "Training Loss: 0.007683547759661451\n",
      "Training Loss: 0.007740250616334379\n",
      "Training Loss: 0.007291706051910296\n",
      "Validation Loss: 0.018210277208981666\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.011709004899021238\n",
      "Training Loss: 0.010974983407650143\n",
      "Training Loss: 0.011263869082322344\n",
      "Training Loss: 0.00912799914018251\n",
      "Training Loss: 0.006822558424901217\n",
      "Training Loss: 0.00688038783846423\n",
      "Training Loss: 0.006527803746284917\n",
      "Validation Loss: 0.017160471836593322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.010791047174716368\n",
      "Training Loss: 0.01011104707722552\n",
      "Training Loss: 0.010407377080991865\n",
      "Training Loss: 0.008362158861127683\n",
      "Training Loss: 0.0062532534066122025\n",
      "Training Loss: 0.0063032074249349535\n",
      "Training Loss: 0.006020547306980007\n",
      "Validation Loss: 0.01650111382209769\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.01012225121143274\n",
      "Training Loss: 0.009472207735525444\n",
      "Training Loss: 0.009777124127140269\n",
      "Training Loss: 0.007795350177912041\n",
      "Training Loss: 0.0058452202775515615\n",
      "Training Loss: 0.005897643702337518\n",
      "Training Loss: 0.005654411255382002\n",
      "Validation Loss: 0.015974261865982515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.009605176344048233\n",
      "Training Loss: 0.009003654302796349\n",
      "Training Loss: 0.009332084760535509\n",
      "Training Loss: 0.007399122953647748\n",
      "Training Loss: 0.005564643935067579\n",
      "Training Loss: 0.0056070636166259645\n",
      "Training Loss: 0.005397698183078319\n",
      "Validation Loss: 0.015552316464427928\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.009259303386788814\n",
      "Training Loss: 0.008680905712535604\n",
      "Training Loss: 0.009023304015863686\n",
      "Training Loss: 0.007112759246956557\n",
      "Training Loss: 0.005356812920072116\n",
      "Training Loss: 0.005389267285354435\n",
      "Training Loss: 0.005205709835863672\n",
      "Validation Loss: 0.01520570324583865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.009004907123744488\n",
      "Training Loss: 0.008439954159548506\n",
      "Training Loss: 0.008793075921712443\n",
      "Training Loss: 0.006893536702264101\n",
      "Training Loss: 0.005195565757458098\n",
      "Training Loss: 0.005218822348397225\n",
      "Training Loss: 0.005056123154936358\n",
      "Validation Loss: 0.014918476762598876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008805769780883566\n",
      "Training Loss: 0.008249734742566944\n",
      "Training Loss: 0.008611034149071202\n",
      "Training Loss: 0.006717600466217845\n",
      "Training Loss: 0.005066261981846764\n",
      "Training Loss: 0.005081395144225098\n",
      "Training Loss: 0.00493632291443646\n",
      "Validation Loss: 0.01468066435328193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.00864156094728969\n",
      "Training Loss: 0.008092509401030838\n",
      "Training Loss: 0.0084601497114636\n",
      "Training Loss: 0.0065714283037232235\n",
      "Training Loss: 0.004960164127405733\n",
      "Training Loss: 0.004968138200347312\n",
      "Training Loss: 0.004838383595342748\n",
      "Validation Loss: 0.014483224035481388\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008501298545161263\n",
      "Training Loss: 0.007958477021893486\n",
      "Training Loss: 0.008331134716281668\n",
      "Training Loss: 0.006447227403987199\n",
      "Training Loss: 0.004871548958471976\n",
      "Training Loss: 0.0048731149703962725\n",
      "Training Loss: 0.004756836786982604\n",
      "Validation Loss: 0.01431761636339435\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008379256391199305\n",
      "Training Loss: 0.00784232146688737\n",
      "Training Loss: 0.00821897758753039\n",
      "Training Loss: 0.00634029158973135\n",
      "Training Loss: 0.0047963815444381904\n",
      "Training Loss: 0.004792126570246183\n",
      "Training Loss: 0.004687715715845115\n",
      "Validation Loss: 0.014176120053739583\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008272350737825037\n",
      "Training Loss: 0.007741026401054114\n",
      "Training Loss: 0.008120829546824098\n",
      "Training Loss: 0.006247523445636034\n",
      "Training Loss: 0.004731708598555997\n",
      "Training Loss: 0.0047221255698241295\n",
      "Training Loss: 0.004628111267229542\n",
      "Validation Loss: 0.014052506029598889\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008178663700819015\n",
      "Training Loss: 0.007652615007245913\n",
      "Training Loss: 0.008034805395873264\n",
      "Training Loss: 0.0061666648578830065\n",
      "Training Loss: 0.004675343930139206\n",
      "Training Loss: 0.004660876464913599\n",
      "Training Loss: 0.004575917316833511\n",
      "Validation Loss: 0.013942242291326939\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.008096673734253273\n",
      "Training Loss: 0.0075754977762699125\n",
      "Training Loss: 0.007959394142962992\n",
      "Training Loss: 0.006095927846617996\n",
      "Training Loss: 0.004625691957189701\n",
      "Training Loss: 0.004606746947974898\n",
      "Training Loss: 0.0045296402147505434\n",
      "Validation Loss: 0.013842427741199006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.008024984045187011\n",
      "Training Loss: 0.007508218900766223\n",
      "Training Loss: 0.007893216715892777\n",
      "Training Loss: 0.00603382256696932\n",
      "Training Loss: 0.00458159894333221\n",
      "Training Loss: 0.004558550583315082\n",
      "Training Loss: 0.004488242806401104\n",
      "Validation Loss: 0.013751331611260883\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007962240325286984\n",
      "Training Loss: 0.007449400564655662\n",
      "Training Loss: 0.007834980350453406\n",
      "Training Loss: 0.00597908521653153\n",
      "Training Loss: 0.004542234719265252\n",
      "Training Loss: 0.00451541829330381\n",
      "Training Loss: 0.004451002539135516\n",
      "Validation Loss: 0.013668044342062948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007907165989745408\n",
      "Training Loss: 0.007397763032931834\n",
      "Training Loss: 0.007783492715097964\n",
      "Training Loss: 0.005930647067143582\n",
      "Training Loss: 0.004506991624948569\n",
      "Training Loss: 0.00447670382913202\n",
      "Training Loss: 0.004417401520186104\n",
      "Validation Loss: 0.01359208285449289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007858597999438643\n",
      "Training Loss: 0.007352159629808739\n",
      "Training Loss: 0.007737684714375064\n",
      "Training Loss: 0.005887600312125869\n",
      "Training Loss: 0.004475400385563262\n",
      "Training Loss: 0.004441900359233841\n",
      "Training Loss: 0.004387047841446474\n",
      "Validation Loss: 0.013523067270531161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.007815504671307281\n",
      "Training Loss: 0.007311586962314323\n",
      "Training Loss: 0.0076966282143257556\n",
      "Training Loss: 0.005849176087649539\n",
      "Training Loss: 0.00444707790738903\n",
      "Training Loss: 0.004410593067877926\n",
      "Training Loss: 0.004359620236209593\n",
      "Validation Loss: 0.013460656085177167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007776989219710231\n",
      "Training Loss: 0.0072751904523465786\n",
      "Training Loss: 0.00765952720073983\n",
      "Training Loss: 0.005814720522612333\n",
      "Training Loss: 0.00442169179499615\n",
      "Training Loss: 0.004382422656053677\n",
      "Training Loss: 0.00433483999571763\n",
      "Validation Loss: 0.013404465499351478\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007742287304718047\n",
      "Training Loss: 0.0072422489244490865\n",
      "Training Loss: 0.007625713694142178\n",
      "Training Loss: 0.0057836780708748845\n",
      "Training Loss: 0.004398941958788783\n",
      "Training Loss: 0.004357069564284757\n",
      "Training Loss: 0.004312450711731799\n",
      "Validation Loss: 0.013354025506030782\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007710757517488673\n",
      "Training Loss: 0.007212166781537235\n",
      "Training Loss: 0.0075946348148863765\n",
      "Training Loss: 0.005755569175234996\n",
      "Training Loss: 0.004378548953100108\n",
      "Training Loss: 0.004334238506271504\n",
      "Training Loss: 0.004292212220607325\n",
      "Validation Loss: 0.013308827234222815\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.007681861751480028\n",
      "Training Loss: 0.007184453218942508\n",
      "Training Loss: 0.0075658319378271695\n",
      "Training Loss: 0.005729984692297876\n",
      "Training Loss: 0.004360251746256836\n",
      "Training Loss: 0.004313656166777946\n",
      "Training Loss: 0.004273898440296762\n",
      "Validation Loss: 0.013268323361870138\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007655150942737237\n",
      "Training Loss: 0.007158700581640005\n",
      "Training Loss: 0.00753892732784152\n",
      "Training Loss: 0.0057065748464083296\n",
      "Training Loss: 0.004343811969156377\n",
      "Training Loss: 0.004295074008987285\n",
      "Training Loss: 0.004257299116579816\n",
      "Validation Loss: 0.01323201249123373\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007630253782263025\n",
      "Training Loss: 0.007134577634278685\n",
      "Training Loss: 0.007513610851019621\n",
      "Training Loss: 0.005685035145143047\n",
      "Training Loss: 0.004329006742336787\n",
      "Training Loss: 0.004278263498563319\n",
      "Training Loss: 0.004242219000589103\n",
      "Validation Loss: 0.013199434728598858\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007606858676299452\n",
      "Training Loss: 0.007111808456247672\n",
      "Training Loss: 0.0074896276637446135\n",
      "Training Loss: 0.005665103928186\n",
      "Training Loss: 0.004315633787191473\n",
      "Training Loss: 0.004263017912162468\n",
      "Training Loss: 0.0042284790502162654\n",
      "Validation Loss: 0.01317012276237112\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.007584707280620932\n",
      "Training Loss: 0.007090169035363942\n",
      "Training Loss: 0.007466764980927109\n",
      "Training Loss: 0.0056465539999771865\n",
      "Training Loss: 0.004303509332239628\n",
      "Training Loss: 0.004249144964269362\n",
      "Training Loss: 0.004215912773506716\n",
      "Validation Loss: 0.013143713565539806\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007563583495793864\n",
      "Training Loss: 0.007069471416762099\n",
      "Training Loss: 0.007444848814047873\n",
      "Training Loss: 0.005629188747843727\n",
      "Training Loss: 0.00429246618237812\n",
      "Training Loss: 0.004236475439392961\n",
      "Training Loss: 0.004204373880638741\n",
      "Validation Loss: 0.013119847985936768\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.00754331341595389\n",
      "Training Loss: 0.007049564262852073\n",
      "Training Loss: 0.007423736443743109\n",
      "Training Loss: 0.005612842565169558\n",
      "Training Loss: 0.004282361107179895\n",
      "Training Loss: 0.004224861402763054\n",
      "Training Loss: 0.004193731812993064\n",
      "Validation Loss: 0.013098255800055374\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007523748226230964\n",
      "Training Loss: 0.007030322611099109\n",
      "Training Loss: 0.007403310333611444\n",
      "Training Loss: 0.00559736983210314\n",
      "Training Loss: 0.004273061787243932\n",
      "Training Loss: 0.004214165897574276\n",
      "Training Loss: 0.00418386715638917\n",
      "Validation Loss: 0.013078682079705434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.007504765194607898\n",
      "Training Loss: 0.007011641199933365\n",
      "Training Loss: 0.007383473578374833\n",
      "Training Loss: 0.005582646324764937\n",
      "Training Loss: 0.004264454114600085\n",
      "Training Loss: 0.0042042705207131804\n",
      "Training Loss: 0.004174676982220262\n",
      "Validation Loss: 0.013060894001219491\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.0074862668942660094\n",
      "Training Loss: 0.0069934380613267426\n",
      "Training Loss: 0.007364147829357535\n",
      "Training Loss: 0.00556856673094444\n",
      "Training Loss: 0.004256436747382395\n",
      "Training Loss: 0.004195070008863695\n",
      "Training Loss: 0.0041660701204091315\n",
      "Validation Loss: 0.01304473423604829\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007468169325729832\n",
      "Training Loss: 0.006975642489269376\n",
      "Training Loss: 0.007345267491182313\n",
      "Training Loss: 0.0055550419632345435\n",
      "Training Loss: 0.0042489233100786805\n",
      "Training Loss: 0.004186470722197555\n",
      "Training Loss: 0.004157963346806355\n",
      "Validation Loss: 0.013030019348525627\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007450412384932861\n",
      "Training Loss: 0.006958203648682684\n",
      "Training Loss: 0.007326785334153101\n",
      "Training Loss: 0.005541994603117928\n",
      "Training Loss: 0.004241835077409633\n",
      "Training Loss: 0.004178391416207888\n",
      "Training Loss: 0.004150286604999565\n",
      "Validation Loss: 0.013016574105251344\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.0074329442228190604\n",
      "Training Loss: 0.00694107765564695\n",
      "Training Loss: 0.007308661927236244\n",
      "Training Loss: 0.005529360503423959\n",
      "Training Loss: 0.004235100520309061\n",
      "Training Loss: 0.004170755132799968\n",
      "Training Loss: 0.004142975729191676\n",
      "Validation Loss: 0.013004295202669746\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.0074157249520067125\n",
      "Training Loss: 0.006924233633326366\n",
      "Training Loss: 0.007290868959389627\n",
      "Training Loss: 0.005517086596228182\n",
      "Training Loss: 0.004228664635447786\n",
      "Training Loss: 0.0041635020333342255\n",
      "Training Loss: 0.004135976586258039\n",
      "Validation Loss: 0.012993032810337535\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007398729205597192\n",
      "Training Loss: 0.006907647299813107\n",
      "Training Loss: 0.007273384383879602\n",
      "Training Loss: 0.005505125127965585\n",
      "Training Loss: 0.004222467522486113\n",
      "Training Loss: 0.0041565686528338116\n",
      "Training Loss: 0.004129237753222697\n",
      "Validation Loss: 0.012982633465827767\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007381938928738237\n",
      "Training Loss: 0.006891304505988956\n",
      "Training Loss: 0.007256195317022502\n",
      "Training Loss: 0.005493440826539881\n",
      "Training Loss: 0.004216469715465791\n",
      "Training Loss: 0.004149909652769565\n",
      "Training Loss: 0.004122719574952498\n",
      "Validation Loss: 0.012973006981711012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007365336020011454\n",
      "Training Loss: 0.006875190478749574\n",
      "Training Loss: 0.007239292239537462\n",
      "Training Loss: 0.005482004751684144\n",
      "Training Loss: 0.004210630142479204\n",
      "Training Loss: 0.0041434800165006894\n",
      "Training Loss: 0.004116383834625595\n",
      "Validation Loss: 0.012964018399928338\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007348917981144041\n",
      "Training Loss: 0.006859303617384285\n",
      "Training Loss: 0.007222673465148546\n",
      "Training Loss: 0.00547078852483537\n",
      "Training Loss: 0.004204910099506378\n",
      "Training Loss: 0.0041372361622052265\n",
      "Training Loss: 0.004110193207161501\n",
      "Validation Loss: 0.012955518067493505\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007332689110189677\n",
      "Training Loss: 0.006843645579647273\n",
      "Training Loss: 0.007206341500859708\n",
      "Training Loss: 0.005459774001501501\n",
      "Training Loss: 0.004199279151507653\n",
      "Training Loss: 0.004131143048289232\n",
      "Training Loss: 0.004104122282005847\n",
      "Validation Loss: 0.012947407415945933\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007316649123094976\n",
      "Training Loss: 0.006828216699650511\n",
      "Training Loss: 0.007190298884524964\n",
      "Training Loss: 0.005448944515082985\n",
      "Training Loss: 0.004193714399589226\n",
      "Training Loss: 0.004125173821812496\n",
      "Training Loss: 0.004098146753385663\n",
      "Validation Loss: 0.012939589299533642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.007300808356376365\n",
      "Training Loss: 0.006813024949515238\n",
      "Training Loss: 0.007174554016091861\n",
      "Training Loss: 0.005438287649885751\n",
      "Training Loss: 0.004188187325489708\n",
      "Training Loss: 0.004119298281730153\n",
      "Training Loss: 0.004092242984916084\n",
      "Validation Loss: 0.012931908894162835\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007285175235010683\n",
      "Training Loss: 0.0067980779975187035\n",
      "Training Loss: 0.007159115467220545\n",
      "Training Loss: 0.005427793046110309\n",
      "Training Loss: 0.004182681746315211\n",
      "Training Loss: 0.00411349170783069\n",
      "Training Loss: 0.0040863904351135715\n",
      "Validation Loss: 0.012924304840238661\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007269765854580328\n",
      "Training Loss: 0.006783385573653504\n",
      "Training Loss: 0.007143990430049599\n",
      "Training Loss: 0.005417453100671992\n",
      "Training Loss: 0.0041771799873095\n",
      "Training Loss: 0.004107735581346788\n",
      "Training Loss: 0.004080577782006003\n",
      "Validation Loss: 0.012916662003443845\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007254590983502567\n",
      "Training Loss: 0.006768957141321153\n",
      "Training Loss: 0.007129190587438643\n",
      "Training Loss: 0.005407261929358356\n",
      "Training Loss: 0.004171667116461322\n",
      "Training Loss: 0.004102009258349426\n",
      "Training Loss: 0.004074788619764149\n",
      "Validation Loss: 0.012908884880049258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.007239666391396895\n",
      "Training Loss: 0.006754802366485819\n",
      "Training Loss: 0.007114724522689357\n",
      "Training Loss: 0.00539721584354993\n",
      "Training Loss: 0.00416613558656536\n",
      "Training Loss: 0.004096303990809247\n",
      "Training Loss: 0.0040690152940806\n",
      "Validation Loss: 0.012900910928430322\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007225004819920286\n",
      "Training Loss: 0.0067409293522359805\n",
      "Training Loss: 0.007100598552497104\n",
      "Training Loss: 0.005387311136582866\n",
      "Training Loss: 0.004160575115238316\n",
      "Training Loss: 0.004090600206400268\n",
      "Training Loss: 0.004063246081350371\n",
      "Validation Loss: 0.012892650509661253\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007210620905971155\n",
      "Training Loss: 0.006727349795401096\n",
      "Training Loss: 0.007086821577977389\n",
      "Training Loss: 0.005377542650094256\n",
      "Training Loss: 0.0041549758188193665\n",
      "Training Loss: 0.004084889045916498\n",
      "Training Loss: 0.004057474539731629\n",
      "Validation Loss: 0.01288406305714451\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.0071965269825886935\n",
      "Training Loss: 0.006714067414868623\n",
      "Training Loss: 0.007073396731284447\n",
      "Training Loss: 0.005367910049390048\n",
      "Training Loss: 0.004149338475544937\n",
      "Training Loss: 0.004079166451701894\n",
      "Training Loss: 0.004051698402618058\n",
      "Validation Loss: 0.012875116442431337\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007182734716916456\n",
      "Training Loss: 0.006701090396381915\n",
      "Training Loss: 0.007060330164968036\n",
      "Training Loss: 0.005358411115012131\n",
      "Training Loss: 0.004143657407257706\n",
      "Training Loss: 0.004073421973153017\n",
      "Training Loss: 0.004045912086730823\n",
      "Validation Loss: 0.012865762686276675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.0071692490472923965\n",
      "Training Loss: 0.0066884181118803095\n",
      "Training Loss: 0.007047618377255276\n",
      "Training Loss: 0.005349040438304655\n",
      "Training Loss: 0.004137932482408359\n",
      "Training Loss: 0.0040676531987264754\n",
      "Training Loss: 0.004040114677627571\n",
      "Validation Loss: 0.012856007087539728\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007156079629203305\n",
      "Training Loss: 0.006676053244154901\n",
      "Training Loss: 0.007035261059645564\n",
      "Training Loss: 0.005339799101930112\n",
      "Training Loss: 0.004132167500210926\n",
      "Training Loss: 0.004061858446220867\n",
      "Training Loss: 0.004034305800450966\n",
      "Validation Loss: 0.012845815100082744\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.007143229108769447\n",
      "Training Loss: 0.006663993782713078\n",
      "Training Loss: 0.007023253939114511\n",
      "Training Loss: 0.005330680767656304\n",
      "Training Loss: 0.004126358951325528\n",
      "Training Loss: 0.004056034334353171\n",
      "Training Loss: 0.004028486474999227\n",
      "Validation Loss: 0.012835235900876953\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007130697082029656\n",
      "Training Loss: 0.006652234719949774\n",
      "Training Loss: 0.00701159059186466\n",
      "Training Loss: 0.005321684858645312\n",
      "Training Loss: 0.004120511459186673\n",
      "Training Loss: 0.00405018114077393\n",
      "Training Loss: 0.004022654537693598\n",
      "Validation Loss: 0.012824256318422515\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007118484831880778\n",
      "Training Loss: 0.006640773284598254\n",
      "Training Loss: 0.007000262609217316\n",
      "Training Loss: 0.005312805699068121\n",
      "Training Loss: 0.0041146269923774525\n",
      "Training Loss: 0.0040442970383446665\n",
      "Training Loss: 0.0040168115636333825\n",
      "Validation Loss: 0.012812901126510335\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.0071065889031160625\n",
      "Training Loss: 0.006629600541200489\n",
      "Training Loss: 0.006989260390982963\n",
      "Training Loss: 0.005304038231843151\n",
      "Training Loss: 0.004108707731938921\n",
      "Training Loss: 0.004038383337901905\n",
      "Training Loss: 0.004010959585430101\n",
      "Validation Loss: 0.01280119977254867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.00709500175784342\n",
      "Training Loss: 0.0066187047760467976\n",
      "Training Loss: 0.006978569743223488\n",
      "Training Loss: 0.0052953805070137605\n",
      "Training Loss: 0.004102757057407871\n",
      "Training Loss: 0.004032442693714984\n",
      "Training Loss: 0.004005101192742586\n",
      "Validation Loss: 0.012789212800353096\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007083714519394562\n",
      "Training Loss: 0.0066080750559922305\n",
      "Training Loss: 0.00696817634801846\n",
      "Training Loss: 0.005286825825460255\n",
      "Training Loss: 0.004096781076514162\n",
      "Training Loss: 0.004026478699524887\n",
      "Training Loss: 0.003999238843098283\n",
      "Validation Loss: 0.012776984565905277\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007072718668496236\n",
      "Training Loss: 0.006597701417049393\n",
      "Training Loss: 0.006958067510859109\n",
      "Training Loss: 0.005278368556173518\n",
      "Training Loss: 0.00409077996679116\n",
      "Training Loss: 0.004020489171962254\n",
      "Training Loss: 0.003993371095857583\n",
      "Validation Loss: 0.012764532948767397\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.007062005086336285\n",
      "Training Loss: 0.006587568738032132\n",
      "Training Loss: 0.006948226863169111\n",
      "Training Loss: 0.005270001867902465\n",
      "Training Loss: 0.0040847560547990725\n",
      "Training Loss: 0.0040144761360716074\n",
      "Training Loss: 0.003987498673959635\n",
      "Validation Loss: 0.01275192386224824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007051557300146669\n",
      "Training Loss: 0.006577660280745476\n",
      "Training Loss: 0.006938635930418968\n",
      "Training Loss: 0.005261723468429409\n",
      "Training Loss: 0.004078713709022849\n",
      "Training Loss: 0.004008444732171483\n",
      "Training Loss: 0.003981627072207629\n",
      "Validation Loss: 0.01273921268472399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.00704136005253531\n",
      "Training Loss: 0.00656796257593669\n",
      "Training Loss: 0.006929278723546304\n",
      "Training Loss: 0.005253520589903928\n",
      "Training Loss: 0.0040726489532971755\n",
      "Training Loss: 0.004002390194218605\n",
      "Training Loss: 0.003975750179379247\n",
      "Validation Loss: 0.012726405727474738\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.007031400823034346\n",
      "Training Loss: 0.006558457738719881\n",
      "Training Loss: 0.006920136010157876\n",
      "Training Loss: 0.005245392437791452\n",
      "Training Loss: 0.004066572253941558\n",
      "Training Loss: 0.003996322368620895\n",
      "Training Loss: 0.003969875633483753\n",
      "Validation Loss: 0.012713601581633704\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007021661550970748\n",
      "Training Loss: 0.006549130169441923\n",
      "Training Loss: 0.006911190466489643\n",
      "Training Loss: 0.005237328220973722\n",
      "Training Loss: 0.004060476394952275\n",
      "Training Loss: 0.00399023242527619\n",
      "Training Loss: 0.003963995832018554\n",
      "Validation Loss: 0.01270080692255137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007012127459747716\n",
      "Training Loss: 0.00653996316017583\n",
      "Training Loss: 0.006902424274594523\n",
      "Training Loss: 0.005229322337545455\n",
      "Training Loss: 0.0040543660370167345\n",
      "Training Loss: 0.003984127877629362\n",
      "Training Loss: 0.0039581161562819035\n",
      "Validation Loss: 0.012688084059893695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007002775764558464\n",
      "Training Loss: 0.006530937167699449\n",
      "Training Loss: 0.006893817138043232\n",
      "Training Loss: 0.005221365774050355\n",
      "Training Loss: 0.004048237665556371\n",
      "Training Loss: 0.00397800553473644\n",
      "Training Loss: 0.003952230651048012\n",
      "Validation Loss: 0.012675462318549442\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.006993593942606822\n",
      "Training Loss: 0.00652203650563024\n",
      "Training Loss: 0.006885350853553973\n",
      "Training Loss: 0.0052134514623321596\n",
      "Training Loss: 0.004042089977301658\n",
      "Training Loss: 0.003971865742933005\n",
      "Training Loss: 0.0039463410055032\n",
      "Validation Loss: 0.012662993315851476\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.006984560955315828\n",
      "Training Loss: 0.006513244952075183\n",
      "Training Loss: 0.006877009552554227\n",
      "Training Loss: 0.0052055713644949715\n",
      "Training Loss: 0.004035922604962252\n",
      "Training Loss: 0.003965705242590048\n",
      "Training Loss: 0.003940442544990219\n",
      "Validation Loss: 0.012650677743751542\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.006975661308970303\n",
      "Training Loss: 0.006504544507479295\n",
      "Training Loss: 0.006868774534086697\n",
      "Training Loss: 0.005197717448463663\n",
      "Training Loss: 0.004029730518814176\n",
      "Training Loss: 0.003959523054072633\n",
      "Training Loss: 0.003934531171689741\n",
      "Validation Loss: 0.012638563557077995\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.006966874575009569\n",
      "Training Loss: 0.006495918110013008\n",
      "Training Loss: 0.006860626286361367\n",
      "Training Loss: 0.005189880400430411\n",
      "Training Loss: 0.004023509695543908\n",
      "Training Loss: 0.003953314261743799\n",
      "Training Loss: 0.003928603897220455\n",
      "Validation Loss: 0.012626678108199315\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.006958184581017122\n",
      "Training Loss: 0.006487348461523652\n",
      "Training Loss: 0.006852548595052212\n",
      "Training Loss: 0.005182052524178289\n",
      "Training Loss: 0.00401725597679615\n",
      "Training Loss: 0.003947075725300238\n",
      "Training Loss: 0.00392265661386773\n",
      "Validation Loss: 0.012615019347421015\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.006949570289580151\n",
      "Training Loss: 0.006478819256881252\n",
      "Training Loss: 0.006844524103798904\n",
      "Training Loss: 0.005174221511697397\n",
      "Training Loss: 0.004010964595945552\n",
      "Training Loss: 0.003940804257290438\n",
      "Training Loss: 0.003916684530558996\n",
      "Validation Loss: 0.012603633458052904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.006941016138298437\n",
      "Training Loss: 0.006470312089659274\n",
      "Training Loss: 0.006836533000459895\n",
      "Training Loss: 0.005166382637107745\n",
      "Training Loss: 0.004004630934796296\n",
      "Training Loss: 0.003934493548003956\n",
      "Training Loss: 0.00391068102850113\n",
      "Validation Loss: 0.01259250570897864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.006932504125870764\n",
      "Training Loss: 0.0064618123933905735\n",
      "Training Loss: 0.006828560274443589\n",
      "Training Loss: 0.005158522843848914\n",
      "Training Loss: 0.003998246565461158\n",
      "Training Loss: 0.003928139312774874\n",
      "Training Loss: 0.0039046434103511274\n",
      "Validation Loss: 0.012581673297291615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.006924010657239705\n",
      "Training Loss: 0.006453298271517269\n",
      "Training Loss: 0.0068205851799575615\n",
      "Training Loss: 0.005150633218581788\n",
      "Training Loss: 0.003991805062396452\n",
      "Training Loss: 0.003921734126633964\n",
      "Training Loss: 0.003898562031099573\n",
      "Validation Loss: 0.01257113088707157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.006915521221235395\n",
      "Training Loss: 0.00644475519831758\n",
      "Training Loss: 0.00681259309349116\n",
      "Training Loss: 0.005142704068566673\n",
      "Training Loss: 0.0039852985163452105\n",
      "Training Loss: 0.003915270019788295\n",
      "Training Loss: 0.0038924298621714117\n",
      "Validation Loss: 0.012560879028566209\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.006907017395133152\n",
      "Training Loss: 0.006436166265048087\n",
      "Training Loss: 0.006804564138292335\n",
      "Training Loss: 0.0051347242709016425\n",
      "Training Loss: 0.003978717685677111\n",
      "Training Loss: 0.003908737829769962\n",
      "Training Loss: 0.0038862395740579814\n",
      "Validation Loss: 0.012550923501556453\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.006898481077514589\n",
      "Training Loss: 0.006427514249226079\n",
      "Training Loss: 0.006796482548816129\n",
      "Training Loss: 0.005126683056587354\n",
      "Training Loss: 0.003972055432968773\n",
      "Training Loss: 0.003902132253278978\n",
      "Training Loss: 0.0038799841183936225\n",
      "Validation Loss: 0.012541242545969394\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.006889891545288265\n",
      "Training Loss: 0.006418780577951111\n",
      "Training Loss: 0.00678832879057154\n",
      "Training Loss: 0.00511856927012559\n",
      "Training Loss: 0.003965298443217762\n",
      "Training Loss: 0.003895439250045456\n",
      "Training Loss: 0.0038736514182528482\n",
      "Validation Loss: 0.01253183235759648\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.006881231254665181\n",
      "Training Loss: 0.006409944975166582\n",
      "Training Loss: 0.006780083294142969\n",
      "Training Loss: 0.005110370966140181\n",
      "Training Loss: 0.0039584409195231275\n",
      "Training Loss: 0.0038886531261960043\n",
      "Training Loss: 0.003867236208170652\n",
      "Validation Loss: 0.012522682371420249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.006872479543089866\n",
      "Training Loss: 0.006400990809197538\n",
      "Training Loss: 0.006771729895262979\n",
      "Training Loss: 0.0051020765764405954\n",
      "Training Loss: 0.003951470180763863\n",
      "Training Loss: 0.0038817623519571496\n",
      "Training Loss: 0.003860726944403723\n",
      "Validation Loss: 0.012513770281916227\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.006863617865601555\n",
      "Training Loss: 0.006391899296431802\n",
      "Training Loss: 0.006763248502393253\n",
      "Training Loss: 0.005093676088145003\n",
      "Training Loss: 0.003944375507999211\n",
      "Training Loss: 0.0038747540808981283\n",
      "Training Loss: 0.0038541143998736516\n",
      "Validation Loss: 0.01250509753141357\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.006854628013679758\n",
      "Training Loss: 0.0063826509058708325\n",
      "Training Loss: 0.006754620706778951\n",
      "Training Loss: 0.0050851543649332595\n",
      "Training Loss: 0.003937145785894245\n",
      "Training Loss: 0.003867619210504927\n",
      "Training Loss: 0.003847388388821855\n",
      "Validation Loss: 0.012496596530135651\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.006845490563428029\n",
      "Training Loss: 0.006373229983728379\n",
      "Training Loss: 0.006745829242863693\n",
      "Training Loss: 0.005076501380535774\n",
      "Training Loss: 0.003929766596411355\n",
      "Training Loss: 0.003860342280822806\n",
      "Training Loss: 0.0038405349745880813\n",
      "Validation Loss: 0.012488242598034245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.006836185321444646\n",
      "Training Loss: 0.0063636144006159155\n",
      "Training Loss: 0.006736852473695762\n",
      "Training Loss: 0.005067704308894463\n",
      "Training Loss: 0.003922228658921085\n",
      "Training Loss: 0.0038529143552295864\n",
      "Training Loss: 0.003833547941176221\n",
      "Validation Loss: 0.012479974443532443\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.006826688873115927\n",
      "Training Loss: 0.006353782610967755\n",
      "Training Loss: 0.006727671884000301\n",
      "Training Loss: 0.00505874989554286\n",
      "Training Loss: 0.00391451665898785\n",
      "Training Loss: 0.0038453208829741926\n",
      "Training Loss: 0.003826414464274421\n",
      "Validation Loss: 0.012471769098366859\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.006816988945938646\n",
      "Training Loss: 0.006343720091390424\n",
      "Training Loss: 0.006718269108678215\n",
      "Training Loss: 0.0050496268883580345\n",
      "Training Loss: 0.003906623359653167\n",
      "Training Loss: 0.0038375532801728698\n",
      "Training Loss: 0.003819126404123381\n",
      "Validation Loss: 0.012463565244799836\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.006807059766724705\n",
      "Training Loss: 0.006333403174066916\n",
      "Training Loss: 0.00670862469880376\n",
      "Training Loss: 0.005040324324509129\n",
      "Training Loss: 0.0038985334150493144\n",
      "Training Loss: 0.0038295971386833115\n",
      "Training Loss: 0.0038116704754065723\n",
      "Validation Loss: 0.012455261068694183\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.00679688372882083\n",
      "Training Loss: 0.006322814563754946\n",
      "Training Loss: 0.006698719512787648\n",
      "Training Loss: 0.0050308286229847\n",
      "Training Loss: 0.0038902327982941643\n",
      "Training Loss: 0.003821438103914261\n",
      "Training Loss: 0.0038040360034210605\n",
      "Validation Loss: 0.012446812395449407\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.006786444374010898\n",
      "Training Loss: 0.006311936721904204\n",
      "Training Loss: 0.006688535340945236\n",
      "Training Loss: 0.005021130322129466\n",
      "Training Loss: 0.003881717112963088\n",
      "Training Loss: 0.0038130700978217646\n",
      "Training Loss: 0.0037962165410863236\n",
      "Validation Loss: 0.012438129881756164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.006775720032746904\n",
      "Training Loss: 0.0063007488858420405\n",
      "Training Loss: 0.006678055488155223\n",
      "Training Loss: 0.00501121909939684\n",
      "Training Loss: 0.003872970581287518\n",
      "Training Loss: 0.0038044793385779486\n",
      "Training Loss: 0.003788201395072974\n",
      "Validation Loss: 0.012429098121661427\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.00676469367230311\n",
      "Training Loss: 0.0062892363197170195\n",
      "Training Loss: 0.006667261820985005\n",
      "Training Loss: 0.005001083095557988\n",
      "Training Loss: 0.0038639829051680865\n",
      "Training Loss: 0.0037956549786031246\n",
      "Training Loss: 0.003779982413398102\n",
      "Validation Loss: 0.012419643523241305\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.0067533492250368\n",
      "Training Loss: 0.00627738096867688\n",
      "Training Loss: 0.006656139892293141\n",
      "Training Loss: 0.004990715871681459\n",
      "Training Loss: 0.0038547479297267274\n",
      "Training Loss: 0.0037865901074837895\n",
      "Training Loss: 0.003771552192629315\n",
      "Validation Loss: 0.012409639038574578\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.00674167116987519\n",
      "Training Loss: 0.006265168900717981\n",
      "Training Loss: 0.00664467373455409\n",
      "Training Loss: 0.004980108359013684\n",
      "Training Loss: 0.0038452549354406076\n",
      "Training Loss: 0.0037772745784604923\n",
      "Training Loss: 0.0037629047979135066\n",
      "Validation Loss: 0.012398979452190997\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.006729645717423409\n",
      "Training Loss: 0.006252587044145912\n",
      "Training Loss: 0.006632850065943785\n",
      "Training Loss: 0.004969254104071297\n",
      "Training Loss: 0.0038354984269244594\n",
      "Training Loss: 0.003767702422919683\n",
      "Training Loss: 0.0037540353438816963\n",
      "Validation Loss: 0.012387513287264281\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.006717258910648525\n",
      "Training Loss: 0.006239621915156022\n",
      "Training Loss: 0.006620658311294392\n",
      "Training Loss: 0.004958149003214203\n",
      "Training Loss: 0.0038254770589992403\n",
      "Training Loss: 0.003757871533744037\n",
      "Training Loss: 0.003744940696051344\n",
      "Validation Loss: 0.012375149538841671\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.006704501729109325\n",
      "Training Loss: 0.006226265414152294\n",
      "Training Loss: 0.006608088564244099\n",
      "Training Loss: 0.004946786393411458\n",
      "Training Loss: 0.0038151796051533893\n",
      "Training Loss: 0.003747773110517301\n",
      "Training Loss: 0.003735618503415026\n",
      "Validation Loss: 0.012361716542720851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.006691362952697091\n",
      "Training Loss: 0.0062125093233771625\n",
      "Training Loss: 0.006595130903297104\n",
      "Training Loss: 0.004935167234507389\n",
      "Training Loss: 0.0038046115246834233\n",
      "Training Loss: 0.0037374095356790347\n",
      "Training Loss: 0.0037260684685315936\n",
      "Validation Loss: 0.012347122632518187\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.006677839941112325\n",
      "Training Loss: 0.006198348582838662\n",
      "Training Loss: 0.006581781545537524\n",
      "Training Loss: 0.004923290033475496\n",
      "Training Loss: 0.0037937749893171713\n",
      "Training Loss: 0.003726782049634494\n",
      "Training Loss: 0.0037162963114678858\n",
      "Validation Loss: 0.012331179458271252\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.0066639200819190595\n",
      "Training Loss: 0.00618377891543787\n",
      "Training Loss: 0.006568035677191802\n",
      "Training Loss: 0.004911156381713227\n",
      "Training Loss: 0.003782667497289367\n",
      "Training Loss: 0.0037158900342183186\n",
      "Training Loss: 0.003706300551421009\n",
      "Validation Loss: 0.01231380773242563\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.006649611320463009\n",
      "Training Loss: 0.006168804053450003\n",
      "Training Loss: 0.00655389295425266\n",
      "Training Loss: 0.004898770791478455\n",
      "Training Loss: 0.00377130123146344\n",
      "Training Loss: 0.0037047438212903217\n",
      "Training Loss: 0.003696094639599323\n",
      "Validation Loss: 0.012294859732222161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.006634906263207086\n",
      "Training Loss: 0.006153423871146515\n",
      "Training Loss: 0.006539354459382593\n",
      "Training Loss: 0.004886137485736981\n",
      "Training Loss: 0.0037596800702158362\n",
      "Training Loss: 0.0036933453526580705\n",
      "Training Loss: 0.0036856816668296233\n",
      "Validation Loss: 0.012274212475555638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.0066198121348861605\n",
      "Training Loss: 0.006137644737609662\n",
      "Training Loss: 0.006524423328810372\n",
      "Training Loss: 0.0048732643475523215\n",
      "Training Loss: 0.0037478167115477844\n",
      "Training Loss: 0.003681710109813139\n",
      "Training Loss: 0.003675076815416105\n",
      "Validation Loss: 0.012251759725814678\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.006604332213755697\n",
      "Training Loss: 0.006121474034152925\n",
      "Training Loss: 0.006509104944416322\n",
      "Training Loss: 0.0048601623979629945\n",
      "Training Loss: 0.003735726599697955\n",
      "Training Loss: 0.0036698518064804376\n",
      "Training Loss: 0.003664293702458963\n",
      "Validation Loss: 0.012227415270259261\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.006588475134340115\n",
      "Training Loss: 0.006104924260289408\n",
      "Training Loss: 0.00649340946751181\n",
      "Training Loss: 0.004846842366387136\n",
      "Training Loss: 0.00372342364047654\n",
      "Training Loss: 0.0036577830428723246\n",
      "Training Loss: 0.003653350793174468\n",
      "Validation Loss: 0.01220107174823793\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.006572249666205608\n",
      "Training Loss: 0.006088008471997455\n",
      "Training Loss: 0.0064773491979576645\n",
      "Training Loss: 0.004833321711048484\n",
      "Training Loss: 0.003710930322413333\n",
      "Training Loss: 0.003645527701592073\n",
      "Training Loss: 0.003642266641254537\n",
      "Validation Loss: 0.012172653346343406\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.006555675434647128\n",
      "Training Loss: 0.0060707500501303\n",
      "Training Loss: 0.006460940309916623\n",
      "Training Loss: 0.00481961571786087\n",
      "Training Loss: 0.003698271120083518\n",
      "Training Loss: 0.0036331083462573586\n",
      "Training Loss: 0.0036310714983846994\n",
      "Validation Loss: 0.012142156069393685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.006538767249439843\n",
      "Training Loss: 0.006053165458142757\n",
      "Training Loss: 0.006444202644051984\n",
      "Training Loss: 0.004805748985381797\n",
      "Training Loss: 0.0036854729510378092\n",
      "Training Loss: 0.0036205552617320793\n",
      "Training Loss: 0.0036197933380026372\n",
      "Validation Loss: 0.012109541509488828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.006521541699767113\n",
      "Training Loss: 0.006035279954085126\n",
      "Training Loss: 0.006427157498546876\n",
      "Training Loss: 0.004791745794354938\n",
      "Training Loss: 0.0036725741648115217\n",
      "Training Loss: 0.003607905174139887\n",
      "Training Loss: 0.0036084678320912646\n",
      "Validation Loss: 0.012074790430195936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.0065040298987878485\n",
      "Training Loss: 0.006017128273961134\n",
      "Training Loss: 0.006409837080864236\n",
      "Training Loss: 0.004777633856283501\n",
      "Training Loss: 0.0036596091865794735\n",
      "Training Loss: 0.0035951925191329793\n",
      "Training Loss: 0.003597133883158676\n",
      "Validation Loss: 0.012037996316506538\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.006486260518431664\n",
      "Training Loss: 0.00599874400999397\n",
      "Training Loss: 0.0063922742189606654\n",
      "Training Loss: 0.004763451189501211\n",
      "Training Loss: 0.003646625292603858\n",
      "Training Loss: 0.003582462946069427\n",
      "Training Loss: 0.003585836181882769\n",
      "Validation Loss: 0.011999190587913164\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.006468265501316637\n",
      "Training Loss: 0.005980166532099247\n",
      "Training Loss: 0.006374507163418457\n",
      "Training Loss: 0.004749232800095342\n",
      "Training Loss: 0.003633666399400681\n",
      "Training Loss: 0.0035697623546002435\n",
      "Training Loss: 0.003574622918386012\n",
      "Validation Loss: 0.011958497137351011\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.00645008375053294\n",
      "Training Loss: 0.005961439036764204\n",
      "Training Loss: 0.00635657881910447\n",
      "Training Loss: 0.004735020968364551\n",
      "Training Loss: 0.003620790668646805\n",
      "Training Loss: 0.0035571457009064035\n",
      "Training Loss: 0.0035635476699098943\n",
      "Validation Loss: 0.011916090410345753\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.006431755920057185\n",
      "Training Loss: 0.00594261015765369\n",
      "Training Loss: 0.006338537982082925\n",
      "Training Loss: 0.004720862681278959\n",
      "Training Loss: 0.003608051860355772\n",
      "Training Loss: 0.003544665741501376\n",
      "Training Loss: 0.0035526640433818104\n",
      "Validation Loss: 0.011872147628078271\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.00641332785889972\n",
      "Training Loss: 0.005923730122740381\n",
      "Training Loss: 0.006320434877416119\n",
      "Training Loss: 0.004706803523586132\n",
      "Training Loss: 0.0035955087561160325\n",
      "Training Loss: 0.003532377082738094\n",
      "Training Loss: 0.0035420266492292283\n",
      "Validation Loss: 0.011826908023162896\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.006394847055198625\n",
      "Training Loss: 0.00590485223394353\n",
      "Training Loss: 0.006302325880387798\n",
      "Training Loss: 0.004692892684834078\n",
      "Training Loss: 0.0035832153860246765\n",
      "Training Loss: 0.003520332329208031\n",
      "Training Loss: 0.0035316840081941335\n",
      "Validation Loss: 0.011780577256564008\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.006376360474387183\n",
      "Training Loss: 0.0058860295952763405\n",
      "Training Loss: 0.00628426352457609\n",
      "Training Loss: 0.0046791758964536715\n",
      "Training Loss: 0.0035712314606644213\n",
      "Training Loss: 0.0035085858771344647\n",
      "Training Loss: 0.003521690359339118\n",
      "Validation Loss: 0.011733502593006562\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.00635792167566251\n",
      "Training Loss: 0.005867319206008688\n",
      "Training Loss: 0.006266307370970026\n",
      "Training Loss: 0.0046657020749989895\n",
      "Training Loss: 0.0035596057068323717\n",
      "Training Loss: 0.0034971788979601113\n",
      "Training Loss: 0.003512083913083188\n",
      "Validation Loss: 0.011685939441602467\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.006339577232138254\n",
      "Training Loss: 0.00584876837732736\n",
      "Training Loss: 0.006248506337287836\n",
      "Training Loss: 0.0046525097056292\n",
      "Training Loss: 0.00354838132916484\n",
      "Training Loss: 0.003486154357669875\n",
      "Training Loss: 0.0035029013897292316\n",
      "Validation Loss: 0.01163820381893703\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.006321369429351762\n",
      "Training Loss: 0.005830425827298313\n",
      "Training Loss: 0.006230911139282398\n",
      "Training Loss: 0.004639635848579928\n",
      "Training Loss: 0.0035375944682164116\n",
      "Training Loss: 0.003475540619692765\n",
      "Training Loss: 0.003494167941971682\n",
      "Validation Loss: 0.011590559104865606\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.006303342198953033\n",
      "Training Loss: 0.005812333488720469\n",
      "Training Loss: 0.006213567586382851\n",
      "Training Loss: 0.004627110084402375\n",
      "Training Loss: 0.003527269440237433\n",
      "Training Loss: 0.003465357355889864\n",
      "Training Loss: 0.003485895016929135\n",
      "Validation Loss: 0.011543287906084167\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.006285532272886485\n",
      "Training Loss: 0.0057945279072737325\n",
      "Training Loss: 0.006196513780159876\n",
      "Training Loss: 0.004614952525007539\n",
      "Training Loss: 0.0035174229380208998\n",
      "Training Loss: 0.0034556193329626696\n",
      "Training Loss: 0.003478092307341285\n",
      "Validation Loss: 0.011496646977239027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006267969120526687\n",
      "Training Loss: 0.005777040182729252\n",
      "Training Loss: 0.006179783137631603\n",
      "Training Loss: 0.004603178170509636\n",
      "Training Loss: 0.003508053764817305\n",
      "Training Loss: 0.003446318328497\n",
      "Training Loss: 0.0034707461623474955\n",
      "Validation Loss: 0.011450817558673745\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006250685907434672\n",
      "Training Loss: 0.005759898902615532\n",
      "Training Loss: 0.00616340437263716\n",
      "Training Loss: 0.00459179499419406\n",
      "Training Loss: 0.003499162768712267\n",
      "Training Loss: 0.0034374563221354036\n",
      "Training Loss: 0.0034638476645341143\n",
      "Validation Loss: 0.011406041946862074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006233701718738303\n",
      "Training Loss: 0.005743119739927352\n",
      "Training Loss: 0.00614739703189116\n",
      "Training Loss: 0.004580800967523828\n",
      "Training Loss: 0.003490726776653901\n",
      "Training Loss: 0.003429008398670703\n",
      "Training Loss: 0.003457370231626555\n",
      "Validation Loss: 0.011362381796579292\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006217041764175519\n",
      "Training Loss: 0.0057267237454652785\n",
      "Training Loss: 0.006131778694689274\n",
      "Training Loss: 0.004570191540988162\n",
      "Training Loss: 0.0034827272268012164\n",
      "Training Loss: 0.0034209559398004786\n",
      "Training Loss: 0.0034512862301198767\n",
      "Validation Loss: 0.011319996674862526\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006200715568265878\n",
      "Training Loss: 0.005710716798203066\n",
      "Training Loss: 0.006116558414651081\n",
      "Training Loss: 0.00455995746422559\n",
      "Training Loss: 0.0034751364571275188\n",
      "Training Loss: 0.0034132740186760204\n",
      "Training Loss: 0.003445566020673141\n",
      "Validation Loss: 0.011278949285096974\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006184737817384303\n",
      "Training Loss: 0.005695109612424858\n",
      "Training Loss: 0.0061017439828719945\n",
      "Training Loss: 0.004550085565424525\n",
      "Training Loss: 0.003467925654258579\n",
      "Training Loss: 0.003405935047194362\n",
      "Training Loss: 0.003440177594893612\n",
      "Validation Loss: 0.011239255558305215\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.0061691127781523395\n",
      "Training Loss: 0.0056799021386541425\n",
      "Training Loss: 0.006087336196796969\n",
      "Training Loss: 0.004540562726906501\n",
      "Training Loss: 0.0034610644401982427\n",
      "Training Loss: 0.003398912317934446\n",
      "Training Loss: 0.003435088488040492\n",
      "Validation Loss: 0.01120096680094324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.006153855207376182\n",
      "Training Loss: 0.005665101750055328\n",
      "Training Loss: 0.0060733385855564846\n",
      "Training Loss: 0.004531373511999845\n",
      "Training Loss: 0.0034545213676756246\n",
      "Training Loss: 0.003392174448235892\n",
      "Training Loss: 0.003430265749921091\n",
      "Validation Loss: 0.011164052860134662\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006138963782577775\n",
      "Training Loss: 0.005650705563020893\n",
      "Training Loss: 0.006059747171821073\n",
      "Training Loss: 0.004522501594037749\n",
      "Training Loss: 0.00344826459127944\n",
      "Training Loss: 0.0033856975135859104\n",
      "Training Loss: 0.00342568009684328\n",
      "Validation Loss: 0.011128481827616998\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006124447210459039\n",
      "Training Loss: 0.0056367142644012345\n",
      "Training Loss: 0.0060465599136659874\n",
      "Training Loss: 0.004513930533430539\n",
      "Training Loss: 0.0034422670752974225\n",
      "Training Loss: 0.0033794543228577822\n",
      "Training Loss: 0.003421305100200698\n",
      "Validation Loss: 0.011094233217345697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006110304108588025\n",
      "Training Loss: 0.005623122986289673\n",
      "Training Loss: 0.006033768785418943\n",
      "Training Loss: 0.004505647533223964\n",
      "Training Loss: 0.0034365045092999936\n",
      "Training Loss: 0.003373424689634703\n",
      "Training Loss: 0.003417115721385926\n",
      "Validation Loss: 0.011061222785394918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006096530195209198\n",
      "Training Loss: 0.0056099263136275114\n",
      "Training Loss: 0.006021367920329795\n",
      "Training Loss: 0.004497635205625556\n",
      "Training Loss: 0.0034309517859946936\n",
      "Training Loss: 0.003367587097454816\n",
      "Training Loss: 0.003413092354312539\n",
      "Validation Loss: 0.011029440647798629\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006083125697332434\n",
      "Training Loss: 0.005597119152662344\n",
      "Training Loss: 0.006009347764775157\n",
      "Training Loss: 0.004489881519693881\n",
      "Training Loss: 0.003425591134582646\n",
      "Training Loss: 0.0033619264187291263\n",
      "Training Loss: 0.0034092150500509887\n",
      "Validation Loss: 0.010998821983023195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.0060700858739437535\n",
      "Training Loss: 0.005584692289121449\n",
      "Training Loss: 0.005997700545121915\n",
      "Training Loss: 0.004482373463688418\n",
      "Training Loss: 0.0034203992935363204\n",
      "Training Loss: 0.003356421713833697\n",
      "Training Loss: 0.003405465323594399\n",
      "Validation Loss: 0.010969273253319582\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006057409226777963\n",
      "Training Loss: 0.005572641263133846\n",
      "Training Loss: 0.005986414200742729\n",
      "Training Loss: 0.004475097206886857\n",
      "Training Loss: 0.003415364556130953\n",
      "Training Loss: 0.0033510625758208334\n",
      "Training Loss: 0.0034018296137219295\n",
      "Validation Loss: 0.010940761808550145\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.006045086824451573\n",
      "Training Loss: 0.0055609560175798834\n",
      "Training Loss: 0.005975480323540978\n",
      "Training Loss: 0.004468043458764441\n",
      "Training Loss: 0.0034104731329716743\n",
      "Training Loss: 0.003345837855013087\n",
      "Training Loss: 0.0033982990466756746\n",
      "Validation Loss: 0.010913213611622289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.00603310854639858\n",
      "Training Loss: 0.0055496223800582814\n",
      "Training Loss: 0.005964885749272071\n",
      "Training Loss: 0.004461201297817752\n",
      "Training Loss: 0.0034057129063876346\n",
      "Training Loss: 0.003340737171820365\n",
      "Training Loss: 0.0033948600094299763\n",
      "Validation Loss: 0.010886579414058743\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006021471979329363\n",
      "Training Loss: 0.005538637314457446\n",
      "Training Loss: 0.0059546209353720765\n",
      "Training Loss: 0.004454559352016076\n",
      "Training Loss: 0.003401072504930198\n",
      "Training Loss: 0.0033357529854401947\n",
      "Training Loss: 0.003391504164901562\n",
      "Validation Loss: 0.010860782906488073\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006010168036445975\n",
      "Training Loss: 0.005527989847469144\n",
      "Training Loss: 0.005944675507489592\n",
      "Training Loss: 0.004448110338416882\n",
      "Training Loss: 0.0033965428557712583\n",
      "Training Loss: 0.0033308761642547326\n",
      "Training Loss: 0.003388225144590251\n",
      "Validation Loss: 0.010835798316868895\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.005999183504609391\n",
      "Training Loss: 0.005517666031373665\n",
      "Training Loss: 0.005935035488219001\n",
      "Training Loss: 0.004441844832617789\n",
      "Training Loss: 0.003392120747594163\n",
      "Training Loss: 0.0033261004427913576\n",
      "Training Loss: 0.0033850135665852575\n",
      "Validation Loss: 0.010811538758385954\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.005988515703356825\n",
      "Training Loss: 0.0055076595785794775\n",
      "Training Loss: 0.0059256917599122974\n",
      "Training Loss: 0.004435753362486139\n",
      "Training Loss: 0.003387794055161066\n",
      "Training Loss: 0.0033214206097181885\n",
      "Training Loss: 0.003381867648568004\n",
      "Validation Loss: 0.01078800780416121\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.005978148867143318\n",
      "Training Loss: 0.005497957253828645\n",
      "Training Loss: 0.00591663320956286\n",
      "Training Loss: 0.004429828818538226\n",
      "Training Loss: 0.003383560400106944\n",
      "Training Loss: 0.0033168331847991794\n",
      "Training Loss: 0.003378778834594414\n",
      "Validation Loss: 0.010765119303150402\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.0059680791234131905\n",
      "Training Loss: 0.0054885502409888435\n",
      "Training Loss: 0.005907847887719982\n",
      "Training Loss: 0.004424064600025304\n",
      "Training Loss: 0.003379413322545588\n",
      "Training Loss: 0.0033123310082009993\n",
      "Training Loss: 0.003375745734083466\n",
      "Validation Loss: 0.010742830124348821\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.005958293018629775\n",
      "Training Loss: 0.005479427557438612\n",
      "Training Loss: 0.005899325779173523\n",
      "Training Loss: 0.004418452869867906\n",
      "Training Loss: 0.0033753529016394166\n",
      "Training Loss: 0.0033079149678815157\n",
      "Training Loss: 0.003372765030362643\n",
      "Validation Loss: 0.010721118439665615\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.005948778494494036\n",
      "Training Loss: 0.005470577638479881\n",
      "Training Loss: 0.005891055737738498\n",
      "Training Loss: 0.004412988441181369\n",
      "Training Loss: 0.0033713690197328104\n",
      "Training Loss: 0.0033035786455729976\n",
      "Training Loss: 0.0033698308269958944\n",
      "Validation Loss: 0.010699929176369326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.005939533342025243\n",
      "Training Loss: 0.005461994200595654\n",
      "Training Loss: 0.005883027145173401\n",
      "Training Loss: 0.004407662298181094\n",
      "Training Loss: 0.003367460409644991\n",
      "Training Loss: 0.003299318166973535\n",
      "Training Loss: 0.003366943377768621\n",
      "Validation Loss: 0.01067924360598155\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.0059305391542147845\n",
      "Training Loss: 0.005453663238440641\n",
      "Training Loss: 0.005875230862875469\n",
      "Training Loss: 0.004402471485664136\n",
      "Training Loss: 0.00336362756730523\n",
      "Training Loss: 0.0032951348804635926\n",
      "Training Loss: 0.003364097659359686\n",
      "Validation Loss: 0.010659029494538513\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.005921795023023151\n",
      "Training Loss: 0.005445577513310127\n",
      "Training Loss: 0.005867656449554488\n",
      "Training Loss: 0.004397408032673411\n",
      "Training Loss: 0.003359862409415655\n",
      "Training Loss: 0.00329102236602921\n",
      "Training Loss: 0.003361292785848491\n",
      "Validation Loss: 0.010639252154634436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00591328740818426\n",
      "Training Loss: 0.005437728114775382\n",
      "Training Loss: 0.0058602950809290635\n",
      "Training Loss: 0.004392467471188865\n",
      "Training Loss: 0.0033561644807923586\n",
      "Training Loss: 0.00328697908873437\n",
      "Training Loss: 0.0033585262089036406\n",
      "Validation Loss: 0.010619885589681523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.0059050076326821\n",
      "Training Loss: 0.005430105606210418\n",
      "Training Loss: 0.005853139003156684\n",
      "Training Loss: 0.004387645627721213\n",
      "Training Loss: 0.003352533814613707\n",
      "Training Loss: 0.003283007023856044\n",
      "Training Loss: 0.003355797852273099\n",
      "Validation Loss: 0.010600911967424948\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.005896948323934339\n",
      "Training Loss: 0.005422703701769933\n",
      "Training Loss: 0.0058461802359670405\n",
      "Training Loss: 0.004382934782770462\n",
      "Training Loss: 0.0033489622204797343\n",
      "Training Loss: 0.003279097201884724\n",
      "Training Loss: 0.0033531025162665175\n",
      "Validation Loss: 0.010582277232786284\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.005889101709472016\n",
      "Training Loss: 0.005415509978192858\n",
      "Training Loss: 0.005839407435851172\n",
      "Training Loss: 0.0043783327471464874\n",
      "Training Loss: 0.0033454530889866873\n",
      "Training Loss: 0.0032752543094102292\n",
      "Training Loss: 0.0033504429273307325\n",
      "Validation Loss: 0.010564019380107675\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.005881454245536588\n",
      "Training Loss: 0.005408515050075949\n",
      "Training Loss: 0.0058328134723706175\n",
      "Training Loss: 0.004373834625585005\n",
      "Training Loss: 0.0033420041063800454\n",
      "Training Loss: 0.003271474531793501\n",
      "Training Loss: 0.003347816673340276\n",
      "Validation Loss: 0.010546064720452459\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.005874003238859587\n",
      "Training Loss: 0.00540171385044232\n",
      "Training Loss: 0.005826390336733311\n",
      "Training Loss: 0.004369436705019325\n",
      "Training Loss: 0.0033386134158354254\n",
      "Training Loss: 0.003267757984576747\n",
      "Training Loss: 0.0033452228282112627\n",
      "Validation Loss: 0.010528431360327294\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.005866739853518084\n",
      "Training Loss: 0.005395101110916584\n",
      "Training Loss: 0.005820133372908458\n",
      "Training Loss: 0.004365133228129707\n",
      "Training Loss: 0.003335276634898037\n",
      "Training Loss: 0.0032640987265040167\n",
      "Training Loss: 0.003342657843022607\n",
      "Validation Loss: 0.01051107614714485\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.00585965916281566\n",
      "Training Loss: 0.005388667213264853\n",
      "Training Loss: 0.005814033980714157\n",
      "Training Loss: 0.00436092123563867\n",
      "Training Loss: 0.0033319938468048347\n",
      "Training Loss: 0.003260498686286155\n",
      "Training Loss: 0.0033401241508545353\n",
      "Validation Loss: 0.010494001376728635\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.005852750553167425\n",
      "Training Loss: 0.005382403787807561\n",
      "Training Loss: 0.0058080861065536735\n",
      "Training Loss: 0.004356798673979938\n",
      "Training Loss: 0.00332876565400511\n",
      "Training Loss: 0.0032569558720570058\n",
      "Training Loss: 0.0033376174449222164\n",
      "Validation Loss: 0.010477168379571246\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.005846010904060677\n",
      "Training Loss: 0.005376307257101871\n",
      "Training Loss: 0.005802283497760072\n",
      "Training Loss: 0.004352759829489514\n",
      "Training Loss: 0.003325586089049466\n",
      "Training Loss: 0.003253468826878816\n",
      "Training Loss: 0.003335141282877885\n",
      "Validation Loss: 0.010460612242683865\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.0058394288038834926\n",
      "Training Loss: 0.005370367831783369\n",
      "Training Loss: 0.005796618072781712\n",
      "Training Loss: 0.004348802241147496\n",
      "Training Loss: 0.00332245858036913\n",
      "Training Loss: 0.003250038103433326\n",
      "Training Loss: 0.0033326930558541788\n",
      "Validation Loss: 0.01044429137985386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.0058329989871708674\n",
      "Training Loss: 0.005364579959423282\n",
      "Training Loss: 0.005791086774552241\n",
      "Training Loss: 0.004344924344914034\n",
      "Training Loss: 0.0033193809824297203\n",
      "Training Loss: 0.00324666071071988\n",
      "Training Loss: 0.0033302712423028424\n",
      "Validation Loss: 0.010428190846318791\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.0058267206011805685\n",
      "Training Loss: 0.005358942603925243\n",
      "Training Loss: 0.005785685053560883\n",
      "Training Loss: 0.004341120169847272\n",
      "Training Loss: 0.0033163486525882037\n",
      "Training Loss: 0.0032433338434202596\n",
      "Training Loss: 0.0033278742094989865\n",
      "Validation Loss: 0.010412299073360554\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.005820587082416751\n",
      "Training Loss: 0.005353446918306872\n",
      "Training Loss: 0.0057804056536406275\n",
      "Training Loss: 0.004337389417341911\n",
      "Training Loss: 0.0033133620268199593\n",
      "Training Loss: 0.003240057666262146\n",
      "Training Loss: 0.0033255017938790842\n",
      "Validation Loss: 0.010396636589534915\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.00581459138833452\n",
      "Training Loss: 0.0053480873681837696\n",
      "Training Loss: 0.0057752439414616675\n",
      "Training Loss: 0.004333727898192592\n",
      "Training Loss: 0.003310421929927543\n",
      "Training Loss: 0.003236832473776303\n",
      "Training Loss: 0.003323157250415534\n",
      "Validation Loss: 0.010381172335713628\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.005808722863439471\n",
      "Training Loss: 0.005342854292830452\n",
      "Training Loss: 0.005770194129436277\n",
      "Training Loss: 0.004330134532647207\n",
      "Training Loss: 0.0033075261960038914\n",
      "Training Loss: 0.003233656904194504\n",
      "Training Loss: 0.0033208365488098936\n",
      "Validation Loss: 0.010365905153411632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.005802987191127613\n",
      "Training Loss: 0.005337752873892896\n",
      "Training Loss: 0.005765254939324223\n",
      "Training Loss: 0.004326604987145401\n",
      "Training Loss: 0.0033046722668223084\n",
      "Training Loss: 0.003230527841078583\n",
      "Training Loss: 0.003318539092433639\n",
      "Validation Loss: 0.010350811047120236\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.005797373724635691\n",
      "Training Loss: 0.005332770501263439\n",
      "Training Loss: 0.00576041936816182\n",
      "Training Loss: 0.004323139531770721\n",
      "Training Loss: 0.0033018616860499604\n",
      "Training Loss: 0.0032274466956732795\n",
      "Training Loss: 0.0033162657637149096\n",
      "Validation Loss: 0.010335917677468715\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.005791877557639964\n",
      "Training Loss: 0.005327906847815029\n",
      "Training Loss: 0.005755685936310329\n",
      "Training Loss: 0.004319732672302052\n",
      "Training Loss: 0.003299090311047621\n",
      "Training Loss: 0.0032244101385003887\n",
      "Training Loss: 0.0033140163571806626\n",
      "Validation Loss: 0.010321195487609684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.005786496621440164\n",
      "Training Loss: 0.005323154043289833\n",
      "Training Loss: 0.005751048734528013\n",
      "Training Loss: 0.004316385826678015\n",
      "Training Loss: 0.0032963610329898073\n",
      "Training Loss: 0.0032214207627112045\n",
      "Training Loss: 0.0033117913675960154\n",
      "Validation Loss: 0.010306640319510499\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.005781224599923007\n",
      "Training Loss: 0.0053185086679877714\n",
      "Training Loss: 0.005746502770925872\n",
      "Training Loss: 0.004313094691606238\n",
      "Training Loss: 0.0032936720084398986\n",
      "Training Loss: 0.0032184758101357147\n",
      "Training Loss: 0.0033095901290653273\n",
      "Validation Loss: 0.010292271928240856\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.005776058083283715\n",
      "Training Loss: 0.005313968732370995\n",
      "Training Loss: 0.0057420479546999555\n",
      "Training Loss: 0.004309858857304789\n",
      "Training Loss: 0.0032910215918673202\n",
      "Training Loss: 0.0032155750397942027\n",
      "Training Loss: 0.0033074111194582654\n",
      "Validation Loss: 0.010278065139314417\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.005770995093043894\n",
      "Training Loss: 0.005309530691592954\n",
      "Training Loss: 0.005737680543097668\n",
      "Training Loss: 0.004306675819680095\n",
      "Training Loss: 0.0032884094398468733\n",
      "Training Loss: 0.0032127148186555134\n",
      "Training Loss: 0.003305253284634091\n",
      "Validation Loss: 0.010264009326889985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.005766031834646128\n",
      "Training Loss: 0.005305189281934872\n",
      "Training Loss: 0.005733396503492258\n",
      "Training Loss: 0.004303543638088741\n",
      "Training Loss: 0.0032858322584070265\n",
      "Training Loss: 0.003209897976485081\n",
      "Training Loss: 0.00330311888246797\n",
      "Validation Loss: 0.010250129093405572\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.005761166354059242\n",
      "Training Loss: 0.005300945081980899\n",
      "Training Loss: 0.005729194820160047\n",
      "Training Loss: 0.004300460433587432\n",
      "Training Loss: 0.0032832902361406013\n",
      "Training Loss: 0.00320711855427362\n",
      "Training Loss: 0.003301004470558837\n",
      "Validation Loss: 0.010236398814191992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.005756392864277586\n",
      "Training Loss: 0.005296789354179055\n",
      "Training Loss: 0.005725070683984086\n",
      "Training Loss: 0.004297426812117919\n",
      "Training Loss: 0.003280787757248618\n",
      "Training Loss: 0.0032043838957906703\n",
      "Training Loss: 0.0032989149674540388\n",
      "Validation Loss: 0.010222808008600193\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.005751707281451673\n",
      "Training Loss: 0.005292722102021799\n",
      "Training Loss: 0.0057210216036764905\n",
      "Training Loss: 0.004294440157827921\n",
      "Training Loss: 0.003278319223318249\n",
      "Training Loss: 0.0032016877122805452\n",
      "Training Loss: 0.003296845585573465\n",
      "Validation Loss: 0.010209378734499579\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.005747110153315589\n",
      "Training Loss: 0.005288738745148294\n",
      "Training Loss: 0.005717045069904998\n",
      "Training Loss: 0.004291497711674311\n",
      "Training Loss: 0.003275884772883728\n",
      "Training Loss: 0.0031990298136952335\n",
      "Training Loss: 0.0032947985344799237\n",
      "Validation Loss: 0.010196106061461463\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.005742596111958847\n",
      "Training Loss: 0.005284837747458368\n",
      "Training Loss: 0.0057131387101253496\n",
      "Training Loss: 0.004288600120926276\n",
      "Training Loss: 0.003273486061953008\n",
      "Training Loss: 0.003196412947727367\n",
      "Training Loss: 0.003292775841546245\n",
      "Validation Loss: 0.010182991007792899\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.00573815988143906\n",
      "Training Loss: 0.005281013394123874\n",
      "Training Loss: 0.005709300471353345\n",
      "Training Loss: 0.004285744951339439\n",
      "Training Loss: 0.0032711210730485617\n",
      "Training Loss: 0.0031938323011854665\n",
      "Training Loss: 0.0032907722209347414\n",
      "Validation Loss: 0.010170013093989523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.005733806864591315\n",
      "Training Loss: 0.005277268178178929\n",
      "Training Loss: 0.005705529449041933\n",
      "Training Loss: 0.004282932900823652\n",
      "Training Loss: 0.0032687897881260143\n",
      "Training Loss: 0.003191290011163801\n",
      "Training Loss: 0.0032887912320438773\n",
      "Validation Loss: 0.010157197556451437\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.005729529313975945\n",
      "Training Loss: 0.005273597448249348\n",
      "Training Loss: 0.005701823080307804\n",
      "Training Loss: 0.00428016031277366\n",
      "Training Loss: 0.0032664882205426693\n",
      "Training Loss: 0.0031887839804403484\n",
      "Training Loss: 0.0032868322206195443\n",
      "Validation Loss: 0.010144511108680834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.00572532357124146\n",
      "Training Loss: 0.0052699982729973276\n",
      "Training Loss: 0.005698179200990126\n",
      "Training Loss: 0.004277428907807916\n",
      "Training Loss: 0.003264221147983335\n",
      "Training Loss: 0.0031863132381113246\n",
      "Training Loss: 0.0032848927093436942\n",
      "Validation Loss: 0.010131966622855012\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.00572119265794754\n",
      "Training Loss: 0.005266468408517539\n",
      "Training Loss: 0.005694594946689903\n",
      "Training Loss: 0.0042747349356068295\n",
      "Training Loss: 0.003261984898708761\n",
      "Training Loss: 0.0031838803048594854\n",
      "Training Loss: 0.00328297623549588\n",
      "Validation Loss: 0.010119576885474825\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.00571713087381795\n",
      "Training Loss: 0.005263007612084039\n",
      "Training Loss: 0.005691070929169655\n",
      "Training Loss: 0.004272079630754888\n",
      "Training Loss: 0.0032597797422204166\n",
      "Training Loss: 0.0031814794152160175\n",
      "Training Loss: 0.0032810805056942625\n",
      "Validation Loss: 0.01010730992963412\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.005713136605918407\n",
      "Training Loss: 0.005259610167122446\n",
      "Training Loss: 0.005687603753758594\n",
      "Training Loss: 0.004269461008952931\n",
      "Training Loss: 0.0032576055516256018\n",
      "Training Loss: 0.0031791160040302202\n",
      "Training Loss: 0.0032792068156413732\n",
      "Validation Loss: 0.010095200379952885\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.005709208727348596\n",
      "Training Loss: 0.005256278637098148\n",
      "Training Loss: 0.005684193081106059\n",
      "Training Loss: 0.004266878211055882\n",
      "Training Loss: 0.003255461711669341\n",
      "Training Loss: 0.0031767841486725957\n",
      "Training Loss: 0.0032773521274793893\n",
      "Validation Loss: 0.01008321814132638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.0057053449476370584\n",
      "Training Loss: 0.005253007633727975\n",
      "Training Loss: 0.005680835888488218\n",
      "Training Loss: 0.004264331182930618\n",
      "Training Loss: 0.003253347621648572\n",
      "Training Loss: 0.003174488552613184\n",
      "Training Loss: 0.0032755205529974773\n",
      "Validation Loss: 0.010071385865036942\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.0057015418226365\n",
      "Training Loss: 0.005249796280986629\n",
      "Training Loss: 0.005677531381952577\n",
      "Training Loss: 0.004261817092774436\n",
      "Training Loss: 0.003251262496924028\n",
      "Training Loss: 0.0031722250007442197\n",
      "Training Loss: 0.0032737094309413808\n",
      "Validation Loss: 0.010059680415392411\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.00569780032383278\n",
      "Training Loss: 0.005246641742996871\n",
      "Training Loss: 0.005674278792575933\n",
      "Training Loss: 0.0042593386297812685\n",
      "Training Loss: 0.003249207618064247\n",
      "Training Loss: 0.003169993868214078\n",
      "Training Loss: 0.00327191854827106\n",
      "Validation Loss: 0.010048116239665027\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.0056941198772983625\n",
      "Training Loss: 0.005243546983692795\n",
      "Training Loss: 0.005671077854931355\n",
      "Training Loss: 0.004256891562254168\n",
      "Training Loss: 0.0032471791759599\n",
      "Training Loss: 0.003167792942840606\n",
      "Training Loss: 0.0032701482088305055\n",
      "Validation Loss: 0.010036686970547107\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.005690497515024618\n",
      "Training Loss: 0.005240505613619462\n",
      "Training Loss: 0.0056679250462912025\n",
      "Training Loss: 0.004254477035719901\n",
      "Training Loss: 0.003245181496604346\n",
      "Training Loss: 0.0031656273786211386\n",
      "Training Loss: 0.0032684005406918002\n",
      "Validation Loss: 0.010025423102094774\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.005686927032656968\n",
      "Training Loss: 0.0052375170675804834\n",
      "Training Loss: 0.005664819065132178\n",
      "Training Loss: 0.004252094367984682\n",
      "Training Loss: 0.003243211138760671\n",
      "Training Loss: 0.0031634917022893205\n",
      "Training Loss: 0.00326667160843499\n",
      "Validation Loss: 0.01001426125161545\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.005683414884842932\n",
      "Training Loss: 0.005234581828699447\n",
      "Training Loss: 0.005661761498777196\n",
      "Training Loss: 0.0042497424519388005\n",
      "Training Loss: 0.0032412688818294557\n",
      "Training Loss: 0.0031613885195110924\n",
      "Training Loss: 0.003264966545975767\n",
      "Validation Loss: 0.010003268786737423\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.005679953443468548\n",
      "Training Loss: 0.005231694829417393\n",
      "Training Loss: 0.005658747752895579\n",
      "Training Loss: 0.004247420880710706\n",
      "Training Loss: 0.00323935336782597\n",
      "Training Loss: 0.0031593141399207524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [29:19<08:26, 253.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.003263279945240356\n",
      "Validation Loss: 0.009992391176692695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 1\n",
      "Training Loss: 0.5732372327148915\n",
      "Training Loss: 0.45710805878043176\n",
      "Training Loss: 0.35544033147394655\n",
      "Training Loss: 0.27029704354703427\n",
      "Training Loss: 0.20209736309945583\n",
      "Training Loss: 0.14740215860307215\n",
      "Training Loss: 0.10907539963722229\n",
      "Validation Loss: 0.09408568278345722\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.08433636667206884\n",
      "Training Loss: 0.06668025283142924\n",
      "Training Loss: 0.059895478691905736\n",
      "Training Loss: 0.05530106011778116\n",
      "Training Loss: 0.05181911044754088\n",
      "Training Loss: 0.05013028830289841\n",
      "Training Loss: 0.04967684764415026\n",
      "Validation Loss: 0.05567792268672239\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.05304921194911003\n",
      "Training Loss: 0.048531280187889936\n",
      "Training Loss: 0.046683763321489095\n",
      "Training Loss: 0.04253445539623499\n",
      "Training Loss: 0.03827349541708827\n",
      "Training Loss: 0.03551744172349572\n",
      "Training Loss: 0.03349743596278131\n",
      "Validation Loss: 0.04139181687618686\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.03532445054501295\n",
      "Training Loss: 0.030716465897858144\n",
      "Training Loss: 0.028198119523003697\n",
      "Training Loss: 0.023747189370915293\n",
      "Training Loss: 0.01923427829518914\n",
      "Training Loss: 0.017163649778813125\n",
      "Training Loss: 0.015385169158689678\n",
      "Validation Loss: 0.026790560650454365\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.018458106191828846\n",
      "Training Loss: 0.01626071111066267\n",
      "Training Loss: 0.015684513747692107\n",
      "Training Loss: 0.013042381422128529\n",
      "Training Loss: 0.010260149501264096\n",
      "Training Loss: 0.009956287393579259\n",
      "Training Loss: 0.009312546543078497\n",
      "Validation Loss: 0.02123052254493596\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.013283192398957908\n",
      "Training Loss: 0.012287864165846258\n",
      "Training Loss: 0.012421750631183386\n",
      "Training Loss: 0.010171602923655883\n",
      "Training Loss: 0.007897466628346592\n",
      "Training Loss: 0.007817852863809094\n",
      "Training Loss: 0.007405278399819509\n",
      "Validation Loss: 0.01875730642476834\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.011363227607216687\n",
      "Training Loss: 0.010615667072124779\n",
      "Training Loss: 0.01084872800973244\n",
      "Training Loss: 0.008746480806730688\n",
      "Training Loss: 0.0066572770685888825\n",
      "Training Loss: 0.006594601427204907\n",
      "Training Loss: 0.006312541121733375\n",
      "Validation Loss: 0.01703504554505289\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.010216739112511277\n",
      "Training Loss: 0.009554073506733403\n",
      "Training Loss: 0.009832759434357286\n",
      "Training Loss: 0.007817317550070584\n",
      "Training Loss: 0.00584232836321462\n",
      "Training Loss: 0.005778583124629222\n",
      "Training Loss: 0.005598328337655402\n",
      "Validation Loss: 0.01576705742976192\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.009457893195794896\n",
      "Training Loss: 0.008834520492237062\n",
      "Training Loss: 0.009154707661364227\n",
      "Training Loss: 0.0071730892243795094\n",
      "Training Loss: 0.005294831595383584\n",
      "Training Loss: 0.005231149168685079\n",
      "Training Loss: 0.005113894919632002\n",
      "Validation Loss: 0.014879045250201214\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.008918230301933363\n",
      "Training Loss: 0.008324696988565847\n",
      "Training Loss: 0.008673999574966729\n",
      "Training Loss: 0.006702333697467111\n",
      "Training Loss: 0.004928418170311488\n",
      "Training Loss: 0.0048659178329398855\n",
      "Training Loss: 0.004782091011875309\n",
      "Validation Loss: 0.01432169228704988\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.008512697763508185\n",
      "Training Loss: 0.007954740332206712\n",
      "Training Loss: 0.00832149114808999\n",
      "Training Loss: 0.0063625268824398515\n",
      "Training Loss: 0.0046980174240889025\n",
      "Training Loss: 0.004635403589345515\n",
      "Training Loss: 0.004569392933044583\n",
      "Validation Loss: 0.014019957703471964\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008220437312265858\n",
      "Training Loss: 0.007700667059980333\n",
      "Training Loss: 0.008078943779692054\n",
      "Training Loss: 0.00613786636327859\n",
      "Training Loss: 0.004566505523398518\n",
      "Training Loss: 0.004499923131661489\n",
      "Training Loss: 0.004444756212760695\n",
      "Validation Loss: 0.013874638631193434\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008029163976898417\n",
      "Training Loss: 0.007541176698869095\n",
      "Training Loss: 0.007926766752498225\n",
      "Training Loss: 0.006001724105444737\n",
      "Training Loss: 0.004494174169376492\n",
      "Training Loss: 0.004420498072868213\n",
      "Training Loss: 0.004373661444988102\n",
      "Validation Loss: 0.013807675353868792\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.007913005783921108\n",
      "Training Loss: 0.007445547294337302\n",
      "Training Loss: 0.00783444831846282\n",
      "Training Loss: 0.005920432659331709\n",
      "Training Loss: 0.004450408112606965\n",
      "Training Loss: 0.004368921050336212\n",
      "Training Loss: 0.004329516278812662\n",
      "Validation Loss: 0.013775553506771137\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.007841795842396096\n",
      "Training Loss: 0.007385048270225525\n",
      "Training Loss: 0.007774463656824082\n",
      "Training Loss: 0.005867850604117848\n",
      "Training Loss: 0.004418987634708173\n",
      "Training Loss: 0.00433050676540006\n",
      "Training Loss: 0.004297849938157014\n",
      "Validation Loss: 0.013759785839304161\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.007793481511762366\n",
      "Training Loss: 0.0073414142511319365\n",
      "Training Loss: 0.0077299911400768905\n",
      "Training Loss: 0.00582943836809136\n",
      "Training Loss: 0.00439349515363574\n",
      "Training Loss: 0.0042992296809097755\n",
      "Training Loss: 0.004272497276542708\n",
      "Validation Loss: 0.013753687587482959\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.007756053608609363\n",
      "Training Loss: 0.007305648374604061\n",
      "Training Loss: 0.007692923813592643\n",
      "Training Loss: 0.00579845625848975\n",
      "Training Loss: 0.00437170788878575\n",
      "Training Loss: 0.004272751420503482\n",
      "Training Loss: 0.004251040926901623\n",
      "Validation Loss: 0.013754394706792097\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 17\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.0077239544840995225\n",
      "Training Loss: 0.007273890844080597\n",
      "Training Loss: 0.007659787947777659\n",
      "Training Loss: 0.0057719158899271865\n",
      "Training Loss: 0.004352738233865239\n",
      "Training Loss: 0.004249965018243529\n",
      "Training Loss: 0.004232415239675902\n",
      "Validation Loss: 0.013759907800268228\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 18\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007694793926784769\n",
      "Training Loss: 0.007244560450781137\n",
      "Training Loss: 0.007629147513071075\n",
      "Training Loss: 0.005748404340120032\n",
      "Training Loss: 0.004336060952045955\n",
      "Training Loss: 0.004230144341709092\n",
      "Training Loss: 0.004215998182189651\n",
      "Validation Loss: 0.013768445125306618\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 19\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007667575679952279\n",
      "Training Loss: 0.007217013732297346\n",
      "Training Loss: 0.007600398511858657\n",
      "Training Loss: 0.0057271668832981956\n",
      "Training Loss: 0.004321274945395998\n",
      "Training Loss: 0.004212722892989404\n",
      "Training Loss: 0.004201350237126462\n",
      "Validation Loss: 0.013778432171219743\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 20\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007641882689204067\n",
      "Training Loss: 0.007190964517067186\n",
      "Training Loss: 0.00757325925747864\n",
      "Training Loss: 0.005707740640500561\n",
      "Training Loss: 0.00430805413867347\n",
      "Training Loss: 0.0041972467507002875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [30:02<03:07, 187.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.004188134644064121\n",
      "Validation Loss: 0.01378869866143061\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 21\n",
      "Early stopping after 21 epochs\n",
      "Epoch: 1\n",
      "Training Loss: 0.37269078828394414\n",
      "Training Loss: 0.30078212343156335\n",
      "Training Loss: 0.22650113999843596\n",
      "Training Loss: 0.15607223879545928\n",
      "Training Loss: 0.099931746032089\n",
      "Training Loss: 0.06975164646282792\n",
      "Training Loss: 0.060899528432637455\n",
      "Validation Loss: 0.06018775129474504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.06098320895805955\n",
      "Training Loss: 0.057771068532019854\n",
      "Training Loss: 0.05625944262370467\n",
      "Training Loss: 0.05353976663202047\n",
      "Training Loss: 0.050219062408432366\n",
      "Training Loss: 0.047962899496778844\n",
      "Training Loss: 0.046784819439053535\n",
      "Validation Loss: 0.04917492220799128\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.04763099438510835\n",
      "Training Loss: 0.043615025887265804\n",
      "Training Loss: 0.04094929737970233\n",
      "Training Loss: 0.03662819787859917\n",
      "Training Loss: 0.03172568839043379\n",
      "Training Loss: 0.02830420445650816\n",
      "Training Loss: 0.02568662361241877\n",
      "Validation Loss: 0.03339144851914729\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.02682284018956125\n",
      "Training Loss: 0.02334513415582478\n",
      "Training Loss: 0.02148088426794857\n",
      "Training Loss: 0.017799931291956454\n",
      "Training Loss: 0.01406518485629931\n",
      "Training Loss: 0.012967151473276317\n",
      "Training Loss: 0.011954018087126315\n",
      "Validation Loss: 0.023291914057586523\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.015609902942087502\n",
      "Training Loss: 0.01422965913079679\n",
      "Training Loss: 0.014202739000320435\n",
      "Training Loss: 0.011716836573323236\n",
      "Training Loss: 0.009154019188135862\n",
      "Training Loss: 0.009016685307724401\n",
      "Training Loss: 0.008531600115820765\n",
      "Validation Loss: 0.020656738991845638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.012730976502643898\n",
      "Training Loss: 0.011813083819579333\n",
      "Training Loss: 0.012107981815934182\n",
      "Training Loss: 0.009890069082612172\n",
      "Training Loss: 0.007700933301821351\n",
      "Training Loss: 0.007695781367365271\n",
      "Training Loss: 0.0073708829539828\n",
      "Validation Loss: 0.01928416992910904\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.01147407164447941\n",
      "Training Loss: 0.010689442488364875\n",
      "Training Loss: 0.010968794929794967\n",
      "Training Loss: 0.00887591167294886\n",
      "Training Loss: 0.006889020227827131\n",
      "Training Loss: 0.006909191462909803\n",
      "Training Loss: 0.006652794808614999\n",
      "Validation Loss: 0.018411326904045174\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.010472730547189713\n",
      "Training Loss: 0.00974043246707879\n",
      "Training Loss: 0.009953890553442762\n",
      "Training Loss: 0.007973467375268228\n",
      "Training Loss: 0.006245597577653825\n",
      "Training Loss: 0.00628753307799343\n",
      "Training Loss: 0.006084550602245145\n",
      "Validation Loss: 0.018080630629194364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.009465446586254984\n",
      "Training Loss: 0.008798421625979245\n",
      "Training Loss: 0.009005236604716629\n",
      "Training Loss: 0.007227042572922073\n",
      "Training Loss: 0.005847957722144201\n",
      "Training Loss: 0.005930045806453563\n",
      "Training Loss: 0.005769312637858093\n",
      "Validation Loss: 0.01808233854660855\n",
      "Validation Accuracy: 0.0\n",
      "INFO: Validation loss did not improve in epoch 9\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.00876515981508419\n",
      "Training Loss: 0.008224539586808532\n",
      "Training Loss: 0.008507978775305673\n",
      "Training Loss: 0.006899957632413134\n",
      "Training Loss: 0.005707702238578349\n",
      "Training Loss: 0.005796512025408446\n",
      "Training Loss: 0.005640202343929559\n",
      "Validation Loss: 0.01789030191063016\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.008465905183693395\n",
      "Training Loss: 0.007991477015893906\n",
      "Training Loss: 0.008313760993769393\n",
      "Training Loss: 0.0067592596786562355\n",
      "Training Loss: 0.005620408761315048\n",
      "Training Loss: 0.005705355027457699\n",
      "Training Loss: 0.005550489134038799\n",
      "Validation Loss: 0.017594600953545408\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.008323314148001373\n",
      "Training Loss: 0.00787403687951155\n",
      "Training Loss: 0.008210720119532198\n",
      "Training Loss: 0.006666726864641532\n",
      "Training Loss: 0.0055422835575882345\n",
      "Training Loss: 0.0056236326997168365\n",
      "Training Loss: 0.00547280624625273\n",
      "Validation Loss: 0.01730950400303031\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.008233490453567355\n",
      "Training Loss: 0.007795976424822584\n",
      "Training Loss: 0.008139360731001943\n",
      "Training Loss: 0.006593025194015354\n",
      "Training Loss: 0.005471717327600345\n",
      "Training Loss: 0.005549553170567378\n",
      "Training Loss: 0.0054035975120496\n",
      "Validation Loss: 0.017057316082142546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.008166089224396274\n",
      "Training Loss: 0.007735496532404795\n",
      "Training Loss: 0.008083022714126855\n",
      "Training Loss: 0.006530145086580888\n",
      "Training Loss: 0.005408075731247663\n",
      "Training Loss: 0.0054823345423210415\n",
      "Training Loss: 0.00534131484630052\n",
      "Validation Loss: 0.016836028539118697\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.008110896967118607\n",
      "Training Loss: 0.007685046957340092\n",
      "Training Loss: 0.008035708563402294\n",
      "Training Loss: 0.00647485148278065\n",
      "Training Loss: 0.005350404264172539\n",
      "Training Loss: 0.0054210550547577445\n",
      "Training Loss: 0.0052848279738100246\n",
      "Validation Loss: 0.016640081914483608\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.008063690293347463\n",
      "Training Loss: 0.007641384719172493\n",
      "Training Loss: 0.007994695346569642\n",
      "Training Loss: 0.006425436808494851\n",
      "Training Loss: 0.005297837828984484\n",
      "Training Loss: 0.0053648947912734\n",
      "Training Loss: 0.005233284233254381\n",
      "Validation Loss: 0.01646466230474803\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.008022352148545906\n",
      "Training Loss: 0.007602823779452592\n",
      "Training Loss: 0.007958491838071496\n",
      "Training Loss: 0.006380833417642862\n",
      "Training Loss: 0.0052496848185546695\n",
      "Training Loss: 0.005313193923793733\n",
      "Training Loss: 0.005186032494530082\n",
      "Validation Loss: 0.01630621568617247\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.007985642640851437\n",
      "Training Loss: 0.007568342019803822\n",
      "Training Loss: 0.007926166675752029\n",
      "Training Loss: 0.006340295878471807\n",
      "Training Loss: 0.005205393087817356\n",
      "Training Loss: 0.005265420607756823\n",
      "Training Loss: 0.005142557584913447\n",
      "Validation Loss: 0.01616215900333131\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.007952733682468533\n",
      "Training Loss: 0.007537234907504171\n",
      "Training Loss: 0.007897067712619901\n",
      "Training Loss: 0.0063032603223109615\n",
      "Training Loss: 0.005164516069926322\n",
      "Training Loss: 0.005221146445255727\n",
      "Training Loss: 0.005102441816707142\n",
      "Validation Loss: 0.016030570709282595\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.007923024295596406\n",
      "Training Loss: 0.007508983670268208\n",
      "Training Loss: 0.0078707122663036\n",
      "Training Loss: 0.00626928515615873\n",
      "Training Loss: 0.005126689923927188\n",
      "Training Loss: 0.005180022191489116\n",
      "Training Loss: 0.005065338808344677\n",
      "Validation Loss: 0.015910010488375967\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.007896058254409581\n",
      "Training Loss: 0.007483188401674851\n",
      "Training Loss: 0.007846726642455906\n",
      "Training Loss: 0.006238006502971984\n",
      "Training Loss: 0.005091605560155585\n",
      "Training Loss: 0.005141751546179876\n",
      "Training Loss: 0.0050309514487162236\n",
      "Validation Loss: 0.015799376258124293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.007871469791280106\n",
      "Training Loss: 0.007459529505576938\n",
      "Training Loss: 0.007824810816673562\n",
      "Training Loss: 0.00620912351005245\n",
      "Training Loss: 0.005058997607557103\n",
      "Training Loss: 0.0051060804817825555\n",
      "Training Loss: 0.0049990273441653695\n",
      "Validation Loss: 0.0156976877666368\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.00784895640448667\n",
      "Training Loss: 0.007437743076588958\n",
      "Training Loss: 0.007804718656698242\n",
      "Training Loss: 0.006182382041588426\n",
      "Training Loss: 0.005028635982889682\n",
      "Training Loss: 0.005072790458798409\n",
      "Training Loss: 0.004969343512202613\n",
      "Validation Loss: 0.015604205555125568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.007828268236480654\n",
      "Training Loss: 0.007417608354007826\n",
      "Training Loss: 0.007786243202863261\n",
      "Training Loss: 0.00615756438113749\n",
      "Training Loss: 0.00500032305251807\n",
      "Training Loss: 0.0050416893826331945\n",
      "Training Loss: 0.004941708297701552\n",
      "Validation Loss: 0.01551824365306492\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.007809191924752668\n",
      "Training Loss: 0.007398943324806169\n",
      "Training Loss: 0.007769211848499253\n",
      "Training Loss: 0.0061344833858311175\n",
      "Training Loss: 0.004973877336014993\n",
      "Training Loss: 0.005012602111091838\n",
      "Training Loss: 0.004915945303509943\n",
      "Validation Loss: 0.015439219521672537\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.007791548251407221\n",
      "Training Loss: 0.007381590479053557\n",
      "Training Loss: 0.007753474133787677\n",
      "Training Loss: 0.006112976066651754\n",
      "Training Loss: 0.004949138754745945\n",
      "Training Loss: 0.004985371769871563\n",
      "Training Loss: 0.004891900339280255\n",
      "Validation Loss: 0.015366597564137552\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.0077751804585568605\n",
      "Training Loss: 0.007365415216190741\n",
      "Training Loss: 0.0077389019401744\n",
      "Training Loss: 0.006092899575596675\n",
      "Training Loss: 0.004925959589891136\n",
      "Training Loss: 0.004959849595325068\n",
      "Training Loss: 0.004869427410303615\n",
      "Validation Loss: 0.015299886690927076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.007759954303037375\n",
      "Training Loss: 0.007350302236154675\n",
      "Training Loss: 0.0077253833564464\n",
      "Training Loss: 0.00607412779761944\n",
      "Training Loss: 0.004904208785737865\n",
      "Training Loss: 0.004935903699370101\n",
      "Training Loss: 0.004848396666930057\n",
      "Validation Loss: 0.015238625577333548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.007745753549970686\n",
      "Training Loss: 0.007336149360053241\n",
      "Training Loss: 0.007712818923173472\n",
      "Training Loss: 0.006056550098583103\n",
      "Training Loss: 0.00488376225810498\n",
      "Training Loss: 0.004913408608408645\n",
      "Training Loss: 0.004828687948174775\n",
      "Validation Loss: 0.015182380077048913\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.007732475913362577\n",
      "Training Loss: 0.007322867909679189\n",
      "Training Loss: 0.007701119623379782\n",
      "Training Loss: 0.006040065055130981\n",
      "Training Loss: 0.004864513360662386\n",
      "Training Loss: 0.00489225129596889\n",
      "Training Loss: 0.004810190385906026\n",
      "Validation Loss: 0.015130743979954262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.0077200292574707416\n",
      "Training Loss: 0.007310376613168046\n",
      "Training Loss: 0.0076902049209456895\n",
      "Training Loss: 0.0060245839186245575\n",
      "Training Loss: 0.004846358090871945\n",
      "Training Loss: 0.004872322315350175\n",
      "Training Loss: 0.004792800667928532\n",
      "Validation Loss: 0.015083319289533052\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.007708335828501731\n",
      "Training Loss: 0.007298607733100653\n",
      "Training Loss: 0.007680004187859595\n",
      "Training Loss: 0.006010022928821854\n",
      "Training Loss: 0.004829202403780073\n",
      "Training Loss: 0.004853521139593795\n",
      "Training Loss: 0.004776421497226692\n",
      "Validation Loss: 0.015039729845643824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.007697323042666539\n",
      "Training Loss: 0.00728749439236708\n",
      "Training Loss: 0.00767045033746399\n",
      "Training Loss: 0.005996307276072912\n",
      "Training Loss: 0.00481296343205031\n",
      "Training Loss: 0.00483575850026682\n",
      "Training Loss: 0.004760967993643134\n",
      "Validation Loss: 0.014999579094971219\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.007686924895970151\n",
      "Training Loss: 0.007276979086454958\n",
      "Training Loss: 0.007661481710383669\n",
      "Training Loss: 0.005983368573361077\n",
      "Training Loss: 0.004797564501641319\n",
      "Training Loss: 0.004818949514301494\n",
      "Training Loss: 0.004746358943521045\n",
      "Validation Loss: 0.014962594642230634\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.0076770842436235396\n",
      "Training Loss: 0.007267007423797623\n",
      "Training Loss: 0.00765304158674553\n",
      "Training Loss: 0.005971142187481746\n",
      "Training Loss: 0.0047829381003975865\n",
      "Training Loss: 0.004803017576923594\n",
      "Training Loss: 0.004732520827674307\n",
      "Validation Loss: 0.014928400193860804\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.007667744437931105\n",
      "Training Loss: 0.007257527561159804\n",
      "Training Loss: 0.007645075331674888\n",
      "Training Loss: 0.005959567526588216\n",
      "Training Loss: 0.004769019482773728\n",
      "Training Loss: 0.004787890495499596\n",
      "Training Loss: 0.004719386193319224\n",
      "Validation Loss: 0.014896737974946306\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.007658857948845252\n",
      "Training Loss: 0.007248495313106105\n",
      "Training Loss: 0.00763753593317233\n",
      "Training Loss: 0.00594859039701987\n",
      "Training Loss: 0.0047557508910540496\n",
      "Training Loss: 0.004773502503521741\n",
      "Training Loss: 0.0047068917931756\n",
      "Validation Loss: 0.01486728469795837\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.007650377108948305\n",
      "Training Loss: 0.00723986754543148\n",
      "Training Loss: 0.00763037689961493\n",
      "Training Loss: 0.005938160178484395\n",
      "Training Loss: 0.004743080431362614\n",
      "Training Loss: 0.004759793148841709\n",
      "Training Loss: 0.0046949823969043795\n",
      "Validation Loss: 0.014839835741386264\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.007642260992433876\n",
      "Training Loss: 0.007231603376567364\n",
      "Training Loss: 0.007623557118931785\n",
      "Training Loss: 0.005928227702970617\n",
      "Training Loss: 0.0047309613676043225\n",
      "Training Loss: 0.004746708645252511\n",
      "Training Loss: 0.004683608055347577\n",
      "Validation Loss: 0.014814140565505021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.007634470213670284\n",
      "Training Loss: 0.007223667412763462\n",
      "Training Loss: 0.0076170389947947115\n",
      "Training Loss: 0.005918749764678068\n",
      "Training Loss: 0.004719348676153459\n",
      "Training Loss: 0.0047341975395102055\n",
      "Training Loss: 0.004672720241942443\n",
      "Validation Loss: 0.014789990110197262\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.007626969581469894\n",
      "Training Loss: 0.0072160246933344755\n",
      "Training Loss: 0.00761078697280027\n",
      "Training Loss: 0.005909686303930357\n",
      "Training Loss: 0.004708204632624984\n",
      "Training Loss: 0.004722214390640147\n",
      "Training Loss: 0.0046622796554584055\n",
      "Validation Loss: 0.014767198039878034\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.007619724258547649\n",
      "Training Loss: 0.007208643696503714\n",
      "Training Loss: 0.007604770375182852\n",
      "Training Loss: 0.00590099940483924\n",
      "Training Loss: 0.004697490516118705\n",
      "Training Loss: 0.0047107157623395325\n",
      "Training Loss: 0.004652245782781392\n",
      "Validation Loss: 0.014745601691385864\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.007612707201624289\n",
      "Training Loss: 0.00720149626256898\n",
      "Training Loss: 0.007598961532348767\n",
      "Training Loss: 0.005892655177158304\n",
      "Training Loss: 0.004687173911370337\n",
      "Training Loss: 0.0046996640431461855\n",
      "Training Loss: 0.004642586596310139\n",
      "Validation Loss: 0.014725059042824258\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.007605889319675044\n",
      "Training Loss: 0.007194556130561977\n",
      "Training Loss: 0.007593333550030366\n",
      "Training Loss: 0.005884622657904401\n",
      "Training Loss: 0.004677225300110876\n",
      "Training Loss: 0.004689023396931589\n",
      "Training Loss: 0.0046332705387612805\n",
      "Validation Loss: 0.014705460055553343\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.007599248680053279\n",
      "Training Loss: 0.007187801672844216\n",
      "Training Loss: 0.007587866737740114\n",
      "Training Loss: 0.005876872871303931\n",
      "Training Loss: 0.0046676144306547936\n",
      "Training Loss: 0.004678760173846968\n",
      "Training Loss: 0.004624268607585691\n",
      "Validation Loss: 0.014686667127098735\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.007592762934509664\n",
      "Training Loss: 0.0071812102966941896\n",
      "Training Loss: 0.0075825393479317426\n",
      "Training Loss: 0.005869380588992498\n",
      "Training Loss: 0.004658316606655717\n",
      "Training Loss: 0.004668844740954228\n",
      "Training Loss: 0.004615556244971231\n",
      "Validation Loss: 0.014668607367516568\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.0075864126032683995\n",
      "Training Loss: 0.007174763494404033\n",
      "Training Loss: 0.007577334305969998\n",
      "Training Loss: 0.005862121507525444\n",
      "Training Loss: 0.004649305931525305\n",
      "Training Loss: 0.004659248656244017\n",
      "Training Loss: 0.004607108687050641\n",
      "Validation Loss: 0.014651139640015609\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.007580180927179754\n",
      "Training Loss: 0.00716844427282922\n",
      "Training Loss: 0.0075722364650573585\n",
      "Training Loss: 0.005855074936989695\n",
      "Training Loss: 0.00464056155004073\n",
      "Training Loss: 0.004649946070276201\n",
      "Training Loss: 0.004598904995364137\n",
      "Validation Loss: 0.01463425695836851\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.007574054814176634\n",
      "Training Loss: 0.007162239758763463\n",
      "Training Loss: 0.007567233761074021\n",
      "Training Loss: 0.005848221885971725\n",
      "Training Loss: 0.004632061218144372\n",
      "Training Loss: 0.0046409130579559135\n",
      "Training Loss: 0.004590925713418983\n",
      "Validation Loss: 0.014617845974600968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.007568020017351955\n",
      "Training Loss: 0.00715613481705077\n",
      "Training Loss: 0.007562312105437741\n",
      "Training Loss: 0.005841544213471934\n",
      "Training Loss: 0.004623787206364796\n",
      "Training Loss: 0.004632129457313568\n",
      "Training Loss: 0.004583155082655139\n",
      "Validation Loss: 0.014601877259617245\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.0075620640104170885\n",
      "Training Loss: 0.007150117789860815\n",
      "Training Loss: 0.007557462200056761\n",
      "Training Loss: 0.005835026162094437\n",
      "Training Loss: 0.0046157227520598094\n",
      "Training Loss: 0.004623575296136551\n",
      "Training Loss: 0.004575575044145808\n",
      "Validation Loss: 0.014586263962355111\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.007556177362566814\n",
      "Training Loss: 0.007144177765585482\n",
      "Training Loss: 0.007552672893507406\n",
      "Training Loss: 0.00582865369564388\n",
      "Training Loss: 0.004607851015171036\n",
      "Training Loss: 0.004615230782073923\n",
      "Training Loss: 0.004568171721184626\n",
      "Validation Loss: 0.01457099457688225\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.007550351826939732\n",
      "Training Loss: 0.007138305603293702\n",
      "Training Loss: 0.007547937147319317\n",
      "Training Loss: 0.005822413516580127\n",
      "Training Loss: 0.0046001569245709105\n",
      "Training Loss: 0.004607081566355191\n",
      "Training Loss: 0.004560932051972486\n",
      "Validation Loss: 0.01455597774594785\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.007544578011147678\n",
      "Training Loss: 0.007132493326207623\n",
      "Training Loss: 0.0075432480371091515\n",
      "Training Loss: 0.005816293691750616\n",
      "Training Loss: 0.0045926261396380145\n",
      "Training Loss: 0.004599109104601666\n",
      "Training Loss: 0.00455384173837956\n",
      "Validation Loss: 0.014541220694278063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.007538852012949064\n",
      "Training Loss: 0.007126733978511765\n",
      "Training Loss: 0.007538597198436037\n",
      "Training Loss: 0.0058102824905654415\n",
      "Training Loss: 0.004585245579946786\n",
      "Training Loss: 0.004591298765153624\n",
      "Training Loss: 0.004546889148768969\n",
      "Validation Loss: 0.014526632682015693\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.007533166147768497\n",
      "Training Loss: 0.00712102168938145\n",
      "Training Loss: 0.0075339807744603604\n",
      "Training Loss: 0.005804371458943933\n",
      "Training Loss: 0.004578004151699133\n",
      "Training Loss: 0.004583639630582183\n",
      "Training Loss: 0.004540066052577459\n",
      "Validation Loss: 0.014512230914211674\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.007527514466783031\n",
      "Training Loss: 0.007115346593782306\n",
      "Training Loss: 0.007529390382114798\n",
      "Training Loss: 0.0057985507312696425\n",
      "Training Loss: 0.004570891268085689\n",
      "Training Loss: 0.004576118853874505\n",
      "Training Loss: 0.004533362026559189\n",
      "Validation Loss: 0.01449796027758539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.0075218929443508385\n",
      "Training Loss: 0.00710970742860809\n",
      "Training Loss: 0.007524821765255183\n",
      "Training Loss: 0.005792812424479052\n",
      "Training Loss: 0.004563897494808771\n",
      "Training Loss: 0.004568725785939023\n",
      "Training Loss: 0.004526768907089718\n",
      "Validation Loss: 0.014483787817008487\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.007516295074019581\n",
      "Training Loss: 0.007104095224058256\n",
      "Training Loss: 0.007520269306842238\n",
      "Training Loss: 0.005787148404633627\n",
      "Training Loss: 0.004557011420838535\n",
      "Training Loss: 0.0045614476827904584\n",
      "Training Loss: 0.004520275939721614\n",
      "Validation Loss: 0.014469676072908085\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.007510719418060034\n",
      "Training Loss: 0.007098508439958096\n",
      "Training Loss: 0.007515728659927845\n",
      "Training Loss: 0.00578155156399589\n",
      "Training Loss: 0.00455022553098388\n",
      "Training Loss: 0.0045542770973406735\n",
      "Training Loss: 0.00451387730485294\n",
      "Validation Loss: 0.014455603777033308\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.007505162346642464\n",
      "Training Loss: 0.0070929414487909525\n",
      "Training Loss: 0.007511195325059816\n",
      "Training Loss: 0.0057760158827295524\n",
      "Training Loss: 0.0045435320562683046\n",
      "Training Loss: 0.0045472040498862045\n",
      "Training Loss: 0.004507566095562652\n",
      "Validation Loss: 0.014441543982507249\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.007499619083246216\n",
      "Training Loss: 0.007087389969965443\n",
      "Training Loss: 0.007506662268424407\n",
      "Training Loss: 0.005770534428884275\n",
      "Training Loss: 0.004536926060682163\n",
      "Training Loss: 0.004540223145158962\n",
      "Training Loss: 0.0045013383333571255\n",
      "Validation Loss: 0.014427459478284117\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.007494084680220112\n",
      "Training Loss: 0.00708184881717898\n",
      "Training Loss: 0.007502127398038283\n",
      "Training Loss: 0.005765102473669685\n",
      "Training Loss: 0.004530397829366848\n",
      "Training Loss: 0.004533323805080727\n",
      "Training Loss: 0.0044951839064015075\n",
      "Validation Loss: 0.01441330796854103\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.007488561341306195\n",
      "Training Loss: 0.007076318212784827\n",
      "Training Loss: 0.007497586231911555\n",
      "Training Loss: 0.005759715086896904\n",
      "Training Loss: 0.004523942859959789\n",
      "Training Loss: 0.004526499899220653\n",
      "Training Loss: 0.004489101012004539\n",
      "Validation Loss: 0.014399069298166879\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.0074830414715688675\n",
      "Training Loss: 0.007070792287122458\n",
      "Training Loss: 0.007493033240316436\n",
      "Training Loss: 0.005754366523469798\n",
      "Training Loss: 0.0045175552135333415\n",
      "Training Loss: 0.004519744458957575\n",
      "Training Loss: 0.004483081888756715\n",
      "Validation Loss: 0.014384703533218177\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.007477526194415987\n",
      "Training Loss: 0.0070652691414579746\n",
      "Training Loss: 0.0074884641845710575\n",
      "Training Loss: 0.0057490526197943835\n",
      "Training Loss: 0.004511228679912165\n",
      "Training Loss: 0.0045130514405900615\n",
      "Training Loss: 0.004477123150136322\n",
      "Validation Loss: 0.014370200812837549\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.0074720123631414025\n",
      "Training Loss: 0.007059745952719822\n",
      "Training Loss: 0.007483876365004107\n",
      "Training Loss: 0.005743770449771546\n",
      "Training Loss: 0.00450496137724258\n",
      "Training Loss: 0.0045064161391928795\n",
      "Training Loss: 0.004471220041741617\n",
      "Validation Loss: 0.01435550095902386\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.0074664981465321035\n",
      "Training Loss: 0.007054218562552705\n",
      "Training Loss: 0.007479263653513044\n",
      "Training Loss: 0.005738514245604165\n",
      "Training Loss: 0.0044987476710230115\n",
      "Training Loss: 0.004499831744469702\n",
      "Training Loss: 0.004465368784149177\n",
      "Validation Loss: 0.014340582929380685\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.007460982109187171\n",
      "Training Loss: 0.007048687936039641\n",
      "Training Loss: 0.007474624511087313\n",
      "Training Loss: 0.00573328239552211\n",
      "Training Loss: 0.004492583743412979\n",
      "Training Loss: 0.0044932936347322535\n",
      "Training Loss: 0.004459565145662054\n",
      "Validation Loss: 0.01432540953815095\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.007455464055528865\n",
      "Training Loss: 0.007043149505043402\n",
      "Training Loss: 0.0074699535116087646\n",
      "Training Loss: 0.005728071557241492\n",
      "Training Loss: 0.0044864677678560835\n",
      "Training Loss: 0.004486797453719191\n",
      "Training Loss: 0.004453806487726979\n",
      "Validation Loss: 0.01430994670006206\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.007449940568767488\n",
      "Training Loss: 0.0070376003615092485\n",
      "Training Loss: 0.007465247026411817\n",
      "Training Loss: 0.005722877829102799\n",
      "Training Loss: 0.004480399153544567\n",
      "Training Loss: 0.0044803404400590805\n",
      "Training Loss: 0.004448089747456834\n",
      "Validation Loss: 0.014294162021569684\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.007444411893375218\n",
      "Training Loss: 0.007032040761550888\n",
      "Training Loss: 0.007460502455942332\n",
      "Training Loss: 0.0057176991342566905\n",
      "Training Loss: 0.004474371389369481\n",
      "Training Loss: 0.004473914180416614\n",
      "Training Loss: 0.004442408753093332\n",
      "Validation Loss: 0.014278032340384909\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.0074388799071311955\n",
      "Training Loss: 0.007026468528201804\n",
      "Training Loss: 0.0074557161994744095\n",
      "Training Loss: 0.005712532710749656\n",
      "Training Loss: 0.004468385597574525\n",
      "Training Loss: 0.004467517419834621\n",
      "Training Loss: 0.004436761948163621\n",
      "Validation Loss: 0.01426151548407637\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.007433339523850009\n",
      "Training Loss: 0.007020879868650809\n",
      "Training Loss: 0.007450885493308306\n",
      "Training Loss: 0.005707376060308888\n",
      "Training Loss: 0.004462439293856733\n",
      "Training Loss: 0.00446114354475867\n",
      "Training Loss: 0.00443114442168735\n",
      "Validation Loss: 0.014244609853786448\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.007427793561946601\n",
      "Training Loss: 0.007015274441801012\n",
      "Training Loss: 0.007446007411926985\n",
      "Training Loss: 0.005702226175344549\n",
      "Training Loss: 0.004456529718008823\n",
      "Training Loss: 0.0044547884969506416\n",
      "Training Loss: 0.004425550730084069\n",
      "Validation Loss: 0.014227275772382983\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.007422241242602467\n",
      "Training Loss: 0.0070096480473876\n",
      "Training Loss: 0.00744107982260175\n",
      "Training Loss: 0.005697080089594238\n",
      "Training Loss: 0.004450656280387193\n",
      "Training Loss: 0.004448447853792459\n",
      "Training Loss: 0.0044199774431763214\n",
      "Validation Loss: 0.014209547179946432\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.007416680975584313\n",
      "Training Loss: 0.0070039984793402255\n",
      "Training Loss: 0.007436101398197934\n",
      "Training Loss: 0.005691934765200131\n",
      "Training Loss: 0.004444815878523514\n",
      "Training Loss: 0.004442115232814103\n",
      "Training Loss: 0.004414418895030394\n",
      "Validation Loss: 0.014191416593631276\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.007411109212553129\n",
      "Training Loss: 0.006998320487327874\n",
      "Training Loss: 0.007431067958241329\n",
      "Training Loss: 0.005686784699792042\n",
      "Training Loss: 0.0044390049675712365\n",
      "Training Loss: 0.004435785100213252\n",
      "Training Loss: 0.00440886638883967\n",
      "Validation Loss: 0.014172906281464918\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.0074055260908789935\n",
      "Training Loss: 0.006992610389133915\n",
      "Training Loss: 0.007425979719264433\n",
      "Training Loss: 0.0056816256453748794\n",
      "Training Loss: 0.004433218362391926\n",
      "Training Loss: 0.004429447918664664\n",
      "Training Loss: 0.004403314452501945\n",
      "Validation Loss: 0.014154049107449109\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.007399927205406129\n",
      "Training Loss: 0.006986860276665539\n",
      "Training Loss: 0.007420830603223294\n",
      "Training Loss: 0.005676450905157253\n",
      "Training Loss: 0.0044274521199986335\n",
      "Training Loss: 0.004423099036212079\n",
      "Training Loss: 0.004397754535311833\n",
      "Validation Loss: 0.014134914504821074\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.007394305245252326\n",
      "Training Loss: 0.006981060712132603\n",
      "Training Loss: 0.007415617045480758\n",
      "Training Loss: 0.005671253565815278\n",
      "Training Loss: 0.004421698804944754\n",
      "Training Loss: 0.004416728675132617\n",
      "Training Loss: 0.004392178709385916\n",
      "Validation Loss: 0.01411554314656539\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.007388655337272212\n",
      "Training Loss: 0.0069752043671906\n",
      "Training Loss: 0.007410335558233783\n",
      "Training Loss: 0.0056660254765301945\n",
      "Training Loss: 0.004415949051035568\n",
      "Training Loss: 0.004410327483783476\n",
      "Training Loss: 0.004386576332617551\n",
      "Validation Loss: 0.01409603507748076\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.007382968879537657\n",
      "Training Loss: 0.00696927792741917\n",
      "Training Loss: 0.0074049801903311166\n",
      "Training Loss: 0.005660756438737735\n",
      "Training Loss: 0.004410197133547626\n",
      "Training Loss: 0.004403888172819279\n",
      "Training Loss: 0.004380941440467722\n",
      "Validation Loss: 0.014076473276402927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.007377234499435872\n",
      "Training Loss: 0.006963267428800463\n",
      "Training Loss: 0.007399541885824874\n",
      "Training Loss: 0.005655438258545473\n",
      "Training Loss: 0.004404431278235279\n",
      "Training Loss: 0.004397401374299079\n",
      "Training Loss: 0.004375265225535259\n",
      "Validation Loss: 0.014056982546661063\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.007371439886046573\n",
      "Training Loss: 0.006957157535944134\n",
      "Training Loss: 0.00739401254337281\n",
      "Training Loss: 0.005650058695464395\n",
      "Training Loss: 0.004398643554886803\n",
      "Training Loss: 0.004390858386759646\n",
      "Training Loss: 0.004369540245388635\n",
      "Validation Loss: 0.014037615308286936\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.007365569971734658\n",
      "Training Loss: 0.006950933701591566\n",
      "Training Loss: 0.007388383187353611\n",
      "Training Loss: 0.005644606447312981\n",
      "Training Loss: 0.0043928177852649245\n",
      "Training Loss: 0.004384247760172002\n",
      "Training Loss: 0.004363758290419355\n",
      "Validation Loss: 0.014018474155443996\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.007359612712170929\n",
      "Training Loss: 0.006944576253881678\n",
      "Training Loss: 0.007382640703581273\n",
      "Training Loss: 0.005639072023332119\n",
      "Training Loss: 0.004386950476327911\n",
      "Training Loss: 0.004377565946197137\n",
      "Training Loss: 0.004357915638829582\n",
      "Validation Loss: 0.013999661893325716\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.00735354810836725\n",
      "Training Loss: 0.006938069275347516\n",
      "Training Loss: 0.007376771478448063\n",
      "Training Loss: 0.005633442819816992\n",
      "Training Loss: 0.004381024453905411\n",
      "Training Loss: 0.0043708009441616015\n",
      "Training Loss: 0.004352003667736426\n",
      "Validation Loss: 0.013981230611466429\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.007347363110166043\n",
      "Training Loss: 0.006931394110433757\n",
      "Training Loss: 0.00737076553166844\n",
      "Training Loss: 0.005627707939711399\n",
      "Training Loss: 0.004375029823277146\n",
      "Training Loss: 0.004363945670775138\n",
      "Training Loss: 0.00434601950168144\n",
      "Validation Loss: 0.013963253232946947\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.007341040659230203\n",
      "Training Loss: 0.006924534577410668\n",
      "Training Loss: 0.007364606322953477\n",
      "Training Loss: 0.005621858371887356\n",
      "Training Loss: 0.00436895675258711\n",
      "Training Loss: 0.0043569924595067274\n",
      "Training Loss: 0.004339956503827125\n",
      "Validation Loss: 0.013945781296617893\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.0073345656401943415\n",
      "Training Loss: 0.006917473031207919\n",
      "Training Loss: 0.007358279692707584\n",
      "Training Loss: 0.005615882845595479\n",
      "Training Loss: 0.004362794068292715\n",
      "Training Loss: 0.004349934947676957\n",
      "Training Loss: 0.004333812085096724\n",
      "Validation Loss: 0.01392887798809422\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.007327920295065269\n",
      "Training Loss: 0.006910192158538848\n",
      "Training Loss: 0.007351770923705771\n",
      "Training Loss: 0.0056097726151347165\n",
      "Training Loss: 0.004356532634119503\n",
      "Training Loss: 0.004342768178903497\n",
      "Training Loss: 0.004327582883415743\n",
      "Validation Loss: 0.013912548293178197\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.007321087849559263\n",
      "Training Loss: 0.006902674016309902\n",
      "Training Loss: 0.0073450631415471436\n",
      "Training Loss: 0.005603520174627192\n",
      "Training Loss: 0.004350162454065867\n",
      "Training Loss: 0.0043354833079501985\n",
      "Training Loss: 0.004321263393503614\n",
      "Validation Loss: 0.013896847560597158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.007314058127813041\n",
      "Training Loss: 0.0068949076149147\n",
      "Training Loss: 0.007338144986424595\n",
      "Training Loss: 0.005597116795252077\n",
      "Training Loss: 0.004343676763237454\n",
      "Training Loss: 0.00432807766890619\n",
      "Training Loss: 0.004314852961688303\n",
      "Validation Loss: 0.013881785207783824\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.007306815251940862\n",
      "Training Loss: 0.006886877391953022\n",
      "Training Loss: 0.00733100023586303\n",
      "Training Loss: 0.005590556035749614\n",
      "Training Loss: 0.004337065555737354\n",
      "Training Loss: 0.0043205451907124374\n",
      "Training Loss: 0.00430834632308688\n",
      "Validation Loss: 0.01386738299960724\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.007299351231195033\n",
      "Training Loss: 0.006878573368303478\n",
      "Training Loss: 0.0073236169072333724\n",
      "Training Loss: 0.005583831180119887\n",
      "Training Loss: 0.004330321260495111\n",
      "Training Loss: 0.004312881474616006\n",
      "Training Loss: 0.004301739102811552\n",
      "Validation Loss: 0.013853627499472\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.007291658902540803\n",
      "Training Loss: 0.006869990004925057\n",
      "Training Loss: 0.007315986071480438\n",
      "Training Loss: 0.005576939758611843\n",
      "Training Loss: 0.004323438470601104\n",
      "Training Loss: 0.00430508402583655\n",
      "Training Loss: 0.0042950312665198\n",
      "Validation Loss: 0.013840530726933078\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.007283729426562786\n",
      "Training Loss: 0.00686111758928746\n",
      "Training Loss: 0.007308097768109292\n",
      "Training Loss: 0.005569877757807262\n",
      "Training Loss: 0.004316413645283319\n",
      "Training Loss: 0.004297151383943856\n",
      "Training Loss: 0.004288219547597691\n",
      "Validation Loss: 0.013828055032752175\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.007275559520348906\n",
      "Training Loss: 0.006851955935126171\n",
      "Training Loss: 0.00729994529276155\n",
      "Training Loss: 0.005562644640449434\n",
      "Training Loss: 0.004309240725706332\n",
      "Training Loss: 0.004289082704926841\n",
      "Training Loss: 0.004281300330185331\n",
      "Validation Loss: 0.013816198247767399\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.007267152381828055\n",
      "Training Loss: 0.006842507434776053\n",
      "Training Loss: 0.007291528498753906\n",
      "Training Loss: 0.005555242246482521\n",
      "Training Loss: 0.004301918996497988\n",
      "Training Loss: 0.0042808775982121\n",
      "Training Loss: 0.004274271960020996\n",
      "Validation Loss: 0.013804915021016691\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.00725851422525011\n",
      "Training Loss: 0.006832779574906454\n",
      "Training Loss: 0.007282849340699613\n",
      "Training Loss: 0.005547672751126811\n",
      "Training Loss: 0.004294447272550315\n",
      "Training Loss: 0.004272538737859577\n",
      "Training Loss: 0.004267132407985628\n",
      "Validation Loss: 0.013794133216421702\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.007249650745652616\n",
      "Training Loss: 0.006822782040107995\n",
      "Training Loss: 0.007273912959499284\n",
      "Training Loss: 0.005539941241731867\n",
      "Training Loss: 0.004286829446791671\n",
      "Training Loss: 0.004264071612269617\n",
      "Training Loss: 0.004259883002960123\n",
      "Validation Loss: 0.013783796729645534\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.00724057275801897\n",
      "Training Loss: 0.0068125290924217555\n",
      "Training Loss: 0.007264731258619577\n",
      "Training Loss: 0.0055320564686553554\n",
      "Training Loss: 0.004279066704912111\n",
      "Training Loss: 0.004255480610881932\n",
      "Training Loss: 0.0042525221884716306\n",
      "Validation Loss: 0.01377381840485326\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.007231300356797874\n",
      "Training Loss: 0.00680204154108651\n",
      "Training Loss: 0.007255319554824382\n",
      "Training Loss: 0.005524028367944993\n",
      "Training Loss: 0.00427116789331194\n",
      "Training Loss: 0.004246774222701788\n",
      "Training Loss: 0.004245051194448024\n",
      "Validation Loss: 0.01376408187991657\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.007221848499029875\n",
      "Training Loss: 0.006791341612115503\n",
      "Training Loss: 0.007245698226615787\n",
      "Training Loss: 0.005515869430964813\n",
      "Training Loss: 0.004263140286784619\n",
      "Training Loss: 0.004237963343621231\n",
      "Training Loss: 0.0042374728457070885\n",
      "Validation Loss: 0.013754505937489985\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.007212243638932705\n",
      "Training Loss: 0.0067804591113235805\n",
      "Training Loss: 0.007235893986653537\n",
      "Training Loss: 0.0055075917253270745\n",
      "Training Loss: 0.004254992687492631\n",
      "Training Loss: 0.004229057596530765\n",
      "Training Loss: 0.004229790030512959\n",
      "Validation Loss: 0.013744894726453035\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.007202508348273113\n",
      "Training Loss: 0.00676942080957815\n",
      "Training Loss: 0.0072259344498161225\n",
      "Training Loss: 0.005499213652219623\n",
      "Training Loss: 0.004246743705007248\n",
      "Training Loss: 0.004220074121258221\n",
      "Training Loss: 0.004222010565572418\n",
      "Validation Loss: 0.013735161701824223\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.00719266838626936\n",
      "Training Loss: 0.006758258809568361\n",
      "Training Loss: 0.00721585160237737\n",
      "Training Loss: 0.005490749996388331\n",
      "Training Loss: 0.004238400952890515\n",
      "Training Loss: 0.004211026387056335\n",
      "Training Loss: 0.0042141399794491\n",
      "Validation Loss: 0.013725171878511846\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.0071827500453218816\n",
      "Training Loss: 0.0067470023117493835\n",
      "Training Loss: 0.007205676470184699\n",
      "Training Loss: 0.005482217095559463\n",
      "Training Loss: 0.004229985144920647\n",
      "Training Loss: 0.004201929326518439\n",
      "Training Loss: 0.004206186935771256\n",
      "Validation Loss: 0.013714801764712157\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.007172777423402294\n",
      "Training Loss: 0.006735681392019615\n",
      "Training Loss: 0.007195441056974232\n",
      "Training Loss: 0.005473631695494987\n",
      "Training Loss: 0.00422151297214441\n",
      "Training Loss: 0.004192802793695592\n",
      "Training Loss: 0.004198163517285139\n",
      "Validation Loss: 0.013703872840363212\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.007162773456657306\n",
      "Training Loss: 0.006724321122746914\n",
      "Training Loss: 0.0071851754852104936\n",
      "Training Loss: 0.005465010182233527\n",
      "Training Loss: 0.004213002684991807\n",
      "Training Loss: 0.004183664491283707\n",
      "Training Loss: 0.004190081026172266\n",
      "Validation Loss: 0.013692333579694762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.007152758848387748\n",
      "Training Loss: 0.006712946912739426\n",
      "Training Loss: 0.00717490853392519\n",
      "Training Loss: 0.00545636517519597\n",
      "Training Loss: 0.004204469626420178\n",
      "Training Loss: 0.004174527800059878\n",
      "Training Loss: 0.004181953337974846\n",
      "Validation Loss: 0.013680045221747364\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.00714275314239785\n",
      "Training Loss: 0.006701578608481213\n",
      "Training Loss: 0.007164664015872404\n",
      "Training Loss: 0.005447710565640591\n",
      "Training Loss: 0.004195934322779067\n",
      "Training Loss: 0.004165412367437966\n",
      "Training Loss: 0.004173793022055179\n",
      "Validation Loss: 0.013666960741707196\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.007132770879543386\n",
      "Training Loss: 0.0066902363230474295\n",
      "Training Loss: 0.007154463082551956\n",
      "Training Loss: 0.0054390583734493705\n",
      "Training Loss: 0.0041874118440318854\n",
      "Training Loss: 0.0041563329345081\n",
      "Training Loss: 0.00416561754362192\n",
      "Validation Loss: 0.01365301968165314\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.007122823733370751\n",
      "Training Loss: 0.006678932443028316\n",
      "Training Loss: 0.007144323559477925\n",
      "Training Loss: 0.005430417399038561\n",
      "Training Loss: 0.0041789213276933876\n",
      "Training Loss: 0.004147307661478408\n",
      "Training Loss: 0.004157440306735225\n",
      "Validation Loss: 0.013638213180504349\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.0071129209198988975\n",
      "Training Loss: 0.006667676875367761\n",
      "Training Loss: 0.007134258190635592\n",
      "Training Loss: 0.005421795981237665\n",
      "Training Loss: 0.004170474670827389\n",
      "Training Loss: 0.004138345421524719\n",
      "Training Loss: 0.0041492741683032365\n",
      "Validation Loss: 0.01362251620024638\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.007103070273296907\n",
      "Training Loss: 0.006656477485084906\n",
      "Training Loss: 0.00712427690741606\n",
      "Training Loss: 0.005413200364564545\n",
      "Training Loss: 0.0041620879422407595\n",
      "Training Loss: 0.0041294619353720915\n",
      "Training Loss: 0.0041411329334368925\n",
      "Validation Loss: 0.013605965362436204\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.007093278585234657\n",
      "Training Loss: 0.006645342773990706\n",
      "Training Loss: 0.007114385975291952\n",
      "Training Loss: 0.005404635831946507\n",
      "Training Loss: 0.004153772903373465\n",
      "Training Loss: 0.004120666693197563\n",
      "Training Loss: 0.004133030590019189\n",
      "Validation Loss: 0.013588582826534126\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.0070835483417613435\n",
      "Training Loss: 0.0066342739970423285\n",
      "Training Loss: 0.007104589866939932\n",
      "Training Loss: 0.005396106584230438\n",
      "Training Loss: 0.0041455405455781144\n",
      "Training Loss: 0.004111968944198452\n",
      "Training Loss: 0.0041249774186871944\n",
      "Validation Loss: 0.013570442009623047\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.0070738819555845114\n",
      "Training Loss: 0.00662327344645746\n",
      "Training Loss: 0.007094890882726758\n",
      "Training Loss: 0.005387615536455996\n",
      "Training Loss: 0.004137401404441334\n",
      "Training Loss: 0.004103378057479858\n",
      "Training Loss: 0.004116983651765622\n",
      "Validation Loss: 0.013551603117172888\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.0070642803481314334\n",
      "Training Loss: 0.006612340619321913\n",
      "Training Loss: 0.007085289143724367\n",
      "Training Loss: 0.005379163977340795\n",
      "Training Loss: 0.004129361783852801\n",
      "Training Loss: 0.0040948985092109065\n",
      "Training Loss: 0.004109058419126086\n",
      "Validation Loss: 0.013532116975153932\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.007054748206282966\n",
      "Training Loss: 0.006601478859083727\n",
      "Training Loss: 0.0070757841446902605\n",
      "Training Loss: 0.005370754434261471\n",
      "Training Loss: 0.004121429905062542\n",
      "Training Loss: 0.004086537905386649\n",
      "Training Loss: 0.004101208877400495\n",
      "Validation Loss: 0.01351208483306726\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.007045283402549103\n",
      "Training Loss: 0.006590685240225867\n",
      "Training Loss: 0.0070663738588336855\n",
      "Training Loss: 0.005362385842599906\n",
      "Training Loss: 0.004113608438638039\n",
      "Training Loss: 0.004078296509687789\n",
      "Training Loss: 0.004093439690768719\n",
      "Validation Loss: 0.013491614074672987\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.00703588827745989\n",
      "Training Loss: 0.00657995932851918\n",
      "Training Loss: 0.007057055417681113\n",
      "Training Loss: 0.005354059593519196\n",
      "Training Loss: 0.004105903680901975\n",
      "Training Loss: 0.0040701812296174466\n",
      "Training Loss: 0.004085758790024556\n",
      "Validation Loss: 0.013470798418665312\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.007026560151134617\n",
      "Training Loss: 0.006569298871327191\n",
      "Training Loss: 0.007047824084293097\n",
      "Training Loss: 0.005345776453032159\n",
      "Training Loss: 0.0040983201540075245\n",
      "Training Loss: 0.004062194272992201\n",
      "Training Loss: 0.004078169803251513\n",
      "Validation Loss: 0.013449697710367876\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.007017300965962932\n",
      "Training Loss: 0.006558702308684588\n",
      "Training Loss: 0.007038678540848196\n",
      "Training Loss: 0.00533753604569938\n",
      "Training Loss: 0.004090857839328237\n",
      "Training Loss: 0.0040543351863743735\n",
      "Training Loss: 0.0040706741926260295\n",
      "Validation Loss: 0.013428411410322713\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.007008109978050925\n",
      "Training Loss: 0.00654816712369211\n",
      "Training Loss: 0.0070296124648302795\n",
      "Training Loss: 0.005329336280119605\n",
      "Training Loss: 0.004083520311978645\n",
      "Training Loss: 0.004046607405762188\n",
      "Training Loss: 0.004063275654334575\n",
      "Validation Loss: 0.01340705485515687\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.006998985658865422\n",
      "Training Loss: 0.0065376925643067805\n",
      "Training Loss: 0.007020622062264011\n",
      "Training Loss: 0.005321179688326083\n",
      "Training Loss: 0.00407630874949973\n",
      "Training Loss: 0.004039010729175061\n",
      "Training Loss: 0.004055976193631068\n",
      "Validation Loss: 0.013385680612274324\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.006989928869297728\n",
      "Training Loss: 0.006527276046108454\n",
      "Training Loss: 0.007011703713797033\n",
      "Training Loss: 0.005313064929796382\n",
      "Training Loss: 0.004069223494734615\n",
      "Training Loss: 0.004031544928438962\n",
      "Training Loss: 0.004048775649280288\n",
      "Validation Loss: 0.013364378368126208\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.006980937463231385\n",
      "Training Loss: 0.006516915232641623\n",
      "Training Loss: 0.0070028509455733\n",
      "Training Loss: 0.005304991831071675\n",
      "Training Loss: 0.004062267136177979\n",
      "Training Loss: 0.004024214525124989\n",
      "Training Loss: 0.0040416791441384705\n",
      "Validation Loss: 0.013343188902956158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.006972008000593633\n",
      "Training Loss: 0.006506606017937884\n",
      "Training Loss: 0.006994057714473456\n",
      "Training Loss: 0.00529695954232011\n",
      "Training Loss: 0.004055437814095057\n",
      "Training Loss: 0.004017016447032801\n",
      "Training Loss: 0.004034682464553043\n",
      "Validation Loss: 0.013322196085501309\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.006963143316097558\n",
      "Training Loss: 0.006496351843234152\n",
      "Training Loss: 0.006985321318497881\n",
      "Training Loss: 0.005288968784734607\n",
      "Training Loss: 0.0040487343800487\n",
      "Training Loss: 0.0040099505055695775\n",
      "Training Loss: 0.004027789715328254\n",
      "Validation Loss: 0.013301459265775169\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.006954337530769408\n",
      "Training Loss: 0.006486145905219018\n",
      "Training Loss: 0.006976634833263233\n",
      "Training Loss: 0.0052810216706711795\n",
      "Training Loss: 0.004042159701348282\n",
      "Training Loss: 0.004003018232178874\n",
      "Training Loss: 0.004021000209613703\n",
      "Validation Loss: 0.013281005384550475\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.006945591463590972\n",
      "Training Loss: 0.006475989571772516\n",
      "Training Loss: 0.00696799332392402\n",
      "Training Loss: 0.005273115891613997\n",
      "Training Loss: 0.004035714517813176\n",
      "Training Loss: 0.003996221078559756\n",
      "Training Loss: 0.004014314471860416\n",
      "Validation Loss: 0.013260908653324797\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.00693690410873387\n",
      "Training Loss: 0.0064658827963285145\n",
      "Training Loss: 0.006959391474956647\n",
      "Training Loss: 0.005265254228725098\n",
      "Training Loss: 0.004029394935350865\n",
      "Training Loss: 0.003989557416061871\n",
      "Training Loss: 0.0040077325468882916\n",
      "Validation Loss: 0.013241163005421028\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.006928274437668734\n",
      "Training Loss: 0.006455826248275116\n",
      "Training Loss: 0.006950825555250049\n",
      "Training Loss: 0.005257437989930622\n",
      "Training Loss: 0.004023203629185445\n",
      "Training Loss: 0.003983028655638919\n",
      "Training Loss: 0.004001256644842215\n",
      "Validation Loss: 0.013221825480858764\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.006919698479468934\n",
      "Training Loss: 0.0064458190067671235\n",
      "Training Loss: 0.0069422900129575285\n",
      "Training Loss: 0.005249668551259674\n",
      "Training Loss: 0.004017139461939223\n",
      "Training Loss: 0.003976636287407018\n",
      "Training Loss: 0.0039948870555963365\n",
      "Validation Loss: 0.013202937172066546\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.006911177840083838\n",
      "Training Loss: 0.0064358624035958205\n",
      "Training Loss: 0.006933778205420822\n",
      "Training Loss: 0.005241948207840324\n",
      "Training Loss: 0.004011202820111066\n",
      "Training Loss: 0.003970377886435017\n",
      "Training Loss: 0.0039886225672671576\n",
      "Validation Loss: 0.013184443380411588\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.006902710915892385\n",
      "Training Loss: 0.006425958208274097\n",
      "Training Loss: 0.006925290573854\n",
      "Training Loss: 0.005234278834541329\n",
      "Training Loss: 0.004005391891696491\n",
      "Training Loss: 0.0039642554376041516\n",
      "Training Loss: 0.003982466221787035\n",
      "Validation Loss: 0.013166410234592828\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.006894294818048366\n",
      "Training Loss: 0.006416106948163361\n",
      "Training Loss: 0.006916818090248853\n",
      "Training Loss: 0.005226661573979072\n",
      "Training Loss: 0.003999705871101469\n",
      "Training Loss: 0.003958268751739524\n",
      "Training Loss: 0.003976418187376112\n",
      "Validation Loss: 0.013148831608199449\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.006885930395801551\n",
      "Training Loss: 0.006406312417821028\n",
      "Training Loss: 0.006908358425134793\n",
      "Training Loss: 0.005219099890673533\n",
      "Training Loss: 0.0039941480226116256\n",
      "Training Loss: 0.003952419489505701\n",
      "Training Loss: 0.003970480524585583\n",
      "Validation Loss: 0.013131746467227319\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.006877615822013468\n",
      "Training Loss: 0.006396576901897788\n",
      "Training Loss: 0.0068999099114444105\n",
      "Training Loss: 0.005211595182190649\n",
      "Training Loss: 0.003988713499857113\n",
      "Training Loss: 0.003946703854599037\n",
      "Training Loss: 0.003964652704307809\n",
      "Validation Loss: 0.013115097534902087\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.00686935015488416\n",
      "Training Loss: 0.006386902458034456\n",
      "Training Loss: 0.0068914664653129875\n",
      "Training Loss: 0.005204150404315442\n",
      "Training Loss: 0.003983401922159829\n",
      "Training Loss: 0.003941123142722063\n",
      "Training Loss: 0.003958934990805574\n",
      "Validation Loss: 0.013098959208026612\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.006861133073689416\n",
      "Training Loss: 0.006377294004196301\n",
      "Training Loss: 0.006883028713054955\n",
      "Training Loss: 0.005196766810840927\n",
      "Training Loss: 0.003978213773225434\n",
      "Training Loss: 0.0039356776355998595\n",
      "Training Loss: 0.003953330286894925\n",
      "Validation Loss: 0.013083275329942504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.006852963126730174\n",
      "Training Loss: 0.006367751233046875\n",
      "Training Loss: 0.0068745903251692655\n",
      "Training Loss: 0.005189447524026036\n",
      "Training Loss: 0.003973147202050314\n",
      "Training Loss: 0.0039303649059729655\n",
      "Training Loss: 0.003947837665327825\n",
      "Validation Loss: 0.013068087179691632\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.006844838273827918\n",
      "Training Loss: 0.006358278696425259\n",
      "Training Loss: 0.006866151678841561\n",
      "Training Loss: 0.005182193011860363\n",
      "Training Loss: 0.003968199799419381\n",
      "Training Loss: 0.003925183619139716\n",
      "Training Loss: 0.0039424579229671505\n",
      "Validation Loss: 0.013053345954837451\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.006836757456767373\n",
      "Training Loss: 0.006348878195858561\n",
      "Training Loss: 0.0068577102816198025\n",
      "Training Loss: 0.00517500416666735\n",
      "Training Loss: 0.003963369637494907\n",
      "Training Loss: 0.003920130906626582\n",
      "Training Loss: 0.00393719004932791\n",
      "Validation Loss: 0.013039081547956927\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.006828721729689278\n",
      "Training Loss: 0.006339553755242378\n",
      "Training Loss: 0.006849266564240679\n",
      "Training Loss: 0.005167884811526164\n",
      "Training Loss: 0.003958655063179321\n",
      "Training Loss: 0.003915204814402387\n",
      "Training Loss: 0.003932034016470425\n",
      "Validation Loss: 0.013025274663319469\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.006820728060556575\n",
      "Training Loss: 0.006330307233147323\n",
      "Training Loss: 0.006840818496420979\n",
      "Training Loss: 0.005160834403941408\n",
      "Training Loss: 0.003954052494955249\n",
      "Training Loss: 0.003910401712637394\n",
      "Training Loss: 0.003926988127641379\n",
      "Validation Loss: 0.013011930329892575\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.006812777624581941\n",
      "Training Loss: 0.006321140444488265\n",
      "Training Loss: 0.006832366576418281\n",
      "Training Loss: 0.005153853071387857\n",
      "Training Loss: 0.003949561034678481\n",
      "Training Loss: 0.0039057217782828956\n",
      "Training Loss: 0.003922054613940418\n",
      "Validation Loss: 0.012999018403956116\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.006804865726153366\n",
      "Training Loss: 0.006312054959707893\n",
      "Training Loss: 0.006823912149993703\n",
      "Training Loss: 0.005146942721912637\n",
      "Training Loss: 0.0039451757486676795\n",
      "Training Loss: 0.0039011573069728913\n",
      "Training Loss: 0.003917229311191477\n",
      "Validation Loss: 0.012986541483708229\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.006796994630130939\n",
      "Training Loss: 0.006303053157171235\n",
      "Training Loss: 0.006815455815522\n",
      "Training Loss: 0.005140103406156413\n",
      "Training Loss: 0.003940895421546884\n",
      "Training Loss: 0.003896707922103815\n",
      "Training Loss: 0.003912511772359722\n",
      "Validation Loss: 0.012974495014998965\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.0067891611851518974\n",
      "Training Loss: 0.006294136068318039\n",
      "Training Loss: 0.006806999669643119\n",
      "Training Loss: 0.005133334985002875\n",
      "Training Loss: 0.003936714206356555\n",
      "Training Loss: 0.0038923682464519515\n",
      "Training Loss: 0.003907899933401495\n",
      "Validation Loss: 0.01296290397610906\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.006781366427312605\n",
      "Training Loss: 0.006285306064528413\n",
      "Training Loss: 0.006798544762423262\n",
      "Training Loss: 0.00512663803587202\n",
      "Training Loss: 0.003932631440693513\n",
      "Training Loss: 0.003888134717126377\n",
      "Training Loss: 0.003903391802450642\n",
      "Validation Loss: 0.012951685064681544\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.006773608029470779\n",
      "Training Loss: 0.00627656196244061\n",
      "Training Loss: 0.0067900961369741705\n",
      "Training Loss: 0.00512001191440504\n",
      "Training Loss: 0.003928640543017536\n",
      "Training Loss: 0.0038840030843857675\n",
      "Training Loss: 0.0038989846920594574\n",
      "Validation Loss: 0.012940897527394976\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.00676588702655863\n",
      "Training Loss: 0.006267907525179908\n",
      "Training Loss: 0.006781655413797125\n",
      "Training Loss: 0.005113455824321136\n",
      "Training Loss: 0.00392474086896982\n",
      "Training Loss: 0.00387997001002077\n",
      "Training Loss: 0.003894676337367855\n",
      "Validation Loss: 0.01293049253041992\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.006758202422643081\n",
      "Training Loss: 0.0062593388312961904\n",
      "Training Loss: 0.006773225828073919\n",
      "Training Loss: 0.005106970714405179\n",
      "Training Loss: 0.0039209260686766355\n",
      "Training Loss: 0.003876030507381074\n",
      "Training Loss: 0.0038904629927128554\n",
      "Validation Loss: 0.012920466235974867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.006750554395257496\n",
      "Training Loss: 0.006250861102598719\n",
      "Training Loss: 0.006764813016634435\n",
      "Training Loss: 0.005100555306999013\n",
      "Training Loss: 0.0039171941776294265\n",
      "Training Loss: 0.003872180110774934\n",
      "Training Loss: 0.0038863435486564415\n",
      "Validation Loss: 0.012910813868851559\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.006742940951953642\n",
      "Training Loss: 0.006242470419383608\n",
      "Training Loss: 0.006756419108714908\n",
      "Training Loss: 0.005094208989758045\n",
      "Training Loss: 0.003913540178327821\n",
      "Training Loss: 0.00386841525149066\n",
      "Training Loss: 0.00388231344812084\n",
      "Validation Loss: 0.012901522489072762\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.006735365668428131\n",
      "Training Loss: 0.006234169804956764\n",
      "Training Loss: 0.0067480513185728345\n",
      "Training Loss: 0.005087932050228119\n",
      "Training Loss: 0.003909960397286341\n",
      "Training Loss: 0.0038647328416118397\n",
      "Training Loss: 0.0038783705630339683\n",
      "Validation Loss: 0.012892576754232695\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.006727827796712518\n",
      "Training Loss: 0.006225958185968921\n",
      "Training Loss: 0.006739711583359167\n",
      "Training Loss: 0.00508172353671398\n",
      "Training Loss: 0.003906451141228899\n",
      "Training Loss: 0.0038611269340617584\n",
      "Training Loss: 0.003874510225141421\n",
      "Validation Loss: 0.01288396050745433\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.0067203273443738\n",
      "Training Loss: 0.006217835642164573\n",
      "Training Loss: 0.006731405477039516\n",
      "Training Loss: 0.00507558177865576\n",
      "Training Loss: 0.0039030091889435425\n",
      "Training Loss: 0.0038575954787665977\n",
      "Training Loss: 0.003870731359347701\n",
      "Validation Loss: 0.012875676608979283\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.006712864238652401\n",
      "Training Loss: 0.006209800860960968\n",
      "Training Loss: 0.006723138581728563\n",
      "Training Loss: 0.005069507323787548\n",
      "Training Loss: 0.0038996278488775717\n",
      "Training Loss: 0.0038541325222468\n",
      "Training Loss: 0.0038670277304481714\n",
      "Validation Loss: 0.01286769987385692\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.006705441903322935\n",
      "Training Loss: 0.006201855042017996\n",
      "Training Loss: 0.006714913435280323\n",
      "Training Loss: 0.005063498605159112\n",
      "Training Loss: 0.003896307821269147\n",
      "Training Loss: 0.003850737119792029\n",
      "Training Loss: 0.003863398467656225\n",
      "Validation Loss: 0.012860017126227278\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.006698059240006842\n",
      "Training Loss: 0.006193996935035102\n",
      "Training Loss: 0.006706736022606492\n",
      "Training Loss: 0.005057556384126655\n",
      "Training Loss: 0.003893042025156319\n",
      "Training Loss: 0.0038474042032612486\n",
      "Training Loss: 0.0038598392670974135\n",
      "Validation Loss: 0.012852602915172134\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.006690716809243895\n",
      "Training Loss: 0.006186224800767377\n",
      "Training Loss: 0.006698610493913293\n",
      "Training Loss: 0.005051677042501979\n",
      "Training Loss: 0.0038898278126725926\n",
      "Training Loss: 0.0038441291905473916\n",
      "Training Loss: 0.0038563452864764257\n",
      "Validation Loss: 0.012845468859551021\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.0066834189812652765\n",
      "Training Loss: 0.00617854135518428\n",
      "Training Loss: 0.006690540843410417\n",
      "Training Loss: 0.005045862456317991\n",
      "Training Loss: 0.0038866628223331646\n",
      "Training Loss: 0.003840911168954335\n",
      "Training Loss: 0.00385291593906004\n",
      "Validation Loss: 0.012838599879437645\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.006676162149524316\n",
      "Training Loss: 0.006170941542950459\n",
      "Training Loss: 0.006682528664823622\n",
      "Training Loss: 0.005040109621477313\n",
      "Training Loss: 0.003883542292751372\n",
      "Training Loss: 0.0038377471145940945\n",
      "Training Loss: 0.0038495479780249297\n",
      "Validation Loss: 0.01283198308368817\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.0066689494031015786\n",
      "Training Loss: 0.0061634255183162165\n",
      "Training Loss: 0.006674579196842387\n",
      "Training Loss: 0.005034419345320202\n",
      "Training Loss: 0.0038804647797951474\n",
      "Training Loss: 0.0038346337393159046\n",
      "Training Loss: 0.003846236311364919\n",
      "Validation Loss: 0.012825584555330794\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.006661783680319786\n",
      "Training Loss: 0.00615599689015653\n",
      "Training Loss: 0.006666696580359712\n",
      "Training Loss: 0.005028790606884286\n",
      "Training Loss: 0.003877424601232633\n",
      "Training Loss: 0.003831567543675192\n",
      "Training Loss: 0.0038429808343062176\n",
      "Validation Loss: 0.012819413863966584\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.006654664598172531\n",
      "Training Loss: 0.006148650423856452\n",
      "Training Loss: 0.00665888165589422\n",
      "Training Loss: 0.00502322235784959\n",
      "Training Loss: 0.0038744224375113845\n",
      "Training Loss: 0.003828546909498982\n",
      "Training Loss: 0.003839775883825496\n",
      "Validation Loss: 0.012813460105796403\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.006647591177606955\n",
      "Training Loss: 0.006141385541995987\n",
      "Training Loss: 0.006651135797146708\n",
      "Training Loss: 0.0050177116232225675\n",
      "Training Loss: 0.0038714517315384\n",
      "Training Loss: 0.003825567607418634\n",
      "Training Loss: 0.0038366190734086558\n",
      "Validation Loss: 0.012807673808668605\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.0066405675071291624\n",
      "Training Loss: 0.006134203239926137\n",
      "Training Loss: 0.006643463405780494\n",
      "Training Loss: 0.005012259273789823\n",
      "Training Loss: 0.0038685128948418423\n",
      "Training Loss: 0.0038226292323088273\n",
      "Training Loss: 0.0038335087680025025\n",
      "Validation Loss: 0.012802097128882084\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.00663359192898497\n",
      "Training Loss: 0.006127100052544847\n",
      "Training Loss: 0.006635864542331547\n",
      "Training Loss: 0.005006863773451187\n",
      "Training Loss: 0.0038656005723169073\n",
      "Training Loss: 0.0038197286147624255\n",
      "Training Loss: 0.0038304407114628704\n",
      "Validation Loss: 0.012796714183811642\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.006626665887888521\n",
      "Training Loss: 0.0061200751003343615\n",
      "Training Loss: 0.006628339865710586\n",
      "Training Loss: 0.005001523792161606\n",
      "Training Loss: 0.003862713587004691\n",
      "Training Loss: 0.003816862270468846\n",
      "Training Loss: 0.003827413850813173\n",
      "Validation Loss: 0.01279149105561346\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.006619790421100333\n",
      "Training Loss: 0.0061131290660705415\n",
      "Training Loss: 0.0066208926378749314\n",
      "Training Loss: 0.004996238878229633\n",
      "Training Loss: 0.0038598489336436614\n",
      "Training Loss: 0.0038140294165350495\n",
      "Training Loss: 0.003824423826881684\n",
      "Validation Loss: 0.012786404278969972\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.00661296549369581\n",
      "Training Loss: 0.006106259123771452\n",
      "Training Loss: 0.006613523216219619\n",
      "Training Loss: 0.0049910080089466645\n",
      "Training Loss: 0.0038570078019984065\n",
      "Training Loss: 0.003811228652484715\n",
      "Training Loss: 0.003821471117553301\n",
      "Validation Loss: 0.012781470956033172\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.00660619321744889\n",
      "Training Loss: 0.006099464967264794\n",
      "Training Loss: 0.006606229582102969\n",
      "Training Loss: 0.004985828693606891\n",
      "Training Loss: 0.0038541835692012683\n",
      "Training Loss: 0.003808456947444938\n",
      "Training Loss: 0.0038185510406037793\n",
      "Validation Loss: 0.012776694297598682\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.006599471245426685\n",
      "Training Loss: 0.006092743612243794\n",
      "Training Loss: 0.00659901412203908\n",
      "Training Loss: 0.0049807009380310775\n",
      "Training Loss: 0.0038513775274623186\n",
      "Training Loss: 0.0038057123217731716\n",
      "Training Loss: 0.0038156620663357898\n",
      "Validation Loss: 0.012772022175763068\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.00659280275751371\n",
      "Training Loss: 0.006086096591316164\n",
      "Training Loss: 0.006591875246958807\n",
      "Training Loss: 0.004975623259088025\n",
      "Training Loss: 0.003848586119711399\n",
      "Training Loss: 0.003802994255675003\n",
      "Training Loss: 0.0038128025288460777\n",
      "Validation Loss: 0.012767503086010113\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.006586183368926868\n",
      "Training Loss: 0.006079517079051584\n",
      "Training Loss: 0.00658481213147752\n",
      "Training Loss: 0.004970593586331233\n",
      "Training Loss: 0.0038458083831937983\n",
      "Training Loss: 0.0038003007601946593\n",
      "Training Loss: 0.003809971029404551\n",
      "Validation Loss: 0.012763094838903973\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.00657961466407869\n",
      "Training Loss: 0.006073007487575523\n",
      "Training Loss: 0.00657782458816655\n",
      "Training Loss: 0.004965611847001128\n",
      "Training Loss: 0.00384304158273153\n",
      "Training Loss: 0.003797627862659283\n",
      "Training Loss: 0.0038071626675082373\n",
      "Validation Loss: 0.012758775678295852\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.006573098638909869\n",
      "Training Loss: 0.006066566000226885\n",
      "Training Loss: 0.006570912831230089\n",
      "Training Loss: 0.004960676538175903\n",
      "Training Loss: 0.003840287033235654\n",
      "Training Loss: 0.0037949775625020265\n",
      "Training Loss: 0.0038043792569078506\n",
      "Validation Loss: 0.01275458856623564\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.006566632553003728\n",
      "Training Loss: 0.006060187252587639\n",
      "Training Loss: 0.006564072748878971\n",
      "Training Loss: 0.0049557843059301375\n",
      "Training Loss: 0.0038375400920631366\n",
      "Training Loss: 0.003792346578557044\n",
      "Training Loss: 0.003801617265562527\n",
      "Validation Loss: 0.012750472141384436\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.006560216843499802\n",
      "Training Loss: 0.006053872628835961\n",
      "Training Loss: 0.006557304636808112\n",
      "Training Loss: 0.004950935527449474\n",
      "Training Loss: 0.00383480224001687\n",
      "Training Loss: 0.0037897352810250594\n",
      "Training Loss: 0.0037988773663528265\n",
      "Validation Loss: 0.01274646836165548\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.006553845818270929\n",
      "Training Loss: 0.006047616020077839\n",
      "Training Loss: 0.006550605578813702\n",
      "Training Loss: 0.004946128586307168\n",
      "Training Loss: 0.0038320731808198618\n",
      "Training Loss: 0.003787142138462514\n",
      "Training Loss: 0.003796156483585946\n",
      "Validation Loss: 0.012742571118514468\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.0065475217183120545\n",
      "Training Loss: 0.006041417280212045\n",
      "Training Loss: 0.006543975594686344\n",
      "Training Loss: 0.004941362171666697\n",
      "Training Loss: 0.0038293480762513353\n",
      "Training Loss: 0.0037845620134612547\n",
      "Training Loss: 0.003793450749362819\n",
      "Validation Loss: 0.01273872185113041\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.0065412483853288\n",
      "Training Loss: 0.0060352781176334245\n",
      "Training Loss: 0.006537412278121337\n",
      "Training Loss: 0.004936634430196136\n",
      "Training Loss: 0.003826627345988527\n",
      "Training Loss: 0.0037819991243304685\n",
      "Training Loss: 0.003790763375000097\n",
      "Validation Loss: 0.012734978099193158\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.0065350163955008615\n",
      "Training Loss: 0.006029189125401899\n",
      "Training Loss: 0.006530912440503016\n",
      "Training Loss: 0.0049319446488516406\n",
      "Training Loss: 0.003823912525549531\n",
      "Training Loss: 0.003779450146248564\n",
      "Training Loss: 0.0037880907458020373\n",
      "Validation Loss: 0.012731308085243968\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.006528828149894253\n",
      "Training Loss: 0.006023153096903116\n",
      "Training Loss: 0.0065244753682054575\n",
      "Training Loss: 0.00492729026300367\n",
      "Training Loss: 0.0038211994420271366\n",
      "Training Loss: 0.003776912875473499\n",
      "Training Loss: 0.0037854305503424255\n",
      "Validation Loss: 0.01272771119930143\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.006522685827221721\n",
      "Training Loss: 0.006017166536184959\n",
      "Training Loss: 0.006518098888918757\n",
      "Training Loss: 0.00492267027089838\n",
      "Training Loss: 0.0038184889766853304\n",
      "Training Loss: 0.003774387979065068\n",
      "Training Loss: 0.003782784233917482\n",
      "Validation Loss: 0.012724192969567293\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.006516581326723099\n",
      "Training Loss: 0.00601122488908004\n",
      "Training Loss: 0.00651177964406088\n",
      "Training Loss: 0.004918083578231745\n",
      "Training Loss: 0.0038157788052922115\n",
      "Training Loss: 0.0037718722166027873\n",
      "Training Loss: 0.0037801476434106006\n",
      "Validation Loss: 0.012720745973365751\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.006510517016868107\n",
      "Training Loss: 0.006005328772589564\n",
      "Training Loss: 0.0065055169945117085\n",
      "Training Loss: 0.004913527785101905\n",
      "Training Loss: 0.0038130705285584553\n",
      "Training Loss: 0.0037693672691239046\n",
      "Training Loss: 0.003777522359159775\n",
      "Validation Loss: 0.012717342141523874\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.006504490713705308\n",
      "Training Loss: 0.005999474141281098\n",
      "Training Loss: 0.006499307201011106\n",
      "Training Loss: 0.004909003719803877\n",
      "Training Loss: 0.003810363552765921\n",
      "Training Loss: 0.0037668726703850553\n",
      "Training Loss: 0.003774906829930842\n",
      "Validation Loss: 0.012714044177862868\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.006498500342131592\n",
      "Training Loss: 0.005993658984662034\n",
      "Training Loss: 0.006493149345042184\n",
      "Training Loss: 0.004904506183811464\n",
      "Training Loss: 0.0038076549395918845\n",
      "Training Loss: 0.0037643841753015293\n",
      "Training Loss: 0.0037722986959852277\n",
      "Validation Loss: 0.012710782381433867\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.006492543804924935\n",
      "Training Loss: 0.005987880888278596\n",
      "Training Loss: 0.0064870401727966966\n",
      "Training Loss: 0.0049000375147443265\n",
      "Training Loss: 0.0038049450633116065\n",
      "Training Loss: 0.0037619037774857134\n",
      "Training Loss: 0.003769699024851434\n",
      "Validation Loss: 0.012707596890670195\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.006486620443174615\n",
      "Training Loss: 0.005982136668171734\n",
      "Training Loss: 0.006480976303573698\n",
      "Training Loss: 0.004895594211993739\n",
      "Training Loss: 0.003802234841277823\n",
      "Training Loss: 0.003759430851787329\n",
      "Training Loss: 0.003767106328159571\n",
      "Validation Loss: 0.01270444914986369\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.006480726877925918\n",
      "Training Loss: 0.005976424570544623\n",
      "Training Loss: 0.006474956426536664\n",
      "Training Loss: 0.004891175697557628\n",
      "Training Loss: 0.003799523670459166\n",
      "Training Loss: 0.00375696417351719\n",
      "Training Loss: 0.003764519902761094\n",
      "Validation Loss: 0.012701396148456504\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.0064748632756527515\n",
      "Training Loss: 0.005970743106445298\n",
      "Training Loss: 0.006468977814074605\n",
      "Training Loss: 0.00488678039284423\n",
      "Training Loss: 0.00379680939251557\n",
      "Training Loss: 0.0037545028497697787\n",
      "Training Loss: 0.003761938921525143\n",
      "Validation Loss: 0.012698389491247717\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.006469025873811916\n",
      "Training Loss: 0.005965088316006586\n",
      "Training Loss: 0.006463039501104504\n",
      "Training Loss: 0.004882406610995531\n",
      "Training Loss: 0.003794091905001551\n",
      "Training Loss: 0.0037520456506172197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [36:51<00:00, 221.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0037593619636027142\n",
      "Validation Loss: 0.012695426748776006\n",
      "Validation Accuracy: 0.0\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictive performance\n",
    "predictive_results = predictive_evaluation(data_real_numpy, data_syn_numpy, hyperparameters, include_baseline=True, verbose=True)\n",
    "\n",
    "# save results\n",
    "bidirectionality = \"bi\" if hyperparameters[\"bidirectional\"] else 'no_bi'\n",
    "predictive_results.to_csv(DATA_FOLDER / f\"results_{syn_data_type}_{hyperparameters['num_epochs']}_{hyperparameters['num_evaluation_runs']}_{bidirectionality}.csv\", index=False)\n",
    "\n",
    "# split in mse and mae results\n",
    "mse_results = predictive_results.loc[predictive_results['Metric'] == 'MSE']\n",
    "mae_results = predictive_results.loc[predictive_results['Metric'] == 'MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x194580d7f50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Model', y='Error', hue='Model', data=mse_results)\n",
    "sns.stripplot(x='Model', y='Error', hue='Metric', data=mse_results, dodge=True, jitter=True, palette='dark:black', alpha=0.7)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Metric')\n",
    "plt.title(f'MSE | {syn_data_type} | {hyperparameters[\"num_evaluation_runs\"]} Training Runs {\" | jitter factor = \" + str(jitter_factor) if syn_data_type == \"jitter\" else \"\"}')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Model', y='Error', hue='Model', data=mae_results)\n",
    "sns.stripplot(x='Model', y='Error', hue='Metric', data=mae_results, dodge=True, jitter=True, palette='dark:black', alpha=0.7)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel('Metric')\n",
    "plt.title(f'MAE | {syn_data_type} | {hyperparameters[\"num_evaluation_runs\"]} Training Runs {\" | jitter factor = \" + str(jitter_factor) if syn_data_type == \"jitter\" else \"\"}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2*1e06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series_data_augmentation_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
