{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LSTM Baseline Model Testing"]},{"cell_type":"markdown","metadata":{},"source":["## 0 Imports & Constants"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","\n","# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n","parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n","sys.path.insert(0, parent_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from pathlib import Path\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from copy import deepcopy as dc\n","from sklearn.preprocessing import MinMaxScaler\n","import itertools\n","from tqdm import tqdm\n","import json\n","from datetime import datetime\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","from utils.utils import load_time_series, add_lagged_data, scale_data, train_test_split_to_tensor, inverse_scale_data\n","from baseline_model import TimeSeriesDataset\n","\n","from baseline_model.LSTM import LSTM, train_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DATA_FOLDER = Path(\"../data\")\n","MULTIVARIATE_DATA_FOLDER = DATA_FOLDER / \"multivariate\"\n","UNIVARIATE_DATA_FOLDER = DATA_FOLDER / \"univariate\"\n","BENCHMARK = False"]},{"cell_type":"markdown","metadata":{},"source":["## 1 Data"]},{"cell_type":"markdown","metadata":{},"source":["### Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load data from csv\n","# -> convert Date column to datetime\n","data = load_time_series(f'{UNIVARIATE_DATA_FOLDER}/NVDA_open_high_low_close_adjClose_volume_99_24.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## 2 Benchmark Loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hyperparameters = {\n","    'lag': [7, 14, 21],\n","    'lr': [0.002, 0.001],\n","    'hidden_size': [2, 4, 6, 8, 12],\n","    'num_layers': [1, 2],\n","    'batch_size': [8, 16, 32, 64],\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get all combinations of hyperparameters\n","keys, values = zip(*hyperparameters.items())\n","possible_hyperparameters = [dict(zip(keys, v)) for v in itertools.product(*values)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["possible_features = [\n","    ['Close', 'Volume'],\n","    ['Close', 'Open', 'Volume'],\n","    ['Close', 'Open', 'High', 'Low', 'Volume']\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["RESULTS = {}\n","for features in possible_features:\n","\n","    for hyperparameters in tqdm(possible_hyperparameters):\n","        \n","        print('*'*50)\n","        print('*'*50)\n","        print('STARTING NEW BENCHMARK RUN:')\n","        print(f\"Features: {features}\")\n","        print(f\"Hyperparameters: {hyperparameters}\")\n","        print('*'*50)\n","        print('*'*50)\n","\n","        ### Select features\n","        features_incl_date = features+['Date']\n","        data_only_features = data[features_incl_date]\n","        \n","        ### Data Preprocessing\n","        data_lagged = add_lagged_data(data_only_features, hyperparameters['lag'], features)\n","        data_lagged_scaled, scaler_close = scale_data(data_lagged)\n","        X_train, y_train, X_test, y_test = train_test_split_to_tensor(data_lagged_scaled)\n","\n","        ### Create datasets and DataLoaders\n","        train_dataset = TimeSeriesDataset(X_train, y_train)\n","        test_dataset = TimeSeriesDataset(X_test, y_test)\n","        train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n","        test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)\n","\n","        ### Train model\n","        validation_losses = [] # reset validation losses\n","        for i in range(2): # train 2 times because sometimes the model converges to a local minimum\n","            ### Instantiate model\n","            model = LSTM(\n","                device=device,\n","                input_size=len(features),\n","                hidden_size=hyperparameters['hidden_size'],\n","                num_stacked_layers=hyperparameters['num_layers']\n","            ).to(device)\n","\n","            ### Optimizer, Criterion\n","            optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['lr'])\n","            criterion = nn.MSELoss()\n","\n","            validation_loss, model = train_model(\n","                model=model,\n","                train_loader=train_loader,\n","                test_loader=test_loader,\n","                optimizer=optimizer,\n","                criterion=criterion,\n","                device=device)\n","            \n","            # save loss for each run\n","            validation_losses.append(validation_loss)\n","        \n","        ### Save results to dict\n","        feature_acronym = ''.join([feature[0] for feature in features])\n","        RESULTS[f'{feature_acronym}_lag{hyperparameters[\"lag\"]}_lr{hyperparameters[\"lr\"]}_bs{hyperparameters[\"batch_size\"]}_hs{hyperparameters[\"hidden_size\"]}_nl{hyperparameters[\"num_layers\"]}'] = min(validation_losses) # only save min loss\n","    \n","### Save results to json\n","print('Saving results to json...')\n","with open(f'./results/LSTM_benchmark_results_{datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")}.json', 'w') as json_file:\n","    json.dump(RESULTS, json_file, indent=4)\n","print('Results saved!')\n","\n","print('#'*50)\n","print('#'*50)\n","print('#'*50)\n","print('TRAINING FINISHED')\n","print('#'*50)\n","print('#'*50)\n","print('#'*50)"]},{"cell_type":"markdown","metadata":{},"source":["## 3 Evaluate Results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["RESULTS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_params = min(RESULTS, key=RESULTS.get)\n","best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["RESULTS[best_params]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('CV_lag7_lr0.001_bs32_hs12_nl1')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"time_series_data_augmentation_venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":2}
