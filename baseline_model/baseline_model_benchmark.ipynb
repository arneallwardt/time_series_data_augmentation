{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LSTM Baseline Model Testing"]},{"cell_type":"markdown","metadata":{},"source":["## 0 Imports & Constants"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","\n","# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n","parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n","sys.path.insert(0, parent_dir)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","import pandas as pd\n","from pathlib import Path\n","import itertools\n","from tqdm import tqdm\n","import json\n","from datetime import datetime\n","import re\n","\n","from TimeSeriesDataset import TimeSeriesDataset\n","from utils import load_complete_time_series, split_data_into_sequences\n","from LSTM import scale_data, train_test_split_to_tensor\n","from baseline_model.LSTM import LSTM, train_model"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["DATA_FOLDER = Path(\"../data\")\n","REAL_DATA_FOLDER = DATA_FOLDER / \"real\"\n","SYNTHETIC_DATA_FOLDER = DATA_FOLDER / \"synthetic\"\n","BENCHMARK = True"]},{"cell_type":"markdown","metadata":{},"source":["## 1 Data"]},{"cell_type":"markdown","metadata":{},"source":["### Data Loading"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Load data from csv\n","# -> convert Date column to datetime\n","data = load_complete_time_series(f'{REAL_DATA_FOLDER}/AAPL_10_24_real.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## 2 Benchmark Loop"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["hyperparameters = {\n","    'seqLen': [7, 14, 21],\n","    'lr': [0.002, 0.001],\n","    'hidden_size': [2, 4, 6, 8, 12],\n","    'num_layers': [1, 2],\n","    'batch_size': [8, 16, 32, 64],\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# get all combinations of hyperparameters\n","keys, values = zip(*hyperparameters.items())\n","possible_hyperparameters = [dict(zip(keys, v)) for v in itertools.product(*values)]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["possible_features = [\n","    ['Close', 'Volume'],\n","    ['Close', 'Open', 'Volume'],\n","    ['Close', 'Open', 'High', 'Low', 'Volume']\n","]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/240 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["**************************************************\n","**************************************************\n","STARTING NEW BENCHMARK RUN:\n","Features: ['Close', 'Volume']\n","Hyperparameters: {'seqLen': 7, 'lr': 0.002, 'hidden_size': 2, 'num_layers': 1, 'batch_size': 8}\n","**************************************************\n","**************************************************\n","Shape of the data after splitting into sequences: (3611, 7, 2)\n","Shape of X_train: torch.Size([3430, 6, 2]) \n"," Shape of y_train: torch.Size([3430, 1]) \n"," Shape of X_test: torch.Size([181, 6, 2]) \n"," Shape of y_test: torch.Size([181, 1])\n","Epoch: 1\n","Validation Loss: 0.010744380288878861\n","**************************************************\n","Epoch: 2\n","Validation Loss: 0.002387306496055554\n","**************************************************\n","Epoch: 3\n","Validation Loss: 0.001590228764025201\n","**************************************************\n","Epoch: 4\n","Validation Loss: 0.0011733043701615711\n","**************************************************\n","Epoch: 5\n","Validation Loss: 0.0011945788523323995\n","INFO: Validation loss did not improve in epoch 5\n","**************************************************\n","Epoch: 6\n","Validation Loss: 0.0008684815215731404\n","**************************************************\n","Epoch: 7\n","Validation Loss: 0.0012953240644571413\n","INFO: Validation loss did not improve in epoch 7\n","**************************************************\n","Epoch: 8\n","Validation Loss: 0.0007452542011615942\n","**************************************************\n","Epoch: 9\n","Validation Loss: 0.0008302427619207225\n","INFO: Validation loss did not improve in epoch 9\n","**************************************************\n","Epoch: 10\n","Validation Loss: 0.00049754166890204\n","**************************************************\n","Epoch: 11\n","Validation Loss: 0.0005038148758657095\n","INFO: Validation loss did not improve in epoch 11\n","**************************************************\n","Epoch: 12\n","Validation Loss: 0.0006947977238704208\n","INFO: Validation loss did not improve in epoch 12\n","**************************************************\n","Epoch: 13\n","Validation Loss: 0.0002754143688830284\n","**************************************************\n","Epoch: 14\n","Validation Loss: 0.00025234260813348277\n","**************************************************\n","Epoch: 15\n","Validation Loss: 0.00040057589767852534\n","INFO: Validation loss did not improve in epoch 15\n","**************************************************\n","Epoch: 16\n","Validation Loss: 0.00029937778305358495\n","INFO: Validation loss did not improve in epoch 16\n","**************************************************\n","Epoch: 17\n","Validation Loss: 0.00022809233933398701\n","**************************************************\n","Epoch: 18\n","Validation Loss: 0.00032864538550948845\n","INFO: Validation loss did not improve in epoch 18\n","**************************************************\n","Epoch: 19\n","Validation Loss: 0.0002189035259779421\n","**************************************************\n","Epoch: 20\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/240 [00:44<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     43\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m---> 45\u001b[0m validation_loss, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# save loss for each run\u001b[39;00m\n\u001b[1;32m     54\u001b[0m validation_losses\u001b[38;5;241m.\u001b[39mappend(validation_loss)\n","File \u001b[0;32m~/time_series_data_augmentation/baseline_model/LSTM.py:124\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, device, patience, num_epochs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     current_validation_loss \u001b[38;5;241m=\u001b[39m validate_one_epoch(model, test_loader, criterion, device)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# early stopping\u001b[39;00m\n","File \u001b[0;32m~/time_series_data_augmentation/baseline_model/LSTM.py:60\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, log_interval, scheduler)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_index, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     58\u001b[0m     x_batch, y_batch \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[0;32m---> 60\u001b[0m     train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m criterion(train_pred, y_batch)\n\u001b[1;32m     62\u001b[0m     running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m~/time_series_data_augmentation/ba_venv_3_8_10/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/time_series_data_augmentation/ba_venv_3_8_10/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/time_series_data_augmentation/baseline_model/LSTM.py:36\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_stacked_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     35\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, (h0, c0)) \u001b[38;5;66;03m# get output of LSTM layer\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# run output through fully connected layer\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m~/time_series_data_augmentation/ba_venv_3_8_10/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/time_series_data_augmentation/ba_venv_3_8_10/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/time_series_data_augmentation/ba_venv_3_8_10/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["RESULTS = {}\n","if BENCHMARK:\n","    for features in possible_features:\n","\n","        for hyperparameters in tqdm(possible_hyperparameters):\n","            \n","            print('*'*50)\n","            print('*'*50)\n","            print('STARTING NEW BENCHMARK RUN:')\n","            print(f\"Features: {features}\")\n","            print(f\"Hyperparameters: {hyperparameters}\")\n","            print('*'*50)\n","            print('*'*50)\n","\n","            ### Select features\n","            features_incl_date = features+['Date']\n","            data_only_features = data[features_incl_date]\n","            \n","            ### Data Preprocessing\n","            data_lagged = split_data_into_sequences(data_only_features, hyperparameters['seqLen'])\n","            data_lagged_scaled, scaler_close = scale_data(data_lagged)\n","            X_train, y_train, X_test, y_test = train_test_split_to_tensor(data_lagged_scaled)\n","\n","            ### Create datasets and DataLoaders\n","            train_dataset = TimeSeriesDataset(X_train, y_train)\n","            test_dataset = TimeSeriesDataset(X_test, y_test)\n","            train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n","            test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)\n","\n","            ### Train model\n","            validation_losses = [] # reset validation losses\n","            for i in range(2): # train 2 times because sometimes the model converges to a local minimum\n","                ### Instantiate model\n","                model = LSTM(\n","                    device=device,\n","                    input_size=len(features),\n","                    hidden_size=hyperparameters['hidden_size'],\n","                    num_stacked_layers=hyperparameters['num_layers']\n","                ).to(device)\n","\n","                ### Optimizer, Criterion\n","                optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['lr'])\n","                criterion = nn.MSELoss()\n","\n","                validation_loss, model = train_model(\n","                    model=model,\n","                    train_loader=train_loader,\n","                    test_loader=test_loader,\n","                    optimizer=optimizer,\n","                    criterion=criterion,\n","                    device=device)\n","                \n","                # save loss for each run\n","                validation_losses.append(validation_loss)\n","            \n","            ### Save results to dict\n","            feature_acronym = ''.join([feature[0] for feature in features])\n","            RESULTS[f'{feature_acronym}_seqLen{hyperparameters[\"seqLen\"]}_lr{hyperparameters[\"lr\"]}_bs{hyperparameters[\"batch_size\"]}_hs{hyperparameters[\"hidden_size\"]}_nl{hyperparameters[\"num_layers\"]}'] = min(validation_losses) # only save min loss\n","        \n","    ### Save results to json\n","    print('Saving results to json...')\n","    with open(f'./benchmark_results/LSTM_benchmark_results_{datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")}.json', 'w') as json_file:\n","        json.dump(RESULTS, json_file, indent=4)\n","    print('Results saved!')\n","\n","    print('#'*50)\n","    print('#'*50)\n","    print('#'*50)\n","    print('TRAINING FINISHED')\n","    print('#'*50)\n","    print('#'*50)\n","    print('#'*50)"]},{"cell_type":"markdown","metadata":{},"source":["## 3 Evaluate Results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('./benchmark_results/LSTM_benchmark_results_2024_06_19_205109.json', 'r') as json_file:\n","    results = json.load(json_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get results as array of dicts (bc i saved them shitty in the first place)\n","result_array = []\n","for key, value in results.items():\n","    result_dict = {}\n","    result_dict['error'] = value\n","    result_dict['features'] = key.split('_')[0]\n","    for feature in ['lag', 'lr', 'bs', 'hs', 'nl']:\n","        pattern = rf\"{feature}(\\d+\\.?\\d*)\" # regex pattern to extract the value of the hyperparameter\n","        match = re.search(pattern, key) # search for the value in the key\n","        result_dict[feature] = match.group()[len(feature):]\n","    result_array.append(result_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# turn into dataframe and select best 20\n","result_df = pd.DataFrame(result_array)\n","result_df_sorted = result_df.sort_values(by='error', ascending=True)\n","best_20 = result_df_sorted.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# extract best hyperparameters from best 20 results\n","best_hyperparameters = {}\n","for feature in ['features', 'lag', 'lr', 'bs', 'hs', 'nl']:\n","    best_hyperparameters[feature] = best_20[feature].value_counts().idxmax()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["{'features': 'CV',\n"," 'lag': '14',\n"," 'lr': '0.001',\n"," 'bs': '32',\n"," 'hs': '12',\n"," 'nl': '1'}"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["best_hyperparameters"]}],"metadata":{"kernelspec":{"display_name":"time_series_data_augmentation_venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":2}
