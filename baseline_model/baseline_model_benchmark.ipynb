{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LSTM Baseline Model Testing"]},{"cell_type":"markdown","metadata":{},"source":["## 0 Imports & Constants"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","\n","# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n","parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n","sys.path.insert(0, parent_dir)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from pathlib import Path\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from copy import deepcopy as dc\n","from sklearn.preprocessing import MinMaxScaler\n","import itertools\n","from tqdm import tqdm\n","import json\n","from datetime import datetime\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","from utils.utils import load_time_series, add_lagged_data, scale_data, train_test_split_to_tensor, inverse_scale_data\n","from utils.TimeSeriesDataset import TimeSeriesDataset\n","\n","from baseline_model.LSTM import LSTM, train_model"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["DATA_FOLDER = Path(\"../data\")\n","MULTIVARIATE_DATA_FOLDER = DATA_FOLDER / \"multivariate\"\n","UNIVARIATE_DATA_FOLDER = DATA_FOLDER / \"univariate\"\n","BENCHMARK = False"]},{"cell_type":"markdown","metadata":{},"source":["## 1 Data"]},{"cell_type":"markdown","metadata":{},"source":["### Data Loading"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Load data from csv\n","# -> convert Date column to datetime\n","data = load_time_series(f'{UNIVARIATE_DATA_FOLDER}/NVDA_open_high_low_close_adjClose_volume_99_24.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## 2 Benchmark Loop"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["hyperparameters = {\n","    'lag': [7, 14, 21],\n","    'lr': [0.002, 0.001],\n","    'hidden_size': [2, 4, 6, 8, 12],\n","    'num_layers': [1, 2],\n","    'batch_size': [8, 16, 32, 64],\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# get all combinations of hyperparameters\n","keys, values = zip(*hyperparameters.items())\n","possible_hyperparameters = [dict(zip(keys, v)) for v in itertools.product(*values)]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["possible_features = [\n","    ['Close', 'Volume'],\n","    ['Close', 'Open', 'Volume'],\n","    ['Close', 'Open', 'High', 'Low', 'Volume']\n","]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/240 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["**************************************************\n","**************************************************\n","STARTING NEW BENCHMARK RUN:\n","Features: ['Close', 'Volume']\n","Hyperparameters: {'lag': 7, 'lr': 0.002, 'hidden_size': 2, 'num_layers': 1, 'batch_size': 8}\n","**************************************************\n","**************************************************\n","Adding lagged data for columns: ['Close', 'Volume']\n","Shape of the numpy array wit lagged data: (6384, 8, 2)\n","Shape of X_train: torch.Size([6064, 7, 2]) \n"," Shape of y_train: torch.Size([6064, 1]) \n"," Shape of X_test: torch.Size([320, 7, 2]) \n"," Shape of y_test: torch.Size([320, 1])\n","Epoch: 1\n","Validation Loss: 0.16784588224254549\n","**************************************************\n","Epoch: 2\n","Validation Loss: 0.12619454411324113\n","**************************************************\n","Epoch: 3\n","Validation Loss: 0.06167772792978212\n","**************************************************\n","Epoch: 4\n","Validation Loss: 0.05576030578376958\n","**************************************************\n","Epoch: 5\n","Validation Loss: 0.051380640596107696\n","**************************************************\n","Epoch: 6\n","Validation Loss: 0.04825865675447858\n","**************************************************\n","Epoch: 7\n","Validation Loss: 0.04608590132365862\n","**************************************************\n","Epoch: 8\n","Validation Loss: 0.044298264427197864\n","**************************************************\n","Epoch: 9\n","Validation Loss: 0.04113092992729435\n","**************************************************\n","Epoch: 10\n","Validation Loss: 0.037986202051592956\n","**************************************************\n","Epoch: 11\n","Validation Loss: 0.034014573596391526\n","**************************************************\n","Epoch: 12\n","Validation Loss: 0.03207938690206902\n","**************************************************\n","Epoch: 13\n","Validation Loss: 0.03038291984667012\n","**************************************************\n","Epoch: 14\n","Validation Loss: 0.02766846152578637\n","**************************************************\n","Epoch: 15\n","Validation Loss: 0.025975646157621667\n","**************************************************\n","Epoch: 16\n","Validation Loss: 0.025093643885975327\n","**************************************************\n","Epoch: 17\n","Validation Loss: 0.021992933978981454\n","**************************************************\n","Epoch: 18\n","Validation Loss: 0.01962830482270874\n","**************************************************\n","Epoch: 19\n","Validation Loss: 0.019198201015547055\n","**************************************************\n","Epoch: 20\n","Validation Loss: 0.017382977270608536\n","**************************************************\n","Epoch: 21\n","Validation Loss: 0.015514999153037935\n","**************************************************\n","Epoch: 22\n","Validation Loss: 0.016394268179101345\n","INFO: Validation loss did not improve in epoch 22\n","**************************************************\n","Epoch: 23\n","Validation Loss: 0.013964698169729672\n","**************************************************\n","Epoch: 24\n","Validation Loss: 0.013672467242895437\n","**************************************************\n","Epoch: 25\n","Validation Loss: 0.012885475646726263\n","**************************************************\n","Epoch: 26\n","Validation Loss: 0.01302418517489059\n","INFO: Validation loss did not improve in epoch 26\n","**************************************************\n","Epoch: 27\n","Validation Loss: 0.012058695710129541\n","**************************************************\n","Epoch: 28\n","Validation Loss: 0.011998040731941727\n","**************************************************\n","Epoch: 29\n","Validation Loss: 0.009707824000975052\n","**************************************************\n","Epoch: 30\n","Validation Loss: 0.010736463323155476\n","INFO: Validation loss did not improve in epoch 30\n","**************************************************\n","Epoch: 31\n","Validation Loss: 0.00967007370813917\n","**************************************************\n","Epoch: 32\n","Validation Loss: 0.008953541947175837\n","**************************************************\n","Epoch: 33\n","Validation Loss: 0.009554337662984835\n","INFO: Validation loss did not improve in epoch 33\n","**************************************************\n","Epoch: 34\n","Validation Loss: 0.00894644037255148\n","**************************************************\n","Epoch: 35\n","Validation Loss: 0.008589411345769803\n","**************************************************\n","Epoch: 36\n","Validation Loss: 0.008252560480923422\n","**************************************************\n","Epoch: 37\n","Validation Loss: 0.008288246482061367\n","INFO: Validation loss did not improve in epoch 37\n","**************************************************\n","Epoch: 38\n","Validation Loss: 0.009083153808433053\n","INFO: Validation loss did not improve in epoch 38\n","**************************************************\n","Epoch: 39\n","Validation Loss: 0.008005189964387682\n","**************************************************\n","Epoch: 40\n","Validation Loss: 0.0067839601080777355\n","**************************************************\n","Epoch: 41\n","Validation Loss: 0.008066111199696024\n","INFO: Validation loss did not improve in epoch 41\n","**************************************************\n","Epoch: 42\n","Validation Loss: 0.006724183207234091\n","**************************************************\n","Epoch: 43\n","Validation Loss: 0.007363356896917139\n","INFO: Validation loss did not improve in epoch 43\n","**************************************************\n","Epoch: 44\n","Validation Loss: 0.005482676500287198\n","**************************************************\n","Epoch: 45\n","Validation Loss: 0.007578046621847534\n","INFO: Validation loss did not improve in epoch 45\n","**************************************************\n","Epoch: 46\n","Validation Loss: 0.007426598871279566\n","INFO: Validation loss did not improve in epoch 46\n","**************************************************\n","Epoch: 47\n","Validation Loss: 0.007005292190615364\n","INFO: Validation loss did not improve in epoch 47\n","**************************************************\n","Epoch: 48\n","Validation Loss: 0.006869750519990702\n","INFO: Validation loss did not improve in epoch 48\n","**************************************************\n","Epoch: 49\n","Validation Loss: 0.0054622635493615235\n","**************************************************\n","Epoch: 50\n","Validation Loss: 0.007415409322402411\n","INFO: Validation loss did not improve in epoch 50\n","**************************************************\n","Epoch: 51\n","Validation Loss: 0.0067276199861225905\n","INFO: Validation loss did not improve in epoch 51\n","**************************************************\n","Epoch: 52\n","Validation Loss: 0.006480124385097952\n","INFO: Validation loss did not improve in epoch 52\n","**************************************************\n","Epoch: 53\n","Validation Loss: 0.005748022079296788\n","INFO: Validation loss did not improve in epoch 53\n","**************************************************\n","Epoch: 54\n","Validation Loss: 0.006336428261124638\n","INFO: Validation loss did not improve in epoch 54\n","**************************************************\n","Epoch: 55\n","Validation Loss: 0.006028090578638512\n","INFO: Validation loss did not improve in epoch 55\n","**************************************************\n","Epoch: 56\n","Validation Loss: 0.0061488338037179345\n","INFO: Validation loss did not improve in epoch 56\n","**************************************************\n","Epoch: 57\n","Validation Loss: 0.007103791341592114\n","INFO: Validation loss did not improve in epoch 57\n","**************************************************\n","Epoch: 58\n","Validation Loss: 0.006974963201901119\n","INFO: Validation loss did not improve in epoch 58\n","**************************************************\n","Epoch: 59\n","Validation Loss: 0.007115956715301764\n","INFO: Validation loss did not improve in epoch 59\n","Early stopping after 59 epochs\n","Epoch: 1\n","Validation Loss: 0.0490684203163255\n","**************************************************\n","Epoch: 2\n","Validation Loss: 0.03087126779337268\n","**************************************************\n","Epoch: 3\n","Validation Loss: 0.0254857464599354\n","**************************************************\n","Epoch: 4\n","Validation Loss: 0.023105125690608474\n","**************************************************\n","Epoch: 5\n","Validation Loss: 0.02198579939852152\n","**************************************************\n","Epoch: 6\n","Validation Loss: 0.020030362679949575\n","**************************************************\n","Epoch: 7\n","Validation Loss: 0.019266686522337297\n","**************************************************\n","Epoch: 8\n","Validation Loss: 0.01931995088880285\n","INFO: Validation loss did not improve in epoch 8\n","**************************************************\n","Epoch: 9\n","Validation Loss: 0.018010019695134362\n","**************************************************\n","Epoch: 10\n","Validation Loss: 0.01836641299250914\n","INFO: Validation loss did not improve in epoch 10\n","**************************************************\n","Epoch: 11\n","Validation Loss: 0.01633951986455031\n","**************************************************\n","Epoch: 12\n","Validation Loss: 0.015728470261024086\n","**************************************************\n","Epoch: 13\n","Validation Loss: 0.01423618871758663\n","**************************************************\n","Epoch: 14\n","Validation Loss: 0.014494796020926515\n","INFO: Validation loss did not improve in epoch 14\n","**************************************************\n","Epoch: 15\n","Validation Loss: 0.01475338928939891\n","INFO: Validation loss did not improve in epoch 15\n","**************************************************\n","Epoch: 16\n","Validation Loss: 0.014082390787007171\n","**************************************************\n","Epoch: 17\n","Validation Loss: 0.01325854303718188\n","**************************************************\n","Epoch: 18\n","Validation Loss: 0.012852396440143821\n","**************************************************\n","Epoch: 19\n","Validation Loss: 0.012397093822255557\n","**************************************************\n","Epoch: 20\n","Validation Loss: 0.011922630683147872\n","**************************************************\n","Epoch: 21\n","Validation Loss: 0.011634224312956576\n","**************************************************\n","Epoch: 22\n","Validation Loss: 0.011436914270279885\n","**************************************************\n","Epoch: 23\n","Validation Loss: 0.011234627719341006\n","**************************************************\n","Epoch: 24\n","Validation Loss: 0.011049838874419038\n","**************************************************\n","Epoch: 25\n","Validation Loss: 0.00977607207814799\n","**************************************************\n","Epoch: 26\n","Validation Loss: 0.010412658837230993\n","INFO: Validation loss did not improve in epoch 26\n","**************************************************\n","Epoch: 27\n","Validation Loss: 0.009920739302219771\n","INFO: Validation loss did not improve in epoch 27\n","**************************************************\n","Epoch: 28\n","Validation Loss: 0.009489089849807897\n","**************************************************\n","Epoch: 29\n","Validation Loss: 0.008987226574686247\n","**************************************************\n","Epoch: 30\n","Validation Loss: 0.008895123773072555\n","**************************************************\n","Epoch: 31\n","Validation Loss: 0.00829941838328523\n","**************************************************\n","Epoch: 32\n","Validation Loss: 0.009855648759275937\n","INFO: Validation loss did not improve in epoch 32\n","**************************************************\n","Epoch: 33\n","Validation Loss: 0.009121308684325414\n","INFO: Validation loss did not improve in epoch 33\n","**************************************************\n","Epoch: 34\n","Validation Loss: 0.008244957067699944\n","**************************************************\n","Epoch: 35\n","Validation Loss: 0.007925645384284507\n","**************************************************\n","Epoch: 36\n","Validation Loss: 0.008431243152745082\n","INFO: Validation loss did not improve in epoch 36\n","**************************************************\n","Epoch: 37\n","Validation Loss: 0.007051933032812485\n","**************************************************\n","Epoch: 38\n","Validation Loss: 0.007801295660897267\n","INFO: Validation loss did not improve in epoch 38\n","**************************************************\n","Epoch: 39\n","Validation Loss: 0.007601758666260139\n","INFO: Validation loss did not improve in epoch 39\n","**************************************************\n","Epoch: 40\n","Validation Loss: 0.00695631836404118\n","**************************************************\n","Epoch: 41\n","Validation Loss: 0.006241652598282599\n","**************************************************\n","Epoch: 42\n","Validation Loss: 0.007128903589523361\n","INFO: Validation loss did not improve in epoch 42\n","**************************************************\n","Epoch: 43\n","Validation Loss: 0.007496155572562202\n","INFO: Validation loss did not improve in epoch 43\n","**************************************************\n","Epoch: 44\n","Validation Loss: 0.006737173114242978\n","INFO: Validation loss did not improve in epoch 44\n","**************************************************\n","Epoch: 45\n","Validation Loss: 0.00640850611832775\n","INFO: Validation loss did not improve in epoch 45\n","**************************************************\n","Epoch: 46\n","Validation Loss: 0.006490882546086141\n","INFO: Validation loss did not improve in epoch 46\n","**************************************************\n","Epoch: 47\n","Validation Loss: 0.0058164315673593595\n","**************************************************\n","Epoch: 48\n","Validation Loss: 0.005447345184802543\n","**************************************************\n","Epoch: 49\n","Validation Loss: 0.005973593526277909\n","INFO: Validation loss did not improve in epoch 49\n","**************************************************\n","Epoch: 50\n","Validation Loss: 0.006616635089176271\n","INFO: Validation loss did not improve in epoch 50\n","**************************************************\n","Epoch: 51\n","Validation Loss: 0.006053120120327549\n","INFO: Validation loss did not improve in epoch 51\n","**************************************************\n","Epoch: 52\n","Validation Loss: 0.00612077228677208\n","INFO: Validation loss did not improve in epoch 52\n","**************************************************\n","Epoch: 53\n","Validation Loss: 0.006298903915148912\n","INFO: Validation loss did not improve in epoch 53\n","**************************************************\n","Epoch: 54\n","Validation Loss: 0.006355594374417706\n","INFO: Validation loss did not improve in epoch 54\n","**************************************************\n","Epoch: 55\n","Validation Loss: 0.005793642006642586\n","INFO: Validation loss did not improve in epoch 55\n","**************************************************\n","Epoch: 56\n","Validation Loss: 0.006194229782249749\n","INFO: Validation loss did not improve in epoch 56\n","**************************************************\n","Epoch: 57\n","Validation Loss: 0.006111214316342739\n","INFO: Validation loss did not improve in epoch 57\n","**************************************************\n","Epoch: 58\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/240 [01:24<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.005703880919782023\n","INFO: Validation loss did not improve in epoch 58\n","Early stopping after 58 epochs\n","Saving results to json...\n","Results saved!\n","##################################################\n","##################################################\n","##################################################\n","TRAINING FINISHED\n","##################################################\n","##################################################\n","##################################################\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["RESULTS = {}\n","for features in possible_features:\n","\n","    for hyperparameters in tqdm(possible_hyperparameters):\n","        \n","        print('*'*50)\n","        print('*'*50)\n","        print('STARTING NEW BENCHMARK RUN:')\n","        print(f\"Features: {features}\")\n","        print(f\"Hyperparameters: {hyperparameters}\")\n","        print('*'*50)\n","        print('*'*50)\n","\n","        ### Select features\n","        features_incl_date = features+['Date']\n","        data_only_features = data[features_incl_date]\n","        \n","        ### Data Preprocessing\n","        data_lagged = add_lagged_data(data_only_features, hyperparameters['lag'], features)\n","        data_lagged_scaled, scaler_close = scale_data(data_lagged)\n","        X_train, y_train, X_test, y_test = train_test_split_to_tensor(data_lagged_scaled)\n","\n","        ### Create datasets and DataLoaders\n","        train_dataset = TimeSeriesDataset(X_train, y_train)\n","        test_dataset = TimeSeriesDataset(X_test, y_test)\n","        train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n","        test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)\n","\n","        ### Train model\n","        validation_losses = [] # reset validation losses\n","        for i in range(2): # train 2 times because sometimes the model converges to a local minimum\n","            ### Instantiate model\n","            model = LSTM(\n","                device=device,\n","                input_size=len(features),\n","                hidden_size=hyperparameters['hidden_size'],\n","                num_stacked_layers=hyperparameters['num_layers']\n","            ).to(device)\n","\n","            ### Optimizer, Criterion\n","            optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['lr'])\n","            criterion = nn.MSELoss()\n","\n","            validation_loss, model = train_model(\n","                model=model,\n","                train_loader=train_loader,\n","                test_loader=test_loader,\n","                optimizer=optimizer,\n","                criterion=criterion,\n","                device=device)\n","            \n","            # save loss for each run\n","            validation_losses.append(validation_loss)\n","        \n","        ### Save results to dict\n","        feature_acronym = ''.join([feature[0] for feature in features])\n","        RESULTS[f'{feature_acronym}_lag{hyperparameters[\"lag\"]}_lr{hyperparameters[\"lr\"]}_bs{hyperparameters[\"batch_size\"]}_hs{hyperparameters[\"hidden_size\"]}_nl{hyperparameters[\"num_layers\"]}'] = min(validation_losses) # only save min loss\n","\n","    \n","### Save results to json\n","print('Saving results to json...')\n","with open(f'./results/LSTM_benchmark_results_{datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")}.json', 'w') as json_file:\n","    json.dump(RESULTS, json_file, indent=4)\n","print('Results saved!')\n","\n","print('#'*50)\n","print('#'*50)\n","print('#'*50)\n","print('TRAINING FINISHED')\n","print('#'*50)\n","print('#'*50)\n","print('#'*50)"]},{"cell_type":"markdown","metadata":{},"source":["## 3 Evaluate Results"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["{'CV_lag7_lr0.002_bs8_hs2_nl1': 0.005447345184802543}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["RESULTS"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["'CV_lag7_lr0.002_bs8_hs2_nl1'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["best_params = min(RESULTS, key=RESULTS.get)\n","best_params"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["0.005447345184802543"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["RESULTS[best_params]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"time_series_data_augmentation_venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
