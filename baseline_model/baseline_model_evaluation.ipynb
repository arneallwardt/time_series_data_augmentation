{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Comparison\n",
    "\n",
    "In this notebook, different ways to compare the quality of augmented time series are explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Füge das übergeordnete Verzeichnis zu sys.path hinzu\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "# own classes\n",
    "from utilities import reconstruct_sequential_data, train_test_split, extract_features_and_targets_reg, extract_features_and_targets, split_data_into_sequences, Scaler, ValidationLossAccumulationCallback, accuracy\n",
    "from baseline_model.LSTM import LSTMRegression, train_model, LSTMClassification\n",
    "from baseline_model.TimeSeriesDataset import TimeSeriesDataset\n",
    "from baseline_model.mean_regressor import MeanRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../data\")\n",
    "SYNTHETIC_DATA_FOLDER = DATA_FOLDER / \"synthetic\"\n",
    "REAL_DATA_FOLDER = DATA_FOLDER / \"real\"\n",
    "LOAD_ORIGINAL_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVING_AVERAGES = [50, 20]\n",
    "MA_FEATURES = [f'{ma}d MA' for ma in MOVING_AVERAGES]\n",
    "INCLUDE_MOVING_AVERAGES = False\n",
    "\n",
    "FEATURES = ['Trend', 'Close', 'Log Close', 'Daily Returns Percent', 'Volume', 'mom', 'mom1', 'mom2', 'mom3', 'ROC_5',\n",
    "       'ROC_10', 'ROC_15', 'ROC_20', 'EMA_10', 'EMA_20', 'EMA_50', 'EMA_200',\n",
    "       'DTB4WK', 'DTB3', 'DTB6', 'DGS5', 'DGS10', 'Oil', 'Gold', 'DAAA',\n",
    "       'DBAA', 'GBP', 'JPY', 'CAD', 'CNY', 'AAPL', 'AMZN', 'GE', 'JNJ', 'JPM',\n",
    "       'MSFT', 'WFC', 'XOM', 'FCHI', 'FTSE', 'GDAXI', 'DJI', 'HSI', 'IXIC',\n",
    "       'SSEC', 'RUT', 'NYSE', 'TE1', 'TE2', 'TE3', 'TE5', 'TE6', 'DE1', 'DE2',\n",
    "       'DE4', 'DE5', 'DE6', 'CTB3M', 'CTB6M', 'CTB1Y', 'AUD', 'Brent',\n",
    "       'CAC-F', 'copper-F', 'WIT-oil', 'DAX-F', 'DJI-F', 'EUR', 'FTSE-F',\n",
    "       'gold-F', 'HSI-F', 'KOSPI-F', 'NASDAQ-F', 'GAS-F', 'Nikkei-F', 'NZD',\n",
    "       'silver-F', 'RUSSELL-F', 'S&P-F', 'CHF', 'Dollar index-F',\n",
    "       'Dollar index', 'wheat-F', 'XAG', 'XAU']\n",
    "\n",
    "# FEATURES = ['Trend', 'AAPL', 'FTSE', 'Volume',\n",
    "#             'Close', 'Gold', 'JNJ', 'Dollar index']\n",
    "\n",
    "if INCLUDE_MOVING_AVERAGES:\n",
    "    FEATURES += MA_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams (ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK = False\n",
    "RANDOM_LABEL_PERMUTATION = False\n",
    "CLASSIFICATION = True\n",
    "\n",
    "\n",
    "SEQ_LEN = 12\n",
    "FIRST_SPLIT = 0.8\n",
    "SECOND_SPLIT = 0.5 \n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 4\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "OUTPUT_LOGITS = True\n",
    "BIDIRECTIONAL = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_ORIGINAL_DATA:\n",
    "    # load and convert date column to datetime\n",
    "    traffic = pd.read_csv(REAL_DATA_FOLDER / 'metro_interstate_traffic_volume_original.csv')\n",
    "    traffic['date'] = pd.to_datetime(traffic['date'])\n",
    "\n",
    "    # create a series with a full range of dates with hourly frequency\n",
    "    # does take leap years and different month length into account\n",
    "    full_range = pd.date_range(start=traffic['date'].min(), end=traffic['date'].max(), freq='H')\n",
    "\n",
    "    traffic = traffic.drop_duplicates(subset='date') # drop duplicates\n",
    "    traffic.set_index('date', inplace=True) # set date as index\n",
    "\n",
    "    traffic = traffic.reindex(full_range, method='nearest') # reindex to full_range and fill missing values with nearest value\n",
    "\n",
    "    # set index name and reset index to keep date as column\n",
    "    traffic.index.name = 'date'\n",
    "    traffic.reset_index(inplace=True)\n",
    "\n",
    "else:\n",
    "    \n",
    "    traffic = pd.read_csv(REAL_DATA_FOLDER / 'metro_interstate_traffic_volume_filled.csv')\n",
    "    traffic['date'] = pd.to_datetime(traffic['date'])\n",
    "\n",
    "# only include data from 2015-07-01\n",
    "# the reason is because the data before that date is not complete\n",
    "traffic = traffic[traffic['date'] > '2015-07-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24040</th>\n",
       "      <td>2015-07-01 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24041</th>\n",
       "      <td>2015-07-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24042</th>\n",
       "      <td>2015-07-01 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288.74</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24043</th>\n",
       "      <td>2015-07-01 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24044</th>\n",
       "      <td>2015-07-01 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date holiday    temp  rain_1h  snow_1h  clouds_all  \\\n",
       "24040 2015-07-01 01:00:00     NaN  289.40      0.0      0.0           1   \n",
       "24041 2015-07-01 02:00:00     NaN  289.19      0.0      0.0           1   \n",
       "24042 2015-07-01 03:00:00     NaN  288.74      0.3      0.0           1   \n",
       "24043 2015-07-01 04:00:00     NaN  288.07      0.0      0.0           1   \n",
       "24044 2015-07-01 05:00:00     NaN  287.87      0.0      0.0           1   \n",
       "\n",
       "      weather_main weather_description  traffic_volume  \n",
       "24040        Clear        sky is clear             444  \n",
       "24041        Clear        sky is clear             347  \n",
       "24042         Rain          light rain             356  \n",
       "24043        Clear        sky is clear             936  \n",
       "24044        Clear        sky is clear            2886  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot traffic volume\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(traffic['date'], traffic['traffic_volume'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.title('Traffic Volume over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monat extrahieren\n",
    "traffic['month'] = traffic['date'].dt.month\n",
    "\n",
    "# one hot encoding for categorical variables\n",
    "traffic = pd.get_dummies(traffic, columns=['weather_main', 'weather_description', 'month'], dtype=int)\n",
    "\n",
    "# encode holiday as binary variable\n",
    "traffic['holiday'] = traffic['holiday'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "\n",
    "# encode weekend as binary variable\n",
    "traffic['weekend'] = traffic['date'].apply(lambda x: 1 if x.day_of_week in [5, 6] else 0)\n",
    "\n",
    "# encode hour as cyclic variable\n",
    "traffic['hour'] = traffic['date'].dt.hour\n",
    "traffic['hour_sin'] = np.sin((2 * np.pi * traffic['hour']) / 24)\n",
    "traffic['hour_cos'] = np.cos((2 * np.pi * traffic['hour']) / 24)\n",
    "\n",
    "# drop unnecessary columns\n",
    "traffic.drop(columns=['date', 'hour'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns which have to be scaled\n",
    "traffic_volume = traffic.pop('traffic_volume')\n",
    "temp = traffic.pop('temp')\n",
    "clouds_all = traffic.pop('clouds_all')\n",
    "\n",
    "# insert so that target is the first column\n",
    "traffic.insert(0, 'clouds_all', clouds_all)\n",
    "traffic.insert(0, 'temp', temp)\n",
    "traffic.insert(0, 'traffic_volume', traffic_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASSIFICATION:\n",
    "    traffic['traffic_volume_diff'] = traffic['traffic_volume'].diff()\n",
    "    traffic_volume_diff = traffic.pop('traffic_volume_diff')\n",
    "    traffic.insert(0, 'traffic_volume_diff', traffic_volume_diff)\n",
    "\n",
    "    traffic.dropna(inplace=True)\n",
    "\n",
    "    traffic['traffic_volume_diff'] = traffic['traffic_volume_diff'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume_diff</th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>temp</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>holiday</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>weather_main_Clear</th>\n",
       "      <th>weather_main_Clouds</th>\n",
       "      <th>weather_main_Drizzle</th>\n",
       "      <th>...</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24041</th>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "      <td>289.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24042</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>288.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24043</th>\n",
       "      <td>1</td>\n",
       "      <td>936</td>\n",
       "      <td>288.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24044</th>\n",
       "      <td>1</td>\n",
       "      <td>2886</td>\n",
       "      <td>287.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24045</th>\n",
       "      <td>1</td>\n",
       "      <td>5741</td>\n",
       "      <td>287.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24046</th>\n",
       "      <td>1</td>\n",
       "      <td>6261</td>\n",
       "      <td>287.58</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24047</th>\n",
       "      <td>0</td>\n",
       "      <td>4409</td>\n",
       "      <td>288.58</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24048</th>\n",
       "      <td>0</td>\n",
       "      <td>4409</td>\n",
       "      <td>288.58</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24049</th>\n",
       "      <td>0</td>\n",
       "      <td>4273</td>\n",
       "      <td>289.24</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24050</th>\n",
       "      <td>1</td>\n",
       "      <td>4469</td>\n",
       "      <td>289.44</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24051</th>\n",
       "      <td>1</td>\n",
       "      <td>4625</td>\n",
       "      <td>290.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24052</th>\n",
       "      <td>0</td>\n",
       "      <td>4462</td>\n",
       "      <td>292.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053</th>\n",
       "      <td>1</td>\n",
       "      <td>4996</td>\n",
       "      <td>293.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24054</th>\n",
       "      <td>1</td>\n",
       "      <td>5623</td>\n",
       "      <td>294.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24055</th>\n",
       "      <td>1</td>\n",
       "      <td>6210</td>\n",
       "      <td>295.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24056</th>\n",
       "      <td>0</td>\n",
       "      <td>5969</td>\n",
       "      <td>295.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24057</th>\n",
       "      <td>0</td>\n",
       "      <td>4604</td>\n",
       "      <td>295.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24058</th>\n",
       "      <td>0</td>\n",
       "      <td>3649</td>\n",
       "      <td>294.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24059</th>\n",
       "      <td>0</td>\n",
       "      <td>3144</td>\n",
       "      <td>293.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24060</th>\n",
       "      <td>0</td>\n",
       "      <td>2788</td>\n",
       "      <td>291.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       traffic_volume_diff  traffic_volume    temp  clouds_all  holiday  \\\n",
       "24041                    0             347  289.19           1        0   \n",
       "24042                    1             356  288.74           1        0   \n",
       "24043                    1             936  288.07           1        0   \n",
       "24044                    1            2886  287.87           1        0   \n",
       "24045                    1            5741  287.38           1        0   \n",
       "24046                    1            6261  287.58          75        0   \n",
       "24047                    0            4409  288.58          40        0   \n",
       "24048                    0            4409  288.58          40        0   \n",
       "24049                    0            4273  289.24          40        0   \n",
       "24050                    1            4469  289.44          75        0   \n",
       "24051                    1            4625  290.53           1        0   \n",
       "24052                    0            4462  292.17           1        0   \n",
       "24053                    1            4996  293.61           1        0   \n",
       "24054                    1            5623  294.85           1        0   \n",
       "24055                    1            6210  295.07           1        0   \n",
       "24056                    0            5969  295.56           1        0   \n",
       "24057                    0            4604  295.17           1        0   \n",
       "24058                    0            3649  294.86           1        0   \n",
       "24059                    0            3144  293.76           1        0   \n",
       "24060                    0            2788  291.19           1        0   \n",
       "\n",
       "       rain_1h  snow_1h  weather_main_Clear  weather_main_Clouds  \\\n",
       "24041      0.0      0.0                   1                    0   \n",
       "24042      0.3      0.0                   0                    0   \n",
       "24043      0.0      0.0                   1                    0   \n",
       "24044      0.0      0.0                   1                    0   \n",
       "24045      0.0      0.0                   1                    0   \n",
       "24046      0.0      0.0                   0                    1   \n",
       "24047      0.0      0.0                   0                    1   \n",
       "24048      0.0      0.0                   0                    1   \n",
       "24049      0.0      0.0                   0                    1   \n",
       "24050      0.0      0.0                   0                    1   \n",
       "24051      0.0      0.0                   1                    0   \n",
       "24052      0.0      0.0                   1                    0   \n",
       "24053      0.0      0.0                   1                    0   \n",
       "24054      0.0      0.0                   1                    0   \n",
       "24055      0.0      0.0                   1                    0   \n",
       "24056      0.0      0.0                   1                    0   \n",
       "24057      0.0      0.0                   1                    0   \n",
       "24058      0.0      0.0                   1                    0   \n",
       "24059      0.0      0.0                   1                    0   \n",
       "24060      0.0      0.0                   1                    0   \n",
       "\n",
       "       weather_main_Drizzle  ...  month_6  month_7  month_8  month_9  \\\n",
       "24041                     0  ...        0        1        0        0   \n",
       "24042                     0  ...        0        1        0        0   \n",
       "24043                     0  ...        0        1        0        0   \n",
       "24044                     0  ...        0        1        0        0   \n",
       "24045                     0  ...        0        1        0        0   \n",
       "24046                     0  ...        0        1        0        0   \n",
       "24047                     0  ...        0        1        0        0   \n",
       "24048                     0  ...        0        1        0        0   \n",
       "24049                     0  ...        0        1        0        0   \n",
       "24050                     0  ...        0        1        0        0   \n",
       "24051                     0  ...        0        1        0        0   \n",
       "24052                     0  ...        0        1        0        0   \n",
       "24053                     0  ...        0        1        0        0   \n",
       "24054                     0  ...        0        1        0        0   \n",
       "24055                     0  ...        0        1        0        0   \n",
       "24056                     0  ...        0        1        0        0   \n",
       "24057                     0  ...        0        1        0        0   \n",
       "24058                     0  ...        0        1        0        0   \n",
       "24059                     0  ...        0        1        0        0   \n",
       "24060                     0  ...        0        1        0        0   \n",
       "\n",
       "       month_10  month_11  month_12  weekend      hour_sin      hour_cos  \n",
       "24041         0         0         0        0  5.000000e-01  8.660254e-01  \n",
       "24042         0         0         0        0  7.071068e-01  7.071068e-01  \n",
       "24043         0         0         0        0  8.660254e-01  5.000000e-01  \n",
       "24044         0         0         0        0  9.659258e-01  2.588190e-01  \n",
       "24045         0         0         0        0  1.000000e+00  6.123234e-17  \n",
       "24046         0         0         0        0  9.659258e-01 -2.588190e-01  \n",
       "24047         0         0         0        0  8.660254e-01 -5.000000e-01  \n",
       "24048         0         0         0        0  7.071068e-01 -7.071068e-01  \n",
       "24049         0         0         0        0  5.000000e-01 -8.660254e-01  \n",
       "24050         0         0         0        0  2.588190e-01 -9.659258e-01  \n",
       "24051         0         0         0        0  1.224647e-16 -1.000000e+00  \n",
       "24052         0         0         0        0 -2.588190e-01 -9.659258e-01  \n",
       "24053         0         0         0        0 -5.000000e-01 -8.660254e-01  \n",
       "24054         0         0         0        0 -7.071068e-01 -7.071068e-01  \n",
       "24055         0         0         0        0 -8.660254e-01 -5.000000e-01  \n",
       "24056         0         0         0        0 -9.659258e-01 -2.588190e-01  \n",
       "24057         0         0         0        0 -1.000000e+00 -1.836970e-16  \n",
       "24058         0         0         0        0 -9.659258e-01  2.588190e-01  \n",
       "24059         0         0         0        0 -8.660254e-01  5.000000e-01  \n",
       "24060         0         0         0        0 -7.071068e-01  7.071068e-01  \n",
       "\n",
       "[20 rows x 66 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_np = traffic.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_train, traffic_test = train_test_split(traffic_np, FIRST_SPLIT)\n",
    "traffic_test, traffic_val = train_test_split(traffic_test, SECOND_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22808, 66), (2851, 66), (2851, 66))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_train.shape, traffic_test.shape, traffic_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler(traffic_train, no_features_to_scale = 4 if CLASSIFICATION else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_train_scaled = scaler.scale_data(traffic_train)\n",
    "traffic_test_scaled = scaler.scale_data(traffic_test)\n",
    "traffic_val_scaled = scaler.scale_data(traffic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data after splitting into sequences: (22797, 12, 66)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 66)\n",
      "Shape of the data after splitting into sequences: (2840, 12, 66)\n"
     ]
    }
   ],
   "source": [
    "traffic_train_seq_scaled = split_data_into_sequences(traffic_train_scaled, SEQ_LEN)\n",
    "traffic_test_seq_scaled = split_data_into_sequences(traffic_test_scaled, SEQ_LEN)\n",
    "traffic_val_seq_scaled = split_data_into_sequences(traffic_val_scaled, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASSIFICATION:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "    # get baseline performance\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_once(no_features, train_loader, val_loader):\n",
    "    # create and train model\n",
    "    model = LSTMClassification(\n",
    "        device=device,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        input_size=no_features,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_stacked_layers=NUM_LAYERS,\n",
    "        bidirectional=BIDIRECTIONAL,\n",
    "        output_logits=OUTPUT_LOGITS\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    _, _, _, _, model = train_model(model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                device=device,\n",
    "                verbose=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_performance(model, X_test, y_test):\n",
    "    with torch.inference_mode(): \n",
    "        test_logits = model(X_test.to(device)) # get plain model output (logits)\n",
    "        test_probs = torch.sigmoid(test_logits) # get probabilities\n",
    "        test_preds = torch.round(test_probs) # get classes\n",
    "\n",
    "        test_acc = accuracy(y_true=y_test, y_pred=torch.tensor(test_preds))\n",
    "        test_loss = criterion(test_logits, y_test).item()\n",
    "\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark / Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification\n"
     ]
    }
   ],
   "source": [
    "# get train, test and validation data\n",
    "if CLASSIFICATION:\n",
    "    print('Classification')\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = extract_features_and_targets(traffic_train_seq_scaled, traffic_test_seq_scaled, traffic_val_seq_scaled)\n",
    "else:\n",
    "    print('Regression')\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = extract_features_and_targets_reg(traffic_train_seq_scaled, traffic_test_seq_scaled, traffic_val_seq_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BCEWithLogitsLoss for classification\n",
      "Epoch: 1\n",
      "Training Loss: 0.6793346866965294\n",
      "Training Loss: 0.6890949791669846\n",
      "Training Loss: 0.6912445551156998\n",
      "Validation Loss: 0.6852712557556924\n",
      "Validation Accuracy: 56.00421348314607\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "Training Loss: 0.6674977868795395\n",
      "Training Loss: 0.6807410138845443\n",
      "Training Loss: 0.683688525557518\n",
      "Validation Loss: 0.6766304929604691\n",
      "Validation Accuracy: 56.00421348314607\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "Training Loss: 0.6552615609765052\n",
      "Training Loss: 0.6703122293949128\n",
      "Training Loss: 0.6719454270601273\n",
      "Validation Loss: 0.6619525283909915\n",
      "Validation Accuracy: 56.00421348314607\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "Training Loss: 0.6389263129234314\n",
      "Training Loss: 0.6534709832072259\n",
      "Training Loss: 0.6513625028729438\n",
      "Validation Loss: 0.6373126667537047\n",
      "Validation Accuracy: 57.57256554307116\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "Training Loss: 0.6186716565489769\n",
      "Training Loss: 0.6283480608463288\n",
      "Training Loss: 0.6210441946983337\n",
      "Validation Loss: 0.6048409088274066\n",
      "Validation Accuracy: 63.33099250936329\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "Training Loss: 0.5979977191984653\n",
      "Training Loss: 0.6003513470292091\n",
      "Training Loss: 0.5906052260100841\n",
      "Validation Loss: 0.5742722384715349\n",
      "Validation Accuracy: 69.33520599250936\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "Training Loss: 0.5810538744926452\n",
      "Training Loss: 0.5760618364810943\n",
      "Training Loss: 0.5660710221529007\n",
      "Validation Loss: 0.5493281929010756\n",
      "Validation Accuracy: 73.0688202247191\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "Training Loss: 0.5686455835402012\n",
      "Training Loss: 0.5564378772675991\n",
      "Training Loss: 0.5470447839796543\n",
      "Validation Loss: 0.5295518609914887\n",
      "Validation Accuracy: 74.96488764044943\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "Training Loss: 0.5593486467003822\n",
      "Training Loss: 0.540657608360052\n",
      "Training Loss: 0.5320946389436721\n",
      "Validation Loss: 0.5136561517635089\n",
      "Validation Accuracy: 76.31086142322097\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "Training Loss: 0.5515231004357338\n",
      "Training Loss: 0.5276327736675739\n",
      "Training Loss: 0.519911533743143\n",
      "Validation Loss: 0.5004035984532217\n",
      "Validation Accuracy: 78.03136704119851\n",
      "**************************************************\n",
      "Epoch: 11\n",
      "Training Loss: 0.5441495296359062\n",
      "Training Loss: 0.5164626163244247\n",
      "Training Loss: 0.5094978369772434\n",
      "Validation Loss: 0.4888252287768246\n",
      "Validation Accuracy: 78.69850187265918\n",
      "**************************************************\n",
      "Epoch: 12\n",
      "Training Loss: 0.5368502809107304\n",
      "Training Loss: 0.5065643432736396\n",
      "Training Loss: 0.5001783546805382\n",
      "Validation Loss: 0.4782885842108994\n",
      "Validation Accuracy: 79.36563670411985\n",
      "**************************************************\n",
      "Epoch: 13\n",
      "Training Loss: 0.5296752032637596\n",
      "Training Loss: 0.49759223327040675\n",
      "Training Loss: 0.4915761707723141\n",
      "Validation Loss: 0.468477042873254\n",
      "Validation Accuracy: 80.03277153558052\n",
      "**************************************************\n",
      "Epoch: 14\n",
      "Training Loss: 0.5228179717063903\n",
      "Training Loss: 0.4893565660715103\n",
      "Training Loss: 0.48350916340947153\n",
      "Validation Loss: 0.45924578623825246\n",
      "Validation Accuracy: 80.27855805243446\n",
      "**************************************************\n",
      "Epoch: 15\n",
      "Training Loss: 0.5163837318122387\n",
      "Training Loss: 0.48165476232767107\n",
      "Training Loss: 0.47587420761585236\n",
      "Validation Loss: 0.45050053917959837\n",
      "Validation Accuracy: 80.84035580524345\n",
      "**************************************************\n",
      "Epoch: 16\n",
      "Training Loss: 0.510361742079258\n",
      "Training Loss: 0.4744022715091705\n",
      "Training Loss: 0.4685992430150509\n",
      "Validation Loss: 0.44217010830225567\n",
      "Validation Accuracy: 81.19147940074907\n",
      "**************************************************\n",
      "Epoch: 17\n",
      "Training Loss: 0.5046962147951126\n",
      "Training Loss: 0.46750420704483986\n",
      "Training Loss: 0.46162973463535306\n",
      "Validation Loss: 0.434211668673526\n",
      "Validation Accuracy: 81.54260299625469\n",
      "**************************************************\n",
      "Epoch: 18\n",
      "Training Loss: 0.4993398889899254\n",
      "Training Loss: 0.4608892548084259\n",
      "Training Loss: 0.45493301391601565\n",
      "Validation Loss: 0.4266057225425592\n",
      "Validation Accuracy: 81.95224719101124\n",
      "**************************************************\n",
      "Epoch: 19\n",
      "Training Loss: 0.4942653985321522\n",
      "Training Loss: 0.45451664432883265\n",
      "Training Loss: 0.44849716536700723\n",
      "Validation Loss: 0.41934070895227155\n",
      "Validation Accuracy: 82.12780898876404\n",
      "**************************************************\n",
      "Epoch: 20\n",
      "Training Loss: 0.4894568894803524\n",
      "Training Loss: 0.4483711764216423\n",
      "Training Loss: 0.44231965005397794\n",
      "Validation Loss: 0.4124028947246209\n",
      "Validation Accuracy: 82.30337078651685\n",
      "**************************************************\n",
      "Epoch: 21\n",
      "Training Loss: 0.4848989184200764\n",
      "Training Loss: 0.4424482496082783\n",
      "Training Loss: 0.4363966275006533\n",
      "Validation Loss: 0.40577511707048736\n",
      "Validation Accuracy: 82.33848314606742\n",
      "**************************************************\n",
      "Epoch: 22\n",
      "Training Loss: 0.48057244047522546\n",
      "Training Loss: 0.4367444920539856\n",
      "Training Loss: 0.43072126284241674\n",
      "Validation Loss: 0.3994370526477192\n",
      "Validation Accuracy: 82.47893258426966\n",
      "**************************************************\n",
      "Epoch: 23\n",
      "Training Loss: 0.47646082684397695\n",
      "Training Loss: 0.4312574632465839\n",
      "Training Loss: 0.4252855446189642\n",
      "Validation Loss: 0.3933690091532268\n",
      "Validation Accuracy: 82.7247191011236\n",
      "**************************************************\n",
      "Epoch: 24\n",
      "Training Loss: 0.47255733266472816\n",
      "Training Loss: 0.4259892002493143\n",
      "Training Loss: 0.4200812418758869\n",
      "Validation Loss: 0.3875589007407092\n",
      "Validation Accuracy: 82.7247191011236\n",
      "**************************************************\n",
      "Epoch: 25\n",
      "Training Loss: 0.46886896818876267\n",
      "Training Loss: 0.4209461037814617\n",
      "Training Loss: 0.41509914994239805\n",
      "Validation Loss: 0.38200507170698617\n",
      "Validation Accuracy: 82.83005617977528\n",
      "**************************************************\n",
      "Epoch: 26\n",
      "Training Loss: 0.4654151862859726\n",
      "Training Loss: 0.416134187579155\n",
      "Training Loss: 0.41032682672142984\n",
      "Validation Loss: 0.37671156863818006\n",
      "Validation Accuracy: 83.00561797752809\n",
      "**************************************************\n",
      "Epoch: 27\n",
      "Training Loss: 0.46220637902617456\n",
      "Training Loss: 0.4115579131245613\n",
      "Training Loss: 0.4057579980790615\n",
      "Validation Loss: 0.37168486114968075\n",
      "Validation Accuracy: 83.14606741573034\n",
      "**************************************************\n",
      "Epoch: 28\n",
      "Training Loss: 0.4592494404315948\n",
      "Training Loss: 0.40721563443541525\n",
      "Training Loss: 0.4013843584060669\n",
      "Validation Loss: 0.3669270231817546\n",
      "Validation Accuracy: 83.39185393258427\n",
      "**************************************************\n",
      "Epoch: 29\n",
      "Training Loss: 0.456532261967659\n",
      "Training Loss: 0.4031025659292936\n",
      "Training Loss: 0.39720056653022767\n",
      "Validation Loss: 0.362435100621052\n",
      "Validation Accuracy: 83.78979400749064\n",
      "**************************************************\n",
      "Epoch: 30\n",
      "Training Loss: 0.454038223028183\n",
      "Training Loss: 0.3992105124890804\n",
      "Training Loss: 0.39320307582616804\n",
      "Validation Loss: 0.35819936886932074\n",
      "Validation Accuracy: 84.14091760299625\n",
      "**************************************************\n",
      "Epoch: 31\n",
      "Training Loss: 0.4517490653693676\n",
      "Training Loss: 0.39552869498729704\n",
      "Training Loss: 0.38938484512269494\n",
      "Validation Loss: 0.35420639109745455\n",
      "Validation Accuracy: 84.63249063670412\n",
      "**************************************************\n",
      "Epoch: 32\n",
      "Training Loss: 0.4496460721641779\n",
      "Training Loss: 0.39204062715172766\n",
      "Training Loss: 0.3857344873249531\n",
      "Validation Loss: 0.3504342788390899\n",
      "Validation Accuracy: 85.44007490636704\n",
      "**************************************************\n",
      "Epoch: 33\n",
      "Training Loss: 0.44771420195698736\n",
      "Training Loss: 0.3887303237617016\n",
      "Training Loss: 0.38224015772342684\n",
      "Validation Loss: 0.34686674328332534\n",
      "Validation Accuracy: 85.86142322097379\n",
      "**************************************************\n",
      "Epoch: 34\n",
      "Training Loss: 0.44594949632883074\n",
      "Training Loss: 0.38558148056268693\n",
      "Training Loss: 0.3788899523764849\n",
      "Validation Loss: 0.3434855191225416\n",
      "Validation Accuracy: 86.28277153558052\n",
      "**************************************************\n",
      "Epoch: 35\n",
      "Training Loss: 0.44432797126471996\n",
      "Training Loss: 0.38258415527641776\n",
      "Training Loss: 0.37568027153611183\n",
      "Validation Loss: 0.3402730475985602\n",
      "Validation Accuracy: 86.70411985018727\n",
      "**************************************************\n",
      "Epoch: 36\n",
      "Training Loss: 0.4428349128365517\n",
      "Training Loss: 0.37972952947020533\n",
      "Training Loss: 0.37260763831436633\n",
      "Validation Loss: 0.33721538088964614\n",
      "Validation Accuracy: 87.54681647940075\n",
      "**************************************************\n",
      "Epoch: 37\n",
      "Training Loss: 0.4414584317058325\n",
      "Training Loss: 0.3770105239003897\n",
      "Training Loss: 0.369668267890811\n",
      "Validation Loss: 0.33430183603522484\n",
      "Validation Accuracy: 88.21395131086143\n",
      "**************************************************\n",
      "Epoch: 38\n",
      "Training Loss: 0.4401911549270153\n",
      "Training Loss: 0.3744204088300467\n",
      "Training Loss: 0.3668579150736332\n",
      "Validation Loss: 0.3315241102422221\n",
      "Validation Accuracy: 88.84597378277154\n",
      "**************************************************\n",
      "Epoch: 39\n",
      "Training Loss: 0.43902387976646423\n",
      "Training Loss: 0.3719540814310312\n",
      "Training Loss: 0.36417179353535173\n",
      "Validation Loss: 0.3288755475470189\n",
      "Validation Accuracy: 89.23220973782772\n",
      "**************************************************\n",
      "Epoch: 40\n",
      "Training Loss: 0.43794807910919187\n",
      "Training Loss: 0.3696081456542015\n",
      "Training Loss: 0.3616054793447256\n",
      "Validation Loss: 0.32635067319602107\n",
      "Validation Accuracy: 89.87593632958801\n",
      "**************************************************\n",
      "Epoch: 41\n",
      "Training Loss: 0.436949282810092\n",
      "Training Loss: 0.3673759476095438\n",
      "Training Loss: 0.3591524487733841\n",
      "Validation Loss: 0.32394870178083357\n",
      "Validation Accuracy: 90.36750936329588\n",
      "**************************************************\n",
      "Epoch: 42\n",
      "Training Loss: 0.4360190074145794\n",
      "Training Loss: 0.3652137792110443\n",
      "Training Loss: 0.35681624472141266\n",
      "Validation Loss: 0.3216576427221298\n",
      "Validation Accuracy: 90.68352059925093\n",
      "**************************************************\n",
      "Epoch: 43\n",
      "Training Loss: 0.4351467812806368\n",
      "Training Loss: 0.36320496164262295\n",
      "Training Loss: 0.354588254019618\n",
      "Validation Loss: 0.31947684321510655\n",
      "Validation Accuracy: 90.96441947565543\n",
      "**************************************************\n",
      "Epoch: 44\n",
      "Training Loss: 0.4343188524246216\n",
      "Training Loss: 0.36129872255027295\n",
      "Training Loss: 0.3524628730118275\n",
      "Validation Loss: 0.31740006837952\n",
      "Validation Accuracy: 91.03464419475655\n",
      "**************************************************\n",
      "Epoch: 45\n",
      "Training Loss: 0.43353165082633494\n",
      "Training Loss: 0.35948703981935975\n",
      "Training Loss: 0.3504299599677324\n",
      "Validation Loss: 0.31542045011949005\n",
      "Validation Accuracy: 91.10486891385767\n",
      "**************************************************\n",
      "Epoch: 46\n",
      "Training Loss: 0.4327862660586834\n",
      "Training Loss: 0.35776265263557433\n",
      "Training Loss: 0.3484820160269737\n",
      "Validation Loss: 0.3135297132676907\n",
      "Validation Accuracy: 91.28043071161048\n",
      "**************************************************\n",
      "Epoch: 47\n",
      "Training Loss: 0.43207550898194313\n",
      "Training Loss: 0.35611962020397187\n",
      "Training Loss: 0.34661409698426726\n",
      "Validation Loss: 0.3117203287194284\n",
      "Validation Accuracy: 91.31554307116104\n",
      "**************************************************\n",
      "Epoch: 48\n",
      "Training Loss: 0.43139681495726107\n",
      "Training Loss: 0.3545516134798527\n",
      "Training Loss: 0.3448180590569973\n",
      "Validation Loss: 0.30998583506332356\n",
      "Validation Accuracy: 91.35065543071161\n",
      "**************************************************\n",
      "Epoch: 49\n",
      "Training Loss: 0.430753673017025\n",
      "Training Loss: 0.35305110208690166\n",
      "Training Loss: 0.34308746092021464\n",
      "Validation Loss: 0.30832015128617873\n",
      "Validation Accuracy: 91.31554307116104\n",
      "**************************************************\n",
      "Epoch: 50\n",
      "Training Loss: 0.4301444761455059\n",
      "Training Loss: 0.35161228723824023\n",
      "Training Loss: 0.34141833290457724\n",
      "Validation Loss: 0.3067163009656949\n",
      "Validation Accuracy: 91.42088014981273\n",
      "**************************************************\n",
      "Epoch: 51\n",
      "Training Loss: 0.4295652247220278\n",
      "Training Loss: 0.350231000483036\n",
      "Training Loss: 0.3398077516257763\n",
      "Validation Loss: 0.30516688475448095\n",
      "Validation Accuracy: 91.4559925093633\n",
      "**************************************************\n",
      "Epoch: 52\n",
      "Training Loss: 0.42901127129793165\n",
      "Training Loss: 0.3489020789414644\n",
      "Training Loss: 0.33825252182781695\n",
      "Validation Loss: 0.3036693433362446\n",
      "Validation Accuracy: 91.4559925093633\n",
      "**************************************************\n",
      "Epoch: 53\n",
      "Training Loss: 0.4284805788099766\n",
      "Training Loss: 0.34762016370892523\n",
      "Training Loss: 0.33674724102020265\n",
      "Validation Loss: 0.302218961749184\n",
      "Validation Accuracy: 91.52621722846442\n",
      "**************************************************\n",
      "Epoch: 54\n",
      "Training Loss: 0.4279717942327261\n",
      "Training Loss: 0.3463825861364603\n",
      "Training Loss: 0.3352919267117977\n",
      "Validation Loss: 0.30081166946486143\n",
      "Validation Accuracy: 91.42088014981273\n",
      "**************************************************\n",
      "Epoch: 55\n",
      "Training Loss: 0.42748365662992\n",
      "Training Loss: 0.3451865121722221\n",
      "Training Loss: 0.3338844420015812\n",
      "Validation Loss: 0.2994441708152214\n",
      "Validation Accuracy: 91.42088014981273\n",
      "**************************************************\n",
      "Epoch: 56\n",
      "Training Loss: 0.4270176597684622\n",
      "Training Loss: 0.3440261249244213\n",
      "Training Loss: 0.3325194579362869\n",
      "Validation Loss: 0.29811342161023213\n",
      "Validation Accuracy: 91.4559925093633\n",
      "**************************************************\n",
      "Epoch: 57\n",
      "Training Loss: 0.4265728971362114\n",
      "Training Loss: 0.34289932072162627\n",
      "Training Loss: 0.3311950306594372\n",
      "Validation Loss: 0.2968170932504568\n",
      "Validation Accuracy: 91.38576779026216\n",
      "**************************************************\n",
      "Epoch: 58\n",
      "Training Loss: 0.42614194221794605\n",
      "Training Loss: 0.34180618152022363\n",
      "Training Loss: 0.329911315664649\n",
      "Validation Loss: 0.29555312100421177\n",
      "Validation Accuracy: 91.2687265917603\n",
      "**************************************************\n",
      "Epoch: 59\n",
      "Training Loss: 0.4257251426577568\n",
      "Training Loss: 0.3407446262985468\n",
      "Training Loss: 0.32866748109459876\n",
      "Validation Loss: 0.29432074993513946\n",
      "Validation Accuracy: 91.33895131086143\n",
      "**************************************************\n",
      "Epoch: 60\n",
      "Training Loss: 0.4253163142502308\n",
      "Training Loss: 0.3397131760418415\n",
      "Training Loss: 0.3274672446399927\n",
      "Validation Loss: 0.2931190627009681\n",
      "Validation Accuracy: 91.30383895131087\n",
      "**************************************************\n",
      "Epoch: 61\n",
      "Training Loss: 0.42491018764674665\n",
      "Training Loss: 0.3387109370529652\n",
      "Training Loss: 0.326306477189064\n",
      "Validation Loss: 0.29194865116242613\n",
      "Validation Accuracy: 91.30383895131087\n",
      "**************************************************\n",
      "Epoch: 62\n",
      "Training Loss: 0.42450857803225517\n",
      "Training Loss: 0.3377364920079708\n",
      "Training Loss: 0.32518072456121444\n",
      "Validation Loss: 0.29080976060267244\n",
      "Validation Accuracy: 91.23361423220975\n",
      "**************************************************\n",
      "Epoch: 63\n",
      "Training Loss: 0.42411836825311183\n",
      "Training Loss: 0.33678794771432874\n",
      "Training Loss: 0.32408899046480655\n",
      "Validation Loss: 0.28970113379901713\n",
      "Validation Accuracy: 91.19850187265918\n",
      "**************************************************\n",
      "Epoch: 64\n",
      "Training Loss: 0.4237431349605322\n",
      "Training Loss: 0.3358626423031092\n",
      "Training Loss: 0.3230283550918102\n",
      "Validation Loss: 0.2886197446437364\n",
      "Validation Accuracy: 91.2687265917603\n",
      "**************************************************\n",
      "Epoch: 65\n",
      "Training Loss: 0.42337679788470267\n",
      "Training Loss: 0.33495967522263526\n",
      "Training Loss: 0.32200139462947847\n",
      "Validation Loss: 0.28756346846564435\n",
      "Validation Accuracy: 91.23361423220975\n",
      "**************************************************\n",
      "Epoch: 66\n",
      "Training Loss: 0.4230178707093\n",
      "Training Loss: 0.3340776900947094\n",
      "Training Loss: 0.32100570514798166\n",
      "Validation Loss: 0.28653126452746014\n",
      "Validation Accuracy: 91.19850187265918\n",
      "**************************************************\n",
      "Epoch: 67\n",
      "Training Loss: 0.4226619167625904\n",
      "Training Loss: 0.33321577243506906\n",
      "Training Loss: 0.32003819808363915\n",
      "Validation Loss: 0.28552167151081426\n",
      "Validation Accuracy: 91.19850187265918\n",
      "**************************************************\n",
      "Epoch: 68\n",
      "Training Loss: 0.4223131179064512\n",
      "Training Loss: 0.3323720221966505\n",
      "Training Loss: 0.3190966073423624\n",
      "Validation Loss: 0.2845331718412678\n",
      "Validation Accuracy: 91.2687265917603\n",
      "**************************************************\n",
      "Epoch: 69\n",
      "Training Loss: 0.42197390884160996\n",
      "Training Loss: 0.3315455547720194\n",
      "Training Loss: 0.3181789290904999\n",
      "Validation Loss: 0.28356470820609103\n",
      "Validation Accuracy: 91.2687265917603\n",
      "**************************************************\n",
      "Epoch: 70\n",
      "Training Loss: 0.42164337933063506\n",
      "Training Loss: 0.3307358116656542\n",
      "Training Loss: 0.31728453278541563\n",
      "Validation Loss: 0.28261525694573864\n",
      "Validation Accuracy: 91.30383895131087\n",
      "**************************************************\n",
      "Epoch: 71\n",
      "Training Loss: 0.4213181997835636\n",
      "Training Loss: 0.32994213707745074\n",
      "Training Loss: 0.31641255035996435\n",
      "Validation Loss: 0.28168524684530966\n",
      "Validation Accuracy: 91.33895131086143\n",
      "**************************************************\n",
      "Epoch: 72\n",
      "Training Loss: 0.420995329990983\n",
      "Training Loss: 0.3291649557650089\n",
      "Training Loss: 0.3155639221519232\n",
      "Validation Loss: 0.28077334885516864\n",
      "Validation Accuracy: 91.33895131086143\n",
      "**************************************************\n",
      "Epoch: 73\n",
      "Training Loss: 0.4206770223379135\n",
      "Training Loss: 0.3284035749733448\n",
      "Training Loss: 0.3147367289662361\n",
      "Validation Loss: 0.279878405540177\n",
      "Validation Accuracy: 91.33895131086143\n",
      "**************************************************\n",
      "Epoch: 74\n",
      "Training Loss: 0.42036542370915414\n",
      "Training Loss: 0.3276569384336472\n",
      "Training Loss: 0.3139294572919607\n",
      "Validation Loss: 0.2789987906646193\n",
      "Validation Accuracy: 91.33895131086143\n",
      "**************************************************\n",
      "Epoch: 75\n",
      "Training Loss: 0.42006347633898256\n",
      "Training Loss: 0.3269262856990099\n",
      "Training Loss: 0.31314346052706243\n",
      "Validation Loss: 0.27813484025805185\n",
      "Validation Accuracy: 91.37406367041199\n",
      "**************************************************\n",
      "Epoch: 76\n",
      "Training Loss: 0.41976749822497367\n",
      "Training Loss: 0.32620980493724344\n",
      "Training Loss: 0.31237478740513325\n",
      "Validation Loss: 0.27728571265601043\n",
      "Validation Accuracy: 91.33895131086143\n",
      "**************************************************\n",
      "Epoch: 77\n",
      "Training Loss: 0.41947885766625403\n",
      "Training Loss: 0.32546286314725875\n",
      "Training Loss: 0.31162154592573643\n",
      "Validation Loss: 0.27645171023486703\n",
      "Validation Accuracy: 91.37406367041199\n",
      "**************************************************\n",
      "Epoch: 78\n",
      "Training Loss: 0.41919905722141265\n",
      "Training Loss: 0.3247719352692366\n",
      "Training Loss: 0.31088612459599974\n",
      "Validation Loss: 0.2756312648566921\n",
      "Validation Accuracy: 91.37406367041199\n",
      "**************************************************\n",
      "Epoch: 79\n",
      "Training Loss: 0.4189230291545391\n",
      "Training Loss: 0.32409391418099404\n",
      "Training Loss: 0.3101668054610491\n",
      "Validation Loss: 0.27482444885071744\n",
      "Validation Accuracy: 91.37406367041199\n",
      "**************************************************\n",
      "Epoch: 80\n",
      "Training Loss: 0.4186537428945303\n",
      "Training Loss: 0.32344957791268825\n",
      "Training Loss: 0.30945397228002547\n",
      "Validation Loss: 0.2740318902422873\n",
      "Validation Accuracy: 91.44428838951312\n",
      "**************************************************\n",
      "Epoch: 81\n",
      "Training Loss: 0.4183986860513687\n",
      "Training Loss: 0.3227772668004036\n",
      "Training Loss: 0.30876741871237756\n",
      "Validation Loss: 0.27324833143293187\n",
      "Validation Accuracy: 91.44428838951312\n",
      "**************************************************\n",
      "Epoch: 82\n",
      "Training Loss: 0.4181531621515751\n",
      "Training Loss: 0.32213268578052523\n",
      "Training Loss: 0.3080905980616808\n",
      "Validation Loss: 0.27247850228561443\n",
      "Validation Accuracy: 91.44428838951312\n",
      "**************************************************\n",
      "Epoch: 83\n",
      "Training Loss: 0.4179181785136461\n",
      "Training Loss: 0.3214996276050806\n",
      "Training Loss: 0.3074252850562334\n",
      "Validation Loss: 0.27172101933634685\n",
      "Validation Accuracy: 91.40917602996255\n",
      "**************************************************\n",
      "Epoch: 84\n",
      "Training Loss: 0.41770160138607026\n",
      "Training Loss: 0.3208762925863266\n",
      "Training Loss: 0.30676278449594974\n",
      "Validation Loss: 0.2709766380237729\n",
      "Validation Accuracy: 91.44428838951312\n",
      "**************************************************\n",
      "Epoch: 85\n",
      "Training Loss: 0.417504153624177\n",
      "Training Loss: 0.32026328846812246\n",
      "Training Loss: 0.30610873028635976\n",
      "Validation Loss: 0.27024418132358724\n",
      "Validation Accuracy: 91.47940074906367\n",
      "**************************************************\n",
      "Epoch: 86\n",
      "Training Loss: 0.4173152379691601\n",
      "Training Loss: 0.31966154620051385\n",
      "Training Loss: 0.30545943945646287\n",
      "Validation Loss: 0.2695240115516641\n",
      "Validation Accuracy: 91.51451310861424\n",
      "**************************************************\n",
      "Epoch: 87\n",
      "Training Loss: 0.417130980938673\n",
      "Training Loss: 0.31907419234514234\n",
      "Training Loss: 0.3048310686647892\n",
      "Validation Loss: 0.26881307782082076\n",
      "Validation Accuracy: 91.58473782771536\n",
      "**************************************************\n",
      "Epoch: 88\n",
      "Training Loss: 0.41694974824786185\n",
      "Training Loss: 0.3184930408000946\n",
      "Training Loss: 0.3042107693105936\n",
      "Validation Loss: 0.2681144003787737\n",
      "Validation Accuracy: 91.61985018726593\n",
      "**************************************************\n",
      "Epoch: 89\n",
      "Training Loss: 0.4167704180628061\n",
      "Training Loss: 0.3179229111224413\n",
      "Training Loss: 0.3036016710102558\n",
      "Validation Loss: 0.26742671547311075\n",
      "Validation Accuracy: 91.65496254681648\n",
      "**************************************************\n",
      "Epoch: 90\n",
      "Training Loss: 0.41659238271415233\n",
      "Training Loss: 0.31736507929861546\n",
      "Training Loss: 0.30300896652042864\n",
      "Validation Loss: 0.26674984663390044\n",
      "Validation Accuracy: 91.65496254681648\n",
      "**************************************************\n",
      "Epoch: 91\n",
      "Training Loss: 0.4164100009948015\n",
      "Training Loss: 0.3168179411441088\n",
      "Training Loss: 0.3024271471053362\n",
      "Validation Loss: 0.2660843577612652\n",
      "Validation Accuracy: 91.61985018726593\n",
      "**************************************************\n",
      "Epoch: 92\n",
      "Training Loss: 0.4162268110364675\n",
      "Training Loss: 0.31628014959394934\n",
      "Training Loss: 0.301854485347867\n",
      "Validation Loss: 0.2654296228390061\n",
      "Validation Accuracy: 91.61985018726593\n",
      "**************************************************\n",
      "Epoch: 93\n",
      "Training Loss: 0.4160444165021181\n",
      "Training Loss: 0.31575100556015967\n",
      "Training Loss: 0.30129054106771946\n",
      "Validation Loss: 0.2647861893592256\n",
      "Validation Accuracy: 91.65496254681648\n",
      "**************************************************\n",
      "Epoch: 94\n",
      "Training Loss: 0.41586289621889594\n",
      "Training Loss: 0.3152478962391615\n",
      "Training Loss: 0.3007243029028177\n",
      "Validation Loss: 0.26415437141831\n",
      "Validation Accuracy: 91.61985018726593\n",
      "**************************************************\n",
      "Epoch: 95\n",
      "Training Loss: 0.4156862886250019\n",
      "Training Loss: 0.31472128100693225\n",
      "Training Loss: 0.3001800883561373\n",
      "Validation Loss: 0.2635294562310315\n",
      "Validation Accuracy: 91.58473782771536\n",
      "**************************************************\n",
      "Epoch: 96\n",
      "Training Loss: 0.41551337607204913\n",
      "Training Loss: 0.314216303229332\n",
      "Training Loss: 0.29963823735713957\n",
      "Validation Loss: 0.26291695940360593\n",
      "Validation Accuracy: 91.61985018726593\n",
      "**************************************************\n",
      "Epoch: 97\n",
      "Training Loss: 0.41534205347299574\n",
      "Training Loss: 0.3137219351530075\n",
      "Training Loss: 0.29910281613469125\n",
      "Validation Loss: 0.26231539768449375\n",
      "Validation Accuracy: 91.65496254681648\n",
      "**************************************************\n",
      "Epoch: 98\n",
      "Training Loss: 0.4151713978499174\n",
      "Training Loss: 0.3132371248304844\n",
      "Training Loss: 0.29857342652976515\n",
      "Validation Loss: 0.2617249587613545\n",
      "Validation Accuracy: 91.72518726591761\n",
      "**************************************************\n",
      "Epoch: 99\n",
      "Training Loss: 0.41500834055244923\n",
      "Training Loss: 0.31275976218283175\n",
      "Training Loss: 0.2980500092357397\n",
      "Validation Loss: 0.26114568901195956\n",
      "Validation Accuracy: 91.72518726591761\n",
      "**************************************************\n",
      "Epoch: 100\n",
      "Training Loss: 0.41485013253986835\n",
      "Training Loss: 0.31229139052331445\n",
      "Training Loss: 0.2975234142690897\n",
      "Validation Loss: 0.26057817711589043\n",
      "Validation Accuracy: 91.72518726591761\n",
      "**************************************************\n",
      "Epoch: 101\n",
      "Training Loss: 0.4146959663182497\n",
      "Training Loss: 0.31183191545307637\n",
      "Training Loss: 0.2970175091177225\n",
      "Validation Loss: 0.26001798704768836\n",
      "Validation Accuracy: 91.72518726591761\n",
      "**************************************************\n",
      "Epoch: 102\n",
      "Training Loss: 0.41454044423997405\n",
      "Training Loss: 0.31137600764632223\n",
      "Training Loss: 0.2965149153769016\n",
      "Validation Loss: 0.25946889633543035\n",
      "Validation Accuracy: 91.79541198501873\n",
      "**************************************************\n",
      "Epoch: 103\n",
      "Training Loss: 0.4143878694623709\n",
      "Training Loss: 0.31092896513640883\n",
      "Training Loss: 0.29601956874132157\n",
      "Validation Loss: 0.258929390083538\n",
      "Validation Accuracy: 91.79541198501873\n",
      "**************************************************\n",
      "Epoch: 104\n",
      "Training Loss: 0.41423373140394687\n",
      "Training Loss: 0.3104892207682133\n",
      "Training Loss: 0.29552896320819855\n",
      "Validation Loss: 0.2583987655097179\n",
      "Validation Accuracy: 91.8305243445693\n",
      "**************************************************\n",
      "Epoch: 105\n",
      "Training Loss: 0.4140793725848198\n",
      "Training Loss: 0.3100557641685009\n",
      "Training Loss: 0.2950429067015648\n",
      "Validation Loss: 0.25787677456823627\n",
      "Validation Accuracy: 91.8305243445693\n",
      "**************************************************\n",
      "Epoch: 106\n",
      "Training Loss: 0.4139247526228428\n",
      "Training Loss: 0.3096286728978157\n",
      "Training Loss: 0.2945618198812008\n",
      "Validation Loss: 0.257362326042036\n",
      "Validation Accuracy: 91.8305243445693\n",
      "**************************************************\n",
      "Epoch: 107\n",
      "Training Loss: 0.413770607188344\n",
      "Training Loss: 0.30920749455690383\n",
      "Training Loss: 0.2940848301723599\n",
      "Validation Loss: 0.25685626368844106\n",
      "Validation Accuracy: 91.79541198501873\n",
      "**************************************************\n",
      "Epoch: 108\n",
      "Training Loss: 0.4136179185658693\n",
      "Training Loss: 0.308791718557477\n",
      "Training Loss: 0.29361208125948907\n",
      "Validation Loss: 0.25635728089327225\n",
      "Validation Accuracy: 91.79541198501873\n",
      "**************************************************\n",
      "Epoch: 109\n",
      "Training Loss: 0.4134681098908186\n",
      "Training Loss: 0.30838160768151285\n",
      "Training Loss: 0.29314350366592407\n",
      "Validation Loss: 0.2558646107490143\n",
      "Validation Accuracy: 91.8305243445693\n",
      "**************************************************\n",
      "Epoch: 110\n",
      "Training Loss: 0.41331710398197175\n",
      "Training Loss: 0.30797660976648333\n",
      "Training Loss: 0.2926789411902428\n",
      "Validation Loss: 0.25537958623987905\n",
      "Validation Accuracy: 91.8305243445693\n",
      "**************************************************\n",
      "Epoch: 111\n",
      "Training Loss: 0.4131672879308462\n",
      "Training Loss: 0.3075925006717444\n",
      "Training Loss: 0.29220673121511936\n",
      "Validation Loss: 0.2549036054798726\n",
      "Validation Accuracy: 91.86563670411985\n",
      "**************************************************\n",
      "Epoch: 112\n",
      "Training Loss: 0.4130214507877827\n",
      "Training Loss: 0.3071850086003542\n",
      "Training Loss: 0.29175512854009866\n",
      "Validation Loss: 0.2544313215472725\n",
      "Validation Accuracy: 91.88904494382022\n",
      "**************************************************\n",
      "Epoch: 113\n",
      "Training Loss: 0.41287469416856765\n",
      "Training Loss: 0.3067920174449682\n",
      "Training Loss: 0.29130320087075234\n",
      "Validation Loss: 0.25396767174929713\n",
      "Validation Accuracy: 91.92415730337079\n",
      "**************************************************\n",
      "Epoch: 114\n",
      "Training Loss: 0.41272131346166135\n",
      "Training Loss: 0.306449895426631\n",
      "Training Loss: 0.29085216622799637\n",
      "Validation Loss: 0.25351017713546753\n",
      "Validation Accuracy: 91.92415730337079\n",
      "**************************************************\n",
      "Epoch: 115\n",
      "Training Loss: 0.41256462931633\n",
      "Training Loss: 0.3060292308777571\n",
      "Training Loss: 0.2904121384397149\n",
      "Validation Loss: 0.25305917323305366\n",
      "Validation Accuracy: 91.92415730337079\n",
      "**************************************************\n",
      "Epoch: 116\n",
      "Training Loss: 0.4124089077860117\n",
      "Training Loss: 0.3056537140160799\n",
      "Training Loss: 0.2899749429151416\n",
      "Validation Loss: 0.25261588804842383\n",
      "Validation Accuracy: 91.92415730337079\n",
      "**************************************************\n",
      "Epoch: 117\n",
      "Training Loss: 0.41225562170147895\n",
      "Training Loss: 0.30528210118412974\n",
      "Training Loss: 0.2895394480600953\n",
      "Validation Loss: 0.2521793746044127\n",
      "Validation Accuracy: 91.95926966292134\n",
      "**************************************************\n",
      "Epoch: 118\n",
      "Training Loss: 0.4121042750775814\n",
      "Training Loss: 0.30491584964096546\n",
      "Training Loss: 0.2890956934541464\n",
      "Validation Loss: 0.2517508685253979\n",
      "Validation Accuracy: 92.02949438202248\n",
      "**************************************************\n",
      "Epoch: 119\n",
      "Training Loss: 0.4119551706314087\n",
      "Training Loss: 0.3045551374927163\n",
      "Training Loss: 0.2886709886416793\n",
      "Validation Loss: 0.25132469548268266\n",
      "Validation Accuracy: 92.06460674157303\n",
      "**************************************************\n",
      "Epoch: 120\n",
      "Training Loss: 0.4118056570738554\n",
      "Training Loss: 0.3041931329295039\n",
      "Training Loss: 0.2882443925365806\n",
      "Validation Loss: 0.25090552456258386\n",
      "Validation Accuracy: 92.06460674157303\n",
      "**************************************************\n",
      "Epoch: 121\n",
      "Training Loss: 0.4116541808843613\n",
      "Training Loss: 0.30383631177246573\n",
      "Training Loss: 0.28782099597156047\n",
      "Validation Loss: 0.25049212323815634\n",
      "Validation Accuracy: 92.05290262172285\n",
      "**************************************************\n",
      "Epoch: 122\n",
      "Training Loss: 0.4115017706155777\n",
      "Training Loss: 0.3034852074459195\n",
      "Training Loss: 0.28739873707294467\n",
      "Validation Loss: 0.2500837961776873\n",
      "Validation Accuracy: 92.08801498127342\n",
      "**************************************************\n",
      "Epoch: 123\n",
      "Training Loss: 0.41134599708020686\n",
      "Training Loss: 0.3031369370594621\n",
      "Training Loss: 0.28698239773511885\n",
      "Validation Loss: 0.2496810739629724\n",
      "Validation Accuracy: 92.12312734082397\n",
      "**************************************************\n",
      "Epoch: 124\n",
      "Training Loss: 0.41119206123054025\n",
      "Training Loss: 0.30279084991663696\n",
      "Training Loss: 0.28656882654875515\n",
      "Validation Loss: 0.24928409857361505\n",
      "Validation Accuracy: 92.13483146067416\n",
      "**************************************************\n",
      "Epoch: 125\n",
      "Training Loss: 0.411037737801671\n",
      "Training Loss: 0.3024487294256687\n",
      "Training Loss: 0.28615994695574043\n",
      "Validation Loss: 0.24889226040143644\n",
      "Validation Accuracy: 92.0997191011236\n",
      "**************************************************\n",
      "Epoch: 126\n",
      "Training Loss: 0.41088251046836377\n",
      "Training Loss: 0.3021099532023072\n",
      "Training Loss: 0.28574889529496433\n",
      "Validation Loss: 0.24850710180033458\n",
      "Validation Accuracy: 92.0997191011236\n",
      "**************************************************\n",
      "Epoch: 127\n",
      "Training Loss: 0.4107277747243643\n",
      "Training Loss: 0.3017779776081443\n",
      "Training Loss: 0.2853504048287869\n",
      "Validation Loss: 0.2481257716256581\n",
      "Validation Accuracy: 92.13483146067416\n",
      "**************************************************\n",
      "Epoch: 128\n",
      "Training Loss: 0.4105738724768162\n",
      "Training Loss: 0.3014460916817188\n",
      "Training Loss: 0.2849530292674899\n",
      "Validation Loss: 0.2477512222327543\n",
      "Validation Accuracy: 92.28698501872658\n",
      "**************************************************\n",
      "Epoch: 129\n",
      "Training Loss: 0.41041984021663663\n",
      "Training Loss: 0.3011179212108254\n",
      "Training Loss: 0.2845588133111596\n",
      "Validation Loss: 0.2473819755603758\n",
      "Validation Accuracy: 92.28698501872658\n",
      "**************************************************\n",
      "Epoch: 130\n",
      "Training Loss: 0.4102661395072937\n",
      "Training Loss: 0.3007931389659643\n",
      "Training Loss: 0.2841676044091582\n",
      "Validation Loss: 0.2470174754938383\n",
      "Validation Accuracy: 92.28698501872658\n",
      "**************************************************\n",
      "Epoch: 131\n",
      "Training Loss: 0.41011132530868055\n",
      "Training Loss: 0.300473943091929\n",
      "Training Loss: 0.28377982068806884\n",
      "Validation Loss: 0.2466565528779887\n",
      "Validation Accuracy: 92.32209737827715\n",
      "**************************************************\n",
      "Epoch: 132\n",
      "Training Loss: 0.40995620250701903\n",
      "Training Loss: 0.3001563593745232\n",
      "Training Loss: 0.2833949813991785\n",
      "Validation Loss: 0.24630000073923153\n",
      "Validation Accuracy: 92.32209737827715\n",
      "**************************************************\n",
      "Epoch: 133\n",
      "Training Loss: 0.4098035737872124\n",
      "Training Loss: 0.2998414523899555\n",
      "Training Loss: 0.283013484030962\n",
      "Validation Loss: 0.24594728364033647\n",
      "Validation Accuracy: 92.25187265917603\n",
      "**************************************************\n",
      "Epoch: 134\n",
      "Training Loss: 0.4096520493924618\n",
      "Training Loss: 0.2995293165370822\n",
      "Training Loss: 0.28263560209423305\n",
      "Validation Loss: 0.24559743811240356\n",
      "Validation Accuracy: 92.28698501872658\n",
      "**************************************************\n",
      "Epoch: 135\n",
      "Training Loss: 0.40950332686305047\n",
      "Training Loss: 0.2992191034182906\n",
      "Training Loss: 0.282261528968811\n",
      "Validation Loss: 0.2452500375469079\n",
      "Validation Accuracy: 92.21676029962546\n",
      "**************************************************\n",
      "Epoch: 136\n",
      "Training Loss: 0.4093575695902109\n",
      "Training Loss: 0.29891172781586645\n",
      "Training Loss: 0.2818911835551262\n",
      "Validation Loss: 0.24490532973844015\n",
      "Validation Accuracy: 92.25187265917603\n",
      "**************************************************\n",
      "Epoch: 137\n",
      "Training Loss: 0.40921122193336484\n",
      "Training Loss: 0.2986068308725953\n",
      "Training Loss: 0.2815246145427227\n",
      "Validation Loss: 0.24456272483541724\n",
      "Validation Accuracy: 92.21676029962546\n",
      "**************************************************\n",
      "Epoch: 138\n",
      "Training Loss: 0.4090650222450495\n",
      "Training Loss: 0.2983044909313321\n",
      "Training Loss: 0.2811620241031051\n",
      "Validation Loss: 0.24422250964333503\n",
      "Validation Accuracy: 92.21676029962546\n",
      "**************************************************\n",
      "Epoch: 139\n",
      "Training Loss: 0.4089202259480953\n",
      "Training Loss: 0.29800607670098544\n",
      "Training Loss: 0.2807929280772805\n",
      "Validation Loss: 0.24388554575068228\n",
      "Validation Accuracy: 92.25187265917603\n",
      "**************************************************\n",
      "Epoch: 140\n",
      "Training Loss: 0.4087731464207172\n",
      "Training Loss: 0.2977118429169059\n",
      "Training Loss: 0.2804428438842297\n",
      "Validation Loss: 0.243547510146425\n",
      "Validation Accuracy: 92.28698501872658\n",
      "**************************************************\n",
      "Epoch: 141\n",
      "Training Loss: 0.40863335587084293\n",
      "Training Loss: 0.2974143045023084\n",
      "Training Loss: 0.28009252198040485\n",
      "Validation Loss: 0.24321370345822882\n",
      "Validation Accuracy: 92.28698501872658\n",
      "**************************************************\n",
      "Epoch: 142\n",
      "Training Loss: 0.40849017441272734\n",
      "Training Loss: 0.29712020259350536\n",
      "Training Loss: 0.2797460540384054\n",
      "Validation Loss: 0.2428824340694406\n",
      "Validation Accuracy: 92.32209737827715\n",
      "**************************************************\n",
      "Epoch: 143\n",
      "Training Loss: 0.4083453433215618\n",
      "Training Loss: 0.2968276427313685\n",
      "Training Loss: 0.27940197944641115\n",
      "Validation Loss: 0.2425533507144853\n",
      "Validation Accuracy: 92.28698501872658\n",
      "**************************************************\n",
      "Epoch: 144\n",
      "Training Loss: 0.4081987166404724\n",
      "Training Loss: 0.2965377120673656\n",
      "Training Loss: 0.27906139601022006\n",
      "Validation Loss: 0.24222629944260202\n",
      "Validation Accuracy: 92.25187265917603\n",
      "**************************************************\n",
      "Epoch: 145\n",
      "Training Loss: 0.40805256597697737\n",
      "Training Loss: 0.29624969866126777\n",
      "Training Loss: 0.2787237896025181\n",
      "Validation Loss: 0.2419007389565532\n",
      "Validation Accuracy: 92.21676029962546\n",
      "**************************************************\n",
      "Epoch: 146\n",
      "Training Loss: 0.4079081476479769\n",
      "Training Loss: 0.2959631336852908\n",
      "Training Loss: 0.27838909953832625\n",
      "Validation Loss: 0.24157638571570428\n",
      "Validation Accuracy: 92.21676029962546\n",
      "**************************************************\n",
      "Epoch: 147\n",
      "Training Loss: 0.4077652979642153\n",
      "Training Loss: 0.295678307749331\n",
      "Training Loss: 0.27805726762861016\n",
      "Validation Loss: 0.24125329840384171\n",
      "Validation Accuracy: 92.32209737827715\n",
      "**************************************************\n",
      "Epoch: 148\n",
      "Training Loss: 0.4076248846203089\n",
      "Training Loss: 0.2953966027125716\n",
      "Training Loss: 0.27772852532565595\n",
      "Validation Loss: 0.24093054017324125\n",
      "Validation Accuracy: 92.3572097378277\n",
      "**************************************************\n",
      "Epoch: 149\n",
      "Training Loss: 0.4074834873527288\n",
      "Training Loss: 0.2951153863221407\n",
      "Training Loss: 0.27740239564329383\n",
      "Validation Loss: 0.24060950947276663\n",
      "Validation Accuracy: 92.32209737827715\n",
      "**************************************************\n",
      "Epoch: 150\n",
      "Training Loss: 0.4073449133336544\n",
      "Training Loss: 0.29483488071709874\n",
      "Training Loss: 0.27707872427999974\n",
      "Validation Loss: 0.24028915016168959\n",
      "Validation Accuracy: 92.3572097378277\n",
      "**************************************************\n",
      "Epoch: 151\n",
      "Training Loss: 0.40720487423241136\n",
      "Training Loss: 0.29455576967447994\n",
      "Training Loss: 0.27675756957381964\n",
      "Validation Loss: 0.23996896246510946\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 152\n",
      "Training Loss: 0.40706448048353194\n",
      "Training Loss: 0.2942768127843738\n",
      "Training Loss: 0.2764385912567377\n",
      "Validation Loss: 0.23964915089727787\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 153\n",
      "Training Loss: 0.40692401699721814\n",
      "Training Loss: 0.29399858966469766\n",
      "Training Loss: 0.27612188387662173\n",
      "Validation Loss: 0.23932981206459947\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 154\n",
      "Training Loss: 0.40678344428539276\n",
      "Training Loss: 0.2937266818061471\n",
      "Training Loss: 0.2757944306358695\n",
      "Validation Loss: 0.2390121151222272\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 155\n",
      "Training Loss: 0.40663865990936754\n",
      "Training Loss: 0.29345584865659474\n",
      "Training Loss: 0.2754909737408161\n",
      "Validation Loss: 0.23868974122438538\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 156\n",
      "Training Loss: 0.40649758324027063\n",
      "Training Loss: 0.2931800723820925\n",
      "Training Loss: 0.27518415927886963\n",
      "Validation Loss: 0.23837035492564854\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 157\n",
      "Training Loss: 0.40635186433792114\n",
      "Training Loss: 0.2929051064699888\n",
      "Training Loss: 0.2748780560493469\n",
      "Validation Loss: 0.2380517717827572\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 158\n",
      "Training Loss: 0.4062056639045477\n",
      "Training Loss: 0.29263038508594036\n",
      "Training Loss: 0.2745734406635165\n",
      "Validation Loss: 0.23773361935039586\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 159\n",
      "Training Loss: 0.4060594189167023\n",
      "Training Loss: 0.29235553566366435\n",
      "Training Loss: 0.27427030086517334\n",
      "Validation Loss: 0.23741578419556778\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 160\n",
      "Training Loss: 0.4059125279635191\n",
      "Training Loss: 0.2920802041143179\n",
      "Training Loss: 0.2739692747220397\n",
      "Validation Loss: 0.23709812710124456\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 161\n",
      "Training Loss: 0.40576571710407733\n",
      "Training Loss: 0.29180462326854467\n",
      "Training Loss: 0.2736698756366968\n",
      "Validation Loss: 0.23678118685323202\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 162\n",
      "Training Loss: 0.40562558874487875\n",
      "Training Loss: 0.2915291167423129\n",
      "Training Loss: 0.2733716466277838\n",
      "Validation Loss: 0.23646548373645612\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 163\n",
      "Training Loss: 0.4054840212315321\n",
      "Training Loss: 0.2912493897229433\n",
      "Training Loss: 0.27306535210460425\n",
      "Validation Loss: 0.23615153652898382\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 164\n",
      "Training Loss: 0.40534023083746434\n",
      "Training Loss: 0.2909785786271095\n",
      "Training Loss: 0.2727754572406411\n",
      "Validation Loss: 0.2358356253819519\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 165\n",
      "Training Loss: 0.4052009782940149\n",
      "Training Loss: 0.29070169389247896\n",
      "Training Loss: 0.2724834112077951\n",
      "Validation Loss: 0.2355226572979702\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 166\n",
      "Training Loss: 0.4050594151765108\n",
      "Training Loss: 0.2904252730309963\n",
      "Training Loss: 0.27219195187091827\n",
      "Validation Loss: 0.23521128581481032\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 167\n",
      "Training Loss: 0.4049167107790709\n",
      "Training Loss: 0.29014865942299367\n",
      "Training Loss: 0.2719013644754887\n",
      "Validation Loss: 0.2349013781614518\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 168\n",
      "Training Loss: 0.40477345608174803\n",
      "Training Loss: 0.2898718650266528\n",
      "Training Loss: 0.2716116391122341\n",
      "Validation Loss: 0.234593118342121\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 169\n",
      "Training Loss: 0.4046284359693527\n",
      "Training Loss: 0.2895947454869747\n",
      "Training Loss: 0.27132286205887796\n",
      "Validation Loss: 0.23428643084643933\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 170\n",
      "Training Loss: 0.40448323763906957\n",
      "Training Loss: 0.2893172013759613\n",
      "Training Loss: 0.27103503242135046\n",
      "Validation Loss: 0.23398136992133065\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 171\n",
      "Training Loss: 0.4043369873613119\n",
      "Training Loss: 0.2890392927080393\n",
      "Training Loss: 0.2707480669766664\n",
      "Validation Loss: 0.23367778697375502\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 172\n",
      "Training Loss: 0.4041902562230825\n",
      "Training Loss: 0.2887630289420485\n",
      "Training Loss: 0.27046204708516597\n",
      "Validation Loss: 0.23337465558159218\n",
      "Validation Accuracy: 92.63810861423221\n",
      "**************************************************\n",
      "Epoch: 173\n",
      "Training Loss: 0.4040405010432005\n",
      "Training Loss: 0.2884848629310727\n",
      "Training Loss: 0.27017697334289553\n",
      "Validation Loss: 0.2330736101008533\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 174\n",
      "Training Loss: 0.4038911281898618\n",
      "Training Loss: 0.2882058957591653\n",
      "Training Loss: 0.2698924093320966\n",
      "Validation Loss: 0.23277396265040623\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 175\n",
      "Training Loss: 0.4037405421584845\n",
      "Training Loss: 0.28792475029826164\n",
      "Training Loss: 0.26960712563246486\n",
      "Validation Loss: 0.2324753621321046\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 176\n",
      "Training Loss: 0.4035884805768728\n",
      "Training Loss: 0.28764026150107386\n",
      "Training Loss: 0.2693196506053209\n",
      "Validation Loss: 0.23217768247207898\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 177\n",
      "Training Loss: 0.40343521621078254\n",
      "Training Loss: 0.287355083823204\n",
      "Training Loss: 0.2690322358906269\n",
      "Validation Loss: 0.2318811487783207\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 178\n",
      "Training Loss: 0.40327923879027366\n",
      "Training Loss: 0.2870691641792655\n",
      "Training Loss: 0.2687450985237956\n",
      "Validation Loss: 0.23158602835087294\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 179\n",
      "Training Loss: 0.4031201234459877\n",
      "Training Loss: 0.28678226072341206\n",
      "Training Loss: 0.26845841463655234\n",
      "Validation Loss: 0.23129220156187422\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 180\n",
      "Training Loss: 0.40295673042535785\n",
      "Training Loss: 0.28649468276649714\n",
      "Training Loss: 0.26817260909825563\n",
      "Validation Loss: 0.23099953078486946\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 181\n",
      "Training Loss: 0.4027870655059814\n",
      "Training Loss: 0.2862071771547198\n",
      "Training Loss: 0.267881134301424\n",
      "Validation Loss: 0.23070769890975418\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 182\n",
      "Training Loss: 0.40260992221534253\n",
      "Training Loss: 0.2859204399585724\n",
      "Training Loss: 0.2676005252078176\n",
      "Validation Loss: 0.23041585908177192\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 183\n",
      "Training Loss: 0.40242899663746357\n",
      "Training Loss: 0.28562900245189665\n",
      "Training Loss: 0.2673183345422149\n",
      "Validation Loss: 0.23012679848778114\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 184\n",
      "Training Loss: 0.40224050484597684\n",
      "Training Loss: 0.2853335566446185\n",
      "Training Loss: 0.2670381832867861\n",
      "Validation Loss: 0.22984127097585227\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 185\n",
      "Training Loss: 0.40203862585127353\n",
      "Training Loss: 0.2850383846834302\n",
      "Training Loss: 0.26675475787371394\n",
      "Validation Loss: 0.22955204847823368\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 186\n",
      "Training Loss: 0.40183717481791975\n",
      "Training Loss: 0.28474357441067694\n",
      "Training Loss: 0.2664717381447554\n",
      "Validation Loss: 0.22926633202292945\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 187\n",
      "Training Loss: 0.4016273511946201\n",
      "Training Loss: 0.2844476693496108\n",
      "Training Loss: 0.2661909835413098\n",
      "Validation Loss: 0.22898201543963356\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 188\n",
      "Training Loss: 0.4014087999612093\n",
      "Training Loss: 0.2841504871845245\n",
      "Training Loss: 0.26591118235141037\n",
      "Validation Loss: 0.22869928809029333\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 189\n",
      "Training Loss: 0.40118204422295095\n",
      "Training Loss: 0.28385186169296506\n",
      "Training Loss: 0.26563186407089234\n",
      "Validation Loss: 0.2284177147438017\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 190\n",
      "Training Loss: 0.4009458539634943\n",
      "Training Loss: 0.2835531949624419\n",
      "Training Loss: 0.2653528646379709\n",
      "Validation Loss: 0.22813635788271935\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 191\n",
      "Training Loss: 0.4006977229565382\n",
      "Training Loss: 0.28325254876166583\n",
      "Training Loss: 0.26507406529039146\n",
      "Validation Loss: 0.22785657451728755\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 192\n",
      "Training Loss: 0.40044099871069194\n",
      "Training Loss: 0.28295062970370055\n",
      "Training Loss: 0.26479537960141897\n",
      "Validation Loss: 0.2275773708739977\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 193\n",
      "Training Loss: 0.4001717708259821\n",
      "Training Loss: 0.28264789931476114\n",
      "Training Loss: 0.26451689038425685\n",
      "Validation Loss: 0.22729906515124138\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 194\n",
      "Training Loss: 0.3998900992050767\n",
      "Training Loss: 0.28234577007591727\n",
      "Training Loss: 0.2642380511760712\n",
      "Validation Loss: 0.22702040364233295\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 195\n",
      "Training Loss: 0.39959492288529874\n",
      "Training Loss: 0.2820427369698882\n",
      "Training Loss: 0.2639596551284194\n",
      "Validation Loss: 0.2267432664887289\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 196\n",
      "Training Loss: 0.39928997922688725\n",
      "Training Loss: 0.281739596799016\n",
      "Training Loss: 0.263681765422225\n",
      "Validation Loss: 0.22646692420324582\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 197\n",
      "Training Loss: 0.3989732450991869\n",
      "Training Loss: 0.28143655821681024\n",
      "Training Loss: 0.2634040056169033\n",
      "Validation Loss: 0.2261913118235181\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 198\n",
      "Training Loss: 0.3986454143002629\n",
      "Training Loss: 0.28113378476351497\n",
      "Training Loss: 0.26312658946961165\n",
      "Validation Loss: 0.22591630135024532\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 199\n",
      "Training Loss: 0.39830656699836253\n",
      "Training Loss: 0.28083138674497604\n",
      "Training Loss: 0.2628497164323926\n",
      "Validation Loss: 0.22564170911405865\n",
      "Validation Accuracy: 92.63810861423221\n",
      "**************************************************\n",
      "Epoch: 200\n",
      "Training Loss: 0.3979579344764352\n",
      "Training Loss: 0.28053059335798025\n",
      "Training Loss: 0.2625625181943178\n",
      "Validation Loss: 0.22536686908328132\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 201\n",
      "Training Loss: 0.39759872645139693\n",
      "Training Loss: 0.28023287311196327\n",
      "Training Loss: 0.2622921648994088\n",
      "Validation Loss: 0.2250908628273546\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 202\n",
      "Training Loss: 0.39723087891936304\n",
      "Training Loss: 0.2799307683855295\n",
      "Training Loss: 0.26201889634132386\n",
      "Validation Loss: 0.22481729843643275\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 203\n",
      "Training Loss: 0.3968553692102432\n",
      "Training Loss: 0.2796295958384871\n",
      "Training Loss: 0.26174458377063275\n",
      "Validation Loss: 0.22454451058018074\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 204\n",
      "Training Loss: 0.3964731058478355\n",
      "Training Loss: 0.2793287115544081\n",
      "Training Loss: 0.26147022675722836\n",
      "Validation Loss: 0.22427165315727168\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 205\n",
      "Training Loss: 0.3960828973352909\n",
      "Training Loss: 0.2790282567963004\n",
      "Training Loss: 0.26119641445577146\n",
      "Validation Loss: 0.22399898518002434\n",
      "Validation Accuracy: 92.60299625468164\n",
      "**************************************************\n",
      "Epoch: 206\n",
      "Training Loss: 0.39568777844309805\n",
      "Training Loss: 0.2787279253453016\n",
      "Training Loss: 0.2609233531728387\n",
      "Validation Loss: 0.223725648743383\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 207\n",
      "Training Loss: 0.39529063683003185\n",
      "Training Loss: 0.27842789120972156\n",
      "Training Loss: 0.2606510716676712\n",
      "Validation Loss: 0.22345243193460315\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 208\n",
      "Training Loss: 0.3948903176560998\n",
      "Training Loss: 0.27812842428684237\n",
      "Training Loss: 0.26037987679243085\n",
      "Validation Loss: 0.2231784097934037\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 209\n",
      "Training Loss: 0.3944865594431758\n",
      "Training Loss: 0.277829220443964\n",
      "Training Loss: 0.2601095617562532\n",
      "Validation Loss: 0.2229043356655689\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 210\n",
      "Training Loss: 0.39407898429781196\n",
      "Training Loss: 0.277532020509243\n",
      "Training Loss: 0.2598409294709563\n",
      "Validation Loss: 0.2226275366343809\n",
      "Validation Accuracy: 92.56788389513108\n",
      "**************************************************\n",
      "Epoch: 211\n",
      "Training Loss: 0.3936663449555635\n",
      "Training Loss: 0.27723423700779676\n",
      "Training Loss: 0.2595731673017144\n",
      "Validation Loss: 0.22235156938935932\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 212\n",
      "Training Loss: 0.3932544856518507\n",
      "Training Loss: 0.27693755879998205\n",
      "Training Loss: 0.2593067267164588\n",
      "Validation Loss: 0.22207431411475279\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 213\n",
      "Training Loss: 0.3928418703004718\n",
      "Training Loss: 0.27664261654019356\n",
      "Training Loss: 0.2590402437373996\n",
      "Validation Loss: 0.22179660803816292\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 214\n",
      "Training Loss: 0.39242956034839155\n",
      "Training Loss: 0.27634870052337646\n",
      "Training Loss: 0.2587753911316395\n",
      "Validation Loss: 0.22151739660943492\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 215\n",
      "Training Loss: 0.3920194607228041\n",
      "Training Loss: 0.2760563752427697\n",
      "Training Loss: 0.2585102412104607\n",
      "Validation Loss: 0.22123760428656353\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 216\n",
      "Training Loss: 0.39161066345870493\n",
      "Training Loss: 0.27576626900583506\n",
      "Training Loss: 0.2582459932938218\n",
      "Validation Loss: 0.22095651765552798\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 217\n",
      "Training Loss: 0.39120202548801897\n",
      "Training Loss: 0.2754787566885352\n",
      "Training Loss: 0.2579820339754224\n",
      "Validation Loss: 0.22067528084087906\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 218\n",
      "Training Loss: 0.39079455997794865\n",
      "Training Loss: 0.2751940246671438\n",
      "Training Loss: 0.25771931272000076\n",
      "Validation Loss: 0.22039302070154232\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 219\n",
      "Training Loss: 0.3903880251571536\n",
      "Training Loss: 0.27491099666804075\n",
      "Training Loss: 0.25745664101094007\n",
      "Validation Loss: 0.2201107328527429\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 220\n",
      "Training Loss: 0.389984294064343\n",
      "Training Loss: 0.2746320473775268\n",
      "Training Loss: 0.2571952898800373\n",
      "Validation Loss: 0.21982604014069845\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 221\n",
      "Training Loss: 0.38958137631416323\n",
      "Training Loss: 0.2743530833721161\n",
      "Training Loss: 0.25693400129675864\n",
      "Validation Loss: 0.21954245731401978\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 222\n",
      "Training Loss: 0.389182656891644\n",
      "Training Loss: 0.27407610297203067\n",
      "Training Loss: 0.2566738212108612\n",
      "Validation Loss: 0.21925802662801208\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 223\n",
      "Training Loss: 0.3887850612774491\n",
      "Training Loss: 0.27380049262195827\n",
      "Training Loss: 0.2564139456674457\n",
      "Validation Loss: 0.21897374420018678\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 224\n",
      "Training Loss: 0.3883890143036842\n",
      "Training Loss: 0.27352701157331466\n",
      "Training Loss: 0.2561555314809084\n",
      "Validation Loss: 0.2186886514170786\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 225\n",
      "Training Loss: 0.3879941376671195\n",
      "Training Loss: 0.27325477384030816\n",
      "Training Loss: 0.2558973826095462\n",
      "Validation Loss: 0.21840404509828332\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 226\n",
      "Training Loss: 0.38760118678212163\n",
      "Training Loss: 0.27298468675464393\n",
      "Training Loss: 0.2556409876793623\n",
      "Validation Loss: 0.21811885964334682\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 227\n",
      "Training Loss: 0.3872099332511425\n",
      "Training Loss: 0.27271579690277575\n",
      "Training Loss: 0.255385163910687\n",
      "Validation Loss: 0.21783428480116168\n",
      "Validation Accuracy: 92.39232209737827\n",
      "**************************************************\n",
      "Epoch: 228\n",
      "Training Loss: 0.38682183653116226\n",
      "Training Loss: 0.2724486984312534\n",
      "Training Loss: 0.25513108566403386\n",
      "Validation Loss: 0.21754963352773968\n",
      "Validation Accuracy: 92.39232209737827\n",
      "**************************************************\n",
      "Epoch: 229\n",
      "Training Loss: 0.38643704187124966\n",
      "Training Loss: 0.27218244276940823\n",
      "Training Loss: 0.25487773276865483\n",
      "Validation Loss: 0.21726636203487268\n",
      "Validation Accuracy: 92.39232209737827\n",
      "**************************************************\n",
      "Epoch: 230\n",
      "Training Loss: 0.38605388417840003\n",
      "Training Loss: 0.27191888824105265\n",
      "Training Loss: 0.25462661769241096\n",
      "Validation Loss: 0.216982584739669\n",
      "Validation Accuracy: 92.39232209737827\n",
      "**************************************************\n",
      "Epoch: 231\n",
      "Training Loss: 0.38567138500511644\n",
      "Training Loss: 0.27165570452809334\n",
      "Training Loss: 0.2543765188381076\n",
      "Validation Loss: 0.21670056460948472\n",
      "Validation Accuracy: 92.39232209737827\n",
      "**************************************************\n",
      "Epoch: 232\n",
      "Training Loss: 0.3852929385006428\n",
      "Training Loss: 0.27139441270381215\n",
      "Training Loss: 0.25412864200770857\n",
      "Validation Loss: 0.21641906367593935\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 233\n",
      "Training Loss: 0.3849169309437275\n",
      "Training Loss: 0.2711341710761189\n",
      "Training Loss: 0.2538816060125828\n",
      "Validation Loss: 0.21613889522431942\n",
      "Validation Accuracy: 92.39232209737827\n",
      "**************************************************\n",
      "Epoch: 234\n",
      "Training Loss: 0.38454343140125274\n",
      "Training Loss: 0.27087630309164523\n",
      "Training Loss: 0.2536368855088949\n",
      "Validation Loss: 0.2158594351638569\n",
      "Validation Accuracy: 92.39232209737827\n",
      "**************************************************\n",
      "Epoch: 235\n",
      "Training Loss: 0.3841724521666765\n",
      "Training Loss: 0.27062001183629036\n",
      "Training Loss: 0.253392435759306\n",
      "Validation Loss: 0.21558078043581394\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 236\n",
      "Training Loss: 0.38380390528589486\n",
      "Training Loss: 0.2703656308725476\n",
      "Training Loss: 0.25315018590539695\n",
      "Validation Loss: 0.21530357798498667\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 237\n",
      "Training Loss: 0.3834391278401017\n",
      "Training Loss: 0.27011285003274677\n",
      "Training Loss: 0.2529091373831034\n",
      "Validation Loss: 0.21502749153067557\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 238\n",
      "Training Loss: 0.38307760778814554\n",
      "Training Loss: 0.2698624584451318\n",
      "Training Loss: 0.2526701876521111\n",
      "Validation Loss: 0.21475190652555295\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 239\n",
      "Training Loss: 0.38271850883960723\n",
      "Training Loss: 0.2696137323603034\n",
      "Training Loss: 0.2524322470277548\n",
      "Validation Loss: 0.21447762486974845\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 240\n",
      "Training Loss: 0.38236207611858847\n",
      "Training Loss: 0.2693676946312189\n",
      "Training Loss: 0.2521965130791068\n",
      "Validation Loss: 0.21420430869198917\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 241\n",
      "Training Loss: 0.38200863886624575\n",
      "Training Loss: 0.2691232831776142\n",
      "Training Loss: 0.25196171276271345\n",
      "Validation Loss: 0.2139323368835985\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 242\n",
      "Training Loss: 0.3816584349796176\n",
      "Training Loss: 0.2688805639743805\n",
      "Training Loss: 0.2517287325486541\n",
      "Validation Loss: 0.21366178311323852\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 243\n",
      "Training Loss: 0.38131149679422377\n",
      "Training Loss: 0.2686386567354202\n",
      "Training Loss: 0.2514965432137251\n",
      "Validation Loss: 0.21339276725991388\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 244\n",
      "Training Loss: 0.38096721839159725\n",
      "Training Loss: 0.268398955501616\n",
      "Training Loss: 0.251266555339098\n",
      "Validation Loss: 0.21312467628315593\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 245\n",
      "Training Loss: 0.38062517024576664\n",
      "Training Loss: 0.2681603149697185\n",
      "Training Loss: 0.2510373380407691\n",
      "Validation Loss: 0.2128579347823443\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 246\n",
      "Training Loss: 0.38028576284646987\n",
      "Training Loss: 0.2679235950857401\n",
      "Training Loss: 0.25081012822687626\n",
      "Validation Loss: 0.21259255991892867\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 247\n",
      "Training Loss: 0.37994955014437437\n",
      "Training Loss: 0.26768758717924357\n",
      "Training Loss: 0.25058378614485266\n",
      "Validation Loss: 0.21232876968517733\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 248\n",
      "Training Loss: 0.37961915496736764\n",
      "Training Loss: 0.26745300825685264\n",
      "Training Loss: 0.25035849288105966\n",
      "Validation Loss: 0.21206627568502104\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 249\n",
      "Training Loss: 0.37929178986698386\n",
      "Training Loss: 0.26721900448203084\n",
      "Training Loss: 0.25013384871184824\n",
      "Validation Loss: 0.21180568761035298\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 250\n",
      "Training Loss: 0.37896840900182727\n",
      "Training Loss: 0.26698691554367543\n",
      "Training Loss: 0.24991099566221237\n",
      "Validation Loss: 0.21154641544216135\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 251\n",
      "Training Loss: 0.37864768873900173\n",
      "Training Loss: 0.26675560653209685\n",
      "Training Loss: 0.249688956476748\n",
      "Validation Loss: 0.21128862393036318\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 252\n",
      "Training Loss: 0.37833028584718703\n",
      "Training Loss: 0.26652644112706186\n",
      "Training Loss: 0.24946850903332232\n",
      "Validation Loss: 0.2110324375582545\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 253\n",
      "Training Loss: 0.37801589235663413\n",
      "Training Loss: 0.26629821144044397\n",
      "Training Loss: 0.24924858514219522\n",
      "Validation Loss: 0.21077779605147545\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 254\n",
      "Training Loss: 0.3777042776718736\n",
      "Training Loss: 0.2660720032453537\n",
      "Training Loss: 0.24903020452708005\n",
      "Validation Loss: 0.2105247841289874\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 255\n",
      "Training Loss: 0.37739511746913196\n",
      "Training Loss: 0.26584667779505256\n",
      "Training Loss: 0.2488123617321253\n",
      "Validation Loss: 0.2102733472927233\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 256\n",
      "Training Loss: 0.3770892056450248\n",
      "Training Loss: 0.26562335759401323\n",
      "Training Loss: 0.24859627932310105\n",
      "Validation Loss: 0.21002362526199791\n",
      "Validation Accuracy: 92.42743445692884\n",
      "**************************************************\n",
      "Epoch: 257\n",
      "Training Loss: 0.37678543247282503\n",
      "Training Loss: 0.2654009774699807\n",
      "Training Loss: 0.24838110510259867\n",
      "Validation Loss: 0.209775611088517\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 258\n",
      "Training Loss: 0.37648448199033735\n",
      "Training Loss: 0.2651809269934893\n",
      "Training Loss: 0.24816759906709193\n",
      "Validation Loss: 0.20952968357988958\n",
      "Validation Accuracy: 92.46254681647939\n",
      "**************************************************\n",
      "Epoch: 259\n",
      "Training Loss: 0.37618632294237614\n",
      "Training Loss: 0.2649616765230894\n",
      "Training Loss: 0.24795494865626097\n",
      "Validation Loss: 0.2092855859840854\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 260\n",
      "Training Loss: 0.37589139558374884\n",
      "Training Loss: 0.26474436432123183\n",
      "Training Loss: 0.2477439248561859\n",
      "Validation Loss: 0.20904369911785875\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 261\n",
      "Training Loss: 0.37559904120862486\n",
      "Training Loss: 0.2645277713611722\n",
      "Training Loss: 0.24753382574766875\n",
      "Validation Loss: 0.20880345430936706\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 262\n",
      "Training Loss: 0.3753091352060437\n",
      "Training Loss: 0.2643131060153246\n",
      "Training Loss: 0.24732517022639514\n",
      "Validation Loss: 0.2085651827327321\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 263\n",
      "Training Loss: 0.3750223720446229\n",
      "Training Loss: 0.2640990459546447\n",
      "Training Loss: 0.24711696248501538\n",
      "Validation Loss: 0.2083283227481199\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 264\n",
      "Training Loss: 0.3747392790392041\n",
      "Training Loss: 0.26388678230345247\n",
      "Training Loss: 0.2469100597500801\n",
      "Validation Loss: 0.20809326605515532\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 265\n",
      "Training Loss: 0.374458966627717\n",
      "Training Loss: 0.2636753697320819\n",
      "Training Loss: 0.24670384790748356\n",
      "Validation Loss: 0.20785959893732928\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 266\n",
      "Training Loss: 0.3741814506798983\n",
      "Training Loss: 0.26346588421612976\n",
      "Training Loss: 0.2464988249912858\n",
      "Validation Loss: 0.20762758635068207\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 267\n",
      "Training Loss: 0.37390685226768255\n",
      "Training Loss: 0.26325737927109005\n",
      "Training Loss: 0.24629470121115446\n",
      "Validation Loss: 0.20739665175421854\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 268\n",
      "Training Loss: 0.3736345105245709\n",
      "Training Loss: 0.26305076327174903\n",
      "Training Loss: 0.24609197061508895\n",
      "Validation Loss: 0.20716741990842177\n",
      "Validation Accuracy: 92.49765917602996\n",
      "**************************************************\n",
      "Epoch: 269\n",
      "Training Loss: 0.3733642965182662\n",
      "Training Loss: 0.26284518126398326\n",
      "Training Loss: 0.24589002706110477\n",
      "Validation Loss: 0.2069395070665338\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 270\n",
      "Training Loss: 0.373096616640687\n",
      "Training Loss: 0.26264177668839694\n",
      "Training Loss: 0.24568982556462288\n",
      "Validation Loss: 0.20671351731158374\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 271\n",
      "Training Loss: 0.3728313288465142\n",
      "Training Loss: 0.2624397373944521\n",
      "Training Loss: 0.24549088448286058\n",
      "Validation Loss: 0.20648855632275678\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 272\n",
      "Training Loss: 0.3725682375580072\n",
      "Training Loss: 0.26223979212343695\n",
      "Training Loss: 0.24529376972466707\n",
      "Validation Loss: 0.20626533039835063\n",
      "Validation Accuracy: 92.53277153558052\n",
      "**************************************************\n",
      "Epoch: 273\n",
      "Training Loss: 0.3723075072094798\n",
      "Training Loss: 0.2620409892871976\n",
      "Training Loss: 0.24509746324270965\n",
      "Validation Loss: 0.206043516233396\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 274\n",
      "Training Loss: 0.3720496363192797\n",
      "Training Loss: 0.26184445444494486\n",
      "Training Loss: 0.24490264650434257\n",
      "Validation Loss: 0.20582349472836162\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 275\n",
      "Training Loss: 0.37179523024708033\n",
      "Training Loss: 0.2616493297368288\n",
      "Training Loss: 0.24470846280455588\n",
      "Validation Loss: 0.20560477858179071\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 276\n",
      "Training Loss: 0.37154420629143714\n",
      "Training Loss: 0.2614564871788025\n",
      "Training Loss: 0.24451560363173486\n",
      "Validation Loss: 0.20538786313172136\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 277\n",
      "Training Loss: 0.37129593107849357\n",
      "Training Loss: 0.2612648916617036\n",
      "Training Loss: 0.2443234284222126\n",
      "Validation Loss: 0.2051720191421134\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 278\n",
      "Training Loss: 0.37105110604315994\n",
      "Training Loss: 0.26107567369937895\n",
      "Training Loss: 0.24413274899125098\n",
      "Validation Loss: 0.20495791724893483\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 279\n",
      "Training Loss: 0.37080950930714607\n",
      "Training Loss: 0.26088834132999184\n",
      "Training Loss: 0.24394314762204886\n",
      "Validation Loss: 0.2047447773177972\n",
      "Validation Accuracy: 92.43913857677903\n",
      "**************************************************\n",
      "Epoch: 280\n",
      "Training Loss: 0.3705713226273656\n",
      "Training Loss: 0.260704259313643\n",
      "Training Loss: 0.24375561896711587\n",
      "Validation Loss: 0.20453319497657627\n",
      "Validation Accuracy: 92.43913857677903\n",
      "**************************************************\n",
      "Epoch: 281\n",
      "Training Loss: 0.37033593595027925\n",
      "Training Loss: 0.2605217554420233\n",
      "Training Loss: 0.24356911431998016\n",
      "Validation Loss: 0.20432248125585278\n",
      "Validation Accuracy: 92.43913857677903\n",
      "**************************************************\n",
      "Epoch: 282\n",
      "Training Loss: 0.3701039956510067\n",
      "Training Loss: 0.26034164980053903\n",
      "Training Loss: 0.24338437687605619\n",
      "Validation Loss: 0.20411340423514335\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 283\n",
      "Training Loss: 0.3698750672489405\n",
      "Training Loss: 0.2601632206887007\n",
      "Training Loss: 0.24320081882178785\n",
      "Validation Loss: 0.20390526724330496\n",
      "Validation Accuracy: 92.43913857677903\n",
      "**************************************************\n",
      "Epoch: 284\n",
      "Training Loss: 0.36964945334941146\n",
      "Training Loss: 0.2599874735251069\n",
      "Training Loss: 0.24301911924034358\n",
      "Validation Loss: 0.20369873999544744\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 285\n",
      "Training Loss: 0.36942679949104784\n",
      "Training Loss: 0.2598134127631784\n",
      "Training Loss: 0.24283877380192279\n",
      "Validation Loss: 0.2034931778907776\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 286\n",
      "Training Loss: 0.36920729976147415\n",
      "Training Loss: 0.2596420715376735\n",
      "Training Loss: 0.24266040533781053\n",
      "Validation Loss: 0.2032892866415924\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 287\n",
      "Training Loss: 0.3689905136078596\n",
      "Training Loss: 0.2594722567126155\n",
      "Training Loss: 0.2424837401881814\n",
      "Validation Loss: 0.20308633994185524\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 288\n",
      "Training Loss: 0.368776507563889\n",
      "Training Loss: 0.25930519830435517\n",
      "Training Loss: 0.24230939000844956\n",
      "Validation Loss: 0.2028852029797736\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 289\n",
      "Training Loss: 0.3685647738724947\n",
      "Training Loss: 0.25913975287228824\n",
      "Training Loss: 0.24213667780160905\n",
      "Validation Loss: 0.20268496519394136\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 290\n",
      "Training Loss: 0.3683559579774737\n",
      "Training Loss: 0.25897698987275364\n",
      "Training Loss: 0.24196592323482036\n",
      "Validation Loss: 0.20248661357700154\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 291\n",
      "Training Loss: 0.36814982432872057\n",
      "Training Loss: 0.258815858848393\n",
      "Training Loss: 0.24179649502038955\n",
      "Validation Loss: 0.20228933689467024\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 292\n",
      "Training Loss: 0.36794643215835093\n",
      "Training Loss: 0.25865710515528917\n",
      "Training Loss: 0.24162867024540902\n",
      "Validation Loss: 0.20209380511320038\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 293\n",
      "Training Loss: 0.3677458583936095\n",
      "Training Loss: 0.258499578088522\n",
      "Training Loss: 0.24146194364875556\n",
      "Validation Loss: 0.2018990907608793\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 294\n",
      "Training Loss: 0.3675480415672064\n",
      "Training Loss: 0.25834450289607047\n",
      "Training Loss: 0.24129721343517305\n",
      "Validation Loss: 0.20170630070935475\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 295\n",
      "Training Loss: 0.3673524434491992\n",
      "Training Loss: 0.2581905993074179\n",
      "Training Loss: 0.24113356363028288\n",
      "Validation Loss: 0.20151434353228365\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 296\n",
      "Training Loss: 0.3671598081290722\n",
      "Training Loss: 0.25803886730223896\n",
      "Training Loss: 0.2409716148674488\n",
      "Validation Loss: 0.20132410216532395\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 297\n",
      "Training Loss: 0.3669694517552853\n",
      "Training Loss: 0.25788134448230265\n",
      "Training Loss: 0.2407992122322321\n",
      "Validation Loss: 0.20113538004709094\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 298\n",
      "Training Loss: 0.36678322713822126\n",
      "Training Loss: 0.2577332528680563\n",
      "Training Loss: 0.24064927130937577\n",
      "Validation Loss: 0.20094560229041603\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 299\n",
      "Training Loss: 0.36659230902791023\n",
      "Training Loss: 0.2575872672349215\n",
      "Training Loss: 0.24049402087926863\n",
      "Validation Loss: 0.200758563166254\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 300\n",
      "Training Loss: 0.3664084834977984\n",
      "Training Loss: 0.2574433420598507\n",
      "Training Loss: 0.24033919345587493\n",
      "Validation Loss: 0.2005732756401046\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 301\n",
      "Training Loss: 0.366226849257946\n",
      "Training Loss: 0.25730016611516476\n",
      "Training Loss: 0.24018542975187301\n",
      "Validation Loss: 0.20038874497574366\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 302\n",
      "Training Loss: 0.36604827389121053\n",
      "Training Loss: 0.2571589245647192\n",
      "Training Loss: 0.24003293830901384\n",
      "Validation Loss: 0.20020604661006605\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 303\n",
      "Training Loss: 0.365871712975204\n",
      "Training Loss: 0.2570184603706002\n",
      "Training Loss: 0.23988161969929933\n",
      "Validation Loss: 0.20002429245897893\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 304\n",
      "Training Loss: 0.3656974806636572\n",
      "Training Loss: 0.25687978480011225\n",
      "Training Loss: 0.23973167717456817\n",
      "Validation Loss: 0.19984472392315275\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 305\n",
      "Training Loss: 0.3655248183384538\n",
      "Training Loss: 0.2567418883368373\n",
      "Training Loss: 0.2395829015597701\n",
      "Validation Loss: 0.19966632889562777\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 306\n",
      "Training Loss: 0.36535403855144977\n",
      "Training Loss: 0.25660554878413677\n",
      "Training Loss: 0.2394357445091009\n",
      "Validation Loss: 0.19949030457587724\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 307\n",
      "Training Loss: 0.36518421724438666\n",
      "Training Loss: 0.25647002171725036\n",
      "Training Loss: 0.23928963962942362\n",
      "Validation Loss: 0.19931561621219923\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 308\n",
      "Training Loss: 0.3650163147598505\n",
      "Training Loss: 0.2563359175249934\n",
      "Training Loss: 0.23914495415985584\n",
      "Validation Loss: 0.1991429009129492\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 309\n",
      "Training Loss: 0.36484966352581977\n",
      "Training Loss: 0.25620216894894837\n",
      "Training Loss: 0.2390012751892209\n",
      "Validation Loss: 0.19897113568829686\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 310\n",
      "Training Loss: 0.36468502968549726\n",
      "Training Loss: 0.2560699563100934\n",
      "Training Loss: 0.23885894440114497\n",
      "Validation Loss: 0.19880120548304547\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 311\n",
      "Training Loss: 0.3645220547541976\n",
      "Training Loss: 0.25593820575624704\n",
      "Training Loss: 0.238717575147748\n",
      "Validation Loss: 0.19863231886136398\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 312\n",
      "Training Loss: 0.3643611987307668\n",
      "Training Loss: 0.25580782763659954\n",
      "Training Loss: 0.2385774377733469\n",
      "Validation Loss: 0.19846561006950528\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 313\n",
      "Training Loss: 0.36420170452445744\n",
      "Training Loss: 0.2556778114661574\n",
      "Training Loss: 0.23843813333660363\n",
      "Validation Loss: 0.1983001067648443\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 314\n",
      "Training Loss: 0.364044054672122\n",
      "Training Loss: 0.25554910622537136\n",
      "Training Loss: 0.23830028712749482\n",
      "Validation Loss: 0.19813662026537937\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 315\n",
      "Training Loss: 0.36388791736215353\n",
      "Training Loss: 0.25542056173086164\n",
      "Training Loss: 0.2381631786003709\n",
      "Validation Loss: 0.19797430890664625\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 316\n",
      "Training Loss: 0.3637337890267372\n",
      "Training Loss: 0.25529348190873863\n",
      "Training Loss: 0.23802759226411582\n",
      "Validation Loss: 0.19781417834959672\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 317\n",
      "Training Loss: 0.36358104303479194\n",
      "Training Loss: 0.25516642510890963\n",
      "Training Loss: 0.2378927805274725\n",
      "Validation Loss: 0.19765515738491263\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 318\n",
      "Training Loss: 0.3634300893545151\n",
      "Training Loss: 0.2550406789779663\n",
      "Training Loss: 0.23775930982083082\n",
      "Validation Loss: 0.19749834668937694\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 319\n",
      "Training Loss: 0.3632813446223736\n",
      "Training Loss: 0.25491498786956074\n",
      "Training Loss: 0.237626299187541\n",
      "Validation Loss: 0.19734282523728489\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 320\n",
      "Training Loss: 0.36313473716378214\n",
      "Training Loss: 0.25479072604328395\n",
      "Training Loss: 0.2374947215616703\n",
      "Validation Loss: 0.1971894767595811\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 321\n",
      "Training Loss: 0.36298919532448054\n",
      "Training Loss: 0.25466630786657335\n",
      "Training Loss: 0.23736388955265283\n",
      "Validation Loss: 0.19703736608282904\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 322\n",
      "Training Loss: 0.36284558080136775\n",
      "Training Loss: 0.25454313654452565\n",
      "Training Loss: 0.23723445009440183\n",
      "Validation Loss: 0.1968875334838803\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 323\n",
      "Training Loss: 0.3627031218260527\n",
      "Training Loss: 0.254419849999249\n",
      "Training Loss: 0.23710579723119735\n",
      "Validation Loss: 0.1967389445458905\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 324\n",
      "Training Loss: 0.3625622287765145\n",
      "Training Loss: 0.25429772526025773\n",
      "Training Loss: 0.23697849348187447\n",
      "Validation Loss: 0.19659272321824278\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 325\n",
      "Training Loss: 0.36242246598005295\n",
      "Training Loss: 0.254175467453897\n",
      "Training Loss: 0.23685210302472115\n",
      "Validation Loss: 0.19644763370913065\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 326\n",
      "Training Loss: 0.3622844042629004\n",
      "Training Loss: 0.2540543168410659\n",
      "Training Loss: 0.2367271053045988\n",
      "Validation Loss: 0.19630493160881354\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 327\n",
      "Training Loss: 0.3621471491456032\n",
      "Training Loss: 0.2539330055192113\n",
      "Training Loss: 0.23660298686474562\n",
      "Validation Loss: 0.19616355001926422\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 328\n",
      "Training Loss: 0.3620116161182523\n",
      "Training Loss: 0.2538128388673067\n",
      "Training Loss: 0.23648029617965222\n",
      "Validation Loss: 0.19602432717265708\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 329\n",
      "Training Loss: 0.3618760922551155\n",
      "Training Loss: 0.2536922869458795\n",
      "Training Loss: 0.23635841421782972\n",
      "Validation Loss: 0.19588652931237488\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 330\n",
      "Training Loss: 0.3617419912666082\n",
      "Training Loss: 0.25357282981276513\n",
      "Training Loss: 0.23623802877962588\n",
      "Validation Loss: 0.19575096256612393\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 331\n",
      "Training Loss: 0.36160831537097693\n",
      "Training Loss: 0.2534530582651496\n",
      "Training Loss: 0.23611855823546649\n",
      "Validation Loss: 0.1956166024372149\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 332\n",
      "Training Loss: 0.3614758313819766\n",
      "Training Loss: 0.25333444330841304\n",
      "Training Loss: 0.23600069727748632\n",
      "Validation Loss: 0.1954847328532278\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 333\n",
      "Training Loss: 0.3613437069952488\n",
      "Training Loss: 0.25321535520255567\n",
      "Training Loss: 0.23588335700333118\n",
      "Validation Loss: 0.19535414820139327\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 334\n",
      "Training Loss: 0.3612127011269331\n",
      "Training Loss: 0.25309718899428846\n",
      "Training Loss: 0.2357673967257142\n",
      "Validation Loss: 0.195225987625256\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 335\n",
      "Training Loss: 0.36108232077211144\n",
      "Training Loss: 0.2529787689819932\n",
      "Training Loss: 0.23565201193094254\n",
      "Validation Loss: 0.19509897201081342\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 336\n",
      "Training Loss: 0.3609532904997468\n",
      "Training Loss: 0.25286143634468317\n",
      "Training Loss: 0.2355380865558982\n",
      "Validation Loss: 0.19497430977526675\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 337\n",
      "Training Loss: 0.3608244916051626\n",
      "Training Loss: 0.2527436647191644\n",
      "Training Loss: 0.2354252065718174\n",
      "Validation Loss: 0.1948506577212489\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 338\n",
      "Training Loss: 0.3606965647265315\n",
      "Training Loss: 0.2526272112131119\n",
      "Training Loss: 0.2353140675276518\n",
      "Validation Loss: 0.1947292491291346\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 339\n",
      "Training Loss: 0.36056796461343765\n",
      "Training Loss: 0.25251024451106785\n",
      "Training Loss: 0.23520337086170912\n",
      "Validation Loss: 0.19460903706677843\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 340\n",
      "Training Loss: 0.36044051449745895\n",
      "Training Loss: 0.252394602149725\n",
      "Training Loss: 0.23509405042976142\n",
      "Validation Loss: 0.19449119734462728\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 341\n",
      "Training Loss: 0.3603132211789489\n",
      "Training Loss: 0.25227852471172807\n",
      "Training Loss: 0.23498521585017443\n",
      "Validation Loss: 0.1943743841701679\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 342\n",
      "Training Loss: 0.36018699806183574\n",
      "Training Loss: 0.2521637926250696\n",
      "Training Loss: 0.23487784296274186\n",
      "Validation Loss: 0.1942599652272262\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 343\n",
      "Training Loss: 0.36006099976599215\n",
      "Training Loss: 0.2520486854016781\n",
      "Training Loss: 0.23477084506303073\n",
      "Validation Loss: 0.19414652390091608\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 344\n",
      "Training Loss: 0.3599364995956421\n",
      "Training Loss: 0.2519350222125649\n",
      "Training Loss: 0.2346648867428303\n",
      "Validation Loss: 0.19403554181034646\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 345\n",
      "Training Loss: 0.35981248691678047\n",
      "Training Loss: 0.25182103980332615\n",
      "Training Loss: 0.23455935887992382\n",
      "Validation Loss: 0.19392544989672938\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 346\n",
      "Training Loss: 0.3596893625333905\n",
      "Training Loss: 0.25170859165489673\n",
      "Training Loss: 0.23445516377687453\n",
      "Validation Loss: 0.19381763534934332\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 347\n",
      "Training Loss: 0.3595663961023092\n",
      "Training Loss: 0.25159568402916194\n",
      "Training Loss: 0.23435131154954433\n",
      "Validation Loss: 0.19371060005734475\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 348\n",
      "Training Loss: 0.3594445553049445\n",
      "Training Loss: 0.2514843841269612\n",
      "Training Loss: 0.23424888860434293\n",
      "Validation Loss: 0.19360597875345958\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 349\n",
      "Training Loss: 0.3593231339752674\n",
      "Training Loss: 0.2513727430254221\n",
      "Training Loss: 0.23414647147059442\n",
      "Validation Loss: 0.1935021025076341\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 350\n",
      "Training Loss: 0.3592025778070092\n",
      "Training Loss: 0.2512628326192498\n",
      "Training Loss: 0.23404550161212684\n",
      "Validation Loss: 0.19340064372406918\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 351\n",
      "Training Loss: 0.35908200070261953\n",
      "Training Loss: 0.2511525650694966\n",
      "Training Loss: 0.23394466660916804\n",
      "Validation Loss: 0.19329981882585567\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 352\n",
      "Training Loss: 0.35896254658699034\n",
      "Training Loss: 0.2510439961031079\n",
      "Training Loss: 0.233845355771482\n",
      "Validation Loss: 0.1932013650121314\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 353\n",
      "Training Loss: 0.3588433314114809\n",
      "Training Loss: 0.25093509010970594\n",
      "Training Loss: 0.2337460971996188\n",
      "Validation Loss: 0.19310362515657137\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 354\n",
      "Training Loss: 0.35872499860823154\n",
      "Training Loss: 0.25082782316952945\n",
      "Training Loss: 0.2336480652540922\n",
      "Validation Loss: 0.193008098207163\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 355\n",
      "Training Loss: 0.3586071478202939\n",
      "Training Loss: 0.25072024431079626\n",
      "Training Loss: 0.2335501303896308\n",
      "Validation Loss: 0.1929132164026914\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 356\n",
      "Training Loss: 0.35849029537290333\n",
      "Training Loss: 0.2506143869832158\n",
      "Training Loss: 0.23345341056585311\n",
      "Validation Loss: 0.19282059693771803\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 357\n",
      "Training Loss: 0.3583735904097557\n",
      "Training Loss: 0.2505081576853991\n",
      "Training Loss: 0.23335690971463918\n",
      "Validation Loss: 0.19272850466410765\n",
      "Validation Accuracy: 92.43913857677903\n",
      "**************************************************\n",
      "Epoch: 358\n",
      "Training Loss: 0.35825758181512357\n",
      "Training Loss: 0.2504037781059742\n",
      "Training Loss: 0.23326179828494786\n",
      "Validation Loss: 0.19263854141483147\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 359\n",
      "Training Loss: 0.35814160719513893\n",
      "Training Loss: 0.25029898539185524\n",
      "Training Loss: 0.23316687516868115\n",
      "Validation Loss: 0.19254904089683897\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 360\n",
      "Training Loss: 0.3580264039337635\n",
      "Training Loss: 0.2501960534602404\n",
      "Training Loss: 0.23307333521544935\n",
      "Validation Loss: 0.1924617433648431\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 361\n",
      "Training Loss: 0.3579113886505365\n",
      "Training Loss: 0.25009266134351493\n",
      "Training Loss: 0.232979808524251\n",
      "Validation Loss: 0.19237481446915797\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 362\n",
      "Training Loss: 0.35779722571372985\n",
      "Training Loss: 0.24999119937419892\n",
      "Training Loss: 0.23288744565099478\n",
      "Validation Loss: 0.19229012133365267\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 363\n",
      "Training Loss: 0.35768349196761845\n",
      "Training Loss: 0.24988923627883197\n",
      "Training Loss: 0.23279501549899578\n",
      "Validation Loss: 0.1922058214464884\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 364\n",
      "Training Loss: 0.357570505104959\n",
      "Training Loss: 0.2497892402485013\n",
      "Training Loss: 0.2327040384709835\n",
      "Validation Loss: 0.19212354208981053\n",
      "Validation Accuracy: 92.4742509363296\n",
      "**************************************************\n",
      "Epoch: 365\n",
      "Training Loss: 0.35745743367820976\n",
      "Training Loss: 0.24968874115496875\n",
      "Training Loss: 0.23261299580335618\n",
      "Validation Loss: 0.19204159286082462\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 366\n",
      "Training Loss: 0.3573453573510051\n",
      "Training Loss: 0.24959013741463423\n",
      "Training Loss: 0.23252334166318178\n",
      "Validation Loss: 0.19196168341663447\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 367\n",
      "Training Loss: 0.35723321985453366\n",
      "Training Loss: 0.249490994438529\n",
      "Training Loss: 0.23243360456079246\n",
      "Validation Loss: 0.19188215098019396\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 368\n",
      "Training Loss: 0.35712162993848323\n",
      "Training Loss: 0.24939387768507004\n",
      "Training Loss: 0.2323452802374959\n",
      "Validation Loss: 0.19180458043231052\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 369\n",
      "Training Loss: 0.3570100505277514\n",
      "Training Loss: 0.24929617132991552\n",
      "Training Loss: 0.2322568028792739\n",
      "Validation Loss: 0.19172727902618686\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 370\n",
      "Training Loss: 0.3568990858644247\n",
      "Training Loss: 0.24920052457600833\n",
      "Training Loss: 0.23216997351497412\n",
      "Validation Loss: 0.1916519853841053\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 371\n",
      "Training Loss: 0.3567881114780903\n",
      "Training Loss: 0.24910425450652837\n",
      "Training Loss: 0.2320830525830388\n",
      "Validation Loss: 0.1915769281096003\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 372\n",
      "Training Loss: 0.3566775326430798\n",
      "Training Loss: 0.24901017893105745\n",
      "Training Loss: 0.23199789967387915\n",
      "Validation Loss: 0.19150390589002814\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 373\n",
      "Training Loss: 0.3565670023113489\n",
      "Training Loss: 0.24891530647873877\n",
      "Training Loss: 0.23191235143691302\n",
      "Validation Loss: 0.1914311634439431\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 374\n",
      "Training Loss: 0.3564569366723299\n",
      "Training Loss: 0.24882236085832118\n",
      "Training Loss: 0.23182825729250908\n",
      "Validation Loss: 0.19136047359095532\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 375\n",
      "Training Loss: 0.3563471732661128\n",
      "Training Loss: 0.24872873146086932\n",
      "Training Loss: 0.23174387879669667\n",
      "Validation Loss: 0.19128983765003388\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 376\n",
      "Training Loss: 0.35623778082430363\n",
      "Training Loss: 0.2486369750648737\n",
      "Training Loss: 0.23166115701198578\n",
      "Validation Loss: 0.1912211191034719\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 377\n",
      "Training Loss: 0.3561287776380777\n",
      "Training Loss: 0.24854434724897145\n",
      "Training Loss: 0.2315779384598136\n",
      "Validation Loss: 0.1911524763602889\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 378\n",
      "Training Loss: 0.3560200348123908\n",
      "Training Loss: 0.24845376033335925\n",
      "Training Loss: 0.23149654403328895\n",
      "Validation Loss: 0.19108579190594427\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 379\n",
      "Training Loss: 0.3559113754704595\n",
      "Training Loss: 0.24836215004324913\n",
      "Training Loss: 0.23141451042145492\n",
      "Validation Loss: 0.19101920769958014\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 380\n",
      "Training Loss: 0.3558034297451377\n",
      "Training Loss: 0.2482726339623332\n",
      "Training Loss: 0.23133438169956208\n",
      "Validation Loss: 0.19095429593927404\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 381\n",
      "Training Loss: 0.35569568660110235\n",
      "Training Loss: 0.2481805754825473\n",
      "Training Loss: 0.2312531005963683\n",
      "Validation Loss: 0.1908894009218457\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 382\n",
      "Training Loss: 0.35558881096541883\n",
      "Training Loss: 0.24809030637145044\n",
      "Training Loss: 0.2311734289303422\n",
      "Validation Loss: 0.19082650642716484\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 383\n",
      "Training Loss: 0.3554820116236806\n",
      "Training Loss: 0.24799903403967619\n",
      "Training Loss: 0.2310929563641548\n",
      "Validation Loss: 0.1907639851312289\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 384\n",
      "Training Loss: 0.35537642866373065\n",
      "Training Loss: 0.24790999814867973\n",
      "Training Loss: 0.23101374685764312\n",
      "Validation Loss: 0.19070336017548367\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 385\n",
      "Training Loss: 0.355271322876215\n",
      "Training Loss: 0.24781963147222996\n",
      "Training Loss: 0.2309337840601802\n",
      "Validation Loss: 0.19064309904247187\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 386\n",
      "Training Loss: 0.3551672753691673\n",
      "Training Loss: 0.24773147832602263\n",
      "Training Loss: 0.2308554755523801\n",
      "Validation Loss: 0.1905842214153054\n",
      "Validation Accuracy: 92.50936329588016\n",
      "**************************************************\n",
      "Epoch: 387\n",
      "Training Loss: 0.3550635780021548\n",
      "Training Loss: 0.24764211434870959\n",
      "Training Loss: 0.23077640794217585\n",
      "Validation Loss: 0.19052584193060906\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 388\n",
      "Training Loss: 0.35496101327240465\n",
      "Training Loss: 0.24755508609116078\n",
      "Training Loss: 0.23069917868822812\n",
      "Validation Loss: 0.1904686095423243\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 389\n",
      "Training Loss: 0.3548585016280413\n",
      "Training Loss: 0.24746655456721783\n",
      "Training Loss: 0.23062086660414935\n",
      "Validation Loss: 0.19041204481814686\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 390\n",
      "Training Loss: 0.3547570390999317\n",
      "Training Loss: 0.24738055869936942\n",
      "Training Loss: 0.2305445119738579\n",
      "Validation Loss: 0.19035614118649719\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 391\n",
      "Training Loss: 0.35465580455958845\n",
      "Training Loss: 0.2472930710762739\n",
      "Training Loss: 0.23046716403216125\n",
      "Validation Loss: 0.19030113961924328\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 392\n",
      "Training Loss: 0.35455522175878285\n",
      "Training Loss: 0.24720803637057542\n",
      "Training Loss: 0.230391753166914\n",
      "Validation Loss: 0.19024662020501126\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 393\n",
      "Training Loss: 0.3544547025859356\n",
      "Training Loss: 0.2471222421899438\n",
      "Training Loss: 0.23031555250287056\n",
      "Validation Loss: 0.19019324474790122\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 394\n",
      "Training Loss: 0.3543548124283552\n",
      "Training Loss: 0.24703901778906584\n",
      "Training Loss: 0.2302412486076355\n",
      "Validation Loss: 0.19013955791512233\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 395\n",
      "Training Loss: 0.35425502609461546\n",
      "Training Loss: 0.24695432227104902\n",
      "Training Loss: 0.23016575671732425\n",
      "Validation Loss: 0.19008766323997733\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 396\n",
      "Training Loss: 0.3541562654823065\n",
      "Training Loss: 0.2468724487349391\n",
      "Training Loss: 0.23009235929697752\n",
      "Validation Loss: 0.19003434600622465\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 397\n",
      "Training Loss: 0.354057882539928\n",
      "Training Loss: 0.246789040453732\n",
      "Training Loss: 0.23001739602535964\n",
      "Validation Loss: 0.189983393787668\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 398\n",
      "Training Loss: 0.3539594204351306\n",
      "Training Loss: 0.2467083855718374\n",
      "Training Loss: 0.2299445990845561\n",
      "Validation Loss: 0.18993072123842292\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 399\n",
      "Training Loss: 0.3538612704351544\n",
      "Training Loss: 0.24662623714655638\n",
      "Training Loss: 0.22987043093889953\n",
      "Validation Loss: 0.1898807491479295\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 400\n",
      "Training Loss: 0.35376393139362333\n",
      "Training Loss: 0.2465469479188323\n",
      "Training Loss: 0.22979827307164669\n",
      "Validation Loss: 0.18982889511612025\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 401\n",
      "Training Loss: 0.3536669220030308\n",
      "Training Loss: 0.24646587379276752\n",
      "Training Loss: 0.22972454346716403\n",
      "Validation Loss: 0.1897793175715409\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 402\n",
      "Training Loss: 0.3535707591846585\n",
      "Training Loss: 0.2463878146559\n",
      "Training Loss: 0.22965297035872936\n",
      "Validation Loss: 0.18972830290205023\n",
      "Validation Accuracy: 92.54447565543072\n",
      "**************************************************\n",
      "Epoch: 403\n",
      "Training Loss: 0.35347485072910784\n",
      "Training Loss: 0.24630827125161886\n",
      "Training Loss: 0.22958008278161288\n",
      "Validation Loss: 0.18967903221256277\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 404\n",
      "Training Loss: 0.3533797361701727\n",
      "Training Loss: 0.24623137649148702\n",
      "Training Loss: 0.22950907524675132\n",
      "Validation Loss: 0.18962891316145994\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 405\n",
      "Training Loss: 0.3532850119099021\n",
      "Training Loss: 0.24615307487547397\n",
      "Training Loss: 0.2294362661242485\n",
      "Validation Loss: 0.189580085781518\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 406\n",
      "Training Loss: 0.35319110509008167\n",
      "Training Loss: 0.2460776276513934\n",
      "Training Loss: 0.22936538215726615\n",
      "Validation Loss: 0.18953093400831972\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 407\n",
      "Training Loss: 0.35309747237712147\n",
      "Training Loss: 0.24600057665258646\n",
      "Training Loss: 0.2292928049713373\n",
      "Validation Loss: 0.18948275143845697\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 408\n",
      "Training Loss: 0.3530050038546324\n",
      "Training Loss: 0.24592640276998282\n",
      "Training Loss: 0.2292222750931978\n",
      "Validation Loss: 0.18943460503321016\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 409\n",
      "Training Loss: 0.3529126316681504\n",
      "Training Loss: 0.24585065245628357\n",
      "Training Loss: 0.2291500637680292\n",
      "Validation Loss: 0.1893867091432716\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 410\n",
      "Training Loss: 0.3528210858255625\n",
      "Training Loss: 0.24577768318355084\n",
      "Training Loss: 0.22907994914799928\n",
      "Validation Loss: 0.18933934057026766\n",
      "Validation Accuracy: 92.57958801498128\n",
      "**************************************************\n",
      "Epoch: 411\n",
      "Training Loss: 0.352730167619884\n",
      "Training Loss: 0.24570300716906787\n",
      "Training Loss: 0.2290079513564706\n",
      "Validation Loss: 0.18929228605179305\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 412\n",
      "Training Loss: 0.3526400090381503\n",
      "Training Loss: 0.24563124284148216\n",
      "Training Loss: 0.22893792018294334\n",
      "Validation Loss: 0.18924583285377267\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 413\n",
      "Training Loss: 0.35255014285445213\n",
      "Training Loss: 0.2455576454102993\n",
      "Training Loss: 0.22886604305356742\n",
      "Validation Loss: 0.1891995926251572\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 414\n",
      "Training Loss: 0.3524614279717207\n",
      "Training Loss: 0.24548691395670175\n",
      "Training Loss: 0.2287961570546031\n",
      "Validation Loss: 0.18915390759036782\n",
      "Validation Accuracy: 92.61470037453184\n",
      "**************************************************\n",
      "Epoch: 415\n",
      "Training Loss: 0.35237290006130934\n",
      "Training Loss: 0.24541517335921526\n",
      "Training Loss: 0.22872437827289105\n",
      "Validation Loss: 0.18910635271099177\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 416\n",
      "Training Loss: 0.35228506941348314\n",
      "Training Loss: 0.24534443750977517\n",
      "Training Loss: 0.22865404076874257\n",
      "Validation Loss: 0.18906154491928187\n",
      "Validation Accuracy: 92.68492509363297\n",
      "**************************************************\n",
      "Epoch: 417\n",
      "Training Loss: 0.3521987033262849\n",
      "Training Loss: 0.24527233693748712\n",
      "Training Loss: 0.22858198218047618\n",
      "Validation Loss: 0.1890167868120617\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 418\n",
      "Training Loss: 0.3521133806928992\n",
      "Training Loss: 0.2452036328613758\n",
      "Training Loss: 0.2285121137648821\n",
      "Validation Loss: 0.18897169602386069\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 419\n",
      "Training Loss: 0.3520280468836427\n",
      "Training Loss: 0.24513205897063017\n",
      "Training Loss: 0.2284401773288846\n",
      "Validation Loss: 0.1889274629732866\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 420\n",
      "Training Loss: 0.3519438800960779\n",
      "Training Loss: 0.2450657542422414\n",
      "Training Loss: 0.22837095871567725\n",
      "Validation Loss: 0.18888047040345962\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 421\n",
      "Training Loss: 0.3518592890352011\n",
      "Training Loss: 0.2449941736087203\n",
      "Training Loss: 0.22829896185547113\n",
      "Validation Loss: 0.18883673118406466\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 422\n",
      "Training Loss: 0.35177719976752997\n",
      "Training Loss: 0.24492645308375358\n",
      "Training Loss: 0.22822942815721034\n",
      "Validation Loss: 0.18879414759994892\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 423\n",
      "Training Loss: 0.35169527992606164\n",
      "Training Loss: 0.24485692583024501\n",
      "Training Loss: 0.2281583060324192\n",
      "Validation Loss: 0.1887514147112209\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 424\n",
      "Training Loss: 0.3516138739511371\n",
      "Training Loss: 0.24479033667594194\n",
      "Training Loss: 0.22808968402445318\n",
      "Validation Loss: 0.18870953788583197\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 425\n",
      "Training Loss: 0.35153242107480764\n",
      "Training Loss: 0.24472385473549366\n",
      "Training Loss: 0.2280195213854313\n",
      "Validation Loss: 0.1886630572713493\n",
      "Validation Accuracy: 92.6498127340824\n",
      "**************************************************\n",
      "Epoch: 426\n",
      "Training Loss: 0.3514499252662063\n",
      "Training Loss: 0.24465638443827628\n",
      "Training Loss: 0.22795071586966514\n",
      "Validation Loss: 0.18862123996689079\n",
      "Validation Accuracy: 92.68492509363297\n",
      "**************************************************\n",
      "Epoch: 427\n",
      "Training Loss: 0.3513696995005012\n",
      "Training Loss: 0.24458805218338966\n",
      "Training Loss: 0.22788016568869351\n",
      "Validation Loss: 0.18857948959208606\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 428\n",
      "Training Loss: 0.35128996703773735\n",
      "Training Loss: 0.2445226963609457\n",
      "Training Loss: 0.22781220067292451\n",
      "Validation Loss: 0.18853881808646608\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 429\n",
      "Training Loss: 0.3512103081867099\n",
      "Training Loss: 0.2444553454592824\n",
      "Training Loss: 0.2277425142005086\n",
      "Validation Loss: 0.18849779330612568\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 430\n",
      "Training Loss: 0.3511314956098795\n",
      "Training Loss: 0.24439240608364343\n",
      "Training Loss: 0.22767544332891704\n",
      "Validation Loss: 0.1884544159840332\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 431\n",
      "Training Loss: 0.3510517861321569\n",
      "Training Loss: 0.24432446841150524\n",
      "Training Loss: 0.22760557420551777\n",
      "Validation Loss: 0.1884139147534799\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 432\n",
      "Training Loss: 0.3509742707014084\n",
      "Training Loss: 0.24426022510975598\n",
      "Training Loss: 0.22753838531672954\n",
      "Validation Loss: 0.18837414560525606\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 433\n",
      "Training Loss: 0.3508968155086041\n",
      "Training Loss: 0.2441941311582923\n",
      "Training Loss: 0.227469282746315\n",
      "Validation Loss: 0.18833402481474235\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 434\n",
      "Training Loss: 0.35081974692642687\n",
      "Training Loss: 0.24414137169718741\n",
      "Training Loss: 0.22740337237715721\n",
      "Validation Loss: 0.18828900066319476\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 435\n",
      "Training Loss: 0.35074050813913343\n",
      "Training Loss: 0.24407346528023482\n",
      "Training Loss: 0.2273338358476758\n",
      "Validation Loss: 0.18824955138765023\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 436\n",
      "Training Loss: 0.3506655352935195\n",
      "Training Loss: 0.24400287315249444\n",
      "Training Loss: 0.2272674398496747\n",
      "Validation Loss: 0.1882113041251563\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 437\n",
      "Training Loss: 0.35059036340564487\n",
      "Training Loss: 0.2439378532767296\n",
      "Training Loss: 0.22719930671155453\n",
      "Validation Loss: 0.18817310612858013\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 438\n",
      "Training Loss: 0.3505148150399327\n",
      "Training Loss: 0.24387584023177625\n",
      "Training Loss: 0.22713385816663503\n",
      "Validation Loss: 0.18813552460476254\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 439\n",
      "Training Loss: 0.35043914601206777\n",
      "Training Loss: 0.2438113445788622\n",
      "Training Loss: 0.22706646006554365\n",
      "Validation Loss: 0.18809875259908398\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 440\n",
      "Training Loss: 0.35036384616047145\n",
      "Training Loss: 0.2437497289478779\n",
      "Training Loss: 0.22700163055211306\n",
      "Validation Loss: 0.18806207824623986\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 441\n",
      "Training Loss: 0.35028797172009946\n",
      "Training Loss: 0.2436880187690258\n",
      "Training Loss: 0.22693508855998515\n",
      "Validation Loss: 0.18802170141526822\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 442\n",
      "Training Loss: 0.3502107847481966\n",
      "Training Loss: 0.24363285105675458\n",
      "Training Loss: 0.22687059119343758\n",
      "Validation Loss: 0.1879857966069425\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 443\n",
      "Training Loss: 0.35013614758849143\n",
      "Training Loss: 0.24356156677007676\n",
      "Training Loss: 0.22680402718484402\n",
      "Validation Loss: 0.187950517228815\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 444\n",
      "Training Loss: 0.35006131313741207\n",
      "Training Loss: 0.2435009941086173\n",
      "Training Loss: 0.2267405963689089\n",
      "Validation Loss: 0.18791599843776627\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 445\n",
      "Training Loss: 0.3499867866560817\n",
      "Training Loss: 0.24343937199562787\n",
      "Training Loss: 0.22667521126568319\n",
      "Validation Loss: 0.18787932408492217\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 446\n",
      "Training Loss: 0.34991125855594873\n",
      "Training Loss: 0.2433789011836052\n",
      "Training Loss: 0.22661241982132196\n",
      "Validation Loss: 0.18784525253799525\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 447\n",
      "Training Loss: 0.34983614053577183\n",
      "Training Loss: 0.24331661619246006\n",
      "Training Loss: 0.2265475580841303\n",
      "Validation Loss: 0.18781167260381612\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 448\n",
      "Training Loss: 0.3497615113854408\n",
      "Training Loss: 0.24326504435390234\n",
      "Training Loss: 0.22646392147988081\n",
      "Validation Loss: 0.18777306214644668\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 449\n",
      "Training Loss: 0.349687728472054\n",
      "Training Loss: 0.24319991491734982\n",
      "Training Loss: 0.22641477726399897\n",
      "Validation Loss: 0.18773699108134495\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 450\n",
      "Training Loss: 0.3496085703000426\n",
      "Training Loss: 0.24314064353704454\n",
      "Training Loss: 0.2263561449944973\n",
      "Validation Loss: 0.18770453710569424\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 451\n",
      "Training Loss: 0.349533582739532\n",
      "Training Loss: 0.24307993028312921\n",
      "Training Loss: 0.2262936670705676\n",
      "Validation Loss: 0.18767352904496568\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 452\n",
      "Training Loss: 0.349459520727396\n",
      "Training Loss: 0.243022383172065\n",
      "Training Loss: 0.22623362224549054\n",
      "Validation Loss: 0.18764234911859706\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 453\n",
      "Training Loss: 0.34938582438975574\n",
      "Training Loss: 0.2429697302170098\n",
      "Training Loss: 0.226170802898705\n",
      "Validation Loss: 0.18761214894357692\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 454\n",
      "Training Loss: 0.3493126196041703\n",
      "Training Loss: 0.242913367934525\n",
      "Training Loss: 0.22611134395003318\n",
      "Validation Loss: 0.18758194843369924\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 455\n",
      "Training Loss: 0.34923856765031813\n",
      "Training Loss: 0.24285700725391507\n",
      "Training Loss: 0.22604943294078111\n",
      "Validation Loss: 0.18754788161663527\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 456\n",
      "Training Loss: 0.34916285030543803\n",
      "Training Loss: 0.24279994778335096\n",
      "Training Loss: 0.22598913077265023\n",
      "Validation Loss: 0.18751845404170872\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 457\n",
      "Training Loss: 0.3490888034924865\n",
      "Training Loss: 0.24274080127477646\n",
      "Training Loss: 0.22592644967138767\n",
      "Validation Loss: 0.18748987788397276\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 458\n",
      "Training Loss: 0.34901561576873064\n",
      "Training Loss: 0.24268496310338378\n",
      "Training Loss: 0.225866668112576\n",
      "Validation Loss: 0.18746184340018904\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 459\n",
      "Training Loss: 0.348942469060421\n",
      "Training Loss: 0.24263097263872624\n",
      "Training Loss: 0.22579993955790997\n",
      "Validation Loss: 0.18742756047443057\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 460\n",
      "Training Loss: 0.34886719457805154\n",
      "Training Loss: 0.2425739978440106\n",
      "Training Loss: 0.2257432644814253\n",
      "Validation Loss: 0.1873992272977079\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 461\n",
      "Training Loss: 0.3487930528074503\n",
      "Training Loss: 0.24251529814675452\n",
      "Training Loss: 0.22568142402917146\n",
      "Validation Loss: 0.18737224874536643\n",
      "Validation Accuracy: 92.82537453183521\n",
      "**************************************************\n",
      "Epoch: 462\n",
      "Training Loss: 0.3487216721102595\n",
      "Training Loss: 0.24246040774509311\n",
      "Training Loss: 0.22562240723520519\n",
      "Validation Loss: 0.18734624563308244\n",
      "Validation Accuracy: 92.82537453183521\n",
      "**************************************************\n",
      "Epoch: 463\n",
      "Training Loss: 0.34865036442875863\n",
      "Training Loss: 0.24240280056372285\n",
      "Training Loss: 0.22556053400039672\n",
      "Validation Loss: 0.18732057084863105\n",
      "Validation Accuracy: 92.82537453183521\n",
      "**************************************************\n",
      "Epoch: 464\n",
      "Training Loss: 0.3485794880986214\n",
      "Training Loss: 0.2423488374054432\n",
      "Training Loss: 0.22550189405679702\n",
      "Validation Loss: 0.1872959766495094\n",
      "Validation Accuracy: 92.82537453183521\n",
      "**************************************************\n",
      "Epoch: 465\n",
      "Training Loss: 0.3485081259161234\n",
      "Training Loss: 0.24229220053181053\n",
      "Training Loss: 0.2254405226558447\n",
      "Validation Loss: 0.18727068330967026\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 466\n",
      "Training Loss: 0.34843713622540234\n",
      "Training Loss: 0.24224304724484683\n",
      "Training Loss: 0.2253797674924135\n",
      "Validation Loss: 0.1872400084322088\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 467\n",
      "Training Loss: 0.3483626917749643\n",
      "Training Loss: 0.24218437211588026\n",
      "Training Loss: 0.2253204594552517\n",
      "Validation Loss: 0.18721500373958203\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 468\n",
      "Training Loss: 0.3482923575863242\n",
      "Training Loss: 0.24213059512898327\n",
      "Training Loss: 0.22526276774704457\n",
      "Validation Loss: 0.18719202870230997\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 469\n",
      "Training Loss: 0.3482220373675227\n",
      "Training Loss: 0.24207452030852436\n",
      "Training Loss: 0.2252023560926318\n",
      "Validation Loss: 0.18716916010788318\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 470\n",
      "Training Loss: 0.34815191980451343\n",
      "Training Loss: 0.2420219623297453\n",
      "Training Loss: 0.22514522306621074\n",
      "Validation Loss: 0.18714779795388156\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 471\n",
      "Training Loss: 0.34808193139731886\n",
      "Training Loss: 0.2419663017243147\n",
      "Training Loss: 0.22508531007915736\n",
      "Validation Loss: 0.18712600513120717\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 472\n",
      "Training Loss: 0.34801210135221483\n",
      "Training Loss: 0.24191521257162094\n",
      "Training Loss: 0.2250286017358303\n",
      "Validation Loss: 0.18710443126351645\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 473\n",
      "Training Loss: 0.3479407027363777\n",
      "Training Loss: 0.24185996737331153\n",
      "Training Loss: 0.22496880635619163\n",
      "Validation Loss: 0.18708263538526684\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 474\n",
      "Training Loss: 0.3478709029406309\n",
      "Training Loss: 0.24181128052994608\n",
      "Training Loss: 0.22491264972835778\n",
      "Validation Loss: 0.18705710107355975\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 475\n",
      "Training Loss: 0.3477978687733412\n",
      "Training Loss: 0.24175541756674648\n",
      "Training Loss: 0.22485264278948308\n",
      "Validation Loss: 0.18703661113977432\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 476\n",
      "Training Loss: 0.3477275644242763\n",
      "Training Loss: 0.24170435708016158\n",
      "Training Loss: 0.2247962835431099\n",
      "Validation Loss: 0.18701748315537914\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 477\n",
      "Training Loss: 0.347657171562314\n",
      "Training Loss: 0.2416509459167719\n",
      "Training Loss: 0.2247371378913522\n",
      "Validation Loss: 0.186996490432975\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 478\n",
      "Training Loss: 0.3475857111439109\n",
      "Training Loss: 0.2416025771573186\n",
      "Training Loss: 0.2246811605989933\n",
      "Validation Loss: 0.18697609497087725\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 479\n",
      "Training Loss: 0.34751110365614296\n",
      "Training Loss: 0.24155995881184936\n",
      "Training Loss: 0.22460043519735337\n",
      "Validation Loss: 0.1869453013864126\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 480\n",
      "Training Loss: 0.34742955980822443\n",
      "Training Loss: 0.24151680804789066\n",
      "Training Loss: 0.22455998081713915\n",
      "Validation Loss: 0.18691500640484723\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 481\n",
      "Training Loss: 0.3473323556408286\n",
      "Training Loss: 0.24147977018728853\n",
      "Training Loss: 0.2245026133581996\n",
      "Validation Loss: 0.1868772026611848\n",
      "Validation Accuracy: 92.86048689138578\n",
      "**************************************************\n",
      "Epoch: 482\n",
      "Training Loss: 0.34722353765740993\n",
      "Training Loss: 0.24144563779234887\n",
      "Training Loss: 0.22444660853594542\n",
      "Validation Loss: 0.1868382357479481\n",
      "Validation Accuracy: 92.86048689138578\n",
      "**************************************************\n",
      "Epoch: 483\n",
      "Training Loss: 0.34711135813966393\n",
      "Training Loss: 0.24140346432104706\n",
      "Training Loss: 0.22438887398689986\n",
      "Validation Loss: 0.1868044086470363\n",
      "Validation Accuracy: 92.86048689138578\n",
      "**************************************************\n",
      "Epoch: 484\n",
      "Training Loss: 0.34699898660182954\n",
      "Training Loss: 0.24136425506323575\n",
      "Training Loss: 0.22433609295636414\n",
      "Validation Loss: 0.18677758165959563\n",
      "Validation Accuracy: 92.86048689138578\n",
      "**************************************************\n",
      "Epoch: 485\n",
      "Training Loss: 0.346892636269331\n",
      "Training Loss: 0.24132199788466097\n",
      "Training Loss: 0.22428238444030285\n",
      "Validation Loss: 0.18675261648016028\n",
      "Validation Accuracy: 92.86048689138578\n",
      "**************************************************\n",
      "Epoch: 486\n",
      "Training Loss: 0.3467951534315944\n",
      "Training Loss: 0.24128391318023204\n",
      "Training Loss: 0.22423387307673692\n",
      "Validation Loss: 0.1867320921397611\n",
      "Validation Accuracy: 92.86048689138578\n",
      "**************************************************\n",
      "Epoch: 487\n",
      "Training Loss: 0.34670335236936806\n",
      "Training Loss: 0.24124290408566595\n",
      "Training Loss: 0.22418368089944124\n",
      "Validation Loss: 0.1867113814929898\n",
      "Validation Accuracy: 92.82537453183521\n",
      "**************************************************\n",
      "Epoch: 488\n",
      "Training Loss: 0.34661592185497286\n",
      "Training Loss: 0.2412050318904221\n",
      "Training Loss: 0.22413760162889956\n",
      "Validation Loss: 0.18669428395923604\n",
      "Validation Accuracy: 92.82537453183521\n",
      "**************************************************\n",
      "Epoch: 489\n",
      "Training Loss: 0.3465340300090611\n",
      "Training Loss: 0.24116384794935583\n",
      "Training Loss: 0.2240893479064107\n",
      "Validation Loss: 0.18667651583137138\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 490\n",
      "Training Loss: 0.3464573596790433\n",
      "Training Loss: 0.24112654196098446\n",
      "Training Loss: 0.2240446611866355\n",
      "Validation Loss: 0.1866635060712193\n",
      "Validation Accuracy: 92.79026217228466\n",
      "**************************************************\n",
      "Epoch: 491\n",
      "Training Loss: 0.3463850378990173\n",
      "Training Loss: 0.2410846378467977\n",
      "Training Loss: 0.22399720903486015\n",
      "Validation Loss: 0.1866530357451921\n",
      "Validation Accuracy: 92.75514981273409\n",
      "**************************************************\n",
      "Epoch: 492\n",
      "Training Loss: 0.34631776943802833\n",
      "Training Loss: 0.24104393154382706\n",
      "Training Loss: 0.22395175736397505\n",
      "Validation Loss: 0.18665255501531483\n",
      "Validation Accuracy: 92.72003745318352\n",
      "**************************************************\n",
      "Epoch: 493\n",
      "Training Loss: 0.3462501673400402\n",
      "Training Loss: 0.24099289251491426\n",
      "Training Loss: 0.22390174724161624\n",
      "Validation Loss: 0.18665496134356166\n",
      "Validation Accuracy: 92.72003745318352\n",
      "INFO: Validation loss did not improve in epoch 493\n",
      "**************************************************\n",
      "Epoch: 494\n",
      "Training Loss: 0.3461879652738571\n",
      "Training Loss: 0.24094304390251636\n",
      "Training Loss: 0.22385389376431702\n",
      "Validation Loss: 0.18666096525580694\n",
      "Validation Accuracy: 92.72003745318352\n",
      "INFO: Validation loss did not improve in epoch 494\n",
      "**************************************************\n",
      "Epoch: 495\n",
      "Training Loss: 0.34612516693770884\n",
      "Training Loss: 0.24088768290355803\n",
      "Training Loss: 0.22377719251438977\n",
      "Validation Loss: 0.18666782698939355\n",
      "Validation Accuracy: 92.72003745318352\n",
      "INFO: Validation loss did not improve in epoch 495\n",
      "**************************************************\n",
      "Epoch: 496\n",
      "Training Loss: 0.3460622055828571\n",
      "Training Loss: 0.24083859780803324\n",
      "Training Loss: 0.22374928303062916\n",
      "Validation Loss: 0.18667072693953354\n",
      "Validation Accuracy: 92.72003745318352\n",
      "INFO: Validation loss did not improve in epoch 496\n",
      "**************************************************\n",
      "Epoch: 497\n",
      "Training Loss: 0.3459939752146602\n",
      "Training Loss: 0.24078345200046897\n",
      "Training Loss: 0.22369983818382025\n",
      "Validation Loss: 0.18667420447709854\n",
      "Validation Accuracy: 92.72003745318352\n",
      "INFO: Validation loss did not improve in epoch 497\n",
      "Early stopping after 497 epochs\n"
     ]
    }
   ],
   "source": [
    "if BENCHMARK:\n",
    "        \n",
    "    results = pd.DataFrame(columns=['Feature', 'Metric', 'Value'])\n",
    "    test_accs = []\n",
    "    test_losses = []\n",
    "\n",
    "    for i in range(5):\n",
    "        # get baseline performance\n",
    "        train_loader, test_loader, val_loader = create_data_loader(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "        trained_model = train_model_once(len(FEATURES)-1, train_loader, val_loader)\n",
    "        test_acc, test_loss = get_test_performance(trained_model, X_test, y_test)\n",
    "\n",
    "        test_accs.append(test_acc)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    # save baseline performance\n",
    "    results = pd.concat([results, pd.DataFrame([{'Feature': 'baseline', 'Metric': 'Accuracy', 'Value': np.mean(np.array(test_accs))}])], ignore_index=True)\n",
    "    results = pd.concat([results, pd.DataFrame([{'Feature': 'baseline', 'Metric': 'Loss', 'Value': np.mean(np.array(test_losses))}])], ignore_index=True)\n",
    "\n",
    "    for feature in FEATURES[1:]:\n",
    "\n",
    "        print(f'Current feature: {feature}')\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        for i in range(5):\n",
    "            print(f'Iteration {i+1}')\n",
    "\n",
    "            # random permutation of one specific feature\n",
    "            feature_index = FEATURES.index(feature)-1 # -1 because of the trend feature\n",
    "            permuted_X_test = dc(X_test)\n",
    "            permuted_X_test[:, :, feature_index] = torch.tensor(np.random.permutation(permuted_X_test[:, :, feature_index]), dtype=torch.float32)\n",
    "\n",
    "            train_loader, test_loader, val_loader = create_data_loader(X_train, y_train, permuted_X_test, y_test, X_val, y_val)\n",
    "            trained_model = train_model_once(len(FEATURES)-1, train_loader, val_loader)\n",
    "            test_acc, test_loss = get_test_performance(trained_model, permuted_X_test, y_test)\n",
    "\n",
    "            test_accs.append(test_acc)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        # save performance\n",
    "        results = pd.concat([results, pd.DataFrame([{'Feature': feature, 'Metric': 'Accuracy', 'Value': np.mean(np.array(test_accs))}])], ignore_index=True)\n",
    "        results = pd.concat([results, pd.DataFrame([{'Feature': feature, 'Metric': 'Loss', 'Value': np.mean(np.array(test_accs))}])], ignore_index=True)\n",
    "\n",
    "else:\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "    val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    if CLASSIFICATION:\n",
    "        print('Using BCEWithLogitsLoss for classification')\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        print('Using MSELoss for regression')\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "\n",
    "    model = LSTMClassification(\n",
    "            device=device,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            input_size=X_train.shape[2], # number of features\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_stacked_layers=NUM_LAYERS,\n",
    "            bidirectional=BIDIRECTIONAL,\n",
    "            output_logits=OUTPUT_LOGITS\n",
    "        ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_losses, train_accs, val_losses, val_accs, model = train_model(model=model,\n",
    "                        train_loader=train_loader,\n",
    "                        val_loader=val_loader,\n",
    "                        criterion=criterion,\n",
    "                        optimizer=optimizer,\n",
    "                        device=device,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if BENCHMARK:\n",
    "\n",
    "    # Erstelle eine Pivot-Tabelle, um die Daten besser zu handhaben\n",
    "    pivot_df = results.pivot(index='Feature', columns='Metric', values='Value')\n",
    "\n",
    "    # Sortiere die Daten nach den Accuracy-Werten\n",
    "    pivot_df = pivot_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "    # Anzahl der Features\n",
    "    num_features = len(pivot_df.index)\n",
    "\n",
    "    # Initialisiere die Hauptfigur und die Hauptachse\n",
    "    fig, ax1 = plt.subplots(figsize=(10, num_features * 0.4))  # Höhe proportional zur Anzahl der Features\n",
    "\n",
    "    # Balkenbreite\n",
    "    bar_height = 0.35\n",
    "\n",
    "    # Positionen der Balken\n",
    "    r1 = np.arange(len(pivot_df.index))\n",
    "    r2 = [x + bar_height for x in r1]\n",
    "\n",
    "    # Balken für Accuracy\n",
    "    accuracy_bars = ax1.barh(r1, pivot_df['Accuracy'], color='skyblue', height=bar_height, label='Accuracy')\n",
    "\n",
    "    # Zweite y-Achse für Loss\n",
    "    ax2 = ax1.twiny()\n",
    "    loss_bars = ax2.barh(r2, pivot_df['Loss'], color='salmon', height=bar_height, label='Loss')\n",
    "\n",
    "    # Titel und Achsenbeschriftungen hinzufügen\n",
    "    ax1.set_title('Feature Importance: Accuracy and Loss', fontsize=16)\n",
    "    ax1.set_ylabel('Feature', fontsize=14)\n",
    "    ax1.set_xlabel('Accuracy', fontsize=14, color='skyblue')\n",
    "    ax2.set_xlabel('Loss', fontsize=14, color='salmon')\n",
    "\n",
    "    # y-Ticks setzen\n",
    "    ax1.set_yticks([r + bar_height/2 for r in range(len(pivot_df.index))])\n",
    "    ax1.set_yticklabels(pivot_df.index)\n",
    "\n",
    "    # Achsenbeschriftungen einfärben\n",
    "    ax1.tick_params(axis='x', labelcolor='skyblue')\n",
    "    ax2.tick_params(axis='x', labelcolor='salmon')\n",
    "\n",
    "    # Legenden kombinieren\n",
    "    bars = accuracy_bars + loss_bars\n",
    "    labels = [bar.get_label() for bar in bars]\n",
    "    ax1.legend(bars, labels, loc='lower right')\n",
    "\n",
    "    # Diagramm anzeigen\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "    # Diagramm 1 (oben links)\n",
    "    axs[0, 0].plot(train_losses, label=\"MSELoss\")\n",
    "    axs[0, 0].set_title('Training Loss')\n",
    "\n",
    "    axs[0, 1].plot(val_losses, label=\"MSELoss\")\n",
    "    axs[0, 1].set_title('Validation Loss')\n",
    "\n",
    "    axs[1, 0].plot(train_accs, label=\"Accuracy\")\n",
    "    axs[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "    axs[1, 1].plot(val_accs, label=\"Accuracy\")\n",
    "    axs[1, 1].set_title('Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.21384872496128082\n",
      "Test Accuracy: 92.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/9qymy01n6cnff41vb6p0yj_80000gn/T/ipykernel_46649/3543369078.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_acc = accuracy(y_true=y_test, y_pred=torch.tensor(test_preds))\n"
     ]
    }
   ],
   "source": [
    "if CLASSIFICATION:\n",
    "    acc, loss = get_test_performance(model, X_test, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "    print(f'Test Accuracy: {acc}')\n",
    "\n",
    "else:\n",
    "    with torch.inference_mode(): \n",
    "        test_preds = model(X_test.to(device)) # get plain model output (logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CLASSIFICATION:\n",
    "    start = 350\n",
    "    end = start + 24*7\n",
    "\n",
    "    # plot actual vs predicted traffic volume\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(y_test[start:end], label='Actual Values', color='b')\n",
    "    plt.plot(test_preds[start:end], label='Predictions', color='r', alpha=0.7)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Traffic Volume')\n",
    "    plt.title('Actual vs Predicted Traffic Volume')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plot last feature vs predicted traffic volume\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(X_test[start:end, -1, 0], label='Last Value From Feature', color='b')\n",
    "    plt.plot(test_preds[start:end], label='Predictions', color='r', alpha=0.7)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Traffic Volume')\n",
    "    plt.title('Last Feature Traffic Volume vs Predicted Traffic Volume')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # calculate cross-correlation\n",
    "    def cross_correlation(x, y):\n",
    "        correlation = torch.nn.functional.conv1d(\n",
    "            x.unsqueeze(0).unsqueeze(0), \n",
    "            y.flip(0).unsqueeze(0).unsqueeze(0),\n",
    "            padding=x.size(0) - 1\n",
    "        ).squeeze().numpy()\n",
    "        lags = np.arange(-(x.size(0) - 1), x.size(0))\n",
    "        return correlation, lags\n",
    "\n",
    "    correlation, lags = cross_correlation(test_preds[start:start+5].flatten(), X_test[start:start+5, -1, 0])\n",
    "\n",
    "    # plot cross-correlation\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(lags, correlation, label='Cross-Correlation', color='b')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Correlation')\n",
    "    plt.title('Cross-Correlation between Predictions and Feature')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series_data_augmentation_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
